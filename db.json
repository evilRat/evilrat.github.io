{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"source/ads.txt","path":"ads.txt","modified":0,"renderable":0},{"_id":"themes/3-hexo/source/css/gitalk.css","path":"css/gitalk.css","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/mobile.styl","path":"css/mobile.styl","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/style.styl","path":"css/style.styl","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/img/alipay.png","path":"img/alipay.png","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/img/article-list-background.jpeg","path":"img/article-list-background.jpeg","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/img/brown-papersq.png","path":"img/brown-papersq.png","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/img/school-book.png","path":"img/school-book.png","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/img/weixin.png","path":"img/weixin.png","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/js/iconfont.js","path":"js/iconfont.js","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/js/jquery.autocomplete.min.js","path":"js/jquery.autocomplete.min.js","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/js/jquery.pjax.js","path":"js/jquery.pjax.js","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/js/search.js","path":"js/search.js","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/js/script.js","path":"js/script.js","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/fonts/icomoon.eot","path":"css/fonts/icomoon.eot","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/fonts/icomoon.ttf","path":"css/fonts/icomoon.ttf","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/fonts/icomoon.svg","path":"css/fonts/icomoon.svg","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/fonts/icomoon.woff","path":"css/fonts/icomoon.woff","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/fonts/iconfont.eot","path":"css/fonts/iconfont.eot","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/fonts/iconfont.svg","path":"css/fonts/iconfont.svg","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/fonts/iconfont.ttf","path":"css/fonts/iconfont.ttf","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/fonts/iconfont.woff","path":"css/fonts/iconfont.woff","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/fonts/selection.json","path":"css/fonts/selection.json","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/hl_theme/atom-dark.styl","path":"css/hl_theme/atom-dark.styl","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/hl_theme/atom-light.styl","path":"css/hl_theme/atom-light.styl","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/hl_theme/brown-paper.styl","path":"css/hl_theme/brown-paper.styl","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/hl_theme/darcula.styl","path":"css/hl_theme/darcula.styl","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/hl_theme/github-gist.styl","path":"css/hl_theme/github-gist.styl","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/hl_theme/github.styl","path":"css/hl_theme/github.styl","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/hl_theme/gruvbox-dark.styl","path":"css/hl_theme/gruvbox-dark.styl","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/hl_theme/gruvbox-light.styl","path":"css/hl_theme/gruvbox-light.styl","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/hl_theme/kimbie-dark.styl","path":"css/hl_theme/kimbie-dark.styl","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/hl_theme/kimbie-light.styl","path":"css/hl_theme/kimbie-light.styl","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/hl_theme/railscasts.styl","path":"css/hl_theme/railscasts.styl","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/hl_theme/rainbow.styl","path":"css/hl_theme/rainbow.styl","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/hl_theme/school-book.styl","path":"css/hl_theme/school-book.styl","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/hl_theme/sublime.styl","path":"css/hl_theme/sublime.styl","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/hl_theme/sunburst.styl","path":"css/hl_theme/sunburst.styl","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/hl_theme/zenbum.styl","path":"css/hl_theme/zenbum.styl","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/img/avatar.png","path":"img/avatar.png","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/js/gitalk.js","path":"js/gitalk.js","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/js/gitment.js","path":"js/gitment.js","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/img/gongzhonghao.png","path":"img/gongzhonghao.png","modified":0,"renderable":1}],"Cache":[{"_id":"themes/3-hexo/.gitignore","hash":"86a50fa08e69cab561892aa5edef24f9081bbde1","modified":1678259158853},{"_id":"source/.DS_Store","hash":"556a424650221d4eca5c3eeda829861b4d900267","modified":1680509582990},{"_id":"themes/3-hexo/LICENSE.bak","hash":"34cce6b041640a2283f75337f39b94c5beb0b15b","modified":1678259158853},{"_id":"themes/3-hexo/README.md","hash":"e09f474a250f3e862d1d1c2a0c2af675e756a31a","modified":1678259158853},{"_id":"themes/3-hexo/_config.yml","hash":"03c0df597252ea08ef18dd7bd294b207a878fba5","modified":1716089062473},{"_id":"source/ads.txt","hash":"72acced352e6dd9cb6f7fcba103c8bd65798ecf2","modified":1678259158836},{"_id":"themes/3-hexo/.git_bak/HEAD","hash":"acbaef275e46a7f14c1ef456fff2c8bbe8c84724","modified":1678259158845},{"_id":"themes/3-hexo/.git_bak/config","hash":"024eec43f4595faf3e671b7491a8685bbe82c293","modified":1678259158845},{"_id":"themes/3-hexo/.git_bak/description","hash":"9635f1b7e12c045212819dd934d809ef07efa2f4","modified":1678259158845},{"_id":"themes/3-hexo/.git_bak/index","hash":"ad9b130adf5dcad076b30790d8bd7b98e1d0405c","modified":1678259158846},{"_id":"themes/3-hexo/.git_bak/packed-refs","hash":"e24e7e35870da3d7e40bdad484fefa0f6d191b9c","modified":1678259158852},{"_id":"themes/3-hexo/layout/index.ejs","hash":"003421f9a57927aa85aa71905313badb0b47820e","modified":1678259158855},{"_id":"themes/3-hexo/layout/post.ejs","hash":"810f046277fc49f523a72d1552eab1e39d3c299c","modified":1678259158855},{"_id":"themes/3-hexo/layout/indexs.md","hash":"f52e3550db4b1050cddd23de0e63803cc8ebe1d2","modified":1678259807943},{"_id":"source/_posts/.DS_Store","hash":"5e72e5907d3d67617fbbc27e4efbd905c123d3e6","modified":1679540301706},{"_id":"source/_posts/2016-05-20-kongzheng1993-DB_Exchange.md","hash":"7b4b8bfa113a2319ef25823573b0842057ed036a","modified":1678259158769},{"_id":"source/_posts/2016-05-20-kongzheng1993-Properties.md","hash":"8fab38116cada9d1d88f8ba0d2a8097024abdbb4","modified":1678259158769},{"_id":"source/_posts/2016-05-20-kongzheng1993-Session.md","hash":"4e98f4a6f2c46296f57c2f5485170e0e0a879247","modified":1678259158769},{"_id":"source/_posts/2016-05-20-kongzheng1993-aboutFloat.md","hash":"f38ad542a69cff341bd628e67d6ded3f23e47510","modified":1678259158769},{"_id":"source/_posts/2016-05-20-kongzheng1993-servlet.md","hash":"63be4bc099a4207ddaf9784b9e3b01a6283e9485","modified":1678259158769},{"_id":"source/_posts/2016-05-20-kongzheng1993-method_of_request&response.md","hash":"2ca39f26e868c955655ffcd2dc3c296c6fa3c5dd","modified":1678259158769},{"_id":"source/_posts/2016-05-21-kongzheng1993-resume.html","hash":"94fe7a322be890a2d63d4912eea4b850beb8f1e4","modified":1716087144512},{"_id":"source/_posts/2016-05-20-kongzheng1993-请求转发与重定向.md","hash":"e5794cb17fc61d0059c0189d0f599b65d938eeef","modified":1678259158770},{"_id":"source/_posts/2016-06-10-kongzheng1993-thewayofsort.md","hash":"0d477fd78ad2d6ed68b7e07ca0c4e65705356e04","modified":1678259158771},{"_id":"source/_posts/2016-06-13-kongzheng1993-String_Original.md","hash":"39e5f529c7153533f15017c4bd2a412a87ff79dc","modified":1678259158771},{"_id":"source/_posts/2016-05-21-kongzheng1993-resume.md","hash":"b51cec39c2e9b62f662dc685ec487673cf469879","modified":1716088384661},{"_id":"source/_posts/2016-06-13-kongzheng1993-aboutFinal.md","hash":"b203cfab59c6ec922791dd7c71efaada1eb0463c","modified":1678259158771},{"_id":"source/_posts/2016-06-16-kongzheng1993-synchronized.md","hash":"f897dbbd6b79fdbd2d0794f210bf050892df5fa4","modified":1678259158771},{"_id":"source/_posts/2016-07-13-kongzheng1993-oracle.md","hash":"205e4ccdafe87e4fac9da0ebc502c1f45e7e0b9c","modified":1678259158772},{"_id":"source/_posts/2016-07-11-kongzheng1993-ablout_try_catch.md","hash":"7984088331b692e275063b11305b69a612f29400","modified":1678259158772},{"_id":"source/_posts/2016-07-21-kongzheng1993-OracleAfterChangetheNameofComputer.md","hash":"e7e060dad0bc6abffa7aae19e0329f0d4fbc174b","modified":1678259158772},{"_id":"source/_posts/2016-07-05-kongzheng1993-PreparedStatement&Statement.md","hash":"87f9bbf1493087e52e901f44c86123a5ac5504a2","modified":1678259158772},{"_id":"source/_posts/2016-07-23-kongzheng1993-about_sqlplus_sys.md","hash":"d21ce78832a6deb77e6f79ef498bf3bc888f8aef","modified":1678259158772},{"_id":"source/_posts/2017-03-08-kongzheng1993-JavaReflect.md","hash":"2a9cf40cc2e6e69fc32852f446b25c9d2b01c0e1","modified":1678259158772},{"_id":"source/_posts/2017-03-08-kongzheng1993-有关字符串的笔记.md","hash":"0ac1e3de015e01cde177236d361254c3d980cf93","modified":1678259158773},{"_id":"source/_posts/2017-03-09-kongzheng1993-about_comparator_and_comparable.md","hash":"b69eec9e8dc19dfa9e4f14583310c303beb06e8c","modified":1678259158773},{"_id":"source/_posts/2018-02-01-kongzheng1993-hexo搭建githubPages.md","hash":"2dd5d99a91fbabf1daf02b1d70aa3a35971b509d","modified":1678259158773},{"_id":"source/_posts/2017-03-28-kongzheng1993-centos7_mysql.md","hash":"d273b67052f14530b95af8a95b9968cbbf93b283","modified":1678259158773},{"_id":"source/_posts/2018-02-07-kongzheng1993-suse_ftp服务配置.md","hash":"6deb96a53563ec01f57c7c97a04e06e0be85d14d","modified":1678259158773},{"_id":"source/_posts/2018-05-02-kongzheng1993-linux命令行下的ss.md","hash":"da052339bcca40eef1a990bf0e05fb04a2365801","modified":1678259158773},{"_id":"source/_posts/2018-08-05-kongzheng1993-mysql数据库导出导入.md","hash":"8f03e3d38389b52e32e5fcf15f2a6a72048c41c3","modified":1678259158774},{"_id":"source/_posts/2019-05-30-kongzheng1993-生产部署illegal-character.md","hash":"f04a462842b71f72b421482c9cba8f45939756d6","modified":1678259158774},{"_id":"source/_posts/2019-06-04-kongzheng1993-MQ.md","hash":"3a57677cbf994056f1870ab1e3b326545c0f02b4","modified":1678259158775},{"_id":"source/_posts/2019-06-05-kongzheng1993-nohup和&.md","hash":"8877a816e2c5d9bf326d6c4a1e425c77c5a013e4","modified":1678259158775},{"_id":"source/_posts/2019-06-11-kongzheng1993-关于分布式锁.md","hash":"5f07c51adcdea34631730fea299d8d4c886e996f","modified":1678259158775},{"_id":"source/_posts/2019-06-13-kongzheng1993-Connect-timed-out与Read-timed-out.md","hash":"da27436f43a221420a737f973271899cb1101aa4","modified":1678259158775},{"_id":"source/_posts/2019-06-13-kongzheng1993-RSA加密与SHA签名.md","hash":"995d84255e5e5d385828a1f50186e771c9ee28f2","modified":1678259158775},{"_id":"source/_posts/2019-06-05-kongzheng1993-关于学习业务的思考.md","hash":"1d969cb57722ac103257ecd913fcdbc557de4ef4","modified":1678259158775},{"_id":"source/_posts/2019-06-14-kongzheng1993-mysql超过最大连接数-一次生产问题定位.md","hash":"99041b0b94e1d5109777ec4c9a973993f60d58f7","modified":1678259158775},{"_id":"source/_posts/2019-08-18-kongzheng1993-HashMap&ConcurrentHashMap.md","hash":"40ea81133b12456f678a7532aa52b4fb017726bc","modified":1678259158776},{"_id":"source/_posts/2019-09-11-kongzheng1993-NIO&BIO.md","hash":"adb68112d705b27ac4f8eff7aa39dc3d9eed2f84","modified":1678259158776},{"_id":"source/_posts/2019-09-11-kongzheng1993-MySQL基础.md","hash":"fc8c2db331fa19cb8d413df3a5a196fa7773031a","modified":1678259158776},{"_id":"source/_posts/2020-03-06-kongzheng1993-Guava.md","hash":"6238b7b56ec4487eb48332324fbbe3ce15558763","modified":1678259158776},{"_id":"source/_posts/2020-03-08-kongzheng1993-Map遍历的几种方法.md","hash":"65e3e1e3e47521327a7759c194268a1d72bb3b1e","modified":1678259158776},{"_id":"source/_posts/2020-03-08-kongzheng1993-URLEncode.md","hash":"75c6e9fc33e1e2a9912be9d49863a1d5139af020","modified":1678259158777},{"_id":"source/_posts/2020-03-08-kongzheng1993-jhat.md","hash":"6ce81b26deff16216671797627083136524c4078","modified":1678259158777},{"_id":"source/_posts/2020-03-08-kongzheng1993-jmap.md","hash":"afae20b36f1a9e799890a483e53dcb8cbc382ebe","modified":1678259158777},{"_id":"source/_posts/2020-03-25-kongzheng1993-RocketMQ定时消息示例.md","hash":"2736c92c486b2563fd02e51583293103997a6dc0","modified":1678259158783},{"_id":"source/_posts/2020-03-19-kongzheng1993-Future.md","hash":"0816167e7b3a759b7e75fc511fb06352302d6987","modified":1678259158783},{"_id":"source/_posts/2020-03-08-kongzheng1993-带你撸一台免费云服务器.md","hash":"218c90265541291502abd8b1dae70361e3b7b853","modified":1678259158777},{"_id":"source/_posts/2020-03-25-kongzheng1993-一次老代码优化.md","hash":"901e2f913d0fafad40eb9344cbb2d65061aaa52c","modified":1678259158783},{"_id":"source/_posts/2020-03-30-kongzheng1993-一次老代码优化2.md","hash":"5cec72c41a59c99fa6e0ff3425726b4c90c1a8b6","modified":1678259158783},{"_id":"source/_posts/2020-03-19-kongzheng1993-Thread和Runnable.md","hash":"5331a00dc8b7a64bf1715c5de757a16c85dbc349","modified":1678259158783},{"_id":"source/_posts/2020-03-30-kongzheng1993-用nodejs做一个测试api服务.md","hash":"16f52be12576043cd5af9afda02c7e87fb5f3b70","modified":1678259158784},{"_id":"source/_posts/2020-04-02-kongzheng1993-localStorage.md","hash":"03ab36a8bf91dbbab1b1028c2be19c6e3b493d21","modified":1678259158785},{"_id":"source/_posts/2020-04-04-kongzheng1993-TCP三次握手&四次挥手.md","hash":"1e25918e300eedcad9b9f88e2f6d41475efb9b53","modified":1678259158785},{"_id":"source/_posts/2020-04-08-kongzheng1993-chromebook再次折腾crouton.md","hash":"aae84494ec0f7ed0a7ef8fbeda02b81f7fc37ec0","modified":1678259158792},{"_id":"source/_posts/2020-04-06-kongzheng1993-Effective_Java学习笔记1.md","hash":"860119d70160698324cf80ad0fdcdead445c6923","modified":1678259158790},{"_id":"source/_posts/2020-04-09-kongzheng1993-OpenMessageing_Example.md","hash":"4506cb2434aaea8a5313b9bac10fc02df62a9bf3","modified":1678259158794},{"_id":"source/_posts/2020-04-09-kongzheng1993-TransactionMessage.md","hash":"a9ff77fe0911f9f0c0462e6211c1626003c59fbc","modified":1678259158794},{"_id":"source/_posts/2020-04-14-kongzheng1993-CAS.md","hash":"154d4ebe83642b9ea524c4c4743232cb84c5ebff","modified":1678259158794},{"_id":"source/_posts/2020-04-14-kongzheng1993-JavaObjectHeader.md","hash":"96549450d615769c734e5dce7ceed0826673af87","modified":1678259158795},{"_id":"source/_posts/2020-04-09-kongzheng1993-序列化与反序列化.md","hash":"be582c20ee05cb17da182affbb99e0a069256c10","modified":1678259158794},{"_id":"source/_posts/2020-04-17-kongzheng1993-Java_Monitor.md","hash":"21e9dfc6047faac47cae58129c4fe200f60a5aab","modified":1678259158795},{"_id":"source/_posts/2020-04-17-kongzheng1993-MySQL事务隔离级别.md","hash":"57bfc689653b633b0d11bb49653d69f2d17790d0","modified":1678259158795},{"_id":"source/_posts/2020-04-19-kongzheng1993-Java就是值传递的.md","hash":"b24144ae94c81a5956d998c315be169f7ada4a8e","modified":1678259158795},{"_id":"source/_posts/2020-04-21-kongzheng1993-synchronized锁升级.md","hash":"df396e5dbfb2aaa02b4ae29cbf323600111fc526","modified":1678259158796},{"_id":"source/_posts/2020-04-22-kongzheng1993-SQL优化.md","hash":"26b33c8b44b118c6a59b7abc6efd4a7708dbc9ac","modified":1678259158797},{"_id":"source/_posts/2020-04-20-kongzheng1993-JVM.md","hash":"a612254ad560c14fb716faf246a204e0f951d51b","modified":1678259158796},{"_id":"source/_posts/2020-04-24-kongzheng1993-SPI.md","hash":"d816a9d029dca482e79c464bc97df7933f440c0d","modified":1678259158797},{"_id":"source/_posts/2020-04-25-kongzheng1993-死锁.md","hash":"1d1339f23380a290ef1482380ea5e116281e3511","modified":1678259158798},{"_id":"source/_posts/2020-04-26-kongzheng1993-银行家算法.md","hash":"6425f8f43f5512ac818e0f1b1debfa7201e9e1ef","modified":1678259158798},{"_id":"source/_posts/2020-04-27-kongzheng1993-java.lang.IllegalMonitorStateException.md","hash":"61ec56b827b77190272694d73f9255cba892695a","modified":1678259158798},{"_id":"source/_posts/2020-04-28-kongzheng1993-devtools.md","hash":"b7ae6e9478112b5b66db91b4a22797200cb5634b","modified":1678259158798},{"_id":"source/_posts/2020-04-29-kongzheng1993-各种索引.md","hash":"bb264ef36ad7fb17e9e4872a3a9cf46b6eaf7820","modified":1678259158799},{"_id":"source/_posts/2020-05-09-kongzheng1993-数据库设计范式.md","hash":"06ad6b6d5ae6d86490f29cb69016839b8a58a362","modified":1678259158801},{"_id":"source/_posts/2020-04-30-kongzheng1993-一次服务器告警的处理.md","hash":"ee320eb2e708a9ac5c007122036d6562b6c6bf2c","modified":1678259158800},{"_id":"source/_posts/2020-05-12-kongzheng1993-Linux文件句柄.md","hash":"32677694dbe90aaf174524a87c3bec40898db35a","modified":1678259158801},{"_id":"source/_posts/2020-05-15-kongzheng1993-Nginx.md","hash":"019892414c1b96600003ece230f7462c1dc0995f","modified":1678259158801},{"_id":"source/_posts/2020-05-15-kongzheng1993-ThreadPool总结.md","hash":"e040844817f791b3074d8c9cc01d642594798a66","modified":1678259158801},{"_id":"source/_posts/2020-05-19-kongzheng1993-maven_install.md","hash":"5b123c7d0d44de9d9d7343eb8791f08b4b1c9c78","modified":1678259158802},{"_id":"source/_posts/2020-05-21-kongzheng1993-分布式事务.md","hash":"4d46076663a67ed618b9847237571341d399174c","modified":1678259158802},{"_id":"source/_posts/2020-06-29-kongzheng1993-NLP.md","hash":"6549bbc26e56e31323388b72563a7dd2d2b4380b","modified":1678259158803},{"_id":"source/_posts/2020-05-29-kongzheng1993-Java动态代理.md","hash":"72d36ae73f0d842fd06e2a8f81f7df8b4a84a202","modified":1678259158803},{"_id":"source/_posts/2020-05-22-kongzheng1993-Unicast_Multicast_Broadcast.md","hash":"5244c5a8b6a6f22f50926c63b6c93d4af341c853","modified":1678259158803},{"_id":"source/_posts/2020-07-05-kongzheng1993-Java-rmi.md","hash":"fcaf20624579e7d7470b4f7d195aec580ebe6c31","modified":1678259158805},{"_id":"source/_posts/2020-07-05-kongzheng1993-move-to-csdn.md","hash":"825e4c591576c6ced6417c7dc0a2fba1bc6e7a21","modified":1678259158805},{"_id":"source/_posts/2020-07-11-kongzheng1993-think-in-md-catalog.md","hash":"4d7197e94d536205d556d290d89a310761afb5d5","modified":1678259158806},{"_id":"source/_posts/2020-07-26-kongzheng1993-java调用外部程序.md","hash":"8de1cf470f9c0da1432cd6e5fecbacea5c62c05c","modified":1678259158807},{"_id":"source/_posts/2020-10-21-kongzheng1993-原生js实现双击复制后的思考.md","hash":"4d1965fcbadaf918976cd103b48b6b9828ef52f2","modified":1678259158807},{"_id":"source/_posts/2020-07-26-kongzheng1993-apollo.md","hash":"fb14aae6e1d56170cf7b71c77fb0807152cc1195","modified":1678259158806},{"_id":"source/_posts/2020-10-19-kongzheng1993-Vue.prototype.md","hash":"a95900290213cd6bfc611a59d8d93f70fb1a4c16","modified":1678259158807},{"_id":"source/_posts/2020-10-23-kongzheng1993-SpringBoot自定义starter.md","hash":"f3bd091a356735ee9a100ede00f0d5fa1c5040d5","modified":1678259158808},{"_id":"source/_posts/2020-11-11-kongzheng1993-StopWatch.md","hash":"7dd71f740e552b465f33ee034aff1939781e5289","modified":1678259158808},{"_id":"source/_posts/2020-11-11-kongzheng1993-乐观锁实现方式.md","hash":"26634e56c37812d64f3f25a6215b8debc284a14e","modified":1678259158808},{"_id":"source/_posts/2020-12-18-kongzheng1993-iframe重复加载的问题.md","hash":"f5139a8d512fc62fdd5d08d3fb0c1d65712e2605","modified":1678259158808},{"_id":"source/_posts/2020-12-29-kongzheng1993-javax.script.md","hash":"758f39b335d9dc2cc3e53af2ca7192f5346fbf2b","modified":1678259158808},{"_id":"source/_posts/2020-12-18-kongzheng1993-避免浏览器缓存的技巧.md","hash":"be4f1e48a2338aa1ffaa44a9dd6b45272b71de5e","modified":1678259158808},{"_id":"source/_posts/2021-01-04-kongzheng1993-PageHelper.md","hash":"d13d320f9bda25615c4c69679192b58729c7fd7b","modified":1678259158808},{"_id":"source/_posts/2021-01-07-kongzheng1993-包装类型存在的意义.md","hash":"07ea01f747cd9fe2d0c811170727773f9c7a0d53","modified":1678259158808},{"_id":"source/_posts/2021-01-21-kongzheng1993-Java8Lambda.md","hash":"50dc0620833aa283ba741f73c6f3ae2865d4d3d3","modified":1678259158808},{"_id":"source/_posts/2021-02-05-kongzheng1993-Vue学习笔记.md","hash":"d50fc3930e5650e41492b2a96e940bd52717bb99","modified":1678259158809},{"_id":"source/_posts/2021-01-22-kongzheng1993-MySQL技术内幕读书笔记.md","hash":"c07626b81b5bda0e66cd4c22d6f3bd503c10cddc","modified":1678259158808},{"_id":"source/_posts/2021-02-02-kongzheng1993-Vue父子组件之间传递参数.md","hash":"7291cd49a2869d86749b1168b23ca0b134439559","modified":1678259158808},{"_id":"source/_posts/2021-02-05-kongzheng1993-Win10下的wls中git状态不对的问题.md","hash":"c4a7bf350aa02e70cf81f003dd5324bc87277f3f","modified":1678259158809},{"_id":"source/_posts/2021-03-15-kongzheng1993-FeignClient遇到的小问题.md","hash":"7612a6b20933d78997b7a3effd4dee4e6d42f274","modified":1678259158809},{"_id":"source/_posts/2021-03-27-kongzheng1993-JavaRemoteDebug.md","hash":"f0f3eccc7d2b24aac25e17375b9b4174f3ee7d66","modified":1678259158809},{"_id":"source/_posts/2021-03-29-kongzheng1993-JavaRetry.md","hash":"15e84ba09eee3f5ebcba47b358b46ee0867db9d9","modified":1678259158809},{"_id":"source/_posts/2021-04-29-kongzheng1993-getResource.md","hash":"393ee8a68970f0d62a7436e74695336426750e8a","modified":1678259158809},{"_id":"source/_posts/2021-06-06-kongzheng1993-最近的一些感悟.md","hash":"6316151b744ace4aca4cf3402a7f3fa1826c6870","modified":1678259158810},{"_id":"source/_posts/2021-07-01-kongzheng1993-springMVC消息转换器.md","hash":"ffb5e6d5557843b029b088c129747779b3e53d9d","modified":1678259158810},{"_id":"source/_posts/2021-07-04-kongzheng1993-JVM调优.md","hash":"f88e3d847ea3af49e6da8f4a1ac575c649b722f3","modified":1678259158812},{"_id":"source/_posts/2021-07-13-kongzheng1993-泛型.md","hash":"b328d7b8b93030db6ea0d32d044802f5a8a16af0","modified":1678259158813},{"_id":"source/_posts/2021-07-15-kongzheng1993-MongoDB.md","hash":"d945dde0c9ec60b02739afc017fe83c66e9bf2c1","modified":1678259158814},{"_id":"source/_posts/2021-07-25-kongzheng1993-mysql联表查询字符集不一致不走索引.md","hash":"f17d23469f4c24be6ae2fbc1a108bc5fffbf6757","modified":1678259158815},{"_id":"source/_posts/2021-07-25-kongzheng1993-关于编译.md","hash":"d53356c33eb53b3e3ede258eecad88dcee3d4281","modified":1678259158815},{"_id":"source/_posts/2021-07-15-kongzheng1993-feign上传文件.md","hash":"0ca4a5bb36b2682efee7fd4d359abd7c7afde63e","modified":1678259158814},{"_id":"source/_posts/2021-10-08-kongzheng1993-Java异常和错误.md","hash":"cc1ae60b72751ef67a586911b488e60b0824ea1e","modified":1678259158815},{"_id":"source/_posts/2021-10-08-kongzheng1993-Spring启动过程代码跟踪.md","hash":"e844302804982b627cb98d45e5864698b77d14ea","modified":1678259158815},{"_id":"source/_posts/2021-10-08-kongzheng1993-Spring是如何解决循环依赖的（三级缓存）.md","hash":"ac66b39ede3a8d537d4abb66123e0d4b31302e1a","modified":1678259158815},{"_id":"source/_posts/2021-11-03-kongzheng1993-Feign_Request_Header_is_too_large.md","hash":"b1d2fc5b51ccb89a88d9cdfe5ac8f07671fef3f2","modified":1678259158815},{"_id":"source/_posts/2021-11-26-kongzheng1993-记一次频繁FullGC解决.md","hash":"24fb27fb69787730c16db7a0900c97f4fd91a4b9","modified":1678259158815},{"_id":"source/_posts/2021-11-29-kongzheng1993-BigDecimal.md","hash":"f7182ffb55a90a9071588d9b5e1204df19aacd1a","modified":1678259158815},{"_id":"source/_posts/2021-11-29-kongzheng1993-hs_err_pid_pid_log.md","hash":"a7198010897a827502e0cea3856d914b25c77f11","modified":1678259158815},{"_id":"source/_posts/2021-11-29-kongzheng1993-maven_resource_plugin.md","hash":"297d353a3e21e959e69cdc8567798bc63d4426f5","modified":1678259158818},{"_id":"source/_posts/2021-11-29-kongzheng1993-spring_session.md","hash":"4488a8537bfe31b96da0b9170df37729da248ec4","modified":1678259158819},{"_id":"source/_posts/2021-11-29-kongzheng1993-mysql_bitMap.md","hash":"002286c7de398333e409f2bcfe316e95bf566d0e","modified":1678259158819},{"_id":"source/_posts/2022-01-09-kongzheng1993-MySQL性能优化.md","hash":"ca22ead0adf2ec60fa9f71e90b9a192782cde50f","modified":1678259158820},{"_id":"source/_posts/2022-01-09-kongzheng1993-jsoup遇到的问题.md","hash":"1f8f2f38ab78723adaa5bab4d97a4f359b11678a","modified":1678259158820},{"_id":"source/_posts/2022-02-20-kongzheng1993-MySQL_MVCC.md","hash":"93158a44445a222db33ffe6b8f2f14ae590aff88","modified":1678259158820},{"_id":"source/_posts/2022-03-02-kongzheng1993-DevTools.md","hash":"aa8943f1ea5f970189439ce927aaf9077d29cd65","modified":1678259158820},{"_id":"source/_posts/2022-03-05-kongzheng1993-JVM知识点总结.md","hash":"4b7fd20097bed3d69cb15f0855c4b7073c836eff","modified":1678259158821},{"_id":"source/_posts/2022-03-09-kongzheng1993-包装类==的问题.md","hash":"f11b07b075a96f9c2095b1cb061a3c4880f1458c","modified":1678259158823},{"_id":"source/_posts/2022-05-06-kongzheng1993-spring_provides.md","hash":"d862e366211b0e18a71b64f67e1b0345032c32a8","modified":1678259158832},{"_id":"source/_posts/2022-03-10-kongzheng1993-DDD.md","hash":"98ba64cbe3982d388a65855309f8c254263e89e7","modified":1678259158824},{"_id":"source/_posts/2022-03-10-kongzheng1993-review_point.md","hash":"fd05ea70997ed12d543bde108725b952c98d10e0","modified":1678259158829},{"_id":"source/_posts/2022-04-15-kongzheng1993-FastThrow.md","hash":"29bd2ef345a6374a9e46178cf539397b89efff24","modified":1678259158829},{"_id":"source/_posts/2022-06-12-kongzheng1993-volatile.md","hash":"3fc44d407d57a71a2bfe2ee94b1cb10830c61076","modified":1678259158832},{"_id":"source/_posts/2022-06-22-kongzheng1993-主键自增.md","hash":"bb4925b1c035d47b94c0cf0c15669f4fed77d286","modified":1678259158833},{"_id":"source/_posts/2022-07-12-kongzheng1993-package-info.md","hash":"fe782ae63a36fcc57b560b5889bad2664c97a05b","modified":1678259158833},{"_id":"source/_posts/2022-07-02-kongzheng1993-MySQL中的锁.md","hash":"7563631b5ec6fdbb3f0bfdda0d95ffe729304d7a","modified":1678259158833},{"_id":"source/_posts/2022-07-14-kongzheng1993-NoSuchMethodError.md","hash":"eb6ea9bc082a64f66f64817545aaad98678916c4","modified":1678259158833},{"_id":"source/_posts/2022-09-25-kongzheng1993-为什么需要JMM.md","hash":"f37e54b06b8bdf69ac340b261bac6c9827d5d6de","modified":1678259158834},{"_id":"source/_posts/2022-11-19-kongzheng1993-feign继承特性.md","hash":"f28a5304449f262324e1aee31a71564477988ad8","modified":1678259158834},{"_id":"source/_posts/2022-09-25-kongzheng1993-双检锁.md","hash":"bbfe1acfa8b7b72fbf0bc7e0b54f594c8560a146","modified":1678259158834},{"_id":"source/_posts/2023-02-20-kongzheng1993-kafka.md","hash":"85610749c1786023d4c009a48b0bb084ef882e03","modified":1678259158835},{"_id":"source/_posts/2023-02-16-kongzheng1993-eureka_ribbon.md","hash":"2d3d596aac57969e04ef46d5a2d8da3f492e4c8c","modified":1678259158835},{"_id":"source/_posts/2023-03-07-kongzheng1993-think-in-springmvc-and-acutator.md","hash":"d4cac864ccb6fa7e2a1a10d91e47d36e96a0a69b","modified":1679539883198},{"_id":"source/_posts/npm-debug.log","hash":"e76c99ac93259e7c89a028677d9190318bfb9762","modified":1678259158836},{"_id":"source/_posts/2023-01-30-kongzheng1993-Netty.md","hash":"db4a188f924f3dd76befbaea27b0d398349efb9d","modified":1680243569691},{"_id":"source/_posts/2023-03-23-kongzheng1993-服务日志实现方式切换引起的问题.md","hash":"f2774a47e646987d14777089b527217690cdff02","modified":1679556610999},{"_id":"source/_posts/2018-06-08-kongzheng1993-java多线程总结.md","hash":"1c3147a681fb74858e487de927a14268306e05b5","modified":1678259158773},{"_id":"themes/3-hexo/.git_bak/hooks/applypatch-msg.sample","hash":"4de88eb95a5e93fd27e78b5fb3b5231a8d8917dd","modified":1678259158845},{"_id":"themes/3-hexo/.git_bak/hooks/commit-msg.sample","hash":"ee1ed5aad98a435f2020b6de35c173b75d9affac","modified":1678259158845},{"_id":"themes/3-hexo/.git_bak/hooks/fsmonitor-watchman.sample","hash":"f7c0aa40cb0d620ff0bca3efe3521ec79e5d7156","modified":1678259158845},{"_id":"themes/3-hexo/.git_bak/hooks/post-update.sample","hash":"b614c2f63da7dca9f1db2e7ade61ef30448fc96c","modified":1678259158845},{"_id":"themes/3-hexo/.git_bak/hooks/pre-commit.sample","hash":"33729ad4ce51acda35094e581e4088f3167a0af8","modified":1678259158845},{"_id":"themes/3-hexo/.git_bak/hooks/pre-push.sample","hash":"5c8518bfd1d1d3d2c1a7194994c0a16d8a313a41","modified":1678259158845},{"_id":"themes/3-hexo/.git_bak/hooks/pre-applypatch.sample","hash":"f208287c1a92525de9f5462e905a9d31de1e2d75","modified":1678259158845},{"_id":"themes/3-hexo/.git_bak/hooks/prepare-commit-msg.sample","hash":"2584806ba147152ae005cb675aa4f01d5d068456","modified":1678259158845},{"_id":"themes/3-hexo/.git_bak/hooks/update.sample","hash":"e729cd61b27c128951d139de8e7c63d1a3758dde","modified":1678259158846},{"_id":"themes/3-hexo/.git_bak/hooks/pre-receive.sample","hash":"705a17d259e7896f0082fe2e9f2c0c3b127be5ac","modified":1678259158845},{"_id":"themes/3-hexo/.git_bak/info/exclude","hash":"bb5a85730dcf100facee799c05cc4f6affec0745","modified":1678259158846},{"_id":"themes/3-hexo/.git_bak/logs/HEAD","hash":"dcfc493e902b78444b98c0e8bd1b7433ec574764","modified":1678259158846},{"_id":"themes/3-hexo/.git_bak/hooks/pre-rebase.sample","hash":"288efdc0027db4cfd8b7c47c4aeddba09b6ded12","modified":1678259158845},{"_id":"themes/3-hexo/layout/_partial/article.ejs","hash":"a0a0f191faafca2aa14abd32ec1b1a385dae1af7","modified":1678259158853},{"_id":"themes/3-hexo/layout/_partial/article_copyright.ejs","hash":"7f28d7736133cc8012fbb8a5eeeb1174b862aec6","modified":1678259158853},{"_id":"themes/3-hexo/layout/_partial/copyright.ejs","hash":"d209ddcfd0149760a30837076be345a09e1797c5","modified":1678259158854},{"_id":"themes/3-hexo/layout/_partial/comment.ejs","hash":"5507b4dfab2032345e012a0c5356f63b01395157","modified":1678259158854},{"_id":"themes/3-hexo/layout/_partial/footer.ejs","hash":"9ba925f69d273c8f802e67a99eadd21da91b5673","modified":1678259158854},{"_id":"themes/3-hexo/layout/_partial/dashang.ejs","hash":"122f28c7623ed4cb030039449462656f9ca6c7ac","modified":1678259158854},{"_id":"themes/3-hexo/layout/_partial/friends.ejs","hash":"7a31274da81c076021692ff7c80a1be3bbf6fa4c","modified":1678259158854},{"_id":"themes/3-hexo/layout/_partial/full-toc.ejs","hash":"f39f2ab3a67042e55cd6a51792bfd5ad697808f0","modified":1678259158854},{"_id":"themes/3-hexo/layout/_partial/header.ejs","hash":"7b5cf037296e0d695ac6e447275e2f8daeb2abfc","modified":1678259158854},{"_id":"themes/3-hexo/layout/_partial/mathjax.ejs","hash":"c2e5cef2377884cd79e5f686fe4f74b082744306","modified":1678259158854},{"_id":"themes/3-hexo/layout/_partial/meta.ejs","hash":"4f7e00e37783208cb350842085f1987ee854452e","modified":1678259158855},{"_id":"themes/3-hexo/layout/_partial/nav-left.ejs","hash":"c2c08485361645d7e75addb7a458647477a6f8db","modified":1678259158855},{"_id":"themes/3-hexo/layout/_partial/nav-right.ejs","hash":"ad54659a10f0c75b502da6f0ae07f18f55c9d3ab","modified":1678259158855},{"_id":"themes/3-hexo/layout/_partial/tag.ejs","hash":"71340ddd60ea14061771463140e299204ecf7ed9","modified":1678259158855},{"_id":"themes/3-hexo/layout/_partial/toc-ref.ejs","hash":"6406251dabda66ef686d4c15edbc3061b6d828b8","modified":1678259158855},{"_id":"themes/3-hexo/source/css/gitalk.css","hash":"58177ce227c50ee359fbf99a4fdd26058887afc5","modified":1678259158857},{"_id":"themes/3-hexo/source/css/mobile.styl","hash":"3934bcba5095e7e6c6b3a801a6e4fa3a35096e10","modified":1678259158859},{"_id":"themes/3-hexo/source/css/style.styl","hash":"c7285882370f522c3bb17055cdf615cf92f48cd0","modified":1678259158859},{"_id":"themes/3-hexo/source/img/alipay.png","hash":"73ca818d426466ce3df646a300768e8629ddbddf","modified":1678259158860},{"_id":"themes/3-hexo/source/img/article-list-background.jpeg","hash":"4fdf8b3e53dd02d6ee6360aebfadb0cba1fb5633","modified":1678259158860},{"_id":"themes/3-hexo/source/img/brown-papersq.png","hash":"3a1332ede3a75a3d24f60b6ed69035b72da5e182","modified":1678259158861},{"_id":"themes/3-hexo/source/img/school-book.png","hash":"711ec983c874e093bb89eb77afcbdf6741fa61ee","modified":1678259158868},{"_id":"themes/3-hexo/source/img/weixin.png","hash":"b243e081ea88d672c1b4aa8be0759a78e93e629b","modified":1678259158868},{"_id":"themes/3-hexo/source/js/iconfont.js","hash":"3a0869ca1b09af07d82987e343a3bc4cb9558ecb","modified":1678259158870},{"_id":"themes/3-hexo/source/js/jquery.autocomplete.min.js","hash":"7b8ac4d06c9e763963832529f44a56ad42a81e5f","modified":1678259158870},{"_id":"themes/3-hexo/source/js/jquery.pjax.js","hash":"191c49fdb40dff115a49cfd2b30dffb888d86550","modified":1678259158870},{"_id":"themes/3-hexo/source/js/search.js","hash":"c80c9a231ee040c7adc07a477793873fb85ce8bc","modified":1678259158870},{"_id":"themes/3-hexo/source/js/script.js","hash":"7502191e29366a11323dc72ae365b1aed254e6f2","modified":1678259158870},{"_id":"source/_posts/2016-05-20-kongzheng1993-servlet/servlet接口.jpg","hash":"55c1d6b94b27a27827b37e62804e965e0fe8237a","modified":1678259158770},{"_id":"source/_posts/2016-06-16-kongzheng1993-synchronized/fanyi.png","hash":"ae4ffc14a6d221d98b0c6459b7d9cc86e66ef1b4","modified":1678259158772},{"_id":"source/_posts/2020-04-08-kongzheng1993-chromebook再次折腾crouton/linuxRelease.jpg","hash":"38c2090ec8816fcfc91f64710961e2b3e856ce51","modified":1678259158793},{"_id":"source/_posts/2020-04-08-kongzheng1993-chromebook再次折腾crouton/finishInstall.jpg","hash":"55ae851a46d9f742f21ab9bc2e27254841c11c1e","modified":1678259158792},{"_id":"source/_posts/2020-04-08-kongzheng1993-chromebook再次折腾crouton/xfce4.jpg","hash":"22eef68634de6967b8e0a43a53c698f83f0804c4","modified":1678259158794},{"_id":"source/_posts/2020-04-17-kongzheng1993-Java_Monitor/1.png","hash":"7881446860378e046659d3b5e2ebe07c39deb2e5","modified":1678259158795},{"_id":"source/_posts/2020-04-14-kongzheng1993-JavaObjectHeader/Java_Monitor.png","hash":"203178617c885aabef70c76780ea51b9794a8530","modified":1678259158795},{"_id":"source/_posts/2020-04-19-kongzheng1993-Java就是值传递的/1.jpg","hash":"d07d4d9091273bdc89e5b41debd7c2b916acb016","modified":1678259158796},{"_id":"source/_posts/2020-04-20-kongzheng1993-JVM/20170513134212845.png","hash":"130e45f5c7b0d38071a40f5d061021d2598b0cc7","modified":1678259158796},{"_id":"source/_posts/2020-04-19-kongzheng1993-Java就是值传递的/2.png","hash":"44f945f1b8dda0f98fb2aa85a29e92d20c52dfca","modified":1678259158796},{"_id":"source/_posts/2020-04-24-kongzheng1993-SPI/v2-a4598f8b9ab46951b190cc9ce059eee0_720w.jpg","hash":"381ff33a509bdfd504c3e6c0f38a21a9c799349a","modified":1678259158797},{"_id":"source/_posts/2020-04-29-kongzheng1993-各种索引/1216484-20190825001255129-2032384167.png","hash":"891212385045d7060460369ed0ae0fe986895706","modified":1678259158799},{"_id":"source/_posts/2020-04-29-kongzheng1993-各种索引/v2-2c2264cc1c6c603dfeca4f84a2575901_r.jpg","hash":"e04daddd6330c63d74580033232c9d6bb595d309","modified":1678259158800},{"_id":"source/_posts/2020-05-15-kongzheng1993-ThreadPool总结/2020-05-18 12-50-13屏幕截图.png","hash":"4d68ac02e807a1a55f053ca56cef3110d1138b47","modified":1678259158802},{"_id":"source/_posts/2021-03-27-kongzheng1993-JavaRemoteDebug/idea_remote_debug.png","hash":"db8ad65cd8a1f37a93803b427b1a25557868b113","modified":1678259158809},{"_id":"source/_posts/2021-04-29-kongzheng1993-getResource/IDE.png","hash":"ea581c0338ff20a9586eee1e41e1c27b8bce5bda","modified":1678259158809},{"_id":"source/_posts/2021-11-29-kongzheng1993-maven_resource_plugin/20161012101735543.png","hash":"e77479b68e17dfbc820c3981e70a85ebb588ef7b","modified":1678259158819},{"_id":"source/_posts/2022-03-10-kongzheng1993-DDD/.DS_Store","hash":"d1535594eacdf1760b742d868e6deaced13735bd","modified":1678259158825},{"_id":"source/_posts/2022-11-19-kongzheng1993-feign继承特性/1.png","hash":"5a596bd420ff5ff092821911508cc93c9d3f7e98","modified":1678259158834},{"_id":"source/_posts/2022-11-19-kongzheng1993-feign继承特性/2.png","hash":"1bcc7a74f68050d4981a8c2a43c00b60a8e45385","modified":1678259158834},{"_id":"source/_posts/2023-03-23-kongzheng1993-服务日志实现方式切换引起的问题/.DS_Store","hash":"df2fbeb1400acda0909a32c1cf6bf492f1121e07","modified":1679540312330},{"_id":"source/_posts/2016-05-20-kongzheng1993-servlet/servlet实例化过程.jpg","hash":"b67fbe1816562e6ed9109f98e778e94835647f79","modified":1678259158770},{"_id":"source/_posts/2018-06-08-kongzheng1993-java多线程总结/20150309140927553.jpeg","hash":"391773d5b0c871dc2623b8403e9166aafa170237","modified":1678259158774},{"_id":"source/_posts/2020-03-08-kongzheng1993-带你撸一台免费云服务器/12.png","hash":"55ab184caff7c9a3a6f5bad70c8498a2437332e7","modified":1678259158779},{"_id":"source/_posts/2020-03-08-kongzheng1993-带你撸一台免费云服务器/11.png","hash":"a50613ebd7db5cf0121bce5eaa6c57b96d56ad28","modified":1678259158778},{"_id":"source/_posts/2020-03-08-kongzheng1993-带你撸一台免费云服务器/2.png","hash":"89d51fb65c56326bb3fe62dbf7a4e769fa276850","modified":1678259158780},{"_id":"source/_posts/2020-03-08-kongzheng1993-带你撸一台免费云服务器/6.png","hash":"bf40ef518007c6fa5cd72fb71fa2f942dcf1b768","modified":1678259158781},{"_id":"source/_posts/2020-03-08-kongzheng1993-带你撸一台免费云服务器/5.png","hash":"ca3342a074768d0ce53b861d30920f7202720648","modified":1678259158781},{"_id":"source/_posts/2020-04-08-kongzheng1993-chromebook再次折腾crouton/kaliLinux.png","hash":"e42a78cd3e4baabac8f105e4df40a47d5799ddae","modified":1678259158793},{"_id":"source/_posts/2020-04-08-kongzheng1993-chromebook再次折腾crouton/taobao.jpg","hash":"cec87bb7d3588a1e94e2c9d7244abd90d82bd98d","modified":1678259158794},{"_id":"source/_posts/2020-04-17-kongzheng1993-Java_Monitor/2.png","hash":"6dc9b19e3fbb8d6e1d2b48a07f0451abc2b31d18","modified":1678259158795},{"_id":"source/_posts/2020-04-25-kongzheng1993-死锁/v2-fccd6ccc07c0caf2643f324cdb7856e7_b.jpg","hash":"09eb8b22ff8a570e107fb2274a19379319f4e136","modified":1678259158798},{"_id":"source/_posts/2020-04-29-kongzheng1993-各种索引/820365-20160721211316388-637070407.png","hash":"a6d4e6ceb02def25f69ad4bf49e1bdabca8e69bb","modified":1678259158799},{"_id":"source/_posts/2020-05-15-kongzheng1993-Nginx/v2-e1826bab1d07df8e97d61aa809b94a10_r.jpg","hash":"c32c3361e7b2590907d96f6ae583d7d770e6f0f3","modified":1678259158801},{"_id":"source/_posts/2020-05-21-kongzheng1993-分布式事务/seata.png","hash":"7d6474d370b2a5fa2d5d88dfe1875c8cae2f414e","modified":1678259158803},{"_id":"source/_posts/2020-07-26-kongzheng1993-apollo/apollo-flow.png","hash":"4f8a4e881840463c1384e33fc4e954b9d60e37c5","modified":1678259158806},{"_id":"source/_posts/2020-07-26-kongzheng1993-apollo/overall-architecture.png","hash":"7912b3d4b2e9bac5bc2caa14824ab4af6e56cc49","modified":1678259158807},{"_id":"source/_posts/2021-07-04-kongzheng1993-JVM调优/stack.png","hash":"2ca00441becc0f8cb0248a7ceab192d554d4e13b","modified":1678259158813},{"_id":"source/_posts/2021-11-29-kongzheng1993-hs_err_pid_pid_log/飞书20211129-112155.png","hash":"161d06aee8592411d5075557d014e646c6ad9df5","modified":1678259158817},{"_id":"source/_posts/2022-03-09-kongzheng1993-包装类==的问题/Integer.png","hash":"dbd07e0c2eb082f4f4d92c18c3946aa8854cc880","modified":1678259158824},{"_id":"source/_posts/2023-01-30-kongzheng1993-Netty/Reactor.png","hash":"a7d542a86fd802c82d6309023ffd558c32687512","modified":1680243330790},{"_id":"source/_posts/2023-01-30-kongzheng1993-Netty/handler.png","hash":"6926c30ced41710393fb602f337f38b430cc8224","modified":1680243534382},{"_id":"source/_posts/2023-01-30-kongzheng1993-Netty/EventLoop.png","hash":"9adcdb470a4ef26f012232684a32d8abd6a10306","modified":1680243498942},{"_id":"source/_posts/2023-01-30-kongzheng1993-Netty/channel.png","hash":"5b517c34b4ed9d918d28d8a62c0ef948e7fe71dc","modified":1680243424339},{"_id":"themes/3-hexo/.git_bak/objects/pack/pack-5b8098fbc245138a69707baa4030f120275380e3.idx","hash":"c9ca085131109ee66118a1b3ecf43eeb7e39ce87","modified":1678259158847},{"_id":"themes/3-hexo/.git_bak/refs/heads/master","hash":"6cdfd86ed8d3fc1146b90331ae2b9cf1c35518a9","modified":1678259158852},{"_id":"themes/3-hexo/layout/_partial/comments/click2show.ejs","hash":"fa6675230f8c313236604e26926b142f4f418bdd","modified":1678259158854},{"_id":"themes/3-hexo/layout/_partial/comments/gentie.ejs","hash":"1d6eacdadeb247e3b349ca7168f797beae8ff4c5","modified":1678259158854},{"_id":"themes/3-hexo/layout/_partial/comments/gitalk.ejs","hash":"fbd3c7d72c8354d700918390c6cbfc0a11408277","modified":1678259158854},{"_id":"themes/3-hexo/layout/_partial/comments/disqus.ejs","hash":"cd0022ce7e6d6efb07a00e87477cdf791f7f6703","modified":1678259158854},{"_id":"themes/3-hexo/layout/_partial/comments/gitment.ejs","hash":"f16442568b43d034faaa8e3507f5ae8da34c7b72","modified":1678259158854},{"_id":"themes/3-hexo/source/css/_partial/autocomplete.styl","hash":"f6847a2c6d35dbd6d06dc591bd34ed2019784048","modified":1678259158855},{"_id":"themes/3-hexo/source/css/_partial/comment.styl","hash":"cc0a862b31359a85d12579e49d2eca58d128275c","modified":1678259158855},{"_id":"themes/3-hexo/source/css/_partial/dashang.styl","hash":"f6447a2ac407228e1d53e3455db2919ac0e9f094","modified":1678259158855},{"_id":"themes/3-hexo/source/css/_partial/fade.styl","hash":"4f687cbc74caf8a0887f5e89250284a9bce8b5c1","modified":1678259158855},{"_id":"themes/3-hexo/source/css/_partial/font.styl","hash":"4d5ac149709447c5eee45f0e23dadeea94fd98ce","modified":1678259158855},{"_id":"themes/3-hexo/source/css/_partial/full-toc.styl","hash":"0ba318911afbbbffbd2473b472aedf2d3900e978","modified":1678259158856},{"_id":"themes/3-hexo/source/css/_partial/nav-left.styl","hash":"1bd865029ba8c11750fff83d87f69e5d7c137928","modified":1678259158856},{"_id":"themes/3-hexo/source/css/_partial/nav-right.styl","hash":"3da8fa04efccfd054a6a65f7153f197d4d68281d","modified":1678259158856},{"_id":"themes/3-hexo/source/css/_partial/nprogress.styl","hash":"65efbddd23a264e7d1e85f4073228526770e833c","modified":1678259158856},{"_id":"themes/3-hexo/source/css/_partial/num-load.styl","hash":"4b996440bba8ec755aa70bc6d074d7dbba55ec0c","modified":1678259158856},{"_id":"themes/3-hexo/source/css/_partial/post.styl","hash":"c791204c5f10fd876025abf08f4dcb3ca5dde3b6","modified":1678259158856},{"_id":"themes/3-hexo/source/css/fonts/icomoon.eot","hash":"b6195bedc1cb2f9cfcb26cc27021f2e94be2ab0a","modified":1678259158856},{"_id":"themes/3-hexo/source/css/fonts/icomoon.ttf","hash":"eb976d8b8559fcddfc2658a03a4350cb566fc06b","modified":1678259158856},{"_id":"themes/3-hexo/source/css/fonts/icomoon.svg","hash":"37ac1ef28b03f46bf3ad2606c86f0e1ec3e4405f","modified":1678259158856},{"_id":"themes/3-hexo/source/css/fonts/icomoon.woff","hash":"3985d29416bb9b19f50a2f20f2bbbce47f10af8d","modified":1678259158857},{"_id":"themes/3-hexo/source/css/fonts/iconfont.eot","hash":"3dfe8e557d9dfaf39bca088a02b76deb82dbaa3d","modified":1678259158857},{"_id":"themes/3-hexo/source/css/fonts/iconfont.svg","hash":"c61a31e5310430312677fffe4286097d29d10151","modified":1678259158857},{"_id":"themes/3-hexo/source/css/fonts/iconfont.ttf","hash":"aa087561480fb9c2cfd541e33d1e99d5ac1a56bb","modified":1678259158857},{"_id":"themes/3-hexo/source/css/fonts/iconfont.woff","hash":"f8ed131ccf13f4bdd3ec11fc3e997339dd7b66ba","modified":1678259158857},{"_id":"themes/3-hexo/source/css/fonts/selection.json","hash":"57c7f100019d57b512aab509185cb0a6eb9aa4c8","modified":1678259158857},{"_id":"themes/3-hexo/source/css/hl_theme/atom-dark.styl","hash":"f3eb4e5feda9cbd6242ccf44ca064e2979b5d719","modified":1678259158858},{"_id":"themes/3-hexo/source/css/hl_theme/atom-light.styl","hash":"69d184a682bcaeba2b180b437dc4431bc3be38aa","modified":1678259158858},{"_id":"themes/3-hexo/source/css/hl_theme/brown-paper.styl","hash":"03af387edcc1cf8c18d12e9c440fd51b6cf425b6","modified":1678259158858},{"_id":"themes/3-hexo/source/css/hl_theme/darcula.styl","hash":"2bfc14f27ccca108b4b3755782de8366e8bd001e","modified":1678259158858},{"_id":"themes/3-hexo/source/css/hl_theme/github-gist.styl","hash":"5e05b19832c1099bd9d284bc3ed00dc8a3d7ee23","modified":1678259158858},{"_id":"themes/3-hexo/source/css/hl_theme/github.styl","hash":"53276ff1f224f691dfe811e82c0af7f4476abf5d","modified":1678259158858},{"_id":"themes/3-hexo/source/css/hl_theme/gruvbox-dark.styl","hash":"315ad610d303caba9eac80a7d51002193a15478a","modified":1678259158858},{"_id":"themes/3-hexo/source/css/hl_theme/gruvbox-light.styl","hash":"1bece084b1dbbbd4af064f05feffd8c332b96a48","modified":1678259158858},{"_id":"themes/3-hexo/source/css/hl_theme/kimbie-dark.styl","hash":"e9c190f9ffc37a13cac430512e4e0c760205be4a","modified":1678259158858},{"_id":"themes/3-hexo/source/css/hl_theme/kimbie-light.styl","hash":"0c3ccd0d64e7504c7061d246dc32737f502f64e4","modified":1678259158858},{"_id":"themes/3-hexo/source/css/hl_theme/railscasts.styl","hash":"a6e8cfd2202afd7893f5268f3437421e35066e7b","modified":1678259158859},{"_id":"themes/3-hexo/source/css/hl_theme/rainbow.styl","hash":"e5c37646a9d9c1094f9aab7a7c65a4b242e8db00","modified":1678259158859},{"_id":"themes/3-hexo/source/css/hl_theme/school-book.styl","hash":"51659351b391a2be5c68728bb51b7ad467c5e0db","modified":1678259158859},{"_id":"themes/3-hexo/source/css/hl_theme/sublime.styl","hash":"501d75ef0f4385bea24d9b9b4cc434ba68d4be27","modified":1678259158859},{"_id":"themes/3-hexo/source/css/hl_theme/sunburst.styl","hash":"2aa9817e68fb2ed216781ea04b733039ebe18214","modified":1678259158859},{"_id":"themes/3-hexo/source/css/hl_theme/zenbum.styl","hash":"933a3b196d01254dea5e6f48105ea15e210ae000","modified":1678259158859},{"_id":"source/_posts/2019-05-30-kongzheng1993-生产部署illegal-character/WechatIMG1.jpeg","hash":"80ecb632806183e9ebee073854908d37ed4c98ad","modified":1678259158775},{"_id":"source/_posts/2020-03-08-kongzheng1993-带你撸一台免费云服务器/1.png","hash":"31a24cb85cbe55c29e48af9fc1ae9218a09a4455","modified":1678259158777},{"_id":"source/_posts/2020-03-08-kongzheng1993-带你撸一台免费云服务器/10.png","hash":"7073ef7ae5fa2e63bf5acb2dbe5c5430e218a94f","modified":1678259158778},{"_id":"source/_posts/2020-03-08-kongzheng1993-带你撸一台免费云服务器/3.png","hash":"2a37e0a0f459ebbcc369c924b899966aa2c081fc","modified":1678259158780},{"_id":"source/_posts/2020-03-08-kongzheng1993-带你撸一台免费云服务器/7.png","hash":"12d31602b966012736d2eee897e131db3c87ee67","modified":1678259158782},{"_id":"source/_posts/2020-03-08-kongzheng1993-带你撸一台免费云服务器/9.png","hash":"0312c5e7da78bdde1fb678d7d58cc071ff55a168","modified":1678259158783},{"_id":"source/_posts/2020-03-30-kongzheng1993-用nodejs做一个测试api服务/test.bmp","hash":"342db818da38cc5e5de107295a625ca329c1f59c","modified":1678259158785},{"_id":"source/_posts/2020-04-04-kongzheng1993-TCP三次握手&四次挥手/11585992522_.pic.jpg","hash":"a94a79099003686436a82d536c34cffb263ea410","modified":1678259158786},{"_id":"source/_posts/2020-04-04-kongzheng1993-TCP三次握手&四次挥手/41585998713_.pic_hd.jpg","hash":"82c87473f3e7fd25f46b1aebe5fa2700350ce466","modified":1678259158789},{"_id":"source/_posts/2020-04-21-kongzheng1993-synchronized锁升级/v2-8f405804cd55a26b34d59fefc002dc08_r.jpg","hash":"c593759b7e10b8e845404e3195534c88715fc2e6","modified":1678259158797},{"_id":"source/_posts/2020-04-28-kongzheng1993-devtools/截屏2020-04-28下午6.51.22.png","hash":"1ffa309e4258ee29e097b5c444dd7475c98bf590","modified":1678259158799},{"_id":"source/_posts/2020-04-29-kongzheng1993-各种索引/v2-5f069fd820637db1b877fdd6799a2b67_r.jpg","hash":"9b864b9346d3c6279ae33012cbd1aef064c37825","modified":1678259158800},{"_id":"source/_posts/2020-10-21-kongzheng1993-原生js实现双击复制后的思考/WechatIMG26.jpeg","hash":"efa0e6553deab43b3bb2b3d0b541b4193725e8bb","modified":1678259158808},{"_id":"source/_posts/2021-07-01-kongzheng1993-springMVC消息转换器/2.jpg","hash":"c2fee12722f5b1776b3cd3b962c3c38caff2fac2","modified":1678259158811},{"_id":"source/_posts/2021-07-15-kongzheng1993-MongoDB/image-20210715174420382.png","hash":"8f2f48f954c3bd6e3d898379f71e8f991e7c08a9","modified":1678259158814},{"_id":"source/_posts/2022-04-15-kongzheng1993-FastThrow/noParam.png","hash":"29e0a505bcca6cae78db31b95deb0cd1bcecd7fd","modified":1678259158830},{"_id":"source/_posts/2022-04-15-kongzheng1993-FastThrow/param.png","hash":"940b0c9c3a9af22b6d338413acca8929760e0e99","modified":1678259158832},{"_id":"source/_posts/2023-01-30-kongzheng1993-Netty/asyncIO.png","hash":"8a295f37c6ade6a47de56d7c96637de63ad8fc6b","modified":1680242999176},{"_id":"source/_posts/2023-01-30-kongzheng1993-Netty/multiplexing.png","hash":"059d485b9b523d14e28fdfa15887a1297049d18a","modified":1680241767072},{"_id":"source/_posts/2023-01-30-kongzheng1993-Netty/netty_reactor.png","hash":"7975e3b62f2abfdf2483c2ed190f189773e7be8c","modified":1680243459338},{"_id":"themes/3-hexo/source/img/avatar.png","hash":"f3f94ac1fa440c0b90ea2c7ab8332b7fb61b56c3","modified":1678259158860},{"_id":"themes/3-hexo/source/js/gitalk.js","hash":"00419a6156f5d4f9b8aba00d446cd64ba73e0d12","modified":1678259158869},{"_id":"themes/3-hexo/source/js/gitment.js","hash":"59a1e03f2b0ce61dd9bd405d3c52d3e07cc10dec","modified":1678259158869},{"_id":"source/_posts/2016-06-16-kongzheng1993-synchronized/1.png","hash":"32ef9add0dea53e2c543fc79ca7ca79a93441334","modified":1678259158772},{"_id":"source/_posts/2020-03-08-kongzheng1993-带你撸一台免费云服务器/13.png","hash":"740ad4f0dc293566110778bad6f7a92e2ce5f8fe","modified":1678259158779},{"_id":"source/_posts/2020-03-08-kongzheng1993-带你撸一台免费云服务器/8.png","hash":"d5c219fd68e07a4a2d2bdf42f97aedd2b89ca5ac","modified":1678259158782},{"_id":"source/_posts/2020-04-04-kongzheng1993-TCP三次握手&四次挥手/11111.png","hash":"5ca10aadaef4e65d8f1fa19ad6bd3c071460cad0","modified":1678259158786},{"_id":"source/_posts/2020-04-08-kongzheng1993-chromebook再次折腾crouton/recovery.bmp","hash":"da765789d3a0a45d7d53cb93d88bc81b1d2d93dc","modified":1678259158793},{"_id":"source/_posts/2021-07-01-kongzheng1993-springMVC消息转换器/3.jpg","hash":"ce41c810da9c690fc80f95ba0f3ebca9cc948d63","modified":1678259158812},{"_id":"source/_posts/2023-01-30-kongzheng1993-Netty/blockingIO.png","hash":"08497be207bad6e98776ab42ac49031b921800af","modified":1680241653515},{"_id":"themes/3-hexo/.git_bak/logs/refs/heads/master","hash":"dcfc493e902b78444b98c0e8bd1b7433ec574764","modified":1678259158846},{"_id":"themes/3-hexo/.git_bak/refs/remotes/origin/HEAD","hash":"d9427cda09aba1cdde5c69c2b13c905bddb0bc51","modified":1678259158852},{"_id":"source/_posts/2020-04-04-kongzheng1993-TCP三次握手&四次挥手/51585999731_.pic_hd.jpg","hash":"b8575906ee1f238c450037b27dbbbde960dae593","modified":1678259158790},{"_id":"source/_posts/2021-07-01-kongzheng1993-springMVC消息转换器/1.jpg","hash":"8bc1834622c7c15d99c50b69b64cf9949e5d2350","modified":1678259158810},{"_id":"source/_posts/2020-03-30-kongzheng1993-用nodejs做一个测试api服务/run.bmp","hash":"0a01b2afca0b35d0125fc7e04c30eac9b7da23d7","modified":1678259158785},{"_id":"source/_posts/2022-03-05-kongzheng1993-JVM知识点总结/Class.png","hash":"ce82dfa79bb0a7cd0e2363f517b3ced0d2931ba9","modified":1678259158823},{"_id":"source/_posts/2022-03-10-kongzheng1993-DDD/entity_model的副本.png","hash":"68d6fa59d04e953c523a8d61f20cd3cdea3ca50c","modified":1678259158829},{"_id":"source/_posts/2023-01-30-kongzheng1993-Netty/nonBlockingIO.png","hash":"fd0f23612b15290eb1590f746d774414ed328a36","modified":1680241692898},{"_id":"themes/3-hexo/.git_bak/logs/refs/remotes/origin/HEAD","hash":"dcfc493e902b78444b98c0e8bd1b7433ec574764","modified":1678259158846},{"_id":"source/_posts/2020-04-04-kongzheng1993-TCP三次握手&四次挥手/31585998651_.pic_hd.jpg","hash":"aebb809e9446d43118e92baca7533264df068b64","modified":1678259158788},{"_id":"source/_posts/2020-04-04-kongzheng1993-TCP三次握手&四次挥手/21585993169_.pic_hd.jpg","hash":"15964296af5bc0fa6973f59c2d0ccd2fb18543dc","modified":1678259158788},{"_id":"source/_posts/2021-07-04-kongzheng1993-JVM调优/JVM.png","hash":"fa1875a4a9072f0cf99190a44a5455287ba27a86","modified":1678259158813},{"_id":"source/_posts/2020-07-05-kongzheng1993-Java-rmi/rmi.png","hash":"efb67c848ec92c8ddf651c3854f1182d9e9b087e","modified":1678259158805},{"_id":"source/_posts/2022-03-10-kongzheng1993-DDD/entity_model.png","hash":"68d6fa59d04e953c523a8d61f20cd3cdea3ca50c","modified":1678259158827},{"_id":"source/_posts/2020-03-30-kongzheng1993-用nodejs做一个测试api服务/cnpm.bmp","hash":"07aab8787fb73fedad9956b1aa5cfb9ec77af0cb","modified":1678259158784},{"_id":"source/_posts/2023-03-23-kongzheng1993-服务日志实现方式切换引起的问题/old.png","hash":"a695f344ad773a3749b074618a970fcf112ae06c","modified":1679540242622},{"_id":"source/_posts/2020-04-06-kongzheng1993-博客改造/11111.png","hash":"1c18bd80f676e31e8a536ab8ab7e64900462d445","modified":1678259158792},{"_id":"source/_posts/2021-11-29-kongzheng1993-hs_err_pid_pid_log/飞书20211129-112140.png","hash":"beb8b4353e878baef14a054a556b381ffc917c86","modified":1678259158817},{"_id":"source/_posts/2020-06-29-kongzheng1993-NLP/statistical-machine-translation.png","hash":"b9e9e87e8271540c97526b961554583d79cfb3de","modified":1678259158805},{"_id":"source/_posts/2020-03-30-kongzheng1993-用nodejs做一个测试api服务/express.bmp","hash":"3e8b011854c29de777706ec2a9570265aa1538a7","modified":1678259158785},{"_id":"source/_posts/2023-03-23-kongzheng1993-服务日志实现方式切换引起的问题/new.png","hash":"c6a831591f6009fede80358deda478d42bebf85f","modified":1679540219336},{"_id":"source/_posts/JAVA.xmind","hash":"4c8118625c428d71247fc66222c4fc768c0e60a0","modified":1680509462053},{"_id":"source/_posts/2023-01-30-kongzheng1993-Netty/man2kqueue.png","hash":"9004e97ab8c6c6e6825aaf9e52ca576cb50088a6","modified":1680242862079},{"_id":"source/_posts/2023-01-30-kongzheng1993-Netty/man2select.png","hash":"32167bdc209a75747726514226acc129410676ad","modified":1680242852258},{"_id":"themes/3-hexo/.git_bak/objects/pack/pack-5b8098fbc245138a69707baa4030f120275380e3.pack","hash":"2b4efc53bf09ce178c6f4987e8676d690c1a2888","modified":1678259158852},{"_id":"themes/3-hexo/source/img/gongzhonghao.png","hash":"7fad9908a7ade993f434150a9873518df5d91b4c","modified":1678259158867},{"_id":"public/sitemap.xml","hash":"259d8b4066d0fab871ec6099fac48fb488bc6fa6","modified":1680509668553},{"_id":"public/2023/03/23/kongzheng1993-服务日志实现方式切换引起的问题/index.html","hash":"2bc2c9f0f8b0f40de9be0413a6d77c0f2498c8fe","modified":1716089075523},{"_id":"public/2023/03/08/kongzheng1993-MongoDB/index.html","hash":"c915c4aae3ad501a56025c2680811676f050d80d","modified":1716089075523},{"_id":"public/2023/01/30/kongzheng1993-eureka_ribbon/index.html","hash":"572eb74f45bc0083da64ec0d2652141dc33f5f8d","modified":1716089075523},{"_id":"public/2023/01/30/kongzheng1993-Netty/index.html","hash":"7ad792133c5ad8a55dbdc44d873c8890f3fb62bb","modified":1716089075523},{"_id":"public/2022/11/19/kongzheng1993-feign继承特性/index.html","hash":"682a1b609a3d2fd2e503effddb445144f501ab3c","modified":1716089075523},{"_id":"public/2022/09/27/kongzheng1993-双检锁/index.html","hash":"f41d9abe5f666181ba087e0da3eacf9276ae4a99","modified":1716089075523},{"_id":"public/2023/02/20/kongzheng1993-kafka/index.html","hash":"5107553cb85934d0613380da1f81951c2fa3436f","modified":1716089075523},{"_id":"public/2023/02/20/kongzheng1993-think-in-springmvc-and-acutator/index.html","hash":"c260da1d57631f236a86b982a560ee86e871c02f","modified":1716089075523},{"_id":"public/2022/07/12/kongzheng1993-package-info/index.html","hash":"90ed9b5731a33f7664ff052220a18081689ffc7d","modified":1716089075524},{"_id":"public/2022/09/27/kongzheng1993-为什么需要JMM/index.html","hash":"225590039317122b36dac15e6845ae5f4eab7540","modified":1716089075523},{"_id":"public/2022/07/14/kongzheng1993-NoSuchMethodError/index.html","hash":"7f21f2c6e247d09c1d5b8ddf7b36ca40e426908c","modified":1716089075523},{"_id":"public/2022/07/13/kongzheng1993-resume/index.html","hash":"cfe10d7ae0074a05e4b9e519259a32a349a64f64","modified":1716089075523},{"_id":"public/2022/06/12/kongzheng1993-volatile/index.html","hash":"8074bcb3061e40adeaa1cd393e6af3fb8ce7bfb2","modified":1716089075524},{"_id":"public/2022/04/15/kongzheng1993-FastThrow/index.html","hash":"1a735815988c1ce842e0818a903e605646afbba6","modified":1716089075524},{"_id":"public/2022/07/02/kongzheng1993-MySQL中的锁/index.html","hash":"9affe2936b0059eee5a4f70520133fb6df18e822","modified":1716089075524},{"_id":"public/2022/05/06/kongzheng1993-spring_provides/index.html","hash":"9968fc2d9743400e2c9f57d4ba7db5585f7fe6ae","modified":1716089075524},{"_id":"public/2022/03/09/kongzheng1993-包装类==的问题/index.html","hash":"9611fa66e388526c3e14ce1db86c111e09789d59","modified":1716089075524},{"_id":"public/2022/06/22/kongzheng1993-主键自增/index.html","hash":"980e163f9a0c7af57879b30cb2fae078ec7f3675","modified":1716089075524},{"_id":"public/2022/03/05/kongzheng1993-JVM知识点总结/index.html","hash":"05f35a80661ab65b05826607eb6f530a80e645f2","modified":1716089075524},{"_id":"public/2022/03/10/kongzheng1993-DDD/index.html","hash":"a04ab3844d882e505a75fb3c735ef472e11fc443","modified":1716089075524},{"_id":"public/2022/01/14/kongzheng1993-jsoup遇到的问题/index.html","hash":"07f5c0931a36b10833567fd2fa4a1af5fd41dc0d","modified":1716089075524},{"_id":"public/2022/01/09/kongzheng1993-MySQL性能优化/index.html","hash":"fd9c81868b7ba3f7134e8d0edaf7aaaaead9a875","modified":1716089075524},{"_id":"public/2021/11/29/kongzheng1993-hs_err_pid_pid_log/index.html","hash":"4d4246fe6890932042e89113b1e91d176c10439c","modified":1716089075524},{"_id":"public/2022/01/09/kongzheng1993-MySQL_MVCC/index.html","hash":"0ad45752dbd4082376c0f256a82d57b8e8604aa9","modified":1716089075524},{"_id":"public/2022/03/02/kongzheng1993-DevTools/index.html","hash":"964e66b1f7ac9d22af4f06ece8f6ab1309ed8d8c","modified":1716089075524},{"_id":"public/2021/11/26/kongzheng1993-maven_resource_plugin/index.html","hash":"f60b55efe7d0b692a1568546ec20535d3bd86d9f","modified":1716089075524},{"_id":"public/2021/11/26/kongzheng1993-mysql_bitMap/index.html","hash":"180a55c3d0b3c79f29674ed89ab06fb855d6b43c","modified":1716089075524},{"_id":"public/2021/11/26/kongzheng1993-BigDecimal/index.html","hash":"0f071617f181d436559aec68950e49fcdbe57ef6","modified":1716089075524},{"_id":"public/2021/11/26/kongzheng1993-spring_session/index.html","hash":"62c9423acdcb6240d8e65a9d25210a5b77588bd0","modified":1716089075524},{"_id":"public/2021/11/26/kongzheng1993-记一次频繁FullGC解决/index.html","hash":"7d752693b45c487d389dd81cdbb1951f9b521010","modified":1716089075524},{"_id":"public/2021/11/03/kongzheng1993-Java异常和错误/index.html","hash":"6469c92b783034320f5a0b244290869d0b725cfe","modified":1716089075524},{"_id":"public/2021/10/09/kongzheng1993-Feign_Request_Header_is_too_large/index.html","hash":"7d8c640005282dd314a9590e240f56841c183a6e","modified":1716089075524},{"_id":"public/2021/10/09/kongzheng1993-Spring启动过程代码跟踪/index.html","hash":"344cc2fbb526f99a5a7f47cc05c14732c7229e9f","modified":1716089075524},{"_id":"public/2021/10/08/kongzheng1993-Spring是如何解决循环依赖的（三级缓存）/index.html","hash":"4db867ef200a50a7b7ef2ac15ff0c95960ba9504","modified":1716089075524},{"_id":"public/2021/07/15/kongzheng1993-feign上传文件/index.html","hash":"1cf4cedae1d181e0c51977c2f985557957eafa91","modified":1716089075524},{"_id":"public/2021/07/27/kongzheng1993-mysql联表查询字符集不一致不走索引/index.html","hash":"c393d0c304f03d652d1c6730be92bf1029b7d54a","modified":1716089075524},{"_id":"public/2022/03/13/kongzheng1993-review_point/index.html","hash":"aeea81fd844fee82bacad9c6f39792c3c7f73eb7","modified":1716089075524},{"_id":"public/2021/07/13/kongzheng1993-泛型/index.html","hash":"51bc87f9cce3fb74afbfc4c54a9be1d144dbc6e6","modified":1716089075524},{"_id":"public/2021/07/04/kongzheng1993-JVM调优/index.html","hash":"5d5bb57ac0eb3a86053f2a624a2b26aad6adcefd","modified":1716089075524},{"_id":"public/2021/07/01/kongzheng1993-springMVC消息转换器/index.html","hash":"818282336a385f0c9be8709f6849a1f1ab6ce631","modified":1716089075524},{"_id":"public/2021/06/06/kongzheng1993-最近的一些感悟/index.html","hash":"ebe4eff08c20bedfb358bfafe81ca089af0c10ff","modified":1716089075524},{"_id":"public/2021/04/29/kongzheng1993-getResource/index.html","hash":"f6fa69d871bb762ee49b501699ca6700bd87175c","modified":1716089075524},{"_id":"public/2021/03/26/kongzheng1993-Win10下的wls中git状态不对的问题/index.html","hash":"29cf514c614f205696a1b1f3c5d2135f7f10ee8e","modified":1716089075524},{"_id":"public/2021/03/29/kongzheng1993-JavaRetry/index.html","hash":"2b586ddcf7450ba6e971c55de5ae8cf29c5876e1","modified":1716089075524},{"_id":"public/2021/02/05/kongzheng1993-Vue学习笔记/index.html","hash":"ce663e4d0feba26e81c1e36ea6263041154880a1","modified":1716089075524},{"_id":"public/2021/02/02/kongzheng1993-Vue父子组件之间传递参数/index.html","hash":"853a4fb71805f384edc117b41887a771e07a62a0","modified":1716089075524},{"_id":"public/2021/01/22/kongzheng1993-MySQL技术内幕读书笔记/index.html","hash":"7a88eaf9aafb4ebf4e25ab761bd25efc187c00dd","modified":1716089075524},{"_id":"public/2021/01/21/kongzheng1993-Java8Lambda/index.html","hash":"9921261d13d181cf1a47063946d85e273eb6f0e4","modified":1716089075524},{"_id":"public/2021/07/25/kongzheng1993-关于编译/index.html","hash":"0b4149dcd45a674a1ba8ae8a995779ac9f588608","modified":1716089075524},{"_id":"public/2021/03/27/kongzheng1993-JavaRemoteDebug/index.html","hash":"071fffabecd1605bd563eb160b2423885184a2a8","modified":1716089075524},{"_id":"public/2020/12/29/kongzheng1993-PageHelper/index.html","hash":"9505a556285a89f21ac9be3f9cfcdcd69bd25684","modified":1716089075525},{"_id":"public/2020/12/29/kongzheng1993-javax.script/index.html","hash":"21e141db79c3b82b981b4031e1e210b167456d3d","modified":1716089075525},{"_id":"public/2020/12/18/kongzheng1993-iframe重复加载的问题/index.html","hash":"91de0f427250721eb88c3930b41345f75e8eca15","modified":1716089075525},{"_id":"public/2020/12/18/kongzheng1993-避免浏览器缓存的技巧/index.html","hash":"223bb324323c9b5277931d65ae93c4ed86984ffc","modified":1716089075525},{"_id":"public/2021/01/07/kongzheng1993-包装类型存在的意义/index.html","hash":"c6abe85d911d3dbf38c07112e79942d1c9fcb673","modified":1716089075524},{"_id":"public/2020/11/11/kongzheng1993-StopWatch/index.html","hash":"63c7fb7de258deb7e245b4aaae67e79943693479","modified":1716089075525},{"_id":"public/2020/11/11/kongzheng1993-乐观锁实现方式/index.html","hash":"4e0bf01b8ed4a9c768e66fe12c4071e11f8895ec","modified":1716089075525},{"_id":"public/2020/10/23/kongzheng1993-SpringBoot自定义starter/index.html","hash":"0447c5dfebc78a0fcb00191672874ada6d5b0f34","modified":1716089075525},{"_id":"public/2020/10/21/kongzheng1993-原生js实现双击复制后的思考/index.html","hash":"c570b78078e6933f9bb5ac9b7c7a23ddb0bf5618","modified":1716089075525},{"_id":"public/2020/07/26/kongzheng1993-apollo/index.html","hash":"c0d0a0ae2ea3d47d9906e1f112cdc41769330bb7","modified":1716089075525},{"_id":"public/2020/10/19/kongzheng1993-Vue.prototype/index.html","hash":"2f8218bd3c711d3e42f2921c5229487b608ba6b0","modified":1716089075525},{"_id":"public/2020/08/04/kongzheng1993-java调用外部程序/index.html","hash":"558042cef601eb56e7d670ea7789bb851efefcb8","modified":1716089075525},{"_id":"public/2020/07/11/kongzheng1993-think-in-md-catalog/index.html","hash":"d3c6d438e3cfa6d1a67674c81335f1ddff9e2a05","modified":1716089075525},{"_id":"public/2020/07/05/kongzheng1993-Java-rmi/index.html","hash":"4cb4b4e02662d5c37bb2f0c7e3e5721dc9cc009f","modified":1716089075525},{"_id":"public/2020/07/08/kongzheng1993-move-to-csdn/index.html","hash":"4b3d3e417f8c4c2e267e7ef1d1c400dc638621c9","modified":1716089075525},{"_id":"public/2020/06/29/kongzheng1993-NLP/index.html","hash":"b596bba2b8fae4999ee8e710339eae5bdf8e4a5b","modified":1716089075525},{"_id":"public/2021/03/15/kongzheng1993-FeignClient遇到的小问题/index.html","hash":"2e482e3ffa762d822fa18e66aaf1117a29b78568","modified":1716089075524},{"_id":"public/2020/05/22/kongzheng1993-Unicast_Multicast_Broadcast/index.html","hash":"fb9a3574c8d7a4e45e3c278a97be878cf9cf46e2","modified":1716089075525},{"_id":"public/2020/05/18/kongzheng1993-ThreadPool总结/index.html","hash":"f0c4206732ad9fcc3dcc7e113da949ee5b1888c9","modified":1716089075525},{"_id":"public/2020/05/21/kongzheng1993-分布式事务/index.html","hash":"1417b4071e9763d381f4c22a98c6cf3ff0924115","modified":1716089075525},{"_id":"public/2020/05/12/kongzheng1993-Nginx/index.html","hash":"3a39565e8821356ebc383ce6d93d8e534efbe0d1","modified":1716089075525},{"_id":"public/2020/05/21/kongzheng1993-maven_install/index.html","hash":"74ce214ab226db39b33fe6cf3f2827a0dc0ac0e5","modified":1716089075525},{"_id":"public/2020/05/29/kongzheng1993-Java动态代理/index.html","hash":"6075ffaef70c27ff5e8ced459b2bd56387bd387a","modified":1716089075525},{"_id":"public/2020/05/09/kongzheng1993-数据库设计范式/index.html","hash":"d0f85021bffd7a34ed81a19c2349124c11fc7d1f","modified":1716089075525},{"_id":"public/2020/04/30/kongzheng1993-一次服务器告警的处理/index.html","hash":"d6157a04c4d1e9484182daec9263843f618ee55b","modified":1716089075525},{"_id":"public/2020/05/12/kongzheng1993-Linux文件句柄/index.html","hash":"5d0631ffcac39b1132864bd4c57dc1f824f834af","modified":1716089075525},{"_id":"public/2020/04/28/kongzheng1993-devtools/index.html","hash":"1997658ca07a31a6ac3e2c5f33d38e1260dd673d","modified":1716089075525},{"_id":"public/2020/04/25/kongzheng1993-死锁/index.html","hash":"2630fcbf0a1412558ce6b67b76bf6b289f6ee3b1","modified":1716089075525},{"_id":"public/2020/04/29/kongzheng1993-各种索引/index.html","hash":"c886dcd3cc403c5d1c909e773f7b9b7d175c6328","modified":1716089075525},{"_id":"public/2020/04/24/kongzheng1993-SPI/index.html","hash":"a9c27aaaef16d07f228cb0f685cfc8d7d703e50e","modified":1716089075525},{"_id":"public/2020/04/25/kongzheng1993-银行家算法/index.html","hash":"897641cb1e6a13bb3e726a8d6eb9c6323b04e313","modified":1716089075525},{"_id":"public/2020/04/21/kongzheng1993-synchronized锁升级/index.html","hash":"4fdbbea54012566e33a6052b03650f3ced21c0e5","modified":1716089075525},{"_id":"public/2020/04/20/kongzheng1993-JVM/index.html","hash":"7132dbdba95ee22d62d3d29828a307ae4004ebd5","modified":1716089075525},{"_id":"public/2020/04/19/kongzheng1993-Java就是值传递的/index.html","hash":"fb5ef6e846eccd7899b747f63c3169d7b79c807d","modified":1716089075525},{"_id":"public/2020/04/22/kongzheng1993-SQL优化/index.html","hash":"4e7df1a3ad61fbaf682db34b23dfec5d86fd6710","modified":1716089075525},{"_id":"public/2020/04/17/kongzheng1993-Java_Monitor/index.html","hash":"bd423ff1a648c305cae0b4d127b1ce744f4d0ab0","modified":1716089075525},{"_id":"public/2020/04/14/kongzheng1993-JavaObjectHeader/index.html","hash":"c1fc02372497ba881ec8f5f4bbbf5761f4aa299d","modified":1716089075525},{"_id":"public/2020/04/17/kongzheng1993-MySQL事务隔离级别/index.html","hash":"7d8c9c444408abf8419267b38956c4b8480bee72","modified":1716089075525},{"_id":"public/2020/04/16/kongzheng1993-CAS/index.html","hash":"6abdaaec193be604872fd66bbd340a6928a4d2dc","modified":1716089075525},{"_id":"public/2020/04/12/kongzheng1993-序列化与反序列化/index.html","hash":"89283d2ce5bea15f3417ced9c463556826a7e339","modified":1716089075525},{"_id":"public/2020/04/10/kongzheng1993-OpenMessageing_Example/index.html","hash":"1ba93e45ba4fdbd6f113d26b5846a7f9e3c304a6","modified":1716089075525},{"_id":"public/2020/04/08/kongzheng1993-chromebook再次折腾crouton/index.html","hash":"25c643d9f5f893af051a8bc539ca3d3a5a073537","modified":1716089075525},{"_id":"public/2020/04/09/kongzheng1993-TransactionMessage/index.html","hash":"fb8071532c0f69c1c8cced590bdde32c0f579693","modified":1716089075525},{"_id":"public/2020/03/30/kongzheng1993-用nodejs做一个测试api服务/index.html","hash":"e2865feba37bdb9ee7c0b9c3b7ab9ac7c4e79261","modified":1716089075526},{"_id":"public/2020/04/04/kongzheng1993-TCP三次握手&四次挥手/index.html","hash":"9494344a13190631b3e58b0d06e43aad301396bd","modified":1716089075526},{"_id":"public/2020/04/07/kongzheng1993-Effective_Java学习笔记1/index.html","hash":"b68432c41f7798940804b7e8b1c91da8d86eb0ce","modified":1716089075525},{"_id":"public/2020/03/30/kongzheng1993-一次老代码优化2/index.html","hash":"b02df67c0da0f0cb1f1492d1ee35201d87a10be4","modified":1716089075526},{"_id":"public/2020/03/30/kongzheng1993-localStorage/index.html","hash":"954cd72f5e8be3075810ff053db7dfd0a0cbb17d","modified":1716089075526},{"_id":"public/2020/03/25/kongzheng1993-RocketMQ定时消息示例/index.html","hash":"eeb6f67d4ed5542128db30fb2375f1919c9b1c90","modified":1716089075526},{"_id":"public/2020/03/25/kongzheng1993-一次老代码优化/index.html","hash":"356848536ea39e3bfae093efc4de557e92985639","modified":1716089075526},{"_id":"public/2020/03/19/kongzheng1993-Thread和Runnable/index.html","hash":"cbcb77bc6b418b90721cb0795477dfc91622467c","modified":1716089075526},{"_id":"public/2020/03/19/kongzheng1993-Future/index.html","hash":"7f7cd55ad24f54a7917bd169172911d597766fec","modified":1716089075526},{"_id":"public/2020/03/08/kongzheng1993-带你撸一台免费云服务器/index.html","hash":"15388459594bbab37e6ba10eb7fc26fa1918d765","modified":1716089075526},{"_id":"public/2020/03/08/kongzheng1993-jhat/index.html","hash":"1d61c7e1500141e2d069074d127a150b596e3cce","modified":1716089075526},{"_id":"public/2020/03/08/kongzheng1993-URLEncode/index.html","hash":"3871df681c8dfd423630735a55517c581dfb873d","modified":1716089075526},{"_id":"public/2020/03/08/kongzheng1993-Map遍历的几种方法/index.html","hash":"b2767b624aba413b22fb2d25b0442631b4087de1","modified":1716089075526},{"_id":"public/2020/03/06/kongzheng1993-Guava/index.html","hash":"eca5ee4776f5a8a15ec0801a73b5c0ae9cf55c16","modified":1716089075526},{"_id":"public/2019/09/11/kongzheng1993-MySQL基础/index.html","hash":"a4baf335f4c0e0a9c142c060f032217caaa5491a","modified":1716089075526},{"_id":"public/2020/03/08/kongzheng1993-jmap/index.html","hash":"14c26e49a11722ca192c5acfbdb33c0cb243e7a9","modified":1716089075526},{"_id":"public/2019/09/11/kongzheng1993-NIO&BIO/index.html","hash":"bc8f423932c8ff691882a02256ddd2fa11b5c39f","modified":1716089075526},{"_id":"public/2019/08/18/kongzheng1993-HashMap&ConcurrentHashMap/index.html","hash":"93eea6cbdbdc534b46365eed1fb3d0999ee72d38","modified":1716089075526},{"_id":"public/2019/06/14/kongzheng1993-mysql超过最大连接数-一次生产问题定位/index.html","hash":"d777bf5597491fa601262fafe227797945d08955","modified":1716089075526},{"_id":"public/2020/04/27/kongzheng1993-java.lang.IllegalMonitorStateException/index.html","hash":"4e09df17c57eb56c7b43b23305cbce146adbaa48","modified":1716089075525},{"_id":"public/2019/06/11/kongzheng1993-关于分布式锁/index.html","hash":"bba7ac4fb70af1b0e8f6e3661ed815075a2d14be","modified":1716089075526},{"_id":"public/2019/06/13/kongzheng1993-Connect-timed-out与Read-timed-out/index.html","hash":"b360a8fd77e1ebb27f6d71429448fe7f35e38518","modified":1716089075526},{"_id":"public/2019/06/05/kongzheng1993-关于学习业务的思考/index.html","hash":"e6d24c9a77017736ecd748860a65b481d49255f7","modified":1716089075526},{"_id":"public/2019/06/05/kongzheng1993-nohup和&/index.html","hash":"6512a7c8f589fb2bad8092689fc1bf7cc8e2bde7","modified":1716089075526},{"_id":"public/2019/06/04/kongzheng1993-MQ/index.html","hash":"2a440a34bc04bbcb58ba548ca7d8dcd432b51779","modified":1716089075526},{"_id":"public/2019/05/30/kongzheng1993-生产部署illegal-character/index.html","hash":"93a7cb02c135d87561a8ec8092415eadbfd6a8f9","modified":1716089075526},{"_id":"public/2018/06/08/kongzheng1993-java多线程总结/index.html","hash":"35f571a73cffa124ddc1b3bd473f844e9c37ed2a","modified":1716089075526},{"_id":"public/2019/06/13/kongzheng1993-RSA加密与SHA签名/index.html","hash":"cb48d289e198687a623c51c967a9ef3dd3dcf9ad","modified":1716089075526},{"_id":"public/2018/05/02/kongzheng1993-linux命令行下的ss/index.html","hash":"6df954a2d7681f18e501865f7171d7027c057ae0","modified":1716089075526},{"_id":"public/2018/02/01/kongzheng1993-hexo搭建githubPages/index.html","hash":"03dfe51e8b2570cd8f512a1b87fab089f4628ed9","modified":1716089075526},{"_id":"public/2018/02/01/kongzheng1993-suse_ftp服务配置/index.html","hash":"99b7cd01196e3a855baa8eaf7c971f15c013957a","modified":1716089075526},{"_id":"public/2016/07/28/kongzheng1993-method_of_request&response/index.html","hash":"a682d4d61453961ef5ed029ddd23bf1c6a1dc272","modified":1716089075526},{"_id":"public/2017/03/08/kongzheng1993-JavaReflect/index.html","hash":"4d224a690b9124586fd9802ffc6f37c00905af6b","modified":1716089075526},{"_id":"public/2016/07/28/kongzheng1993-Properties/index.html","hash":"0103530bca107698a98c7f571bbe4c66533b4331","modified":1716089075526},{"_id":"public/2016/07/26/kongzheng1993-about_comparator_and_comparable/index.html","hash":"1f2a11229e0a27509124a35cc4bdbbf55491b70e","modified":1716089075526},{"_id":"public/2016/07/27/kongzheng1993-Session/index.html","hash":"b836a5a7504d57cf3c92b55e75dc76aecc9108f5","modified":1716089075526},{"_id":"public/2016/07/26/kongzheng1993-centos7_mysql/index.html","hash":"fb9c5c3b721f096dd96f1dd7938db3dc4bf1bdbf","modified":1716089075526},{"_id":"public/2016/07/26/kongzheng1993-servlet/index.html","hash":"8fd596fb95a4fcf0fdd02c21b9a946da5339928c","modified":1716089075526},{"_id":"public/2018/08/05/kongzheng1993-mysql数据库导出导入/index.html","hash":"85ce36c128776136d5a1f855a592147a36cd9f78","modified":1716089075526},{"_id":"public/2016/07/26/kongzheng1993-请求转发与重定向/index.html","hash":"88cdfc97ea3fda51cf599defa4b6706d4535ccf9","modified":1716089075526},{"_id":"public/2016/07/11/kongzheng1993-ablout_try_catch/index.html","hash":"def892ac783f5124f5617d4204577739b6d7d70f","modified":1716089075527},{"_id":"public/2016/07/11/kongzheng1993-String_Original/index.html","hash":"90b4aa96a2211682b623599a26c50c8a8ca43505","modified":1716089075527},{"_id":"public/2016/07/22/kongzheng1993-有关字符串的笔记/index.html","hash":"e1ecf83543b6a1112f84164d835ec76a9c92dac8","modified":1716089075526},{"_id":"public/2016/07/07/kongzheng1993-DB_Exchange/index.html","hash":"631b2e06fdc4d6e895c165751259f1de0ee67c8b","modified":1716089075527},{"_id":"public/2016/07/05/kongzheng1993-PreparedStatement&Statement/index.html","hash":"4bc0d0c5eb36aaf3634bc1010a012d7b4896a45c","modified":1716089075527},{"_id":"public/2016/07/20/kongzheng1993-OracleAfterChangetheNameofComputer/index.html","hash":"0b6b2c7b328ceeb513a986d4a8832c01d26bcc74","modified":1716089075526},{"_id":"public/2016/06/13/kongzheng1993-aboutFinal/index.html","hash":"90932cc2005a2825b70a796cfeeaf4a4e6b1a896","modified":1716089075527},{"_id":"public/2016/06/10/kongzheng1993-aboutFloat/index.html","hash":"5615dc0520e83eb5b1aeefd51f0001cc89f10e9a","modified":1716089075527},{"_id":"public/2016/06/10/kongzheng1993-oracle/index.html","hash":"4250cfd62f376736ef548676555d25cb17f21456","modified":1716089075527},{"_id":"public/2016/06/10/kongzheng1993-about_sqlplus_sys/index.html","hash":"da053658db95348b9801b1f77ae3a0a9db4b577b","modified":1716089075527},{"_id":"public/2016/05/20/kongzheng1993-synchronized/index.html","hash":"b7235facb6d40da9a50fdb93d64f28d05b0bb2b2","modified":1716089075527},{"_id":"public/2016/06/10/kongzheng1993-thewayofsort/index.html","hash":"43df2d2f5c62a711b17f3b573ca64f50d37e6201","modified":1716089075527},{"_id":"public/archives/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075532},{"_id":"public/archives/page/3/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075532},{"_id":"public/archives/page/2/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075532},{"_id":"public/archives/page/4/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075532},{"_id":"public/archives/page/5/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075532},{"_id":"public/archives/page/6/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075532},{"_id":"public/archives/page/7/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075532},{"_id":"public/archives/page/8/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075532},{"_id":"public/archives/page/10/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075532},{"_id":"public/archives/page/9/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075532},{"_id":"public/archives/page/11/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075532},{"_id":"public/archives/page/12/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075532},{"_id":"public/archives/page/13/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075532},{"_id":"public/archives/page/14/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075532},{"_id":"public/archives/2016/page/2/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075532},{"_id":"public/2016/05/21/kongzheng1993-resume/index.html","hash":"8fd6d6d959ae822aa272530862dcd107d1a5ff22","modified":1716089075527},{"_id":"public/archives/page/15/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075532},{"_id":"public/archives/2016/07/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075532},{"_id":"public/archives/2016/07/page/2/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075532},{"_id":"public/archives/2016/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075532},{"_id":"public/archives/2016/05/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075532},{"_id":"public/archives/2017/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075532},{"_id":"public/archives/2018/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075532},{"_id":"public/archives/2017/03/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075532},{"_id":"public/archives/2018/02/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075532},{"_id":"public/archives/2016/06/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075532},{"_id":"public/archives/2018/05/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075532},{"_id":"public/archives/2018/06/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075532},{"_id":"public/archives/2019/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075532},{"_id":"public/archives/2019/page/2/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075532},{"_id":"public/archives/2019/05/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075532},{"_id":"public/archives/2018/08/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075532},{"_id":"public/archives/2019/06/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075532},{"_id":"public/archives/2019/09/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075532},{"_id":"public/archives/2019/08/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075532},{"_id":"public/archives/2020/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075533},{"_id":"public/archives/2020/page/3/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075533},{"_id":"public/archives/2020/page/2/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075533},{"_id":"public/archives/2020/page/5/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075533},{"_id":"public/archives/2020/03/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075533},{"_id":"public/archives/2020/04/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075533},{"_id":"public/archives/2020/page/6/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075533},{"_id":"public/archives/2020/page/4/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075533},{"_id":"public/archives/2020/03/page/2/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075533},{"_id":"public/archives/2020/04/page/2/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075533},{"_id":"public/archives/2020/04/page/3/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075533},{"_id":"public/archives/2020/06/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075533},{"_id":"public/archives/2020/05/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075533},{"_id":"public/archives/2020/07/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075533},{"_id":"public/archives/2020/10/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075533},{"_id":"public/archives/2020/08/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075533},{"_id":"public/archives/2021/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075533},{"_id":"public/archives/2021/page/2/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075533},{"_id":"public/archives/2020/11/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075533},{"_id":"public/archives/2021/page/3/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075533},{"_id":"public/archives/2021/02/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075533},{"_id":"public/archives/2021/04/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075533},{"_id":"public/archives/2020/12/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075533},{"_id":"public/archives/2021/01/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075533},{"_id":"public/archives/2021/06/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075533},{"_id":"public/archives/2021/10/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075533},{"_id":"public/archives/2021/07/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075533},{"_id":"public/archives/2022/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075533},{"_id":"public/archives/2022/01/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075533},{"_id":"public/archives/2021/11/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075533},{"_id":"public/archives/2021/03/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075533},{"_id":"public/archives/2022/03/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075533},{"_id":"public/archives/2022/05/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075533},{"_id":"public/archives/2022/04/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075533},{"_id":"public/archives/2022/page/2/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075533},{"_id":"public/archives/2022/06/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075533},{"_id":"public/archives/2022/07/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075533},{"_id":"public/archives/2022/09/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075534},{"_id":"public/archives/2023/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075534},{"_id":"public/archives/2022/11/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075534},{"_id":"public/archives/2023/02/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075534},{"_id":"public/archives/2023/01/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075534},{"_id":"public/archives/2023/03/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075534},{"_id":"public/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075529},{"_id":"public/page/2/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075529},{"_id":"public/page/4/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075529},{"_id":"public/page/3/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075529},{"_id":"public/page/5/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075529},{"_id":"public/page/7/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075529},{"_id":"public/page/9/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075529},{"_id":"public/page/8/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075529},{"_id":"public/page/10/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075529},{"_id":"public/page/6/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075529},{"_id":"public/page/11/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075529},{"_id":"public/page/14/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075529},{"_id":"public/page/13/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075529},{"_id":"public/page/12/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075529},{"_id":"public/page/15/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075529},{"_id":"public/page/18/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075529},{"_id":"public/page/19/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075529},{"_id":"public/page/17/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075529},{"_id":"public/page/20/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075529},{"_id":"public/page/21/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075529},{"_id":"public/page/22/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075529},{"_id":"public/page/16/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075529},{"_id":"public/page/24/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075529},{"_id":"public/page/25/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075529},{"_id":"public/page/26/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075529},{"_id":"public/page/28/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075529},{"_id":"public/page/27/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075529},{"_id":"public/page/29/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075529},{"_id":"public/page/23/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075529},{"_id":"public/categories/blog/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075527},{"_id":"public/categories/suse/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075527},{"_id":"public/categories/linux/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075527},{"_id":"public/categories/blog/github/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075527},{"_id":"public/categories/mysql/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075527},{"_id":"public/categories/编码/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075527},{"_id":"public/categories/suse/server/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075527},{"_id":"public/categories/linux/ss/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075527},{"_id":"public/categories/quartz/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075527},{"_id":"public/categories/Linux/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075528},{"_id":"public/categories/RSA/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075527},{"_id":"public/categories/blog/github/git/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075527},{"_id":"public/categories/NIO-BIO-IO/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075527},{"_id":"public/categories/Java/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075527},{"_id":"public/categories/Java/page/2/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075527},{"_id":"public/categories/Java/page/3/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075527},{"_id":"public/categories/Java/page/4/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075527},{"_id":"public/categories/jvm/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075527},{"_id":"public/categories/quartz/锁/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075527},{"_id":"public/page/30/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075529},{"_id":"public/categories/MQ/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075527},{"_id":"public/categories/other/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075527},{"_id":"public/categories/suse/server/FTP/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075527},{"_id":"public/categories/RSA/SHA/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075527},{"_id":"public/categories/node-js/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075527},{"_id":"public/categories/Web/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075527},{"_id":"public/categories/Mysql/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075530},{"_id":"public/categories/mysql/java/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075527},{"_id":"public/categories/MySQL/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075528},{"_id":"public/categories/多线程/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075527},{"_id":"public/categories/SQL/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075527},{"_id":"public/categories/Ohters/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075527},{"_id":"public/categories/others/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075527},{"_id":"public/categories/maven/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075528},{"_id":"public/categories/RocketMQ/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075527},{"_id":"public/categories/quartz/锁/分布式/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075528},{"_id":"public/categories/java/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075528},{"_id":"public/categories/AI/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075528},{"_id":"public/categories/JavaScript/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075528},{"_id":"public/categories/vue/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075528},{"_id":"public/categories/SpringBoot/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075528},{"_id":"public/categories/Spring/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075528},{"_id":"public/categories/RSA/SHA/加密/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075528},{"_id":"public/categories/算法/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075528},{"_id":"public/categories/JDK/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075528},{"_id":"public/categories/分页/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075528},{"_id":"public/categories/JVM/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075528},{"_id":"public/categories/OS/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075528},{"_id":"public/categories/SpringCloud/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075528},{"_id":"public/categories/Maven/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075528},{"_id":"public/categories/Spring-Cloud/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075528},{"_id":"public/categories/并发/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075528},{"_id":"public/categories/数据库/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075528},{"_id":"public/categories/feign/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075528},{"_id":"public/categories/杂谈/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075528},{"_id":"public/categories/netty/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075528},{"_id":"public/categories/Kafka/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075528},{"_id":"public/categories/分布式/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075528},{"_id":"public/categories/RSA/SHA/加密/签名/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075528},{"_id":"public/categories/resume/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075528},{"_id":"public/categories/jdk/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075528},{"_id":"public/categories/网络/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075528},{"_id":"public/categories/Java/并发/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075528},{"_id":"public/categories/Nginx/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075528},{"_id":"public/categories/MongoDB/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075528},{"_id":"public/categories/spring/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075529},{"_id":"public/categories/架构/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075529},{"_id":"public/categories/面试/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075529},{"_id":"public/tags/oop/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075529},{"_id":"public/categories/SpringMVC/Actuator/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075528},{"_id":"public/categories/SpringMVC/Logger/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075529},{"_id":"public/tags/float/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075529},{"_id":"public/categories/SpringMVC/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075528},{"_id":"public/tags/String/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075529},{"_id":"public/tags/re/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075529},{"_id":"public/tags/new/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075529},{"_id":"public/tags/sample-post/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075529},{"_id":"public/tags/test/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075530},{"_id":"public/tags/images/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075529},{"_id":"public/tags/catch，try/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075530},{"_id":"public/tags/sql/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075530},{"_id":"public/tags/servlet/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075529},{"_id":"public/tags/select/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075530},{"_id":"public/tags/distinct/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075530},{"_id":"public/tags/order-by/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075530},{"_id":"public/tags/group-by/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075530},{"_id":"public/tags/sys/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075530},{"_id":"public/tags/oracle/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075530},{"_id":"public/tags/java/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075530},{"_id":"public/tags/sqlplus/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075530},{"_id":"public/tags/reflect/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075530},{"_id":"public/tags/github/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075530},{"_id":"public/tags/hexo/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075530},{"_id":"public/tags/git/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075530},{"_id":"public/tags/Class/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075530},{"_id":"public/tags/对象，Class对象/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075530},{"_id":"public/tags/linux/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075530},{"_id":"public/tags/suse/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075530},{"_id":"public/tags/ss/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075530},{"_id":"public/tags/server/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075530},{"_id":"public/tags/FTP/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075530},{"_id":"public/tags/console/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075530},{"_id":"public/tags/编码/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075530},{"_id":"public/tags/mysql/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075530},{"_id":"public/tags/quartz/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075530},{"_id":"public/tags/备份/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075530},{"_id":"public/tags/锁/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075530},{"_id":"public/tags/分布式/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075530},{"_id":"public/tags/RSA/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075530},{"_id":"public/tags/消息队列/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075530},{"_id":"public/tags/SHA/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075530},{"_id":"public/tags/mq/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075530},{"_id":"public/tags/加密/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075530},{"_id":"public/tags/Linux/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075530},{"_id":"public/tags/职业/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075530},{"_id":"public/tags/学习/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075530},{"_id":"public/tags/NIO-BIO-IO/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075531},{"_id":"public/tags/Java/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075531},{"_id":"public/tags/Java/page/2/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075531},{"_id":"public/tags/Java/page/3/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075531},{"_id":"public/tags/业务/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075530},{"_id":"public/tags/签名/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075530},{"_id":"public/tags/Java/page/4/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075531},{"_id":"public/tags/MQ/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075531},{"_id":"public/tags/jvm/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075531},{"_id":"public/tags/node-js/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075531},{"_id":"public/tags/Web/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075531},{"_id":"public/tags/Guava/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075531},{"_id":"public/tags/Mysql/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075531},{"_id":"public/tags/SQL/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075531},{"_id":"public/tags/RocketMQ/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075531},{"_id":"public/tags/多线程/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075531},{"_id":"public/tags/MySQL/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075531},{"_id":"public/tags/other/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075531},{"_id":"public/tags/算法/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075531},{"_id":"public/tags/tools/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075531},{"_id":"public/tags/Ohters/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075531},{"_id":"public/tags/others/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075531},{"_id":"public/tags/maven/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075531},{"_id":"public/tags/AI/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075531},{"_id":"public/tags/JavaScript/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075531},{"_id":"public/tags/blog/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075531},{"_id":"public/tags/SpringBoot/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075531},{"_id":"public/tags/JDK/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075531},{"_id":"public/tags/Spring/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075531},{"_id":"public/tags/分页/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075531},{"_id":"public/tags/JVM/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075531},{"_id":"public/tags/Windows/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075531},{"_id":"public/tags/SpringCloud/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075531},{"_id":"public/tags/Maven/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075531},{"_id":"public/tags/Spring-Cloud/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075531},{"_id":"public/tags/并发/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075531},{"_id":"public/tags/数据库/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075531},{"_id":"public/tags/feign/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075531},{"_id":"public/tags/Kafka/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075531},{"_id":"public/tags/杂谈/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075531},{"_id":"public/tags/netty/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075531},{"_id":"public/tags/Actuator/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075531},{"_id":"public/tags/SpringMVC/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075531},{"_id":"public/tags/resume/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075531},{"_id":"public/tags/jdk/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075532},{"_id":"public/tags/vue/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075531},{"_id":"public/tags/网络/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075532},{"_id":"public/tags/简历/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075532},{"_id":"public/tags/Nginx/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075532},{"_id":"public/tags/MongoDB/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075532},{"_id":"public/tags/spring/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075532},{"_id":"public/tags/Logger/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075532},{"_id":"public/tags/架构/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075532},{"_id":"public/tags/安全/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075532},{"_id":"public/tags/面试/index.html","hash":"9bf9bf59fd311338ff464c40ac557c0a6d336b1d","modified":1716089075532},{"_id":"public/ads.txt","hash":"72acced352e6dd9cb6f7fcba103c8bd65798ecf2","modified":1716088873135},{"_id":"public/img/article-list-background.jpeg","hash":"4fdf8b3e53dd02d6ee6360aebfadb0cba1fb5633","modified":1716088873135},{"_id":"public/img/alipay.png","hash":"73ca818d426466ce3df646a300768e8629ddbddf","modified":1716088873135},{"_id":"public/img/weixin.png","hash":"b243e081ea88d672c1b4aa8be0759a78e93e629b","modified":1716088873135},{"_id":"public/img/brown-papersq.png","hash":"3a1332ede3a75a3d24f60b6ed69035b72da5e182","modified":1716088873135},{"_id":"public/img/school-book.png","hash":"711ec983c874e093bb89eb77afcbdf6741fa61ee","modified":1716088873135},{"_id":"public/css/fonts/icomoon.ttf","hash":"eb976d8b8559fcddfc2658a03a4350cb566fc06b","modified":1716088873135},{"_id":"public/css/fonts/icomoon.woff","hash":"3985d29416bb9b19f50a2f20f2bbbce47f10af8d","modified":1716088873135},{"_id":"public/css/fonts/iconfont.eot","hash":"3dfe8e557d9dfaf39bca088a02b76deb82dbaa3d","modified":1716088873135},{"_id":"public/css/fonts/iconfont.svg","hash":"c61a31e5310430312677fffe4286097d29d10151","modified":1716088873135},{"_id":"public/css/fonts/iconfont.ttf","hash":"aa087561480fb9c2cfd541e33d1e99d5ac1a56bb","modified":1716088873135},{"_id":"public/css/fonts/iconfont.woff","hash":"f8ed131ccf13f4bdd3ec11fc3e997339dd7b66ba","modified":1716088873135},{"_id":"public/css/fonts/icomoon.svg","hash":"37ac1ef28b03f46bf3ad2606c86f0e1ec3e4405f","modified":1716088873135},{"_id":"public/css/fonts/icomoon.eot","hash":"b6195bedc1cb2f9cfcb26cc27021f2e94be2ab0a","modified":1716088873135},{"_id":"public/2020/04/14/kongzheng1993-JavaObjectHeader/Java_Monitor.png","hash":"203178617c885aabef70c76780ea51b9794a8530","modified":1716088873136},{"_id":"public/2020/04/24/kongzheng1993-SPI/v2-a4598f8b9ab46951b190cc9ce059eee0_720w.jpg","hash":"381ff33a509bdfd504c3e6c0f38a21a9c799349a","modified":1716088873136},{"_id":"public/2020/04/20/kongzheng1993-JVM/20170513134212845.png","hash":"130e45f5c7b0d38071a40f5d061021d2598b0cc7","modified":1716088873136},{"_id":"public/2021/03/27/kongzheng1993-JavaRemoteDebug/idea_remote_debug.png","hash":"db8ad65cd8a1f37a93803b427b1a25557868b113","modified":1716088873482},{"_id":"public/2021/04/29/kongzheng1993-getResource/IDE.png","hash":"ea581c0338ff20a9586eee1e41e1c27b8bce5bda","modified":1716088873482},{"_id":"public/2016/05/20/kongzheng1993-synchronized/fanyi.png","hash":"ae4ffc14a6d221d98b0c6459b7d9cc86e66ef1b4","modified":1716088873484},{"_id":"public/2021/11/26/kongzheng1993-maven_resource_plugin/20161012101735543.png","hash":"e77479b68e17dfbc820c3981e70a85ebb588ef7b","modified":1716088873484},{"_id":"public/2020/04/17/kongzheng1993-Java_Monitor/1.png","hash":"7881446860378e046659d3b5e2ebe07c39deb2e5","modified":1716088873484},{"_id":"public/2016/07/26/kongzheng1993-servlet/servlet接口.jpg","hash":"55c1d6b94b27a27827b37e62804e965e0fe8237a","modified":1716088873484},{"_id":"public/2020/04/19/kongzheng1993-Java就是值传递的/2.png","hash":"44f945f1b8dda0f98fb2aa85a29e92d20c52dfca","modified":1716088873484},{"_id":"public/2020/04/17/kongzheng1993-Java_Monitor/2.png","hash":"6dc9b19e3fbb8d6e1d2b48a07f0451abc2b31d18","modified":1716088873484},{"_id":"public/2020/04/19/kongzheng1993-Java就是值传递的/1.jpg","hash":"d07d4d9091273bdc89e5b41debd7c2b916acb016","modified":1716088873484},{"_id":"public/2022/11/19/kongzheng1993-feign继承特性/1.png","hash":"5a596bd420ff5ff092821911508cc93c9d3f7e98","modified":1716088873484},{"_id":"public/2022/11/19/kongzheng1993-feign继承特性/2.png","hash":"1bcc7a74f68050d4981a8c2a43c00b60a8e45385","modified":1716088873484},{"_id":"public/2020/04/29/kongzheng1993-各种索引/1216484-20190825001255129-2032384167.png","hash":"891212385045d7060460369ed0ae0fe986895706","modified":1716088873484},{"_id":"public/2020/04/29/kongzheng1993-各种索引/v2-2c2264cc1c6c603dfeca4f84a2575901_r.jpg","hash":"e04daddd6330c63d74580033232c9d6bb595d309","modified":1716088873484},{"_id":"public/2020/05/18/kongzheng1993-ThreadPool总结/2020-05-18 12-50-13屏幕截图.png","hash":"4d68ac02e807a1a55f053ca56cef3110d1138b47","modified":1716088873484},{"_id":"public/2020/04/08/kongzheng1993-chromebook再次折腾crouton/linuxRelease.jpg","hash":"38c2090ec8816fcfc91f64710961e2b3e856ce51","modified":1716088873484},{"_id":"public/2020/04/08/kongzheng1993-chromebook再次折腾crouton/finishInstall.jpg","hash":"55ae851a46d9f742f21ab9bc2e27254841c11c1e","modified":1716088873484},{"_id":"public/2020/04/08/kongzheng1993-chromebook再次折腾crouton/xfce4.jpg","hash":"22eef68634de6967b8e0a43a53c698f83f0804c4","modified":1716088873484},{"_id":"public/css/mobile.css","hash":"79ab291be160e0ca753512a96c5198f7477f13be","modified":1716088873496},{"_id":"public/js/search.js","hash":"c80c9a231ee040c7adc07a477793873fb85ce8bc","modified":1716088873496},{"_id":"public/css/hl_theme/atom-dark.css","hash":"88d11052a24e8100af6248eb4dbe1ce7b0e96408","modified":1716088873496},{"_id":"public/css/hl_theme/darcula.css","hash":"4341074bae4bc9f0b86e32b623e27babc0159b6e","modified":1716088873496},{"_id":"public/css/hl_theme/github-gist.css","hash":"7a41c1c479d09df875f99f1f6d94aac42e9e2ad0","modified":1716088873496},{"_id":"public/css/hl_theme/github.css","hash":"e05a0806a508a26b9f3f3794b6b588ec6504ad3f","modified":1716088873496},{"_id":"public/css/hl_theme/gruvbox-dark.css","hash":"8c440d9b4ee19ac03eaee3c6af78ba52e5ba5535","modified":1716088873496},{"_id":"public/css/hl_theme/gruvbox-light.css","hash":"30514aaa242a34647aa666cfca4fc74c595ea8f2","modified":1716088873496},{"_id":"public/css/hl_theme/kimbie-dark.css","hash":"728527fcc308da454722c119b89e6da3025bd1e3","modified":1716088873496},{"_id":"public/css/hl_theme/kimbie-light.css","hash":"0c61926c989163faefb031d27bce3e287d6e10f2","modified":1716088873496},{"_id":"public/css/hl_theme/railscasts.css","hash":"511f2fd2a84d426e5da5cb17880cc08f73beb002","modified":1716088873496},{"_id":"public/css/hl_theme/rainbow.css","hash":"7ff4251938076ddb7e4e49413db82653e5b61321","modified":1716088873496},{"_id":"public/css/hl_theme/school-book.css","hash":"ffbbcd13a74ac2404262c50b7a43053dfd0096ff","modified":1716088873496},{"_id":"public/css/hl_theme/atom-light.css","hash":"a3c8f3ee9a655594eff7ac545cb2e6914c1abcc2","modified":1716088873496},{"_id":"public/css/hl_theme/brown-paper.css","hash":"500c8e750373f6656ff49a7857c871ceedcf8777","modified":1716088873496},{"_id":"public/css/hl_theme/sublime.css","hash":"f65c5b116d9213afb9c324384a2f3bc86cb71121","modified":1716088873496},{"_id":"public/css/hl_theme/zenbum.css","hash":"0a78f74a93568e20b32ca7427c719e9bae9a0b55","modified":1716088873496},{"_id":"public/css/hl_theme/sunburst.css","hash":"8a135abac1512cf430d1d1ad2304b79afa1a4d6e","modified":1716088873496},{"_id":"public/css/style.css","hash":"fc4b532e837d1177f0cb6957985bdf07c708c9d7","modified":1716088873496},{"_id":"public/2020/03/08/kongzheng1993-带你撸一台免费云服务器/3.png","hash":"2a37e0a0f459ebbcc369c924b899966aa2c081fc","modified":1716088873484},{"_id":"public/2020/03/08/kongzheng1993-带你撸一台免费云服务器/10.png","hash":"7073ef7ae5fa2e63bf5acb2dbe5c5430e218a94f","modified":1716088873484},{"_id":"public/2020/03/08/kongzheng1993-带你撸一台免费云服务器/7.png","hash":"12d31602b966012736d2eee897e131db3c87ee67","modified":1716088873484},{"_id":"public/2020/04/25/kongzheng1993-死锁/v2-fccd6ccc07c0caf2643f324cdb7856e7_b.jpg","hash":"09eb8b22ff8a570e107fb2274a19379319f4e136","modified":1716088873484},{"_id":"public/2020/10/21/kongzheng1993-原生js实现双击复制后的思考/WechatIMG26.jpeg","hash":"efa0e6553deab43b3bb2b3d0b541b4193725e8bb","modified":1716088873497},{"_id":"public/2020/05/21/kongzheng1993-分布式事务/seata.png","hash":"7d6474d370b2a5fa2d5d88dfe1875c8cae2f414e","modified":1716088873496},{"_id":"public/2016/07/26/kongzheng1993-servlet/servlet实例化过程.jpg","hash":"b67fbe1816562e6ed9109f98e778e94835647f79","modified":1716088873497},{"_id":"public/2020/07/26/kongzheng1993-apollo/apollo-flow.png","hash":"4f8a4e881840463c1384e33fc4e954b9d60e37c5","modified":1716088873497},{"_id":"public/2021/07/04/kongzheng1993-JVM调优/stack.png","hash":"2ca00441becc0f8cb0248a7ceab192d554d4e13b","modified":1716088873497},{"_id":"public/2020/07/26/kongzheng1993-apollo/overall-architecture.png","hash":"7912b3d4b2e9bac5bc2caa14824ab4af6e56cc49","modified":1716088873497},{"_id":"public/2021/11/29/kongzheng1993-hs_err_pid_pid_log/飞书20211129-112155.png","hash":"161d06aee8592411d5075557d014e646c6ad9df5","modified":1716088873497},{"_id":"public/2022/03/09/kongzheng1993-包装类==的问题/Integer.png","hash":"dbd07e0c2eb082f4f4d92c18c3946aa8854cc880","modified":1716088873497},{"_id":"public/2020/04/29/kongzheng1993-各种索引/820365-20160721211316388-637070407.png","hash":"a6d4e6ceb02def25f69ad4bf49e1bdabca8e69bb","modified":1716088873497},{"_id":"public/2020/03/08/kongzheng1993-带你撸一台免费云服务器/11.png","hash":"a50613ebd7db5cf0121bce5eaa6c57b96d56ad28","modified":1716088873497},{"_id":"public/2020/03/08/kongzheng1993-带你撸一台免费云服务器/12.png","hash":"55ab184caff7c9a3a6f5bad70c8498a2437332e7","modified":1716088873497},{"_id":"public/2020/03/08/kongzheng1993-带你撸一台免费云服务器/5.png","hash":"ca3342a074768d0ce53b861d30920f7202720648","modified":1716088873497},{"_id":"public/2020/03/08/kongzheng1993-带你撸一台免费云服务器/2.png","hash":"89d51fb65c56326bb3fe62dbf7a4e769fa276850","modified":1716088873497},{"_id":"public/2020/03/08/kongzheng1993-带你撸一台免费云服务器/6.png","hash":"bf40ef518007c6fa5cd72fb71fa2f942dcf1b768","modified":1716088873497},{"_id":"public/2023/03/08/kongzheng1993-MongoDB/image-20210715174420382.png","hash":"8f2f48f954c3bd6e3d898379f71e8f991e7c08a9","modified":1716088873497},{"_id":"public/2020/05/12/kongzheng1993-Nginx/v2-e1826bab1d07df8e97d61aa809b94a10_r.jpg","hash":"c32c3361e7b2590907d96f6ae583d7d770e6f0f3","modified":1716088873497},{"_id":"public/2020/04/08/kongzheng1993-chromebook再次折腾crouton/taobao.jpg","hash":"cec87bb7d3588a1e94e2c9d7244abd90d82bd98d","modified":1716088873497},{"_id":"public/2020/04/08/kongzheng1993-chromebook再次折腾crouton/kaliLinux.png","hash":"e42a78cd3e4baabac8f105e4df40a47d5799ddae","modified":1716088873497},{"_id":"public/2021/07/01/kongzheng1993-springMVC消息转换器/2.jpg","hash":"c2fee12722f5b1776b3cd3b962c3c38caff2fac2","modified":1716088873497},{"_id":"public/2018/06/08/kongzheng1993-java多线程总结/20150309140927553.jpeg","hash":"391773d5b0c871dc2623b8403e9166aafa170237","modified":1716088873497},{"_id":"public/img/avatar.png","hash":"f3f94ac1fa440c0b90ea2c7ab8332b7fb61b56c3","modified":1716088873497},{"_id":"public/2019/05/30/kongzheng1993-生产部署illegal-character/WechatIMG1.jpeg","hash":"80ecb632806183e9ebee073854908d37ed4c98ad","modified":1716088873497},{"_id":"public/2023/01/30/kongzheng1993-Netty/EventLoop.png","hash":"9adcdb470a4ef26f012232684a32d8abd6a10306","modified":1716088873497},{"_id":"public/2023/01/30/kongzheng1993-Netty/Reactor.png","hash":"a7d542a86fd802c82d6309023ffd558c32687512","modified":1716088873497},{"_id":"public/2023/01/30/kongzheng1993-Netty/channel.png","hash":"5b517c34b4ed9d918d28d8a62c0ef948e7fe71dc","modified":1716088873497},{"_id":"public/2023/01/30/kongzheng1993-Netty/handler.png","hash":"6926c30ced41710393fb602f337f38b430cc8224","modified":1716088873497},{"_id":"public/js/jquery.autocomplete.min.js","hash":"7b8ac4d06c9e763963832529f44a56ad42a81e5f","modified":1716088873496},{"_id":"public/2020/03/08/kongzheng1993-带你撸一台免费云服务器/1.png","hash":"31a24cb85cbe55c29e48af9fc1ae9218a09a4455","modified":1716088873497},{"_id":"public/2020/03/08/kongzheng1993-带你撸一台免费云服务器/9.png","hash":"0312c5e7da78bdde1fb678d7d58cc071ff55a168","modified":1716088873497},{"_id":"public/2020/03/08/kongzheng1993-带你撸一台免费云服务器/13.png","hash":"740ad4f0dc293566110778bad6f7a92e2ce5f8fe","modified":1716088873497},{"_id":"public/2020/03/30/kongzheng1993-用nodejs做一个测试api服务/test.bmp","hash":"342db818da38cc5e5de107295a625ca329c1f59c","modified":1716088873497},{"_id":"public/2020/03/08/kongzheng1993-带你撸一台免费云服务器/8.png","hash":"d5c219fd68e07a4a2d2bdf42f97aedd2b89ca5ac","modified":1716088873497},{"_id":"public/2020/04/08/kongzheng1993-chromebook再次折腾crouton/recovery.bmp","hash":"da765789d3a0a45d7d53cb93d88bc81b1d2d93dc","modified":1716088873497},{"_id":"public/2021/07/01/kongzheng1993-springMVC消息转换器/1.jpg","hash":"8bc1834622c7c15d99c50b69b64cf9949e5d2350","modified":1716088873497},{"_id":"public/2016/05/20/kongzheng1993-synchronized/1.png","hash":"32ef9add0dea53e2c543fc79ca7ca79a93441334","modified":1716088873497},{"_id":"public/2020/04/04/kongzheng1993-TCP三次握手&四次挥手/11111.png","hash":"5ca10aadaef4e65d8f1fa19ad6bd3c071460cad0","modified":1716088873497},{"_id":"public/2020/04/21/kongzheng1993-synchronized锁升级/v2-8f405804cd55a26b34d59fefc002dc08_r.jpg","hash":"c593759b7e10b8e845404e3195534c88715fc2e6","modified":1716088873497},{"_id":"public/2020/04/28/kongzheng1993-devtools/截屏2020-04-28下午6.51.22.png","hash":"1ffa309e4258ee29e097b5c444dd7475c98bf590","modified":1716088873497},{"_id":"public/2020/04/29/kongzheng1993-各种索引/v2-5f069fd820637db1b877fdd6799a2b67_r.jpg","hash":"9b864b9346d3c6279ae33012cbd1aef064c37825","modified":1716088873518},{"_id":"public/2022/04/15/kongzheng1993-FastThrow/param.png","hash":"940b0c9c3a9af22b6d338413acca8929760e0e99","modified":1716088873518},{"_id":"public/2022/04/15/kongzheng1993-FastThrow/noParam.png","hash":"29e0a505bcca6cae78db31b95deb0cd1bcecd7fd","modified":1716088873518},{"_id":"public/2021/07/01/kongzheng1993-springMVC消息转换器/3.jpg","hash":"ce41c810da9c690fc80f95ba0f3ebca9cc948d63","modified":1716088873519},{"_id":"public/2023/01/30/kongzheng1993-Netty/asyncIO.png","hash":"8a295f37c6ade6a47de56d7c96637de63ad8fc6b","modified":1716088873519},{"_id":"public/css/gitalk.css","hash":"58177ce227c50ee359fbf99a4fdd26058887afc5","modified":1716088873496},{"_id":"public/2023/01/30/kongzheng1993-Netty/blockingIO.png","hash":"08497be207bad6e98776ab42ac49031b921800af","modified":1716088873524},{"_id":"public/2023/01/30/kongzheng1993-Netty/multiplexing.png","hash":"059d485b9b523d14e28fdfa15887a1297049d18a","modified":1716088873519},{"_id":"public/2023/01/30/kongzheng1993-Netty/netty_reactor.png","hash":"7975e3b62f2abfdf2483c2ed190f189773e7be8c","modified":1716088873519},{"_id":"public/js/jquery.pjax.js","hash":"191c49fdb40dff115a49cfd2b30dffb888d86550","modified":1716088873496},{"_id":"public/css/fonts/selection.json","hash":"047b615ea32dc48dae5b964061427d41feaaafdf","modified":1716088873496},{"_id":"public/js/script.js","hash":"7502191e29366a11323dc72ae365b1aed254e6f2","modified":1716088873496},{"_id":"public/2020/04/04/kongzheng1993-TCP三次握手&四次挥手/11585992522_.pic.jpg","hash":"a94a79099003686436a82d536c34cffb263ea410","modified":1716088873519},{"_id":"public/2020/04/04/kongzheng1993-TCP三次握手&四次挥手/41585998713_.pic_hd.jpg","hash":"82c87473f3e7fd25f46b1aebe5fa2700350ce466","modified":1716088873519},{"_id":"public/js/iconfont.js","hash":"3a0869ca1b09af07d82987e343a3bc4cb9558ecb","modified":1716088873496},{"_id":"public/2020/07/05/kongzheng1993-Java-rmi/rmi.png","hash":"efb67c848ec92c8ddf651c3854f1182d9e9b087e","modified":1716088873537},{"_id":"public/2020/03/30/kongzheng1993-用nodejs做一个测试api服务/run.bmp","hash":"0a01b2afca0b35d0125fc7e04c30eac9b7da23d7","modified":1716088873537},{"_id":"public/2022/03/05/kongzheng1993-JVM知识点总结/Class.png","hash":"ce82dfa79bb0a7cd0e2363f517b3ced0d2931ba9","modified":1716088873524},{"_id":"public/2022/03/10/kongzheng1993-DDD/entity_model的副本.png","hash":"68d6fa59d04e953c523a8d61f20cd3cdea3ca50c","modified":1716088873557},{"_id":"public/2023/01/30/kongzheng1993-Netty/nonBlockingIO.png","hash":"fd0f23612b15290eb1590f746d774414ed328a36","modified":1716088873537},{"_id":"public/2020/04/04/kongzheng1993-TCP三次握手&四次挥手/21585993169_.pic_hd.jpg","hash":"15964296af5bc0fa6973f59c2d0ccd2fb18543dc","modified":1716088873537},{"_id":"public/2020/04/04/kongzheng1993-TCP三次握手&四次挥手/31585998651_.pic_hd.jpg","hash":"aebb809e9446d43118e92baca7533264df068b64","modified":1716088873537},{"_id":"public/2022/03/10/kongzheng1993-DDD/entity_model.png","hash":"68d6fa59d04e953c523a8d61f20cd3cdea3ca50c","modified":1716088873558},{"_id":"public/2021/07/04/kongzheng1993-JVM调优/JVM.png","hash":"fa1875a4a9072f0cf99190a44a5455287ba27a86","modified":1716088873537},{"_id":"public/2020/03/30/kongzheng1993-用nodejs做一个测试api服务/cnpm.bmp","hash":"07aab8787fb73fedad9956b1aa5cfb9ec77af0cb","modified":1716088873557},{"_id":"public/2021/11/29/kongzheng1993-hs_err_pid_pid_log/飞书20211129-112140.png","hash":"beb8b4353e878baef14a054a556b381ffc917c86","modified":1716088873565},{"_id":"public/2020/04/04/kongzheng1993-TCP三次握手&四次挥手/51585999731_.pic_hd.jpg","hash":"b8575906ee1f238c450037b27dbbbde960dae593","modified":1716088873524},{"_id":"public/2020/03/30/kongzheng1993-用nodejs做一个测试api服务/express.bmp","hash":"3e8b011854c29de777706ec2a9570265aa1538a7","modified":1716088873597},{"_id":"public/2020/06/29/kongzheng1993-NLP/statistical-machine-translation.png","hash":"b9e9e87e8271540c97526b961554583d79cfb3de","modified":1716088873597},{"_id":"public/2023/03/23/kongzheng1993-服务日志实现方式切换引起的问题/new.png","hash":"c6a831591f6009fede80358deda478d42bebf85f","modified":1716088873597},{"_id":"public/2023/03/23/kongzheng1993-服务日志实现方式切换引起的问题/old.png","hash":"a695f344ad773a3749b074618a970fcf112ae06c","modified":1716088873597},{"_id":"public/js/gitalk.js","hash":"00419a6156f5d4f9b8aba00d446cd64ba73e0d12","modified":1716088873496},{"_id":"public/js/gitment.js","hash":"59a1e03f2b0ce61dd9bd405d3c52d3e07cc10dec","modified":1716088873496},{"_id":"public/2023/01/30/kongzheng1993-Netty/man2kqueue.png","hash":"9004e97ab8c6c6e6825aaf9e52ca576cb50088a6","modified":1716088873637},{"_id":"public/2023/01/30/kongzheng1993-Netty/man2select.png","hash":"32167bdc209a75747726514226acc129410676ad","modified":1716088873637},{"_id":"public/img/gongzhonghao.png","hash":"7fad9908a7ade993f434150a9873518df5d91b4c","modified":1716088873651}],"Category":[{"name":"blog","_id":"clg0k2ac00010t26f6gsknie7"},{"name":"linux","_id":"clg0k2ac30017t26fjt58hkz7"},{"name":"suse","_id":"clg0k2ac5001ct26f6v9sbmzs"},{"name":"github","parent":"clg0k2ac00010t26f6gsknie7","_id":"clg0k2ac6001gt26fhvt0dzxx"},{"name":"编码","_id":"clg0k2acj001lt26fy872xsu7"},{"name":"mysql","_id":"clg0k2acx001tt26f81m22ixl"},{"name":"ss","parent":"clg0k2ac30017t26fjt58hkz7","_id":"clg0k2ada001yt26flpge9yoz"},{"name":"quartz","_id":"clg0k2adk0023t26fmdya3cv3"},{"name":"server","parent":"clg0k2ac5001ct26f6v9sbmzs","_id":"clg0k2adm0028t26fznptrq8i"},{"name":"RSA","_id":"clg0k2ae1002et26fdhe7glqe"},{"name":"Linux","_id":"clg0k2ae4002jt26fbrjwekvu"},{"name":"git","parent":"clg0k2ac6001gt26fhvt0dzxx","_id":"clg0k2aeb002qt26fmrekq8cw"},{"name":"NIO BIO IO","_id":"clg0k2agt0031t26faz9he24d"},{"name":"Java","_id":"clg0k2ahp003at26fpnz24slm"},{"name":"jvm","_id":"clg0k2aji003mt26f307upm7q"},{"name":"MQ","_id":"clg0k2ak1003zt26ftyp73z3i"},{"name":"锁","parent":"clg0k2adk0023t26fmdya3cv3","_id":"clg0k2akk004et26faecgwxyv"},{"name":"other","_id":"clg0k2akr004mt26f9679pdbx"},{"name":"FTP","parent":"clg0k2adm0028t26fznptrq8i","_id":"clg0k2akw004xt26fsya5p6yw"},{"name":"Web","_id":"clg0k2al5005ct26fl0zdngfe"},{"name":"SHA","parent":"clg0k2ae1002et26fdhe7glqe","_id":"clg0k2ala005jt26fq7njzfix"},{"name":"node.js","_id":"clg0k2alf005qt26fyutmonz1"},{"name":"RocketMQ","_id":"clg0k2alx006it26fyi4qi6uz"},{"name":"java","parent":"clg0k2acx001tt26f81m22ixl","_id":"clg0k2alz0072t26fpp2w41z6"},{"name":"Mysql","_id":"clg0k2am1007ht26fhfklscr2"},{"name":"SQL","_id":"clg0k2am3007vt26fy0mrre88"},{"name":"多线程","_id":"clg0k2am60081t26fis59zt49"},{"name":"MySQL","_id":"clg0k2amg008ft26fhig3jcrh"},{"name":"Ohters","_id":"clg0k2amq008vt26fuqwhvcuy"},{"name":"others","_id":"clg0k2ams0093t26f5sk60foc"},{"name":"maven","_id":"clg0k2amt009at26fb913q9th"},{"name":"AI","_id":"clg0k2amz009it26fzr966jlm"},{"name":"分布式","parent":"clg0k2akk004et26faecgwxyv","_id":"clg0k2an0009qt26ff679e6nq"},{"name":"分布式","_id":"clg0k2an1009xt26fdujsauis"},{"name":"java","_id":"clg0k2an100a2t26fc63ycuun"},{"name":"JavaScript","_id":"clg0k2an300aet26fnzd6jt3q"},{"name":"vue","_id":"clg0k2an300amt26fn2ilk4bm"},{"name":"SpringBoot","_id":"clg0k2an400ast26flqs58qag"},{"name":"Spring","_id":"clg0k2an400awt26fjt21cw8h"},{"name":"算法","_id":"clg0k2an400b0t26f1nks67np"},{"name":"加密","parent":"clg0k2ala005jt26fq7njzfix","_id":"clg0k2an900b4t26fqql8bck0"},{"name":"JDK","_id":"clg0k2ane00b8t26f39apzduj"},{"name":"分页","_id":"clg0k2anf00bbt26fnmgw8ja6"},{"name":"OS","_id":"clg0k2anf00bft26fttrxdcyp"},{"name":"杂谈","_id":"clg0k2anj00bmt26f6xqdilr4"},{"name":"JVM","_id":"clg0k2ank00bst26fles16vjf"},{"name":"SpringCloud","_id":"clg0k2ank00bzt26fbxs72e41"},{"name":"Spring Cloud","_id":"clg0k2anl00c7t26fxgnwsm4z"},{"name":"Maven","_id":"clg0k2ann00cqt26fdrj4s7jq"},{"name":"并发","_id":"clg0k2anp00det26fvolyusqi"},{"name":"数据库","_id":"clg0k2anp00djt26fxlsv4j7n"},{"name":"feign","_id":"clg0k2anq00dqt26fki3nzawh"},{"name":"Kafka","_id":"clg0k2anq00dvt26ftc3bi4w1"},{"name":"netty","_id":"clg0k2anq00dzt26fwdd3d93b"},{"name":"SpringMVC","_id":"clg0k2anr00e3t26fdf8jqml9"},{"name":"签名","parent":"clg0k2an900b4t26fqql8bck0","_id":"clg0k2anr00e7t26f5tb3num7"},{"name":"Actuator","parent":"clg0k2anr00e3t26fdf8jqml9","_id":"clg0k2anr00ebt26f4n9gkpd0"},{"name":"resume","_id":"clg0k2aor00het26fjyz9u7iu"},{"name":"jdk","_id":"clg0k2aov00hmt26fd64s8myq"},{"name":"网络","_id":"clg0k2aqa00hzt26f37amzu08"},{"name":"并发","parent":"clg0k2ahp003at26fpnz24slm","_id":"clg0k2ar400i9t26f5slmreaj"},{"name":"Nginx","_id":"clg0k2ard00iht26fvo68ayqx"},{"name":"MongoDB","_id":"clg0k2are00int26fvcu5zyts"},{"name":"Logger","parent":"clg0k2anr00e3t26fdf8jqml9","_id":"clg0k2are00itt26fxrprdisl"},{"name":"spring","_id":"clg0k2as200j7t26f1ea0xulv"},{"name":"架构","_id":"clg0k2asc00jct26fiijbs3hw"},{"name":"面试","_id":"clg0k2asm00jjt26fzlwjusb1"}],"Data":[],"Page":[],"Post":[{"layout":"post","title":"数据库和TXT文件内容的交换","date":"2016-07-06T16:00:00.000Z","excerpt":"","project":true,"comments":1,"_content":"\n\n\n### 前言\n\n今天做了一个简单的实验，通过这次试验来练习IO流，数据库连接，SQL等知识。下面是详细信息。\n\n### 项目结构\n\n<img src=\"/assets/img/flant.png\">\n\n\n\n\n### 代码\n\n#### bean.Content\n\n```\n\npackage bean;\npublic class Content {\n\tprivate int id;\n\tprivate String content;\n\tpublic Content(int id,String content){\n\t\tthis.id=id;\n\t\tthis.content=content;\n\t}\t\n\tpublic void setId(int id){\n\t\tthis.id=id;\n\t}\n\tpublic int getId(){\n\t\treturn id;\n\t}\n\tpublic void setContent(String content){\n\t\tthis.content=content;\n\t}\n\tpublic String getContent(){\n\t\treturn content;\n\t}\n\tpublic String toString(){\t\n\t\treturn id+\",\"+content;\t\n\t}\t\n}\n\n\n```\n\n#### bean.Student\n\n```\n\npackage bean;\n\npublic class Student {\n\tprivate int id;\n\tprivate String name;\n\tprivate String sex;\n\tprivate int age;\n\tpublic Student(int id,String name,String sex,int age){\n\t\tthis.id=id;\n\t\tthis.name=name;\n\t\tthis.sex=sex;\n\t\tthis.age=age;\n\t}\t\n\tpublic void setId(int id) {\n\t\tthis.id = id;\n\t}\n\tpublic int getId() {\n\t\treturn id;\n\t}\n\tpublic void setName(String name) {\n\t\tthis.name = name;\n\t}\n\tpublic String getName() {\n\t\treturn name;\n\t}\n\tpublic void setSex(String sex) {\n\t\tthis.sex = sex;\n\t}\n\tpublic String getSex() {\n\t\treturn sex;\n\t}\n\tpublic void setAge(int age) {\n\t\tthis.age = age;\n\t}\n\tpublic int getAge() {\n\t\treturn age;\n\t}\n}\n\n\n```\n\n#### dao.ContentDao\n\n```\npackage dao;\n\nimport java.sql.PreparedStatement;\nimport java.sql.ResultSet;\nimport java.sql.SQLException;\nimport java.util.ArrayList;\nimport java.util.List;\n\nimport bean.Content;\nimport utils.DBUtil;\npublic class ContentDao {\t\n\tDBUtil db=new DBUtil();\n\tPreparedStatement pre=null;\n\tResultSet re=null;\t\n\tpublic List<Content> getInfoFromDB(){\n\t\tdb.getConnection();\n\t\tList<Content> list= new ArrayList<Content>();\n\t\tString sql=\"select * from content;\";\n\t\ttry {\n\t\t\tpre=db.getCon().prepareStatement(sql);\n\t\t} catch (SQLException e1) {\n\t\t\t// TODO Auto-generated catch block\n\t\t\te1.printStackTrace();\n\t\t}\n\t\ttry {\n\t\t\tre=pre.executeQuery();\n\t\t} catch (SQLException e) {\n\t\t\t// TODO Auto-generated catch block\n\t\t\te.printStackTrace();\n\t\t}\n\t\ttry {\n\t\t\twhile(re.next()){\n\t\t\t\tlist.add(new Content(re.getInt(1),re.getString(2)));\n\t\t\t}\n\t\t} catch (SQLException e) {\n\t\t\t// TODO Auto-generated catch block\n\t\t\te.printStackTrace();\n\t\t}\n\t\treturn list;\n\t}\n}\n\n```\n\n#### dao.Student\n\n```\n\npackage dao;\n\nimport java.sql.SQLException;\nimport java.util.List;\nimport java.sql.PreparedStatement;\nimport bean.Student;\nimport utils.DBUtil;\npublic class StudentDao {\t\n\tDBUtil db=new DBUtil();\n\tPreparedStatement pre=null;\t\n\tpublic void senttoDB(List<Student> list){\n\t\tdb.getConnection();\n\t\tfor(Student st:list){\n\t\t\tString sql=\"insert into Student values(?,?,?,?)\";\n\t\t\ttry {\t\t\t\t\n\t\t\t\tpre=db.getCon().prepareStatement(sql);\n\t\t\t\tpre.setInt(1, st.getId());\n\t\t\t\tpre.setString(2, st.getName());\n\t\t\t\tpre.setString(3, st.getSex());\n\t\t\t\tpre.setInt(4, st.getAge());\t\t\t\t\t\t\n\t\t\t\tpre.executeUpdate();\t\t\n\t\t\t} catch (SQLException e) {\n\t\t\t\t// TODO Auto-generated catch block\n\t\t\t\te.printStackTrace();\n\t\t\t}finally{\t\t\t\t\t\t\t\t\t\t\n\t\t\t}\n\t\t}\n\t\tdb.closeConnection(pre,null);\n\t}\n}\n\n```\n\n#### test.Test\n\n```\n\npackage test;\n\nimport java.io.BufferedReader;\nimport java.io.BufferedWriter;\nimport java.io.File;\nimport java.io.FileReader;\nimport java.io.FileWriter;\nimport java.io.IOException;\nimport java.util.ArrayList;\nimport java.util.List;\n\nimport bean.Content;\nimport bean.Student;\nimport dao.ContentDao;\nimport dao.StudentDao;\n\npublic class Test {\n\tpublic static void main(String[]args){\n\t\t\n//\t\treadFromFile();\n\t\twritetoFile();\t\t\t\t\n\t}\n\tpublic static void readFromFile(){\n\t\tStudentDao stuDao=new StudentDao();\n\t\tString line;\n\t\tList<Student> list =new ArrayList<Student>();\t\t\n\t\tFile file=new File(\"files/read.txt\");\t\t\n\t\ttry {\n\t\t\tFileReader in=new FileReader(file);\n\t\t\tBufferedReader read=new BufferedReader(in);\n\t\t\twhile((line=read.readLine())!=null){\n\t\t\t\tString l[] =line.split(\",\");\n\t\t\t\t\n//\t\t\t\tSystem.out.println(line);\n\t\t\t\tlist.add(new Student(Integer.parseInt(l[0]),l[1],l[2],Integer.parseInt(l[3])));\n\t\t\t\t\n//\t\t\t\tread.readLine();\n\t\t\t}\n\t\t\tstuDao.senttoDB(list);\n\t\t\tread.close();\n\t\t\tin.close();\t\t\t\n\t\t} catch (IOException e) {\n\t\t\tSystem.out.println(\"not found this file\");\n\t\t\te.printStackTrace();\n\t\t}\t\t\t\t\t\n\t}\t\n\tpublic static void writetoFile(){\t\t\n\t\tContentDao contDao=new ContentDao();\n\t\tFile file=new File(\"files/write.txt\");\n\t\ttry {\n\t\t\tBufferedWriter out=new BufferedWriter(new FileWriter(file));\n//\t\t\tList <Content> list=new ArrayList<Content>();\n//\t\t\tlist=contDao.getInfoFromDB();\t\t\t\n\t\t\tfor(Content cont:contDao.getInfoFromDB()){\n\t\t\t\tSystem.out.print(cont.toString());\n\t\t\t\tout.write(cont.toString());\n\t\t\t\tout.newLine();\n\t\t\t\tout.flush();\n\t\t\t}\n\t\t\tout.close();\t\t\t\t\t\t\t\t\t\t\t\n\t\t} catch (IOException e) {\n\t\t\t// TODO Auto-generated catch block\n\t\t\te.printStackTrace();\n\t\t}\t\t\t\t\t\t\n\t}\n\t\n\t\n\t\n}\n\n```\n\n#### utils.DBUtil\n\n```\n\npackage utils;\n\nimport java.sql.Connection;\nimport java.sql.DriverManager;\nimport java.sql.PreparedStatement;\nimport java.sql.ResultSet;\nimport java.sql.SQLException;\n\npublic class DBUtil {\t\n\tprivate Connection con=null;\t\n\tpublic Connection getCon() {\n\t\treturn con;\n\t}\t\n\tpublic void getConnection(){\t\t\t\t\t\t\n\t\ttry {\n\t\t\tClass.forName(\"com.mysql.jdbc.Driver\");\n\t\t\tcon=DriverManager.getConnection(\"jdbc:mysql://localhost:3306/db_test\",\"root\",\"root\");\n//\t\t\tString sql=\"insert into \";\n//\t\t\tpre=con.prepareStatement(sql);\t\t\t\t\t\t\t\t\t\n\t\t} catch (ClassNotFoundException | SQLException e) {\n\t\t\t// TODO Auto-generated catch block\n\t\t\te.printStackTrace();\n\t\t}\t\t\t\t\t\n\t}\n\tpublic void closeConnection(PreparedStatement pre,ResultSet re){\t\t\n\t\tif(re!=null){\n\t\t\ttry {\n\t\t\t\tre.close();\n\t\t\t} catch (SQLException e) {\n\t\t\t\t// TODO Auto-generated catch block\n\t\t\t\te.printStackTrace();\n\t\t\t}\n\t\t}\n\t\tif(pre!=null){\n\t\t\ttry {\n\t\t\t\tpre.close();\n\t\t\t} catch (SQLException e) {\n\t\t\t\t// TODO Auto-generated catch block\n\t\t\t\te.printStackTrace();\n\t\t\t}\n\t\t}\n\t\tif(con!=null){\n\t\t\ttry {\n\t\t\t\tcon.close();\n\t\t\t} catch (SQLException e) {\n\t\t\t\t// TODO Auto-generated catch block\n\t\t\t\te.printStackTrace();\n\t\t\t}\n\t\t}\n\t}\n}\n\n```\n\n### 总结\n\n通过这次试验，让我熟练了IO和数据库的一些知识，但是并不扎实，课余时间还要多练\n\n\n\n","source":"_posts/2016-05-20-kongzheng1993-DB_Exchange.md","raw":"---\nlayout: post\ntitle:  \"数据库和TXT文件内容的交换\"\ndate:   2016-07-07\nexcerpt: \"IO&数据库练习\"\nproject: true\ntag:\n- oop\ncomments: true\n---\n\n\n\n### 前言\n\n今天做了一个简单的实验，通过这次试验来练习IO流，数据库连接，SQL等知识。下面是详细信息。\n\n### 项目结构\n\n<img src=\"/assets/img/flant.png\">\n\n\n\n\n### 代码\n\n#### bean.Content\n\n```\n\npackage bean;\npublic class Content {\n\tprivate int id;\n\tprivate String content;\n\tpublic Content(int id,String content){\n\t\tthis.id=id;\n\t\tthis.content=content;\n\t}\t\n\tpublic void setId(int id){\n\t\tthis.id=id;\n\t}\n\tpublic int getId(){\n\t\treturn id;\n\t}\n\tpublic void setContent(String content){\n\t\tthis.content=content;\n\t}\n\tpublic String getContent(){\n\t\treturn content;\n\t}\n\tpublic String toString(){\t\n\t\treturn id+\",\"+content;\t\n\t}\t\n}\n\n\n```\n\n#### bean.Student\n\n```\n\npackage bean;\n\npublic class Student {\n\tprivate int id;\n\tprivate String name;\n\tprivate String sex;\n\tprivate int age;\n\tpublic Student(int id,String name,String sex,int age){\n\t\tthis.id=id;\n\t\tthis.name=name;\n\t\tthis.sex=sex;\n\t\tthis.age=age;\n\t}\t\n\tpublic void setId(int id) {\n\t\tthis.id = id;\n\t}\n\tpublic int getId() {\n\t\treturn id;\n\t}\n\tpublic void setName(String name) {\n\t\tthis.name = name;\n\t}\n\tpublic String getName() {\n\t\treturn name;\n\t}\n\tpublic void setSex(String sex) {\n\t\tthis.sex = sex;\n\t}\n\tpublic String getSex() {\n\t\treturn sex;\n\t}\n\tpublic void setAge(int age) {\n\t\tthis.age = age;\n\t}\n\tpublic int getAge() {\n\t\treturn age;\n\t}\n}\n\n\n```\n\n#### dao.ContentDao\n\n```\npackage dao;\n\nimport java.sql.PreparedStatement;\nimport java.sql.ResultSet;\nimport java.sql.SQLException;\nimport java.util.ArrayList;\nimport java.util.List;\n\nimport bean.Content;\nimport utils.DBUtil;\npublic class ContentDao {\t\n\tDBUtil db=new DBUtil();\n\tPreparedStatement pre=null;\n\tResultSet re=null;\t\n\tpublic List<Content> getInfoFromDB(){\n\t\tdb.getConnection();\n\t\tList<Content> list= new ArrayList<Content>();\n\t\tString sql=\"select * from content;\";\n\t\ttry {\n\t\t\tpre=db.getCon().prepareStatement(sql);\n\t\t} catch (SQLException e1) {\n\t\t\t// TODO Auto-generated catch block\n\t\t\te1.printStackTrace();\n\t\t}\n\t\ttry {\n\t\t\tre=pre.executeQuery();\n\t\t} catch (SQLException e) {\n\t\t\t// TODO Auto-generated catch block\n\t\t\te.printStackTrace();\n\t\t}\n\t\ttry {\n\t\t\twhile(re.next()){\n\t\t\t\tlist.add(new Content(re.getInt(1),re.getString(2)));\n\t\t\t}\n\t\t} catch (SQLException e) {\n\t\t\t// TODO Auto-generated catch block\n\t\t\te.printStackTrace();\n\t\t}\n\t\treturn list;\n\t}\n}\n\n```\n\n#### dao.Student\n\n```\n\npackage dao;\n\nimport java.sql.SQLException;\nimport java.util.List;\nimport java.sql.PreparedStatement;\nimport bean.Student;\nimport utils.DBUtil;\npublic class StudentDao {\t\n\tDBUtil db=new DBUtil();\n\tPreparedStatement pre=null;\t\n\tpublic void senttoDB(List<Student> list){\n\t\tdb.getConnection();\n\t\tfor(Student st:list){\n\t\t\tString sql=\"insert into Student values(?,?,?,?)\";\n\t\t\ttry {\t\t\t\t\n\t\t\t\tpre=db.getCon().prepareStatement(sql);\n\t\t\t\tpre.setInt(1, st.getId());\n\t\t\t\tpre.setString(2, st.getName());\n\t\t\t\tpre.setString(3, st.getSex());\n\t\t\t\tpre.setInt(4, st.getAge());\t\t\t\t\t\t\n\t\t\t\tpre.executeUpdate();\t\t\n\t\t\t} catch (SQLException e) {\n\t\t\t\t// TODO Auto-generated catch block\n\t\t\t\te.printStackTrace();\n\t\t\t}finally{\t\t\t\t\t\t\t\t\t\t\n\t\t\t}\n\t\t}\n\t\tdb.closeConnection(pre,null);\n\t}\n}\n\n```\n\n#### test.Test\n\n```\n\npackage test;\n\nimport java.io.BufferedReader;\nimport java.io.BufferedWriter;\nimport java.io.File;\nimport java.io.FileReader;\nimport java.io.FileWriter;\nimport java.io.IOException;\nimport java.util.ArrayList;\nimport java.util.List;\n\nimport bean.Content;\nimport bean.Student;\nimport dao.ContentDao;\nimport dao.StudentDao;\n\npublic class Test {\n\tpublic static void main(String[]args){\n\t\t\n//\t\treadFromFile();\n\t\twritetoFile();\t\t\t\t\n\t}\n\tpublic static void readFromFile(){\n\t\tStudentDao stuDao=new StudentDao();\n\t\tString line;\n\t\tList<Student> list =new ArrayList<Student>();\t\t\n\t\tFile file=new File(\"files/read.txt\");\t\t\n\t\ttry {\n\t\t\tFileReader in=new FileReader(file);\n\t\t\tBufferedReader read=new BufferedReader(in);\n\t\t\twhile((line=read.readLine())!=null){\n\t\t\t\tString l[] =line.split(\",\");\n\t\t\t\t\n//\t\t\t\tSystem.out.println(line);\n\t\t\t\tlist.add(new Student(Integer.parseInt(l[0]),l[1],l[2],Integer.parseInt(l[3])));\n\t\t\t\t\n//\t\t\t\tread.readLine();\n\t\t\t}\n\t\t\tstuDao.senttoDB(list);\n\t\t\tread.close();\n\t\t\tin.close();\t\t\t\n\t\t} catch (IOException e) {\n\t\t\tSystem.out.println(\"not found this file\");\n\t\t\te.printStackTrace();\n\t\t}\t\t\t\t\t\n\t}\t\n\tpublic static void writetoFile(){\t\t\n\t\tContentDao contDao=new ContentDao();\n\t\tFile file=new File(\"files/write.txt\");\n\t\ttry {\n\t\t\tBufferedWriter out=new BufferedWriter(new FileWriter(file));\n//\t\t\tList <Content> list=new ArrayList<Content>();\n//\t\t\tlist=contDao.getInfoFromDB();\t\t\t\n\t\t\tfor(Content cont:contDao.getInfoFromDB()){\n\t\t\t\tSystem.out.print(cont.toString());\n\t\t\t\tout.write(cont.toString());\n\t\t\t\tout.newLine();\n\t\t\t\tout.flush();\n\t\t\t}\n\t\t\tout.close();\t\t\t\t\t\t\t\t\t\t\t\n\t\t} catch (IOException e) {\n\t\t\t// TODO Auto-generated catch block\n\t\t\te.printStackTrace();\n\t\t}\t\t\t\t\t\t\n\t}\n\t\n\t\n\t\n}\n\n```\n\n#### utils.DBUtil\n\n```\n\npackage utils;\n\nimport java.sql.Connection;\nimport java.sql.DriverManager;\nimport java.sql.PreparedStatement;\nimport java.sql.ResultSet;\nimport java.sql.SQLException;\n\npublic class DBUtil {\t\n\tprivate Connection con=null;\t\n\tpublic Connection getCon() {\n\t\treturn con;\n\t}\t\n\tpublic void getConnection(){\t\t\t\t\t\t\n\t\ttry {\n\t\t\tClass.forName(\"com.mysql.jdbc.Driver\");\n\t\t\tcon=DriverManager.getConnection(\"jdbc:mysql://localhost:3306/db_test\",\"root\",\"root\");\n//\t\t\tString sql=\"insert into \";\n//\t\t\tpre=con.prepareStatement(sql);\t\t\t\t\t\t\t\t\t\n\t\t} catch (ClassNotFoundException | SQLException e) {\n\t\t\t// TODO Auto-generated catch block\n\t\t\te.printStackTrace();\n\t\t}\t\t\t\t\t\n\t}\n\tpublic void closeConnection(PreparedStatement pre,ResultSet re){\t\t\n\t\tif(re!=null){\n\t\t\ttry {\n\t\t\t\tre.close();\n\t\t\t} catch (SQLException e) {\n\t\t\t\t// TODO Auto-generated catch block\n\t\t\t\te.printStackTrace();\n\t\t\t}\n\t\t}\n\t\tif(pre!=null){\n\t\t\ttry {\n\t\t\t\tpre.close();\n\t\t\t} catch (SQLException e) {\n\t\t\t\t// TODO Auto-generated catch block\n\t\t\t\te.printStackTrace();\n\t\t\t}\n\t\t}\n\t\tif(con!=null){\n\t\t\ttry {\n\t\t\t\tcon.close();\n\t\t\t} catch (SQLException e) {\n\t\t\t\t// TODO Auto-generated catch block\n\t\t\t\te.printStackTrace();\n\t\t\t}\n\t\t}\n\t}\n}\n\n```\n\n### 总结\n\n通过这次试验，让我熟练了IO和数据库的一些知识，但是并不扎实，课余时间还要多练\n\n\n\n","slug":"kongzheng1993-DB_Exchange","published":1,"updated":"2023-03-08T07:05:58.769Z","photos":[],"link":"","_id":"clg0k2a8h0000t26f9smaxe1z","content":"<h3 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h3><p>今天做了一个简单的实验，通过这次试验来练习IO流，数据库连接，SQL等知识。下面是详细信息。</p>\n<h3 id=\"项目结构\"><a href=\"#项目结构\" class=\"headerlink\" title=\"项目结构\"></a>项目结构</h3><img src=\"/2016/07/07/kongzheng1993-DB_Exchange/assets/img/flant.png\">\n\n\n\n\n<h3 id=\"代码\"><a href=\"#代码\" class=\"headerlink\" title=\"代码\"></a>代码</h3><h4 id=\"bean-Content\"><a href=\"#bean-Content\" class=\"headerlink\" title=\"bean.Content\"></a>bean.Content</h4><pre><code>\npackage bean;\npublic class Content {\n    private int id;\n    private String content;\n    public Content(int id,String content){\n        this.id=id;\n        this.content=content;\n    }    \n    public void setId(int id){\n        this.id=id;\n    }\n    public int getId(){\n        return id;\n    }\n    public void setContent(String content){\n        this.content=content;\n    }\n    public String getContent(){\n        return content;\n    }\n    public String toString(){    \n        return id+&quot;,&quot;+content;    \n    }    \n}\n\n</code></pre><h4 id=\"bean-Student\"><a href=\"#bean-Student\" class=\"headerlink\" title=\"bean.Student\"></a>bean.Student</h4><pre><code>\npackage bean;\n\npublic class Student {\n    private int id;\n    private String name;\n    private String sex;\n    private int age;\n    public Student(int id,String name,String sex,int age){\n        this.id=id;\n        this.name=name;\n        this.sex=sex;\n        this.age=age;\n    }    \n    public void setId(int id) {\n        this.id = id;\n    }\n    public int getId() {\n        return id;\n    }\n    public void setName(String name) {\n        this.name = name;\n    }\n    public String getName() {\n        return name;\n    }\n    public void setSex(String sex) {\n        this.sex = sex;\n    }\n    public String getSex() {\n        return sex;\n    }\n    public void setAge(int age) {\n        this.age = age;\n    }\n    public int getAge() {\n        return age;\n    }\n}\n\n</code></pre><h4 id=\"dao-ContentDao\"><a href=\"#dao-ContentDao\" class=\"headerlink\" title=\"dao.ContentDao\"></a>dao.ContentDao</h4><pre><code>package dao;\n\nimport java.sql.PreparedStatement;\nimport java.sql.ResultSet;\nimport java.sql.SQLException;\nimport java.util.ArrayList;\nimport java.util.List;\n\nimport bean.Content;\nimport utils.DBUtil;\npublic class ContentDao {    \n    DBUtil db=new DBUtil();\n    PreparedStatement pre=null;\n    ResultSet re=null;    \n    public List&lt;Content&gt; getInfoFromDB(){\n        db.getConnection();\n        List&lt;Content&gt; list= new ArrayList&lt;Content&gt;();\n        String sql=&quot;select * from content;&quot;;\n        try {\n            pre=db.getCon().prepareStatement(sql);\n        } catch (SQLException e1) {\n            // TODO Auto-generated catch block\n            e1.printStackTrace();\n        }\n        try {\n            re=pre.executeQuery();\n        } catch (SQLException e) {\n            // TODO Auto-generated catch block\n            e.printStackTrace();\n        }\n        try {\n            while(re.next()){\n                list.add(new Content(re.getInt(1),re.getString(2)));\n            }\n        } catch (SQLException e) {\n            // TODO Auto-generated catch block\n            e.printStackTrace();\n        }\n        return list;\n    }\n}\n</code></pre><h4 id=\"dao-Student\"><a href=\"#dao-Student\" class=\"headerlink\" title=\"dao.Student\"></a>dao.Student</h4><pre><code>\npackage dao;\n\nimport java.sql.SQLException;\nimport java.util.List;\nimport java.sql.PreparedStatement;\nimport bean.Student;\nimport utils.DBUtil;\npublic class StudentDao {    \n    DBUtil db=new DBUtil();\n    PreparedStatement pre=null;    \n    public void senttoDB(List&lt;Student&gt; list){\n        db.getConnection();\n        for(Student st:list){\n            String sql=&quot;insert into Student values(?,?,?,?)&quot;;\n            try {                \n                pre=db.getCon().prepareStatement(sql);\n                pre.setInt(1, st.getId());\n                pre.setString(2, st.getName());\n                pre.setString(3, st.getSex());\n                pre.setInt(4, st.getAge());                        \n                pre.executeUpdate();        \n            } catch (SQLException e) {\n                // TODO Auto-generated catch block\n                e.printStackTrace();\n            }finally{                                        \n            }\n        }\n        db.closeConnection(pre,null);\n    }\n}\n</code></pre><h4 id=\"test-Test\"><a href=\"#test-Test\" class=\"headerlink\" title=\"test.Test\"></a>test.Test</h4><pre><code>\npackage test;\n\nimport java.io.BufferedReader;\nimport java.io.BufferedWriter;\nimport java.io.File;\nimport java.io.FileReader;\nimport java.io.FileWriter;\nimport java.io.IOException;\nimport java.util.ArrayList;\nimport java.util.List;\n\nimport bean.Content;\nimport bean.Student;\nimport dao.ContentDao;\nimport dao.StudentDao;\n\npublic class Test {\n    public static void main(String[]args){\n\n//        readFromFile();\n        writetoFile();                \n    }\n    public static void readFromFile(){\n        StudentDao stuDao=new StudentDao();\n        String line;\n        List&lt;Student&gt; list =new ArrayList&lt;Student&gt;();        \n        File file=new File(&quot;files/read.txt&quot;);        \n        try {\n            FileReader in=new FileReader(file);\n            BufferedReader read=new BufferedReader(in);\n            while((line=read.readLine())!=null){\n                String l[] =line.split(&quot;,&quot;);\n\n//                System.out.println(line);\n                list.add(new Student(Integer.parseInt(l[0]),l[1],l[2],Integer.parseInt(l[3])));\n\n//                read.readLine();\n            }\n            stuDao.senttoDB(list);\n            read.close();\n            in.close();            \n        } catch (IOException e) {\n            System.out.println(&quot;not found this file&quot;);\n            e.printStackTrace();\n        }                    \n    }    \n    public static void writetoFile(){        \n        ContentDao contDao=new ContentDao();\n        File file=new File(&quot;files/write.txt&quot;);\n        try {\n            BufferedWriter out=new BufferedWriter(new FileWriter(file));\n//            List &lt;Content&gt; list=new ArrayList&lt;Content&gt;();\n//            list=contDao.getInfoFromDB();            \n            for(Content cont:contDao.getInfoFromDB()){\n                System.out.print(cont.toString());\n                out.write(cont.toString());\n                out.newLine();\n                out.flush();\n            }\n            out.close();                                            \n        } catch (IOException e) {\n            // TODO Auto-generated catch block\n            e.printStackTrace();\n        }                        \n    }\n\n\n\n}\n</code></pre><h4 id=\"utils-DBUtil\"><a href=\"#utils-DBUtil\" class=\"headerlink\" title=\"utils.DBUtil\"></a>utils.DBUtil</h4><pre><code>\npackage utils;\n\nimport java.sql.Connection;\nimport java.sql.DriverManager;\nimport java.sql.PreparedStatement;\nimport java.sql.ResultSet;\nimport java.sql.SQLException;\n\npublic class DBUtil {    \n    private Connection con=null;    \n    public Connection getCon() {\n        return con;\n    }    \n    public void getConnection(){                        \n        try {\n            Class.forName(&quot;com.mysql.jdbc.Driver&quot;);\n            con=DriverManager.getConnection(&quot;jdbc:mysql://localhost:3306/db_test&quot;,&quot;root&quot;,&quot;root&quot;);\n//            String sql=&quot;insert into &quot;;\n//            pre=con.prepareStatement(sql);                                    \n        } catch (ClassNotFoundException | SQLException e) {\n            // TODO Auto-generated catch block\n            e.printStackTrace();\n        }                    \n    }\n    public void closeConnection(PreparedStatement pre,ResultSet re){        \n        if(re!=null){\n            try {\n                re.close();\n            } catch (SQLException e) {\n                // TODO Auto-generated catch block\n                e.printStackTrace();\n            }\n        }\n        if(pre!=null){\n            try {\n                pre.close();\n            } catch (SQLException e) {\n                // TODO Auto-generated catch block\n                e.printStackTrace();\n            }\n        }\n        if(con!=null){\n            try {\n                con.close();\n            } catch (SQLException e) {\n                // TODO Auto-generated catch block\n                e.printStackTrace();\n            }\n        }\n    }\n}\n</code></pre><h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3><p>通过这次试验，让我熟练了IO和数据库的一些知识，但是并不扎实，课余时间还要多练</p>\n","site":{"data":{}},"more":"<h3 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h3><p>今天做了一个简单的实验，通过这次试验来练习IO流，数据库连接，SQL等知识。下面是详细信息。</p>\n<h3 id=\"项目结构\"><a href=\"#项目结构\" class=\"headerlink\" title=\"项目结构\"></a>项目结构</h3><img src=\"/2016/07/07/kongzheng1993-DB_Exchange/assets/img/flant.png\">\n\n\n\n\n<h3 id=\"代码\"><a href=\"#代码\" class=\"headerlink\" title=\"代码\"></a>代码</h3><h4 id=\"bean-Content\"><a href=\"#bean-Content\" class=\"headerlink\" title=\"bean.Content\"></a>bean.Content</h4><pre><code>\npackage bean;\npublic class Content {\n    private int id;\n    private String content;\n    public Content(int id,String content){\n        this.id=id;\n        this.content=content;\n    }    \n    public void setId(int id){\n        this.id=id;\n    }\n    public int getId(){\n        return id;\n    }\n    public void setContent(String content){\n        this.content=content;\n    }\n    public String getContent(){\n        return content;\n    }\n    public String toString(){    \n        return id+&quot;,&quot;+content;    \n    }    \n}\n\n</code></pre><h4 id=\"bean-Student\"><a href=\"#bean-Student\" class=\"headerlink\" title=\"bean.Student\"></a>bean.Student</h4><pre><code>\npackage bean;\n\npublic class Student {\n    private int id;\n    private String name;\n    private String sex;\n    private int age;\n    public Student(int id,String name,String sex,int age){\n        this.id=id;\n        this.name=name;\n        this.sex=sex;\n        this.age=age;\n    }    \n    public void setId(int id) {\n        this.id = id;\n    }\n    public int getId() {\n        return id;\n    }\n    public void setName(String name) {\n        this.name = name;\n    }\n    public String getName() {\n        return name;\n    }\n    public void setSex(String sex) {\n        this.sex = sex;\n    }\n    public String getSex() {\n        return sex;\n    }\n    public void setAge(int age) {\n        this.age = age;\n    }\n    public int getAge() {\n        return age;\n    }\n}\n\n</code></pre><h4 id=\"dao-ContentDao\"><a href=\"#dao-ContentDao\" class=\"headerlink\" title=\"dao.ContentDao\"></a>dao.ContentDao</h4><pre><code>package dao;\n\nimport java.sql.PreparedStatement;\nimport java.sql.ResultSet;\nimport java.sql.SQLException;\nimport java.util.ArrayList;\nimport java.util.List;\n\nimport bean.Content;\nimport utils.DBUtil;\npublic class ContentDao {    \n    DBUtil db=new DBUtil();\n    PreparedStatement pre=null;\n    ResultSet re=null;    \n    public List&lt;Content&gt; getInfoFromDB(){\n        db.getConnection();\n        List&lt;Content&gt; list= new ArrayList&lt;Content&gt;();\n        String sql=&quot;select * from content;&quot;;\n        try {\n            pre=db.getCon().prepareStatement(sql);\n        } catch (SQLException e1) {\n            // TODO Auto-generated catch block\n            e1.printStackTrace();\n        }\n        try {\n            re=pre.executeQuery();\n        } catch (SQLException e) {\n            // TODO Auto-generated catch block\n            e.printStackTrace();\n        }\n        try {\n            while(re.next()){\n                list.add(new Content(re.getInt(1),re.getString(2)));\n            }\n        } catch (SQLException e) {\n            // TODO Auto-generated catch block\n            e.printStackTrace();\n        }\n        return list;\n    }\n}\n</code></pre><h4 id=\"dao-Student\"><a href=\"#dao-Student\" class=\"headerlink\" title=\"dao.Student\"></a>dao.Student</h4><pre><code>\npackage dao;\n\nimport java.sql.SQLException;\nimport java.util.List;\nimport java.sql.PreparedStatement;\nimport bean.Student;\nimport utils.DBUtil;\npublic class StudentDao {    \n    DBUtil db=new DBUtil();\n    PreparedStatement pre=null;    \n    public void senttoDB(List&lt;Student&gt; list){\n        db.getConnection();\n        for(Student st:list){\n            String sql=&quot;insert into Student values(?,?,?,?)&quot;;\n            try {                \n                pre=db.getCon().prepareStatement(sql);\n                pre.setInt(1, st.getId());\n                pre.setString(2, st.getName());\n                pre.setString(3, st.getSex());\n                pre.setInt(4, st.getAge());                        \n                pre.executeUpdate();        \n            } catch (SQLException e) {\n                // TODO Auto-generated catch block\n                e.printStackTrace();\n            }finally{                                        \n            }\n        }\n        db.closeConnection(pre,null);\n    }\n}\n</code></pre><h4 id=\"test-Test\"><a href=\"#test-Test\" class=\"headerlink\" title=\"test.Test\"></a>test.Test</h4><pre><code>\npackage test;\n\nimport java.io.BufferedReader;\nimport java.io.BufferedWriter;\nimport java.io.File;\nimport java.io.FileReader;\nimport java.io.FileWriter;\nimport java.io.IOException;\nimport java.util.ArrayList;\nimport java.util.List;\n\nimport bean.Content;\nimport bean.Student;\nimport dao.ContentDao;\nimport dao.StudentDao;\n\npublic class Test {\n    public static void main(String[]args){\n\n//        readFromFile();\n        writetoFile();                \n    }\n    public static void readFromFile(){\n        StudentDao stuDao=new StudentDao();\n        String line;\n        List&lt;Student&gt; list =new ArrayList&lt;Student&gt;();        \n        File file=new File(&quot;files/read.txt&quot;);        \n        try {\n            FileReader in=new FileReader(file);\n            BufferedReader read=new BufferedReader(in);\n            while((line=read.readLine())!=null){\n                String l[] =line.split(&quot;,&quot;);\n\n//                System.out.println(line);\n                list.add(new Student(Integer.parseInt(l[0]),l[1],l[2],Integer.parseInt(l[3])));\n\n//                read.readLine();\n            }\n            stuDao.senttoDB(list);\n            read.close();\n            in.close();            \n        } catch (IOException e) {\n            System.out.println(&quot;not found this file&quot;);\n            e.printStackTrace();\n        }                    \n    }    \n    public static void writetoFile(){        \n        ContentDao contDao=new ContentDao();\n        File file=new File(&quot;files/write.txt&quot;);\n        try {\n            BufferedWriter out=new BufferedWriter(new FileWriter(file));\n//            List &lt;Content&gt; list=new ArrayList&lt;Content&gt;();\n//            list=contDao.getInfoFromDB();            \n            for(Content cont:contDao.getInfoFromDB()){\n                System.out.print(cont.toString());\n                out.write(cont.toString());\n                out.newLine();\n                out.flush();\n            }\n            out.close();                                            \n        } catch (IOException e) {\n            // TODO Auto-generated catch block\n            e.printStackTrace();\n        }                        \n    }\n\n\n\n}\n</code></pre><h4 id=\"utils-DBUtil\"><a href=\"#utils-DBUtil\" class=\"headerlink\" title=\"utils.DBUtil\"></a>utils.DBUtil</h4><pre><code>\npackage utils;\n\nimport java.sql.Connection;\nimport java.sql.DriverManager;\nimport java.sql.PreparedStatement;\nimport java.sql.ResultSet;\nimport java.sql.SQLException;\n\npublic class DBUtil {    \n    private Connection con=null;    \n    public Connection getCon() {\n        return con;\n    }    \n    public void getConnection(){                        \n        try {\n            Class.forName(&quot;com.mysql.jdbc.Driver&quot;);\n            con=DriverManager.getConnection(&quot;jdbc:mysql://localhost:3306/db_test&quot;,&quot;root&quot;,&quot;root&quot;);\n//            String sql=&quot;insert into &quot;;\n//            pre=con.prepareStatement(sql);                                    \n        } catch (ClassNotFoundException | SQLException e) {\n            // TODO Auto-generated catch block\n            e.printStackTrace();\n        }                    \n    }\n    public void closeConnection(PreparedStatement pre,ResultSet re){        \n        if(re!=null){\n            try {\n                re.close();\n            } catch (SQLException e) {\n                // TODO Auto-generated catch block\n                e.printStackTrace();\n            }\n        }\n        if(pre!=null){\n            try {\n                pre.close();\n            } catch (SQLException e) {\n                // TODO Auto-generated catch block\n                e.printStackTrace();\n            }\n        }\n        if(con!=null){\n            try {\n                con.close();\n            } catch (SQLException e) {\n                // TODO Auto-generated catch block\n                e.printStackTrace();\n            }\n        }\n    }\n}\n</code></pre><h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3><p>通过这次试验，让我熟练了IO和数据库的一些知识，但是并不扎实，课余时间还要多练</p>\n"},{"layout":"post","title":"properties文件的使用","date":"2016-07-27T16:00:00.000Z","excerpt":"","comments":1,"_content":"\n\n## 简介\n\njava中的properties文件是一种配置文件，主要用于配置信息，文件类型为.properties，格式为文本文件，文件内容是“键=值”的格式，在properties文件中可以使用“#”来做注释，properties文件在Java编程中用到的地方很多，操作很方便。\n\n## Properties文件\n\nconfig.properties\n\n```\ndb_url=com.mysql.jdbc.Driver\ndb_mysql=jdbc:mysql\ndb_ip=127.0.0.1\ndb_port=3306\ndb_dbName=users\ndb_usn=root\ndb_pwd=root\n\n```\n\n## Properties类的方法\n\nProperites类存在Java.util中，该类继承自Hashtable\n\n1 getProperty ( String  key) ，   用指定的键在此属性列表中搜索属性。也就是通过参数 key ，得到 key 所对应的 value。\n2 load ( InputStream  inStream) ，从输入流中读取属性列表（键和元素对）。通过对指定的文件（比如说上面的 test.properties 文件）进行装载来获取该文\n\n件中的所有键 - 值对。以供 getProperty ( String  key) 来搜索。\n3 setProperty ( String  key, String  value) ，调用 Hashtable 的方法 put 。他通过调用基类的put方法来设置 键 - 值对。 \n4 store ( OutputStream  out, String  comments) ，   以适合使用 load 方法加载到 Properties 表中的格式，将此 Properties 表中的属性列表（键和元素\n\n对）写入输出流。与 load 方法相反，该方法将键 - 值对写入到指定的文件中去。\n5 clear () ，清除所有装载的 键 - 值对。该方法在基类中提供。\n\n## 在JAVA文件中操作properties文件的方法\n\n```\n\n        pr=new Properties();\n        inStream=this.getClass().getResourceAsStream(\"config.properties\");\n        InputStream inStream=DBUtil.class.getResourceAsStream(\"config.properties\");\n        try {\n            pr.load(inStream);\n            url=pr.getProperty(\"db_url\");\n            mysql=pr.getProperty(\"db_mysql\");\n            ip=pr.getProperty(\"db_ip\");\n            port=pr.getProperty(\"db_port\");\n            dbname=pr.getProperty(\"db_dbName\");\n            dbusn=pr.getProperty(\"db_usn\");\n            dbpwd=pr.getProperty(\"db_pwd\");\n        } catch (IOException e) {\n            // TODO Auto-generated catch block\n            e.printStackTrace();\n        }\n\n```\n\n## 总结\n\njava的properties文件需要放到classpath下面，这样程序才能读取到，有关classpath实际上就是java类或者库的存放路径，在java工程中，properties放到class文件一块。在web应用中，最简单的方法是放到web应用的WEB- INF\\classes目录下即可，也可以放在其他文件夹下面，这时候需要在设置classpath环境变量的时候，将这个文件夹路径加到 classpath变量中，这样也也可以读取到。在此，你需要对classpath有个深刻理解，classpath绝非系统中刻意设定的那个系统环境变量，WEB-INF\\classes其实也是，java工程的class文件目录也是。\n\n\n\n\n\n\n<html>\n<div class=\"ds-thread\" data-thread-key=\"http://kongzheng1993.github.io/kongzheng1993-properties/\" data-title=\"properties\" data-url=\"http://kongzheng1993.github.io/kongzheng1993-properties/\"></div>\n<script type=\"text/javascript\">\nvar duoshuoQuery = {short_name:\"kongzheng1993\"};\n\t(function() {\n\t\tvar ds = document.createElement('script');\n\t\tds.type = 'text/javascript';ds.async = true;\n\t\tds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';\n\t\tds.charset = 'UTF-8';\n\t\t(document.getElementsByTagName('head')[0] \n\t\t || document.getElementsByTagName('body')[0]).appendChild(ds);\n\t})();\n</script>\n</html>\n","source":"_posts/2016-05-20-kongzheng1993-Properties.md","raw":"---\nlayout: post\ntitle:  \"properties文件的使用\"\ndate:   2016-07-28\nexcerpt: \"properties\"\ntag:\n- oop\ncomments: true\n---\n\n\n## 简介\n\njava中的properties文件是一种配置文件，主要用于配置信息，文件类型为.properties，格式为文本文件，文件内容是“键=值”的格式，在properties文件中可以使用“#”来做注释，properties文件在Java编程中用到的地方很多，操作很方便。\n\n## Properties文件\n\nconfig.properties\n\n```\ndb_url=com.mysql.jdbc.Driver\ndb_mysql=jdbc:mysql\ndb_ip=127.0.0.1\ndb_port=3306\ndb_dbName=users\ndb_usn=root\ndb_pwd=root\n\n```\n\n## Properties类的方法\n\nProperites类存在Java.util中，该类继承自Hashtable\n\n1 getProperty ( String  key) ，   用指定的键在此属性列表中搜索属性。也就是通过参数 key ，得到 key 所对应的 value。\n2 load ( InputStream  inStream) ，从输入流中读取属性列表（键和元素对）。通过对指定的文件（比如说上面的 test.properties 文件）进行装载来获取该文\n\n件中的所有键 - 值对。以供 getProperty ( String  key) 来搜索。\n3 setProperty ( String  key, String  value) ，调用 Hashtable 的方法 put 。他通过调用基类的put方法来设置 键 - 值对。 \n4 store ( OutputStream  out, String  comments) ，   以适合使用 load 方法加载到 Properties 表中的格式，将此 Properties 表中的属性列表（键和元素\n\n对）写入输出流。与 load 方法相反，该方法将键 - 值对写入到指定的文件中去。\n5 clear () ，清除所有装载的 键 - 值对。该方法在基类中提供。\n\n## 在JAVA文件中操作properties文件的方法\n\n```\n\n        pr=new Properties();\n        inStream=this.getClass().getResourceAsStream(\"config.properties\");\n        InputStream inStream=DBUtil.class.getResourceAsStream(\"config.properties\");\n        try {\n            pr.load(inStream);\n            url=pr.getProperty(\"db_url\");\n            mysql=pr.getProperty(\"db_mysql\");\n            ip=pr.getProperty(\"db_ip\");\n            port=pr.getProperty(\"db_port\");\n            dbname=pr.getProperty(\"db_dbName\");\n            dbusn=pr.getProperty(\"db_usn\");\n            dbpwd=pr.getProperty(\"db_pwd\");\n        } catch (IOException e) {\n            // TODO Auto-generated catch block\n            e.printStackTrace();\n        }\n\n```\n\n## 总结\n\njava的properties文件需要放到classpath下面，这样程序才能读取到，有关classpath实际上就是java类或者库的存放路径，在java工程中，properties放到class文件一块。在web应用中，最简单的方法是放到web应用的WEB- INF\\classes目录下即可，也可以放在其他文件夹下面，这时候需要在设置classpath环境变量的时候，将这个文件夹路径加到 classpath变量中，这样也也可以读取到。在此，你需要对classpath有个深刻理解，classpath绝非系统中刻意设定的那个系统环境变量，WEB-INF\\classes其实也是，java工程的class文件目录也是。\n\n\n\n\n\n\n<html>\n<div class=\"ds-thread\" data-thread-key=\"http://kongzheng1993.github.io/kongzheng1993-properties/\" data-title=\"properties\" data-url=\"http://kongzheng1993.github.io/kongzheng1993-properties/\"></div>\n<script type=\"text/javascript\">\nvar duoshuoQuery = {short_name:\"kongzheng1993\"};\n\t(function() {\n\t\tvar ds = document.createElement('script');\n\t\tds.type = 'text/javascript';ds.async = true;\n\t\tds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';\n\t\tds.charset = 'UTF-8';\n\t\t(document.getElementsByTagName('head')[0] \n\t\t || document.getElementsByTagName('body')[0]).appendChild(ds);\n\t})();\n</script>\n</html>\n","slug":"kongzheng1993-Properties","published":1,"updated":"2023-03-08T07:05:58.769Z","photos":[],"link":"","_id":"clg0k2a9l0001t26fq3yke2gi","content":"<h2 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h2><p>java中的properties文件是一种配置文件，主要用于配置信息，文件类型为.properties，格式为文本文件，文件内容是“键=值”的格式，在properties文件中可以使用“#”来做注释，properties文件在Java编程中用到的地方很多，操作很方便。</p>\n<h2 id=\"Properties文件\"><a href=\"#Properties文件\" class=\"headerlink\" title=\"Properties文件\"></a>Properties文件</h2><p>config.properties</p>\n<pre><code>db_url=com.mysql.jdbc.Driver\ndb_mysql=jdbc:mysql\ndb_ip=127.0.0.1\ndb_port=3306\ndb_dbName=users\ndb_usn=root\ndb_pwd=root\n</code></pre><h2 id=\"Properties类的方法\"><a href=\"#Properties类的方法\" class=\"headerlink\" title=\"Properties类的方法\"></a>Properties类的方法</h2><p>Properites类存在Java.util中，该类继承自Hashtable</p>\n<p>1 getProperty ( String  key) ，   用指定的键在此属性列表中搜索属性。也就是通过参数 key ，得到 key 所对应的 value。<br>2 load ( InputStream  inStream) ，从输入流中读取属性列表（键和元素对）。通过对指定的文件（比如说上面的 test.properties 文件）进行装载来获取该文</p>\n<p>件中的所有键 - 值对。以供 getProperty ( String  key) 来搜索。<br>3 setProperty ( String  key, String  value) ，调用 Hashtable 的方法 put 。他通过调用基类的put方法来设置 键 - 值对。<br>4 store ( OutputStream  out, String  comments) ，   以适合使用 load 方法加载到 Properties 表中的格式，将此 Properties 表中的属性列表（键和元素</p>\n<p>对）写入输出流。与 load 方法相反，该方法将键 - 值对写入到指定的文件中去。<br>5 clear () ，清除所有装载的 键 - 值对。该方法在基类中提供。</p>\n<h2 id=\"在JAVA文件中操作properties文件的方法\"><a href=\"#在JAVA文件中操作properties文件的方法\" class=\"headerlink\" title=\"在JAVA文件中操作properties文件的方法\"></a>在JAVA文件中操作properties文件的方法</h2><pre><code>\n        pr=new Properties();\n        inStream=this.getClass().getResourceAsStream(&quot;config.properties&quot;);\n        InputStream inStream=DBUtil.class.getResourceAsStream(&quot;config.properties&quot;);\n        try {\n            pr.load(inStream);\n            url=pr.getProperty(&quot;db_url&quot;);\n            mysql=pr.getProperty(&quot;db_mysql&quot;);\n            ip=pr.getProperty(&quot;db_ip&quot;);\n            port=pr.getProperty(&quot;db_port&quot;);\n            dbname=pr.getProperty(&quot;db_dbName&quot;);\n            dbusn=pr.getProperty(&quot;db_usn&quot;);\n            dbpwd=pr.getProperty(&quot;db_pwd&quot;);\n        } catch (IOException e) {\n            // TODO Auto-generated catch block\n            e.printStackTrace();\n        }\n</code></pre><h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>java的properties文件需要放到classpath下面，这样程序才能读取到，有关classpath实际上就是java类或者库的存放路径，在java工程中，properties放到class文件一块。在web应用中，最简单的方法是放到web应用的WEB- INF\\classes目录下即可，也可以放在其他文件夹下面，这时候需要在设置classpath环境变量的时候，将这个文件夹路径加到 classpath变量中，这样也也可以读取到。在此，你需要对classpath有个深刻理解，classpath绝非系统中刻意设定的那个系统环境变量，WEB-INF\\classes其实也是，java工程的class文件目录也是。</p>\n<html>\n<div class=\"ds-thread\" data-thread-key=\"http://kongzheng1993.github.io/kongzheng1993-properties/\" data-title=\"properties\" data-url=\"http://kongzheng1993.github.io/kongzheng1993-properties/\"></div>\n<script type=\"text/javascript\">\nvar duoshuoQuery = {short_name:\"kongzheng1993\"};\n    (function() {\n        var ds = document.createElement('script');\n        ds.type = 'text/javascript';ds.async = true;\n        ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';\n        ds.charset = 'UTF-8';\n        (document.getElementsByTagName('head')[0] \n         || document.getElementsByTagName('body')[0]).appendChild(ds);\n    })();\n</script>\n</html>\n","site":{"data":{}},"more":"<h2 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h2><p>java中的properties文件是一种配置文件，主要用于配置信息，文件类型为.properties，格式为文本文件，文件内容是“键=值”的格式，在properties文件中可以使用“#”来做注释，properties文件在Java编程中用到的地方很多，操作很方便。</p>\n<h2 id=\"Properties文件\"><a href=\"#Properties文件\" class=\"headerlink\" title=\"Properties文件\"></a>Properties文件</h2><p>config.properties</p>\n<pre><code>db_url=com.mysql.jdbc.Driver\ndb_mysql=jdbc:mysql\ndb_ip=127.0.0.1\ndb_port=3306\ndb_dbName=users\ndb_usn=root\ndb_pwd=root\n</code></pre><h2 id=\"Properties类的方法\"><a href=\"#Properties类的方法\" class=\"headerlink\" title=\"Properties类的方法\"></a>Properties类的方法</h2><p>Properites类存在Java.util中，该类继承自Hashtable</p>\n<p>1 getProperty ( String  key) ，   用指定的键在此属性列表中搜索属性。也就是通过参数 key ，得到 key 所对应的 value。<br>2 load ( InputStream  inStream) ，从输入流中读取属性列表（键和元素对）。通过对指定的文件（比如说上面的 test.properties 文件）进行装载来获取该文</p>\n<p>件中的所有键 - 值对。以供 getProperty ( String  key) 来搜索。<br>3 setProperty ( String  key, String  value) ，调用 Hashtable 的方法 put 。他通过调用基类的put方法来设置 键 - 值对。<br>4 store ( OutputStream  out, String  comments) ，   以适合使用 load 方法加载到 Properties 表中的格式，将此 Properties 表中的属性列表（键和元素</p>\n<p>对）写入输出流。与 load 方法相反，该方法将键 - 值对写入到指定的文件中去。<br>5 clear () ，清除所有装载的 键 - 值对。该方法在基类中提供。</p>\n<h2 id=\"在JAVA文件中操作properties文件的方法\"><a href=\"#在JAVA文件中操作properties文件的方法\" class=\"headerlink\" title=\"在JAVA文件中操作properties文件的方法\"></a>在JAVA文件中操作properties文件的方法</h2><pre><code>\n        pr=new Properties();\n        inStream=this.getClass().getResourceAsStream(&quot;config.properties&quot;);\n        InputStream inStream=DBUtil.class.getResourceAsStream(&quot;config.properties&quot;);\n        try {\n            pr.load(inStream);\n            url=pr.getProperty(&quot;db_url&quot;);\n            mysql=pr.getProperty(&quot;db_mysql&quot;);\n            ip=pr.getProperty(&quot;db_ip&quot;);\n            port=pr.getProperty(&quot;db_port&quot;);\n            dbname=pr.getProperty(&quot;db_dbName&quot;);\n            dbusn=pr.getProperty(&quot;db_usn&quot;);\n            dbpwd=pr.getProperty(&quot;db_pwd&quot;);\n        } catch (IOException e) {\n            // TODO Auto-generated catch block\n            e.printStackTrace();\n        }\n</code></pre><h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>java的properties文件需要放到classpath下面，这样程序才能读取到，有关classpath实际上就是java类或者库的存放路径，在java工程中，properties放到class文件一块。在web应用中，最简单的方法是放到web应用的WEB- INF\\classes目录下即可，也可以放在其他文件夹下面，这时候需要在设置classpath环境变量的时候，将这个文件夹路径加到 classpath变量中，这样也也可以读取到。在此，你需要对classpath有个深刻理解，classpath绝非系统中刻意设定的那个系统环境变量，WEB-INF\\classes其实也是，java工程的class文件目录也是。</p>\n<html>\n<div class=\"ds-thread\" data-thread-key=\"http://kongzheng1993.github.io/kongzheng1993-properties/\" data-title=\"properties\" data-url=\"http://kongzheng1993.github.io/kongzheng1993-properties/\"></div>\n<script type=\"text/javascript\">\nvar duoshuoQuery = {short_name:\"kongzheng1993\"};\n    (function() {\n        var ds = document.createElement('script');\n        ds.type = 'text/javascript';ds.async = true;\n        ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';\n        ds.charset = 'UTF-8';\n        (document.getElementsByTagName('head')[0] \n         || document.getElementsByTagName('body')[0]).appendChild(ds);\n    })();\n</script>\n</html>\n"},{"layout":"post","title":"Session笔记","date":"2016-07-26T16:00:00.000Z","excerpt":"","comments":1,"_content":"\n### Session简介\n\n在WEB开发中，服务器可以为每个用户浏览器创建一个会话对象（session对象），注意：一个浏览器独占一个session对象(默认情况下)。因此，在需要保存用户数据时，服务器程序可以把用户数据写到用户浏览器独占的session中，当用户使用浏览器访问其它程序时，其它程序可以从用户的session中取出该用户的数据，为用户服务。\n\n### Session和Cookie的区别\n\n* Cookie是把用户的数据写给用户的浏览器。\n* Session技术把用户的数据写到用户独占的session中。\n* Session对象由服务器创建，开发人员可以调用request对象的getSession方法得到session对象。\n\n### Session实现原理\n\nservlet中：\n\n```\n\nresponse.sendRedirect(\"pages/login.jsp\");\nString username=request.getParameter(\"usn\");\nHttpSession session=request.getSession();\n session.setAttribute(\"username\",username);\n\n```\n\n通过`HttpSession session=request.getSession();`，如果此线程中已经存在一个session，就使用这个session，如果没有，就创建一个。这个getSession()方法可以添加boolean的参数，true表示如果没有就创建一个，如果有就使用存在的那一个，false表示，直接创建一个，默认是true。session.setAttribute()来创建一个属性，这样另一端就可以get了。\n\n\nJsp中：\n\n```\n\n Object usn=session.getAttribute(\"username\");\n\n```\n\n直接使用servlet中创建的Session对象，调用getAttribute();得到servlet中set的属性。这里即便是使用getSession()方法再次得到session也是在servlet中设置的Session对象。\n\n\n\n\n\n<html>\n<div class=\"ds-thread\" data-thread-key=\"http://kongzheng1993.github.io/kongzheng1993-session/\" data-title=\"session\" data-url=\"http://kongzheng1993.github.io/kongzheng1993-session/\"></div>\n<script type=\"text/javascript\">\nvar duoshuoQuery = {short_name:\"kongzheng1993\"};\n    (function() {\n        var ds = document.createElement('script');\n        ds.type = 'text/javascript';ds.async = true;\n        ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';\n        ds.charset = 'UTF-8';\n        (document.getElementsByTagName('head')[0] \n         || document.getElementsByTagName('body')[0]).appendChild(ds);\n    })();\n</script>\n</html>\n","source":"_posts/2016-05-20-kongzheng1993-Session.md","raw":"---\nlayout: post\ntitle:  \"Session笔记\"\ndate:   2016-07-27\nexcerpt: \"Session\"\ntag:\n- oop\ncomments: true\n---\n\n### Session简介\n\n在WEB开发中，服务器可以为每个用户浏览器创建一个会话对象（session对象），注意：一个浏览器独占一个session对象(默认情况下)。因此，在需要保存用户数据时，服务器程序可以把用户数据写到用户浏览器独占的session中，当用户使用浏览器访问其它程序时，其它程序可以从用户的session中取出该用户的数据，为用户服务。\n\n### Session和Cookie的区别\n\n* Cookie是把用户的数据写给用户的浏览器。\n* Session技术把用户的数据写到用户独占的session中。\n* Session对象由服务器创建，开发人员可以调用request对象的getSession方法得到session对象。\n\n### Session实现原理\n\nservlet中：\n\n```\n\nresponse.sendRedirect(\"pages/login.jsp\");\nString username=request.getParameter(\"usn\");\nHttpSession session=request.getSession();\n session.setAttribute(\"username\",username);\n\n```\n\n通过`HttpSession session=request.getSession();`，如果此线程中已经存在一个session，就使用这个session，如果没有，就创建一个。这个getSession()方法可以添加boolean的参数，true表示如果没有就创建一个，如果有就使用存在的那一个，false表示，直接创建一个，默认是true。session.setAttribute()来创建一个属性，这样另一端就可以get了。\n\n\nJsp中：\n\n```\n\n Object usn=session.getAttribute(\"username\");\n\n```\n\n直接使用servlet中创建的Session对象，调用getAttribute();得到servlet中set的属性。这里即便是使用getSession()方法再次得到session也是在servlet中设置的Session对象。\n\n\n\n\n\n<html>\n<div class=\"ds-thread\" data-thread-key=\"http://kongzheng1993.github.io/kongzheng1993-session/\" data-title=\"session\" data-url=\"http://kongzheng1993.github.io/kongzheng1993-session/\"></div>\n<script type=\"text/javascript\">\nvar duoshuoQuery = {short_name:\"kongzheng1993\"};\n    (function() {\n        var ds = document.createElement('script');\n        ds.type = 'text/javascript';ds.async = true;\n        ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';\n        ds.charset = 'UTF-8';\n        (document.getElementsByTagName('head')[0] \n         || document.getElementsByTagName('body')[0]).appendChild(ds);\n    })();\n</script>\n</html>\n","slug":"kongzheng1993-Session","published":1,"updated":"2023-03-08T07:05:58.769Z","photos":[],"link":"","_id":"clg0k2a9t0003t26fg296edr5","content":"<h3 id=\"Session简介\"><a href=\"#Session简介\" class=\"headerlink\" title=\"Session简介\"></a>Session简介</h3><p>在WEB开发中，服务器可以为每个用户浏览器创建一个会话对象（session对象），注意：一个浏览器独占一个session对象(默认情况下)。因此，在需要保存用户数据时，服务器程序可以把用户数据写到用户浏览器独占的session中，当用户使用浏览器访问其它程序时，其它程序可以从用户的session中取出该用户的数据，为用户服务。</p>\n<h3 id=\"Session和Cookie的区别\"><a href=\"#Session和Cookie的区别\" class=\"headerlink\" title=\"Session和Cookie的区别\"></a>Session和Cookie的区别</h3><ul>\n<li>Cookie是把用户的数据写给用户的浏览器。</li>\n<li>Session技术把用户的数据写到用户独占的session中。</li>\n<li>Session对象由服务器创建，开发人员可以调用request对象的getSession方法得到session对象。</li>\n</ul>\n<h3 id=\"Session实现原理\"><a href=\"#Session实现原理\" class=\"headerlink\" title=\"Session实现原理\"></a>Session实现原理</h3><p>servlet中：</p>\n<pre><code>\nresponse.sendRedirect(&quot;pages/login.jsp&quot;);\nString username=request.getParameter(&quot;usn&quot;);\nHttpSession session=request.getSession();\n session.setAttribute(&quot;username&quot;,username);\n</code></pre><p>通过<code>HttpSession session=request.getSession();</code>，如果此线程中已经存在一个session，就使用这个session，如果没有，就创建一个。这个getSession()方法可以添加boolean的参数，true表示如果没有就创建一个，如果有就使用存在的那一个，false表示，直接创建一个，默认是true。session.setAttribute()来创建一个属性，这样另一端就可以get了。</p>\n<p>Jsp中：</p>\n<pre><code>\n Object usn=session.getAttribute(&quot;username&quot;);\n</code></pre><p>直接使用servlet中创建的Session对象，调用getAttribute();得到servlet中set的属性。这里即便是使用getSession()方法再次得到session也是在servlet中设置的Session对象。</p>\n<html>\n<div class=\"ds-thread\" data-thread-key=\"http://kongzheng1993.github.io/kongzheng1993-session/\" data-title=\"session\" data-url=\"http://kongzheng1993.github.io/kongzheng1993-session/\"></div>\n<script type=\"text/javascript\">\nvar duoshuoQuery = {short_name:\"kongzheng1993\"};\n    (function() {\n        var ds = document.createElement('script');\n        ds.type = 'text/javascript';ds.async = true;\n        ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';\n        ds.charset = 'UTF-8';\n        (document.getElementsByTagName('head')[0] \n         || document.getElementsByTagName('body')[0]).appendChild(ds);\n    })();\n</script>\n</html>\n","site":{"data":{}},"more":"<h3 id=\"Session简介\"><a href=\"#Session简介\" class=\"headerlink\" title=\"Session简介\"></a>Session简介</h3><p>在WEB开发中，服务器可以为每个用户浏览器创建一个会话对象（session对象），注意：一个浏览器独占一个session对象(默认情况下)。因此，在需要保存用户数据时，服务器程序可以把用户数据写到用户浏览器独占的session中，当用户使用浏览器访问其它程序时，其它程序可以从用户的session中取出该用户的数据，为用户服务。</p>\n<h3 id=\"Session和Cookie的区别\"><a href=\"#Session和Cookie的区别\" class=\"headerlink\" title=\"Session和Cookie的区别\"></a>Session和Cookie的区别</h3><ul>\n<li>Cookie是把用户的数据写给用户的浏览器。</li>\n<li>Session技术把用户的数据写到用户独占的session中。</li>\n<li>Session对象由服务器创建，开发人员可以调用request对象的getSession方法得到session对象。</li>\n</ul>\n<h3 id=\"Session实现原理\"><a href=\"#Session实现原理\" class=\"headerlink\" title=\"Session实现原理\"></a>Session实现原理</h3><p>servlet中：</p>\n<pre><code>\nresponse.sendRedirect(&quot;pages/login.jsp&quot;);\nString username=request.getParameter(&quot;usn&quot;);\nHttpSession session=request.getSession();\n session.setAttribute(&quot;username&quot;,username);\n</code></pre><p>通过<code>HttpSession session=request.getSession();</code>，如果此线程中已经存在一个session，就使用这个session，如果没有，就创建一个。这个getSession()方法可以添加boolean的参数，true表示如果没有就创建一个，如果有就使用存在的那一个，false表示，直接创建一个，默认是true。session.setAttribute()来创建一个属性，这样另一端就可以get了。</p>\n<p>Jsp中：</p>\n<pre><code>\n Object usn=session.getAttribute(&quot;username&quot;);\n</code></pre><p>直接使用servlet中创建的Session对象，调用getAttribute();得到servlet中set的属性。这里即便是使用getSession()方法再次得到session也是在servlet中设置的Session对象。</p>\n<html>\n<div class=\"ds-thread\" data-thread-key=\"http://kongzheng1993.github.io/kongzheng1993-session/\" data-title=\"session\" data-url=\"http://kongzheng1993.github.io/kongzheng1993-session/\"></div>\n<script type=\"text/javascript\">\nvar duoshuoQuery = {short_name:\"kongzheng1993\"};\n    (function() {\n        var ds = document.createElement('script');\n        ds.type = 'text/javascript';ds.async = true;\n        ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';\n        ds.charset = 'UTF-8';\n        (document.getElementsByTagName('head')[0] \n         || document.getElementsByTagName('body')[0]).appendChild(ds);\n    })();\n</script>\n</html>\n"},{"layout":"post","title":"关于float","date":"2016-06-09T16:00:00.000Z","excerpt":"","comments":1,"_content":"\n\n\n\n### Java类型转换 \n\n\nJava中不同类型之间的变量赋值时，需要先进行类型转换，才能进行赋值。Java类型转换分为自动转换和强制转换两种。 \n基本类型间的自动类型转换需要满足以下条件: \n\n(1).转换双方的类型必须兼容，例如int和long类型就是兼容的，而int和boolean就是不兼容的。 \n\n(2).只能是\"窄类型\"向\"宽类型\"转换,也就是目标类型的数据表示范围要比源类型的数据表示范围要大。 \n\n\n\n\n### 数值常量默认类型 \n  \n1.Java中整型常量数值的默认类型是int类型，如果需要声明long类型的常量 ，需要在数值加上'l'或者'L'. \n  例如:int i = 3; \n       long l = 3L; \n  \n2.Java中的浮点型常量数值默认是double类型，如果要声明一个数值为float型，则需要在数值后面加上'f'或者'F'. \n  例如:double d = 3.14; \n       float f = 3.14f; \n   \n### float f = 3.4;语句是错误的\n3.4数值常量默认情况下是double类型，如果赋值给f,那么将由double转换成float类型，由前面的知识可以知道是不能自动类型转换的，所以可以将float f = 3.4修改成: \n\n(1)float f = 3.4f; \n(2)float f = (float)3.4; \n\n\n\n","source":"_posts/2016-05-20-kongzheng1993-aboutFloat.md","raw":"---\nlayout: post\ntitle: \"关于float\"\ndate: 2016-06-10\nexcerpt: \"为什么面试题里float f=3.4是错的？\"\ntags: [float]\ncomments: true\n---\n\n\n\n\n### Java类型转换 \n\n\nJava中不同类型之间的变量赋值时，需要先进行类型转换，才能进行赋值。Java类型转换分为自动转换和强制转换两种。 \n基本类型间的自动类型转换需要满足以下条件: \n\n(1).转换双方的类型必须兼容，例如int和long类型就是兼容的，而int和boolean就是不兼容的。 \n\n(2).只能是\"窄类型\"向\"宽类型\"转换,也就是目标类型的数据表示范围要比源类型的数据表示范围要大。 \n\n\n\n\n### 数值常量默认类型 \n  \n1.Java中整型常量数值的默认类型是int类型，如果需要声明long类型的常量 ，需要在数值加上'l'或者'L'. \n  例如:int i = 3; \n       long l = 3L; \n  \n2.Java中的浮点型常量数值默认是double类型，如果要声明一个数值为float型，则需要在数值后面加上'f'或者'F'. \n  例如:double d = 3.14; \n       float f = 3.14f; \n   \n### float f = 3.4;语句是错误的\n3.4数值常量默认情况下是double类型，如果赋值给f,那么将由double转换成float类型，由前面的知识可以知道是不能自动类型转换的，所以可以将float f = 3.4修改成: \n\n(1)float f = 3.4f; \n(2)float f = (float)3.4; \n\n\n\n","slug":"kongzheng1993-aboutFloat","published":1,"updated":"2023-03-08T07:05:58.769Z","photos":[],"link":"","_id":"clg0k2a9u0004t26f6eb76x5t","content":"<h3 id=\"Java类型转换\"><a href=\"#Java类型转换\" class=\"headerlink\" title=\"Java类型转换\"></a>Java类型转换</h3><p>Java中不同类型之间的变量赋值时，需要先进行类型转换，才能进行赋值。Java类型转换分为自动转换和强制转换两种。<br>基本类型间的自动类型转换需要满足以下条件: </p>\n<p>(1).转换双方的类型必须兼容，例如int和long类型就是兼容的，而int和boolean就是不兼容的。 </p>\n<p>(2).只能是”窄类型”向”宽类型”转换,也就是目标类型的数据表示范围要比源类型的数据表示范围要大。 </p>\n<h3 id=\"数值常量默认类型\"><a href=\"#数值常量默认类型\" class=\"headerlink\" title=\"数值常量默认类型\"></a>数值常量默认类型</h3><p>1.Java中整型常量数值的默认类型是int类型，如果需要声明long类型的常量 ，需要在数值加上’l’或者’L’.<br>  例如:int i = 3;<br>       long l = 3L; </p>\n<p>2.Java中的浮点型常量数值默认是double类型，如果要声明一个数值为float型，则需要在数值后面加上’f’或者’F’.<br>  例如:double d = 3.14;<br>       float f = 3.14f; </p>\n<h3 id=\"float-f-3-4-语句是错误的\"><a href=\"#float-f-3-4-语句是错误的\" class=\"headerlink\" title=\"float f = 3.4;语句是错误的\"></a>float f = 3.4;语句是错误的</h3><p>3.4数值常量默认情况下是double类型，如果赋值给f,那么将由double转换成float类型，由前面的知识可以知道是不能自动类型转换的，所以可以将float f = 3.4修改成: </p>\n<p>(1)float f = 3.4f;<br>(2)float f = (float)3.4; </p>\n","site":{"data":{}},"more":"<h3 id=\"Java类型转换\"><a href=\"#Java类型转换\" class=\"headerlink\" title=\"Java类型转换\"></a>Java类型转换</h3><p>Java中不同类型之间的变量赋值时，需要先进行类型转换，才能进行赋值。Java类型转换分为自动转换和强制转换两种。<br>基本类型间的自动类型转换需要满足以下条件: </p>\n<p>(1).转换双方的类型必须兼容，例如int和long类型就是兼容的，而int和boolean就是不兼容的。 </p>\n<p>(2).只能是”窄类型”向”宽类型”转换,也就是目标类型的数据表示范围要比源类型的数据表示范围要大。 </p>\n<h3 id=\"数值常量默认类型\"><a href=\"#数值常量默认类型\" class=\"headerlink\" title=\"数值常量默认类型\"></a>数值常量默认类型</h3><p>1.Java中整型常量数值的默认类型是int类型，如果需要声明long类型的常量 ，需要在数值加上’l’或者’L’.<br>  例如:int i = 3;<br>       long l = 3L; </p>\n<p>2.Java中的浮点型常量数值默认是double类型，如果要声明一个数值为float型，则需要在数值后面加上’f’或者’F’.<br>  例如:double d = 3.14;<br>       float f = 3.14f; </p>\n<h3 id=\"float-f-3-4-语句是错误的\"><a href=\"#float-f-3-4-语句是错误的\" class=\"headerlink\" title=\"float f = 3.4;语句是错误的\"></a>float f = 3.4;语句是错误的</h3><p>3.4数值常量默认情况下是double类型，如果赋值给f,那么将由double转换成float类型，由前面的知识可以知道是不能自动类型转换的，所以可以将float f = 3.4修改成: </p>\n<p>(1)float f = 3.4f;<br>(2)float f = (float)3.4; </p>\n"},{"layout":"post","title":"Servlet","date":"2016-07-25T16:00:00.000Z","excerpt":"","comments":1,"_content":"\n## WHAT\n\n当一个请求到了web服务器，接收请求和响应请求是web服务器完成的，可是处理请求呢？接收和响应都是固定的东西，但是处理请求是包含业务逻辑在里面的，需要我们自己处理，所以就抽取出来了Servlet让我们来完成请求的处理，当然请求处理咱么又拆分出三层架构：servlet+service+dao。每个servlet来处理对应映射的url来的请求，很多servlet需要统一管理，所以tomcat还是一个servlet容器。\n\n后来spring家族出现，servlet就退居幕后了。现在咱们用的springMVC其实核心组件DispatcherServlet本质上就是Servlet，只是在原来的HttpServlet基础上封装了一层。\n\n## Servlet是怎么工作的\n\n![Servlet接口](servlet接口.jpg)\n\nServlet是一个接口，其中有init()，getServletConfig()，service()，getServiceInfo()，destroy()方法。Tomcat已经替我们完成了大部分工作，并且传入了三个对象ServletConfig、ServletRequest、ServletResponse。\n\n!(servlet实例化过程.jpg)\n\n1. ServletConfig是servlet配置，也就是我们在web.xml里的配置。\n2. Request/Response，也就是请求和响应。tomcat在收到http请求后，tomcat就解析了报文中的字段，然后封装进了Request对象。所以我们通过调用request对象的一些get方法就能获取请求的信息。response在tomcat传给servlet的时候还是空的。servlet逻辑处理后得到结果，最后通过response.write()写入response，tomcat或在servlet处理结束后拿到response组装成http响应发给客户端。\n\nServlet接口五个方法，init、service、destroy是声明周期方法。init和destroy各自执行一次，即创建和销毁。而service是在每次有新请求的时候被调用，也就是我们写业务代码的地方。\n\n如果我们直接实现Servlet接口，会很麻烦，要自己处理请求类型，所以提供了抽象类GenericServlet：\n\n1. 提升了init方法中原本形参的servletConfig对象的作用域，方便其他方法使用\n2. init方法中调用了一个init空参方法，如果我们希望servlet创建时做一些自定义的操作，可以继承GenericServlet后覆盖init空参方法。\n3. 由于其他方法内也可以使用ServletConfig，于是写了一个getServletContext方法\n4. service是没有实现的。\n\n向下找，会找到HttpServlet抽象类，他继承了GenericServlet。虽然他是一个抽象类，但是他并没有抽象方法。HttpServlet类完成了请求方法判断。\n一个类被声明为抽象类，一般有两个原因：\n\n1. 有抽象方法。\n2. 没有抽象方法，但是不希望别人直接实例化使用。\n\n所以这里仅仅是为了不让我们直接使用httpServlet。\n\nHttpServlet的doGet和doPost方法的默认实现是直接返回405，也就是请求不支持。所以我们要重写这两个方法。\n\n设计模式： Filter用到了责任链模式，Listener用到了观察者模式，Servlet使用的就是模板方法模式。\n\n所以到这里，我们写servlet需要重写的方法就是doGet和doPost。\n","source":"_posts/2016-05-20-kongzheng1993-servlet.md","raw":"---\nlayout: post\ntitle:  \"Servlet\"\ndate:   2016-07-26\nexcerpt: \"servlet\"\ntag: [servlet]\ncomments: true\n---\n\n## WHAT\n\n当一个请求到了web服务器，接收请求和响应请求是web服务器完成的，可是处理请求呢？接收和响应都是固定的东西，但是处理请求是包含业务逻辑在里面的，需要我们自己处理，所以就抽取出来了Servlet让我们来完成请求的处理，当然请求处理咱么又拆分出三层架构：servlet+service+dao。每个servlet来处理对应映射的url来的请求，很多servlet需要统一管理，所以tomcat还是一个servlet容器。\n\n后来spring家族出现，servlet就退居幕后了。现在咱们用的springMVC其实核心组件DispatcherServlet本质上就是Servlet，只是在原来的HttpServlet基础上封装了一层。\n\n## Servlet是怎么工作的\n\n![Servlet接口](servlet接口.jpg)\n\nServlet是一个接口，其中有init()，getServletConfig()，service()，getServiceInfo()，destroy()方法。Tomcat已经替我们完成了大部分工作，并且传入了三个对象ServletConfig、ServletRequest、ServletResponse。\n\n!(servlet实例化过程.jpg)\n\n1. ServletConfig是servlet配置，也就是我们在web.xml里的配置。\n2. Request/Response，也就是请求和响应。tomcat在收到http请求后，tomcat就解析了报文中的字段，然后封装进了Request对象。所以我们通过调用request对象的一些get方法就能获取请求的信息。response在tomcat传给servlet的时候还是空的。servlet逻辑处理后得到结果，最后通过response.write()写入response，tomcat或在servlet处理结束后拿到response组装成http响应发给客户端。\n\nServlet接口五个方法，init、service、destroy是声明周期方法。init和destroy各自执行一次，即创建和销毁。而service是在每次有新请求的时候被调用，也就是我们写业务代码的地方。\n\n如果我们直接实现Servlet接口，会很麻烦，要自己处理请求类型，所以提供了抽象类GenericServlet：\n\n1. 提升了init方法中原本形参的servletConfig对象的作用域，方便其他方法使用\n2. init方法中调用了一个init空参方法，如果我们希望servlet创建时做一些自定义的操作，可以继承GenericServlet后覆盖init空参方法。\n3. 由于其他方法内也可以使用ServletConfig，于是写了一个getServletContext方法\n4. service是没有实现的。\n\n向下找，会找到HttpServlet抽象类，他继承了GenericServlet。虽然他是一个抽象类，但是他并没有抽象方法。HttpServlet类完成了请求方法判断。\n一个类被声明为抽象类，一般有两个原因：\n\n1. 有抽象方法。\n2. 没有抽象方法，但是不希望别人直接实例化使用。\n\n所以这里仅仅是为了不让我们直接使用httpServlet。\n\nHttpServlet的doGet和doPost方法的默认实现是直接返回405，也就是请求不支持。所以我们要重写这两个方法。\n\n设计模式： Filter用到了责任链模式，Listener用到了观察者模式，Servlet使用的就是模板方法模式。\n\n所以到这里，我们写servlet需要重写的方法就是doGet和doPost。\n","slug":"kongzheng1993-servlet","published":1,"updated":"2023-03-08T07:05:58.769Z","photos":[],"link":"","_id":"clg0k2a9v0005t26fho0xkfm4","content":"<h2 id=\"WHAT\"><a href=\"#WHAT\" class=\"headerlink\" title=\"WHAT\"></a>WHAT</h2><p>当一个请求到了web服务器，接收请求和响应请求是web服务器完成的，可是处理请求呢？接收和响应都是固定的东西，但是处理请求是包含业务逻辑在里面的，需要我们自己处理，所以就抽取出来了Servlet让我们来完成请求的处理，当然请求处理咱么又拆分出三层架构：servlet+service+dao。每个servlet来处理对应映射的url来的请求，很多servlet需要统一管理，所以tomcat还是一个servlet容器。</p>\n<p>后来spring家族出现，servlet就退居幕后了。现在咱们用的springMVC其实核心组件DispatcherServlet本质上就是Servlet，只是在原来的HttpServlet基础上封装了一层。</p>\n<h2 id=\"Servlet是怎么工作的\"><a href=\"#Servlet是怎么工作的\" class=\"headerlink\" title=\"Servlet是怎么工作的\"></a>Servlet是怎么工作的</h2><p><img src=\"/2016/07/26/kongzheng1993-servlet/servlet%E6%8E%A5%E5%8F%A3.jpg\" alt=\"Servlet接口\"></p>\n<p>Servlet是一个接口，其中有init()，getServletConfig()，service()，getServiceInfo()，destroy()方法。Tomcat已经替我们完成了大部分工作，并且传入了三个对象ServletConfig、ServletRequest、ServletResponse。</p>\n<p>!(servlet实例化过程.jpg)</p>\n<ol>\n<li>ServletConfig是servlet配置，也就是我们在web.xml里的配置。</li>\n<li>Request/Response，也就是请求和响应。tomcat在收到http请求后，tomcat就解析了报文中的字段，然后封装进了Request对象。所以我们通过调用request对象的一些get方法就能获取请求的信息。response在tomcat传给servlet的时候还是空的。servlet逻辑处理后得到结果，最后通过response.write()写入response，tomcat或在servlet处理结束后拿到response组装成http响应发给客户端。</li>\n</ol>\n<p>Servlet接口五个方法，init、service、destroy是声明周期方法。init和destroy各自执行一次，即创建和销毁。而service是在每次有新请求的时候被调用，也就是我们写业务代码的地方。</p>\n<p>如果我们直接实现Servlet接口，会很麻烦，要自己处理请求类型，所以提供了抽象类GenericServlet：</p>\n<ol>\n<li>提升了init方法中原本形参的servletConfig对象的作用域，方便其他方法使用</li>\n<li>init方法中调用了一个init空参方法，如果我们希望servlet创建时做一些自定义的操作，可以继承GenericServlet后覆盖init空参方法。</li>\n<li>由于其他方法内也可以使用ServletConfig，于是写了一个getServletContext方法</li>\n<li>service是没有实现的。</li>\n</ol>\n<p>向下找，会找到HttpServlet抽象类，他继承了GenericServlet。虽然他是一个抽象类，但是他并没有抽象方法。HttpServlet类完成了请求方法判断。<br>一个类被声明为抽象类，一般有两个原因：</p>\n<ol>\n<li>有抽象方法。</li>\n<li>没有抽象方法，但是不希望别人直接实例化使用。</li>\n</ol>\n<p>所以这里仅仅是为了不让我们直接使用httpServlet。</p>\n<p>HttpServlet的doGet和doPost方法的默认实现是直接返回405，也就是请求不支持。所以我们要重写这两个方法。</p>\n<p>设计模式： Filter用到了责任链模式，Listener用到了观察者模式，Servlet使用的就是模板方法模式。</p>\n<p>所以到这里，我们写servlet需要重写的方法就是doGet和doPost。</p>\n","site":{"data":{}},"more":"<h2 id=\"WHAT\"><a href=\"#WHAT\" class=\"headerlink\" title=\"WHAT\"></a>WHAT</h2><p>当一个请求到了web服务器，接收请求和响应请求是web服务器完成的，可是处理请求呢？接收和响应都是固定的东西，但是处理请求是包含业务逻辑在里面的，需要我们自己处理，所以就抽取出来了Servlet让我们来完成请求的处理，当然请求处理咱么又拆分出三层架构：servlet+service+dao。每个servlet来处理对应映射的url来的请求，很多servlet需要统一管理，所以tomcat还是一个servlet容器。</p>\n<p>后来spring家族出现，servlet就退居幕后了。现在咱们用的springMVC其实核心组件DispatcherServlet本质上就是Servlet，只是在原来的HttpServlet基础上封装了一层。</p>\n<h2 id=\"Servlet是怎么工作的\"><a href=\"#Servlet是怎么工作的\" class=\"headerlink\" title=\"Servlet是怎么工作的\"></a>Servlet是怎么工作的</h2><p><img src=\"/2016/07/26/kongzheng1993-servlet/servlet%E6%8E%A5%E5%8F%A3.jpg\" alt=\"Servlet接口\"></p>\n<p>Servlet是一个接口，其中有init()，getServletConfig()，service()，getServiceInfo()，destroy()方法。Tomcat已经替我们完成了大部分工作，并且传入了三个对象ServletConfig、ServletRequest、ServletResponse。</p>\n<p>!(servlet实例化过程.jpg)</p>\n<ol>\n<li>ServletConfig是servlet配置，也就是我们在web.xml里的配置。</li>\n<li>Request/Response，也就是请求和响应。tomcat在收到http请求后，tomcat就解析了报文中的字段，然后封装进了Request对象。所以我们通过调用request对象的一些get方法就能获取请求的信息。response在tomcat传给servlet的时候还是空的。servlet逻辑处理后得到结果，最后通过response.write()写入response，tomcat或在servlet处理结束后拿到response组装成http响应发给客户端。</li>\n</ol>\n<p>Servlet接口五个方法，init、service、destroy是声明周期方法。init和destroy各自执行一次，即创建和销毁。而service是在每次有新请求的时候被调用，也就是我们写业务代码的地方。</p>\n<p>如果我们直接实现Servlet接口，会很麻烦，要自己处理请求类型，所以提供了抽象类GenericServlet：</p>\n<ol>\n<li>提升了init方法中原本形参的servletConfig对象的作用域，方便其他方法使用</li>\n<li>init方法中调用了一个init空参方法，如果我们希望servlet创建时做一些自定义的操作，可以继承GenericServlet后覆盖init空参方法。</li>\n<li>由于其他方法内也可以使用ServletConfig，于是写了一个getServletContext方法</li>\n<li>service是没有实现的。</li>\n</ol>\n<p>向下找，会找到HttpServlet抽象类，他继承了GenericServlet。虽然他是一个抽象类，但是他并没有抽象方法。HttpServlet类完成了请求方法判断。<br>一个类被声明为抽象类，一般有两个原因：</p>\n<ol>\n<li>有抽象方法。</li>\n<li>没有抽象方法，但是不希望别人直接实例化使用。</li>\n</ol>\n<p>所以这里仅仅是为了不让我们直接使用httpServlet。</p>\n<p>HttpServlet的doGet和doPost方法的默认实现是直接返回405，也就是请求不支持。所以我们要重写这两个方法。</p>\n<p>设计模式： Filter用到了责任链模式，Listener用到了观察者模式，Servlet使用的就是模板方法模式。</p>\n<p>所以到这里，我们写servlet需要重写的方法就是doGet和doPost。</p>\n"},{"layout":"post","title":"request&response","date":"2016-07-27T16:00:00.000Z","excerpt":"","comments":1,"_content":"\n#### request的方法：\n\n客户端的请求信息被封装在request对象中，通过它才能了解到客户的需求，然后做出响应。它是HttpServletRequest类的实例。\n\n序号/方法/说明 \n\n* object getAttribute(String name) 返回指定属性的属性值 \n* Enumeration getAttributeNames() 返回所有可用属性名的枚举 \n* String getCharacterEncoding() 返回字符编码方式 \n* int getContentLength() 返回请求体的长度（以字节数） \n* String getContentType() 得到请求体的MIME类型 \n* ServletInputStream getInputStream() 得到请求体中一行的二进制流 \n* String getParameter(String name) 返回name指定参数的参数值 \n* Enumeration getParameterNames() 返回可用参数名的枚举 \n* String[] getParameterValues(String name) 返回包含参数name的所有值的数组 \n* String getProtocol() 返回请求用的协议类型及版本号 \n* String getScheme() 返回请求用的计划名,如:http.https及ftp等 \n* String getServerName() 返回接受请求的服务器主机名 \n* int getServerPort() 返回服务器接受此请求所用的端口号 \n* BufferedReader getReader() 返回解码过了的请求体 \n* String getRemoteAddr() 返回发送此请求的客户端IP地址 \n* String getRemoteHost() 返回发送此请求的客户端主机名 \n* void setAttribute(String key,Object obj) 设置属性的属性值 \n* String getRealPath(String path) 返回一虚拟路径的真实路径\n\n#### response的方法：\n\n序号/方法/说明\n\nresponse对象包含了响应客户请求的有关信息，但在JSP中很少直接用到它。它是HttpServletResponse类的实例。\n序号 方 法 说 明 \n* String getCharacterEncoding() 返回响应用的是何种字符编码 \n* ServletOutputStream getOutputStream() 返回响应的一个二进制输出流 \n* PrintWriter getWriter() 返回可以向客户端输出字符的一个对象 \n* void setContentLength(int len) 设置响应头长度 \n* void setContentType(String type) 设置响应的MIME类型 \n* sendRedirect(java.lang.String location) 重新定向客户端的请求\n\n\n\n\n\n\n<html>\n<div class=\"ds-thread\" data-thread-key=\"http://kongzheng1993.github.io/kongzheng1993-properties/\" data-title=\"properties\" data-url=\"http://kongzheng1993.github.io/kongzheng1993-properties/\"></div>\n<script type=\"text/javascript\">\nvar duoshuoQuery = {short_name:\"kongzheng1993\"};\n    (function() {\n        var ds = document.createElement('script');\n        ds.type = 'text/javascript';ds.async = true;\n        ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';\n        ds.charset = 'UTF-8';\n        (document.getElementsByTagName('head')[0] \n         || document.getElementsByTagName('body')[0]).appendChild(ds);\n    })();\n</script>\n</html>\n","source":"_posts/2016-05-20-kongzheng1993-method_of_request&response.md","raw":"---\nlayout: post\ntitle:  \"request&response\"\ndate:   2016-07-28\nexcerpt: \"properties\"\ntag:\n- oop\ncomments: true\n---\n\n#### request的方法：\n\n客户端的请求信息被封装在request对象中，通过它才能了解到客户的需求，然后做出响应。它是HttpServletRequest类的实例。\n\n序号/方法/说明 \n\n* object getAttribute(String name) 返回指定属性的属性值 \n* Enumeration getAttributeNames() 返回所有可用属性名的枚举 \n* String getCharacterEncoding() 返回字符编码方式 \n* int getContentLength() 返回请求体的长度（以字节数） \n* String getContentType() 得到请求体的MIME类型 \n* ServletInputStream getInputStream() 得到请求体中一行的二进制流 \n* String getParameter(String name) 返回name指定参数的参数值 \n* Enumeration getParameterNames() 返回可用参数名的枚举 \n* String[] getParameterValues(String name) 返回包含参数name的所有值的数组 \n* String getProtocol() 返回请求用的协议类型及版本号 \n* String getScheme() 返回请求用的计划名,如:http.https及ftp等 \n* String getServerName() 返回接受请求的服务器主机名 \n* int getServerPort() 返回服务器接受此请求所用的端口号 \n* BufferedReader getReader() 返回解码过了的请求体 \n* String getRemoteAddr() 返回发送此请求的客户端IP地址 \n* String getRemoteHost() 返回发送此请求的客户端主机名 \n* void setAttribute(String key,Object obj) 设置属性的属性值 \n* String getRealPath(String path) 返回一虚拟路径的真实路径\n\n#### response的方法：\n\n序号/方法/说明\n\nresponse对象包含了响应客户请求的有关信息，但在JSP中很少直接用到它。它是HttpServletResponse类的实例。\n序号 方 法 说 明 \n* String getCharacterEncoding() 返回响应用的是何种字符编码 \n* ServletOutputStream getOutputStream() 返回响应的一个二进制输出流 \n* PrintWriter getWriter() 返回可以向客户端输出字符的一个对象 \n* void setContentLength(int len) 设置响应头长度 \n* void setContentType(String type) 设置响应的MIME类型 \n* sendRedirect(java.lang.String location) 重新定向客户端的请求\n\n\n\n\n\n\n<html>\n<div class=\"ds-thread\" data-thread-key=\"http://kongzheng1993.github.io/kongzheng1993-properties/\" data-title=\"properties\" data-url=\"http://kongzheng1993.github.io/kongzheng1993-properties/\"></div>\n<script type=\"text/javascript\">\nvar duoshuoQuery = {short_name:\"kongzheng1993\"};\n    (function() {\n        var ds = document.createElement('script');\n        ds.type = 'text/javascript';ds.async = true;\n        ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';\n        ds.charset = 'UTF-8';\n        (document.getElementsByTagName('head')[0] \n         || document.getElementsByTagName('body')[0]).appendChild(ds);\n    })();\n</script>\n</html>\n","slug":"kongzheng1993-method_of_request&response","published":1,"updated":"2023-03-08T07:05:58.769Z","photos":[],"link":"","_id":"clg0k2aa60008t26f4hhze9x0","content":"<h4 id=\"request的方法：\"><a href=\"#request的方法：\" class=\"headerlink\" title=\"request的方法：\"></a>request的方法：</h4><p>客户端的请求信息被封装在request对象中，通过它才能了解到客户的需求，然后做出响应。它是HttpServletRequest类的实例。</p>\n<p>序号/方法/说明 </p>\n<ul>\n<li>object getAttribute(String name) 返回指定属性的属性值 </li>\n<li>Enumeration getAttributeNames() 返回所有可用属性名的枚举 </li>\n<li>String getCharacterEncoding() 返回字符编码方式 </li>\n<li>int getContentLength() 返回请求体的长度（以字节数） </li>\n<li>String getContentType() 得到请求体的MIME类型 </li>\n<li>ServletInputStream getInputStream() 得到请求体中一行的二进制流 </li>\n<li>String getParameter(String name) 返回name指定参数的参数值 </li>\n<li>Enumeration getParameterNames() 返回可用参数名的枚举 </li>\n<li>String[] getParameterValues(String name) 返回包含参数name的所有值的数组 </li>\n<li>String getProtocol() 返回请求用的协议类型及版本号 </li>\n<li>String getScheme() 返回请求用的计划名,如:http.https及ftp等 </li>\n<li>String getServerName() 返回接受请求的服务器主机名 </li>\n<li>int getServerPort() 返回服务器接受此请求所用的端口号 </li>\n<li>BufferedReader getReader() 返回解码过了的请求体 </li>\n<li>String getRemoteAddr() 返回发送此请求的客户端IP地址 </li>\n<li>String getRemoteHost() 返回发送此请求的客户端主机名 </li>\n<li>void setAttribute(String key,Object obj) 设置属性的属性值 </li>\n<li>String getRealPath(String path) 返回一虚拟路径的真实路径</li>\n</ul>\n<h4 id=\"response的方法：\"><a href=\"#response的方法：\" class=\"headerlink\" title=\"response的方法：\"></a>response的方法：</h4><p>序号/方法/说明</p>\n<p>response对象包含了响应客户请求的有关信息，但在JSP中很少直接用到它。它是HttpServletResponse类的实例。<br>序号 方 法 说 明 </p>\n<ul>\n<li>String getCharacterEncoding() 返回响应用的是何种字符编码 </li>\n<li>ServletOutputStream getOutputStream() 返回响应的一个二进制输出流 </li>\n<li>PrintWriter getWriter() 返回可以向客户端输出字符的一个对象 </li>\n<li>void setContentLength(int len) 设置响应头长度 </li>\n<li>void setContentType(String type) 设置响应的MIME类型 </li>\n<li>sendRedirect(java.lang.String location) 重新定向客户端的请求</li>\n</ul>\n<html>\n<div class=\"ds-thread\" data-thread-key=\"http://kongzheng1993.github.io/kongzheng1993-properties/\" data-title=\"properties\" data-url=\"http://kongzheng1993.github.io/kongzheng1993-properties/\"></div>\n<script type=\"text/javascript\">\nvar duoshuoQuery = {short_name:\"kongzheng1993\"};\n    (function() {\n        var ds = document.createElement('script');\n        ds.type = 'text/javascript';ds.async = true;\n        ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';\n        ds.charset = 'UTF-8';\n        (document.getElementsByTagName('head')[0] \n         || document.getElementsByTagName('body')[0]).appendChild(ds);\n    })();\n</script>\n</html>\n","site":{"data":{}},"more":"<h4 id=\"request的方法：\"><a href=\"#request的方法：\" class=\"headerlink\" title=\"request的方法：\"></a>request的方法：</h4><p>客户端的请求信息被封装在request对象中，通过它才能了解到客户的需求，然后做出响应。它是HttpServletRequest类的实例。</p>\n<p>序号/方法/说明 </p>\n<ul>\n<li>object getAttribute(String name) 返回指定属性的属性值 </li>\n<li>Enumeration getAttributeNames() 返回所有可用属性名的枚举 </li>\n<li>String getCharacterEncoding() 返回字符编码方式 </li>\n<li>int getContentLength() 返回请求体的长度（以字节数） </li>\n<li>String getContentType() 得到请求体的MIME类型 </li>\n<li>ServletInputStream getInputStream() 得到请求体中一行的二进制流 </li>\n<li>String getParameter(String name) 返回name指定参数的参数值 </li>\n<li>Enumeration getParameterNames() 返回可用参数名的枚举 </li>\n<li>String[] getParameterValues(String name) 返回包含参数name的所有值的数组 </li>\n<li>String getProtocol() 返回请求用的协议类型及版本号 </li>\n<li>String getScheme() 返回请求用的计划名,如:http.https及ftp等 </li>\n<li>String getServerName() 返回接受请求的服务器主机名 </li>\n<li>int getServerPort() 返回服务器接受此请求所用的端口号 </li>\n<li>BufferedReader getReader() 返回解码过了的请求体 </li>\n<li>String getRemoteAddr() 返回发送此请求的客户端IP地址 </li>\n<li>String getRemoteHost() 返回发送此请求的客户端主机名 </li>\n<li>void setAttribute(String key,Object obj) 设置属性的属性值 </li>\n<li>String getRealPath(String path) 返回一虚拟路径的真实路径</li>\n</ul>\n<h4 id=\"response的方法：\"><a href=\"#response的方法：\" class=\"headerlink\" title=\"response的方法：\"></a>response的方法：</h4><p>序号/方法/说明</p>\n<p>response对象包含了响应客户请求的有关信息，但在JSP中很少直接用到它。它是HttpServletResponse类的实例。<br>序号 方 法 说 明 </p>\n<ul>\n<li>String getCharacterEncoding() 返回响应用的是何种字符编码 </li>\n<li>ServletOutputStream getOutputStream() 返回响应的一个二进制输出流 </li>\n<li>PrintWriter getWriter() 返回可以向客户端输出字符的一个对象 </li>\n<li>void setContentLength(int len) 设置响应头长度 </li>\n<li>void setContentType(String type) 设置响应的MIME类型 </li>\n<li>sendRedirect(java.lang.String location) 重新定向客户端的请求</li>\n</ul>\n<html>\n<div class=\"ds-thread\" data-thread-key=\"http://kongzheng1993.github.io/kongzheng1993-properties/\" data-title=\"properties\" data-url=\"http://kongzheng1993.github.io/kongzheng1993-properties/\"></div>\n<script type=\"text/javascript\">\nvar duoshuoQuery = {short_name:\"kongzheng1993\"};\n    (function() {\n        var ds = document.createElement('script');\n        ds.type = 'text/javascript';ds.async = true;\n        ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';\n        ds.charset = 'UTF-8';\n        (document.getElementsByTagName('head')[0] \n         || document.getElementsByTagName('body')[0]).appendChild(ds);\n    })();\n</script>\n</html>\n"},{"layout":"post","title":"请求转发和重定向","date":"2016-07-25T16:00:00.000Z","excerpt":"","comments":1,"_content":"\n### 重定向与转发的区别：\n\n1.重定向访问服务器两次，转发只访问服务器一次。\n2.重定向可以看见目标页面的URL，转发只能看见第一次访问的页面URL，以后的工作都是有服务器来做的。\n3.重定向跳转后必须加上return，要不然页面虽然跳转了，但是还会执行跳转后面的语句，转发是执行了跳转页面，下面的代码就不会在执行了。\n4.在request级别使用信息共享，使用重定向必然出错\n5.还有一个大的区别就是，重定向可以访问自己web应用以外的资源\n\n\n### 一、调用方式 \n\n我们知道，在servlet中调用转发、重定向的语句如下： \nrequest.getRequestDispatcher(\"new.jsp\").forward(request, response);//转发到new.jsp \nresponse.sendRedirect(\"new.jsp\");//重定向到new.jsp \n\n在jsp页面中你也会看到通过下面的方式实现转发： \n<jsp:forward page=\"apage.jsp\" /> \n\n当然也可以在jsp页面中实现重定向： \n<%response.sendRedirect(\"new.jsp\");//重定向到new.jsp%> \n\n### 二、本质区别 \n\n#### 解释一　　 \n\n一句话，转发是服务器行为，重定向是客户端行为。为什么这样说呢，这就要看两个动作的工作流程： \n\n转发过程：客户浏览器发送http请求----》web服务器接受此请求--》调用内部的一个方法在容器内部完成请求处理和转发动作----》将目标资源发送给客户；在这里，转发的路径必须是同一个web容器下的url，其不能转向到其他的web路径上去，中间传递的是自己的容器内的request。在客户浏览器路径栏显示的仍然是其第一次访问的路径，也就是说客户是感觉不到服务器做了转发的。转发行为是浏览器只做了一次访问请求。 \n\n重定向过程：客户浏览器发送http请求----》web服务器接受后发送302状态码响应及对应新的location给客户浏览器--》客户浏览器发现是302响应，则自动再发送一个新的http请求，请求url是新的location地址----》服务器根据此请求寻找资源并发送给客户。在这里location可以重定向到任意URL，既然是浏览器重新发出了请求，则就没有什么request传递的概念了。在客户浏览器路径栏显示的是其重定向的路径，客户可以观察到地址的变化的。重定向行为是浏览器做了至少两次的访问请求的。 \n\n#### 解释二 \n重定向，其实是两次request, \n第一次，客户端request A,服务器响应，并response回来，告诉浏览器，你应该去B。这个时候IE可以看到地址变了，而且历史的回退按钮也亮了。重定向可以访问自己web应用以外的资源。在重定向的过程中，传输的信息会被丢失。 \n\n\n\n请求转发是服务器内部把对一个request/response的处理权，移交给另外一个 \n对于客户端而言，它只知道自己最早请求的那个A，而不知道中间的B，甚至C、D。 传输的信息不会丢失。 \n\n \n\n#### 解释三 \n假设你去办理某个执照， \n\n重定向：你先去了A局，A局的人说：“这个事情不归我们管，去B局”，然后，你就从A退了出来，自己乘车去了B局。 \n\n转发：你先去了A局，A局看了以后，知道这个事情其实应该B局来管，但是他没有把你退回来，而是让你坐一会儿，自己到后面办公室联系了B的人，让他们办好后，送了过来。 \n\n### 三、请求重定向与请求转发的比较 \n\n尽管HttpServletResponse.sendRedirect方法和RequestDispatcher.forward方法都可以让浏览器获得另外一个URL所指向的资源，但两者的内部运行机制有着很大的区别。下面是HttpServletResponse.sendRedirect方法实现的请求重定向与RequestDispatcher.forward方法实现的请求转发的总结比较： \n\n（1）RequestDispatcher.forward方法只能将请求转发给同一个WEB应用中的组件；而HttpServletResponse.sendRedirect 方法不仅可以重定向到当前应用程序中的其他资源，还可以重定向到同一个站点上的其他应用程序中的资源，甚至是使用绝对URL重定向到其他站点的资源。如果传递给HttpServletResponse.sendRedirect 方法的相对URL以“/”开头，它是相对于整个WEB站点的根目录；如果创建RequestDispatcher对象时指定的相对URL以“/”开头，它是相对于当前WEB应用程序的根目录。 \n\n（2）调用HttpServletResponse.sendRedirect方法重定向的访问过程结束后，浏览器地址栏中显示的URL会发生改变，由初始的URL地址变成重定向的目标URL；而调用RequestDispatcher.forward 方法的请求转发过程结束后，浏览器地址栏保持初始的URL地址不变。 \n\n（3）HttpServletResponse.sendRedirect方法对浏览器的请求直接作出响应，响应的结果就是告诉浏览器去重新发出对另外一个URL的 访问请求，这个过程好比有个绰号叫“浏览器”的人写信找张三借钱，张三回信说没有钱，让“浏览器”去找李四借，并将李四现在的通信地址告诉给了“浏览器”。于是，“浏览器”又按张三提供通信地址给李四写信借钱，李四收到信后就把钱汇给了“浏览器”。可见，“浏览器”一共发出了两封信和收到了两次回复， “浏览器”也知道他借到的钱出自李四之手。RequestDispatcher.forward方 法在服务器端内部将请求转发给另外一个资源，浏览器只知道发出了请求并得到了响应结果，并不知道在服务器程序内部发生了转发行为。这个过程好比绰号叫“浏览器”的人写信找张三借钱，张三没有钱，于是张三找李四借了一些钱，甚至还可以加上自己的一些钱，然后再将这些钱汇给了“浏览器”。可见，“浏览器”只发 出了一封信和收到了一次回复，他只知道从张三那里借到了钱，并不知道有一部分钱出自李四之手。 \n\n（4）RequestDispatcher.forward方法的调用者与被调用者之间共享相同的request对象和response对象，它们属于同一个访问请求和响应过程；而HttpServletResponse.sendRedirect方法调用者与被调用者使用各自的request对象和response对象，它们属于两个独立的访问请求和响应过程。对于同一个WEB应用程序的内部资源之间的跳转，特别是跳转之前要对请求进行一些前期预处理，并要使用HttpServletRequest.setAttribute方法传递预处理结果，那就应该使用RequestDispatcher.forward方法。不同WEB应用程序之间的重定向，特别是要重定向到另外一个WEB站点上的资源的情况，都应该使用HttpServletResponse.sendRedirect方法。 \n\n（5）无论是RequestDispatcher.forward方法，还是HttpServletResponse.sendRedirect方法，在调用它们之前，都不能有内容已经被实际输出到了客户端。如果缓冲区中已经有了一些内容，这些内容将被从缓冲区中清除。\n","source":"_posts/2016-05-20-kongzheng1993-请求转发与重定向.md","raw":"---\nlayout: post\ntitle: \"请求转发和重定向\"\ndate: 2016-07-26\nexcerpt: \"getRequestDispatcher,forword,sendRedirect\"\ntags: [re]\ncomments: true\n---\n\n### 重定向与转发的区别：\n\n1.重定向访问服务器两次，转发只访问服务器一次。\n2.重定向可以看见目标页面的URL，转发只能看见第一次访问的页面URL，以后的工作都是有服务器来做的。\n3.重定向跳转后必须加上return，要不然页面虽然跳转了，但是还会执行跳转后面的语句，转发是执行了跳转页面，下面的代码就不会在执行了。\n4.在request级别使用信息共享，使用重定向必然出错\n5.还有一个大的区别就是，重定向可以访问自己web应用以外的资源\n\n\n### 一、调用方式 \n\n我们知道，在servlet中调用转发、重定向的语句如下： \nrequest.getRequestDispatcher(\"new.jsp\").forward(request, response);//转发到new.jsp \nresponse.sendRedirect(\"new.jsp\");//重定向到new.jsp \n\n在jsp页面中你也会看到通过下面的方式实现转发： \n<jsp:forward page=\"apage.jsp\" /> \n\n当然也可以在jsp页面中实现重定向： \n<%response.sendRedirect(\"new.jsp\");//重定向到new.jsp%> \n\n### 二、本质区别 \n\n#### 解释一　　 \n\n一句话，转发是服务器行为，重定向是客户端行为。为什么这样说呢，这就要看两个动作的工作流程： \n\n转发过程：客户浏览器发送http请求----》web服务器接受此请求--》调用内部的一个方法在容器内部完成请求处理和转发动作----》将目标资源发送给客户；在这里，转发的路径必须是同一个web容器下的url，其不能转向到其他的web路径上去，中间传递的是自己的容器内的request。在客户浏览器路径栏显示的仍然是其第一次访问的路径，也就是说客户是感觉不到服务器做了转发的。转发行为是浏览器只做了一次访问请求。 \n\n重定向过程：客户浏览器发送http请求----》web服务器接受后发送302状态码响应及对应新的location给客户浏览器--》客户浏览器发现是302响应，则自动再发送一个新的http请求，请求url是新的location地址----》服务器根据此请求寻找资源并发送给客户。在这里location可以重定向到任意URL，既然是浏览器重新发出了请求，则就没有什么request传递的概念了。在客户浏览器路径栏显示的是其重定向的路径，客户可以观察到地址的变化的。重定向行为是浏览器做了至少两次的访问请求的。 \n\n#### 解释二 \n重定向，其实是两次request, \n第一次，客户端request A,服务器响应，并response回来，告诉浏览器，你应该去B。这个时候IE可以看到地址变了，而且历史的回退按钮也亮了。重定向可以访问自己web应用以外的资源。在重定向的过程中，传输的信息会被丢失。 \n\n\n\n请求转发是服务器内部把对一个request/response的处理权，移交给另外一个 \n对于客户端而言，它只知道自己最早请求的那个A，而不知道中间的B，甚至C、D。 传输的信息不会丢失。 \n\n \n\n#### 解释三 \n假设你去办理某个执照， \n\n重定向：你先去了A局，A局的人说：“这个事情不归我们管，去B局”，然后，你就从A退了出来，自己乘车去了B局。 \n\n转发：你先去了A局，A局看了以后，知道这个事情其实应该B局来管，但是他没有把你退回来，而是让你坐一会儿，自己到后面办公室联系了B的人，让他们办好后，送了过来。 \n\n### 三、请求重定向与请求转发的比较 \n\n尽管HttpServletResponse.sendRedirect方法和RequestDispatcher.forward方法都可以让浏览器获得另外一个URL所指向的资源，但两者的内部运行机制有着很大的区别。下面是HttpServletResponse.sendRedirect方法实现的请求重定向与RequestDispatcher.forward方法实现的请求转发的总结比较： \n\n（1）RequestDispatcher.forward方法只能将请求转发给同一个WEB应用中的组件；而HttpServletResponse.sendRedirect 方法不仅可以重定向到当前应用程序中的其他资源，还可以重定向到同一个站点上的其他应用程序中的资源，甚至是使用绝对URL重定向到其他站点的资源。如果传递给HttpServletResponse.sendRedirect 方法的相对URL以“/”开头，它是相对于整个WEB站点的根目录；如果创建RequestDispatcher对象时指定的相对URL以“/”开头，它是相对于当前WEB应用程序的根目录。 \n\n（2）调用HttpServletResponse.sendRedirect方法重定向的访问过程结束后，浏览器地址栏中显示的URL会发生改变，由初始的URL地址变成重定向的目标URL；而调用RequestDispatcher.forward 方法的请求转发过程结束后，浏览器地址栏保持初始的URL地址不变。 \n\n（3）HttpServletResponse.sendRedirect方法对浏览器的请求直接作出响应，响应的结果就是告诉浏览器去重新发出对另外一个URL的 访问请求，这个过程好比有个绰号叫“浏览器”的人写信找张三借钱，张三回信说没有钱，让“浏览器”去找李四借，并将李四现在的通信地址告诉给了“浏览器”。于是，“浏览器”又按张三提供通信地址给李四写信借钱，李四收到信后就把钱汇给了“浏览器”。可见，“浏览器”一共发出了两封信和收到了两次回复， “浏览器”也知道他借到的钱出自李四之手。RequestDispatcher.forward方 法在服务器端内部将请求转发给另外一个资源，浏览器只知道发出了请求并得到了响应结果，并不知道在服务器程序内部发生了转发行为。这个过程好比绰号叫“浏览器”的人写信找张三借钱，张三没有钱，于是张三找李四借了一些钱，甚至还可以加上自己的一些钱，然后再将这些钱汇给了“浏览器”。可见，“浏览器”只发 出了一封信和收到了一次回复，他只知道从张三那里借到了钱，并不知道有一部分钱出自李四之手。 \n\n（4）RequestDispatcher.forward方法的调用者与被调用者之间共享相同的request对象和response对象，它们属于同一个访问请求和响应过程；而HttpServletResponse.sendRedirect方法调用者与被调用者使用各自的request对象和response对象，它们属于两个独立的访问请求和响应过程。对于同一个WEB应用程序的内部资源之间的跳转，特别是跳转之前要对请求进行一些前期预处理，并要使用HttpServletRequest.setAttribute方法传递预处理结果，那就应该使用RequestDispatcher.forward方法。不同WEB应用程序之间的重定向，特别是要重定向到另外一个WEB站点上的资源的情况，都应该使用HttpServletResponse.sendRedirect方法。 \n\n（5）无论是RequestDispatcher.forward方法，还是HttpServletResponse.sendRedirect方法，在调用它们之前，都不能有内容已经被实际输出到了客户端。如果缓冲区中已经有了一些内容，这些内容将被从缓冲区中清除。\n","slug":"kongzheng1993-请求转发与重定向","published":1,"updated":"2023-03-08T07:05:58.770Z","photos":[],"link":"","_id":"clg0k2aad0009t26f1kp4vfnf","content":"<h3 id=\"重定向与转发的区别：\"><a href=\"#重定向与转发的区别：\" class=\"headerlink\" title=\"重定向与转发的区别：\"></a>重定向与转发的区别：</h3><p>1.重定向访问服务器两次，转发只访问服务器一次。<br>2.重定向可以看见目标页面的URL，转发只能看见第一次访问的页面URL，以后的工作都是有服务器来做的。<br>3.重定向跳转后必须加上return，要不然页面虽然跳转了，但是还会执行跳转后面的语句，转发是执行了跳转页面，下面的代码就不会在执行了。<br>4.在request级别使用信息共享，使用重定向必然出错<br>5.还有一个大的区别就是，重定向可以访问自己web应用以外的资源</p>\n<h3 id=\"一、调用方式\"><a href=\"#一、调用方式\" class=\"headerlink\" title=\"一、调用方式\"></a>一、调用方式</h3><p>我们知道，在servlet中调用转发、重定向的语句如下：<br>request.getRequestDispatcher(“new.jsp”).forward(request, response);//转发到new.jsp<br>response.sendRedirect(“new.jsp”);//重定向到new.jsp </p>\n<p>在jsp页面中你也会看到通过下面的方式实现转发：<br>&lt;jsp:forward page=”apage.jsp” /&gt; </p>\n<p>当然也可以在jsp页面中实现重定向：<br>&lt;%response.sendRedirect(“new.jsp”);//重定向到new.jsp%&gt; </p>\n<h3 id=\"二、本质区别\"><a href=\"#二、本质区别\" class=\"headerlink\" title=\"二、本质区别\"></a>二、本质区别</h3><h4 id=\"解释一\"><a href=\"#解释一\" class=\"headerlink\" title=\"解释一　　\"></a>解释一　　</h4><p>一句话，转发是服务器行为，重定向是客户端行为。为什么这样说呢，这就要看两个动作的工作流程： </p>\n<p>转发过程：客户浏览器发送http请求—-》web服务器接受此请求–》调用内部的一个方法在容器内部完成请求处理和转发动作—-》将目标资源发送给客户；在这里，转发的路径必须是同一个web容器下的url，其不能转向到其他的web路径上去，中间传递的是自己的容器内的request。在客户浏览器路径栏显示的仍然是其第一次访问的路径，也就是说客户是感觉不到服务器做了转发的。转发行为是浏览器只做了一次访问请求。 </p>\n<p>重定向过程：客户浏览器发送http请求—-》web服务器接受后发送302状态码响应及对应新的location给客户浏览器–》客户浏览器发现是302响应，则自动再发送一个新的http请求，请求url是新的location地址—-》服务器根据此请求寻找资源并发送给客户。在这里location可以重定向到任意URL，既然是浏览器重新发出了请求，则就没有什么request传递的概念了。在客户浏览器路径栏显示的是其重定向的路径，客户可以观察到地址的变化的。重定向行为是浏览器做了至少两次的访问请求的。 </p>\n<h4 id=\"解释二\"><a href=\"#解释二\" class=\"headerlink\" title=\"解释二\"></a>解释二</h4><p>重定向，其实是两次request,<br>第一次，客户端request A,服务器响应，并response回来，告诉浏览器，你应该去B。这个时候IE可以看到地址变了，而且历史的回退按钮也亮了。重定向可以访问自己web应用以外的资源。在重定向的过程中，传输的信息会被丢失。 </p>\n<p>请求转发是服务器内部把对一个request/response的处理权，移交给另外一个<br>对于客户端而言，它只知道自己最早请求的那个A，而不知道中间的B，甚至C、D。 传输的信息不会丢失。 </p>\n<h4 id=\"解释三\"><a href=\"#解释三\" class=\"headerlink\" title=\"解释三\"></a>解释三</h4><p>假设你去办理某个执照， </p>\n<p>重定向：你先去了A局，A局的人说：“这个事情不归我们管，去B局”，然后，你就从A退了出来，自己乘车去了B局。 </p>\n<p>转发：你先去了A局，A局看了以后，知道这个事情其实应该B局来管，但是他没有把你退回来，而是让你坐一会儿，自己到后面办公室联系了B的人，让他们办好后，送了过来。 </p>\n<h3 id=\"三、请求重定向与请求转发的比较\"><a href=\"#三、请求重定向与请求转发的比较\" class=\"headerlink\" title=\"三、请求重定向与请求转发的比较\"></a>三、请求重定向与请求转发的比较</h3><p>尽管HttpServletResponse.sendRedirect方法和RequestDispatcher.forward方法都可以让浏览器获得另外一个URL所指向的资源，但两者的内部运行机制有着很大的区别。下面是HttpServletResponse.sendRedirect方法实现的请求重定向与RequestDispatcher.forward方法实现的请求转发的总结比较： </p>\n<p>（1）RequestDispatcher.forward方法只能将请求转发给同一个WEB应用中的组件；而HttpServletResponse.sendRedirect 方法不仅可以重定向到当前应用程序中的其他资源，还可以重定向到同一个站点上的其他应用程序中的资源，甚至是使用绝对URL重定向到其他站点的资源。如果传递给HttpServletResponse.sendRedirect 方法的相对URL以“/”开头，它是相对于整个WEB站点的根目录；如果创建RequestDispatcher对象时指定的相对URL以“/”开头，它是相对于当前WEB应用程序的根目录。 </p>\n<p>（2）调用HttpServletResponse.sendRedirect方法重定向的访问过程结束后，浏览器地址栏中显示的URL会发生改变，由初始的URL地址变成重定向的目标URL；而调用RequestDispatcher.forward 方法的请求转发过程结束后，浏览器地址栏保持初始的URL地址不变。 </p>\n<p>（3）HttpServletResponse.sendRedirect方法对浏览器的请求直接作出响应，响应的结果就是告诉浏览器去重新发出对另外一个URL的 访问请求，这个过程好比有个绰号叫“浏览器”的人写信找张三借钱，张三回信说没有钱，让“浏览器”去找李四借，并将李四现在的通信地址告诉给了“浏览器”。于是，“浏览器”又按张三提供通信地址给李四写信借钱，李四收到信后就把钱汇给了“浏览器”。可见，“浏览器”一共发出了两封信和收到了两次回复， “浏览器”也知道他借到的钱出自李四之手。RequestDispatcher.forward方 法在服务器端内部将请求转发给另外一个资源，浏览器只知道发出了请求并得到了响应结果，并不知道在服务器程序内部发生了转发行为。这个过程好比绰号叫“浏览器”的人写信找张三借钱，张三没有钱，于是张三找李四借了一些钱，甚至还可以加上自己的一些钱，然后再将这些钱汇给了“浏览器”。可见，“浏览器”只发 出了一封信和收到了一次回复，他只知道从张三那里借到了钱，并不知道有一部分钱出自李四之手。 </p>\n<p>（4）RequestDispatcher.forward方法的调用者与被调用者之间共享相同的request对象和response对象，它们属于同一个访问请求和响应过程；而HttpServletResponse.sendRedirect方法调用者与被调用者使用各自的request对象和response对象，它们属于两个独立的访问请求和响应过程。对于同一个WEB应用程序的内部资源之间的跳转，特别是跳转之前要对请求进行一些前期预处理，并要使用HttpServletRequest.setAttribute方法传递预处理结果，那就应该使用RequestDispatcher.forward方法。不同WEB应用程序之间的重定向，特别是要重定向到另外一个WEB站点上的资源的情况，都应该使用HttpServletResponse.sendRedirect方法。 </p>\n<p>（5）无论是RequestDispatcher.forward方法，还是HttpServletResponse.sendRedirect方法，在调用它们之前，都不能有内容已经被实际输出到了客户端。如果缓冲区中已经有了一些内容，这些内容将被从缓冲区中清除。</p>\n","site":{"data":{}},"more":"<h3 id=\"重定向与转发的区别：\"><a href=\"#重定向与转发的区别：\" class=\"headerlink\" title=\"重定向与转发的区别：\"></a>重定向与转发的区别：</h3><p>1.重定向访问服务器两次，转发只访问服务器一次。<br>2.重定向可以看见目标页面的URL，转发只能看见第一次访问的页面URL，以后的工作都是有服务器来做的。<br>3.重定向跳转后必须加上return，要不然页面虽然跳转了，但是还会执行跳转后面的语句，转发是执行了跳转页面，下面的代码就不会在执行了。<br>4.在request级别使用信息共享，使用重定向必然出错<br>5.还有一个大的区别就是，重定向可以访问自己web应用以外的资源</p>\n<h3 id=\"一、调用方式\"><a href=\"#一、调用方式\" class=\"headerlink\" title=\"一、调用方式\"></a>一、调用方式</h3><p>我们知道，在servlet中调用转发、重定向的语句如下：<br>request.getRequestDispatcher(“new.jsp”).forward(request, response);//转发到new.jsp<br>response.sendRedirect(“new.jsp”);//重定向到new.jsp </p>\n<p>在jsp页面中你也会看到通过下面的方式实现转发：<br>&lt;jsp:forward page=”apage.jsp” /&gt; </p>\n<p>当然也可以在jsp页面中实现重定向：<br>&lt;%response.sendRedirect(“new.jsp”);//重定向到new.jsp%&gt; </p>\n<h3 id=\"二、本质区别\"><a href=\"#二、本质区别\" class=\"headerlink\" title=\"二、本质区别\"></a>二、本质区别</h3><h4 id=\"解释一\"><a href=\"#解释一\" class=\"headerlink\" title=\"解释一　　\"></a>解释一　　</h4><p>一句话，转发是服务器行为，重定向是客户端行为。为什么这样说呢，这就要看两个动作的工作流程： </p>\n<p>转发过程：客户浏览器发送http请求—-》web服务器接受此请求–》调用内部的一个方法在容器内部完成请求处理和转发动作—-》将目标资源发送给客户；在这里，转发的路径必须是同一个web容器下的url，其不能转向到其他的web路径上去，中间传递的是自己的容器内的request。在客户浏览器路径栏显示的仍然是其第一次访问的路径，也就是说客户是感觉不到服务器做了转发的。转发行为是浏览器只做了一次访问请求。 </p>\n<p>重定向过程：客户浏览器发送http请求—-》web服务器接受后发送302状态码响应及对应新的location给客户浏览器–》客户浏览器发现是302响应，则自动再发送一个新的http请求，请求url是新的location地址—-》服务器根据此请求寻找资源并发送给客户。在这里location可以重定向到任意URL，既然是浏览器重新发出了请求，则就没有什么request传递的概念了。在客户浏览器路径栏显示的是其重定向的路径，客户可以观察到地址的变化的。重定向行为是浏览器做了至少两次的访问请求的。 </p>\n<h4 id=\"解释二\"><a href=\"#解释二\" class=\"headerlink\" title=\"解释二\"></a>解释二</h4><p>重定向，其实是两次request,<br>第一次，客户端request A,服务器响应，并response回来，告诉浏览器，你应该去B。这个时候IE可以看到地址变了，而且历史的回退按钮也亮了。重定向可以访问自己web应用以外的资源。在重定向的过程中，传输的信息会被丢失。 </p>\n<p>请求转发是服务器内部把对一个request/response的处理权，移交给另外一个<br>对于客户端而言，它只知道自己最早请求的那个A，而不知道中间的B，甚至C、D。 传输的信息不会丢失。 </p>\n<h4 id=\"解释三\"><a href=\"#解释三\" class=\"headerlink\" title=\"解释三\"></a>解释三</h4><p>假设你去办理某个执照， </p>\n<p>重定向：你先去了A局，A局的人说：“这个事情不归我们管，去B局”，然后，你就从A退了出来，自己乘车去了B局。 </p>\n<p>转发：你先去了A局，A局看了以后，知道这个事情其实应该B局来管，但是他没有把你退回来，而是让你坐一会儿，自己到后面办公室联系了B的人，让他们办好后，送了过来。 </p>\n<h3 id=\"三、请求重定向与请求转发的比较\"><a href=\"#三、请求重定向与请求转发的比较\" class=\"headerlink\" title=\"三、请求重定向与请求转发的比较\"></a>三、请求重定向与请求转发的比较</h3><p>尽管HttpServletResponse.sendRedirect方法和RequestDispatcher.forward方法都可以让浏览器获得另外一个URL所指向的资源，但两者的内部运行机制有着很大的区别。下面是HttpServletResponse.sendRedirect方法实现的请求重定向与RequestDispatcher.forward方法实现的请求转发的总结比较： </p>\n<p>（1）RequestDispatcher.forward方法只能将请求转发给同一个WEB应用中的组件；而HttpServletResponse.sendRedirect 方法不仅可以重定向到当前应用程序中的其他资源，还可以重定向到同一个站点上的其他应用程序中的资源，甚至是使用绝对URL重定向到其他站点的资源。如果传递给HttpServletResponse.sendRedirect 方法的相对URL以“/”开头，它是相对于整个WEB站点的根目录；如果创建RequestDispatcher对象时指定的相对URL以“/”开头，它是相对于当前WEB应用程序的根目录。 </p>\n<p>（2）调用HttpServletResponse.sendRedirect方法重定向的访问过程结束后，浏览器地址栏中显示的URL会发生改变，由初始的URL地址变成重定向的目标URL；而调用RequestDispatcher.forward 方法的请求转发过程结束后，浏览器地址栏保持初始的URL地址不变。 </p>\n<p>（3）HttpServletResponse.sendRedirect方法对浏览器的请求直接作出响应，响应的结果就是告诉浏览器去重新发出对另外一个URL的 访问请求，这个过程好比有个绰号叫“浏览器”的人写信找张三借钱，张三回信说没有钱，让“浏览器”去找李四借，并将李四现在的通信地址告诉给了“浏览器”。于是，“浏览器”又按张三提供通信地址给李四写信借钱，李四收到信后就把钱汇给了“浏览器”。可见，“浏览器”一共发出了两封信和收到了两次回复， “浏览器”也知道他借到的钱出自李四之手。RequestDispatcher.forward方 法在服务器端内部将请求转发给另外一个资源，浏览器只知道发出了请求并得到了响应结果，并不知道在服务器程序内部发生了转发行为。这个过程好比绰号叫“浏览器”的人写信找张三借钱，张三没有钱，于是张三找李四借了一些钱，甚至还可以加上自己的一些钱，然后再将这些钱汇给了“浏览器”。可见，“浏览器”只发 出了一封信和收到了一次回复，他只知道从张三那里借到了钱，并不知道有一部分钱出自李四之手。 </p>\n<p>（4）RequestDispatcher.forward方法的调用者与被调用者之间共享相同的request对象和response对象，它们属于同一个访问请求和响应过程；而HttpServletResponse.sendRedirect方法调用者与被调用者使用各自的request对象和response对象，它们属于两个独立的访问请求和响应过程。对于同一个WEB应用程序的内部资源之间的跳转，特别是跳转之前要对请求进行一些前期预处理，并要使用HttpServletRequest.setAttribute方法传递预处理结果，那就应该使用RequestDispatcher.forward方法。不同WEB应用程序之间的重定向，特别是要重定向到另外一个WEB站点上的资源的情况，都应该使用HttpServletResponse.sendRedirect方法。 </p>\n<p>（5）无论是RequestDispatcher.forward方法，还是HttpServletResponse.sendRedirect方法，在调用它们之前，都不能有内容已经被实际输出到了客户端。如果缓冲区中已经有了一些内容，这些内容将被从缓冲区中清除。</p>\n"},{"layout":"post","title":"String str","date":"2016-07-10T16:00:00.000Z","excerpt":"","comments":1,"_content":"\n\nString str=new String(\"abc\"); 跟着这段代码之后，我们会想到一个问题，就是这行代码究竟创建了几个String对象呢？\n答案是2个。\nString str只是定义了一个名为str的String类型的变量，因此它并没有创建对象；=是对变量str进行初始化，将某个对象的引用（或者叫句柄）赋值给它，显然也没有创建对象；现在只剩下了new String(\"abc\")了。那么，new String(\"abc\")什么又能被看作成“abc”和\nnew String()呢？\n这就要了解一下String的构造器：\npublic String (String original){\n\t//other code...\n}\n平常我们创建一个类的实例的方法有两种：\n1.使用new创建对象；\n2.调用Class类里面的newInstance方法，利用反射机制创建对象。\n\n我们正是使用new调用了String类的上面那个构造器方法创建了一个对象，并将它的引用赋值给了str变量。同时我们注意到，被调用的构造器方法接受的参数也是一个String对象，这个对象正是\"abc\"。由此我们又要引入另外一种创建String对象的方式的讨论——引号内包含文本。\n\n这种方式是String特有的，并且它与new的方式存在很大区别。  \n\nString str=\"abc\";  \n\n毫无疑问，这行代码创建了一个String对象。  \n\nString a=\"abc\";  String b=\"abc\";   那这里呢？\n\n答案还是一个。  \n\nString a=\"ab\"+\"cd\";   再看看这里呢？\n\n答案是三个。\n说到这里，我们就需要引入对字符串池相关知识的回顾了。  \n\n在JAVA虚拟机（JVM）中存在着一个字符串池，其中保存着很多String对象，并且可以被共享使用，因此它提高了效率。由于String类是final的，它的值一经创建就不可改变，因此我们不用担心String对象共享而带来程序的混乱。字符串池由String类维护，我们可以调用intern()方法来访问字符串池。  \n\n我们再回头看看String a=\"abc\";，这行代码被执行的时候，JAVA虚拟机首先在字符串池中查找是否已经存在了值为\"abc\"的这么一个对象，它的判断依据是String类equals(Object obj)方法的返回值。如果有，则不再创建新的对象，直接返回已存在对象的引用；如果没有，则先创建这个对象，然后把它加入到字符串池中，再将它的引用返回。因此，我们不难理解前面三个例子中头两个例子为什么是这个答案了。\n\n \n\n只有使用引号包含文本的方式创建的String对象之间使用“+”连接产生的新对象才会被加入字符串池中。对于所有包含new方式新建对象（包括null）的“+”连接表达式，它所产生的新对象都不会被加入字符串池中，对此我们不再赘述。因此我们提倡大家用引号包含文本的方式来创建String对象以提高效率，实际上这也是我们在编程中常采用的。\n\n \n\n栈（stack）：主要保存基本类型（或者叫内置类型）（char、byte、short、int、long、float、double、boolean）和对象的引用，数据可以共享，速度仅次于寄存器（register），快于堆。 \n堆（heap）：用于存储对象\n\n\n\n\n\n\n\n\n\n\n<html>\n<div class=\"ds-thread\" data-thread-key=\"http://kongzheng1993.github.io/kongzheng1993-String_Original/\" data-title=\"String_Original\" data-url=\"http://kongzheng1993.github.io/kongzheng1993-String_Original/\"></div>\n<!-- 多说评论框 end -->\n<!-- 多说公共JS代码 start (一个网页只需插入一次) -->\n<script type=\"text/javascript\">\nvar duoshuoQuery = {short_name:\"kongzheng1993\"};\n    (function() {\n        var ds = document.createElement('script');\n        ds.type = 'text/javascript';ds.async = true;\n        ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';\n        ds.charset = 'UTF-8';\n        (document.getElementsByTagName('head')[0] \n         || document.getElementsByTagName('body')[0]).appendChild(ds);\n    })();\n</script>\n</html>\n","source":"_posts/2016-06-13-kongzheng1993-String_Original.md","raw":"---\nlayout: post\ntitle: \"String str\"\ndate: 2016-07-11\nexcerpt: \"code or die\"\ntags: [String, new]\ncomments: true\n---\n\n\nString str=new String(\"abc\"); 跟着这段代码之后，我们会想到一个问题，就是这行代码究竟创建了几个String对象呢？\n答案是2个。\nString str只是定义了一个名为str的String类型的变量，因此它并没有创建对象；=是对变量str进行初始化，将某个对象的引用（或者叫句柄）赋值给它，显然也没有创建对象；现在只剩下了new String(\"abc\")了。那么，new String(\"abc\")什么又能被看作成“abc”和\nnew String()呢？\n这就要了解一下String的构造器：\npublic String (String original){\n\t//other code...\n}\n平常我们创建一个类的实例的方法有两种：\n1.使用new创建对象；\n2.调用Class类里面的newInstance方法，利用反射机制创建对象。\n\n我们正是使用new调用了String类的上面那个构造器方法创建了一个对象，并将它的引用赋值给了str变量。同时我们注意到，被调用的构造器方法接受的参数也是一个String对象，这个对象正是\"abc\"。由此我们又要引入另外一种创建String对象的方式的讨论——引号内包含文本。\n\n这种方式是String特有的，并且它与new的方式存在很大区别。  \n\nString str=\"abc\";  \n\n毫无疑问，这行代码创建了一个String对象。  \n\nString a=\"abc\";  String b=\"abc\";   那这里呢？\n\n答案还是一个。  \n\nString a=\"ab\"+\"cd\";   再看看这里呢？\n\n答案是三个。\n说到这里，我们就需要引入对字符串池相关知识的回顾了。  \n\n在JAVA虚拟机（JVM）中存在着一个字符串池，其中保存着很多String对象，并且可以被共享使用，因此它提高了效率。由于String类是final的，它的值一经创建就不可改变，因此我们不用担心String对象共享而带来程序的混乱。字符串池由String类维护，我们可以调用intern()方法来访问字符串池。  \n\n我们再回头看看String a=\"abc\";，这行代码被执行的时候，JAVA虚拟机首先在字符串池中查找是否已经存在了值为\"abc\"的这么一个对象，它的判断依据是String类equals(Object obj)方法的返回值。如果有，则不再创建新的对象，直接返回已存在对象的引用；如果没有，则先创建这个对象，然后把它加入到字符串池中，再将它的引用返回。因此，我们不难理解前面三个例子中头两个例子为什么是这个答案了。\n\n \n\n只有使用引号包含文本的方式创建的String对象之间使用“+”连接产生的新对象才会被加入字符串池中。对于所有包含new方式新建对象（包括null）的“+”连接表达式，它所产生的新对象都不会被加入字符串池中，对此我们不再赘述。因此我们提倡大家用引号包含文本的方式来创建String对象以提高效率，实际上这也是我们在编程中常采用的。\n\n \n\n栈（stack）：主要保存基本类型（或者叫内置类型）（char、byte、short、int、long、float、double、boolean）和对象的引用，数据可以共享，速度仅次于寄存器（register），快于堆。 \n堆（heap）：用于存储对象\n\n\n\n\n\n\n\n\n\n\n<html>\n<div class=\"ds-thread\" data-thread-key=\"http://kongzheng1993.github.io/kongzheng1993-String_Original/\" data-title=\"String_Original\" data-url=\"http://kongzheng1993.github.io/kongzheng1993-String_Original/\"></div>\n<!-- 多说评论框 end -->\n<!-- 多说公共JS代码 start (一个网页只需插入一次) -->\n<script type=\"text/javascript\">\nvar duoshuoQuery = {short_name:\"kongzheng1993\"};\n    (function() {\n        var ds = document.createElement('script');\n        ds.type = 'text/javascript';ds.async = true;\n        ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';\n        ds.charset = 'UTF-8';\n        (document.getElementsByTagName('head')[0] \n         || document.getElementsByTagName('body')[0]).appendChild(ds);\n    })();\n</script>\n</html>\n","slug":"kongzheng1993-String_Original","published":1,"updated":"2023-03-08T07:05:58.771Z","photos":[],"link":"","_id":"clg0k2aaw000ct26fc374fm3g","content":"<p>String str=new String(“abc”); 跟着这段代码之后，我们会想到一个问题，就是这行代码究竟创建了几个String对象呢？<br>答案是2个。<br>String str只是定义了一个名为str的String类型的变量，因此它并没有创建对象；=是对变量str进行初始化，将某个对象的引用（或者叫句柄）赋值给它，显然也没有创建对象；现在只剩下了new String(“abc”)了。那么，new String(“abc”)什么又能被看作成“abc”和<br>new String()呢？<br>这就要了解一下String的构造器：<br>public String (String original){<br>    //other code…<br>}\n平常我们创建一个类的实例的方法有两种：<br>1.使用new创建对象；<br>2.调用Class类里面的newInstance方法，利用反射机制创建对象。</p>\n<p>我们正是使用new调用了String类的上面那个构造器方法创建了一个对象，并将它的引用赋值给了str变量。同时我们注意到，被调用的构造器方法接受的参数也是一个String对象，这个对象正是”abc”。由此我们又要引入另外一种创建String对象的方式的讨论——引号内包含文本。</p>\n<p>这种方式是String特有的，并且它与new的方式存在很大区别。  </p>\n<p>String str=”abc”;  </p>\n<p>毫无疑问，这行代码创建了一个String对象。  </p>\n<p>String a=”abc”;  String b=”abc”;   那这里呢？</p>\n<p>答案还是一个。  </p>\n<p>String a=”ab”+”cd”;   再看看这里呢？</p>\n<p>答案是三个。<br>说到这里，我们就需要引入对字符串池相关知识的回顾了。  </p>\n<p>在JAVA虚拟机（JVM）中存在着一个字符串池，其中保存着很多String对象，并且可以被共享使用，因此它提高了效率。由于String类是final的，它的值一经创建就不可改变，因此我们不用担心String对象共享而带来程序的混乱。字符串池由String类维护，我们可以调用intern()方法来访问字符串池。  </p>\n<p>我们再回头看看String a=”abc”;，这行代码被执行的时候，JAVA虚拟机首先在字符串池中查找是否已经存在了值为”abc”的这么一个对象，它的判断依据是String类equals(Object obj)方法的返回值。如果有，则不再创建新的对象，直接返回已存在对象的引用；如果没有，则先创建这个对象，然后把它加入到字符串池中，再将它的引用返回。因此，我们不难理解前面三个例子中头两个例子为什么是这个答案了。</p>\n<p>只有使用引号包含文本的方式创建的String对象之间使用“+”连接产生的新对象才会被加入字符串池中。对于所有包含new方式新建对象（包括null）的“+”连接表达式，它所产生的新对象都不会被加入字符串池中，对此我们不再赘述。因此我们提倡大家用引号包含文本的方式来创建String对象以提高效率，实际上这也是我们在编程中常采用的。</p>\n<p>栈（stack）：主要保存基本类型（或者叫内置类型）（char、byte、short、int、long、float、double、boolean）和对象的引用，数据可以共享，速度仅次于寄存器（register），快于堆。<br>堆（heap）：用于存储对象</p>\n<html>\n<div class=\"ds-thread\" data-thread-key=\"http://kongzheng1993.github.io/kongzheng1993-String_Original/\" data-title=\"String_Original\" data-url=\"http://kongzheng1993.github.io/kongzheng1993-String_Original/\"></div>\n<!-- 多说评论框 end -->\n<!-- 多说公共JS代码 start (一个网页只需插入一次) -->\n<script type=\"text/javascript\">\nvar duoshuoQuery = {short_name:\"kongzheng1993\"};\n    (function() {\n        var ds = document.createElement('script');\n        ds.type = 'text/javascript';ds.async = true;\n        ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';\n        ds.charset = 'UTF-8';\n        (document.getElementsByTagName('head')[0] \n         || document.getElementsByTagName('body')[0]).appendChild(ds);\n    })();\n</script>\n</html>\n","site":{"data":{}},"more":"<p>String str=new String(“abc”); 跟着这段代码之后，我们会想到一个问题，就是这行代码究竟创建了几个String对象呢？<br>答案是2个。<br>String str只是定义了一个名为str的String类型的变量，因此它并没有创建对象；=是对变量str进行初始化，将某个对象的引用（或者叫句柄）赋值给它，显然也没有创建对象；现在只剩下了new String(“abc”)了。那么，new String(“abc”)什么又能被看作成“abc”和<br>new String()呢？<br>这就要了解一下String的构造器：<br>public String (String original){<br>    //other code…<br>}\n平常我们创建一个类的实例的方法有两种：<br>1.使用new创建对象；<br>2.调用Class类里面的newInstance方法，利用反射机制创建对象。</p>\n<p>我们正是使用new调用了String类的上面那个构造器方法创建了一个对象，并将它的引用赋值给了str变量。同时我们注意到，被调用的构造器方法接受的参数也是一个String对象，这个对象正是”abc”。由此我们又要引入另外一种创建String对象的方式的讨论——引号内包含文本。</p>\n<p>这种方式是String特有的，并且它与new的方式存在很大区别。  </p>\n<p>String str=”abc”;  </p>\n<p>毫无疑问，这行代码创建了一个String对象。  </p>\n<p>String a=”abc”;  String b=”abc”;   那这里呢？</p>\n<p>答案还是一个。  </p>\n<p>String a=”ab”+”cd”;   再看看这里呢？</p>\n<p>答案是三个。<br>说到这里，我们就需要引入对字符串池相关知识的回顾了。  </p>\n<p>在JAVA虚拟机（JVM）中存在着一个字符串池，其中保存着很多String对象，并且可以被共享使用，因此它提高了效率。由于String类是final的，它的值一经创建就不可改变，因此我们不用担心String对象共享而带来程序的混乱。字符串池由String类维护，我们可以调用intern()方法来访问字符串池。  </p>\n<p>我们再回头看看String a=”abc”;，这行代码被执行的时候，JAVA虚拟机首先在字符串池中查找是否已经存在了值为”abc”的这么一个对象，它的判断依据是String类equals(Object obj)方法的返回值。如果有，则不再创建新的对象，直接返回已存在对象的引用；如果没有，则先创建这个对象，然后把它加入到字符串池中，再将它的引用返回。因此，我们不难理解前面三个例子中头两个例子为什么是这个答案了。</p>\n<p>只有使用引号包含文本的方式创建的String对象之间使用“+”连接产生的新对象才会被加入字符串池中。对于所有包含new方式新建对象（包括null）的“+”连接表达式，它所产生的新对象都不会被加入字符串池中，对此我们不再赘述。因此我们提倡大家用引号包含文本的方式来创建String对象以提高效率，实际上这也是我们在编程中常采用的。</p>\n<p>栈（stack）：主要保存基本类型（或者叫内置类型）（char、byte、short、int、long、float、double、boolean）和对象的引用，数据可以共享，速度仅次于寄存器（register），快于堆。<br>堆（heap）：用于存储对象</p>\n<html>\n<div class=\"ds-thread\" data-thread-key=\"http://kongzheng1993.github.io/kongzheng1993-String_Original/\" data-title=\"String_Original\" data-url=\"http://kongzheng1993.github.io/kongzheng1993-String_Original/\"></div>\n<!-- 多说评论框 end -->\n<!-- 多说公共JS代码 start (一个网页只需插入一次) -->\n<script type=\"text/javascript\">\nvar duoshuoQuery = {short_name:\"kongzheng1993\"};\n    (function() {\n        var ds = document.createElement('script');\n        ds.type = 'text/javascript';ds.async = true;\n        ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';\n        ds.charset = 'UTF-8';\n        (document.getElementsByTagName('head')[0] \n         || document.getElementsByTagName('body')[0]).appendChild(ds);\n    })();\n</script>\n</html>\n"},{"layout":"post","title":"几种常见的内部排序","date":"2016-06-09T16:00:00.000Z","excerpt":"","comments":1,"_content":"\n## 概论\n\n排序有内部排序和外部排序，内部排序是数据记录在内存中进行排序，而外部排序是因排序的数据很大，一次不能容纳全部的排序记录，在排序过程中需要访问外存。\n\n我整理的排序就是内部排序。\n\n\n\n当数据较多时应该采用时间复杂度为o(nlog2n)的排序方法：快速排序、堆排序、归并排序\n\n快速排序是这几种内部排序中最好的方法，想待排序的关键字是随机分布时，快速排序的平均时间最短。\n\n \n\n## 直接插入排序\n\n### 思想\n\n将一个记录插入到已排序好的有序表中，从而得到一个新，记录数增1的有序表。即：先将序列的第1个记录看成是一个有序的子序列，然后从第2个记录逐个进行插入，直至整个序列有序为止。\n\n### 要点\n设立哨兵，作为临时存储和判断数组边界之用。\n\n如果碰见一个和插入元素相等的，那么插入元素把想插入的元素放在相等元素的后面。所以，相等元素的前后顺序没有改变，从原无序序列出去的顺序就是排好序后的顺序，所以插入排序是稳定的。\n\n### 代码\n```\npublic void insertSort(int[] a){\n    int i, j, k;\nfor (i = 1; i < a.length; i++) {\n             //为a[i]在前面的a[0...i-1]有序区间中找一个合适的位置\n            for (j = i - 1; j >= 0; j--)//这里判断是j>=0也可以防止数组越界，很巧妙\n                 if (a[j] < a[i])\n                     break;\n             //如找到了一个合适的位置\n             if (j != i - 1) {\n                 //将比a[i]大的数据向后移\n                 int temp = a[i];\n                 for (k = i - 1; k > j; k--)\n                     a[k + 1] = a[k];\n                 //将a[i]放到正确位置上\n                 a[k + 1] = temp;\n             }\n         }\n}\n```\n### 效率\n\n时间复杂度：O（n^2）.\n\n其他的插入排序有二分插入排序，2-路插入排序。\n\n## 简单选择排序\n\n### 基本思想\n\n在要排序的一组数中，选出最小（或者最大）的一个数与第1个位置的数交换；然后在剩下的数当中再找最小（或者最大）的与第2个位置的数交换，依次类推，直到第n-1个元素（倒数第二个数）和第n个元素（最后一个数）比较为止。\n\n### 操作方法\n\n第一趟，从n 个记录中找出关键码最小的记录与第一个记录交换；\n\n第二趟，从第二个记录开始的n-1 个记录中再选出关键码最小的记录与第二个记录交换；\n\n以此类推.....\n\n第i 趟，则从第i 个记录开始的n-i+1 个记录中选出关键码最小的记录与第i 个记录交换，\n\n直到整个序列按关键码有序。\n\n### 代码\n```\npublic void selectSort(int a[]){\n    int index,temp;\n    //index保存目前最小的数据的下标\n    //找出最小的数据的位置\n    for (int i=0;i<a.length ;i++) {\n        index=i;//因为每次排完序前面的都是有序的了，前面的肯定比第i个小，所以让index=i，减少不必要的麻烦\n        for (int j=i;j<a.length ;j++ ) {\n            if (a[j]<a[index]) {\n            index=j;\n            }        \n        }\n        System.out.println(\"第\"+i+\"次找到的最小值的下标是：\"+index);\n        if(index!=i)\n            {\n                temp=a[index];//找到无序数列里面的最小值并于当前位置(i)交换\n                a[index]=a[i];\n                a[i]=temp;\n            }\n        for (int m=0; m<a.length;m++ ) {\n            System.out.print(a[m]+\" \");\n\n        }\n        System.out.println();\n    }\n    \n}\n```\n## 简单选择排序的改进 --二元选择排序\n\n简单选择排序，每趟只能确定一个元素排序后的定位，我们可以考虑改进为每趟确定两个元素，也就是最大值和最小值的位置，从而减少循环次数，改进后对n个数据进行排序，最多只需进行[n/2]趟循环。\n\n### 代码\n```\n//这个算法因为比较的是大小，将min和max都记录下来，交换到当前坐标，但是如果数组中有相同的值，他们也会不论你这是交换还是不交换，都不会改变结果，所以这个方法不适用于有相同数据的数组\nvoid selectSort_double(int a[]){\n    int min,max,temp;\n    for (int i=0;i<=a.length/2;i++ ) {\n        min=i;max=i;\n        for (int j=i;j<a.length-i;j++) {\n            if(a[j]<a[min]){\n                min=j;\n                System.out.println(\"min=\"+min);\n                continue;//如果当前左边的数据小于当前最小值，那么它必定小于最大值，直接进入下一次循环\n            }\n            if (a[j]>a[max]) {\n                max=j;\n                System.out.println(\"max=\"+max);\n            }   \n        }\n        System.out.println(\"第\"+i+\"次找到的最小值的下标是：\"+min+\";第\"+i+\"次找到的最大值的下标是：\"+max);\n        temp=a[i];a[i]=a[min];a[min]=temp;\n        temp=a[a.length-i-1];a[a.length-i-1]=a[max];a[max]=temp;\n        for (int w=0;w<a.length ;w++ ) {\n            System.out.print(a[w]+\" \");\n        }\n        temp=a[a.length-i-1];a[a.length-i-1]=a[max];a[max]=temp;\n        System.out.println();\n    }\n}\n```\n## 冒泡排序\n\n### 基本思想\n\n冒泡排序是相继比较交换两个相邻位置的值，每次排序都确定一个值的位置，就像冒泡一样\n\n### 代码\n\n```\npublic class BubbleSort1{\n\n    public void bubble(int a[]){\n\n        for (int i=0;i<a.length;i++ ) {\n            for (int j=0;j<a.length-i-1 ;j++ ) {\n                \n                if (a[j]>a[j+1]) {\n                    int temp=a[j];\n                    a[j]=a[j+1];\n                    a[j+1]=temp;\n                }\n                // out(a);\n\n            }\n            out(a);\n}\n    }\n    public void out(int a[]){\n        for (int i=0;i<a.length ;i++ ) {\n            System.out.print(a[i]+\" \");\n        }\n        System.out.println();\n    }\n    public static void main(String[] args) {\n        BubbleSort1 bu=new BubbleSort1();\n        int arr[]={2,5,1,3,6,9,7};\n        // bu.out(arr);\n        bu.bubble(arr);\n        // bu.out(arr);\n        System.out.println(\"hello world\");\n    }\n\n\n}\n\n```\n\n\n<html>\n<div class=\"ds-thread\" data-thread-key=\"http://kongzheng1993.github.io/kongzheng1993-thewayofsort/\" data-title=\"thewayofsort\" data-url=\"http://kongzheng1993.github.io/kongzheng1993\"></div>\n<!-- 多说评论框 end -->\n<!-- 多说公共JS代码 start (一个网页只需插入一次) -->\n<script type=\"text/javascript\">\nvar duoshuoQuery = {short_name:\"kongzheng1993\"};\n    (function() {\n        var ds = document.createElement('script');\n        ds.type = 'text/javascript';ds.async = true;\n        ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';\n        ds.charset = 'UTF-8';\n        (document.getElementsByTagName('head')[0] \n         || document.getElementsByTagName('body')[0]).appendChild(ds);\n    })();\n</script>\n</html>\n","source":"_posts/2016-06-10-kongzheng1993-thewayofsort.md","raw":"---\nlayout: post\ntitle: \"几种常见的内部排序\"\ndate: 2016-06-10\nexcerpt: \"介绍几种经典的内部排序\"\ntags: [sample post, images, test]\ncomments: true\n---\n\n## 概论\n\n排序有内部排序和外部排序，内部排序是数据记录在内存中进行排序，而外部排序是因排序的数据很大，一次不能容纳全部的排序记录，在排序过程中需要访问外存。\n\n我整理的排序就是内部排序。\n\n\n\n当数据较多时应该采用时间复杂度为o(nlog2n)的排序方法：快速排序、堆排序、归并排序\n\n快速排序是这几种内部排序中最好的方法，想待排序的关键字是随机分布时，快速排序的平均时间最短。\n\n \n\n## 直接插入排序\n\n### 思想\n\n将一个记录插入到已排序好的有序表中，从而得到一个新，记录数增1的有序表。即：先将序列的第1个记录看成是一个有序的子序列，然后从第2个记录逐个进行插入，直至整个序列有序为止。\n\n### 要点\n设立哨兵，作为临时存储和判断数组边界之用。\n\n如果碰见一个和插入元素相等的，那么插入元素把想插入的元素放在相等元素的后面。所以，相等元素的前后顺序没有改变，从原无序序列出去的顺序就是排好序后的顺序，所以插入排序是稳定的。\n\n### 代码\n```\npublic void insertSort(int[] a){\n    int i, j, k;\nfor (i = 1; i < a.length; i++) {\n             //为a[i]在前面的a[0...i-1]有序区间中找一个合适的位置\n            for (j = i - 1; j >= 0; j--)//这里判断是j>=0也可以防止数组越界，很巧妙\n                 if (a[j] < a[i])\n                     break;\n             //如找到了一个合适的位置\n             if (j != i - 1) {\n                 //将比a[i]大的数据向后移\n                 int temp = a[i];\n                 for (k = i - 1; k > j; k--)\n                     a[k + 1] = a[k];\n                 //将a[i]放到正确位置上\n                 a[k + 1] = temp;\n             }\n         }\n}\n```\n### 效率\n\n时间复杂度：O（n^2）.\n\n其他的插入排序有二分插入排序，2-路插入排序。\n\n## 简单选择排序\n\n### 基本思想\n\n在要排序的一组数中，选出最小（或者最大）的一个数与第1个位置的数交换；然后在剩下的数当中再找最小（或者最大）的与第2个位置的数交换，依次类推，直到第n-1个元素（倒数第二个数）和第n个元素（最后一个数）比较为止。\n\n### 操作方法\n\n第一趟，从n 个记录中找出关键码最小的记录与第一个记录交换；\n\n第二趟，从第二个记录开始的n-1 个记录中再选出关键码最小的记录与第二个记录交换；\n\n以此类推.....\n\n第i 趟，则从第i 个记录开始的n-i+1 个记录中选出关键码最小的记录与第i 个记录交换，\n\n直到整个序列按关键码有序。\n\n### 代码\n```\npublic void selectSort(int a[]){\n    int index,temp;\n    //index保存目前最小的数据的下标\n    //找出最小的数据的位置\n    for (int i=0;i<a.length ;i++) {\n        index=i;//因为每次排完序前面的都是有序的了，前面的肯定比第i个小，所以让index=i，减少不必要的麻烦\n        for (int j=i;j<a.length ;j++ ) {\n            if (a[j]<a[index]) {\n            index=j;\n            }        \n        }\n        System.out.println(\"第\"+i+\"次找到的最小值的下标是：\"+index);\n        if(index!=i)\n            {\n                temp=a[index];//找到无序数列里面的最小值并于当前位置(i)交换\n                a[index]=a[i];\n                a[i]=temp;\n            }\n        for (int m=0; m<a.length;m++ ) {\n            System.out.print(a[m]+\" \");\n\n        }\n        System.out.println();\n    }\n    \n}\n```\n## 简单选择排序的改进 --二元选择排序\n\n简单选择排序，每趟只能确定一个元素排序后的定位，我们可以考虑改进为每趟确定两个元素，也就是最大值和最小值的位置，从而减少循环次数，改进后对n个数据进行排序，最多只需进行[n/2]趟循环。\n\n### 代码\n```\n//这个算法因为比较的是大小，将min和max都记录下来，交换到当前坐标，但是如果数组中有相同的值，他们也会不论你这是交换还是不交换，都不会改变结果，所以这个方法不适用于有相同数据的数组\nvoid selectSort_double(int a[]){\n    int min,max,temp;\n    for (int i=0;i<=a.length/2;i++ ) {\n        min=i;max=i;\n        for (int j=i;j<a.length-i;j++) {\n            if(a[j]<a[min]){\n                min=j;\n                System.out.println(\"min=\"+min);\n                continue;//如果当前左边的数据小于当前最小值，那么它必定小于最大值，直接进入下一次循环\n            }\n            if (a[j]>a[max]) {\n                max=j;\n                System.out.println(\"max=\"+max);\n            }   \n        }\n        System.out.println(\"第\"+i+\"次找到的最小值的下标是：\"+min+\";第\"+i+\"次找到的最大值的下标是：\"+max);\n        temp=a[i];a[i]=a[min];a[min]=temp;\n        temp=a[a.length-i-1];a[a.length-i-1]=a[max];a[max]=temp;\n        for (int w=0;w<a.length ;w++ ) {\n            System.out.print(a[w]+\" \");\n        }\n        temp=a[a.length-i-1];a[a.length-i-1]=a[max];a[max]=temp;\n        System.out.println();\n    }\n}\n```\n## 冒泡排序\n\n### 基本思想\n\n冒泡排序是相继比较交换两个相邻位置的值，每次排序都确定一个值的位置，就像冒泡一样\n\n### 代码\n\n```\npublic class BubbleSort1{\n\n    public void bubble(int a[]){\n\n        for (int i=0;i<a.length;i++ ) {\n            for (int j=0;j<a.length-i-1 ;j++ ) {\n                \n                if (a[j]>a[j+1]) {\n                    int temp=a[j];\n                    a[j]=a[j+1];\n                    a[j+1]=temp;\n                }\n                // out(a);\n\n            }\n            out(a);\n}\n    }\n    public void out(int a[]){\n        for (int i=0;i<a.length ;i++ ) {\n            System.out.print(a[i]+\" \");\n        }\n        System.out.println();\n    }\n    public static void main(String[] args) {\n        BubbleSort1 bu=new BubbleSort1();\n        int arr[]={2,5,1,3,6,9,7};\n        // bu.out(arr);\n        bu.bubble(arr);\n        // bu.out(arr);\n        System.out.println(\"hello world\");\n    }\n\n\n}\n\n```\n\n\n<html>\n<div class=\"ds-thread\" data-thread-key=\"http://kongzheng1993.github.io/kongzheng1993-thewayofsort/\" data-title=\"thewayofsort\" data-url=\"http://kongzheng1993.github.io/kongzheng1993\"></div>\n<!-- 多说评论框 end -->\n<!-- 多说公共JS代码 start (一个网页只需插入一次) -->\n<script type=\"text/javascript\">\nvar duoshuoQuery = {short_name:\"kongzheng1993\"};\n    (function() {\n        var ds = document.createElement('script');\n        ds.type = 'text/javascript';ds.async = true;\n        ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';\n        ds.charset = 'UTF-8';\n        (document.getElementsByTagName('head')[0] \n         || document.getElementsByTagName('body')[0]).appendChild(ds);\n    })();\n</script>\n</html>\n","slug":"kongzheng1993-thewayofsort","published":1,"updated":"2023-03-08T07:05:58.771Z","photos":[],"link":"","_id":"clg0k2ab0000et26fvf3zt23d","content":"<h2 id=\"概论\"><a href=\"#概论\" class=\"headerlink\" title=\"概论\"></a>概论</h2><p>排序有内部排序和外部排序，内部排序是数据记录在内存中进行排序，而外部排序是因排序的数据很大，一次不能容纳全部的排序记录，在排序过程中需要访问外存。</p>\n<p>我整理的排序就是内部排序。</p>\n<p>当数据较多时应该采用时间复杂度为o(nlog2n)的排序方法：快速排序、堆排序、归并排序</p>\n<p>快速排序是这几种内部排序中最好的方法，想待排序的关键字是随机分布时，快速排序的平均时间最短。</p>\n<h2 id=\"直接插入排序\"><a href=\"#直接插入排序\" class=\"headerlink\" title=\"直接插入排序\"></a>直接插入排序</h2><h3 id=\"思想\"><a href=\"#思想\" class=\"headerlink\" title=\"思想\"></a>思想</h3><p>将一个记录插入到已排序好的有序表中，从而得到一个新，记录数增1的有序表。即：先将序列的第1个记录看成是一个有序的子序列，然后从第2个记录逐个进行插入，直至整个序列有序为止。</p>\n<h3 id=\"要点\"><a href=\"#要点\" class=\"headerlink\" title=\"要点\"></a>要点</h3><p>设立哨兵，作为临时存储和判断数组边界之用。</p>\n<p>如果碰见一个和插入元素相等的，那么插入元素把想插入的元素放在相等元素的后面。所以，相等元素的前后顺序没有改变，从原无序序列出去的顺序就是排好序后的顺序，所以插入排序是稳定的。</p>\n<h3 id=\"代码\"><a href=\"#代码\" class=\"headerlink\" title=\"代码\"></a>代码</h3><pre><code>public void insertSort(int[] a){\n    int i, j, k;\nfor (i = 1; i &lt; a.length; i++) {\n             //为a[i]在前面的a[0...i-1]有序区间中找一个合适的位置\n            for (j = i - 1; j &gt;= 0; j--)//这里判断是j&gt;=0也可以防止数组越界，很巧妙\n                 if (a[j] &lt; a[i])\n                     break;\n             //如找到了一个合适的位置\n             if (j != i - 1) {\n                 //将比a[i]大的数据向后移\n                 int temp = a[i];\n                 for (k = i - 1; k &gt; j; k--)\n                     a[k + 1] = a[k];\n                 //将a[i]放到正确位置上\n                 a[k + 1] = temp;\n             }\n         }\n}</code></pre><h3 id=\"效率\"><a href=\"#效率\" class=\"headerlink\" title=\"效率\"></a>效率</h3><p>时间复杂度：O（n^2）.</p>\n<p>其他的插入排序有二分插入排序，2-路插入排序。</p>\n<h2 id=\"简单选择排序\"><a href=\"#简单选择排序\" class=\"headerlink\" title=\"简单选择排序\"></a>简单选择排序</h2><h3 id=\"基本思想\"><a href=\"#基本思想\" class=\"headerlink\" title=\"基本思想\"></a>基本思想</h3><p>在要排序的一组数中，选出最小（或者最大）的一个数与第1个位置的数交换；然后在剩下的数当中再找最小（或者最大）的与第2个位置的数交换，依次类推，直到第n-1个元素（倒数第二个数）和第n个元素（最后一个数）比较为止。</p>\n<h3 id=\"操作方法\"><a href=\"#操作方法\" class=\"headerlink\" title=\"操作方法\"></a>操作方法</h3><p>第一趟，从n 个记录中找出关键码最小的记录与第一个记录交换；</p>\n<p>第二趟，从第二个记录开始的n-1 个记录中再选出关键码最小的记录与第二个记录交换；</p>\n<p>以此类推…..</p>\n<p>第i 趟，则从第i 个记录开始的n-i+1 个记录中选出关键码最小的记录与第i 个记录交换，</p>\n<p>直到整个序列按关键码有序。</p>\n<h3 id=\"代码-1\"><a href=\"#代码-1\" class=\"headerlink\" title=\"代码\"></a>代码</h3><pre><code>public void selectSort(int a[]){\n    int index,temp;\n    //index保存目前最小的数据的下标\n    //找出最小的数据的位置\n    for (int i=0;i&lt;a.length ;i++) {\n        index=i;//因为每次排完序前面的都是有序的了，前面的肯定比第i个小，所以让index=i，减少不必要的麻烦\n        for (int j=i;j&lt;a.length ;j++ ) {\n            if (a[j]&lt;a[index]) {\n            index=j;\n            }        \n        }\n        System.out.println(&quot;第&quot;+i+&quot;次找到的最小值的下标是：&quot;+index);\n        if(index!=i)\n            {\n                temp=a[index];//找到无序数列里面的最小值并于当前位置(i)交换\n                a[index]=a[i];\n                a[i]=temp;\n            }\n        for (int m=0; m&lt;a.length;m++ ) {\n            System.out.print(a[m]+&quot; &quot;);\n\n        }\n        System.out.println();\n    }\n\n}</code></pre><h2 id=\"简单选择排序的改进-–二元选择排序\"><a href=\"#简单选择排序的改进-–二元选择排序\" class=\"headerlink\" title=\"简单选择排序的改进 –二元选择排序\"></a>简单选择排序的改进 –二元选择排序</h2><p>简单选择排序，每趟只能确定一个元素排序后的定位，我们可以考虑改进为每趟确定两个元素，也就是最大值和最小值的位置，从而减少循环次数，改进后对n个数据进行排序，最多只需进行[n/2]趟循环。</p>\n<h3 id=\"代码-2\"><a href=\"#代码-2\" class=\"headerlink\" title=\"代码\"></a>代码</h3><pre><code>//这个算法因为比较的是大小，将min和max都记录下来，交换到当前坐标，但是如果数组中有相同的值，他们也会不论你这是交换还是不交换，都不会改变结果，所以这个方法不适用于有相同数据的数组\nvoid selectSort_double(int a[]){\n    int min,max,temp;\n    for (int i=0;i&lt;=a.length/2;i++ ) {\n        min=i;max=i;\n        for (int j=i;j&lt;a.length-i;j++) {\n            if(a[j]&lt;a[min]){\n                min=j;\n                System.out.println(&quot;min=&quot;+min);\n                continue;//如果当前左边的数据小于当前最小值，那么它必定小于最大值，直接进入下一次循环\n            }\n            if (a[j]&gt;a[max]) {\n                max=j;\n                System.out.println(&quot;max=&quot;+max);\n            }   \n        }\n        System.out.println(&quot;第&quot;+i+&quot;次找到的最小值的下标是：&quot;+min+&quot;;第&quot;+i+&quot;次找到的最大值的下标是：&quot;+max);\n        temp=a[i];a[i]=a[min];a[min]=temp;\n        temp=a[a.length-i-1];a[a.length-i-1]=a[max];a[max]=temp;\n        for (int w=0;w&lt;a.length ;w++ ) {\n            System.out.print(a[w]+&quot; &quot;);\n        }\n        temp=a[a.length-i-1];a[a.length-i-1]=a[max];a[max]=temp;\n        System.out.println();\n    }\n}</code></pre><h2 id=\"冒泡排序\"><a href=\"#冒泡排序\" class=\"headerlink\" title=\"冒泡排序\"></a>冒泡排序</h2><h3 id=\"基本思想-1\"><a href=\"#基本思想-1\" class=\"headerlink\" title=\"基本思想\"></a>基本思想</h3><p>冒泡排序是相继比较交换两个相邻位置的值，每次排序都确定一个值的位置，就像冒泡一样</p>\n<h3 id=\"代码-3\"><a href=\"#代码-3\" class=\"headerlink\" title=\"代码\"></a>代码</h3><pre><code>public class BubbleSort1{\n\n    public void bubble(int a[]){\n\n        for (int i=0;i&lt;a.length;i++ ) {\n            for (int j=0;j&lt;a.length-i-1 ;j++ ) {\n\n                if (a[j]&gt;a[j+1]) {\n                    int temp=a[j];\n                    a[j]=a[j+1];\n                    a[j+1]=temp;\n                }\n                // out(a);\n\n            }\n            out(a);\n}\n    }\n    public void out(int a[]){\n        for (int i=0;i&lt;a.length ;i++ ) {\n            System.out.print(a[i]+&quot; &quot;);\n        }\n        System.out.println();\n    }\n    public static void main(String[] args) {\n        BubbleSort1 bu=new BubbleSort1();\n        int arr[]={2,5,1,3,6,9,7};\n        // bu.out(arr);\n        bu.bubble(arr);\n        // bu.out(arr);\n        System.out.println(&quot;hello world&quot;);\n    }\n\n\n}\n</code></pre><html>\n<div class=\"ds-thread\" data-thread-key=\"http://kongzheng1993.github.io/kongzheng1993-thewayofsort/\" data-title=\"thewayofsort\" data-url=\"http://kongzheng1993.github.io/kongzheng1993\"></div>\n<!-- 多说评论框 end -->\n<!-- 多说公共JS代码 start (一个网页只需插入一次) -->\n<script type=\"text/javascript\">\nvar duoshuoQuery = {short_name:\"kongzheng1993\"};\n    (function() {\n        var ds = document.createElement('script');\n        ds.type = 'text/javascript';ds.async = true;\n        ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';\n        ds.charset = 'UTF-8';\n        (document.getElementsByTagName('head')[0] \n         || document.getElementsByTagName('body')[0]).appendChild(ds);\n    })();\n</script>\n</html>\n","site":{"data":{}},"more":"<h2 id=\"概论\"><a href=\"#概论\" class=\"headerlink\" title=\"概论\"></a>概论</h2><p>排序有内部排序和外部排序，内部排序是数据记录在内存中进行排序，而外部排序是因排序的数据很大，一次不能容纳全部的排序记录，在排序过程中需要访问外存。</p>\n<p>我整理的排序就是内部排序。</p>\n<p>当数据较多时应该采用时间复杂度为o(nlog2n)的排序方法：快速排序、堆排序、归并排序</p>\n<p>快速排序是这几种内部排序中最好的方法，想待排序的关键字是随机分布时，快速排序的平均时间最短。</p>\n<h2 id=\"直接插入排序\"><a href=\"#直接插入排序\" class=\"headerlink\" title=\"直接插入排序\"></a>直接插入排序</h2><h3 id=\"思想\"><a href=\"#思想\" class=\"headerlink\" title=\"思想\"></a>思想</h3><p>将一个记录插入到已排序好的有序表中，从而得到一个新，记录数增1的有序表。即：先将序列的第1个记录看成是一个有序的子序列，然后从第2个记录逐个进行插入，直至整个序列有序为止。</p>\n<h3 id=\"要点\"><a href=\"#要点\" class=\"headerlink\" title=\"要点\"></a>要点</h3><p>设立哨兵，作为临时存储和判断数组边界之用。</p>\n<p>如果碰见一个和插入元素相等的，那么插入元素把想插入的元素放在相等元素的后面。所以，相等元素的前后顺序没有改变，从原无序序列出去的顺序就是排好序后的顺序，所以插入排序是稳定的。</p>\n<h3 id=\"代码\"><a href=\"#代码\" class=\"headerlink\" title=\"代码\"></a>代码</h3><pre><code>public void insertSort(int[] a){\n    int i, j, k;\nfor (i = 1; i &lt; a.length; i++) {\n             //为a[i]在前面的a[0...i-1]有序区间中找一个合适的位置\n            for (j = i - 1; j &gt;= 0; j--)//这里判断是j&gt;=0也可以防止数组越界，很巧妙\n                 if (a[j] &lt; a[i])\n                     break;\n             //如找到了一个合适的位置\n             if (j != i - 1) {\n                 //将比a[i]大的数据向后移\n                 int temp = a[i];\n                 for (k = i - 1; k &gt; j; k--)\n                     a[k + 1] = a[k];\n                 //将a[i]放到正确位置上\n                 a[k + 1] = temp;\n             }\n         }\n}</code></pre><h3 id=\"效率\"><a href=\"#效率\" class=\"headerlink\" title=\"效率\"></a>效率</h3><p>时间复杂度：O（n^2）.</p>\n<p>其他的插入排序有二分插入排序，2-路插入排序。</p>\n<h2 id=\"简单选择排序\"><a href=\"#简单选择排序\" class=\"headerlink\" title=\"简单选择排序\"></a>简单选择排序</h2><h3 id=\"基本思想\"><a href=\"#基本思想\" class=\"headerlink\" title=\"基本思想\"></a>基本思想</h3><p>在要排序的一组数中，选出最小（或者最大）的一个数与第1个位置的数交换；然后在剩下的数当中再找最小（或者最大）的与第2个位置的数交换，依次类推，直到第n-1个元素（倒数第二个数）和第n个元素（最后一个数）比较为止。</p>\n<h3 id=\"操作方法\"><a href=\"#操作方法\" class=\"headerlink\" title=\"操作方法\"></a>操作方法</h3><p>第一趟，从n 个记录中找出关键码最小的记录与第一个记录交换；</p>\n<p>第二趟，从第二个记录开始的n-1 个记录中再选出关键码最小的记录与第二个记录交换；</p>\n<p>以此类推…..</p>\n<p>第i 趟，则从第i 个记录开始的n-i+1 个记录中选出关键码最小的记录与第i 个记录交换，</p>\n<p>直到整个序列按关键码有序。</p>\n<h3 id=\"代码-1\"><a href=\"#代码-1\" class=\"headerlink\" title=\"代码\"></a>代码</h3><pre><code>public void selectSort(int a[]){\n    int index,temp;\n    //index保存目前最小的数据的下标\n    //找出最小的数据的位置\n    for (int i=0;i&lt;a.length ;i++) {\n        index=i;//因为每次排完序前面的都是有序的了，前面的肯定比第i个小，所以让index=i，减少不必要的麻烦\n        for (int j=i;j&lt;a.length ;j++ ) {\n            if (a[j]&lt;a[index]) {\n            index=j;\n            }        \n        }\n        System.out.println(&quot;第&quot;+i+&quot;次找到的最小值的下标是：&quot;+index);\n        if(index!=i)\n            {\n                temp=a[index];//找到无序数列里面的最小值并于当前位置(i)交换\n                a[index]=a[i];\n                a[i]=temp;\n            }\n        for (int m=0; m&lt;a.length;m++ ) {\n            System.out.print(a[m]+&quot; &quot;);\n\n        }\n        System.out.println();\n    }\n\n}</code></pre><h2 id=\"简单选择排序的改进-–二元选择排序\"><a href=\"#简单选择排序的改进-–二元选择排序\" class=\"headerlink\" title=\"简单选择排序的改进 –二元选择排序\"></a>简单选择排序的改进 –二元选择排序</h2><p>简单选择排序，每趟只能确定一个元素排序后的定位，我们可以考虑改进为每趟确定两个元素，也就是最大值和最小值的位置，从而减少循环次数，改进后对n个数据进行排序，最多只需进行[n/2]趟循环。</p>\n<h3 id=\"代码-2\"><a href=\"#代码-2\" class=\"headerlink\" title=\"代码\"></a>代码</h3><pre><code>//这个算法因为比较的是大小，将min和max都记录下来，交换到当前坐标，但是如果数组中有相同的值，他们也会不论你这是交换还是不交换，都不会改变结果，所以这个方法不适用于有相同数据的数组\nvoid selectSort_double(int a[]){\n    int min,max,temp;\n    for (int i=0;i&lt;=a.length/2;i++ ) {\n        min=i;max=i;\n        for (int j=i;j&lt;a.length-i;j++) {\n            if(a[j]&lt;a[min]){\n                min=j;\n                System.out.println(&quot;min=&quot;+min);\n                continue;//如果当前左边的数据小于当前最小值，那么它必定小于最大值，直接进入下一次循环\n            }\n            if (a[j]&gt;a[max]) {\n                max=j;\n                System.out.println(&quot;max=&quot;+max);\n            }   \n        }\n        System.out.println(&quot;第&quot;+i+&quot;次找到的最小值的下标是：&quot;+min+&quot;;第&quot;+i+&quot;次找到的最大值的下标是：&quot;+max);\n        temp=a[i];a[i]=a[min];a[min]=temp;\n        temp=a[a.length-i-1];a[a.length-i-1]=a[max];a[max]=temp;\n        for (int w=0;w&lt;a.length ;w++ ) {\n            System.out.print(a[w]+&quot; &quot;);\n        }\n        temp=a[a.length-i-1];a[a.length-i-1]=a[max];a[max]=temp;\n        System.out.println();\n    }\n}</code></pre><h2 id=\"冒泡排序\"><a href=\"#冒泡排序\" class=\"headerlink\" title=\"冒泡排序\"></a>冒泡排序</h2><h3 id=\"基本思想-1\"><a href=\"#基本思想-1\" class=\"headerlink\" title=\"基本思想\"></a>基本思想</h3><p>冒泡排序是相继比较交换两个相邻位置的值，每次排序都确定一个值的位置，就像冒泡一样</p>\n<h3 id=\"代码-3\"><a href=\"#代码-3\" class=\"headerlink\" title=\"代码\"></a>代码</h3><pre><code>public class BubbleSort1{\n\n    public void bubble(int a[]){\n\n        for (int i=0;i&lt;a.length;i++ ) {\n            for (int j=0;j&lt;a.length-i-1 ;j++ ) {\n\n                if (a[j]&gt;a[j+1]) {\n                    int temp=a[j];\n                    a[j]=a[j+1];\n                    a[j+1]=temp;\n                }\n                // out(a);\n\n            }\n            out(a);\n}\n    }\n    public void out(int a[]){\n        for (int i=0;i&lt;a.length ;i++ ) {\n            System.out.print(a[i]+&quot; &quot;);\n        }\n        System.out.println();\n    }\n    public static void main(String[] args) {\n        BubbleSort1 bu=new BubbleSort1();\n        int arr[]={2,5,1,3,6,9,7};\n        // bu.out(arr);\n        bu.bubble(arr);\n        // bu.out(arr);\n        System.out.println(&quot;hello world&quot;);\n    }\n\n\n}\n</code></pre><html>\n<div class=\"ds-thread\" data-thread-key=\"http://kongzheng1993.github.io/kongzheng1993-thewayofsort/\" data-title=\"thewayofsort\" data-url=\"http://kongzheng1993.github.io/kongzheng1993\"></div>\n<!-- 多说评论框 end -->\n<!-- 多说公共JS代码 start (一个网页只需插入一次) -->\n<script type=\"text/javascript\">\nvar duoshuoQuery = {short_name:\"kongzheng1993\"};\n    (function() {\n        var ds = document.createElement('script');\n        ds.type = 'text/javascript';ds.async = true;\n        ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';\n        ds.charset = 'UTF-8';\n        (document.getElementsByTagName('head')[0] \n         || document.getElementsByTagName('body')[0]).appendChild(ds);\n    })();\n</script>\n</html>\n"},{"layout":"post","title":"synchronized浅析","date":"2016-05-19T16:00:00.000Z","excerpt":"","tag":null,"comments":1,"_content":"\n## synchronized是什么？\n\nsynchronized是一个关键字，并不是一个“锁”，“加锁”这个操作更符合它的含义。\n\n字面意思它是同步的过去式。\n<img src=\"fanyi.png\">\n\n多线程环境：\n<img src=\"1.png\">\n\n\n## 原理\n\nsynchronized的底层实现是使用操作系统的mutex lock实现的。JDK5之前被称为重量级锁，JDK6对synchronized内在机制进行了优化，加入了CAS、轻量级锁和偏向锁对功能，性能上已经跟ReentrantLock相差无几，而且在使用上更简单，不易出错。所以如果仅仅要实现互斥效果，不需要基于Lock的复杂操作（中断、条件等），推荐优先使用synchronized。\n\nsynchronized用的锁是存在Java对象头里的。JVM基于`进入`和`退出`Monitor对象来实现方法同步和代码块同步。\n\n## synchronized的几种加锁方式以及基础说明\n\n修饰内容|锁类型|示例\n-|-|-\n没加锁|没加锁|示例1\n修饰代码块|任意对象锁|示例2\n修饰普通方法|this锁|示例3\n修饰静态方法|类锁|示例4\n\n### 示例1:没有synchronized加锁\n\n```java\npublic class NoSynchronizedDemo {\n    public void method() {\n        System.out.println(\"Method 1 start\");\n    }\n}\n```\n\n查看核心字节码\n\n```java\n  public void method();\n    descriptor: ()V\n    flags: ACC_PUBLIC\n    Code:\n      stack=2, locals=1, args_size=1\n         0: getstatic     #2                  // Field java/lang/System.out:Ljava/io/PrintStream;\n         3: ldc           #3                  // String Method 1 start\n         5: invokevirtual #4                  // Method java/io/PrintStream.println:(Ljava/lang/String;)V\n         8: return\n      LineNumberTable:\n        line 5: 0\n        line 6: 8\n      LocalVariableTable:\n        Start  Length  Slot  Name   Signature\n            0       9     0  this   Lcom/lhx/cloud/javathread/NoSynchronizedDemo;\n```\n\n### 示例2:同步方法块，锁是括号里面的对象\n\n```java\npublic class SynchronizedDemo {\n    public void method() {\n        synchronized (this) {\n            System.out.println(\"Method 1 start\");\n        }\n    }\n}\n```\n\n查看字节码\n\n```java\n  public void method();\n    descriptor: ()V\n    flags: ACC_PUBLIC\n    Code:\n      stack=2, locals=3, args_size=1\n         0: aload_0\n         1: dup\n         2: astore_1\n         3: monitorenter\n         4: getstatic     #2                  // Field java/lang/System.out:Ljava/io/PrintStream;\n         7: ldc           #3                  // String Method 1 start\n         9: invokevirtual #4                  // Method java/io/PrintStream.println:(Ljava/lang/String;)V\n        12: aload_1\n        13: monitorexit\n        14: goto          22\n        17: astore_2\n        18: aload_1\n        19: monitorexit\n        20: aload_2\n        21: athrow\n        22: return\n```\n\n可以看在加锁的代码块，多了个 `monitorenter` , `monitorexit`\n\n**monitorenter**\n每个对象有一个监视器锁（monitor）。当monitor被占用时就会处于锁定状态，线程执行monitorenter指令时尝试获取monitor的所有权，过程如下：\n  - 如果monitor的进入数为0，则该线程进入monitor，然后将进入数设置为1，该线程即为monitor的所有者。\n  - 如果线程已经占有该monitor，只是重新进入，则进入monitor的进入数加1.\n  - 如果其他线程已经占用了monitor，则该线程进入阻塞状态，直到monitor的进入数为0，再重新尝试获取monitor的所有权\n\n*总结：*\n- synchronized是可重入锁，即如果当前线程以获得锁对象，可再次获取该锁对象。即：该锁对象的监视器锁 monitor 具有可重入性，每进入一次，进入次数+1\n- 从synchronized使用的语法上，如果修饰代码块，`synchronize (object) {} object` 即为锁对象\n- 如果修饰方法，普通方法可认为是 this 锁，即`当前对象锁`\n- 静态方法可认为是`类锁`\n\n**monitorexit**\n\n- 执行monitorexit的线程必须是objectref所对应的monitor的所有者。\n- 指令执行时，monitor的进入数减1\n- 如果减1后进入数为0，那线程退出monitor，不再是这个monitor的所有者\n- 其他被这个monitor阻塞的线程可以尝试去获取这个monitor的所有权\n\n*总结：*\n通过以上描述，应该能很清楚的看出Synchronized的实现原理，Synchronized的语义底层是通过一个`monitor`的对象来完成，其实wait/notify等方法也依赖于monitor对象，这就是为什么只有在同步的块或者方法中才能调用wait/notify等方法，否则会抛出java.lang.IllegalMonitorStateException的异常的原因。\n\n### 示例3:普通同步方法，锁是当前实例对象\n\n```java\npublic class SynchronizedDemo2 {\n    public synchronized void method() {\n        System.out.println(\"Method 1 start\");\n    }\n}\n```\n\n查看字节码\n\n```java\n  public synchronized void method();\n    descriptor: ()V\n    flags: ACC_PUBLIC, ACC_SYNCHRONIZED\n    Code:\n      stack=2, locals=1, args_size=1\n         0: getstatic     #2                  // Field java/lang/System.out:Ljava/io/PrintStream;\n         3: ldc           #3                  // String Method 1 start\n         5: invokevirtual #4                  // Method java/io/PrintStream.println:(Ljava/lang/String;)V\n         8: return\n```\n\n**注意:** 在flags上增加了ACC_SYNCHRONIZED\n\n### 示例4:静态同步方法，锁是当前类的class对象\n\n```java\npublic class SynchronizedDemoStatic {\n    public static synchronized void method() {\n        System.out.println(\"Method 1 start\");\n    }\n}\n```\n\n查看字节码\n\n```java\n  public static synchronized void method();\n    descriptor: ()V\n    flags: ACC_PUBLIC, ACC_STATIC, ACC_SYNCHRONIZED\n    Code:\n      stack=2, locals=0, args_size=0\n         0: getstatic     #2                  // Field java/lang/System.out:Ljava/io/PrintStream;\n         3: ldc           #3                  // String Method 1 start\n         5: invokevirtual #4                  // Method java/io/PrintStream.println:(Ljava/lang/String;)V\n         8: return\n```\n\n**注意：** 在flags上增加了ACC_STATIC, ACC_SYNCHRONIZED\n\n*总结：*\n\n针对示例3、示例四，在flags上均增加了`ACC_SYNCHRONIZED`\n\n从反编译的结果来看，方法的同步并没有通过指令`monitorenter`和`monitorexit`来完成（理论上其实也可以通过这两条指令来实现），不过相对于普通方法（没加synchronized的），其常量池中多了`ACC_SYNCHRONIZED`标示符。**JVM就是根据该标示符来实现方法的同步的**：当方法调用时，调用指令将会检查方法的`ACC_SYNCHRONIZED`访问标志是否被设置，如果设置了，执行线程将先获取`monitor`，获取成功之后才能执行方法体，方法执行完后再释放`monitor`。在方法执行期间，其他任何线程都无法再获得同一个`monitor`对象。 其实本质上没有区别，只是方法的同步是一种**隐式**的方式来实现，无需通过字节码来完成。","source":"_posts/2016-06-16-kongzheng1993-synchronized.md","raw":"---\nlayout: post\ntitle:  \"synchronized浅析\"\ndate:   2016-05-20\nexcerpt: \"synchronized\"\ntag:\ncomments: true\n---\n\n## synchronized是什么？\n\nsynchronized是一个关键字，并不是一个“锁”，“加锁”这个操作更符合它的含义。\n\n字面意思它是同步的过去式。\n<img src=\"fanyi.png\">\n\n多线程环境：\n<img src=\"1.png\">\n\n\n## 原理\n\nsynchronized的底层实现是使用操作系统的mutex lock实现的。JDK5之前被称为重量级锁，JDK6对synchronized内在机制进行了优化，加入了CAS、轻量级锁和偏向锁对功能，性能上已经跟ReentrantLock相差无几，而且在使用上更简单，不易出错。所以如果仅仅要实现互斥效果，不需要基于Lock的复杂操作（中断、条件等），推荐优先使用synchronized。\n\nsynchronized用的锁是存在Java对象头里的。JVM基于`进入`和`退出`Monitor对象来实现方法同步和代码块同步。\n\n## synchronized的几种加锁方式以及基础说明\n\n修饰内容|锁类型|示例\n-|-|-\n没加锁|没加锁|示例1\n修饰代码块|任意对象锁|示例2\n修饰普通方法|this锁|示例3\n修饰静态方法|类锁|示例4\n\n### 示例1:没有synchronized加锁\n\n```java\npublic class NoSynchronizedDemo {\n    public void method() {\n        System.out.println(\"Method 1 start\");\n    }\n}\n```\n\n查看核心字节码\n\n```java\n  public void method();\n    descriptor: ()V\n    flags: ACC_PUBLIC\n    Code:\n      stack=2, locals=1, args_size=1\n         0: getstatic     #2                  // Field java/lang/System.out:Ljava/io/PrintStream;\n         3: ldc           #3                  // String Method 1 start\n         5: invokevirtual #4                  // Method java/io/PrintStream.println:(Ljava/lang/String;)V\n         8: return\n      LineNumberTable:\n        line 5: 0\n        line 6: 8\n      LocalVariableTable:\n        Start  Length  Slot  Name   Signature\n            0       9     0  this   Lcom/lhx/cloud/javathread/NoSynchronizedDemo;\n```\n\n### 示例2:同步方法块，锁是括号里面的对象\n\n```java\npublic class SynchronizedDemo {\n    public void method() {\n        synchronized (this) {\n            System.out.println(\"Method 1 start\");\n        }\n    }\n}\n```\n\n查看字节码\n\n```java\n  public void method();\n    descriptor: ()V\n    flags: ACC_PUBLIC\n    Code:\n      stack=2, locals=3, args_size=1\n         0: aload_0\n         1: dup\n         2: astore_1\n         3: monitorenter\n         4: getstatic     #2                  // Field java/lang/System.out:Ljava/io/PrintStream;\n         7: ldc           #3                  // String Method 1 start\n         9: invokevirtual #4                  // Method java/io/PrintStream.println:(Ljava/lang/String;)V\n        12: aload_1\n        13: monitorexit\n        14: goto          22\n        17: astore_2\n        18: aload_1\n        19: monitorexit\n        20: aload_2\n        21: athrow\n        22: return\n```\n\n可以看在加锁的代码块，多了个 `monitorenter` , `monitorexit`\n\n**monitorenter**\n每个对象有一个监视器锁（monitor）。当monitor被占用时就会处于锁定状态，线程执行monitorenter指令时尝试获取monitor的所有权，过程如下：\n  - 如果monitor的进入数为0，则该线程进入monitor，然后将进入数设置为1，该线程即为monitor的所有者。\n  - 如果线程已经占有该monitor，只是重新进入，则进入monitor的进入数加1.\n  - 如果其他线程已经占用了monitor，则该线程进入阻塞状态，直到monitor的进入数为0，再重新尝试获取monitor的所有权\n\n*总结：*\n- synchronized是可重入锁，即如果当前线程以获得锁对象，可再次获取该锁对象。即：该锁对象的监视器锁 monitor 具有可重入性，每进入一次，进入次数+1\n- 从synchronized使用的语法上，如果修饰代码块，`synchronize (object) {} object` 即为锁对象\n- 如果修饰方法，普通方法可认为是 this 锁，即`当前对象锁`\n- 静态方法可认为是`类锁`\n\n**monitorexit**\n\n- 执行monitorexit的线程必须是objectref所对应的monitor的所有者。\n- 指令执行时，monitor的进入数减1\n- 如果减1后进入数为0，那线程退出monitor，不再是这个monitor的所有者\n- 其他被这个monitor阻塞的线程可以尝试去获取这个monitor的所有权\n\n*总结：*\n通过以上描述，应该能很清楚的看出Synchronized的实现原理，Synchronized的语义底层是通过一个`monitor`的对象来完成，其实wait/notify等方法也依赖于monitor对象，这就是为什么只有在同步的块或者方法中才能调用wait/notify等方法，否则会抛出java.lang.IllegalMonitorStateException的异常的原因。\n\n### 示例3:普通同步方法，锁是当前实例对象\n\n```java\npublic class SynchronizedDemo2 {\n    public synchronized void method() {\n        System.out.println(\"Method 1 start\");\n    }\n}\n```\n\n查看字节码\n\n```java\n  public synchronized void method();\n    descriptor: ()V\n    flags: ACC_PUBLIC, ACC_SYNCHRONIZED\n    Code:\n      stack=2, locals=1, args_size=1\n         0: getstatic     #2                  // Field java/lang/System.out:Ljava/io/PrintStream;\n         3: ldc           #3                  // String Method 1 start\n         5: invokevirtual #4                  // Method java/io/PrintStream.println:(Ljava/lang/String;)V\n         8: return\n```\n\n**注意:** 在flags上增加了ACC_SYNCHRONIZED\n\n### 示例4:静态同步方法，锁是当前类的class对象\n\n```java\npublic class SynchronizedDemoStatic {\n    public static synchronized void method() {\n        System.out.println(\"Method 1 start\");\n    }\n}\n```\n\n查看字节码\n\n```java\n  public static synchronized void method();\n    descriptor: ()V\n    flags: ACC_PUBLIC, ACC_STATIC, ACC_SYNCHRONIZED\n    Code:\n      stack=2, locals=0, args_size=0\n         0: getstatic     #2                  // Field java/lang/System.out:Ljava/io/PrintStream;\n         3: ldc           #3                  // String Method 1 start\n         5: invokevirtual #4                  // Method java/io/PrintStream.println:(Ljava/lang/String;)V\n         8: return\n```\n\n**注意：** 在flags上增加了ACC_STATIC, ACC_SYNCHRONIZED\n\n*总结：*\n\n针对示例3、示例四，在flags上均增加了`ACC_SYNCHRONIZED`\n\n从反编译的结果来看，方法的同步并没有通过指令`monitorenter`和`monitorexit`来完成（理论上其实也可以通过这两条指令来实现），不过相对于普通方法（没加synchronized的），其常量池中多了`ACC_SYNCHRONIZED`标示符。**JVM就是根据该标示符来实现方法的同步的**：当方法调用时，调用指令将会检查方法的`ACC_SYNCHRONIZED`访问标志是否被设置，如果设置了，执行线程将先获取`monitor`，获取成功之后才能执行方法体，方法执行完后再释放`monitor`。在方法执行期间，其他任何线程都无法再获得同一个`monitor`对象。 其实本质上没有区别，只是方法的同步是一种**隐式**的方式来实现，无需通过字节码来完成。","slug":"kongzheng1993-synchronized","published":1,"updated":"2023-03-08T07:05:58.771Z","photos":[],"link":"","_id":"clg0k2abh000ht26fm0pb7gpr","content":"<h2 id=\"synchronized是什么？\"><a href=\"#synchronized是什么？\" class=\"headerlink\" title=\"synchronized是什么？\"></a>synchronized是什么？</h2><p>synchronized是一个关键字，并不是一个“锁”，“加锁”这个操作更符合它的含义。</p>\n<p>字面意思它是同步的过去式。<br><img src=\"/2016/05/20/kongzheng1993-synchronized/fanyi.png\"></p>\n<p>多线程环境：<br><img src=\"/2016/05/20/kongzheng1993-synchronized/1.png\"></p>\n<h2 id=\"原理\"><a href=\"#原理\" class=\"headerlink\" title=\"原理\"></a>原理</h2><p>synchronized的底层实现是使用操作系统的mutex lock实现的。JDK5之前被称为重量级锁，JDK6对synchronized内在机制进行了优化，加入了CAS、轻量级锁和偏向锁对功能，性能上已经跟ReentrantLock相差无几，而且在使用上更简单，不易出错。所以如果仅仅要实现互斥效果，不需要基于Lock的复杂操作（中断、条件等），推荐优先使用synchronized。</p>\n<p>synchronized用的锁是存在Java对象头里的。JVM基于<code>进入</code>和<code>退出</code>Monitor对象来实现方法同步和代码块同步。</p>\n<h2 id=\"synchronized的几种加锁方式以及基础说明\"><a href=\"#synchronized的几种加锁方式以及基础说明\" class=\"headerlink\" title=\"synchronized的几种加锁方式以及基础说明\"></a>synchronized的几种加锁方式以及基础说明</h2><table>\n<thead>\n<tr>\n<th>修饰内容</th>\n<th>锁类型</th>\n<th>示例</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>没加锁</td>\n<td>没加锁</td>\n<td>示例1</td>\n</tr>\n<tr>\n<td>修饰代码块</td>\n<td>任意对象锁</td>\n<td>示例2</td>\n</tr>\n<tr>\n<td>修饰普通方法</td>\n<td>this锁</td>\n<td>示例3</td>\n</tr>\n<tr>\n<td>修饰静态方法</td>\n<td>类锁</td>\n<td>示例4</td>\n</tr>\n</tbody></table>\n<h3 id=\"示例1-没有synchronized加锁\"><a href=\"#示例1-没有synchronized加锁\" class=\"headerlink\" title=\"示例1:没有synchronized加锁\"></a>示例1:没有synchronized加锁</h3><pre><code class=\"java\">public class NoSynchronizedDemo {\n    public void method() {\n        System.out.println(&quot;Method 1 start&quot;);\n    }\n}</code></pre>\n<p>查看核心字节码</p>\n<pre><code class=\"java\">  public void method();\n    descriptor: ()V\n    flags: ACC_PUBLIC\n    Code:\n      stack=2, locals=1, args_size=1\n         0: getstatic     #2                  // Field java/lang/System.out:Ljava/io/PrintStream;\n         3: ldc           #3                  // String Method 1 start\n         5: invokevirtual #4                  // Method java/io/PrintStream.println:(Ljava/lang/String;)V\n         8: return\n      LineNumberTable:\n        line 5: 0\n        line 6: 8\n      LocalVariableTable:\n        Start  Length  Slot  Name   Signature\n            0       9     0  this   Lcom/lhx/cloud/javathread/NoSynchronizedDemo;</code></pre>\n<h3 id=\"示例2-同步方法块，锁是括号里面的对象\"><a href=\"#示例2-同步方法块，锁是括号里面的对象\" class=\"headerlink\" title=\"示例2:同步方法块，锁是括号里面的对象\"></a>示例2:同步方法块，锁是括号里面的对象</h3><pre><code class=\"java\">public class SynchronizedDemo {\n    public void method() {\n        synchronized (this) {\n            System.out.println(&quot;Method 1 start&quot;);\n        }\n    }\n}</code></pre>\n<p>查看字节码</p>\n<pre><code class=\"java\">  public void method();\n    descriptor: ()V\n    flags: ACC_PUBLIC\n    Code:\n      stack=2, locals=3, args_size=1\n         0: aload_0\n         1: dup\n         2: astore_1\n         3: monitorenter\n         4: getstatic     #2                  // Field java/lang/System.out:Ljava/io/PrintStream;\n         7: ldc           #3                  // String Method 1 start\n         9: invokevirtual #4                  // Method java/io/PrintStream.println:(Ljava/lang/String;)V\n        12: aload_1\n        13: monitorexit\n        14: goto          22\n        17: astore_2\n        18: aload_1\n        19: monitorexit\n        20: aload_2\n        21: athrow\n        22: return</code></pre>\n<p>可以看在加锁的代码块，多了个 <code>monitorenter</code> , <code>monitorexit</code></p>\n<p><strong>monitorenter</strong><br>每个对象有一个监视器锁（monitor）。当monitor被占用时就会处于锁定状态，线程执行monitorenter指令时尝试获取monitor的所有权，过程如下：</p>\n<ul>\n<li>如果monitor的进入数为0，则该线程进入monitor，然后将进入数设置为1，该线程即为monitor的所有者。</li>\n<li>如果线程已经占有该monitor，只是重新进入，则进入monitor的进入数加1.</li>\n<li>如果其他线程已经占用了monitor，则该线程进入阻塞状态，直到monitor的进入数为0，再重新尝试获取monitor的所有权</li>\n</ul>\n<p><em>总结：</em></p>\n<ul>\n<li>synchronized是可重入锁，即如果当前线程以获得锁对象，可再次获取该锁对象。即：该锁对象的监视器锁 monitor 具有可重入性，每进入一次，进入次数+1</li>\n<li>从synchronized使用的语法上，如果修饰代码块，<code>synchronize (object) {} object</code> 即为锁对象</li>\n<li>如果修饰方法，普通方法可认为是 this 锁，即<code>当前对象锁</code></li>\n<li>静态方法可认为是<code>类锁</code></li>\n</ul>\n<p><strong>monitorexit</strong></p>\n<ul>\n<li>执行monitorexit的线程必须是objectref所对应的monitor的所有者。</li>\n<li>指令执行时，monitor的进入数减1</li>\n<li>如果减1后进入数为0，那线程退出monitor，不再是这个monitor的所有者</li>\n<li>其他被这个monitor阻塞的线程可以尝试去获取这个monitor的所有权</li>\n</ul>\n<p><em>总结：</em><br>通过以上描述，应该能很清楚的看出Synchronized的实现原理，Synchronized的语义底层是通过一个<code>monitor</code>的对象来完成，其实wait/notify等方法也依赖于monitor对象，这就是为什么只有在同步的块或者方法中才能调用wait/notify等方法，否则会抛出java.lang.IllegalMonitorStateException的异常的原因。</p>\n<h3 id=\"示例3-普通同步方法，锁是当前实例对象\"><a href=\"#示例3-普通同步方法，锁是当前实例对象\" class=\"headerlink\" title=\"示例3:普通同步方法，锁是当前实例对象\"></a>示例3:普通同步方法，锁是当前实例对象</h3><pre><code class=\"java\">public class SynchronizedDemo2 {\n    public synchronized void method() {\n        System.out.println(&quot;Method 1 start&quot;);\n    }\n}</code></pre>\n<p>查看字节码</p>\n<pre><code class=\"java\">  public synchronized void method();\n    descriptor: ()V\n    flags: ACC_PUBLIC, ACC_SYNCHRONIZED\n    Code:\n      stack=2, locals=1, args_size=1\n         0: getstatic     #2                  // Field java/lang/System.out:Ljava/io/PrintStream;\n         3: ldc           #3                  // String Method 1 start\n         5: invokevirtual #4                  // Method java/io/PrintStream.println:(Ljava/lang/String;)V\n         8: return</code></pre>\n<p><strong>注意:</strong> 在flags上增加了ACC_SYNCHRONIZED</p>\n<h3 id=\"示例4-静态同步方法，锁是当前类的class对象\"><a href=\"#示例4-静态同步方法，锁是当前类的class对象\" class=\"headerlink\" title=\"示例4:静态同步方法，锁是当前类的class对象\"></a>示例4:静态同步方法，锁是当前类的class对象</h3><pre><code class=\"java\">public class SynchronizedDemoStatic {\n    public static synchronized void method() {\n        System.out.println(&quot;Method 1 start&quot;);\n    }\n}</code></pre>\n<p>查看字节码</p>\n<pre><code class=\"java\">  public static synchronized void method();\n    descriptor: ()V\n    flags: ACC_PUBLIC, ACC_STATIC, ACC_SYNCHRONIZED\n    Code:\n      stack=2, locals=0, args_size=0\n         0: getstatic     #2                  // Field java/lang/System.out:Ljava/io/PrintStream;\n         3: ldc           #3                  // String Method 1 start\n         5: invokevirtual #4                  // Method java/io/PrintStream.println:(Ljava/lang/String;)V\n         8: return</code></pre>\n<p><strong>注意：</strong> 在flags上增加了ACC_STATIC, ACC_SYNCHRONIZED</p>\n<p><em>总结：</em></p>\n<p>针对示例3、示例四，在flags上均增加了<code>ACC_SYNCHRONIZED</code></p>\n<p>从反编译的结果来看，方法的同步并没有通过指令<code>monitorenter</code>和<code>monitorexit</code>来完成（理论上其实也可以通过这两条指令来实现），不过相对于普通方法（没加synchronized的），其常量池中多了<code>ACC_SYNCHRONIZED</code>标示符。<strong>JVM就是根据该标示符来实现方法的同步的</strong>：当方法调用时，调用指令将会检查方法的<code>ACC_SYNCHRONIZED</code>访问标志是否被设置，如果设置了，执行线程将先获取<code>monitor</code>，获取成功之后才能执行方法体，方法执行完后再释放<code>monitor</code>。在方法执行期间，其他任何线程都无法再获得同一个<code>monitor</code>对象。 其实本质上没有区别，只是方法的同步是一种<strong>隐式</strong>的方式来实现，无需通过字节码来完成。</p>\n","site":{"data":{}},"more":"<h2 id=\"synchronized是什么？\"><a href=\"#synchronized是什么？\" class=\"headerlink\" title=\"synchronized是什么？\"></a>synchronized是什么？</h2><p>synchronized是一个关键字，并不是一个“锁”，“加锁”这个操作更符合它的含义。</p>\n<p>字面意思它是同步的过去式。<br><img src=\"/2016/05/20/kongzheng1993-synchronized/fanyi.png\"></p>\n<p>多线程环境：<br><img src=\"/2016/05/20/kongzheng1993-synchronized/1.png\"></p>\n<h2 id=\"原理\"><a href=\"#原理\" class=\"headerlink\" title=\"原理\"></a>原理</h2><p>synchronized的底层实现是使用操作系统的mutex lock实现的。JDK5之前被称为重量级锁，JDK6对synchronized内在机制进行了优化，加入了CAS、轻量级锁和偏向锁对功能，性能上已经跟ReentrantLock相差无几，而且在使用上更简单，不易出错。所以如果仅仅要实现互斥效果，不需要基于Lock的复杂操作（中断、条件等），推荐优先使用synchronized。</p>\n<p>synchronized用的锁是存在Java对象头里的。JVM基于<code>进入</code>和<code>退出</code>Monitor对象来实现方法同步和代码块同步。</p>\n<h2 id=\"synchronized的几种加锁方式以及基础说明\"><a href=\"#synchronized的几种加锁方式以及基础说明\" class=\"headerlink\" title=\"synchronized的几种加锁方式以及基础说明\"></a>synchronized的几种加锁方式以及基础说明</h2><table>\n<thead>\n<tr>\n<th>修饰内容</th>\n<th>锁类型</th>\n<th>示例</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>没加锁</td>\n<td>没加锁</td>\n<td>示例1</td>\n</tr>\n<tr>\n<td>修饰代码块</td>\n<td>任意对象锁</td>\n<td>示例2</td>\n</tr>\n<tr>\n<td>修饰普通方法</td>\n<td>this锁</td>\n<td>示例3</td>\n</tr>\n<tr>\n<td>修饰静态方法</td>\n<td>类锁</td>\n<td>示例4</td>\n</tr>\n</tbody></table>\n<h3 id=\"示例1-没有synchronized加锁\"><a href=\"#示例1-没有synchronized加锁\" class=\"headerlink\" title=\"示例1:没有synchronized加锁\"></a>示例1:没有synchronized加锁</h3><pre><code class=\"java\">public class NoSynchronizedDemo {\n    public void method() {\n        System.out.println(&quot;Method 1 start&quot;);\n    }\n}</code></pre>\n<p>查看核心字节码</p>\n<pre><code class=\"java\">  public void method();\n    descriptor: ()V\n    flags: ACC_PUBLIC\n    Code:\n      stack=2, locals=1, args_size=1\n         0: getstatic     #2                  // Field java/lang/System.out:Ljava/io/PrintStream;\n         3: ldc           #3                  // String Method 1 start\n         5: invokevirtual #4                  // Method java/io/PrintStream.println:(Ljava/lang/String;)V\n         8: return\n      LineNumberTable:\n        line 5: 0\n        line 6: 8\n      LocalVariableTable:\n        Start  Length  Slot  Name   Signature\n            0       9     0  this   Lcom/lhx/cloud/javathread/NoSynchronizedDemo;</code></pre>\n<h3 id=\"示例2-同步方法块，锁是括号里面的对象\"><a href=\"#示例2-同步方法块，锁是括号里面的对象\" class=\"headerlink\" title=\"示例2:同步方法块，锁是括号里面的对象\"></a>示例2:同步方法块，锁是括号里面的对象</h3><pre><code class=\"java\">public class SynchronizedDemo {\n    public void method() {\n        synchronized (this) {\n            System.out.println(&quot;Method 1 start&quot;);\n        }\n    }\n}</code></pre>\n<p>查看字节码</p>\n<pre><code class=\"java\">  public void method();\n    descriptor: ()V\n    flags: ACC_PUBLIC\n    Code:\n      stack=2, locals=3, args_size=1\n         0: aload_0\n         1: dup\n         2: astore_1\n         3: monitorenter\n         4: getstatic     #2                  // Field java/lang/System.out:Ljava/io/PrintStream;\n         7: ldc           #3                  // String Method 1 start\n         9: invokevirtual #4                  // Method java/io/PrintStream.println:(Ljava/lang/String;)V\n        12: aload_1\n        13: monitorexit\n        14: goto          22\n        17: astore_2\n        18: aload_1\n        19: monitorexit\n        20: aload_2\n        21: athrow\n        22: return</code></pre>\n<p>可以看在加锁的代码块，多了个 <code>monitorenter</code> , <code>monitorexit</code></p>\n<p><strong>monitorenter</strong><br>每个对象有一个监视器锁（monitor）。当monitor被占用时就会处于锁定状态，线程执行monitorenter指令时尝试获取monitor的所有权，过程如下：</p>\n<ul>\n<li>如果monitor的进入数为0，则该线程进入monitor，然后将进入数设置为1，该线程即为monitor的所有者。</li>\n<li>如果线程已经占有该monitor，只是重新进入，则进入monitor的进入数加1.</li>\n<li>如果其他线程已经占用了monitor，则该线程进入阻塞状态，直到monitor的进入数为0，再重新尝试获取monitor的所有权</li>\n</ul>\n<p><em>总结：</em></p>\n<ul>\n<li>synchronized是可重入锁，即如果当前线程以获得锁对象，可再次获取该锁对象。即：该锁对象的监视器锁 monitor 具有可重入性，每进入一次，进入次数+1</li>\n<li>从synchronized使用的语法上，如果修饰代码块，<code>synchronize (object) {} object</code> 即为锁对象</li>\n<li>如果修饰方法，普通方法可认为是 this 锁，即<code>当前对象锁</code></li>\n<li>静态方法可认为是<code>类锁</code></li>\n</ul>\n<p><strong>monitorexit</strong></p>\n<ul>\n<li>执行monitorexit的线程必须是objectref所对应的monitor的所有者。</li>\n<li>指令执行时，monitor的进入数减1</li>\n<li>如果减1后进入数为0，那线程退出monitor，不再是这个monitor的所有者</li>\n<li>其他被这个monitor阻塞的线程可以尝试去获取这个monitor的所有权</li>\n</ul>\n<p><em>总结：</em><br>通过以上描述，应该能很清楚的看出Synchronized的实现原理，Synchronized的语义底层是通过一个<code>monitor</code>的对象来完成，其实wait/notify等方法也依赖于monitor对象，这就是为什么只有在同步的块或者方法中才能调用wait/notify等方法，否则会抛出java.lang.IllegalMonitorStateException的异常的原因。</p>\n<h3 id=\"示例3-普通同步方法，锁是当前实例对象\"><a href=\"#示例3-普通同步方法，锁是当前实例对象\" class=\"headerlink\" title=\"示例3:普通同步方法，锁是当前实例对象\"></a>示例3:普通同步方法，锁是当前实例对象</h3><pre><code class=\"java\">public class SynchronizedDemo2 {\n    public synchronized void method() {\n        System.out.println(&quot;Method 1 start&quot;);\n    }\n}</code></pre>\n<p>查看字节码</p>\n<pre><code class=\"java\">  public synchronized void method();\n    descriptor: ()V\n    flags: ACC_PUBLIC, ACC_SYNCHRONIZED\n    Code:\n      stack=2, locals=1, args_size=1\n         0: getstatic     #2                  // Field java/lang/System.out:Ljava/io/PrintStream;\n         3: ldc           #3                  // String Method 1 start\n         5: invokevirtual #4                  // Method java/io/PrintStream.println:(Ljava/lang/String;)V\n         8: return</code></pre>\n<p><strong>注意:</strong> 在flags上增加了ACC_SYNCHRONIZED</p>\n<h3 id=\"示例4-静态同步方法，锁是当前类的class对象\"><a href=\"#示例4-静态同步方法，锁是当前类的class对象\" class=\"headerlink\" title=\"示例4:静态同步方法，锁是当前类的class对象\"></a>示例4:静态同步方法，锁是当前类的class对象</h3><pre><code class=\"java\">public class SynchronizedDemoStatic {\n    public static synchronized void method() {\n        System.out.println(&quot;Method 1 start&quot;);\n    }\n}</code></pre>\n<p>查看字节码</p>\n<pre><code class=\"java\">  public static synchronized void method();\n    descriptor: ()V\n    flags: ACC_PUBLIC, ACC_STATIC, ACC_SYNCHRONIZED\n    Code:\n      stack=2, locals=0, args_size=0\n         0: getstatic     #2                  // Field java/lang/System.out:Ljava/io/PrintStream;\n         3: ldc           #3                  // String Method 1 start\n         5: invokevirtual #4                  // Method java/io/PrintStream.println:(Ljava/lang/String;)V\n         8: return</code></pre>\n<p><strong>注意：</strong> 在flags上增加了ACC_STATIC, ACC_SYNCHRONIZED</p>\n<p><em>总结：</em></p>\n<p>针对示例3、示例四，在flags上均增加了<code>ACC_SYNCHRONIZED</code></p>\n<p>从反编译的结果来看，方法的同步并没有通过指令<code>monitorenter</code>和<code>monitorexit</code>来完成（理论上其实也可以通过这两条指令来实现），不过相对于普通方法（没加synchronized的），其常量池中多了<code>ACC_SYNCHRONIZED</code>标示符。<strong>JVM就是根据该标示符来实现方法的同步的</strong>：当方法调用时，调用指令将会检查方法的<code>ACC_SYNCHRONIZED</code>访问标志是否被设置，如果设置了，执行线程将先获取<code>monitor</code>，获取成功之后才能执行方法体，方法执行完后再释放<code>monitor</code>。在方法执行期间，其他任何线程都无法再获得同一个<code>monitor</code>对象。 其实本质上没有区别，只是方法的同步是一种<strong>隐式</strong>的方式来实现，无需通过字节码来完成。</p>\n"},{"layout":"post","title":"关于try-catch","date":"2016-07-10T16:00:00.000Z","excerpt":"","comments":1,"_content":"\n```\n\nimport java.io.IOException;  \npublic class ExceptionTryCatchTest {  \n    public void doSomething() throws IOException{  \n        System.out.println(\"do somthing\");  \n    }  \n    public static void main(String[] args){  \n        ExceptionTryCatchTest etct = new ExceptionTryCatchTest();  \n        try {  \n            etct.doSomething();  \n        } catch (Exception e) {                \n        } catch (IOException e) {                \n        }  \n    }   \n}\n\n```\n\n以上并不能通过编译。\n因为编译的时候会报错:已捕捉到异常 java.io.IOException。  catch(IOException e)这句有错误。 \n分析：对于try..catch捕获异常的形式来说，对于异常的捕获，可以有多个catch。对于try里面发生的异常，他会根据发生的异常和catch里面的进行匹配(怎么匹配，按照catch块从上往下匹配)，当它匹配某一个catch块的时候，他就直接进入到这个catch块里面去了，后面在再有catch块的话，它不做任何处理，直接跳过去，全部忽略掉。如果有finally的话进入到finally里面继续执行。换句话说，如果有匹配的catch，它就会忽略掉这个catch后面所有的catch。对我们这个方法来说，抛出的是IOException，当执行etct.doSomething();时，可能会抛出IOException，一但抛出IOException，它首先进入到catch (Exception e) {}里面，先和Exception匹配，由于IOException extends Exception,根据多态的原则，IOException是匹配Exception的，所以程序就会进入到catch (Exception e) {}里面，进入到第一个catch后，后面的catch都不会执行了，所以catch (IOException e) {}永远都执行不到，就给我们报出了前面的错误:已捕捉到异常 java.io.IOException。 \n\n#### 【总结】\n\n在写异常处理的时候，一定要把异常范围小的放在前面，范围大的放在后面，Exception这个异常的根类一定要放在最后一个catch里面，如果放在前面或者中间，任何异常都会和Exception匹配的，就会报已捕获到...异常的错误。 \n\n\n\n<html>\n<div class=\"ds-thread\" data-thread-key=\"http://kongzheng1993.github.io/kongzheng1993-abouttrycatch/\" data-title=\"About trycatch\" data-url=\"http://kongzheng1993.github.io/kongzheng1993\"></div>\n<!-- 多说评论框 end -->\n<!-- 多说公共JS代码 start (一个网页只需插入一次) -->\n<script type=\"text/javascript\">\nvar duoshuoQuery = {short_name:\"kongzheng1993\"};\n    (function() {\n        var ds = document.createElement('script');\n        ds.type = 'text/javascript';ds.async = true;\n        ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';\n        ds.charset = 'UTF-8';\n        (document.getElementsByTagName('head')[0] \n         || document.getElementsByTagName('body')[0]).appendChild(ds);\n    })();\n</script>\n</html>","source":"_posts/2016-07-11-kongzheng1993-ablout_try_catch.md","raw":"---\nlayout: post\ntitle: \"关于try-catch\"\ndate: 2016-07-11\nexcerpt: \"如果catch到一个异常，后面的catch还运行吗？\"\ntags: [catch，try]\ncomments: true\n---\n\n```\n\nimport java.io.IOException;  \npublic class ExceptionTryCatchTest {  \n    public void doSomething() throws IOException{  \n        System.out.println(\"do somthing\");  \n    }  \n    public static void main(String[] args){  \n        ExceptionTryCatchTest etct = new ExceptionTryCatchTest();  \n        try {  \n            etct.doSomething();  \n        } catch (Exception e) {                \n        } catch (IOException e) {                \n        }  \n    }   \n}\n\n```\n\n以上并不能通过编译。\n因为编译的时候会报错:已捕捉到异常 java.io.IOException。  catch(IOException e)这句有错误。 \n分析：对于try..catch捕获异常的形式来说，对于异常的捕获，可以有多个catch。对于try里面发生的异常，他会根据发生的异常和catch里面的进行匹配(怎么匹配，按照catch块从上往下匹配)，当它匹配某一个catch块的时候，他就直接进入到这个catch块里面去了，后面在再有catch块的话，它不做任何处理，直接跳过去，全部忽略掉。如果有finally的话进入到finally里面继续执行。换句话说，如果有匹配的catch，它就会忽略掉这个catch后面所有的catch。对我们这个方法来说，抛出的是IOException，当执行etct.doSomething();时，可能会抛出IOException，一但抛出IOException，它首先进入到catch (Exception e) {}里面，先和Exception匹配，由于IOException extends Exception,根据多态的原则，IOException是匹配Exception的，所以程序就会进入到catch (Exception e) {}里面，进入到第一个catch后，后面的catch都不会执行了，所以catch (IOException e) {}永远都执行不到，就给我们报出了前面的错误:已捕捉到异常 java.io.IOException。 \n\n#### 【总结】\n\n在写异常处理的时候，一定要把异常范围小的放在前面，范围大的放在后面，Exception这个异常的根类一定要放在最后一个catch里面，如果放在前面或者中间，任何异常都会和Exception匹配的，就会报已捕获到...异常的错误。 \n\n\n\n<html>\n<div class=\"ds-thread\" data-thread-key=\"http://kongzheng1993.github.io/kongzheng1993-abouttrycatch/\" data-title=\"About trycatch\" data-url=\"http://kongzheng1993.github.io/kongzheng1993\"></div>\n<!-- 多说评论框 end -->\n<!-- 多说公共JS代码 start (一个网页只需插入一次) -->\n<script type=\"text/javascript\">\nvar duoshuoQuery = {short_name:\"kongzheng1993\"};\n    (function() {\n        var ds = document.createElement('script');\n        ds.type = 'text/javascript';ds.async = true;\n        ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';\n        ds.charset = 'UTF-8';\n        (document.getElementsByTagName('head')[0] \n         || document.getElementsByTagName('body')[0]).appendChild(ds);\n    })();\n</script>\n</html>","slug":"kongzheng1993-ablout_try_catch","published":1,"updated":"2023-03-08T07:05:58.772Z","photos":[],"link":"","_id":"clg0k2abk000it26fkjqdv0bd","content":"<pre><code>\nimport java.io.IOException;  \npublic class ExceptionTryCatchTest {  \n    public void doSomething() throws IOException{  \n        System.out.println(&quot;do somthing&quot;);  \n    }  \n    public static void main(String[] args){  \n        ExceptionTryCatchTest etct = new ExceptionTryCatchTest();  \n        try {  \n            etct.doSomething();  \n        } catch (Exception e) {                \n        } catch (IOException e) {                \n        }  \n    }   \n}\n</code></pre><p>以上并不能通过编译。<br>因为编译的时候会报错:已捕捉到异常 java.io.IOException。  catch(IOException e)这句有错误。<br>分析：对于try..catch捕获异常的形式来说，对于异常的捕获，可以有多个catch。对于try里面发生的异常，他会根据发生的异常和catch里面的进行匹配(怎么匹配，按照catch块从上往下匹配)，当它匹配某一个catch块的时候，他就直接进入到这个catch块里面去了，后面在再有catch块的话，它不做任何处理，直接跳过去，全部忽略掉。如果有finally的话进入到finally里面继续执行。换句话说，如果有匹配的catch，它就会忽略掉这个catch后面所有的catch。对我们这个方法来说，抛出的是IOException，当执行etct.doSomething();时，可能会抛出IOException，一但抛出IOException，它首先进入到catch (Exception e) {}里面，先和Exception匹配，由于IOException extends Exception,根据多态的原则，IOException是匹配Exception的，所以程序就会进入到catch (Exception e) {}里面，进入到第一个catch后，后面的catch都不会执行了，所以catch (IOException e) {}永远都执行不到，就给我们报出了前面的错误:已捕捉到异常 java.io.IOException。 </p>\n<h4 id=\"【总结】\"><a href=\"#【总结】\" class=\"headerlink\" title=\"【总结】\"></a>【总结】</h4><p>在写异常处理的时候，一定要把异常范围小的放在前面，范围大的放在后面，Exception这个异常的根类一定要放在最后一个catch里面，如果放在前面或者中间，任何异常都会和Exception匹配的，就会报已捕获到…异常的错误。 </p>\n<html>\n<div class=\"ds-thread\" data-thread-key=\"http://kongzheng1993.github.io/kongzheng1993-abouttrycatch/\" data-title=\"About trycatch\" data-url=\"http://kongzheng1993.github.io/kongzheng1993\"></div>\n<!-- 多说评论框 end -->\n<!-- 多说公共JS代码 start (一个网页只需插入一次) -->\n<script type=\"text/javascript\">\nvar duoshuoQuery = {short_name:\"kongzheng1993\"};\n    (function() {\n        var ds = document.createElement('script');\n        ds.type = 'text/javascript';ds.async = true;\n        ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';\n        ds.charset = 'UTF-8';\n        (document.getElementsByTagName('head')[0] \n         || document.getElementsByTagName('body')[0]).appendChild(ds);\n    })();\n</script>\n</html>","site":{"data":{}},"more":"<pre><code>\nimport java.io.IOException;  \npublic class ExceptionTryCatchTest {  \n    public void doSomething() throws IOException{  \n        System.out.println(&quot;do somthing&quot;);  \n    }  \n    public static void main(String[] args){  \n        ExceptionTryCatchTest etct = new ExceptionTryCatchTest();  \n        try {  \n            etct.doSomething();  \n        } catch (Exception e) {                \n        } catch (IOException e) {                \n        }  \n    }   \n}\n</code></pre><p>以上并不能通过编译。<br>因为编译的时候会报错:已捕捉到异常 java.io.IOException。  catch(IOException e)这句有错误。<br>分析：对于try..catch捕获异常的形式来说，对于异常的捕获，可以有多个catch。对于try里面发生的异常，他会根据发生的异常和catch里面的进行匹配(怎么匹配，按照catch块从上往下匹配)，当它匹配某一个catch块的时候，他就直接进入到这个catch块里面去了，后面在再有catch块的话，它不做任何处理，直接跳过去，全部忽略掉。如果有finally的话进入到finally里面继续执行。换句话说，如果有匹配的catch，它就会忽略掉这个catch后面所有的catch。对我们这个方法来说，抛出的是IOException，当执行etct.doSomething();时，可能会抛出IOException，一但抛出IOException，它首先进入到catch (Exception e) {}里面，先和Exception匹配，由于IOException extends Exception,根据多态的原则，IOException是匹配Exception的，所以程序就会进入到catch (Exception e) {}里面，进入到第一个catch后，后面的catch都不会执行了，所以catch (IOException e) {}永远都执行不到，就给我们报出了前面的错误:已捕捉到异常 java.io.IOException。 </p>\n<h4 id=\"【总结】\"><a href=\"#【总结】\" class=\"headerlink\" title=\"【总结】\"></a>【总结】</h4><p>在写异常处理的时候，一定要把异常范围小的放在前面，范围大的放在后面，Exception这个异常的根类一定要放在最后一个catch里面，如果放在前面或者中间，任何异常都会和Exception匹配的，就会报已捕获到…异常的错误。 </p>\n<html>\n<div class=\"ds-thread\" data-thread-key=\"http://kongzheng1993.github.io/kongzheng1993-abouttrycatch/\" data-title=\"About trycatch\" data-url=\"http://kongzheng1993.github.io/kongzheng1993\"></div>\n<!-- 多说评论框 end -->\n<!-- 多说公共JS代码 start (一个网页只需插入一次) -->\n<script type=\"text/javascript\">\nvar duoshuoQuery = {short_name:\"kongzheng1993\"};\n    (function() {\n        var ds = document.createElement('script');\n        ds.type = 'text/javascript';ds.async = true;\n        ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';\n        ds.charset = 'UTF-8';\n        (document.getElementsByTagName('head')[0] \n         || document.getElementsByTagName('body')[0]).appendChild(ds);\n    })();\n</script>\n</html>"},{"layout":"post","title":"sql学习笔记","date":"2016-06-09T16:00:00.000Z","excerpt":"","comments":1,"_content":"\n\n## sql学习笔记\n\n### 关于DISTINCT\n\nDISTINCT可以去除重复的内容，但是，如果查询的数据是多个列，那么只有在这多个列的数据都相同的时候才可以消除。如果一个列重复，另一个列不重复，那么这一行也不会被消除。\n\n### 四则运算可以作为SELECT参数\n\n### 给计算结果设计别名\n\nSELECT empno，ename，sal*12 income FROM emp;\n\n这里打印出来的结果中sal*12那一列的列名就是income。\n\n### 常量如果是字符串要使用单引号而不是双引号，如果是数字不用加引号，如果是日期，就要按照日期格式编写。\n\n### 两列内容的连接使用||\n\nselect empno||ename from emp;\n\n这里的使用方法很像java里面的“+”：\n\n<font face=\"黑体\">例如：</font>\n\n\tselect '雇员编号：'|| empno ||',姓名：'|| ename ||',收入：'|| income from student;\n\n\n### BETWEEN 最小值 AND 最大值;\n\n<font color=\"red\">这里一定要注意是闭区间！！！</font>\n\n### 空判断 IS NULL和IS NOT NULL\n\n### IN和NOT IN\n\nBETWEEN AND 给了一个大的可选范围，IN也用来规定一个范围，不过用起来更灵活。\n\n<font face=\"黑体\">例如：</font>\n\nSELECT * FROM emp WHERE empno=1 OR empno=2 OR empno=3;\n这句代码使用IN来做就是：\nSELECT * FROM emp WHERE empno IN (1,2,3);\n\n指定值查找使用IN会比较方便\n\n\n### 关于NOT IN和NULL的问题\n\n使用NOT IN进行范围判断的时候，如果范围里面包括NULL，那么就不会有任何结果。\n\n<font face=\"黑体\">例如：</font>\nSELECT * FROM emp WHERE empno NOT IN(1,2,3,NULL);\n\n之所以使用WHERE，就是要抓取有用信息，没有限制，显示所有行，对于大型数据库根本没有意义。\n\n使用NOT IN的目的是为了查询部分数据行，但是如果有了NULL（某些数据永远不可能为NULL）,就成了查询全部了。\n\n\n\n为什么sql里面NOT IN后面的子查询如果有记录为NULL的，主查询就查不到记录？？？原因很简单：\nSELECT *\nFROM dbo.TableA AS a\nWHERE a.id NOT IN ( 2, NULL )\n\n等同于：\nSELECT *\nFROM Table_A AS a\nWHERE a.id <> 2\nAND a.ID <> NULL\n\n\n\n<font color=\"red\">于NULL值不能参与比较运算符，导致条件不成立，查询不出来数据。</font>\n\n\n### LIKE\n\n\"_\":匹配任意以为字符；\n\"%\":匹配任意的零位，多位字符。\n\n<font face=\"黑体\">注意：</font>\nLIKE 可以应用在各种数据类型上，不一定是字符串；\nLIKE 如果不设置关键字，那么表示查询全部信息，就像LIKE '%%'。虽然这样可以查询全部数据，但是与不使用WHERE子句相比，不使用WHERE子句的效率更高。\n\n### ORDER BY\n\n排序方式有两种ASC(默认)和DESC。\n\n\n### COUNT(),MAX(),MIN(),SUM(),AVG()\n\ncount是统计个数，里面可以跟上<font color=\"red\">distinct</font>字段。\nmax和min也可以用于<font color=\"red\">日期</font>类型的数据。\n\n<font face=\"黑体\">注意：</font>\n\nCOUNT(*),COUNT(字段),COUNT(DISTINCT 字段)的区别？\n\n* COUNT(*):明确的返回表中的数据个数，是最准确的；\n* COUNT(字段):不统计为null的数据个数，如果某一列的数据不可能为null，那么结果与COUNT(*)相同；\n* COUNT(DISTINCT 字段):统计消除掉重复数据后的数据个数。\n\n\n\n### GROUP BY\n\n```\n\nSELECT job,COUNT(empno),AVG(sal)\nFROM emp\nGROUP BY job;\n\n```\n\n\n```\n\nSELECT DEPTNO,COUNT(empno),MAX(SAL),MIN(SAL)\nFROM EMP\nGROUP BY DEPTNO;\n\n\n```\n* 没有编写group by子句的时候（全表作为一组），那么select子句之中只允许出现统计函数，不允许出现其他字段。\n例如：\nselect count(empno),ename from emp;\n这里查询结果里面第一列已经显示了empno的数目了，这肯定只有一行，所以第二列不可能列出很多行ename的数据了，因为这不符合数据库的表达形式。\n\n\n* 在使用group by子句分组的时候，select子句之中只允许出现分组字段与统计函数，其他字段不允许出现。\n\n正确代码：\n```\nselect job,count(empno) from emp group by job;\n```\n\n错误代码：\n```\nselect job,count(empno),ename from group by job; \n```\n\n* 统计函数允许嵌套查询，但是嵌套后的统计查询中，select子句中不允许再出现任何的字段，包括分组字段，只能够使用嵌套的统计函数。\n\n正确代码：\n\n```\n\nSELECT deptno,AVG(sal)\nFROM emp \nGROUP BY deptno;\n\n```\n\n错误代码：\n\n```\nSELECT deptno,MAX(AVG(sal))\nFROM emp\nGROUP BY deptno;\n```\n这里已经有了嵌套的统计函数，就不能再有deptno了。\n\n\n修改：\n\n```\nSELECT MAX(AVG(sal))\nFROM emp\nGROUP BY deptno;\n\n```\n\n### 多表查询\n\n<font face=\"黑体\">示例：</font>\n\n查询出每个部门的名称、人数、平均工资：\n\n分析：\n1.确定要使用的表：\n（1）dept:部门名称\n（2）emp:统计出人数，平均工资\n2.确定已知的关联字段：\n雇员与部门：emp.deptno=dept.deptno\n\n\n#### 第一步：查询每个雇员的编号，部门名称，工资\n```\n\nSELECT e.empno,d.dnama,e.sal\nFROM emp e,dept d\nWHERE e.deptno=d.deptno;\n\n```\n\n#### 第二步：通过以上的查询可以发现dname字段上出现了重复查询，有重复数据才可以分组。另外我们的查询明确要求是根据部门名称分组，现在对查询结果分组。（上面查询出来的结果可以看作是一张临时数据表）\n\n```\n\nSELECT e.empno,d.dnama,e.sal\nFROM emp e,dept d\nWHERE e.deptno=d.deptno\nGROUP BY d.name;\n\n```\n\n#### 第三步：部门一共有三个，但是我们现在只出现了三个，加入外连接控制\n\n```\n\nSELECT e.empno,d.dnama,e.sal\nFROM emp e,dept d\nWHERE e.deptno(+)=d.deptno\nGROUP BY d.name;\n\n```\n\n#### 查询成功。\n\n\n\n\n\n\n\n\n\n\n\n<html>\n<div class=\"ds-thread\" data-thread-key=\"http://kongzheng1993.github.io/kongzheng1993-sql/\" data-title=\"lover\" data-url=\"http://kongzheng1993.github.io/kongzheng1993-sql/\"></div>\n<!-- 多说评论框 end -->\n<!-- 多说公共JS代码 start (一个网页只需插入一次) -->\n<script type=\"text/javascript\">\nvar duoshuoQuery = {short_name:\"kongzheng1993\"};\n\t(function() {\n\t\tvar ds = document.createElement('script');\n\t\tds.type = 'text/javascript';ds.async = true;\n\t\tds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';\n\t\tds.charset = 'UTF-8';\n\t\t(document.getElementsByTagName('head')[0] \n\t\t || document.getElementsByTagName('body')[0]).appendChild(ds);\n\t})();\n</script>\n</html>\n","source":"_posts/2016-07-13-kongzheng1993-oracle.md","raw":"---\nlayout: post\ntitle: \"sql学习笔记\"\ndate: 2016-06-10\nexcerpt: \"love you forever\"\ntags: [sql,select,distinct,group by,order by]\ncomments: true\n---\n\n\n## sql学习笔记\n\n### 关于DISTINCT\n\nDISTINCT可以去除重复的内容，但是，如果查询的数据是多个列，那么只有在这多个列的数据都相同的时候才可以消除。如果一个列重复，另一个列不重复，那么这一行也不会被消除。\n\n### 四则运算可以作为SELECT参数\n\n### 给计算结果设计别名\n\nSELECT empno，ename，sal*12 income FROM emp;\n\n这里打印出来的结果中sal*12那一列的列名就是income。\n\n### 常量如果是字符串要使用单引号而不是双引号，如果是数字不用加引号，如果是日期，就要按照日期格式编写。\n\n### 两列内容的连接使用||\n\nselect empno||ename from emp;\n\n这里的使用方法很像java里面的“+”：\n\n<font face=\"黑体\">例如：</font>\n\n\tselect '雇员编号：'|| empno ||',姓名：'|| ename ||',收入：'|| income from student;\n\n\n### BETWEEN 最小值 AND 最大值;\n\n<font color=\"red\">这里一定要注意是闭区间！！！</font>\n\n### 空判断 IS NULL和IS NOT NULL\n\n### IN和NOT IN\n\nBETWEEN AND 给了一个大的可选范围，IN也用来规定一个范围，不过用起来更灵活。\n\n<font face=\"黑体\">例如：</font>\n\nSELECT * FROM emp WHERE empno=1 OR empno=2 OR empno=3;\n这句代码使用IN来做就是：\nSELECT * FROM emp WHERE empno IN (1,2,3);\n\n指定值查找使用IN会比较方便\n\n\n### 关于NOT IN和NULL的问题\n\n使用NOT IN进行范围判断的时候，如果范围里面包括NULL，那么就不会有任何结果。\n\n<font face=\"黑体\">例如：</font>\nSELECT * FROM emp WHERE empno NOT IN(1,2,3,NULL);\n\n之所以使用WHERE，就是要抓取有用信息，没有限制，显示所有行，对于大型数据库根本没有意义。\n\n使用NOT IN的目的是为了查询部分数据行，但是如果有了NULL（某些数据永远不可能为NULL）,就成了查询全部了。\n\n\n\n为什么sql里面NOT IN后面的子查询如果有记录为NULL的，主查询就查不到记录？？？原因很简单：\nSELECT *\nFROM dbo.TableA AS a\nWHERE a.id NOT IN ( 2, NULL )\n\n等同于：\nSELECT *\nFROM Table_A AS a\nWHERE a.id <> 2\nAND a.ID <> NULL\n\n\n\n<font color=\"red\">于NULL值不能参与比较运算符，导致条件不成立，查询不出来数据。</font>\n\n\n### LIKE\n\n\"_\":匹配任意以为字符；\n\"%\":匹配任意的零位，多位字符。\n\n<font face=\"黑体\">注意：</font>\nLIKE 可以应用在各种数据类型上，不一定是字符串；\nLIKE 如果不设置关键字，那么表示查询全部信息，就像LIKE '%%'。虽然这样可以查询全部数据，但是与不使用WHERE子句相比，不使用WHERE子句的效率更高。\n\n### ORDER BY\n\n排序方式有两种ASC(默认)和DESC。\n\n\n### COUNT(),MAX(),MIN(),SUM(),AVG()\n\ncount是统计个数，里面可以跟上<font color=\"red\">distinct</font>字段。\nmax和min也可以用于<font color=\"red\">日期</font>类型的数据。\n\n<font face=\"黑体\">注意：</font>\n\nCOUNT(*),COUNT(字段),COUNT(DISTINCT 字段)的区别？\n\n* COUNT(*):明确的返回表中的数据个数，是最准确的；\n* COUNT(字段):不统计为null的数据个数，如果某一列的数据不可能为null，那么结果与COUNT(*)相同；\n* COUNT(DISTINCT 字段):统计消除掉重复数据后的数据个数。\n\n\n\n### GROUP BY\n\n```\n\nSELECT job,COUNT(empno),AVG(sal)\nFROM emp\nGROUP BY job;\n\n```\n\n\n```\n\nSELECT DEPTNO,COUNT(empno),MAX(SAL),MIN(SAL)\nFROM EMP\nGROUP BY DEPTNO;\n\n\n```\n* 没有编写group by子句的时候（全表作为一组），那么select子句之中只允许出现统计函数，不允许出现其他字段。\n例如：\nselect count(empno),ename from emp;\n这里查询结果里面第一列已经显示了empno的数目了，这肯定只有一行，所以第二列不可能列出很多行ename的数据了，因为这不符合数据库的表达形式。\n\n\n* 在使用group by子句分组的时候，select子句之中只允许出现分组字段与统计函数，其他字段不允许出现。\n\n正确代码：\n```\nselect job,count(empno) from emp group by job;\n```\n\n错误代码：\n```\nselect job,count(empno),ename from group by job; \n```\n\n* 统计函数允许嵌套查询，但是嵌套后的统计查询中，select子句中不允许再出现任何的字段，包括分组字段，只能够使用嵌套的统计函数。\n\n正确代码：\n\n```\n\nSELECT deptno,AVG(sal)\nFROM emp \nGROUP BY deptno;\n\n```\n\n错误代码：\n\n```\nSELECT deptno,MAX(AVG(sal))\nFROM emp\nGROUP BY deptno;\n```\n这里已经有了嵌套的统计函数，就不能再有deptno了。\n\n\n修改：\n\n```\nSELECT MAX(AVG(sal))\nFROM emp\nGROUP BY deptno;\n\n```\n\n### 多表查询\n\n<font face=\"黑体\">示例：</font>\n\n查询出每个部门的名称、人数、平均工资：\n\n分析：\n1.确定要使用的表：\n（1）dept:部门名称\n（2）emp:统计出人数，平均工资\n2.确定已知的关联字段：\n雇员与部门：emp.deptno=dept.deptno\n\n\n#### 第一步：查询每个雇员的编号，部门名称，工资\n```\n\nSELECT e.empno,d.dnama,e.sal\nFROM emp e,dept d\nWHERE e.deptno=d.deptno;\n\n```\n\n#### 第二步：通过以上的查询可以发现dname字段上出现了重复查询，有重复数据才可以分组。另外我们的查询明确要求是根据部门名称分组，现在对查询结果分组。（上面查询出来的结果可以看作是一张临时数据表）\n\n```\n\nSELECT e.empno,d.dnama,e.sal\nFROM emp e,dept d\nWHERE e.deptno=d.deptno\nGROUP BY d.name;\n\n```\n\n#### 第三步：部门一共有三个，但是我们现在只出现了三个，加入外连接控制\n\n```\n\nSELECT e.empno,d.dnama,e.sal\nFROM emp e,dept d\nWHERE e.deptno(+)=d.deptno\nGROUP BY d.name;\n\n```\n\n#### 查询成功。\n\n\n\n\n\n\n\n\n\n\n\n<html>\n<div class=\"ds-thread\" data-thread-key=\"http://kongzheng1993.github.io/kongzheng1993-sql/\" data-title=\"lover\" data-url=\"http://kongzheng1993.github.io/kongzheng1993-sql/\"></div>\n<!-- 多说评论框 end -->\n<!-- 多说公共JS代码 start (一个网页只需插入一次) -->\n<script type=\"text/javascript\">\nvar duoshuoQuery = {short_name:\"kongzheng1993\"};\n\t(function() {\n\t\tvar ds = document.createElement('script');\n\t\tds.type = 'text/javascript';ds.async = true;\n\t\tds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';\n\t\tds.charset = 'UTF-8';\n\t\t(document.getElementsByTagName('head')[0] \n\t\t || document.getElementsByTagName('body')[0]).appendChild(ds);\n\t})();\n</script>\n</html>\n","slug":"kongzheng1993-oracle","published":1,"updated":"2023-03-08T07:05:58.772Z","photos":[],"link":"","_id":"clg0k2abl000kt26fdpdzy47w","content":"<h2 id=\"sql学习笔记\"><a href=\"#sql学习笔记\" class=\"headerlink\" title=\"sql学习笔记\"></a>sql学习笔记</h2><h3 id=\"关于DISTINCT\"><a href=\"#关于DISTINCT\" class=\"headerlink\" title=\"关于DISTINCT\"></a>关于DISTINCT</h3><p>DISTINCT可以去除重复的内容，但是，如果查询的数据是多个列，那么只有在这多个列的数据都相同的时候才可以消除。如果一个列重复，另一个列不重复，那么这一行也不会被消除。</p>\n<h3 id=\"四则运算可以作为SELECT参数\"><a href=\"#四则运算可以作为SELECT参数\" class=\"headerlink\" title=\"四则运算可以作为SELECT参数\"></a>四则运算可以作为SELECT参数</h3><h3 id=\"给计算结果设计别名\"><a href=\"#给计算结果设计别名\" class=\"headerlink\" title=\"给计算结果设计别名\"></a>给计算结果设计别名</h3><p>SELECT empno，ename，sal*12 income FROM emp;</p>\n<p>这里打印出来的结果中sal*12那一列的列名就是income。</p>\n<h3 id=\"常量如果是字符串要使用单引号而不是双引号，如果是数字不用加引号，如果是日期，就要按照日期格式编写。\"><a href=\"#常量如果是字符串要使用单引号而不是双引号，如果是数字不用加引号，如果是日期，就要按照日期格式编写。\" class=\"headerlink\" title=\"常量如果是字符串要使用单引号而不是双引号，如果是数字不用加引号，如果是日期，就要按照日期格式编写。\"></a>常量如果是字符串要使用单引号而不是双引号，如果是数字不用加引号，如果是日期，就要按照日期格式编写。</h3><h3 id=\"两列内容的连接使用\"><a href=\"#两列内容的连接使用\" class=\"headerlink\" title=\"两列内容的连接使用||\"></a>两列内容的连接使用||</h3><p>select empno||ename from emp;</p>\n<p>这里的使用方法很像java里面的“+”：</p>\n<p><font face=\"黑体\">例如：</font></p>\n<pre><code>select &#39;雇员编号：&#39;|| empno ||&#39;,姓名：&#39;|| ename ||&#39;,收入：&#39;|| income from student;</code></pre><h3 id=\"BETWEEN-最小值-AND-最大值\"><a href=\"#BETWEEN-最小值-AND-最大值\" class=\"headerlink\" title=\"BETWEEN 最小值 AND 最大值;\"></a>BETWEEN 最小值 AND 最大值;</h3><p><font color=\"red\">这里一定要注意是闭区间！！！</font></p>\n<h3 id=\"空判断-IS-NULL和IS-NOT-NULL\"><a href=\"#空判断-IS-NULL和IS-NOT-NULL\" class=\"headerlink\" title=\"空判断 IS NULL和IS NOT NULL\"></a>空判断 IS NULL和IS NOT NULL</h3><h3 id=\"IN和NOT-IN\"><a href=\"#IN和NOT-IN\" class=\"headerlink\" title=\"IN和NOT IN\"></a>IN和NOT IN</h3><p>BETWEEN AND 给了一个大的可选范围，IN也用来规定一个范围，不过用起来更灵活。</p>\n<p><font face=\"黑体\">例如：</font></p>\n<p>SELECT * FROM emp WHERE empno=1 OR empno=2 OR empno=3;<br>这句代码使用IN来做就是：<br>SELECT * FROM emp WHERE empno IN (1,2,3);</p>\n<p>指定值查找使用IN会比较方便</p>\n<h3 id=\"关于NOT-IN和NULL的问题\"><a href=\"#关于NOT-IN和NULL的问题\" class=\"headerlink\" title=\"关于NOT IN和NULL的问题\"></a>关于NOT IN和NULL的问题</h3><p>使用NOT IN进行范围判断的时候，如果范围里面包括NULL，那么就不会有任何结果。</p>\n<p><font face=\"黑体\">例如：</font><br>SELECT * FROM emp WHERE empno NOT IN(1,2,3,NULL);</p>\n<p>之所以使用WHERE，就是要抓取有用信息，没有限制，显示所有行，对于大型数据库根本没有意义。</p>\n<p>使用NOT IN的目的是为了查询部分数据行，但是如果有了NULL（某些数据永远不可能为NULL）,就成了查询全部了。</p>\n<p>为什么sql里面NOT IN后面的子查询如果有记录为NULL的，主查询就查不到记录？？？原因很简单：<br>SELECT *\nFROM dbo.TableA AS a<br>WHERE a.id NOT IN ( 2, NULL )</p>\n<p>等同于：<br>SELECT *\nFROM Table_A AS a<br>WHERE a.id &lt;&gt; 2<br>AND a.ID &lt;&gt; NULL</p>\n<p><font color=\"red\">于NULL值不能参与比较运算符，导致条件不成立，查询不出来数据。</font></p>\n<h3 id=\"LIKE\"><a href=\"#LIKE\" class=\"headerlink\" title=\"LIKE\"></a>LIKE</h3><p>“_”:匹配任意以为字符；<br>“%”:匹配任意的零位，多位字符。</p>\n<p><font face=\"黑体\">注意：</font><br>LIKE 可以应用在各种数据类型上，不一定是字符串；<br>LIKE 如果不设置关键字，那么表示查询全部信息，就像LIKE ‘%%’。虽然这样可以查询全部数据，但是与不使用WHERE子句相比，不使用WHERE子句的效率更高。</p>\n<h3 id=\"ORDER-BY\"><a href=\"#ORDER-BY\" class=\"headerlink\" title=\"ORDER BY\"></a>ORDER BY</h3><p>排序方式有两种ASC(默认)和DESC。</p>\n<h3 id=\"COUNT-MAX-MIN-SUM-AVG\"><a href=\"#COUNT-MAX-MIN-SUM-AVG\" class=\"headerlink\" title=\"COUNT(),MAX(),MIN(),SUM(),AVG()\"></a>COUNT(),MAX(),MIN(),SUM(),AVG()</h3><p>count是统计个数，里面可以跟上<font color=\"red\">distinct</font>字段。<br>max和min也可以用于<font color=\"red\">日期</font>类型的数据。</p>\n<p><font face=\"黑体\">注意：</font></p>\n<p>COUNT(*),COUNT(字段),COUNT(DISTINCT 字段)的区别？</p>\n<ul>\n<li>COUNT(*):明确的返回表中的数据个数，是最准确的；</li>\n<li>COUNT(字段):不统计为null的数据个数，如果某一列的数据不可能为null，那么结果与COUNT(*)相同；</li>\n<li>COUNT(DISTINCT 字段):统计消除掉重复数据后的数据个数。</li>\n</ul>\n<h3 id=\"GROUP-BY\"><a href=\"#GROUP-BY\" class=\"headerlink\" title=\"GROUP BY\"></a>GROUP BY</h3><pre><code>\nSELECT job,COUNT(empno),AVG(sal)\nFROM emp\nGROUP BY job;\n</code></pre><pre><code>\nSELECT DEPTNO,COUNT(empno),MAX(SAL),MIN(SAL)\nFROM EMP\nGROUP BY DEPTNO;\n\n</code></pre><ul>\n<li>没有编写group by子句的时候（全表作为一组），那么select子句之中只允许出现统计函数，不允许出现其他字段。<br>例如：<br>select count(empno),ename from emp;<br>这里查询结果里面第一列已经显示了empno的数目了，这肯定只有一行，所以第二列不可能列出很多行ename的数据了，因为这不符合数据库的表达形式。</li>\n</ul>\n<ul>\n<li>在使用group by子句分组的时候，select子句之中只允许出现分组字段与统计函数，其他字段不允许出现。</li>\n</ul>\n<p>正确代码：</p>\n<pre><code>select job,count(empno) from emp group by job;</code></pre><p>错误代码：</p>\n<pre><code>select job,count(empno),ename from group by job; </code></pre><ul>\n<li>统计函数允许嵌套查询，但是嵌套后的统计查询中，select子句中不允许再出现任何的字段，包括分组字段，只能够使用嵌套的统计函数。</li>\n</ul>\n<p>正确代码：</p>\n<pre><code>\nSELECT deptno,AVG(sal)\nFROM emp \nGROUP BY deptno;\n</code></pre><p>错误代码：</p>\n<pre><code>SELECT deptno,MAX(AVG(sal))\nFROM emp\nGROUP BY deptno;</code></pre><p>这里已经有了嵌套的统计函数，就不能再有deptno了。</p>\n<p>修改：</p>\n<pre><code>SELECT MAX(AVG(sal))\nFROM emp\nGROUP BY deptno;\n</code></pre><h3 id=\"多表查询\"><a href=\"#多表查询\" class=\"headerlink\" title=\"多表查询\"></a>多表查询</h3><p><font face=\"黑体\">示例：</font></p>\n<p>查询出每个部门的名称、人数、平均工资：</p>\n<p>分析：<br>1.确定要使用的表：<br>（1）dept:部门名称<br>（2）emp:统计出人数，平均工资<br>2.确定已知的关联字段：<br>雇员与部门：emp.deptno=dept.deptno</p>\n<h4 id=\"第一步：查询每个雇员的编号，部门名称，工资\"><a href=\"#第一步：查询每个雇员的编号，部门名称，工资\" class=\"headerlink\" title=\"第一步：查询每个雇员的编号，部门名称，工资\"></a>第一步：查询每个雇员的编号，部门名称，工资</h4><pre><code>\nSELECT e.empno,d.dnama,e.sal\nFROM emp e,dept d\nWHERE e.deptno=d.deptno;\n</code></pre><h4 id=\"第二步：通过以上的查询可以发现dname字段上出现了重复查询，有重复数据才可以分组。另外我们的查询明确要求是根据部门名称分组，现在对查询结果分组。（上面查询出来的结果可以看作是一张临时数据表）\"><a href=\"#第二步：通过以上的查询可以发现dname字段上出现了重复查询，有重复数据才可以分组。另外我们的查询明确要求是根据部门名称分组，现在对查询结果分组。（上面查询出来的结果可以看作是一张临时数据表）\" class=\"headerlink\" title=\"第二步：通过以上的查询可以发现dname字段上出现了重复查询，有重复数据才可以分组。另外我们的查询明确要求是根据部门名称分组，现在对查询结果分组。（上面查询出来的结果可以看作是一张临时数据表）\"></a>第二步：通过以上的查询可以发现dname字段上出现了重复查询，有重复数据才可以分组。另外我们的查询明确要求是根据部门名称分组，现在对查询结果分组。（上面查询出来的结果可以看作是一张临时数据表）</h4><pre><code>\nSELECT e.empno,d.dnama,e.sal\nFROM emp e,dept d\nWHERE e.deptno=d.deptno\nGROUP BY d.name;\n</code></pre><h4 id=\"第三步：部门一共有三个，但是我们现在只出现了三个，加入外连接控制\"><a href=\"#第三步：部门一共有三个，但是我们现在只出现了三个，加入外连接控制\" class=\"headerlink\" title=\"第三步：部门一共有三个，但是我们现在只出现了三个，加入外连接控制\"></a>第三步：部门一共有三个，但是我们现在只出现了三个，加入外连接控制</h4><pre><code>\nSELECT e.empno,d.dnama,e.sal\nFROM emp e,dept d\nWHERE e.deptno(+)=d.deptno\nGROUP BY d.name;\n</code></pre><h4 id=\"查询成功。\"><a href=\"#查询成功。\" class=\"headerlink\" title=\"查询成功。\"></a>查询成功。</h4><html>\n<div class=\"ds-thread\" data-thread-key=\"http://kongzheng1993.github.io/kongzheng1993-sql/\" data-title=\"lover\" data-url=\"http://kongzheng1993.github.io/kongzheng1993-sql/\"></div>\n<!-- 多说评论框 end -->\n<!-- 多说公共JS代码 start (一个网页只需插入一次) -->\n<script type=\"text/javascript\">\nvar duoshuoQuery = {short_name:\"kongzheng1993\"};\n    (function() {\n        var ds = document.createElement('script');\n        ds.type = 'text/javascript';ds.async = true;\n        ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';\n        ds.charset = 'UTF-8';\n        (document.getElementsByTagName('head')[0] \n         || document.getElementsByTagName('body')[0]).appendChild(ds);\n    })();\n</script>\n</html>\n","site":{"data":{}},"more":"<h2 id=\"sql学习笔记\"><a href=\"#sql学习笔记\" class=\"headerlink\" title=\"sql学习笔记\"></a>sql学习笔记</h2><h3 id=\"关于DISTINCT\"><a href=\"#关于DISTINCT\" class=\"headerlink\" title=\"关于DISTINCT\"></a>关于DISTINCT</h3><p>DISTINCT可以去除重复的内容，但是，如果查询的数据是多个列，那么只有在这多个列的数据都相同的时候才可以消除。如果一个列重复，另一个列不重复，那么这一行也不会被消除。</p>\n<h3 id=\"四则运算可以作为SELECT参数\"><a href=\"#四则运算可以作为SELECT参数\" class=\"headerlink\" title=\"四则运算可以作为SELECT参数\"></a>四则运算可以作为SELECT参数</h3><h3 id=\"给计算结果设计别名\"><a href=\"#给计算结果设计别名\" class=\"headerlink\" title=\"给计算结果设计别名\"></a>给计算结果设计别名</h3><p>SELECT empno，ename，sal*12 income FROM emp;</p>\n<p>这里打印出来的结果中sal*12那一列的列名就是income。</p>\n<h3 id=\"常量如果是字符串要使用单引号而不是双引号，如果是数字不用加引号，如果是日期，就要按照日期格式编写。\"><a href=\"#常量如果是字符串要使用单引号而不是双引号，如果是数字不用加引号，如果是日期，就要按照日期格式编写。\" class=\"headerlink\" title=\"常量如果是字符串要使用单引号而不是双引号，如果是数字不用加引号，如果是日期，就要按照日期格式编写。\"></a>常量如果是字符串要使用单引号而不是双引号，如果是数字不用加引号，如果是日期，就要按照日期格式编写。</h3><h3 id=\"两列内容的连接使用\"><a href=\"#两列内容的连接使用\" class=\"headerlink\" title=\"两列内容的连接使用||\"></a>两列内容的连接使用||</h3><p>select empno||ename from emp;</p>\n<p>这里的使用方法很像java里面的“+”：</p>\n<p><font face=\"黑体\">例如：</font></p>\n<pre><code>select &#39;雇员编号：&#39;|| empno ||&#39;,姓名：&#39;|| ename ||&#39;,收入：&#39;|| income from student;</code></pre><h3 id=\"BETWEEN-最小值-AND-最大值\"><a href=\"#BETWEEN-最小值-AND-最大值\" class=\"headerlink\" title=\"BETWEEN 最小值 AND 最大值;\"></a>BETWEEN 最小值 AND 最大值;</h3><p><font color=\"red\">这里一定要注意是闭区间！！！</font></p>\n<h3 id=\"空判断-IS-NULL和IS-NOT-NULL\"><a href=\"#空判断-IS-NULL和IS-NOT-NULL\" class=\"headerlink\" title=\"空判断 IS NULL和IS NOT NULL\"></a>空判断 IS NULL和IS NOT NULL</h3><h3 id=\"IN和NOT-IN\"><a href=\"#IN和NOT-IN\" class=\"headerlink\" title=\"IN和NOT IN\"></a>IN和NOT IN</h3><p>BETWEEN AND 给了一个大的可选范围，IN也用来规定一个范围，不过用起来更灵活。</p>\n<p><font face=\"黑体\">例如：</font></p>\n<p>SELECT * FROM emp WHERE empno=1 OR empno=2 OR empno=3;<br>这句代码使用IN来做就是：<br>SELECT * FROM emp WHERE empno IN (1,2,3);</p>\n<p>指定值查找使用IN会比较方便</p>\n<h3 id=\"关于NOT-IN和NULL的问题\"><a href=\"#关于NOT-IN和NULL的问题\" class=\"headerlink\" title=\"关于NOT IN和NULL的问题\"></a>关于NOT IN和NULL的问题</h3><p>使用NOT IN进行范围判断的时候，如果范围里面包括NULL，那么就不会有任何结果。</p>\n<p><font face=\"黑体\">例如：</font><br>SELECT * FROM emp WHERE empno NOT IN(1,2,3,NULL);</p>\n<p>之所以使用WHERE，就是要抓取有用信息，没有限制，显示所有行，对于大型数据库根本没有意义。</p>\n<p>使用NOT IN的目的是为了查询部分数据行，但是如果有了NULL（某些数据永远不可能为NULL）,就成了查询全部了。</p>\n<p>为什么sql里面NOT IN后面的子查询如果有记录为NULL的，主查询就查不到记录？？？原因很简单：<br>SELECT *\nFROM dbo.TableA AS a<br>WHERE a.id NOT IN ( 2, NULL )</p>\n<p>等同于：<br>SELECT *\nFROM Table_A AS a<br>WHERE a.id &lt;&gt; 2<br>AND a.ID &lt;&gt; NULL</p>\n<p><font color=\"red\">于NULL值不能参与比较运算符，导致条件不成立，查询不出来数据。</font></p>\n<h3 id=\"LIKE\"><a href=\"#LIKE\" class=\"headerlink\" title=\"LIKE\"></a>LIKE</h3><p>“_”:匹配任意以为字符；<br>“%”:匹配任意的零位，多位字符。</p>\n<p><font face=\"黑体\">注意：</font><br>LIKE 可以应用在各种数据类型上，不一定是字符串；<br>LIKE 如果不设置关键字，那么表示查询全部信息，就像LIKE ‘%%’。虽然这样可以查询全部数据，但是与不使用WHERE子句相比，不使用WHERE子句的效率更高。</p>\n<h3 id=\"ORDER-BY\"><a href=\"#ORDER-BY\" class=\"headerlink\" title=\"ORDER BY\"></a>ORDER BY</h3><p>排序方式有两种ASC(默认)和DESC。</p>\n<h3 id=\"COUNT-MAX-MIN-SUM-AVG\"><a href=\"#COUNT-MAX-MIN-SUM-AVG\" class=\"headerlink\" title=\"COUNT(),MAX(),MIN(),SUM(),AVG()\"></a>COUNT(),MAX(),MIN(),SUM(),AVG()</h3><p>count是统计个数，里面可以跟上<font color=\"red\">distinct</font>字段。<br>max和min也可以用于<font color=\"red\">日期</font>类型的数据。</p>\n<p><font face=\"黑体\">注意：</font></p>\n<p>COUNT(*),COUNT(字段),COUNT(DISTINCT 字段)的区别？</p>\n<ul>\n<li>COUNT(*):明确的返回表中的数据个数，是最准确的；</li>\n<li>COUNT(字段):不统计为null的数据个数，如果某一列的数据不可能为null，那么结果与COUNT(*)相同；</li>\n<li>COUNT(DISTINCT 字段):统计消除掉重复数据后的数据个数。</li>\n</ul>\n<h3 id=\"GROUP-BY\"><a href=\"#GROUP-BY\" class=\"headerlink\" title=\"GROUP BY\"></a>GROUP BY</h3><pre><code>\nSELECT job,COUNT(empno),AVG(sal)\nFROM emp\nGROUP BY job;\n</code></pre><pre><code>\nSELECT DEPTNO,COUNT(empno),MAX(SAL),MIN(SAL)\nFROM EMP\nGROUP BY DEPTNO;\n\n</code></pre><ul>\n<li>没有编写group by子句的时候（全表作为一组），那么select子句之中只允许出现统计函数，不允许出现其他字段。<br>例如：<br>select count(empno),ename from emp;<br>这里查询结果里面第一列已经显示了empno的数目了，这肯定只有一行，所以第二列不可能列出很多行ename的数据了，因为这不符合数据库的表达形式。</li>\n</ul>\n<ul>\n<li>在使用group by子句分组的时候，select子句之中只允许出现分组字段与统计函数，其他字段不允许出现。</li>\n</ul>\n<p>正确代码：</p>\n<pre><code>select job,count(empno) from emp group by job;</code></pre><p>错误代码：</p>\n<pre><code>select job,count(empno),ename from group by job; </code></pre><ul>\n<li>统计函数允许嵌套查询，但是嵌套后的统计查询中，select子句中不允许再出现任何的字段，包括分组字段，只能够使用嵌套的统计函数。</li>\n</ul>\n<p>正确代码：</p>\n<pre><code>\nSELECT deptno,AVG(sal)\nFROM emp \nGROUP BY deptno;\n</code></pre><p>错误代码：</p>\n<pre><code>SELECT deptno,MAX(AVG(sal))\nFROM emp\nGROUP BY deptno;</code></pre><p>这里已经有了嵌套的统计函数，就不能再有deptno了。</p>\n<p>修改：</p>\n<pre><code>SELECT MAX(AVG(sal))\nFROM emp\nGROUP BY deptno;\n</code></pre><h3 id=\"多表查询\"><a href=\"#多表查询\" class=\"headerlink\" title=\"多表查询\"></a>多表查询</h3><p><font face=\"黑体\">示例：</font></p>\n<p>查询出每个部门的名称、人数、平均工资：</p>\n<p>分析：<br>1.确定要使用的表：<br>（1）dept:部门名称<br>（2）emp:统计出人数，平均工资<br>2.确定已知的关联字段：<br>雇员与部门：emp.deptno=dept.deptno</p>\n<h4 id=\"第一步：查询每个雇员的编号，部门名称，工资\"><a href=\"#第一步：查询每个雇员的编号，部门名称，工资\" class=\"headerlink\" title=\"第一步：查询每个雇员的编号，部门名称，工资\"></a>第一步：查询每个雇员的编号，部门名称，工资</h4><pre><code>\nSELECT e.empno,d.dnama,e.sal\nFROM emp e,dept d\nWHERE e.deptno=d.deptno;\n</code></pre><h4 id=\"第二步：通过以上的查询可以发现dname字段上出现了重复查询，有重复数据才可以分组。另外我们的查询明确要求是根据部门名称分组，现在对查询结果分组。（上面查询出来的结果可以看作是一张临时数据表）\"><a href=\"#第二步：通过以上的查询可以发现dname字段上出现了重复查询，有重复数据才可以分组。另外我们的查询明确要求是根据部门名称分组，现在对查询结果分组。（上面查询出来的结果可以看作是一张临时数据表）\" class=\"headerlink\" title=\"第二步：通过以上的查询可以发现dname字段上出现了重复查询，有重复数据才可以分组。另外我们的查询明确要求是根据部门名称分组，现在对查询结果分组。（上面查询出来的结果可以看作是一张临时数据表）\"></a>第二步：通过以上的查询可以发现dname字段上出现了重复查询，有重复数据才可以分组。另外我们的查询明确要求是根据部门名称分组，现在对查询结果分组。（上面查询出来的结果可以看作是一张临时数据表）</h4><pre><code>\nSELECT e.empno,d.dnama,e.sal\nFROM emp e,dept d\nWHERE e.deptno=d.deptno\nGROUP BY d.name;\n</code></pre><h4 id=\"第三步：部门一共有三个，但是我们现在只出现了三个，加入外连接控制\"><a href=\"#第三步：部门一共有三个，但是我们现在只出现了三个，加入外连接控制\" class=\"headerlink\" title=\"第三步：部门一共有三个，但是我们现在只出现了三个，加入外连接控制\"></a>第三步：部门一共有三个，但是我们现在只出现了三个，加入外连接控制</h4><pre><code>\nSELECT e.empno,d.dnama,e.sal\nFROM emp e,dept d\nWHERE e.deptno(+)=d.deptno\nGROUP BY d.name;\n</code></pre><h4 id=\"查询成功。\"><a href=\"#查询成功。\" class=\"headerlink\" title=\"查询成功。\"></a>查询成功。</h4><html>\n<div class=\"ds-thread\" data-thread-key=\"http://kongzheng1993.github.io/kongzheng1993-sql/\" data-title=\"lover\" data-url=\"http://kongzheng1993.github.io/kongzheng1993-sql/\"></div>\n<!-- 多说评论框 end -->\n<!-- 多说公共JS代码 start (一个网页只需插入一次) -->\n<script type=\"text/javascript\">\nvar duoshuoQuery = {short_name:\"kongzheng1993\"};\n    (function() {\n        var ds = document.createElement('script');\n        ds.type = 'text/javascript';ds.async = true;\n        ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';\n        ds.charset = 'UTF-8';\n        (document.getElementsByTagName('head')[0] \n         || document.getElementsByTagName('body')[0]).appendChild(ds);\n    })();\n</script>\n</html>\n"},{"layout":"post","title":"修改主机名oracle无法正常启动","date":"2016-07-19T16:00:00.000Z","excerpt":"","comments":1,"_content":"\n在刚开始学习Oracle时，安装完Oracle后，我发现我的主机名不是很炫酷，就去计算机管理把电脑的名字改成了EvilRat，然后我的Oracle就连不上了，因为listener服务一直启动不了，显示类似下面的情况：（图是从网上找的，不好在弄回去截图了，大家知道是什么情况能解决问题就行）。\n<center>\n<img src=\"/assets/img/oracle_listener.bmp\">\n</center>\n然后我从网上查了资料，发现是因为listener的配置文件里面的主机名还没有改过来，于是我就是手动改过来了。\n<center>\n<img src=\"/assets/img/listener.bmp\">\n</center>\n将箭头指的地方修改后，应该就没问题了，这是我真是遇到的问题，希望可以帮助到大家。\n\n\n\n\n\n\n\n\n<html>\n<div class=\"ds-thread\" data-thread-key=\"http://kongzheng1993.github.io/kongzheng1993-oraclepcname/\" data-title=\"oraclepcname\" data-url=\"http://kongzheng1993.github.io/kongzheng1993-oraclepcname/\"></div>\n<script type=\"text/javascript\">\nvar duoshuoQuery = {short_name:\"kongzheng1993\"};\n\t(function() {\n\t\tvar ds = document.createElement('script');\n\t\tds.type = 'text/javascript';ds.async = true;\n\t\tds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';\n\t\tds.charset = 'UTF-8';\n\t\t(document.getElementsByTagName('head')[0] \n\t\t || document.getElementsByTagName('body')[0]).appendChild(ds);\n\t})();\n</script>\n</html>\n","source":"_posts/2016-07-21-kongzheng1993-OracleAfterChangetheNameofComputer.md","raw":"---\nlayout: post\ntitle: \"修改主机名oracle无法正常启动\"\ndate: 2016-07-20\nexcerpt: \"oracle\"\ntags: [oracle]\ncomments: true\n---\n\n在刚开始学习Oracle时，安装完Oracle后，我发现我的主机名不是很炫酷，就去计算机管理把电脑的名字改成了EvilRat，然后我的Oracle就连不上了，因为listener服务一直启动不了，显示类似下面的情况：（图是从网上找的，不好在弄回去截图了，大家知道是什么情况能解决问题就行）。\n<center>\n<img src=\"/assets/img/oracle_listener.bmp\">\n</center>\n然后我从网上查了资料，发现是因为listener的配置文件里面的主机名还没有改过来，于是我就是手动改过来了。\n<center>\n<img src=\"/assets/img/listener.bmp\">\n</center>\n将箭头指的地方修改后，应该就没问题了，这是我真是遇到的问题，希望可以帮助到大家。\n\n\n\n\n\n\n\n\n<html>\n<div class=\"ds-thread\" data-thread-key=\"http://kongzheng1993.github.io/kongzheng1993-oraclepcname/\" data-title=\"oraclepcname\" data-url=\"http://kongzheng1993.github.io/kongzheng1993-oraclepcname/\"></div>\n<script type=\"text/javascript\">\nvar duoshuoQuery = {short_name:\"kongzheng1993\"};\n\t(function() {\n\t\tvar ds = document.createElement('script');\n\t\tds.type = 'text/javascript';ds.async = true;\n\t\tds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';\n\t\tds.charset = 'UTF-8';\n\t\t(document.getElementsByTagName('head')[0] \n\t\t || document.getElementsByTagName('body')[0]).appendChild(ds);\n\t})();\n</script>\n</html>\n","slug":"kongzheng1993-OracleAfterChangetheNameofComputer","published":1,"updated":"2023-03-08T07:05:58.772Z","photos":[],"link":"","_id":"clg0k2abl000mt26fwgstu05j","content":"<p>在刚开始学习Oracle时，安装完Oracle后，我发现我的主机名不是很炫酷，就去计算机管理把电脑的名字改成了EvilRat，然后我的Oracle就连不上了，因为listener服务一直启动不了，显示类似下面的情况：（图是从网上找的，不好在弄回去截图了，大家知道是什么情况能解决问题就行）。</p>\n<center>\n<img src=\"/2016/07/20/kongzheng1993-OracleAfterChangetheNameofComputer/assets/img/oracle_listener.bmp\">\n</center>\n然后我从网上查了资料，发现是因为listener的配置文件里面的主机名还没有改过来，于是我就是手动改过来了。\n<center>\n<img src=\"/2016/07/20/kongzheng1993-OracleAfterChangetheNameofComputer/assets/img/listener.bmp\">\n</center>\n将箭头指的地方修改后，应该就没问题了，这是我真是遇到的问题，希望可以帮助到大家。\n\n\n\n\n\n\n\n\n<html>\n<div class=\"ds-thread\" data-thread-key=\"http://kongzheng1993.github.io/kongzheng1993-oraclepcname/\" data-title=\"oraclepcname\" data-url=\"http://kongzheng1993.github.io/kongzheng1993-oraclepcname/\"></div>\n<script type=\"text/javascript\">\nvar duoshuoQuery = {short_name:\"kongzheng1993\"};\n    (function() {\n        var ds = document.createElement('script');\n        ds.type = 'text/javascript';ds.async = true;\n        ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';\n        ds.charset = 'UTF-8';\n        (document.getElementsByTagName('head')[0] \n         || document.getElementsByTagName('body')[0]).appendChild(ds);\n    })();\n</script>\n</html>\n","site":{"data":{}},"more":"<p>在刚开始学习Oracle时，安装完Oracle后，我发现我的主机名不是很炫酷，就去计算机管理把电脑的名字改成了EvilRat，然后我的Oracle就连不上了，因为listener服务一直启动不了，显示类似下面的情况：（图是从网上找的，不好在弄回去截图了，大家知道是什么情况能解决问题就行）。</p>\n<center>\n<img src=\"/2016/07/20/kongzheng1993-OracleAfterChangetheNameofComputer/assets/img/oracle_listener.bmp\">\n</center>\n然后我从网上查了资料，发现是因为listener的配置文件里面的主机名还没有改过来，于是我就是手动改过来了。\n<center>\n<img src=\"/2016/07/20/kongzheng1993-OracleAfterChangetheNameofComputer/assets/img/listener.bmp\">\n</center>\n将箭头指的地方修改后，应该就没问题了，这是我真是遇到的问题，希望可以帮助到大家。\n\n\n\n\n\n\n\n\n<html>\n<div class=\"ds-thread\" data-thread-key=\"http://kongzheng1993.github.io/kongzheng1993-oraclepcname/\" data-title=\"oraclepcname\" data-url=\"http://kongzheng1993.github.io/kongzheng1993-oraclepcname/\"></div>\n<script type=\"text/javascript\">\nvar duoshuoQuery = {short_name:\"kongzheng1993\"};\n    (function() {\n        var ds = document.createElement('script');\n        ds.type = 'text/javascript';ds.async = true;\n        ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';\n        ds.charset = 'UTF-8';\n        (document.getElementsByTagName('head')[0] \n         || document.getElementsByTagName('body')[0]).appendChild(ds);\n    })();\n</script>\n</html>\n"},{"layout":"post","title":"PreparedStatement的优点","date":"2016-07-04T16:00:00.000Z","excerpt":"","comments":1,"_content":"\n### 在JDBC应用中,如果你已经是稍有水平开发者,你就应该始终以PreparedStatement代替Statement.也就是说,在任何时候都不要使用Statement\n\n#### 一.代码的可读性和可维护性\n\n虽然用PreparedStatement来代替Statement会使代码多出几行,但这样的代码无论从可读性还是可维护性上来说.都比直接用Statement的代码高很多档次:\n\n```\n\nstmt.executeUpdate(\"insert into tb_name (col1,col2,col2,col4) values ('\"+var1+\"','\"+var2+\"',\"+var3+\",'\"+var4+\"')\");\n\nperstmt = con.prepareStatement(\"insert into tb_name (col1,col2,col2,col4) values (?,?,?,?)\");\nperstmt.setString(1,var1);\nperstmt.setString(2,var2);\nperstmt.setString(3,var3);\nperstmt.setString(4,var4);\nperstmt.executeUpdate();\n\n```\n\n\n哪一种更好，一目了然。\n\n#### 二.PreparedStatement尽最大可能提高性能.\n\n每一种数据库都会尽最大努力对预编译语句提供最大的性能优化.因为预编译语句有可能被重复调用.所以语句在被DB的编译器编译后的执行代码被缓存下来,那么下次调用时只要是相同的预编译语句就不需要编译,只要将参数直接传入编译过的语句执行代码中(相当于一个涵数)就会得到执行.这并不是说只有一个Connection中多次执行的预编译语句被缓存,而是对于整个DB中,只要预编译的语句语法和缓存中匹配.那么在任何时候就可以不需要再次编译而可以直接执行.而statement的语句中,即使是相同一操作,而由于每次操作的数据不同所以使整个语句相匹配的机会极小,几乎不太可能匹配.比如:\ninsert into tb_name (col1,col2) values ('11','22');\ninsert into tb_name (col1,col2) values ('11','23');\n即使是相同操作但因为数据内容不一样,所以整个个语句本身不能匹配,没有缓存语句的意义.事实是没有数据库会对普通语句编译后的执行代码缓存.这样每执行一次都要对传入的语句编译一次.\n\n当然并不是所以预编译语句都一定会被缓存,数据库本身会用一种策略,比如使用频度等因素来决定什么时候不再缓存已有的预编译结果.以保存有更多的空间存储新的预编译语句.\n\n\n#### 三.最重要的一点是极大地提高了安全性.\n\n即使到目前为止,仍有一些人连基本的恶义SQL语法都不知道.\n\n```\n\nString sql = \"select * from tb_name where name= '\"+varname+\"' and passwd='\"+varpasswd+\"'\";\n\n```\n\n如果我们把[' or '1' = '1]作为varpasswd传入进来.用户名随意,看看会成为什么?\n\nselect * from tb_name = '随意' and passwd = '' or '1' = '1';\n因为'1'='1'肯定成立,所以可以任何通过验证.更有甚者:\n把[';drop table tb_name;]作为varpasswd传入进来,则:\nselect * from tb_name = '随意' and passwd = '';drop table tb_name;有些数据库是不会让你成功的,但也有很多数据库就可以使这些语句得到执行.\n\n而如果你使用预编译语句.你传入的任何内容就不会和原来的语句发生任何匹配的关系.(前提是数据库本身支持预编译,但上前可能没有什么服务端数据库不支持编译了,只有少数的桌面数据库,就是直接文件访问的那些)只要全使用预编译语句,你就用不着对传入的数据做任何过虑.而如果使用普通的statement,有可能要对drop,;等做费尽心机的判断和过虑.\n\n\n\n\n\n\n\n<html>\n<div class=\"ds-thread\" data-thread-key=\"http://kongzheng1993.github.io/kongzheng1993-PreparedStatement/\" data-title=\"PreparedStatement\" data-url=\"http://kongzheng1993.github.io/kongzheng1993-PreparedStatement/\"></div>\n<script type=\"text/javascript\">\nvar duoshuoQuery = {short_name:\"kongzheng1993\"};\n\t(function() {\n\t\tvar ds = document.createElement('script');\n\t\tds.type = 'text/javascript';ds.async = true;\n\t\tds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';\n\t\tds.charset = 'UTF-8';\n\t\t(document.getElementsByTagName('head')[0] \n\t\t || document.getElementsByTagName('body')[0]).appendChild(ds);\n\t})();\n</script>\n</html>","source":"_posts/2016-07-05-kongzheng1993-PreparedStatement&Statement.md","raw":"---\nlayout: post\ntitle:  \"PreparedStatement的优点\"\ndate:   2016-07-5\nexcerpt: \"PreparedStatement和Statement对比\"\ntag:\n- oop\ncomments: true\n---\n\n### 在JDBC应用中,如果你已经是稍有水平开发者,你就应该始终以PreparedStatement代替Statement.也就是说,在任何时候都不要使用Statement\n\n#### 一.代码的可读性和可维护性\n\n虽然用PreparedStatement来代替Statement会使代码多出几行,但这样的代码无论从可读性还是可维护性上来说.都比直接用Statement的代码高很多档次:\n\n```\n\nstmt.executeUpdate(\"insert into tb_name (col1,col2,col2,col4) values ('\"+var1+\"','\"+var2+\"',\"+var3+\",'\"+var4+\"')\");\n\nperstmt = con.prepareStatement(\"insert into tb_name (col1,col2,col2,col4) values (?,?,?,?)\");\nperstmt.setString(1,var1);\nperstmt.setString(2,var2);\nperstmt.setString(3,var3);\nperstmt.setString(4,var4);\nperstmt.executeUpdate();\n\n```\n\n\n哪一种更好，一目了然。\n\n#### 二.PreparedStatement尽最大可能提高性能.\n\n每一种数据库都会尽最大努力对预编译语句提供最大的性能优化.因为预编译语句有可能被重复调用.所以语句在被DB的编译器编译后的执行代码被缓存下来,那么下次调用时只要是相同的预编译语句就不需要编译,只要将参数直接传入编译过的语句执行代码中(相当于一个涵数)就会得到执行.这并不是说只有一个Connection中多次执行的预编译语句被缓存,而是对于整个DB中,只要预编译的语句语法和缓存中匹配.那么在任何时候就可以不需要再次编译而可以直接执行.而statement的语句中,即使是相同一操作,而由于每次操作的数据不同所以使整个语句相匹配的机会极小,几乎不太可能匹配.比如:\ninsert into tb_name (col1,col2) values ('11','22');\ninsert into tb_name (col1,col2) values ('11','23');\n即使是相同操作但因为数据内容不一样,所以整个个语句本身不能匹配,没有缓存语句的意义.事实是没有数据库会对普通语句编译后的执行代码缓存.这样每执行一次都要对传入的语句编译一次.\n\n当然并不是所以预编译语句都一定会被缓存,数据库本身会用一种策略,比如使用频度等因素来决定什么时候不再缓存已有的预编译结果.以保存有更多的空间存储新的预编译语句.\n\n\n#### 三.最重要的一点是极大地提高了安全性.\n\n即使到目前为止,仍有一些人连基本的恶义SQL语法都不知道.\n\n```\n\nString sql = \"select * from tb_name where name= '\"+varname+\"' and passwd='\"+varpasswd+\"'\";\n\n```\n\n如果我们把[' or '1' = '1]作为varpasswd传入进来.用户名随意,看看会成为什么?\n\nselect * from tb_name = '随意' and passwd = '' or '1' = '1';\n因为'1'='1'肯定成立,所以可以任何通过验证.更有甚者:\n把[';drop table tb_name;]作为varpasswd传入进来,则:\nselect * from tb_name = '随意' and passwd = '';drop table tb_name;有些数据库是不会让你成功的,但也有很多数据库就可以使这些语句得到执行.\n\n而如果你使用预编译语句.你传入的任何内容就不会和原来的语句发生任何匹配的关系.(前提是数据库本身支持预编译,但上前可能没有什么服务端数据库不支持编译了,只有少数的桌面数据库,就是直接文件访问的那些)只要全使用预编译语句,你就用不着对传入的数据做任何过虑.而如果使用普通的statement,有可能要对drop,;等做费尽心机的判断和过虑.\n\n\n\n\n\n\n\n<html>\n<div class=\"ds-thread\" data-thread-key=\"http://kongzheng1993.github.io/kongzheng1993-PreparedStatement/\" data-title=\"PreparedStatement\" data-url=\"http://kongzheng1993.github.io/kongzheng1993-PreparedStatement/\"></div>\n<script type=\"text/javascript\">\nvar duoshuoQuery = {short_name:\"kongzheng1993\"};\n\t(function() {\n\t\tvar ds = document.createElement('script');\n\t\tds.type = 'text/javascript';ds.async = true;\n\t\tds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';\n\t\tds.charset = 'UTF-8';\n\t\t(document.getElementsByTagName('head')[0] \n\t\t || document.getElementsByTagName('body')[0]).appendChild(ds);\n\t})();\n</script>\n</html>","slug":"kongzheng1993-PreparedStatement&Statement","published":1,"updated":"2023-03-08T07:05:58.772Z","photos":[],"link":"","_id":"clg0k2abm000ot26fp84nuwku","content":"<h3 id=\"在JDBC应用中-如果你已经是稍有水平开发者-你就应该始终以PreparedStatement代替Statement-也就是说-在任何时候都不要使用Statement\"><a href=\"#在JDBC应用中-如果你已经是稍有水平开发者-你就应该始终以PreparedStatement代替Statement-也就是说-在任何时候都不要使用Statement\" class=\"headerlink\" title=\"在JDBC应用中,如果你已经是稍有水平开发者,你就应该始终以PreparedStatement代替Statement.也就是说,在任何时候都不要使用Statement\"></a>在JDBC应用中,如果你已经是稍有水平开发者,你就应该始终以PreparedStatement代替Statement.也就是说,在任何时候都不要使用Statement</h3><h4 id=\"一-代码的可读性和可维护性\"><a href=\"#一-代码的可读性和可维护性\" class=\"headerlink\" title=\"一.代码的可读性和可维护性\"></a>一.代码的可读性和可维护性</h4><p>虽然用PreparedStatement来代替Statement会使代码多出几行,但这样的代码无论从可读性还是可维护性上来说.都比直接用Statement的代码高很多档次:</p>\n<pre><code>\nstmt.executeUpdate(&quot;insert into tb_name (col1,col2,col2,col4) values (&#39;&quot;+var1+&quot;&#39;,&#39;&quot;+var2+&quot;&#39;,&quot;+var3+&quot;,&#39;&quot;+var4+&quot;&#39;)&quot;);\n\nperstmt = con.prepareStatement(&quot;insert into tb_name (col1,col2,col2,col4) values (?,?,?,?)&quot;);\nperstmt.setString(1,var1);\nperstmt.setString(2,var2);\nperstmt.setString(3,var3);\nperstmt.setString(4,var4);\nperstmt.executeUpdate();\n</code></pre><p>哪一种更好，一目了然。</p>\n<h4 id=\"二-PreparedStatement尽最大可能提高性能\"><a href=\"#二-PreparedStatement尽最大可能提高性能\" class=\"headerlink\" title=\"二.PreparedStatement尽最大可能提高性能.\"></a>二.PreparedStatement尽最大可能提高性能.</h4><p>每一种数据库都会尽最大努力对预编译语句提供最大的性能优化.因为预编译语句有可能被重复调用.所以语句在被DB的编译器编译后的执行代码被缓存下来,那么下次调用时只要是相同的预编译语句就不需要编译,只要将参数直接传入编译过的语句执行代码中(相当于一个涵数)就会得到执行.这并不是说只有一个Connection中多次执行的预编译语句被缓存,而是对于整个DB中,只要预编译的语句语法和缓存中匹配.那么在任何时候就可以不需要再次编译而可以直接执行.而statement的语句中,即使是相同一操作,而由于每次操作的数据不同所以使整个语句相匹配的机会极小,几乎不太可能匹配.比如:<br>insert into tb_name (col1,col2) values (‘11’,’22’);<br>insert into tb_name (col1,col2) values (‘11’,’23’);<br>即使是相同操作但因为数据内容不一样,所以整个个语句本身不能匹配,没有缓存语句的意义.事实是没有数据库会对普通语句编译后的执行代码缓存.这样每执行一次都要对传入的语句编译一次.</p>\n<p>当然并不是所以预编译语句都一定会被缓存,数据库本身会用一种策略,比如使用频度等因素来决定什么时候不再缓存已有的预编译结果.以保存有更多的空间存储新的预编译语句.</p>\n<h4 id=\"三-最重要的一点是极大地提高了安全性\"><a href=\"#三-最重要的一点是极大地提高了安全性\" class=\"headerlink\" title=\"三.最重要的一点是极大地提高了安全性.\"></a>三.最重要的一点是极大地提高了安全性.</h4><p>即使到目前为止,仍有一些人连基本的恶义SQL语法都不知道.</p>\n<pre><code>\nString sql = &quot;select * from tb_name where name= &#39;&quot;+varname+&quot;&#39; and passwd=&#39;&quot;+varpasswd+&quot;&#39;&quot;;\n</code></pre><p>如果我们把[‘ or ‘1’ = ‘1]作为varpasswd传入进来.用户名随意,看看会成为什么?</p>\n<p>select * from tb_name = ‘随意’ and passwd = ‘’ or ‘1’ = ‘1’;<br>因为’1’=’1’肯定成立,所以可以任何通过验证.更有甚者:<br>把[‘;drop table tb_name;]作为varpasswd传入进来,则:<br>select * from tb_name = ‘随意’ and passwd = ‘’;drop table tb_name;有些数据库是不会让你成功的,但也有很多数据库就可以使这些语句得到执行.</p>\n<p>而如果你使用预编译语句.你传入的任何内容就不会和原来的语句发生任何匹配的关系.(前提是数据库本身支持预编译,但上前可能没有什么服务端数据库不支持编译了,只有少数的桌面数据库,就是直接文件访问的那些)只要全使用预编译语句,你就用不着对传入的数据做任何过虑.而如果使用普通的statement,有可能要对drop,;等做费尽心机的判断和过虑.</p>\n<html>\n<div class=\"ds-thread\" data-thread-key=\"http://kongzheng1993.github.io/kongzheng1993-PreparedStatement/\" data-title=\"PreparedStatement\" data-url=\"http://kongzheng1993.github.io/kongzheng1993-PreparedStatement/\"></div>\n<script type=\"text/javascript\">\nvar duoshuoQuery = {short_name:\"kongzheng1993\"};\n    (function() {\n        var ds = document.createElement('script');\n        ds.type = 'text/javascript';ds.async = true;\n        ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';\n        ds.charset = 'UTF-8';\n        (document.getElementsByTagName('head')[0] \n         || document.getElementsByTagName('body')[0]).appendChild(ds);\n    })();\n</script>\n</html>","site":{"data":{}},"more":"<h3 id=\"在JDBC应用中-如果你已经是稍有水平开发者-你就应该始终以PreparedStatement代替Statement-也就是说-在任何时候都不要使用Statement\"><a href=\"#在JDBC应用中-如果你已经是稍有水平开发者-你就应该始终以PreparedStatement代替Statement-也就是说-在任何时候都不要使用Statement\" class=\"headerlink\" title=\"在JDBC应用中,如果你已经是稍有水平开发者,你就应该始终以PreparedStatement代替Statement.也就是说,在任何时候都不要使用Statement\"></a>在JDBC应用中,如果你已经是稍有水平开发者,你就应该始终以PreparedStatement代替Statement.也就是说,在任何时候都不要使用Statement</h3><h4 id=\"一-代码的可读性和可维护性\"><a href=\"#一-代码的可读性和可维护性\" class=\"headerlink\" title=\"一.代码的可读性和可维护性\"></a>一.代码的可读性和可维护性</h4><p>虽然用PreparedStatement来代替Statement会使代码多出几行,但这样的代码无论从可读性还是可维护性上来说.都比直接用Statement的代码高很多档次:</p>\n<pre><code>\nstmt.executeUpdate(&quot;insert into tb_name (col1,col2,col2,col4) values (&#39;&quot;+var1+&quot;&#39;,&#39;&quot;+var2+&quot;&#39;,&quot;+var3+&quot;,&#39;&quot;+var4+&quot;&#39;)&quot;);\n\nperstmt = con.prepareStatement(&quot;insert into tb_name (col1,col2,col2,col4) values (?,?,?,?)&quot;);\nperstmt.setString(1,var1);\nperstmt.setString(2,var2);\nperstmt.setString(3,var3);\nperstmt.setString(4,var4);\nperstmt.executeUpdate();\n</code></pre><p>哪一种更好，一目了然。</p>\n<h4 id=\"二-PreparedStatement尽最大可能提高性能\"><a href=\"#二-PreparedStatement尽最大可能提高性能\" class=\"headerlink\" title=\"二.PreparedStatement尽最大可能提高性能.\"></a>二.PreparedStatement尽最大可能提高性能.</h4><p>每一种数据库都会尽最大努力对预编译语句提供最大的性能优化.因为预编译语句有可能被重复调用.所以语句在被DB的编译器编译后的执行代码被缓存下来,那么下次调用时只要是相同的预编译语句就不需要编译,只要将参数直接传入编译过的语句执行代码中(相当于一个涵数)就会得到执行.这并不是说只有一个Connection中多次执行的预编译语句被缓存,而是对于整个DB中,只要预编译的语句语法和缓存中匹配.那么在任何时候就可以不需要再次编译而可以直接执行.而statement的语句中,即使是相同一操作,而由于每次操作的数据不同所以使整个语句相匹配的机会极小,几乎不太可能匹配.比如:<br>insert into tb_name (col1,col2) values (‘11’,’22’);<br>insert into tb_name (col1,col2) values (‘11’,’23’);<br>即使是相同操作但因为数据内容不一样,所以整个个语句本身不能匹配,没有缓存语句的意义.事实是没有数据库会对普通语句编译后的执行代码缓存.这样每执行一次都要对传入的语句编译一次.</p>\n<p>当然并不是所以预编译语句都一定会被缓存,数据库本身会用一种策略,比如使用频度等因素来决定什么时候不再缓存已有的预编译结果.以保存有更多的空间存储新的预编译语句.</p>\n<h4 id=\"三-最重要的一点是极大地提高了安全性\"><a href=\"#三-最重要的一点是极大地提高了安全性\" class=\"headerlink\" title=\"三.最重要的一点是极大地提高了安全性.\"></a>三.最重要的一点是极大地提高了安全性.</h4><p>即使到目前为止,仍有一些人连基本的恶义SQL语法都不知道.</p>\n<pre><code>\nString sql = &quot;select * from tb_name where name= &#39;&quot;+varname+&quot;&#39; and passwd=&#39;&quot;+varpasswd+&quot;&#39;&quot;;\n</code></pre><p>如果我们把[‘ or ‘1’ = ‘1]作为varpasswd传入进来.用户名随意,看看会成为什么?</p>\n<p>select * from tb_name = ‘随意’ and passwd = ‘’ or ‘1’ = ‘1’;<br>因为’1’=’1’肯定成立,所以可以任何通过验证.更有甚者:<br>把[‘;drop table tb_name;]作为varpasswd传入进来,则:<br>select * from tb_name = ‘随意’ and passwd = ‘’;drop table tb_name;有些数据库是不会让你成功的,但也有很多数据库就可以使这些语句得到执行.</p>\n<p>而如果你使用预编译语句.你传入的任何内容就不会和原来的语句发生任何匹配的关系.(前提是数据库本身支持预编译,但上前可能没有什么服务端数据库不支持编译了,只有少数的桌面数据库,就是直接文件访问的那些)只要全使用预编译语句,你就用不着对传入的数据做任何过虑.而如果使用普通的statement,有可能要对drop,;等做费尽心机的判断和过虑.</p>\n<html>\n<div class=\"ds-thread\" data-thread-key=\"http://kongzheng1993.github.io/kongzheng1993-PreparedStatement/\" data-title=\"PreparedStatement\" data-url=\"http://kongzheng1993.github.io/kongzheng1993-PreparedStatement/\"></div>\n<script type=\"text/javascript\">\nvar duoshuoQuery = {short_name:\"kongzheng1993\"};\n    (function() {\n        var ds = document.createElement('script');\n        ds.type = 'text/javascript';ds.async = true;\n        ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';\n        ds.charset = 'UTF-8';\n        (document.getElementsByTagName('head')[0] \n         || document.getElementsByTagName('body')[0]).appendChild(ds);\n    })();\n</script>\n</html>"},{"layout":"post","title":"使用sys登陆sqlplus的问题","date":"2016-06-09T16:00:00.000Z","excerpt":"","comments":1,"_content":"\n\n### 使用sys/root登陆sqlplus\n\n我们用sys/root的账号密码正常登陆sqlplus会出现以下问题：\n\n<img src=\"/assets/img/sqlplus.bmp\">\n\n\n但是我们如果在输入password时不输入我们的密码（root），而是输入sys as sysdba,就可以顺利登陆，我也不知道什么原理，如果有知道的朋友，可以给我留言。\n\n\n如果我们先用其他用户登陆比如learner/learner,然后断开，再使用connect sys/root as sysdba就可以登陆。\n\n<img src=\"/assets/img/sqlplusloginsuccess.bmp\">\n\n\n\n\n\n\n\n\n\n\n\n\n<html>\n<div class=\"ds-thread\" data-thread-key=\"http://kongzheng1993.github.io/kongzheng1993-sqlplusloginsys/\" data-title=\"sqlplusloginsys\" data-url=\"http://kongzheng1993.github.io/kongzheng1993-sqlplusloginsys/\"></div>\n<!-- 多说评论框 end -->\n<!-- 多说公共JS代码 start (一个网页只需插入一次) -->\n<script type=\"text/javascript\">\nvar duoshuoQuery = {short_name:\"kongzheng1993\"};\n\t(function() {\n\t\tvar ds = document.createElement('script');\n\t\tds.type = 'text/javascript';ds.async = true;\n\t\tds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';\n\t\tds.charset = 'UTF-8';\n\t\t(document.getElementsByTagName('head')[0] \n\t\t || document.getElementsByTagName('body')[0]).appendChild(ds);\n\t})();\n</script>\n</html>","source":"_posts/2016-07-23-kongzheng1993-about_sqlplus_sys.md","raw":"---\nlayout: post\ntitle: \"使用sys登陆sqlplus的问题\"\ndate: 2016-06-10\nexcerpt: \"use user sys login sqlplus\"\ntags: [sys,sqlplus,sql]\ncomments: true\n---\n\n\n### 使用sys/root登陆sqlplus\n\n我们用sys/root的账号密码正常登陆sqlplus会出现以下问题：\n\n<img src=\"/assets/img/sqlplus.bmp\">\n\n\n但是我们如果在输入password时不输入我们的密码（root），而是输入sys as sysdba,就可以顺利登陆，我也不知道什么原理，如果有知道的朋友，可以给我留言。\n\n\n如果我们先用其他用户登陆比如learner/learner,然后断开，再使用connect sys/root as sysdba就可以登陆。\n\n<img src=\"/assets/img/sqlplusloginsuccess.bmp\">\n\n\n\n\n\n\n\n\n\n\n\n\n<html>\n<div class=\"ds-thread\" data-thread-key=\"http://kongzheng1993.github.io/kongzheng1993-sqlplusloginsys/\" data-title=\"sqlplusloginsys\" data-url=\"http://kongzheng1993.github.io/kongzheng1993-sqlplusloginsys/\"></div>\n<!-- 多说评论框 end -->\n<!-- 多说公共JS代码 start (一个网页只需插入一次) -->\n<script type=\"text/javascript\">\nvar duoshuoQuery = {short_name:\"kongzheng1993\"};\n\t(function() {\n\t\tvar ds = document.createElement('script');\n\t\tds.type = 'text/javascript';ds.async = true;\n\t\tds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';\n\t\tds.charset = 'UTF-8';\n\t\t(document.getElementsByTagName('head')[0] \n\t\t || document.getElementsByTagName('body')[0]).appendChild(ds);\n\t})();\n</script>\n</html>","slug":"kongzheng1993-about_sqlplus_sys","published":1,"updated":"2023-03-08T07:05:58.772Z","photos":[],"link":"","_id":"clg0k2abn000qt26ftv65xhc8","content":"<h3 id=\"使用sys-root登陆sqlplus\"><a href=\"#使用sys-root登陆sqlplus\" class=\"headerlink\" title=\"使用sys/root登陆sqlplus\"></a>使用sys/root登陆sqlplus</h3><p>我们用sys/root的账号密码正常登陆sqlplus会出现以下问题：</p>\n<img src=\"/2016/06/10/kongzheng1993-about_sqlplus_sys/assets/img/sqlplus.bmp\">\n\n\n<p>但是我们如果在输入password时不输入我们的密码（root），而是输入sys as sysdba,就可以顺利登陆，我也不知道什么原理，如果有知道的朋友，可以给我留言。</p>\n<p>如果我们先用其他用户登陆比如learner/learner,然后断开，再使用connect sys/root as sysdba就可以登陆。</p>\n<img src=\"/2016/06/10/kongzheng1993-about_sqlplus_sys/assets/img/sqlplusloginsuccess.bmp\">\n\n\n\n\n\n\n\n\n\n\n\n\n<html>\n<div class=\"ds-thread\" data-thread-key=\"http://kongzheng1993.github.io/kongzheng1993-sqlplusloginsys/\" data-title=\"sqlplusloginsys\" data-url=\"http://kongzheng1993.github.io/kongzheng1993-sqlplusloginsys/\"></div>\n<!-- 多说评论框 end -->\n<!-- 多说公共JS代码 start (一个网页只需插入一次) -->\n<script type=\"text/javascript\">\nvar duoshuoQuery = {short_name:\"kongzheng1993\"};\n    (function() {\n        var ds = document.createElement('script');\n        ds.type = 'text/javascript';ds.async = true;\n        ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';\n        ds.charset = 'UTF-8';\n        (document.getElementsByTagName('head')[0] \n         || document.getElementsByTagName('body')[0]).appendChild(ds);\n    })();\n</script>\n</html>","site":{"data":{}},"more":"<h3 id=\"使用sys-root登陆sqlplus\"><a href=\"#使用sys-root登陆sqlplus\" class=\"headerlink\" title=\"使用sys/root登陆sqlplus\"></a>使用sys/root登陆sqlplus</h3><p>我们用sys/root的账号密码正常登陆sqlplus会出现以下问题：</p>\n<img src=\"/2016/06/10/kongzheng1993-about_sqlplus_sys/assets/img/sqlplus.bmp\">\n\n\n<p>但是我们如果在输入password时不输入我们的密码（root），而是输入sys as sysdba,就可以顺利登陆，我也不知道什么原理，如果有知道的朋友，可以给我留言。</p>\n<p>如果我们先用其他用户登陆比如learner/learner,然后断开，再使用connect sys/root as sysdba就可以登陆。</p>\n<img src=\"/2016/06/10/kongzheng1993-about_sqlplus_sys/assets/img/sqlplusloginsuccess.bmp\">\n\n\n\n\n\n\n\n\n\n\n\n\n<html>\n<div class=\"ds-thread\" data-thread-key=\"http://kongzheng1993.github.io/kongzheng1993-sqlplusloginsys/\" data-title=\"sqlplusloginsys\" data-url=\"http://kongzheng1993.github.io/kongzheng1993-sqlplusloginsys/\"></div>\n<!-- 多说评论框 end -->\n<!-- 多说公共JS代码 start (一个网页只需插入一次) -->\n<script type=\"text/javascript\">\nvar duoshuoQuery = {short_name:\"kongzheng1993\"};\n    (function() {\n        var ds = document.createElement('script');\n        ds.type = 'text/javascript';ds.async = true;\n        ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';\n        ds.charset = 'UTF-8';\n        (document.getElementsByTagName('head')[0] \n         || document.getElementsByTagName('body')[0]).appendChild(ds);\n    })();\n</script>\n</html>"},{"layout":"post","title":"Java IO","date":"2016-07-21T16:00:00.000Z","excerpt":"","comments":1,"_content":"\n\n## 有关字符串的笔记\n\n\n最近学习到StringBuffer，心中有好些疑问，搜索了一些关于String，StringBuffer，StringBuilder的东西，现在整理一下。\n\n关于这三个类在字符串处理中的位置不言而喻，那么他们到底有什么优缺点，到底什么时候该用谁呢？下面我们从以下几点说明一下：\n\n### 三者在执行速度方面的比较：StringBuilder >  StringBuffer  >  String\n\n### String <（StringBuffer，StringBuilder）的原因\n\n　　　　String：字符串常量\n\n　　　　StringBuffer：字符串变量\n\n　　　　StringBuilder：字符串变量\n\n从上面的名字可以看到，String是“字符串常量”，也就是不可改变的对象。对于这句话的理解你可能会产生这样一个疑问  ，比如这段代码：\n\n```\n\n\n String s = \"abcd\";\n s = s+1;\n System.out.print(s);// result : abcd1\n\n\n```\n\n我们明明就是改变了String型的变量s的，为什么说是没有改变呢? 其实这是一种欺骗，JVM是这样解析这段代码的：首先创建对象s，赋予一个abcd，然后再创建一个新的对象s用来　　　　执行第二行代码，也就是说我们之前对象s并没有变化，所以我们说String类型是不可改变的对象了，由于这种机制，每当用String操作字符串时，实际上是在不断的创建新的对象，而原来的对象就会变为垃圾被ＧＣ回收掉，可想而知这样执行效率会有多底。\n\n而StringBuffer与StringBuilder就不一样了，他们是字符串变量，是可改变的对象，每当我们用它们对字符串做操作时，实际上是在一个对象上操作的，这样就不会像String一样创建一些而外的对象进行操作了，当然速度就快了。\n\n### 一个特殊的例子：\n\n```\n\n String str = “This is only a” + “ simple” + “ test”;\n StringBuffer builder = new StringBuilder(“This is only a”).append(“ simple”).append(“ test”);\n\n \n```\n　　\n\n你会很惊讶的发现，生成str对象的速度简直太快了，而这个时候StringBuffer居然速度上根本一点都不占优势。其实这是JVM的一个把戏，实际上：\n\n\n```\n\n　　　　String str = “This is only a” + “ simple” + “test”;\n\n```\n\n\n其实就是：\n\n```\n\n　　　　String str = “This is only a simple test”;\n\n\n```\n\n所以不需要太多的时间了。但大家这里要注意的是，如果你的字符串是来自另外的String对象的话，速度就没那么快了，譬如：\n\n```\n\n\n　　　　String str2 = “This is only a”;\n\n　　　　String str3 = “ simple”;\n\n　　　　String str4 = “ test”;\n\n　　　　String str1 = str2 +str3 + str4;\n\n\n```\n\n\n\n这时候JVM会规规矩矩的按照原来的方式去做。\n\n### StringBuilder与 StringBuffer\n\n　　　　StringBuilder：线程非安全的\n\n　　　　StringBuffer：线程安全的\n\n当我们在字符串缓冲去被多个线程使用是，JVM不能保证StringBuilder的操作是安全的，虽然他的速度最快，但是可以保证StringBuffer是可以正确操作的。当然大多数情况下就是我们是在单线程下进行的操作，所以大多数情况下是建议用StringBuilder而不用StringBuffer的，就是速度的原因。\n\n \n\n### 对于三者使用的总结： \n\n1.如果要操作少量的数据用 = String\n2.单线程操作字符串缓冲区 下操作大量数据 = StringBuilder\n3.多线程操作字符串缓冲区 下操作大量数据 = StringBuffer\n\n\n\n\n\n\n\n\n\n\n\n<html>\n<div class=\"ds-thread\" data-thread-key=\"http://kongzheng1993.github.io/kongzheng1993-有关字符串的笔记/\" data-title=\"String\" data-url=\"http://kongzheng1993.github.io/kongzheng1993-有关字符串的笔记/\"></div>\n<script type=\"text/javascript\">\nvar duoshuoQuery = {short_name:\"kongzheng1993\"};\n\t(function() {\n\t\tvar ds = document.createElement('script');\n\t\tds.type = 'text/javascript';ds.async = true;\n\t\tds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';\n\t\tds.charset = 'UTF-8';\n\t\t(document.getElementsByTagName('head')[0] \n\t\t || document.getElementsByTagName('body')[0]).appendChild(ds);\n\t})();\n</script>\n</html>\n","source":"_posts/2017-03-08-kongzheng1993-有关字符串的笔记.md","raw":"---\nlayout: post\ntitle:  \"Java IO\"\ndate:   2016-07-22\nexcerpt: \"Java IO\"\ntag:\n- oop\ncomments: true\n---\n\n\n## 有关字符串的笔记\n\n\n最近学习到StringBuffer，心中有好些疑问，搜索了一些关于String，StringBuffer，StringBuilder的东西，现在整理一下。\n\n关于这三个类在字符串处理中的位置不言而喻，那么他们到底有什么优缺点，到底什么时候该用谁呢？下面我们从以下几点说明一下：\n\n### 三者在执行速度方面的比较：StringBuilder >  StringBuffer  >  String\n\n### String <（StringBuffer，StringBuilder）的原因\n\n　　　　String：字符串常量\n\n　　　　StringBuffer：字符串变量\n\n　　　　StringBuilder：字符串变量\n\n从上面的名字可以看到，String是“字符串常量”，也就是不可改变的对象。对于这句话的理解你可能会产生这样一个疑问  ，比如这段代码：\n\n```\n\n\n String s = \"abcd\";\n s = s+1;\n System.out.print(s);// result : abcd1\n\n\n```\n\n我们明明就是改变了String型的变量s的，为什么说是没有改变呢? 其实这是一种欺骗，JVM是这样解析这段代码的：首先创建对象s，赋予一个abcd，然后再创建一个新的对象s用来　　　　执行第二行代码，也就是说我们之前对象s并没有变化，所以我们说String类型是不可改变的对象了，由于这种机制，每当用String操作字符串时，实际上是在不断的创建新的对象，而原来的对象就会变为垃圾被ＧＣ回收掉，可想而知这样执行效率会有多底。\n\n而StringBuffer与StringBuilder就不一样了，他们是字符串变量，是可改变的对象，每当我们用它们对字符串做操作时，实际上是在一个对象上操作的，这样就不会像String一样创建一些而外的对象进行操作了，当然速度就快了。\n\n### 一个特殊的例子：\n\n```\n\n String str = “This is only a” + “ simple” + “ test”;\n StringBuffer builder = new StringBuilder(“This is only a”).append(“ simple”).append(“ test”);\n\n \n```\n　　\n\n你会很惊讶的发现，生成str对象的速度简直太快了，而这个时候StringBuffer居然速度上根本一点都不占优势。其实这是JVM的一个把戏，实际上：\n\n\n```\n\n　　　　String str = “This is only a” + “ simple” + “test”;\n\n```\n\n\n其实就是：\n\n```\n\n　　　　String str = “This is only a simple test”;\n\n\n```\n\n所以不需要太多的时间了。但大家这里要注意的是，如果你的字符串是来自另外的String对象的话，速度就没那么快了，譬如：\n\n```\n\n\n　　　　String str2 = “This is only a”;\n\n　　　　String str3 = “ simple”;\n\n　　　　String str4 = “ test”;\n\n　　　　String str1 = str2 +str3 + str4;\n\n\n```\n\n\n\n这时候JVM会规规矩矩的按照原来的方式去做。\n\n### StringBuilder与 StringBuffer\n\n　　　　StringBuilder：线程非安全的\n\n　　　　StringBuffer：线程安全的\n\n当我们在字符串缓冲去被多个线程使用是，JVM不能保证StringBuilder的操作是安全的，虽然他的速度最快，但是可以保证StringBuffer是可以正确操作的。当然大多数情况下就是我们是在单线程下进行的操作，所以大多数情况下是建议用StringBuilder而不用StringBuffer的，就是速度的原因。\n\n \n\n### 对于三者使用的总结： \n\n1.如果要操作少量的数据用 = String\n2.单线程操作字符串缓冲区 下操作大量数据 = StringBuilder\n3.多线程操作字符串缓冲区 下操作大量数据 = StringBuffer\n\n\n\n\n\n\n\n\n\n\n\n<html>\n<div class=\"ds-thread\" data-thread-key=\"http://kongzheng1993.github.io/kongzheng1993-有关字符串的笔记/\" data-title=\"String\" data-url=\"http://kongzheng1993.github.io/kongzheng1993-有关字符串的笔记/\"></div>\n<script type=\"text/javascript\">\nvar duoshuoQuery = {short_name:\"kongzheng1993\"};\n\t(function() {\n\t\tvar ds = document.createElement('script');\n\t\tds.type = 'text/javascript';ds.async = true;\n\t\tds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';\n\t\tds.charset = 'UTF-8';\n\t\t(document.getElementsByTagName('head')[0] \n\t\t || document.getElementsByTagName('body')[0]).appendChild(ds);\n\t})();\n</script>\n</html>\n","slug":"kongzheng1993-有关字符串的笔记","published":1,"updated":"2023-03-08T07:05:58.773Z","photos":[],"link":"","_id":"clg0k2abn000tt26fm3qwemjv","content":"<h2 id=\"有关字符串的笔记\"><a href=\"#有关字符串的笔记\" class=\"headerlink\" title=\"有关字符串的笔记\"></a>有关字符串的笔记</h2><p>最近学习到StringBuffer，心中有好些疑问，搜索了一些关于String，StringBuffer，StringBuilder的东西，现在整理一下。</p>\n<p>关于这三个类在字符串处理中的位置不言而喻，那么他们到底有什么优缺点，到底什么时候该用谁呢？下面我们从以下几点说明一下：</p>\n<h3 id=\"三者在执行速度方面的比较：StringBuilder-gt-StringBuffer-gt-String\"><a href=\"#三者在执行速度方面的比较：StringBuilder-gt-StringBuffer-gt-String\" class=\"headerlink\" title=\"三者在执行速度方面的比较：StringBuilder &gt;  StringBuffer  &gt;  String\"></a>三者在执行速度方面的比较：StringBuilder &gt;  StringBuffer  &gt;  String</h3><h3 id=\"String-lt-（StringBuffer，StringBuilder）的原因\"><a href=\"#String-lt-（StringBuffer，StringBuilder）的原因\" class=\"headerlink\" title=\"String &lt;（StringBuffer，StringBuilder）的原因\"></a>String &lt;（StringBuffer，StringBuilder）的原因</h3><p>　　　　String：字符串常量</p>\n<p>　　　　StringBuffer：字符串变量</p>\n<p>　　　　StringBuilder：字符串变量</p>\n<p>从上面的名字可以看到，String是“字符串常量”，也就是不可改变的对象。对于这句话的理解你可能会产生这样一个疑问  ，比如这段代码：</p>\n<pre><code>\n\n String s = &quot;abcd&quot;;\n s = s+1;\n System.out.print(s);// result : abcd1\n\n</code></pre><p>我们明明就是改变了String型的变量s的，为什么说是没有改变呢? 其实这是一种欺骗，JVM是这样解析这段代码的：首先创建对象s，赋予一个abcd，然后再创建一个新的对象s用来　　　　执行第二行代码，也就是说我们之前对象s并没有变化，所以我们说String类型是不可改变的对象了，由于这种机制，每当用String操作字符串时，实际上是在不断的创建新的对象，而原来的对象就会变为垃圾被ＧＣ回收掉，可想而知这样执行效率会有多底。</p>\n<p>而StringBuffer与StringBuilder就不一样了，他们是字符串变量，是可改变的对象，每当我们用它们对字符串做操作时，实际上是在一个对象上操作的，这样就不会像String一样创建一些而外的对象进行操作了，当然速度就快了。</p>\n<h3 id=\"一个特殊的例子：\"><a href=\"#一个特殊的例子：\" class=\"headerlink\" title=\"一个特殊的例子：\"></a>一个特殊的例子：</h3><pre><code>\n String str = “This is only a” + “ simple” + “ test”;\n StringBuffer builder = new StringBuilder(“This is only a”).append(“ simple”).append(“ test”);\n\n</code></pre><p>　　</p>\n<p>你会很惊讶的发现，生成str对象的速度简直太快了，而这个时候StringBuffer居然速度上根本一点都不占优势。其实这是JVM的一个把戏，实际上：</p>\n<pre><code>\n　　　　String str = “This is only a” + “ simple” + “test”;\n</code></pre><p>其实就是：</p>\n<pre><code>\n　　　　String str = “This is only a simple test”;\n\n</code></pre><p>所以不需要太多的时间了。但大家这里要注意的是，如果你的字符串是来自另外的String对象的话，速度就没那么快了，譬如：</p>\n<pre><code>\n\n　　　　String str2 = “This is only a”;\n\n　　　　String str3 = “ simple”;\n\n　　　　String str4 = “ test”;\n\n　　　　String str1 = str2 +str3 + str4;\n\n</code></pre><p>这时候JVM会规规矩矩的按照原来的方式去做。</p>\n<h3 id=\"StringBuilder与-StringBuffer\"><a href=\"#StringBuilder与-StringBuffer\" class=\"headerlink\" title=\"StringBuilder与 StringBuffer\"></a>StringBuilder与 StringBuffer</h3><p>　　　　StringBuilder：线程非安全的</p>\n<p>　　　　StringBuffer：线程安全的</p>\n<p>当我们在字符串缓冲去被多个线程使用是，JVM不能保证StringBuilder的操作是安全的，虽然他的速度最快，但是可以保证StringBuffer是可以正确操作的。当然大多数情况下就是我们是在单线程下进行的操作，所以大多数情况下是建议用StringBuilder而不用StringBuffer的，就是速度的原因。</p>\n<h3 id=\"对于三者使用的总结：\"><a href=\"#对于三者使用的总结：\" class=\"headerlink\" title=\"对于三者使用的总结：\"></a>对于三者使用的总结：</h3><p>1.如果要操作少量的数据用 = String<br>2.单线程操作字符串缓冲区 下操作大量数据 = StringBuilder<br>3.多线程操作字符串缓冲区 下操作大量数据 = StringBuffer</p>\n<html>\n<div class=\"ds-thread\" data-thread-key=\"http://kongzheng1993.github.io/kongzheng1993-有关字符串的笔记/\" data-title=\"String\" data-url=\"http://kongzheng1993.github.io/kongzheng1993-有关字符串的笔记/\"></div>\n<script type=\"text/javascript\">\nvar duoshuoQuery = {short_name:\"kongzheng1993\"};\n    (function() {\n        var ds = document.createElement('script');\n        ds.type = 'text/javascript';ds.async = true;\n        ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';\n        ds.charset = 'UTF-8';\n        (document.getElementsByTagName('head')[0] \n         || document.getElementsByTagName('body')[0]).appendChild(ds);\n    })();\n</script>\n</html>\n","site":{"data":{}},"more":"<h2 id=\"有关字符串的笔记\"><a href=\"#有关字符串的笔记\" class=\"headerlink\" title=\"有关字符串的笔记\"></a>有关字符串的笔记</h2><p>最近学习到StringBuffer，心中有好些疑问，搜索了一些关于String，StringBuffer，StringBuilder的东西，现在整理一下。</p>\n<p>关于这三个类在字符串处理中的位置不言而喻，那么他们到底有什么优缺点，到底什么时候该用谁呢？下面我们从以下几点说明一下：</p>\n<h3 id=\"三者在执行速度方面的比较：StringBuilder-gt-StringBuffer-gt-String\"><a href=\"#三者在执行速度方面的比较：StringBuilder-gt-StringBuffer-gt-String\" class=\"headerlink\" title=\"三者在执行速度方面的比较：StringBuilder &gt;  StringBuffer  &gt;  String\"></a>三者在执行速度方面的比较：StringBuilder &gt;  StringBuffer  &gt;  String</h3><h3 id=\"String-lt-（StringBuffer，StringBuilder）的原因\"><a href=\"#String-lt-（StringBuffer，StringBuilder）的原因\" class=\"headerlink\" title=\"String &lt;（StringBuffer，StringBuilder）的原因\"></a>String &lt;（StringBuffer，StringBuilder）的原因</h3><p>　　　　String：字符串常量</p>\n<p>　　　　StringBuffer：字符串变量</p>\n<p>　　　　StringBuilder：字符串变量</p>\n<p>从上面的名字可以看到，String是“字符串常量”，也就是不可改变的对象。对于这句话的理解你可能会产生这样一个疑问  ，比如这段代码：</p>\n<pre><code>\n\n String s = &quot;abcd&quot;;\n s = s+1;\n System.out.print(s);// result : abcd1\n\n</code></pre><p>我们明明就是改变了String型的变量s的，为什么说是没有改变呢? 其实这是一种欺骗，JVM是这样解析这段代码的：首先创建对象s，赋予一个abcd，然后再创建一个新的对象s用来　　　　执行第二行代码，也就是说我们之前对象s并没有变化，所以我们说String类型是不可改变的对象了，由于这种机制，每当用String操作字符串时，实际上是在不断的创建新的对象，而原来的对象就会变为垃圾被ＧＣ回收掉，可想而知这样执行效率会有多底。</p>\n<p>而StringBuffer与StringBuilder就不一样了，他们是字符串变量，是可改变的对象，每当我们用它们对字符串做操作时，实际上是在一个对象上操作的，这样就不会像String一样创建一些而外的对象进行操作了，当然速度就快了。</p>\n<h3 id=\"一个特殊的例子：\"><a href=\"#一个特殊的例子：\" class=\"headerlink\" title=\"一个特殊的例子：\"></a>一个特殊的例子：</h3><pre><code>\n String str = “This is only a” + “ simple” + “ test”;\n StringBuffer builder = new StringBuilder(“This is only a”).append(“ simple”).append(“ test”);\n\n</code></pre><p>　　</p>\n<p>你会很惊讶的发现，生成str对象的速度简直太快了，而这个时候StringBuffer居然速度上根本一点都不占优势。其实这是JVM的一个把戏，实际上：</p>\n<pre><code>\n　　　　String str = “This is only a” + “ simple” + “test”;\n</code></pre><p>其实就是：</p>\n<pre><code>\n　　　　String str = “This is only a simple test”;\n\n</code></pre><p>所以不需要太多的时间了。但大家这里要注意的是，如果你的字符串是来自另外的String对象的话，速度就没那么快了，譬如：</p>\n<pre><code>\n\n　　　　String str2 = “This is only a”;\n\n　　　　String str3 = “ simple”;\n\n　　　　String str4 = “ test”;\n\n　　　　String str1 = str2 +str3 + str4;\n\n</code></pre><p>这时候JVM会规规矩矩的按照原来的方式去做。</p>\n<h3 id=\"StringBuilder与-StringBuffer\"><a href=\"#StringBuilder与-StringBuffer\" class=\"headerlink\" title=\"StringBuilder与 StringBuffer\"></a>StringBuilder与 StringBuffer</h3><p>　　　　StringBuilder：线程非安全的</p>\n<p>　　　　StringBuffer：线程安全的</p>\n<p>当我们在字符串缓冲去被多个线程使用是，JVM不能保证StringBuilder的操作是安全的，虽然他的速度最快，但是可以保证StringBuffer是可以正确操作的。当然大多数情况下就是我们是在单线程下进行的操作，所以大多数情况下是建议用StringBuilder而不用StringBuffer的，就是速度的原因。</p>\n<h3 id=\"对于三者使用的总结：\"><a href=\"#对于三者使用的总结：\" class=\"headerlink\" title=\"对于三者使用的总结：\"></a>对于三者使用的总结：</h3><p>1.如果要操作少量的数据用 = String<br>2.单线程操作字符串缓冲区 下操作大量数据 = StringBuilder<br>3.多线程操作字符串缓冲区 下操作大量数据 = StringBuffer</p>\n<html>\n<div class=\"ds-thread\" data-thread-key=\"http://kongzheng1993.github.io/kongzheng1993-有关字符串的笔记/\" data-title=\"String\" data-url=\"http://kongzheng1993.github.io/kongzheng1993-有关字符串的笔记/\"></div>\n<script type=\"text/javascript\">\nvar duoshuoQuery = {short_name:\"kongzheng1993\"};\n    (function() {\n        var ds = document.createElement('script');\n        ds.type = 'text/javascript';ds.async = true;\n        ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';\n        ds.charset = 'UTF-8';\n        (document.getElementsByTagName('head')[0] \n         || document.getElementsByTagName('body')[0]).appendChild(ds);\n    })();\n</script>\n</html>\n"},{"layout":"post","title":"java反射的学习笔记","date":"2017-03-07T16:00:00.000Z","excerpt":"","comments":1,"_content":"\n\n## java反射学习笔记\n\n\n复习java反射机制，发现我一直没理解Class的对象这个含义，Class是一个类名\n\n```java\n\nimport java.lang.reflect.Method;\n\n/**\n * Created by evilrat on 3/8/17.\n */\npublic class GetMethods {\n\n    public static void main(String [] args){\n\n        Students s = new Students();\n        Class c = s.getClass();\n        Method m = null;\n        try{\n            m = s.getClass().getDeclaredMethod(\"getSex\",null);\n            System.out.println(\"Students类中有方法：\"+m);\n\n        }catch (Exception e){\n            System.out.println(e);\n        }\n    }\n}\n\n\n```\n\n这里先声明了一个Students类的对象，然后调用s.getClass()获得了s的类的对象。这个类的对象是Class类型的。\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n<html>\n<div class=\"ds-thread\" data-thread-key=\"http://kongzheng1993.github.io/kongzheng1993-mto/\" data-title=\"mto\" data-url=\"http://kongzheng1993.github.io/kongzheng1993-mto/\"></div>\n<script type=\"text/javascript\">\nvar duoshuoQuery = {short_name:\"kongzheng1993\"};\n\t(function() {\n\t\tvar ds = document.createElement('script');\n\t\tds.type = 'text/javascript';ds.async = true;\n\t\tds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';\n\t\tds.charset = 'UTF-8';\n\t\t(document.getElementsByTagName('head')[0] \n\t\t || document.getElementsByTagName('body')[0]).appendChild(ds);\n\t})();\n</script>\n</html>\n\n\n","source":"_posts/2017-03-08-kongzheng1993-JavaReflect.md","raw":"---\nlayout: post\ntitle: \"java反射的学习笔记\"\ndate: 2017-03-08\nexcerpt: \"java reflect\"\ntags: [java,reflect,Class,对象，Class对象]\ncomments: true\n---\n\n\n## java反射学习笔记\n\n\n复习java反射机制，发现我一直没理解Class的对象这个含义，Class是一个类名\n\n```java\n\nimport java.lang.reflect.Method;\n\n/**\n * Created by evilrat on 3/8/17.\n */\npublic class GetMethods {\n\n    public static void main(String [] args){\n\n        Students s = new Students();\n        Class c = s.getClass();\n        Method m = null;\n        try{\n            m = s.getClass().getDeclaredMethod(\"getSex\",null);\n            System.out.println(\"Students类中有方法：\"+m);\n\n        }catch (Exception e){\n            System.out.println(e);\n        }\n    }\n}\n\n\n```\n\n这里先声明了一个Students类的对象，然后调用s.getClass()获得了s的类的对象。这个类的对象是Class类型的。\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n<html>\n<div class=\"ds-thread\" data-thread-key=\"http://kongzheng1993.github.io/kongzheng1993-mto/\" data-title=\"mto\" data-url=\"http://kongzheng1993.github.io/kongzheng1993-mto/\"></div>\n<script type=\"text/javascript\">\nvar duoshuoQuery = {short_name:\"kongzheng1993\"};\n\t(function() {\n\t\tvar ds = document.createElement('script');\n\t\tds.type = 'text/javascript';ds.async = true;\n\t\tds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';\n\t\tds.charset = 'UTF-8';\n\t\t(document.getElementsByTagName('head')[0] \n\t\t || document.getElementsByTagName('body')[0]).appendChild(ds);\n\t})();\n</script>\n</html>\n\n\n","slug":"kongzheng1993-JavaReflect","published":1,"updated":"2023-03-08T07:05:58.772Z","photos":[],"link":"","_id":"clg0k2abo000vt26fx7kohq4s","content":"<h2 id=\"java反射学习笔记\"><a href=\"#java反射学习笔记\" class=\"headerlink\" title=\"java反射学习笔记\"></a>java反射学习笔记</h2><p>复习java反射机制，发现我一直没理解Class的对象这个含义，Class是一个类名</p>\n<pre><code class=\"java\">\nimport java.lang.reflect.Method;\n\n/**\n * Created by evilrat on 3/8/17.\n */\npublic class GetMethods {\n\n    public static void main(String [] args){\n\n        Students s = new Students();\n        Class c = s.getClass();\n        Method m = null;\n        try{\n            m = s.getClass().getDeclaredMethod(&quot;getSex&quot;,null);\n            System.out.println(&quot;Students类中有方法：&quot;+m);\n\n        }catch (Exception e){\n            System.out.println(e);\n        }\n    }\n}\n\n</code></pre>\n<p>这里先声明了一个Students类的对象，然后调用s.getClass()获得了s的类的对象。这个类的对象是Class类型的。</p>\n<html>\n<div class=\"ds-thread\" data-thread-key=\"http://kongzheng1993.github.io/kongzheng1993-mto/\" data-title=\"mto\" data-url=\"http://kongzheng1993.github.io/kongzheng1993-mto/\"></div>\n<script type=\"text/javascript\">\nvar duoshuoQuery = {short_name:\"kongzheng1993\"};\n    (function() {\n        var ds = document.createElement('script');\n        ds.type = 'text/javascript';ds.async = true;\n        ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';\n        ds.charset = 'UTF-8';\n        (document.getElementsByTagName('head')[0] \n         || document.getElementsByTagName('body')[0]).appendChild(ds);\n    })();\n</script>\n</html>\n\n\n","site":{"data":{}},"more":"<h2 id=\"java反射学习笔记\"><a href=\"#java反射学习笔记\" class=\"headerlink\" title=\"java反射学习笔记\"></a>java反射学习笔记</h2><p>复习java反射机制，发现我一直没理解Class的对象这个含义，Class是一个类名</p>\n<pre><code class=\"java\">\nimport java.lang.reflect.Method;\n\n/**\n * Created by evilrat on 3/8/17.\n */\npublic class GetMethods {\n\n    public static void main(String [] args){\n\n        Students s = new Students();\n        Class c = s.getClass();\n        Method m = null;\n        try{\n            m = s.getClass().getDeclaredMethod(&quot;getSex&quot;,null);\n            System.out.println(&quot;Students类中有方法：&quot;+m);\n\n        }catch (Exception e){\n            System.out.println(e);\n        }\n    }\n}\n\n</code></pre>\n<p>这里先声明了一个Students类的对象，然后调用s.getClass()获得了s的类的对象。这个类的对象是Class类型的。</p>\n<html>\n<div class=\"ds-thread\" data-thread-key=\"http://kongzheng1993.github.io/kongzheng1993-mto/\" data-title=\"mto\" data-url=\"http://kongzheng1993.github.io/kongzheng1993-mto/\"></div>\n<script type=\"text/javascript\">\nvar duoshuoQuery = {short_name:\"kongzheng1993\"};\n    (function() {\n        var ds = document.createElement('script');\n        ds.type = 'text/javascript';ds.async = true;\n        ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';\n        ds.charset = 'UTF-8';\n        (document.getElementsByTagName('head')[0] \n         || document.getElementsByTagName('body')[0]).appendChild(ds);\n    })();\n</script>\n</html>\n\n\n"},{"layout":"post","title":"Hexo+github搭建个人博客遇到的问题","date":"2018-01-31T16:00:00.000Z","excerpt":"","comments":1,"_content":"\n### hexo+github搭建个人博客遇到的问题\n\n1. hexo博客_config.yml中的配置\n 1. Site配置网站相关的信息，比如网站标题、子标题、描述和作者等。\n 2. URL配置博客在网站的目录，这里需要注意一些问题。如果是在根目录，url就配置为https://githubID.github.io，root就配置为/，但是如果有二级目录，比如blog，就要对应的设置为url:https://githubID.github.io/blog root:/blog/。但是github pages有这么个问题，你访问的时候看起来是一级目录，其实是二级目录。所以我在设置为一记目录时，在本地hexo -s debug的时候是正常的，但是发布后网站是没有样式的，也就是说静态资源是访问不到的。所以我又尝试配置为二级目录url:https://githubID.github.io/blog root:/githubID.github.io/，然后样式就正常了。\n 3. 我的博客是从jekyll迁移过来的，所以要把所有的_posts中的博文复制到source/_posts文件夹，然后修改_config.yml中的new_post_name参数，也就是让新的hexo生成的新博文符合原来jekyll博文的命名规则。\n2. 相关的建站的方法这里不再说明，可以到`hexo.io`跟着做。\n3. 安装服务器hexo-server\n```\nnpm install hexo-server --save\n```\n  这个命令是安装hexo服务器，下面的命令是启动服务器，而且启动后修改文件无需重启，-p选项可以制定端口来运行server\n```\nhexo server\n```\n  运行成功后可以在命令行看到访问http://localhost:4000可以预览网站。\n4. 我是在用github pages来建站，所以需要使用git来部署我的博客到github pages。\n  所以要使用下面的命令安装git的部署器。\n```\nnpm install hexo-deployer-git --save\n```\n  然后还需要修改配置_config.yml\n```\ndeploy:\n  type: git\n  repo: https://github.com/githubID/githubID.github.io.git\n  branch: #github会自动检测\n  message: #自定义的提交信息。\n```\n\n\n\n<html>\n<div class=\"ds-thread\" data-thread-key=\"http://kongzheng1993.github.io/kongzheng1993-web_xml/\" data-title=\"About trycatch\" data-url=\"http://kongzheng1993.github.io/kongzheng1993\"></div>\n<!-- 多说评论框 end -->\n<!-- 多说公共JS代码 start (一个网页只需插入一次) -->\n<script type=\"text/javascript\">\nvar duoshuoQuery = {short_name:\"kongzheng1993\"};\n    (function() {\n        var ds = document.createElement('script');\n        ds.type = 'text/javascript';ds.async = true;\n        ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';\n        ds.charset = 'UTF-8';\n        (document.getElementsByTagName('head')[0] \n         || document.getElementsByTagName('body')[0]).appendChild(ds);\n    })();\n</script>\n</html>\n","source":"_posts/2018-02-01-kongzheng1993-hexo搭建githubPages.md","raw":"---\nlayout: post\ntitle: \"Hexo+github搭建个人博客遇到的问题\"\ndate: 2018-02-01\nexcerpt: \"Hexo+github\"\ntags: [github,hexo,git]\ncategories: [blog,github,git]\ncomments: true\n---\n\n### hexo+github搭建个人博客遇到的问题\n\n1. hexo博客_config.yml中的配置\n 1. Site配置网站相关的信息，比如网站标题、子标题、描述和作者等。\n 2. URL配置博客在网站的目录，这里需要注意一些问题。如果是在根目录，url就配置为https://githubID.github.io，root就配置为/，但是如果有二级目录，比如blog，就要对应的设置为url:https://githubID.github.io/blog root:/blog/。但是github pages有这么个问题，你访问的时候看起来是一级目录，其实是二级目录。所以我在设置为一记目录时，在本地hexo -s debug的时候是正常的，但是发布后网站是没有样式的，也就是说静态资源是访问不到的。所以我又尝试配置为二级目录url:https://githubID.github.io/blog root:/githubID.github.io/，然后样式就正常了。\n 3. 我的博客是从jekyll迁移过来的，所以要把所有的_posts中的博文复制到source/_posts文件夹，然后修改_config.yml中的new_post_name参数，也就是让新的hexo生成的新博文符合原来jekyll博文的命名规则。\n2. 相关的建站的方法这里不再说明，可以到`hexo.io`跟着做。\n3. 安装服务器hexo-server\n```\nnpm install hexo-server --save\n```\n  这个命令是安装hexo服务器，下面的命令是启动服务器，而且启动后修改文件无需重启，-p选项可以制定端口来运行server\n```\nhexo server\n```\n  运行成功后可以在命令行看到访问http://localhost:4000可以预览网站。\n4. 我是在用github pages来建站，所以需要使用git来部署我的博客到github pages。\n  所以要使用下面的命令安装git的部署器。\n```\nnpm install hexo-deployer-git --save\n```\n  然后还需要修改配置_config.yml\n```\ndeploy:\n  type: git\n  repo: https://github.com/githubID/githubID.github.io.git\n  branch: #github会自动检测\n  message: #自定义的提交信息。\n```\n\n\n\n<html>\n<div class=\"ds-thread\" data-thread-key=\"http://kongzheng1993.github.io/kongzheng1993-web_xml/\" data-title=\"About trycatch\" data-url=\"http://kongzheng1993.github.io/kongzheng1993\"></div>\n<!-- 多说评论框 end -->\n<!-- 多说公共JS代码 start (一个网页只需插入一次) -->\n<script type=\"text/javascript\">\nvar duoshuoQuery = {short_name:\"kongzheng1993\"};\n    (function() {\n        var ds = document.createElement('script');\n        ds.type = 'text/javascript';ds.async = true;\n        ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';\n        ds.charset = 'UTF-8';\n        (document.getElementsByTagName('head')[0] \n         || document.getElementsByTagName('body')[0]).appendChild(ds);\n    })();\n</script>\n</html>\n","slug":"kongzheng1993-hexo搭建githubPages","published":1,"updated":"2023-03-08T07:05:58.773Z","photos":[],"link":"","_id":"clg0k2aby000xt26fa5tclbdf","content":"<h3 id=\"hexo-github搭建个人博客遇到的问题\"><a href=\"#hexo-github搭建个人博客遇到的问题\" class=\"headerlink\" title=\"hexo+github搭建个人博客遇到的问题\"></a>hexo+github搭建个人博客遇到的问题</h3><ol>\n<li>hexo博客_config.yml中的配置<ol>\n<li>Site配置网站相关的信息，比如网站标题、子标题、描述和作者等。</li>\n<li>URL配置博客在网站的目录，这里需要注意一些问题。如果是在根目录，url就配置为<a href=\"https://githubID.github.io，root就配置为/，但是如果有二级目录，比如blog，就要对应的设置为url:https://githubID.github.io/blog\" target=\"_blank\" rel=\"noopener\">https://githubID.github.io，root就配置为/，但是如果有二级目录，比如blog，就要对应的设置为url:https://githubID.github.io/blog</a> root:/blog/。但是github pages有这么个问题，你访问的时候看起来是一级目录，其实是二级目录。所以我在设置为一记目录时，在本地hexo -s debug的时候是正常的，但是发布后网站是没有样式的，也就是说静态资源是访问不到的。所以我又尝试配置为二级目录url:<a href=\"https://githubID.github.io/blog\" target=\"_blank\" rel=\"noopener\">https://githubID.github.io/blog</a> root:/githubID.github.io/，然后样式就正常了。</li>\n<li>我的博客是从jekyll迁移过来的，所以要把所有的_posts中的博文复制到source/_posts文件夹，然后修改_config.yml中的new_post_name参数，也就是让新的hexo生成的新博文符合原来jekyll博文的命名规则。</li>\n</ol>\n</li>\n<li>相关的建站的方法这里不再说明，可以到<code>hexo.io</code>跟着做。</li>\n<li>安装服务器hexo-server<pre><code>npm install hexo-server --save</code></pre>这个命令是安装hexo服务器，下面的命令是启动服务器，而且启动后修改文件无需重启，-p选项可以制定端口来运行server<pre><code>hexo server</code></pre>运行成功后可以在命令行看到访问<a href=\"http://localhost:4000可以预览网站。\" target=\"_blank\" rel=\"noopener\">http://localhost:4000可以预览网站。</a></li>\n<li>我是在用github pages来建站，所以需要使用git来部署我的博客到github pages。<br>所以要使用下面的命令安装git的部署器。<pre><code>npm install hexo-deployer-git --save</code></pre>然后还需要修改配置_config.yml<pre><code>deploy:\ntype: git\nrepo: https://github.com/githubID/githubID.github.io.git\nbranch: #github会自动检测\nmessage: #自定义的提交信息。</code></pre></li>\n</ol>\n<html>\n<div class=\"ds-thread\" data-thread-key=\"http://kongzheng1993.github.io/kongzheng1993-web_xml/\" data-title=\"About trycatch\" data-url=\"http://kongzheng1993.github.io/kongzheng1993\"></div>\n<!-- 多说评论框 end -->\n<!-- 多说公共JS代码 start (一个网页只需插入一次) -->\n<script type=\"text/javascript\">\nvar duoshuoQuery = {short_name:\"kongzheng1993\"};\n    (function() {\n        var ds = document.createElement('script');\n        ds.type = 'text/javascript';ds.async = true;\n        ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';\n        ds.charset = 'UTF-8';\n        (document.getElementsByTagName('head')[0] \n         || document.getElementsByTagName('body')[0]).appendChild(ds);\n    })();\n</script>\n</html>\n","site":{"data":{}},"more":"<h3 id=\"hexo-github搭建个人博客遇到的问题\"><a href=\"#hexo-github搭建个人博客遇到的问题\" class=\"headerlink\" title=\"hexo+github搭建个人博客遇到的问题\"></a>hexo+github搭建个人博客遇到的问题</h3><ol>\n<li>hexo博客_config.yml中的配置<ol>\n<li>Site配置网站相关的信息，比如网站标题、子标题、描述和作者等。</li>\n<li>URL配置博客在网站的目录，这里需要注意一些问题。如果是在根目录，url就配置为<a href=\"https://githubID.github.io，root就配置为/，但是如果有二级目录，比如blog，就要对应的设置为url:https://githubID.github.io/blog\" target=\"_blank\" rel=\"noopener\">https://githubID.github.io，root就配置为/，但是如果有二级目录，比如blog，就要对应的设置为url:https://githubID.github.io/blog</a> root:/blog/。但是github pages有这么个问题，你访问的时候看起来是一级目录，其实是二级目录。所以我在设置为一记目录时，在本地hexo -s debug的时候是正常的，但是发布后网站是没有样式的，也就是说静态资源是访问不到的。所以我又尝试配置为二级目录url:<a href=\"https://githubID.github.io/blog\" target=\"_blank\" rel=\"noopener\">https://githubID.github.io/blog</a> root:/githubID.github.io/，然后样式就正常了。</li>\n<li>我的博客是从jekyll迁移过来的，所以要把所有的_posts中的博文复制到source/_posts文件夹，然后修改_config.yml中的new_post_name参数，也就是让新的hexo生成的新博文符合原来jekyll博文的命名规则。</li>\n</ol>\n</li>\n<li>相关的建站的方法这里不再说明，可以到<code>hexo.io</code>跟着做。</li>\n<li>安装服务器hexo-server<pre><code>npm install hexo-server --save</code></pre>这个命令是安装hexo服务器，下面的命令是启动服务器，而且启动后修改文件无需重启，-p选项可以制定端口来运行server<pre><code>hexo server</code></pre>运行成功后可以在命令行看到访问<a href=\"http://localhost:4000可以预览网站。\" target=\"_blank\" rel=\"noopener\">http://localhost:4000可以预览网站。</a></li>\n<li>我是在用github pages来建站，所以需要使用git来部署我的博客到github pages。<br>所以要使用下面的命令安装git的部署器。<pre><code>npm install hexo-deployer-git --save</code></pre>然后还需要修改配置_config.yml<pre><code>deploy:\ntype: git\nrepo: https://github.com/githubID/githubID.github.io.git\nbranch: #github会自动检测\nmessage: #自定义的提交信息。</code></pre></li>\n</ol>\n<html>\n<div class=\"ds-thread\" data-thread-key=\"http://kongzheng1993.github.io/kongzheng1993-web_xml/\" data-title=\"About trycatch\" data-url=\"http://kongzheng1993.github.io/kongzheng1993\"></div>\n<!-- 多说评论框 end -->\n<!-- 多说公共JS代码 start (一个网页只需插入一次) -->\n<script type=\"text/javascript\">\nvar duoshuoQuery = {short_name:\"kongzheng1993\"};\n    (function() {\n        var ds = document.createElement('script');\n        ds.type = 'text/javascript';ds.async = true;\n        ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';\n        ds.charset = 'UTF-8';\n        (document.getElementsByTagName('head')[0] \n         || document.getElementsByTagName('body')[0]).appendChild(ds);\n    })();\n</script>\n</html>\n"},{"layout":"post","title":"关于comparator和comparable","date":"2016-07-25T16:00:00.000Z","excerpt":"","comments":1,"_content":"\n\n## 关于comparator和comparable\n\n### comparator\n\nComparator强行对某个对象collection进行整体排序的比较函数，可以将Comparator传递给Collections.sort或Arrays.sort。\n也就是说Comeparator是需要用sort方法调用的。\n\n```\n\n\nimport java.util.*;\n\n/**\n * Created by evilrat on 3/9/17.\n */\npublic class CollectionTest {\n\n    static List<Demo> d = new ArrayList<Demo>();\n    static Random random = new Random();\n    static CompareterTool ct= new CompareterTool();\n    public static void main(String [] args){\n        for (int i = 0; i < 10;i ++){\n            d.add(new Demo(random.nextInt(10)));\n        }\n        //排序前输出\n        for (Iterator<Demo> it = d.iterator(); it.hasNext();){\n            System.out.print(it.next().getAge()+\"\\t\");\n        }\n        System.out.print(\"\\n\");\n        //排序\n        Collections.sort(d,ct);\n        //排序后输出\n        for (Iterator<Demo> it = d.iterator(); it.hasNext();){\n            System.out.print(it.next().getAge()+\"\\t\");\n        }\n    }\n}\n\n\n```\n\n\n这里是使用Collections.sort方法调用了我们预先写好的比较器。以下是比较器的定义：\n\n```\n\n\nimport java.util.Comparator;\n\n/**\n * Created by evilrat on 3/9/17.\n */\npublic class CompareterTool implements Comparator<Demo> {\n        @Override\n        public int compare(Demo o1, Demo o2) {\n            if (o1.age > o2.age){\n                return 1;\n            }else\n                return -1;\n\n        }\n}\n\n\n\n```\n\n\n在编写比较器的时候我无意中这样写了：\n\n\n```\n\nimport java.util.Comparator;\n\n/**\n * Created by evilrat on 3/9/17.\n */\npublic class CompareterTool {\n\n    public Comparator<Demo> comparator = new Comparator<Demo>() {\n        @Override\n        public int compare(Demo o1, Demo o2) {\n            if (o1.age > o2.age){\n                return 1;\n            }else\n                return -1;\n\n        }\n    };\n}\n\n\n\n```\n\n请注意这种写法，直接声明一个Comparator<Demo>对象，然后紧跟这一段大括号重写了他的compare（）方法，然后在大括号外写了分号。\n反正我是没这么写过，可能是我还没见过的原因吧，记录以下，感觉这样很炫酷。但是随之main方法中的排序代码要改为:\n\n\n```\n\nCollections.sort(d,ct.comparator);\n\n```\n\n\nct是ComparatorTool类的对象，但是从编码来看，compare方法是在Comparator的对象comparator中啊，疑惑？为什么这里是调用ct.comparator，这是一个对象啊，难道说是comparator对象声明时直接写了一个方法？Comparator有这么一种特殊的写法。\n\n\n\n\n\n\n\n### Comparable\n\n对于Comparable来说，需要在编写想要进行排序的类的时候实现Comparable接口，然后在需要排序的时候调用Arrays或者Collections的sort方法就可以直接调用到这个比较器了。\n\n```\n\n/**\n * Created by evilrat on 3/9/17.\n */\npublic class Demo implements Comparable<Demo>{\n\n    String name;\n    int age;\n\n    @Override\n    public int compareTo(Demo o) {\n        return this.getAge()-o.getAge();\n    }\n\n    public Demo(int age){\n        this.age = age;\n    }\n\n    public String getName() {\n        return name;\n    }\n\n    public void setName(String name) {\n        this.name = name;\n    }\n\n    public int getAge() {\n        return age;\n    }\n\n    public void setAge(int age) {\n        this.age = age;\n    }\n}\n\n\n\n\n```\n\n\n调用方法,这里会自动对应到实现Comparable接口而产生的比较器：\n\n\n\n```\n\nCollections.sort(d);\n\n\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n<html>\n<div class=\"ds-thread\" data-thread-key=\"http://kongzheng1993.github.io/kongzheng1993-about_comparator_and_comparable/\" data-title=\"about_comparator_and_comparable\" data-url=\"http://kongzheng1993.github.io/kongzheng1993-about_comparator_and_comparable/\"></div>\n<!-- 多说评论框 end -->\n<!-- 多说公共JS代码 start (一个网页只需插入一次) -->\n<script type=\"text/javascript\">\nvar duoshuoQuery = {short_name:\"kongzheng1993\"};\n    (function() {\n        var ds = document.createElement('script');\n        ds.type = 'text/javascript';ds.async = true;\n        ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';\n        ds.charset = 'UTF-8';\n        (document.getElementsByTagName('head')[0] \n         || document.getElementsByTagName('body')[0]).appendChild(ds);\n    })();\n</script>\n</html>\n\n","source":"_posts/2017-03-09-kongzheng1993-about_comparator_and_comparable.md","raw":"---\nlayout: post\ntitle: \"关于comparator和comparable\"\ndate: 2016-07-26\nexcerpt: \"getRequestDispatcher,forword,sendRedirect\"\ntags: [re]\ncomments: true\n---\n\n\n## 关于comparator和comparable\n\n### comparator\n\nComparator强行对某个对象collection进行整体排序的比较函数，可以将Comparator传递给Collections.sort或Arrays.sort。\n也就是说Comeparator是需要用sort方法调用的。\n\n```\n\n\nimport java.util.*;\n\n/**\n * Created by evilrat on 3/9/17.\n */\npublic class CollectionTest {\n\n    static List<Demo> d = new ArrayList<Demo>();\n    static Random random = new Random();\n    static CompareterTool ct= new CompareterTool();\n    public static void main(String [] args){\n        for (int i = 0; i < 10;i ++){\n            d.add(new Demo(random.nextInt(10)));\n        }\n        //排序前输出\n        for (Iterator<Demo> it = d.iterator(); it.hasNext();){\n            System.out.print(it.next().getAge()+\"\\t\");\n        }\n        System.out.print(\"\\n\");\n        //排序\n        Collections.sort(d,ct);\n        //排序后输出\n        for (Iterator<Demo> it = d.iterator(); it.hasNext();){\n            System.out.print(it.next().getAge()+\"\\t\");\n        }\n    }\n}\n\n\n```\n\n\n这里是使用Collections.sort方法调用了我们预先写好的比较器。以下是比较器的定义：\n\n```\n\n\nimport java.util.Comparator;\n\n/**\n * Created by evilrat on 3/9/17.\n */\npublic class CompareterTool implements Comparator<Demo> {\n        @Override\n        public int compare(Demo o1, Demo o2) {\n            if (o1.age > o2.age){\n                return 1;\n            }else\n                return -1;\n\n        }\n}\n\n\n\n```\n\n\n在编写比较器的时候我无意中这样写了：\n\n\n```\n\nimport java.util.Comparator;\n\n/**\n * Created by evilrat on 3/9/17.\n */\npublic class CompareterTool {\n\n    public Comparator<Demo> comparator = new Comparator<Demo>() {\n        @Override\n        public int compare(Demo o1, Demo o2) {\n            if (o1.age > o2.age){\n                return 1;\n            }else\n                return -1;\n\n        }\n    };\n}\n\n\n\n```\n\n请注意这种写法，直接声明一个Comparator<Demo>对象，然后紧跟这一段大括号重写了他的compare（）方法，然后在大括号外写了分号。\n反正我是没这么写过，可能是我还没见过的原因吧，记录以下，感觉这样很炫酷。但是随之main方法中的排序代码要改为:\n\n\n```\n\nCollections.sort(d,ct.comparator);\n\n```\n\n\nct是ComparatorTool类的对象，但是从编码来看，compare方法是在Comparator的对象comparator中啊，疑惑？为什么这里是调用ct.comparator，这是一个对象啊，难道说是comparator对象声明时直接写了一个方法？Comparator有这么一种特殊的写法。\n\n\n\n\n\n\n\n### Comparable\n\n对于Comparable来说，需要在编写想要进行排序的类的时候实现Comparable接口，然后在需要排序的时候调用Arrays或者Collections的sort方法就可以直接调用到这个比较器了。\n\n```\n\n/**\n * Created by evilrat on 3/9/17.\n */\npublic class Demo implements Comparable<Demo>{\n\n    String name;\n    int age;\n\n    @Override\n    public int compareTo(Demo o) {\n        return this.getAge()-o.getAge();\n    }\n\n    public Demo(int age){\n        this.age = age;\n    }\n\n    public String getName() {\n        return name;\n    }\n\n    public void setName(String name) {\n        this.name = name;\n    }\n\n    public int getAge() {\n        return age;\n    }\n\n    public void setAge(int age) {\n        this.age = age;\n    }\n}\n\n\n\n\n```\n\n\n调用方法,这里会自动对应到实现Comparable接口而产生的比较器：\n\n\n\n```\n\nCollections.sort(d);\n\n\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n<html>\n<div class=\"ds-thread\" data-thread-key=\"http://kongzheng1993.github.io/kongzheng1993-about_comparator_and_comparable/\" data-title=\"about_comparator_and_comparable\" data-url=\"http://kongzheng1993.github.io/kongzheng1993-about_comparator_and_comparable/\"></div>\n<!-- 多说评论框 end -->\n<!-- 多说公共JS代码 start (一个网页只需插入一次) -->\n<script type=\"text/javascript\">\nvar duoshuoQuery = {short_name:\"kongzheng1993\"};\n    (function() {\n        var ds = document.createElement('script');\n        ds.type = 'text/javascript';ds.async = true;\n        ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';\n        ds.charset = 'UTF-8';\n        (document.getElementsByTagName('head')[0] \n         || document.getElementsByTagName('body')[0]).appendChild(ds);\n    })();\n</script>\n</html>\n\n","slug":"kongzheng1993-about_comparator_and_comparable","published":1,"updated":"2023-03-08T07:05:58.773Z","photos":[],"link":"","_id":"clg0k2abz000zt26fhx2k3evc","content":"<h2 id=\"关于comparator和comparable\"><a href=\"#关于comparator和comparable\" class=\"headerlink\" title=\"关于comparator和comparable\"></a>关于comparator和comparable</h2><h3 id=\"comparator\"><a href=\"#comparator\" class=\"headerlink\" title=\"comparator\"></a>comparator</h3><p>Comparator强行对某个对象collection进行整体排序的比较函数，可以将Comparator传递给Collections.sort或Arrays.sort。<br>也就是说Comeparator是需要用sort方法调用的。</p>\n<pre><code>\n\nimport java.util.*;\n\n/**\n * Created by evilrat on 3/9/17.\n */\npublic class CollectionTest {\n\n    static List&lt;Demo&gt; d = new ArrayList&lt;Demo&gt;();\n    static Random random = new Random();\n    static CompareterTool ct= new CompareterTool();\n    public static void main(String [] args){\n        for (int i = 0; i &lt; 10;i ++){\n            d.add(new Demo(random.nextInt(10)));\n        }\n        //排序前输出\n        for (Iterator&lt;Demo&gt; it = d.iterator(); it.hasNext();){\n            System.out.print(it.next().getAge()+&quot;\\t&quot;);\n        }\n        System.out.print(&quot;\\n&quot;);\n        //排序\n        Collections.sort(d,ct);\n        //排序后输出\n        for (Iterator&lt;Demo&gt; it = d.iterator(); it.hasNext();){\n            System.out.print(it.next().getAge()+&quot;\\t&quot;);\n        }\n    }\n}\n\n</code></pre><p>这里是使用Collections.sort方法调用了我们预先写好的比较器。以下是比较器的定义：</p>\n<pre><code>\n\nimport java.util.Comparator;\n\n/**\n * Created by evilrat on 3/9/17.\n */\npublic class CompareterTool implements Comparator&lt;Demo&gt; {\n        @Override\n        public int compare(Demo o1, Demo o2) {\n            if (o1.age &gt; o2.age){\n                return 1;\n            }else\n                return -1;\n\n        }\n}\n\n\n</code></pre><p>在编写比较器的时候我无意中这样写了：</p>\n<pre><code>\nimport java.util.Comparator;\n\n/**\n * Created by evilrat on 3/9/17.\n */\npublic class CompareterTool {\n\n    public Comparator&lt;Demo&gt; comparator = new Comparator&lt;Demo&gt;() {\n        @Override\n        public int compare(Demo o1, Demo o2) {\n            if (o1.age &gt; o2.age){\n                return 1;\n            }else\n                return -1;\n\n        }\n    };\n}\n\n\n</code></pre><p>请注意这种写法，直接声明一个Comparator<demo>对象，然后紧跟这一段大括号重写了他的compare（）方法，然后在大括号外写了分号。<br>反正我是没这么写过，可能是我还没见过的原因吧，记录以下，感觉这样很炫酷。但是随之main方法中的排序代码要改为:</demo></p>\n<pre><code>\nCollections.sort(d,ct.comparator);\n</code></pre><p>ct是ComparatorTool类的对象，但是从编码来看，compare方法是在Comparator的对象comparator中啊，疑惑？为什么这里是调用ct.comparator，这是一个对象啊，难道说是comparator对象声明时直接写了一个方法？Comparator有这么一种特殊的写法。</p>\n<h3 id=\"Comparable\"><a href=\"#Comparable\" class=\"headerlink\" title=\"Comparable\"></a>Comparable</h3><p>对于Comparable来说，需要在编写想要进行排序的类的时候实现Comparable接口，然后在需要排序的时候调用Arrays或者Collections的sort方法就可以直接调用到这个比较器了。</p>\n<pre><code>\n/**\n * Created by evilrat on 3/9/17.\n */\npublic class Demo implements Comparable&lt;Demo&gt;{\n\n    String name;\n    int age;\n\n    @Override\n    public int compareTo(Demo o) {\n        return this.getAge()-o.getAge();\n    }\n\n    public Demo(int age){\n        this.age = age;\n    }\n\n    public String getName() {\n        return name;\n    }\n\n    public void setName(String name) {\n        this.name = name;\n    }\n\n    public int getAge() {\n        return age;\n    }\n\n    public void setAge(int age) {\n        this.age = age;\n    }\n}\n\n\n\n</code></pre><p>调用方法,这里会自动对应到实现Comparable接口而产生的比较器：</p>\n<pre><code>\nCollections.sort(d);\n\n</code></pre><html>\n<div class=\"ds-thread\" data-thread-key=\"http://kongzheng1993.github.io/kongzheng1993-about_comparator_and_comparable/\" data-title=\"about_comparator_and_comparable\" data-url=\"http://kongzheng1993.github.io/kongzheng1993-about_comparator_and_comparable/\"></div>\n<!-- 多说评论框 end -->\n<!-- 多说公共JS代码 start (一个网页只需插入一次) -->\n<script type=\"text/javascript\">\nvar duoshuoQuery = {short_name:\"kongzheng1993\"};\n    (function() {\n        var ds = document.createElement('script');\n        ds.type = 'text/javascript';ds.async = true;\n        ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';\n        ds.charset = 'UTF-8';\n        (document.getElementsByTagName('head')[0] \n         || document.getElementsByTagName('body')[0]).appendChild(ds);\n    })();\n</script>\n</html>\n\n","site":{"data":{}},"more":"<h2 id=\"关于comparator和comparable\"><a href=\"#关于comparator和comparable\" class=\"headerlink\" title=\"关于comparator和comparable\"></a>关于comparator和comparable</h2><h3 id=\"comparator\"><a href=\"#comparator\" class=\"headerlink\" title=\"comparator\"></a>comparator</h3><p>Comparator强行对某个对象collection进行整体排序的比较函数，可以将Comparator传递给Collections.sort或Arrays.sort。<br>也就是说Comeparator是需要用sort方法调用的。</p>\n<pre><code>\n\nimport java.util.*;\n\n/**\n * Created by evilrat on 3/9/17.\n */\npublic class CollectionTest {\n\n    static List&lt;Demo&gt; d = new ArrayList&lt;Demo&gt;();\n    static Random random = new Random();\n    static CompareterTool ct= new CompareterTool();\n    public static void main(String [] args){\n        for (int i = 0; i &lt; 10;i ++){\n            d.add(new Demo(random.nextInt(10)));\n        }\n        //排序前输出\n        for (Iterator&lt;Demo&gt; it = d.iterator(); it.hasNext();){\n            System.out.print(it.next().getAge()+&quot;\\t&quot;);\n        }\n        System.out.print(&quot;\\n&quot;);\n        //排序\n        Collections.sort(d,ct);\n        //排序后输出\n        for (Iterator&lt;Demo&gt; it = d.iterator(); it.hasNext();){\n            System.out.print(it.next().getAge()+&quot;\\t&quot;);\n        }\n    }\n}\n\n</code></pre><p>这里是使用Collections.sort方法调用了我们预先写好的比较器。以下是比较器的定义：</p>\n<pre><code>\n\nimport java.util.Comparator;\n\n/**\n * Created by evilrat on 3/9/17.\n */\npublic class CompareterTool implements Comparator&lt;Demo&gt; {\n        @Override\n        public int compare(Demo o1, Demo o2) {\n            if (o1.age &gt; o2.age){\n                return 1;\n            }else\n                return -1;\n\n        }\n}\n\n\n</code></pre><p>在编写比较器的时候我无意中这样写了：</p>\n<pre><code>\nimport java.util.Comparator;\n\n/**\n * Created by evilrat on 3/9/17.\n */\npublic class CompareterTool {\n\n    public Comparator&lt;Demo&gt; comparator = new Comparator&lt;Demo&gt;() {\n        @Override\n        public int compare(Demo o1, Demo o2) {\n            if (o1.age &gt; o2.age){\n                return 1;\n            }else\n                return -1;\n\n        }\n    };\n}\n\n\n</code></pre><p>请注意这种写法，直接声明一个Comparator<demo>对象，然后紧跟这一段大括号重写了他的compare（）方法，然后在大括号外写了分号。<br>反正我是没这么写过，可能是我还没见过的原因吧，记录以下，感觉这样很炫酷。但是随之main方法中的排序代码要改为:</demo></p>\n<pre><code>\nCollections.sort(d,ct.comparator);\n</code></pre><p>ct是ComparatorTool类的对象，但是从编码来看，compare方法是在Comparator的对象comparator中啊，疑惑？为什么这里是调用ct.comparator，这是一个对象啊，难道说是comparator对象声明时直接写了一个方法？Comparator有这么一种特殊的写法。</p>\n<h3 id=\"Comparable\"><a href=\"#Comparable\" class=\"headerlink\" title=\"Comparable\"></a>Comparable</h3><p>对于Comparable来说，需要在编写想要进行排序的类的时候实现Comparable接口，然后在需要排序的时候调用Arrays或者Collections的sort方法就可以直接调用到这个比较器了。</p>\n<pre><code>\n/**\n * Created by evilrat on 3/9/17.\n */\npublic class Demo implements Comparable&lt;Demo&gt;{\n\n    String name;\n    int age;\n\n    @Override\n    public int compareTo(Demo o) {\n        return this.getAge()-o.getAge();\n    }\n\n    public Demo(int age){\n        this.age = age;\n    }\n\n    public String getName() {\n        return name;\n    }\n\n    public void setName(String name) {\n        this.name = name;\n    }\n\n    public int getAge() {\n        return age;\n    }\n\n    public void setAge(int age) {\n        this.age = age;\n    }\n}\n\n\n\n</code></pre><p>调用方法,这里会自动对应到实现Comparable接口而产生的比较器：</p>\n<pre><code>\nCollections.sort(d);\n\n</code></pre><html>\n<div class=\"ds-thread\" data-thread-key=\"http://kongzheng1993.github.io/kongzheng1993-about_comparator_and_comparable/\" data-title=\"about_comparator_and_comparable\" data-url=\"http://kongzheng1993.github.io/kongzheng1993-about_comparator_and_comparable/\"></div>\n<!-- 多说评论框 end -->\n<!-- 多说公共JS代码 start (一个网页只需插入一次) -->\n<script type=\"text/javascript\">\nvar duoshuoQuery = {short_name:\"kongzheng1993\"};\n    (function() {\n        var ds = document.createElement('script');\n        ds.type = 'text/javascript';ds.async = true;\n        ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';\n        ds.charset = 'UTF-8';\n        (document.getElementsByTagName('head')[0] \n         || document.getElementsByTagName('body')[0]).appendChild(ds);\n    })();\n</script>\n</html>\n\n"},{"layout":"post","title":"linux命令行下的ss","date":"2018-05-01T16:00:00.000Z","excerpt":"","comments":1,"_content":"\n## 为什么不用shadowsocks-qt5\n\n我的pop! os基于ubuntu，因为装了图形界面，所以在用shadowsocks-qt5，而且很好用，只需要打开软件，就会自动连接朋友的ss-server。但是我的chromebook的fq问题一直存在，一度让我产生了卖掉它的想法。昨天开始我准备好好搞一下在shell运行ss客户端，然后了解到了有sslocal和ssserver这样的东西，简直是欣喜若狂，看到了随身携带我的cb的希望。\n\n## 开始搞\n\nsslocal和ssserver都依赖python，所以要先安装python。\n\n```bash\nsudo apt-get update\nsudo apt-get install python python-pip\n```\n之后开始安装shadowsocks\n\n```bash\npip install shadowsocks\n```\n\n运行ss\nsslocal -s server_ip -p server_port -k \"password\" -l local_port -t 600 -m aes-256-cfb\n\n可以通过新建一个配置文件来省去这些参数\n比如我们在/etc下新建一个shadowsock.json\n\n```bash\n{\n\"server\":\"server_ip\",\n\"server_port\":server_port,\n\"local_ip\":\"127.0.0.1\"\n\"local_port\":1080,\n\"password\":\"password\",\n\"timeout\":600,\n\"method\":\"aes-256-cfb\"\n}\n```\n\n然后就可以直接sslocal -c /etc/shadowsock.json来启动sslocal\n\n因为我的设备是chromebook，所以要配置一下chrom代理，我使用的是SwitchyOmega，可以去google商店下载，但是如果环境允许，可以从github下载，然后托到chrome插件里。然后配置一下SwitchyOmega，新建个情景模式，选择代理服务器，用socks5，地址和端口就是sslocal的配置中的local_ip和local_port，然后设置一下自动切换，在按照规则列表匹配请求后面选择刚才新建的SS，默认情景模式选择直接连接。点击应用选项保存。再往下规则列表设置选择AutoProxy 然后将“https://raw.githubusercontent.com/gfwlist/gfwlist/master/gfwlist.txt”填进去，点击下面的立即更新情景模式，会有提示更新成功！这样就配置完了。\n\n在启动sslocal之后，点击chrome右上角的SwitchyOmega图表，选择自动切换，工具会根据gfwlist.txt的配置自动切换是否将请求转发到你的local_ip的local_port。可以节省ss服务器的流量。\n\n## 总结\n\n总体来说还是比较顺利的，以后遇到什么问题要学会思考，不要盲目的尝试。要了解原理，像这次我遇到了很多报错，我都`more sslocal`看了脚本代码了，而且前面尝试了一个自动安装配置ss的脚本，wget一个脚本shadowsocks.sh，然后`./shadowsocks.sh install`就可以，但是我遇到了很多问题，也是进去好好研究了一下人家的代码。虽然最后这个方法没有研究透，不过能看一下大神们写的脚本也很好啊！！！","source":"_posts/2018-05-02-kongzheng1993-linux命令行下的ss.md","raw":"---\nlayout: post\ntitle: \"linux命令行下的ss\"\ndate: 2018-05-02\nexcerpt: \"linux ss\"\ntags: [linux,ss,console]\ncategories: [linux,ss]\ncomments: true\n---\n\n## 为什么不用shadowsocks-qt5\n\n我的pop! os基于ubuntu，因为装了图形界面，所以在用shadowsocks-qt5，而且很好用，只需要打开软件，就会自动连接朋友的ss-server。但是我的chromebook的fq问题一直存在，一度让我产生了卖掉它的想法。昨天开始我准备好好搞一下在shell运行ss客户端，然后了解到了有sslocal和ssserver这样的东西，简直是欣喜若狂，看到了随身携带我的cb的希望。\n\n## 开始搞\n\nsslocal和ssserver都依赖python，所以要先安装python。\n\n```bash\nsudo apt-get update\nsudo apt-get install python python-pip\n```\n之后开始安装shadowsocks\n\n```bash\npip install shadowsocks\n```\n\n运行ss\nsslocal -s server_ip -p server_port -k \"password\" -l local_port -t 600 -m aes-256-cfb\n\n可以通过新建一个配置文件来省去这些参数\n比如我们在/etc下新建一个shadowsock.json\n\n```bash\n{\n\"server\":\"server_ip\",\n\"server_port\":server_port,\n\"local_ip\":\"127.0.0.1\"\n\"local_port\":1080,\n\"password\":\"password\",\n\"timeout\":600,\n\"method\":\"aes-256-cfb\"\n}\n```\n\n然后就可以直接sslocal -c /etc/shadowsock.json来启动sslocal\n\n因为我的设备是chromebook，所以要配置一下chrom代理，我使用的是SwitchyOmega，可以去google商店下载，但是如果环境允许，可以从github下载，然后托到chrome插件里。然后配置一下SwitchyOmega，新建个情景模式，选择代理服务器，用socks5，地址和端口就是sslocal的配置中的local_ip和local_port，然后设置一下自动切换，在按照规则列表匹配请求后面选择刚才新建的SS，默认情景模式选择直接连接。点击应用选项保存。再往下规则列表设置选择AutoProxy 然后将“https://raw.githubusercontent.com/gfwlist/gfwlist/master/gfwlist.txt”填进去，点击下面的立即更新情景模式，会有提示更新成功！这样就配置完了。\n\n在启动sslocal之后，点击chrome右上角的SwitchyOmega图表，选择自动切换，工具会根据gfwlist.txt的配置自动切换是否将请求转发到你的local_ip的local_port。可以节省ss服务器的流量。\n\n## 总结\n\n总体来说还是比较顺利的，以后遇到什么问题要学会思考，不要盲目的尝试。要了解原理，像这次我遇到了很多报错，我都`more sslocal`看了脚本代码了，而且前面尝试了一个自动安装配置ss的脚本，wget一个脚本shadowsocks.sh，然后`./shadowsocks.sh install`就可以，但是我遇到了很多问题，也是进去好好研究了一下人家的代码。虽然最后这个方法没有研究透，不过能看一下大神们写的脚本也很好啊！！！","slug":"kongzheng1993-linux命令行下的ss","published":1,"updated":"2023-03-08T07:05:58.773Z","photos":[],"link":"","_id":"clg0k2ac00011t26fppgdnx4m","content":"<h2 id=\"为什么不用shadowsocks-qt5\"><a href=\"#为什么不用shadowsocks-qt5\" class=\"headerlink\" title=\"为什么不用shadowsocks-qt5\"></a>为什么不用shadowsocks-qt5</h2><p>我的pop! os基于ubuntu，因为装了图形界面，所以在用shadowsocks-qt5，而且很好用，只需要打开软件，就会自动连接朋友的ss-server。但是我的chromebook的fq问题一直存在，一度让我产生了卖掉它的想法。昨天开始我准备好好搞一下在shell运行ss客户端，然后了解到了有sslocal和ssserver这样的东西，简直是欣喜若狂，看到了随身携带我的cb的希望。</p>\n<h2 id=\"开始搞\"><a href=\"#开始搞\" class=\"headerlink\" title=\"开始搞\"></a>开始搞</h2><p>sslocal和ssserver都依赖python，所以要先安装python。</p>\n<pre><code class=\"bash\">sudo apt-get update\nsudo apt-get install python python-pip</code></pre>\n<p>之后开始安装shadowsocks</p>\n<pre><code class=\"bash\">pip install shadowsocks</code></pre>\n<p>运行ss<br>sslocal -s server_ip -p server_port -k “password” -l local_port -t 600 -m aes-256-cfb</p>\n<p>可以通过新建一个配置文件来省去这些参数<br>比如我们在/etc下新建一个shadowsock.json</p>\n<pre><code class=\"bash\">{\n&quot;server&quot;:&quot;server_ip&quot;,\n&quot;server_port&quot;:server_port,\n&quot;local_ip&quot;:&quot;127.0.0.1&quot;\n&quot;local_port&quot;:1080,\n&quot;password&quot;:&quot;password&quot;,\n&quot;timeout&quot;:600,\n&quot;method&quot;:&quot;aes-256-cfb&quot;\n}</code></pre>\n<p>然后就可以直接sslocal -c /etc/shadowsock.json来启动sslocal</p>\n<p>因为我的设备是chromebook，所以要配置一下chrom代理，我使用的是SwitchyOmega，可以去google商店下载，但是如果环境允许，可以从github下载，然后托到chrome插件里。然后配置一下SwitchyOmega，新建个情景模式，选择代理服务器，用socks5，地址和端口就是sslocal的配置中的local_ip和local_port，然后设置一下自动切换，在按照规则列表匹配请求后面选择刚才新建的SS，默认情景模式选择直接连接。点击应用选项保存。再往下规则列表设置选择AutoProxy 然后将“<a href=\"https://raw.githubusercontent.com/gfwlist/gfwlist/master/gfwlist.txt”填进去，点击下面的立即更新情景模式，会有提示更新成功！这样就配置完了。\" target=\"_blank\" rel=\"noopener\">https://raw.githubusercontent.com/gfwlist/gfwlist/master/gfwlist.txt”填进去，点击下面的立即更新情景模式，会有提示更新成功！这样就配置完了。</a></p>\n<p>在启动sslocal之后，点击chrome右上角的SwitchyOmega图表，选择自动切换，工具会根据gfwlist.txt的配置自动切换是否将请求转发到你的local_ip的local_port。可以节省ss服务器的流量。</p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>总体来说还是比较顺利的，以后遇到什么问题要学会思考，不要盲目的尝试。要了解原理，像这次我遇到了很多报错，我都<code>more sslocal</code>看了脚本代码了，而且前面尝试了一个自动安装配置ss的脚本，wget一个脚本shadowsocks.sh，然后<code>./shadowsocks.sh install</code>就可以，但是我遇到了很多问题，也是进去好好研究了一下人家的代码。虽然最后这个方法没有研究透，不过能看一下大神们写的脚本也很好啊！！！</p>\n","site":{"data":{}},"more":"<h2 id=\"为什么不用shadowsocks-qt5\"><a href=\"#为什么不用shadowsocks-qt5\" class=\"headerlink\" title=\"为什么不用shadowsocks-qt5\"></a>为什么不用shadowsocks-qt5</h2><p>我的pop! os基于ubuntu，因为装了图形界面，所以在用shadowsocks-qt5，而且很好用，只需要打开软件，就会自动连接朋友的ss-server。但是我的chromebook的fq问题一直存在，一度让我产生了卖掉它的想法。昨天开始我准备好好搞一下在shell运行ss客户端，然后了解到了有sslocal和ssserver这样的东西，简直是欣喜若狂，看到了随身携带我的cb的希望。</p>\n<h2 id=\"开始搞\"><a href=\"#开始搞\" class=\"headerlink\" title=\"开始搞\"></a>开始搞</h2><p>sslocal和ssserver都依赖python，所以要先安装python。</p>\n<pre><code class=\"bash\">sudo apt-get update\nsudo apt-get install python python-pip</code></pre>\n<p>之后开始安装shadowsocks</p>\n<pre><code class=\"bash\">pip install shadowsocks</code></pre>\n<p>运行ss<br>sslocal -s server_ip -p server_port -k “password” -l local_port -t 600 -m aes-256-cfb</p>\n<p>可以通过新建一个配置文件来省去这些参数<br>比如我们在/etc下新建一个shadowsock.json</p>\n<pre><code class=\"bash\">{\n&quot;server&quot;:&quot;server_ip&quot;,\n&quot;server_port&quot;:server_port,\n&quot;local_ip&quot;:&quot;127.0.0.1&quot;\n&quot;local_port&quot;:1080,\n&quot;password&quot;:&quot;password&quot;,\n&quot;timeout&quot;:600,\n&quot;method&quot;:&quot;aes-256-cfb&quot;\n}</code></pre>\n<p>然后就可以直接sslocal -c /etc/shadowsock.json来启动sslocal</p>\n<p>因为我的设备是chromebook，所以要配置一下chrom代理，我使用的是SwitchyOmega，可以去google商店下载，但是如果环境允许，可以从github下载，然后托到chrome插件里。然后配置一下SwitchyOmega，新建个情景模式，选择代理服务器，用socks5，地址和端口就是sslocal的配置中的local_ip和local_port，然后设置一下自动切换，在按照规则列表匹配请求后面选择刚才新建的SS，默认情景模式选择直接连接。点击应用选项保存。再往下规则列表设置选择AutoProxy 然后将“<a href=\"https://raw.githubusercontent.com/gfwlist/gfwlist/master/gfwlist.txt”填进去，点击下面的立即更新情景模式，会有提示更新成功！这样就配置完了。\" target=\"_blank\" rel=\"noopener\">https://raw.githubusercontent.com/gfwlist/gfwlist/master/gfwlist.txt”填进去，点击下面的立即更新情景模式，会有提示更新成功！这样就配置完了。</a></p>\n<p>在启动sslocal之后，点击chrome右上角的SwitchyOmega图表，选择自动切换，工具会根据gfwlist.txt的配置自动切换是否将请求转发到你的local_ip的local_port。可以节省ss服务器的流量。</p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>总体来说还是比较顺利的，以后遇到什么问题要学会思考，不要盲目的尝试。要了解原理，像这次我遇到了很多报错，我都<code>more sslocal</code>看了脚本代码了，而且前面尝试了一个自动安装配置ss的脚本，wget一个脚本shadowsocks.sh，然后<code>./shadowsocks.sh install</code>就可以，但是我遇到了很多问题，也是进去好好研究了一下人家的代码。虽然最后这个方法没有研究透，不过能看一下大神们写的脚本也很好啊！！！</p>\n"},{"layout":"post","title":"SUSE server FTP配置","date":"2018-01-31T16:00:00.000Z","excerpt":"","comments":1,"_content":"\n## SUSE FTP配置\n\n建议使用vsftp，如果使用了pure-ftpd，需要屏蔽掉pure-ftpd服务。\n\n1. Root用户执行yast2--->network services-->network services （inetd）\n\n将/usr/sbin/pure-ftpd 和/usr/sbin/vsftpd\n\n分别将pure-ftp的状态置为off，vsftpd的状态置为on，然后单击按钮，修改完成。\n\n2. vi /etc/vsftpd.conf 去掉下面几项的注视：\n\n```bash\n#write_enable=YES\n\n#local_enable=YES\n\n#ascii_upload_enable=YES\n\n#ascii_download_enable=YES\n\n#listen=YES\n\n#anonymous_enable=NO\n```\n\n(3)vi /etc/ftpuser 将root用户注释掉\n\n(4)service vsftpd restart  重启ftp服务\n","source":"_posts/2018-02-07-kongzheng1993-suse_ftp服务配置.md","raw":"---\nlayout: post\ntitle: \"SUSE server FTP配置\"\ndate: 2018-02-01\nexcerpt: \"suse server FTP\"\ntags: [suse,server,FTP]\ncategories: [suse,server,FTP]\ncomments: true\n---\n\n## SUSE FTP配置\n\n建议使用vsftp，如果使用了pure-ftpd，需要屏蔽掉pure-ftpd服务。\n\n1. Root用户执行yast2--->network services-->network services （inetd）\n\n将/usr/sbin/pure-ftpd 和/usr/sbin/vsftpd\n\n分别将pure-ftp的状态置为off，vsftpd的状态置为on，然后单击按钮，修改完成。\n\n2. vi /etc/vsftpd.conf 去掉下面几项的注视：\n\n```bash\n#write_enable=YES\n\n#local_enable=YES\n\n#ascii_upload_enable=YES\n\n#ascii_download_enable=YES\n\n#listen=YES\n\n#anonymous_enable=NO\n```\n\n(3)vi /etc/ftpuser 将root用户注释掉\n\n(4)service vsftpd restart  重启ftp服务\n","slug":"kongzheng1993-suse_ftp服务配置","published":1,"updated":"2023-03-08T07:05:58.773Z","photos":[],"link":"","_id":"clg0k2ac10014t26fxr065v9i","content":"<h2 id=\"SUSE-FTP配置\"><a href=\"#SUSE-FTP配置\" class=\"headerlink\" title=\"SUSE FTP配置\"></a>SUSE FTP配置</h2><p>建议使用vsftp，如果使用了pure-ftpd，需要屏蔽掉pure-ftpd服务。</p>\n<ol>\n<li>Root用户执行yast2—&gt;network services–&gt;network services （inetd）</li>\n</ol>\n<p>将/usr/sbin/pure-ftpd 和/usr/sbin/vsftpd</p>\n<p>分别将pure-ftp的状态置为off，vsftpd的状态置为on，然后单击按钮，修改完成。</p>\n<ol start=\"2\">\n<li>vi /etc/vsftpd.conf 去掉下面几项的注视：</li>\n</ol>\n<pre><code class=\"bash\">#write_enable=YES\n\n#local_enable=YES\n\n#ascii_upload_enable=YES\n\n#ascii_download_enable=YES\n\n#listen=YES\n\n#anonymous_enable=NO</code></pre>\n<p>(3)vi /etc/ftpuser 将root用户注释掉</p>\n<p>(4)service vsftpd restart  重启ftp服务</p>\n","site":{"data":{}},"more":"<h2 id=\"SUSE-FTP配置\"><a href=\"#SUSE-FTP配置\" class=\"headerlink\" title=\"SUSE FTP配置\"></a>SUSE FTP配置</h2><p>建议使用vsftp，如果使用了pure-ftpd，需要屏蔽掉pure-ftpd服务。</p>\n<ol>\n<li>Root用户执行yast2—&gt;network services–&gt;network services （inetd）</li>\n</ol>\n<p>将/usr/sbin/pure-ftpd 和/usr/sbin/vsftpd</p>\n<p>分别将pure-ftp的状态置为off，vsftpd的状态置为on，然后单击按钮，修改完成。</p>\n<ol start=\"2\">\n<li>vi /etc/vsftpd.conf 去掉下面几项的注视：</li>\n</ol>\n<pre><code class=\"bash\">#write_enable=YES\n\n#local_enable=YES\n\n#ascii_upload_enable=YES\n\n#ascii_download_enable=YES\n\n#listen=YES\n\n#anonymous_enable=NO</code></pre>\n<p>(3)vi /etc/ftpuser 将root用户注释掉</p>\n<p>(4)service vsftpd restart  重启ftp服务</p>\n"},{"layout":"post","title":"***.java:[1,1] illegal character","date":"2019-05-29T16:00:00.000Z","excerpt":"","comments":1,"_content":"\n## 千万不要用记事本写代码改代码……\n\n刚接到今晚发布留守同事等电话：“你的代码报错了，给你发截图了，qq！！！”。我心里一惊，mmp，不可能吧。。。\n赶紧登陆qq，看了一下他发来等截图\n![编译报错](WechatIMG1.jpeg)\nmmp? 第一行，第一个字符就报错？\n定睛一看，是非法字符。\n仔细回想……\n今天我提代码的时候在生产库用记事本改代码了……\n“大哥，帮我把这个文件重新提一下，多谢多谢🙏”\n重提这个文件，打包，发布，编译成功，总算松了口气。\n\n之前就记得windows记事本会文本文件编码做修改，静下来后百度下：\n\n```\n某些编辑器会往utf8文件中添加utf8标记（editplus称其为签名），它会在文件开始的地方插入三个不可见的字符（0xEF 0xBB 0xBF，即BOM），它的表示的是 Unicode 标记（BOM）。 因此要解决这个问题的关键就是把这个标记选项去掉，可按如下方法操作。 \n首先用editplus打开这个文件，从Doucument菜单中选择Permanet Settings,有三个分类，分别是General,File, Tools.点击File,右边会有一项是 UTF-8 signature: 选择 always remove signature. 点击OK 。中文版本的 Editplus 下操作的菜单结构如下: 文档->参数设置->文件->UTF-8签名->总是移除签名->确定 ，这样就设置了UTF-8格式不需要在文件前面加标记，最后把文件另存为utf-8格式就好了.\n```\n\n\n","source":"_posts/2019-05-30-kongzheng1993-生产部署illegal-character.md","raw":"---\nlayout: post\ntitle: \"***.java:[1,1] illegal character\"\ndate: 2019-05-30\nexcerpt: \"\"\ntags: [编码]\ncategories: [编码]\ncomments: true\n---\n\n## 千万不要用记事本写代码改代码……\n\n刚接到今晚发布留守同事等电话：“你的代码报错了，给你发截图了，qq！！！”。我心里一惊，mmp，不可能吧。。。\n赶紧登陆qq，看了一下他发来等截图\n![编译报错](WechatIMG1.jpeg)\nmmp? 第一行，第一个字符就报错？\n定睛一看，是非法字符。\n仔细回想……\n今天我提代码的时候在生产库用记事本改代码了……\n“大哥，帮我把这个文件重新提一下，多谢多谢🙏”\n重提这个文件，打包，发布，编译成功，总算松了口气。\n\n之前就记得windows记事本会文本文件编码做修改，静下来后百度下：\n\n```\n某些编辑器会往utf8文件中添加utf8标记（editplus称其为签名），它会在文件开始的地方插入三个不可见的字符（0xEF 0xBB 0xBF，即BOM），它的表示的是 Unicode 标记（BOM）。 因此要解决这个问题的关键就是把这个标记选项去掉，可按如下方法操作。 \n首先用editplus打开这个文件，从Doucument菜单中选择Permanet Settings,有三个分类，分别是General,File, Tools.点击File,右边会有一项是 UTF-8 signature: 选择 always remove signature. 点击OK 。中文版本的 Editplus 下操作的菜单结构如下: 文档->参数设置->文件->UTF-8签名->总是移除签名->确定 ，这样就设置了UTF-8格式不需要在文件前面加标记，最后把文件另存为utf-8格式就好了.\n```\n\n\n","slug":"kongzheng1993-生产部署illegal-character","published":1,"updated":"2023-03-08T07:05:58.774Z","photos":[],"link":"","_id":"clg0k2ac20016t26f0eauehtf","content":"<h2 id=\"千万不要用记事本写代码改代码……\"><a href=\"#千万不要用记事本写代码改代码……\" class=\"headerlink\" title=\"千万不要用记事本写代码改代码……\"></a>千万不要用记事本写代码改代码……</h2><p>刚接到今晚发布留守同事等电话：“你的代码报错了，给你发截图了，qq！！！”。我心里一惊，mmp，不可能吧。。。<br>赶紧登陆qq，看了一下他发来等截图<br><img src=\"/2019/05/30/kongzheng1993-生产部署illegal-character/WechatIMG1.jpeg\" alt=\"编译报错\"><br>mmp? 第一行，第一个字符就报错？<br>定睛一看，是非法字符。<br>仔细回想……<br>今天我提代码的时候在生产库用记事本改代码了……<br>“大哥，帮我把这个文件重新提一下，多谢多谢🙏”<br>重提这个文件，打包，发布，编译成功，总算松了口气。</p>\n<p>之前就记得windows记事本会文本文件编码做修改，静下来后百度下：</p>\n<pre><code>某些编辑器会往utf8文件中添加utf8标记（editplus称其为签名），它会在文件开始的地方插入三个不可见的字符（0xEF 0xBB 0xBF，即BOM），它的表示的是 Unicode 标记（BOM）。 因此要解决这个问题的关键就是把这个标记选项去掉，可按如下方法操作。 \n首先用editplus打开这个文件，从Doucument菜单中选择Permanet Settings,有三个分类，分别是General,File, Tools.点击File,右边会有一项是 UTF-8 signature: 选择 always remove signature. 点击OK 。中文版本的 Editplus 下操作的菜单结构如下: 文档-&gt;参数设置-&gt;文件-&gt;UTF-8签名-&gt;总是移除签名-&gt;确定 ，这样就设置了UTF-8格式不需要在文件前面加标记，最后把文件另存为utf-8格式就好了.</code></pre>","site":{"data":{}},"more":"<h2 id=\"千万不要用记事本写代码改代码……\"><a href=\"#千万不要用记事本写代码改代码……\" class=\"headerlink\" title=\"千万不要用记事本写代码改代码……\"></a>千万不要用记事本写代码改代码……</h2><p>刚接到今晚发布留守同事等电话：“你的代码报错了，给你发截图了，qq！！！”。我心里一惊，mmp，不可能吧。。。<br>赶紧登陆qq，看了一下他发来等截图<br><img src=\"/2019/05/30/kongzheng1993-生产部署illegal-character/WechatIMG1.jpeg\" alt=\"编译报错\"><br>mmp? 第一行，第一个字符就报错？<br>定睛一看，是非法字符。<br>仔细回想……<br>今天我提代码的时候在生产库用记事本改代码了……<br>“大哥，帮我把这个文件重新提一下，多谢多谢🙏”<br>重提这个文件，打包，发布，编译成功，总算松了口气。</p>\n<p>之前就记得windows记事本会文本文件编码做修改，静下来后百度下：</p>\n<pre><code>某些编辑器会往utf8文件中添加utf8标记（editplus称其为签名），它会在文件开始的地方插入三个不可见的字符（0xEF 0xBB 0xBF，即BOM），它的表示的是 Unicode 标记（BOM）。 因此要解决这个问题的关键就是把这个标记选项去掉，可按如下方法操作。 \n首先用editplus打开这个文件，从Doucument菜单中选择Permanet Settings,有三个分类，分别是General,File, Tools.点击File,右边会有一项是 UTF-8 signature: 选择 always remove signature. 点击OK 。中文版本的 Editplus 下操作的菜单结构如下: 文档-&gt;参数设置-&gt;文件-&gt;UTF-8签名-&gt;总是移除签名-&gt;确定 ，这样就设置了UTF-8格式不需要在文件前面加标记，最后把文件另存为utf-8格式就好了.</code></pre>"},{"layout":"post","title":"mysql数据库导出导入","date":"2018-08-04T16:00:00.000Z","excerpt":"","comments":1,"_content":"\n一直在用oracle，今天学习了一下mysql如何导库。\n\n## mysqldump\n\nmysqldump一般在/usr/bin/目录下，装晚mysql后就可以使用了。\n\n## 导出\n\n1. 一般形式：mysqldump -h IP -u 用户名 -p 数据库名 > 导出的文件名\n\nmysqldump和mysql登陆数据库的格式差不多，-h指定ip，-u指定登陆用户，-p指定输入密码。后面加上输出重定向到文件名。\n\n这种一般形式是导出此数据库中的所有表和数据。\n\n2. 导出数据库所有表结构，但不导出数据。\n\n```bash\nmysqldump -h localhost -u root -p -d test > /home/evilrat/dbbak/test.sql\n```\n\n3. 导出某张表的表结构，不含数据。\n\n```bash\nmysqldump -h localhost -u root -p -d test t_user > /home/evilrat/dbbak/tuser.sql\n```\n\n4. 备份多个数据库\n\n```bash\nmysqldump -h localhost -u root -p --databases test1 test2 > /home/evilrat/dbbak/test1_test2.sql\n```\n\n5. 备份所有数据库的方法\n\n```bash\nmysqldump -h localhost -u root -p --all-databases > /home/evilrat/dbbak/localhost.sql\n```\n\n## 导入\n\n```bash\nmysql -h localhost -u root -p\n*******\ncreate database test;\nshow databases;\nuse test;\nshow tables;\nsource /home/evilrat/dbbak/test.sql;\nshow tables;\nexit;\n```","source":"_posts/2018-08-05-kongzheng1993-mysql数据库导出导入.md","raw":"---\nlayout: post\ntitle: \"mysql数据库导出导入\"\ndate: 2018-08-05\nexcerpt: \"mysql 导库\"\ntags: [mysql,备份]\ncategories: [mysql]\ncomments: true\n---\n\n一直在用oracle，今天学习了一下mysql如何导库。\n\n## mysqldump\n\nmysqldump一般在/usr/bin/目录下，装晚mysql后就可以使用了。\n\n## 导出\n\n1. 一般形式：mysqldump -h IP -u 用户名 -p 数据库名 > 导出的文件名\n\nmysqldump和mysql登陆数据库的格式差不多，-h指定ip，-u指定登陆用户，-p指定输入密码。后面加上输出重定向到文件名。\n\n这种一般形式是导出此数据库中的所有表和数据。\n\n2. 导出数据库所有表结构，但不导出数据。\n\n```bash\nmysqldump -h localhost -u root -p -d test > /home/evilrat/dbbak/test.sql\n```\n\n3. 导出某张表的表结构，不含数据。\n\n```bash\nmysqldump -h localhost -u root -p -d test t_user > /home/evilrat/dbbak/tuser.sql\n```\n\n4. 备份多个数据库\n\n```bash\nmysqldump -h localhost -u root -p --databases test1 test2 > /home/evilrat/dbbak/test1_test2.sql\n```\n\n5. 备份所有数据库的方法\n\n```bash\nmysqldump -h localhost -u root -p --all-databases > /home/evilrat/dbbak/localhost.sql\n```\n\n## 导入\n\n```bash\nmysql -h localhost -u root -p\n*******\ncreate database test;\nshow databases;\nuse test;\nshow tables;\nsource /home/evilrat/dbbak/test.sql;\nshow tables;\nexit;\n```","slug":"kongzheng1993-mysql数据库导出导入","published":1,"updated":"2023-03-08T07:05:58.774Z","photos":[],"link":"","_id":"clg0k2ac3001at26frlrtdk5c","content":"<p>一直在用oracle，今天学习了一下mysql如何导库。</p>\n<h2 id=\"mysqldump\"><a href=\"#mysqldump\" class=\"headerlink\" title=\"mysqldump\"></a>mysqldump</h2><p>mysqldump一般在/usr/bin/目录下，装晚mysql后就可以使用了。</p>\n<h2 id=\"导出\"><a href=\"#导出\" class=\"headerlink\" title=\"导出\"></a>导出</h2><ol>\n<li>一般形式：mysqldump -h IP -u 用户名 -p 数据库名 &gt; 导出的文件名</li>\n</ol>\n<p>mysqldump和mysql登陆数据库的格式差不多，-h指定ip，-u指定登陆用户，-p指定输入密码。后面加上输出重定向到文件名。</p>\n<p>这种一般形式是导出此数据库中的所有表和数据。</p>\n<ol start=\"2\">\n<li>导出数据库所有表结构，但不导出数据。</li>\n</ol>\n<pre><code class=\"bash\">mysqldump -h localhost -u root -p -d test &gt; /home/evilrat/dbbak/test.sql</code></pre>\n<ol start=\"3\">\n<li>导出某张表的表结构，不含数据。</li>\n</ol>\n<pre><code class=\"bash\">mysqldump -h localhost -u root -p -d test t_user &gt; /home/evilrat/dbbak/tuser.sql</code></pre>\n<ol start=\"4\">\n<li>备份多个数据库</li>\n</ol>\n<pre><code class=\"bash\">mysqldump -h localhost -u root -p --databases test1 test2 &gt; /home/evilrat/dbbak/test1_test2.sql</code></pre>\n<ol start=\"5\">\n<li>备份所有数据库的方法</li>\n</ol>\n<pre><code class=\"bash\">mysqldump -h localhost -u root -p --all-databases &gt; /home/evilrat/dbbak/localhost.sql</code></pre>\n<h2 id=\"导入\"><a href=\"#导入\" class=\"headerlink\" title=\"导入\"></a>导入</h2><pre><code class=\"bash\">mysql -h localhost -u root -p\n*******\ncreate database test;\nshow databases;\nuse test;\nshow tables;\nsource /home/evilrat/dbbak/test.sql;\nshow tables;\nexit;</code></pre>\n","site":{"data":{}},"more":"<p>一直在用oracle，今天学习了一下mysql如何导库。</p>\n<h2 id=\"mysqldump\"><a href=\"#mysqldump\" class=\"headerlink\" title=\"mysqldump\"></a>mysqldump</h2><p>mysqldump一般在/usr/bin/目录下，装晚mysql后就可以使用了。</p>\n<h2 id=\"导出\"><a href=\"#导出\" class=\"headerlink\" title=\"导出\"></a>导出</h2><ol>\n<li>一般形式：mysqldump -h IP -u 用户名 -p 数据库名 &gt; 导出的文件名</li>\n</ol>\n<p>mysqldump和mysql登陆数据库的格式差不多，-h指定ip，-u指定登陆用户，-p指定输入密码。后面加上输出重定向到文件名。</p>\n<p>这种一般形式是导出此数据库中的所有表和数据。</p>\n<ol start=\"2\">\n<li>导出数据库所有表结构，但不导出数据。</li>\n</ol>\n<pre><code class=\"bash\">mysqldump -h localhost -u root -p -d test &gt; /home/evilrat/dbbak/test.sql</code></pre>\n<ol start=\"3\">\n<li>导出某张表的表结构，不含数据。</li>\n</ol>\n<pre><code class=\"bash\">mysqldump -h localhost -u root -p -d test t_user &gt; /home/evilrat/dbbak/tuser.sql</code></pre>\n<ol start=\"4\">\n<li>备份多个数据库</li>\n</ol>\n<pre><code class=\"bash\">mysqldump -h localhost -u root -p --databases test1 test2 &gt; /home/evilrat/dbbak/test1_test2.sql</code></pre>\n<ol start=\"5\">\n<li>备份所有数据库的方法</li>\n</ol>\n<pre><code class=\"bash\">mysqldump -h localhost -u root -p --all-databases &gt; /home/evilrat/dbbak/localhost.sql</code></pre>\n<h2 id=\"导入\"><a href=\"#导入\" class=\"headerlink\" title=\"导入\"></a>导入</h2><pre><code class=\"bash\">mysql -h localhost -u root -p\n*******\ncreate database test;\nshow databases;\nuse test;\nshow tables;\nsource /home/evilrat/dbbak/test.sql;\nshow tables;\nexit;</code></pre>\n"},{"layout":"post","title":"关于分布式锁.md","date":"2019-06-11T07:48:10.000Z","excerpt":"","comments":1,"_content":"\n\n前段时间上线了一个需求：用户在页面填写计划任务，在用户的计划时间给用户下发短信提醒。\n\n我当时一想这不简单，给页面提供一个接口，数据入库，后台做一个定时任务，每分钟去取当前时间需要下发短信的数据，调用短信接口。\n\n为此还特地学习了一下quartz。需求很快完成了，接着就上线了。\n\n第二天验证，每条数据竟然收到了八条短信！！！\n\n找日志看了一下，每个tomcat都跑了task，都取到了所有的数据，都下发了短信，正好8个tomcat，一个不多，一个不少。。。\n\n## 想办法\n\n查资料了解到quartz支持集群的，一开始我猜想的可能是通过集群中各节点互相通信来实现。后来知道是通过数据库锁来实现的。\n\n```sql\n\nselect * from  ... for update;\n\n```\n通过db的行级锁来实现只有一个实例可以继续执行。\n\n想到新建很多表，只为了解决这个问题，还是觉得大材小用，继续寻找其他方法。不过通过这些资料，我了解到分布式锁。\n\n## 什么是分布式锁\n\n在分布式模型下，数据只有一份，可是集群中多个节点都会去操作这份数据。与单机模式下的锁相比，不仅要保证进程可见，还需要考虑进程与锁之间的网络问题。不过思路还是一样的，只要能保证标记能互斥就行。\n\n## 我们需要怎样的分布式锁？\n\n- 可以保证在分布式部署的应用集群中，同一个方法在同一时间只能被一台机器-上的一个线程执行。\n- 这把锁要是一把可重入锁（避免死锁）\n- 这把锁最好是一把阻塞锁（根据业务需求考虑要不要这条）\n- 这把锁最好是一把公平锁（根据业务需求考虑要不要这条）\n- 有高可用的获取锁和释放锁功能\n- 获取锁和释放锁的性能要好\n\n### 基于数据库做分布式锁\n\n#### 基于表主键唯一做分布式锁\n\n利用主键唯一的特性，如果有多个请求同时提交到数据库的话，数据库会保证只有一个操作可以成功，那么我们就可以认为操作成功的那个线程获得了该方法的锁，当方法执行完毕之后，想要释放锁的话，删除这条数据库记录即可。\n\n#### 基于表字段版本号做分布式锁\n\n这个策略源于 mysql 的 mvcc 机制，使用这个策略其实本身没有什么问题，唯一的问题就是对数据表侵入较大，我们要为每个表设计一个版本号字段，然后写一条判断 sql 每次进行判断，增加了数据库操作的次数，在高并发的要求下，对数据库连接的开销也是无法忍受的。\n\n#### 基于数据库排他锁做分布式锁\n\n在查询语句后面增加for update，数据库会在查询过程中给数据库表增加排他锁 (注意： InnoDB 引擎在加锁的时候，只有通过索引进行检索的时候才会使用行级锁，否则会使用表级锁。这里我们希望使用行级锁，就要给要执行的方法字段名添加索引，值得注意的是，这个索引一定要创建成唯一索引，否则会出现多个重载方法之间无法同时被访问的问题。重载方法的话建议把参数类型也加上。)。当某条记录被加上排他锁之后，其他线程无法再在该行记录上增加排他锁。我们可以认为获得排他锁的线程即可获得分布式锁，当获取到锁之后，可以执行方法的业务逻辑，执行完方法之后，通过connection.commit()操作来释放锁。\n\n### 基于 Redis 做分布式锁\n\n#### 基于 REDIS 的 SETNX()、EXPIRE() 方法做分布式锁\n\nsetnx 的含义就是 SET if Not Exists，其主要有两个参数 setnx(key, value)。该方法是原子的，如果 key 不存在，则设置当前 key 成功，返回 1；如果当前 key 已经存在，则设置当前 key 失败，返回 0。\n\nexpire 设置过期时间，要注意的是 setnx 命令不能设置 key 的超时时间，只能通过 expire() 来对 key 设置。\n\n使用步骤\n\n1. setnx(lockkey, 1) 如果返回 0，则说明占位失败；如果返回 1，则说明占位成功\n\n2. expire() 命令对 lockkey 设置超时时间，为的是避免死锁问题。\n\n3. 执行完业务代码后，可以通过 delete 命令删除 key。\n\n#### 基于 REDLOCK 做分布式锁\n\nRedlock 是 Redis 的作者 antirez 给出的集群模式的 Redis 分布式锁，它基于 N 个完全独立的 Redis 节点（通常情况下 N 可以设置成 5）。\n\n算法的步骤如下：\n1. 客户端获取当前时间，以毫秒为单位。\n2. 客户端尝试获取 N 个节点的锁，（每个节点获取锁的方式和前面说的缓存锁一样），N 个节点以相同的 key 和 value 获取锁。客户端需要设置接口访问超时，接口超时时间需要远远小于锁超时时间，比如锁自动释放的时间是 10s，那么接口超时大概设置 5-50ms。这样可以在有 redis 节点宕机后，访问该节点时能尽快超时，而减小锁的正常使用。\n3. 客户端计算在获得锁的时候花费了多少时间，方法是用当前时间减去在步骤一获取的时间，只有客户端获得了超过 3 个节点的锁，而且获取锁的时间小于锁的超时时间，客户端才获得了分布式锁。\n4. 客户端获取的锁的时间为设置的锁超时时间减去步骤三计算出的获取锁花费时间。\n5. 如果客户端获取锁失败了，客户端会依次删除所有的锁。\n使用 Redlock 算法，可以保证在挂掉最多 2 个节点的时候，分布式锁服务仍然能工作，这相比之前的数据库锁和缓存锁大大提高了可用性，由于 redis 的高效性能，分布式缓存锁性能并不比数据库锁差。\n\n\n### 基于 ZooKeeper 做分布式锁\n\n#### ZOOKEEPER 锁相关基础知识\n- zk 一般由多个节点构成（单数），采用 zab 一致性协议。因此可以将 zk 看成一个单点结构，对其修改数据其内部自动将所有节点数据进行修改而后才提供查询服务。\n- zk 的数据以目录树的形式，每个目录称为 znode， znode 中可存储数据（一般不超过 1M），还可以在其中增加子节点。\n- 子节点有三种类型。序列化节点，每在该节点下增加一个节点自动给该节点的名称上自增。临时节点，一旦创建这个 znode 的客户端与服务器失去联系，这个 znode 也将自动删除。最后就是普通节点。\n- Watch 机制，client 可以监控每个节点的变化，当产生变化会给 client 产生一个事件。\n\n#### ZK 基本锁\n- 原理：利用临时节点与 watch 机制。每个锁占用一个普通节点 /lock，当需要获取锁时在 /lock 目录下创建一个临时节点，创建成功则表示获取锁成功，失败则 watch/lock 节点，有删除操作后再去争锁。临时节点好处在于当进程挂掉后能自动上锁的节点自动删除即取消锁。\n- 缺点：所有取锁失败的进程都监听父节点，很容易发生羊群效应，即当释放锁后所有等待进程一起来创建节点，并发量很大。\n\n#### ZK 锁优化\n原理：上锁改为创建临时有序节点，每个上锁的节点均能创建节点成功，只是其序号不同。只有序号最小的可以拥有锁，如果这个节点序号不是最小的则 watch 序号比本身小的前一个节点 (公平锁)。\n\n#### 步骤：\n1. 在 /lock 节点下创建一个有序临时节点 (EPHEMERAL_SEQUENTIAL)。\n2. 判断创建的节点序号是否最小，如果是最小则获取锁成功。不是则取锁失败，然后 watch 序号比本身小的前一个节点。\n3. 当取锁失败，设置 watch 后则等待 watch 事件到来后，再次判断是否序号最小。\n4. 取锁成功则执行代码，最后释放锁（删除该节点）。\n\n\n","source":"_posts/2019-06-11-kongzheng1993-关于分布式锁.md","raw":"---\nlayout: post\ntitle: 关于分布式锁.md\ndate: 2019-06-11 15:48:10\nexcerpt: \"more\"\ntags: [quartz,锁,分布式]\ncategories: [quartz,锁,分布式]\ncomments: true\n---\n\n\n前段时间上线了一个需求：用户在页面填写计划任务，在用户的计划时间给用户下发短信提醒。\n\n我当时一想这不简单，给页面提供一个接口，数据入库，后台做一个定时任务，每分钟去取当前时间需要下发短信的数据，调用短信接口。\n\n为此还特地学习了一下quartz。需求很快完成了，接着就上线了。\n\n第二天验证，每条数据竟然收到了八条短信！！！\n\n找日志看了一下，每个tomcat都跑了task，都取到了所有的数据，都下发了短信，正好8个tomcat，一个不多，一个不少。。。\n\n## 想办法\n\n查资料了解到quartz支持集群的，一开始我猜想的可能是通过集群中各节点互相通信来实现。后来知道是通过数据库锁来实现的。\n\n```sql\n\nselect * from  ... for update;\n\n```\n通过db的行级锁来实现只有一个实例可以继续执行。\n\n想到新建很多表，只为了解决这个问题，还是觉得大材小用，继续寻找其他方法。不过通过这些资料，我了解到分布式锁。\n\n## 什么是分布式锁\n\n在分布式模型下，数据只有一份，可是集群中多个节点都会去操作这份数据。与单机模式下的锁相比，不仅要保证进程可见，还需要考虑进程与锁之间的网络问题。不过思路还是一样的，只要能保证标记能互斥就行。\n\n## 我们需要怎样的分布式锁？\n\n- 可以保证在分布式部署的应用集群中，同一个方法在同一时间只能被一台机器-上的一个线程执行。\n- 这把锁要是一把可重入锁（避免死锁）\n- 这把锁最好是一把阻塞锁（根据业务需求考虑要不要这条）\n- 这把锁最好是一把公平锁（根据业务需求考虑要不要这条）\n- 有高可用的获取锁和释放锁功能\n- 获取锁和释放锁的性能要好\n\n### 基于数据库做分布式锁\n\n#### 基于表主键唯一做分布式锁\n\n利用主键唯一的特性，如果有多个请求同时提交到数据库的话，数据库会保证只有一个操作可以成功，那么我们就可以认为操作成功的那个线程获得了该方法的锁，当方法执行完毕之后，想要释放锁的话，删除这条数据库记录即可。\n\n#### 基于表字段版本号做分布式锁\n\n这个策略源于 mysql 的 mvcc 机制，使用这个策略其实本身没有什么问题，唯一的问题就是对数据表侵入较大，我们要为每个表设计一个版本号字段，然后写一条判断 sql 每次进行判断，增加了数据库操作的次数，在高并发的要求下，对数据库连接的开销也是无法忍受的。\n\n#### 基于数据库排他锁做分布式锁\n\n在查询语句后面增加for update，数据库会在查询过程中给数据库表增加排他锁 (注意： InnoDB 引擎在加锁的时候，只有通过索引进行检索的时候才会使用行级锁，否则会使用表级锁。这里我们希望使用行级锁，就要给要执行的方法字段名添加索引，值得注意的是，这个索引一定要创建成唯一索引，否则会出现多个重载方法之间无法同时被访问的问题。重载方法的话建议把参数类型也加上。)。当某条记录被加上排他锁之后，其他线程无法再在该行记录上增加排他锁。我们可以认为获得排他锁的线程即可获得分布式锁，当获取到锁之后，可以执行方法的业务逻辑，执行完方法之后，通过connection.commit()操作来释放锁。\n\n### 基于 Redis 做分布式锁\n\n#### 基于 REDIS 的 SETNX()、EXPIRE() 方法做分布式锁\n\nsetnx 的含义就是 SET if Not Exists，其主要有两个参数 setnx(key, value)。该方法是原子的，如果 key 不存在，则设置当前 key 成功，返回 1；如果当前 key 已经存在，则设置当前 key 失败，返回 0。\n\nexpire 设置过期时间，要注意的是 setnx 命令不能设置 key 的超时时间，只能通过 expire() 来对 key 设置。\n\n使用步骤\n\n1. setnx(lockkey, 1) 如果返回 0，则说明占位失败；如果返回 1，则说明占位成功\n\n2. expire() 命令对 lockkey 设置超时时间，为的是避免死锁问题。\n\n3. 执行完业务代码后，可以通过 delete 命令删除 key。\n\n#### 基于 REDLOCK 做分布式锁\n\nRedlock 是 Redis 的作者 antirez 给出的集群模式的 Redis 分布式锁，它基于 N 个完全独立的 Redis 节点（通常情况下 N 可以设置成 5）。\n\n算法的步骤如下：\n1. 客户端获取当前时间，以毫秒为单位。\n2. 客户端尝试获取 N 个节点的锁，（每个节点获取锁的方式和前面说的缓存锁一样），N 个节点以相同的 key 和 value 获取锁。客户端需要设置接口访问超时，接口超时时间需要远远小于锁超时时间，比如锁自动释放的时间是 10s，那么接口超时大概设置 5-50ms。这样可以在有 redis 节点宕机后，访问该节点时能尽快超时，而减小锁的正常使用。\n3. 客户端计算在获得锁的时候花费了多少时间，方法是用当前时间减去在步骤一获取的时间，只有客户端获得了超过 3 个节点的锁，而且获取锁的时间小于锁的超时时间，客户端才获得了分布式锁。\n4. 客户端获取的锁的时间为设置的锁超时时间减去步骤三计算出的获取锁花费时间。\n5. 如果客户端获取锁失败了，客户端会依次删除所有的锁。\n使用 Redlock 算法，可以保证在挂掉最多 2 个节点的时候，分布式锁服务仍然能工作，这相比之前的数据库锁和缓存锁大大提高了可用性，由于 redis 的高效性能，分布式缓存锁性能并不比数据库锁差。\n\n\n### 基于 ZooKeeper 做分布式锁\n\n#### ZOOKEEPER 锁相关基础知识\n- zk 一般由多个节点构成（单数），采用 zab 一致性协议。因此可以将 zk 看成一个单点结构，对其修改数据其内部自动将所有节点数据进行修改而后才提供查询服务。\n- zk 的数据以目录树的形式，每个目录称为 znode， znode 中可存储数据（一般不超过 1M），还可以在其中增加子节点。\n- 子节点有三种类型。序列化节点，每在该节点下增加一个节点自动给该节点的名称上自增。临时节点，一旦创建这个 znode 的客户端与服务器失去联系，这个 znode 也将自动删除。最后就是普通节点。\n- Watch 机制，client 可以监控每个节点的变化，当产生变化会给 client 产生一个事件。\n\n#### ZK 基本锁\n- 原理：利用临时节点与 watch 机制。每个锁占用一个普通节点 /lock，当需要获取锁时在 /lock 目录下创建一个临时节点，创建成功则表示获取锁成功，失败则 watch/lock 节点，有删除操作后再去争锁。临时节点好处在于当进程挂掉后能自动上锁的节点自动删除即取消锁。\n- 缺点：所有取锁失败的进程都监听父节点，很容易发生羊群效应，即当释放锁后所有等待进程一起来创建节点，并发量很大。\n\n#### ZK 锁优化\n原理：上锁改为创建临时有序节点，每个上锁的节点均能创建节点成功，只是其序号不同。只有序号最小的可以拥有锁，如果这个节点序号不是最小的则 watch 序号比本身小的前一个节点 (公平锁)。\n\n#### 步骤：\n1. 在 /lock 节点下创建一个有序临时节点 (EPHEMERAL_SEQUENTIAL)。\n2. 判断创建的节点序号是否最小，如果是最小则获取锁成功。不是则取锁失败，然后 watch 序号比本身小的前一个节点。\n3. 当取锁失败，设置 watch 后则等待 watch 事件到来后，再次判断是否序号最小。\n4. 取锁成功则执行代码，最后释放锁（删除该节点）。\n\n\n","slug":"kongzheng1993-关于分布式锁","published":1,"updated":"2023-03-08T07:05:58.775Z","photos":[],"link":"","_id":"clg0k2ac4001bt26f1mr6ck8s","content":"<p>前段时间上线了一个需求：用户在页面填写计划任务，在用户的计划时间给用户下发短信提醒。</p>\n<p>我当时一想这不简单，给页面提供一个接口，数据入库，后台做一个定时任务，每分钟去取当前时间需要下发短信的数据，调用短信接口。</p>\n<p>为此还特地学习了一下quartz。需求很快完成了，接着就上线了。</p>\n<p>第二天验证，每条数据竟然收到了八条短信！！！</p>\n<p>找日志看了一下，每个tomcat都跑了task，都取到了所有的数据，都下发了短信，正好8个tomcat，一个不多，一个不少。。。</p>\n<h2 id=\"想办法\"><a href=\"#想办法\" class=\"headerlink\" title=\"想办法\"></a>想办法</h2><p>查资料了解到quartz支持集群的，一开始我猜想的可能是通过集群中各节点互相通信来实现。后来知道是通过数据库锁来实现的。</p>\n<pre><code class=\"sql\">\nselect * from  ... for update;\n</code></pre>\n<p>通过db的行级锁来实现只有一个实例可以继续执行。</p>\n<p>想到新建很多表，只为了解决这个问题，还是觉得大材小用，继续寻找其他方法。不过通过这些资料，我了解到分布式锁。</p>\n<h2 id=\"什么是分布式锁\"><a href=\"#什么是分布式锁\" class=\"headerlink\" title=\"什么是分布式锁\"></a>什么是分布式锁</h2><p>在分布式模型下，数据只有一份，可是集群中多个节点都会去操作这份数据。与单机模式下的锁相比，不仅要保证进程可见，还需要考虑进程与锁之间的网络问题。不过思路还是一样的，只要能保证标记能互斥就行。</p>\n<h2 id=\"我们需要怎样的分布式锁？\"><a href=\"#我们需要怎样的分布式锁？\" class=\"headerlink\" title=\"我们需要怎样的分布式锁？\"></a>我们需要怎样的分布式锁？</h2><ul>\n<li>可以保证在分布式部署的应用集群中，同一个方法在同一时间只能被一台机器-上的一个线程执行。</li>\n<li>这把锁要是一把可重入锁（避免死锁）</li>\n<li>这把锁最好是一把阻塞锁（根据业务需求考虑要不要这条）</li>\n<li>这把锁最好是一把公平锁（根据业务需求考虑要不要这条）</li>\n<li>有高可用的获取锁和释放锁功能</li>\n<li>获取锁和释放锁的性能要好</li>\n</ul>\n<h3 id=\"基于数据库做分布式锁\"><a href=\"#基于数据库做分布式锁\" class=\"headerlink\" title=\"基于数据库做分布式锁\"></a>基于数据库做分布式锁</h3><h4 id=\"基于表主键唯一做分布式锁\"><a href=\"#基于表主键唯一做分布式锁\" class=\"headerlink\" title=\"基于表主键唯一做分布式锁\"></a>基于表主键唯一做分布式锁</h4><p>利用主键唯一的特性，如果有多个请求同时提交到数据库的话，数据库会保证只有一个操作可以成功，那么我们就可以认为操作成功的那个线程获得了该方法的锁，当方法执行完毕之后，想要释放锁的话，删除这条数据库记录即可。</p>\n<h4 id=\"基于表字段版本号做分布式锁\"><a href=\"#基于表字段版本号做分布式锁\" class=\"headerlink\" title=\"基于表字段版本号做分布式锁\"></a>基于表字段版本号做分布式锁</h4><p>这个策略源于 mysql 的 mvcc 机制，使用这个策略其实本身没有什么问题，唯一的问题就是对数据表侵入较大，我们要为每个表设计一个版本号字段，然后写一条判断 sql 每次进行判断，增加了数据库操作的次数，在高并发的要求下，对数据库连接的开销也是无法忍受的。</p>\n<h4 id=\"基于数据库排他锁做分布式锁\"><a href=\"#基于数据库排他锁做分布式锁\" class=\"headerlink\" title=\"基于数据库排他锁做分布式锁\"></a>基于数据库排他锁做分布式锁</h4><p>在查询语句后面增加for update，数据库会在查询过程中给数据库表增加排他锁 (注意： InnoDB 引擎在加锁的时候，只有通过索引进行检索的时候才会使用行级锁，否则会使用表级锁。这里我们希望使用行级锁，就要给要执行的方法字段名添加索引，值得注意的是，这个索引一定要创建成唯一索引，否则会出现多个重载方法之间无法同时被访问的问题。重载方法的话建议把参数类型也加上。)。当某条记录被加上排他锁之后，其他线程无法再在该行记录上增加排他锁。我们可以认为获得排他锁的线程即可获得分布式锁，当获取到锁之后，可以执行方法的业务逻辑，执行完方法之后，通过connection.commit()操作来释放锁。</p>\n<h3 id=\"基于-Redis-做分布式锁\"><a href=\"#基于-Redis-做分布式锁\" class=\"headerlink\" title=\"基于 Redis 做分布式锁\"></a>基于 Redis 做分布式锁</h3><h4 id=\"基于-REDIS-的-SETNX-、EXPIRE-方法做分布式锁\"><a href=\"#基于-REDIS-的-SETNX-、EXPIRE-方法做分布式锁\" class=\"headerlink\" title=\"基于 REDIS 的 SETNX()、EXPIRE() 方法做分布式锁\"></a>基于 REDIS 的 SETNX()、EXPIRE() 方法做分布式锁</h4><p>setnx 的含义就是 SET if Not Exists，其主要有两个参数 setnx(key, value)。该方法是原子的，如果 key 不存在，则设置当前 key 成功，返回 1；如果当前 key 已经存在，则设置当前 key 失败，返回 0。</p>\n<p>expire 设置过期时间，要注意的是 setnx 命令不能设置 key 的超时时间，只能通过 expire() 来对 key 设置。</p>\n<p>使用步骤</p>\n<ol>\n<li><p>setnx(lockkey, 1) 如果返回 0，则说明占位失败；如果返回 1，则说明占位成功</p>\n</li>\n<li><p>expire() 命令对 lockkey 设置超时时间，为的是避免死锁问题。</p>\n</li>\n<li><p>执行完业务代码后，可以通过 delete 命令删除 key。</p>\n</li>\n</ol>\n<h4 id=\"基于-REDLOCK-做分布式锁\"><a href=\"#基于-REDLOCK-做分布式锁\" class=\"headerlink\" title=\"基于 REDLOCK 做分布式锁\"></a>基于 REDLOCK 做分布式锁</h4><p>Redlock 是 Redis 的作者 antirez 给出的集群模式的 Redis 分布式锁，它基于 N 个完全独立的 Redis 节点（通常情况下 N 可以设置成 5）。</p>\n<p>算法的步骤如下：</p>\n<ol>\n<li>客户端获取当前时间，以毫秒为单位。</li>\n<li>客户端尝试获取 N 个节点的锁，（每个节点获取锁的方式和前面说的缓存锁一样），N 个节点以相同的 key 和 value 获取锁。客户端需要设置接口访问超时，接口超时时间需要远远小于锁超时时间，比如锁自动释放的时间是 10s，那么接口超时大概设置 5-50ms。这样可以在有 redis 节点宕机后，访问该节点时能尽快超时，而减小锁的正常使用。</li>\n<li>客户端计算在获得锁的时候花费了多少时间，方法是用当前时间减去在步骤一获取的时间，只有客户端获得了超过 3 个节点的锁，而且获取锁的时间小于锁的超时时间，客户端才获得了分布式锁。</li>\n<li>客户端获取的锁的时间为设置的锁超时时间减去步骤三计算出的获取锁花费时间。</li>\n<li>如果客户端获取锁失败了，客户端会依次删除所有的锁。<br>使用 Redlock 算法，可以保证在挂掉最多 2 个节点的时候，分布式锁服务仍然能工作，这相比之前的数据库锁和缓存锁大大提高了可用性，由于 redis 的高效性能，分布式缓存锁性能并不比数据库锁差。</li>\n</ol>\n<h3 id=\"基于-ZooKeeper-做分布式锁\"><a href=\"#基于-ZooKeeper-做分布式锁\" class=\"headerlink\" title=\"基于 ZooKeeper 做分布式锁\"></a>基于 ZooKeeper 做分布式锁</h3><h4 id=\"ZOOKEEPER-锁相关基础知识\"><a href=\"#ZOOKEEPER-锁相关基础知识\" class=\"headerlink\" title=\"ZOOKEEPER 锁相关基础知识\"></a>ZOOKEEPER 锁相关基础知识</h4><ul>\n<li>zk 一般由多个节点构成（单数），采用 zab 一致性协议。因此可以将 zk 看成一个单点结构，对其修改数据其内部自动将所有节点数据进行修改而后才提供查询服务。</li>\n<li>zk 的数据以目录树的形式，每个目录称为 znode， znode 中可存储数据（一般不超过 1M），还可以在其中增加子节点。</li>\n<li>子节点有三种类型。序列化节点，每在该节点下增加一个节点自动给该节点的名称上自增。临时节点，一旦创建这个 znode 的客户端与服务器失去联系，这个 znode 也将自动删除。最后就是普通节点。</li>\n<li>Watch 机制，client 可以监控每个节点的变化，当产生变化会给 client 产生一个事件。</li>\n</ul>\n<h4 id=\"ZK-基本锁\"><a href=\"#ZK-基本锁\" class=\"headerlink\" title=\"ZK 基本锁\"></a>ZK 基本锁</h4><ul>\n<li>原理：利用临时节点与 watch 机制。每个锁占用一个普通节点 /lock，当需要获取锁时在 /lock 目录下创建一个临时节点，创建成功则表示获取锁成功，失败则 watch/lock 节点，有删除操作后再去争锁。临时节点好处在于当进程挂掉后能自动上锁的节点自动删除即取消锁。</li>\n<li>缺点：所有取锁失败的进程都监听父节点，很容易发生羊群效应，即当释放锁后所有等待进程一起来创建节点，并发量很大。</li>\n</ul>\n<h4 id=\"ZK-锁优化\"><a href=\"#ZK-锁优化\" class=\"headerlink\" title=\"ZK 锁优化\"></a>ZK 锁优化</h4><p>原理：上锁改为创建临时有序节点，每个上锁的节点均能创建节点成功，只是其序号不同。只有序号最小的可以拥有锁，如果这个节点序号不是最小的则 watch 序号比本身小的前一个节点 (公平锁)。</p>\n<h4 id=\"步骤：\"><a href=\"#步骤：\" class=\"headerlink\" title=\"步骤：\"></a>步骤：</h4><ol>\n<li>在 /lock 节点下创建一个有序临时节点 (EPHEMERAL_SEQUENTIAL)。</li>\n<li>判断创建的节点序号是否最小，如果是最小则获取锁成功。不是则取锁失败，然后 watch 序号比本身小的前一个节点。</li>\n<li>当取锁失败，设置 watch 后则等待 watch 事件到来后，再次判断是否序号最小。</li>\n<li>取锁成功则执行代码，最后释放锁（删除该节点）。</li>\n</ol>\n","site":{"data":{}},"more":"<p>前段时间上线了一个需求：用户在页面填写计划任务，在用户的计划时间给用户下发短信提醒。</p>\n<p>我当时一想这不简单，给页面提供一个接口，数据入库，后台做一个定时任务，每分钟去取当前时间需要下发短信的数据，调用短信接口。</p>\n<p>为此还特地学习了一下quartz。需求很快完成了，接着就上线了。</p>\n<p>第二天验证，每条数据竟然收到了八条短信！！！</p>\n<p>找日志看了一下，每个tomcat都跑了task，都取到了所有的数据，都下发了短信，正好8个tomcat，一个不多，一个不少。。。</p>\n<h2 id=\"想办法\"><a href=\"#想办法\" class=\"headerlink\" title=\"想办法\"></a>想办法</h2><p>查资料了解到quartz支持集群的，一开始我猜想的可能是通过集群中各节点互相通信来实现。后来知道是通过数据库锁来实现的。</p>\n<pre><code class=\"sql\">\nselect * from  ... for update;\n</code></pre>\n<p>通过db的行级锁来实现只有一个实例可以继续执行。</p>\n<p>想到新建很多表，只为了解决这个问题，还是觉得大材小用，继续寻找其他方法。不过通过这些资料，我了解到分布式锁。</p>\n<h2 id=\"什么是分布式锁\"><a href=\"#什么是分布式锁\" class=\"headerlink\" title=\"什么是分布式锁\"></a>什么是分布式锁</h2><p>在分布式模型下，数据只有一份，可是集群中多个节点都会去操作这份数据。与单机模式下的锁相比，不仅要保证进程可见，还需要考虑进程与锁之间的网络问题。不过思路还是一样的，只要能保证标记能互斥就行。</p>\n<h2 id=\"我们需要怎样的分布式锁？\"><a href=\"#我们需要怎样的分布式锁？\" class=\"headerlink\" title=\"我们需要怎样的分布式锁？\"></a>我们需要怎样的分布式锁？</h2><ul>\n<li>可以保证在分布式部署的应用集群中，同一个方法在同一时间只能被一台机器-上的一个线程执行。</li>\n<li>这把锁要是一把可重入锁（避免死锁）</li>\n<li>这把锁最好是一把阻塞锁（根据业务需求考虑要不要这条）</li>\n<li>这把锁最好是一把公平锁（根据业务需求考虑要不要这条）</li>\n<li>有高可用的获取锁和释放锁功能</li>\n<li>获取锁和释放锁的性能要好</li>\n</ul>\n<h3 id=\"基于数据库做分布式锁\"><a href=\"#基于数据库做分布式锁\" class=\"headerlink\" title=\"基于数据库做分布式锁\"></a>基于数据库做分布式锁</h3><h4 id=\"基于表主键唯一做分布式锁\"><a href=\"#基于表主键唯一做分布式锁\" class=\"headerlink\" title=\"基于表主键唯一做分布式锁\"></a>基于表主键唯一做分布式锁</h4><p>利用主键唯一的特性，如果有多个请求同时提交到数据库的话，数据库会保证只有一个操作可以成功，那么我们就可以认为操作成功的那个线程获得了该方法的锁，当方法执行完毕之后，想要释放锁的话，删除这条数据库记录即可。</p>\n<h4 id=\"基于表字段版本号做分布式锁\"><a href=\"#基于表字段版本号做分布式锁\" class=\"headerlink\" title=\"基于表字段版本号做分布式锁\"></a>基于表字段版本号做分布式锁</h4><p>这个策略源于 mysql 的 mvcc 机制，使用这个策略其实本身没有什么问题，唯一的问题就是对数据表侵入较大，我们要为每个表设计一个版本号字段，然后写一条判断 sql 每次进行判断，增加了数据库操作的次数，在高并发的要求下，对数据库连接的开销也是无法忍受的。</p>\n<h4 id=\"基于数据库排他锁做分布式锁\"><a href=\"#基于数据库排他锁做分布式锁\" class=\"headerlink\" title=\"基于数据库排他锁做分布式锁\"></a>基于数据库排他锁做分布式锁</h4><p>在查询语句后面增加for update，数据库会在查询过程中给数据库表增加排他锁 (注意： InnoDB 引擎在加锁的时候，只有通过索引进行检索的时候才会使用行级锁，否则会使用表级锁。这里我们希望使用行级锁，就要给要执行的方法字段名添加索引，值得注意的是，这个索引一定要创建成唯一索引，否则会出现多个重载方法之间无法同时被访问的问题。重载方法的话建议把参数类型也加上。)。当某条记录被加上排他锁之后，其他线程无法再在该行记录上增加排他锁。我们可以认为获得排他锁的线程即可获得分布式锁，当获取到锁之后，可以执行方法的业务逻辑，执行完方法之后，通过connection.commit()操作来释放锁。</p>\n<h3 id=\"基于-Redis-做分布式锁\"><a href=\"#基于-Redis-做分布式锁\" class=\"headerlink\" title=\"基于 Redis 做分布式锁\"></a>基于 Redis 做分布式锁</h3><h4 id=\"基于-REDIS-的-SETNX-、EXPIRE-方法做分布式锁\"><a href=\"#基于-REDIS-的-SETNX-、EXPIRE-方法做分布式锁\" class=\"headerlink\" title=\"基于 REDIS 的 SETNX()、EXPIRE() 方法做分布式锁\"></a>基于 REDIS 的 SETNX()、EXPIRE() 方法做分布式锁</h4><p>setnx 的含义就是 SET if Not Exists，其主要有两个参数 setnx(key, value)。该方法是原子的，如果 key 不存在，则设置当前 key 成功，返回 1；如果当前 key 已经存在，则设置当前 key 失败，返回 0。</p>\n<p>expire 设置过期时间，要注意的是 setnx 命令不能设置 key 的超时时间，只能通过 expire() 来对 key 设置。</p>\n<p>使用步骤</p>\n<ol>\n<li><p>setnx(lockkey, 1) 如果返回 0，则说明占位失败；如果返回 1，则说明占位成功</p>\n</li>\n<li><p>expire() 命令对 lockkey 设置超时时间，为的是避免死锁问题。</p>\n</li>\n<li><p>执行完业务代码后，可以通过 delete 命令删除 key。</p>\n</li>\n</ol>\n<h4 id=\"基于-REDLOCK-做分布式锁\"><a href=\"#基于-REDLOCK-做分布式锁\" class=\"headerlink\" title=\"基于 REDLOCK 做分布式锁\"></a>基于 REDLOCK 做分布式锁</h4><p>Redlock 是 Redis 的作者 antirez 给出的集群模式的 Redis 分布式锁，它基于 N 个完全独立的 Redis 节点（通常情况下 N 可以设置成 5）。</p>\n<p>算法的步骤如下：</p>\n<ol>\n<li>客户端获取当前时间，以毫秒为单位。</li>\n<li>客户端尝试获取 N 个节点的锁，（每个节点获取锁的方式和前面说的缓存锁一样），N 个节点以相同的 key 和 value 获取锁。客户端需要设置接口访问超时，接口超时时间需要远远小于锁超时时间，比如锁自动释放的时间是 10s，那么接口超时大概设置 5-50ms。这样可以在有 redis 节点宕机后，访问该节点时能尽快超时，而减小锁的正常使用。</li>\n<li>客户端计算在获得锁的时候花费了多少时间，方法是用当前时间减去在步骤一获取的时间，只有客户端获得了超过 3 个节点的锁，而且获取锁的时间小于锁的超时时间，客户端才获得了分布式锁。</li>\n<li>客户端获取的锁的时间为设置的锁超时时间减去步骤三计算出的获取锁花费时间。</li>\n<li>如果客户端获取锁失败了，客户端会依次删除所有的锁。<br>使用 Redlock 算法，可以保证在挂掉最多 2 个节点的时候，分布式锁服务仍然能工作，这相比之前的数据库锁和缓存锁大大提高了可用性，由于 redis 的高效性能，分布式缓存锁性能并不比数据库锁差。</li>\n</ol>\n<h3 id=\"基于-ZooKeeper-做分布式锁\"><a href=\"#基于-ZooKeeper-做分布式锁\" class=\"headerlink\" title=\"基于 ZooKeeper 做分布式锁\"></a>基于 ZooKeeper 做分布式锁</h3><h4 id=\"ZOOKEEPER-锁相关基础知识\"><a href=\"#ZOOKEEPER-锁相关基础知识\" class=\"headerlink\" title=\"ZOOKEEPER 锁相关基础知识\"></a>ZOOKEEPER 锁相关基础知识</h4><ul>\n<li>zk 一般由多个节点构成（单数），采用 zab 一致性协议。因此可以将 zk 看成一个单点结构，对其修改数据其内部自动将所有节点数据进行修改而后才提供查询服务。</li>\n<li>zk 的数据以目录树的形式，每个目录称为 znode， znode 中可存储数据（一般不超过 1M），还可以在其中增加子节点。</li>\n<li>子节点有三种类型。序列化节点，每在该节点下增加一个节点自动给该节点的名称上自增。临时节点，一旦创建这个 znode 的客户端与服务器失去联系，这个 znode 也将自动删除。最后就是普通节点。</li>\n<li>Watch 机制，client 可以监控每个节点的变化，当产生变化会给 client 产生一个事件。</li>\n</ul>\n<h4 id=\"ZK-基本锁\"><a href=\"#ZK-基本锁\" class=\"headerlink\" title=\"ZK 基本锁\"></a>ZK 基本锁</h4><ul>\n<li>原理：利用临时节点与 watch 机制。每个锁占用一个普通节点 /lock，当需要获取锁时在 /lock 目录下创建一个临时节点，创建成功则表示获取锁成功，失败则 watch/lock 节点，有删除操作后再去争锁。临时节点好处在于当进程挂掉后能自动上锁的节点自动删除即取消锁。</li>\n<li>缺点：所有取锁失败的进程都监听父节点，很容易发生羊群效应，即当释放锁后所有等待进程一起来创建节点，并发量很大。</li>\n</ul>\n<h4 id=\"ZK-锁优化\"><a href=\"#ZK-锁优化\" class=\"headerlink\" title=\"ZK 锁优化\"></a>ZK 锁优化</h4><p>原理：上锁改为创建临时有序节点，每个上锁的节点均能创建节点成功，只是其序号不同。只有序号最小的可以拥有锁，如果这个节点序号不是最小的则 watch 序号比本身小的前一个节点 (公平锁)。</p>\n<h4 id=\"步骤：\"><a href=\"#步骤：\" class=\"headerlink\" title=\"步骤：\"></a>步骤：</h4><ol>\n<li>在 /lock 节点下创建一个有序临时节点 (EPHEMERAL_SEQUENTIAL)。</li>\n<li>判断创建的节点序号是否最小，如果是最小则获取锁成功。不是则取锁失败，然后 watch 序号比本身小的前一个节点。</li>\n<li>当取锁失败，设置 watch 后则等待 watch 事件到来后，再次判断是否序号最小。</li>\n<li>取锁成功则执行代码，最后释放锁（删除该节点）。</li>\n</ol>\n"},{"title":"MQ","date":"2019-06-04T06:36:47.000Z","_content":"\n最近去面试了，想去一个技术氛围好的团队。。。一直都认为自己菜，环境占大部分问题，是因为队友菜，我才会菜，即使我努力也是菜。面试官很好，很和蔼，让我对自己有了更清晰的认识，我会最近应该不会再面试了，我要沉淀一下，总结一下。\n\n## MQ使用场景\n\n调用方实时依赖执行结果的业务场景，要使用调用，而不是mq。\n\n1. task代替cron排班表，不再硬编码执行时间，而是通过在前一个任务执行完发布消息，下一个任务订阅这个消息来完成整个流程。\n2. 上游不关心执行结果。用mq解耦。上游服务不用等待下游服务处理完再返回。即使下游服务宕机，用户也不会感知到，一旦下游服务恢复正常可以继续消费之前的消息。\n3. 上游关心执行结果，但是执行时间长。这种情况经常使用回调网管+mq来完成。\n    比如下面的过程：\n    - 调用方直接跨公网调用微信接口\n    - 微信返回调用成功，此时并不代表返回成功\n    - 微信执行完成后，回调统一网关\n    - 网关将返回结果通知MQ\n    - 请求方收到结果通知\n\n\n## MQ的作用\n1. 解耦：减小各系统间的耦合度，防止牵一发而动全身。\n2. 异步：提高系统响应时间，本来同步接口需要等下游系统处理完成再返回，现在可以直接返回，下游系统通过消费消息来完成自己的业务。\n3. 削峰/限流：在大量请求来临的时候，系统可能无法即使处理，严重的情况可能会导致系统崩溃。使用mq，可以将请求写到mq，下游系统根据自己的能力去消费消息。","source":"_posts/2019-06-04-kongzheng1993-MQ.md","raw":"---\ntitle: MQ\ndate: 2019-06-04 14:36:47\ntags: [mq, 消息队列]\n---\n\n最近去面试了，想去一个技术氛围好的团队。。。一直都认为自己菜，环境占大部分问题，是因为队友菜，我才会菜，即使我努力也是菜。面试官很好，很和蔼，让我对自己有了更清晰的认识，我会最近应该不会再面试了，我要沉淀一下，总结一下。\n\n## MQ使用场景\n\n调用方实时依赖执行结果的业务场景，要使用调用，而不是mq。\n\n1. task代替cron排班表，不再硬编码执行时间，而是通过在前一个任务执行完发布消息，下一个任务订阅这个消息来完成整个流程。\n2. 上游不关心执行结果。用mq解耦。上游服务不用等待下游服务处理完再返回。即使下游服务宕机，用户也不会感知到，一旦下游服务恢复正常可以继续消费之前的消息。\n3. 上游关心执行结果，但是执行时间长。这种情况经常使用回调网管+mq来完成。\n    比如下面的过程：\n    - 调用方直接跨公网调用微信接口\n    - 微信返回调用成功，此时并不代表返回成功\n    - 微信执行完成后，回调统一网关\n    - 网关将返回结果通知MQ\n    - 请求方收到结果通知\n\n\n## MQ的作用\n1. 解耦：减小各系统间的耦合度，防止牵一发而动全身。\n2. 异步：提高系统响应时间，本来同步接口需要等下游系统处理完成再返回，现在可以直接返回，下游系统通过消费消息来完成自己的业务。\n3. 削峰/限流：在大量请求来临的时候，系统可能无法即使处理，严重的情况可能会导致系统崩溃。使用mq，可以将请求写到mq，下游系统根据自己的能力去消费消息。","slug":"kongzheng1993-MQ","published":1,"updated":"2023-03-08T07:05:58.775Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clg0k2ac5001et26f0aozkpp0","content":"<p>最近去面试了，想去一个技术氛围好的团队。。。一直都认为自己菜，环境占大部分问题，是因为队友菜，我才会菜，即使我努力也是菜。面试官很好，很和蔼，让我对自己有了更清晰的认识，我会最近应该不会再面试了，我要沉淀一下，总结一下。</p>\n<h2 id=\"MQ使用场景\"><a href=\"#MQ使用场景\" class=\"headerlink\" title=\"MQ使用场景\"></a>MQ使用场景</h2><p>调用方实时依赖执行结果的业务场景，要使用调用，而不是mq。</p>\n<ol>\n<li>task代替cron排班表，不再硬编码执行时间，而是通过在前一个任务执行完发布消息，下一个任务订阅这个消息来完成整个流程。</li>\n<li>上游不关心执行结果。用mq解耦。上游服务不用等待下游服务处理完再返回。即使下游服务宕机，用户也不会感知到，一旦下游服务恢复正常可以继续消费之前的消息。</li>\n<li>上游关心执行结果，但是执行时间长。这种情况经常使用回调网管+mq来完成。<br> 比如下面的过程：<ul>\n<li>调用方直接跨公网调用微信接口</li>\n<li>微信返回调用成功，此时并不代表返回成功</li>\n<li>微信执行完成后，回调统一网关</li>\n<li>网关将返回结果通知MQ</li>\n<li>请求方收到结果通知</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"MQ的作用\"><a href=\"#MQ的作用\" class=\"headerlink\" title=\"MQ的作用\"></a>MQ的作用</h2><ol>\n<li>解耦：减小各系统间的耦合度，防止牵一发而动全身。</li>\n<li>异步：提高系统响应时间，本来同步接口需要等下游系统处理完成再返回，现在可以直接返回，下游系统通过消费消息来完成自己的业务。</li>\n<li>削峰/限流：在大量请求来临的时候，系统可能无法即使处理，严重的情况可能会导致系统崩溃。使用mq，可以将请求写到mq，下游系统根据自己的能力去消费消息。</li>\n</ol>\n","site":{"data":{}},"excerpt":"","more":"<p>最近去面试了，想去一个技术氛围好的团队。。。一直都认为自己菜，环境占大部分问题，是因为队友菜，我才会菜，即使我努力也是菜。面试官很好，很和蔼，让我对自己有了更清晰的认识，我会最近应该不会再面试了，我要沉淀一下，总结一下。</p>\n<h2 id=\"MQ使用场景\"><a href=\"#MQ使用场景\" class=\"headerlink\" title=\"MQ使用场景\"></a>MQ使用场景</h2><p>调用方实时依赖执行结果的业务场景，要使用调用，而不是mq。</p>\n<ol>\n<li>task代替cron排班表，不再硬编码执行时间，而是通过在前一个任务执行完发布消息，下一个任务订阅这个消息来完成整个流程。</li>\n<li>上游不关心执行结果。用mq解耦。上游服务不用等待下游服务处理完再返回。即使下游服务宕机，用户也不会感知到，一旦下游服务恢复正常可以继续消费之前的消息。</li>\n<li>上游关心执行结果，但是执行时间长。这种情况经常使用回调网管+mq来完成。<br> 比如下面的过程：<ul>\n<li>调用方直接跨公网调用微信接口</li>\n<li>微信返回调用成功，此时并不代表返回成功</li>\n<li>微信执行完成后，回调统一网关</li>\n<li>网关将返回结果通知MQ</li>\n<li>请求方收到结果通知</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"MQ的作用\"><a href=\"#MQ的作用\" class=\"headerlink\" title=\"MQ的作用\"></a>MQ的作用</h2><ol>\n<li>解耦：减小各系统间的耦合度，防止牵一发而动全身。</li>\n<li>异步：提高系统响应时间，本来同步接口需要等下游系统处理完成再返回，现在可以直接返回，下游系统通过消费消息来完成自己的业务。</li>\n<li>削峰/限流：在大量请求来临的时候，系统可能无法即使处理，严重的情况可能会导致系统崩溃。使用mq，可以将请求写到mq，下游系统根据自己的能力去消费消息。</li>\n</ol>\n"},{"title":"kongzheng1993-Connect_timed_out与Read_timed_out.md","date":"2019-06-13T03:45:08.000Z","_content":"","source":"_posts/2019-06-13-kongzheng1993-Connect-timed-out与Read-timed-out.md","raw":"---\ntitle: kongzheng1993-Connect_timed_out与Read_timed_out.md\ndate: 2019-06-13 11:45:08\ntags:\n---\n","slug":"kongzheng1993-Connect-timed-out与Read-timed-out","published":1,"updated":"2023-03-08T07:05:58.775Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clg0k2ac6001ft26fbd9moauc","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"RSA加密与SHA签名","date":"2019-06-13T03:43:52.000Z","excerpt":"","comments":1,"_content":"\n## 概念和意义\n\n### 数字签名\n\n数字签名，简单来说就是通过提供可鉴别的数字信息验证自身身份的一种方式。一套数字签名通常定义两种互补的运算，一个用于签名，另一个用于验证。分别由 发送者持有能够代表自己身份 的 私钥 (私钥不可泄露),由接受者持有与私钥对应的公钥，能够在接受到来自发送者信息时用于验证其身份。\n\n### 加密和解密\n\n数据加密的基本过程，就是对原来为明文的文件或数据按某种算法进行处理，使其成为不可读 的一段代码，通常称为“密文”。通过这样的途径，来达到保护数据不被非法人窃取、阅读的目的。\n加密的逆过程为解密，即将该编码信息转化为其原来数据的过程。\n\n加密算法分对称加密和非对称加密，其中对称加密算法的加密与解密密钥相同，非对称加密算法的加密密钥与解密密钥不同，此外，还有一类不需要密钥的散列算法。\n常见的对称加密算法主要有DES、3DES、AES 等，常见的非对称算法主要有RSA、DSA等，散列算法主要有SHA-1、MD5等。\n\n### 总结\n\n1. 签名的作用是确认信息来源。A对信息签名的作用是确认这个信息是A发出的。\n2. 加密是对内容进行机密性保护，主要保证信息内容不会被其他人获取，只有B可以解密。也就能保证整个过程端到端的唯一确定性，就算被截获，他人也不能获取信息的具体内容。\n\n## 加解密的过程\n\n通常公钥是公开出去的，私钥自己持有。\n需要发给对端的信息，用对端的公钥加密，对端用私钥解密。但是签名是对端确定你的身份，所以你要用自己的私钥加密，对端用你的公钥解签。这样对端就能得到明文的信息了。\n","source":"_posts/2019-06-13-kongzheng1993-RSA加密与SHA签名.md","raw":"---\ntitle: RSA加密与SHA签名\ndate: 2019-06-13 11:43:52\nexcerpt: \"mysql\"\ntags: [RSA,SHA,加密,签名]\ncategories: [RSA,SHA,加密,签名]\ncomments: true\n---\n\n## 概念和意义\n\n### 数字签名\n\n数字签名，简单来说就是通过提供可鉴别的数字信息验证自身身份的一种方式。一套数字签名通常定义两种互补的运算，一个用于签名，另一个用于验证。分别由 发送者持有能够代表自己身份 的 私钥 (私钥不可泄露),由接受者持有与私钥对应的公钥，能够在接受到来自发送者信息时用于验证其身份。\n\n### 加密和解密\n\n数据加密的基本过程，就是对原来为明文的文件或数据按某种算法进行处理，使其成为不可读 的一段代码，通常称为“密文”。通过这样的途径，来达到保护数据不被非法人窃取、阅读的目的。\n加密的逆过程为解密，即将该编码信息转化为其原来数据的过程。\n\n加密算法分对称加密和非对称加密，其中对称加密算法的加密与解密密钥相同，非对称加密算法的加密密钥与解密密钥不同，此外，还有一类不需要密钥的散列算法。\n常见的对称加密算法主要有DES、3DES、AES 等，常见的非对称算法主要有RSA、DSA等，散列算法主要有SHA-1、MD5等。\n\n### 总结\n\n1. 签名的作用是确认信息来源。A对信息签名的作用是确认这个信息是A发出的。\n2. 加密是对内容进行机密性保护，主要保证信息内容不会被其他人获取，只有B可以解密。也就能保证整个过程端到端的唯一确定性，就算被截获，他人也不能获取信息的具体内容。\n\n## 加解密的过程\n\n通常公钥是公开出去的，私钥自己持有。\n需要发给对端的信息，用对端的公钥加密，对端用私钥解密。但是签名是对端确定你的身份，所以你要用自己的私钥加密，对端用你的公钥解签。这样对端就能得到明文的信息了。\n","slug":"kongzheng1993-RSA加密与SHA签名","published":1,"updated":"2023-03-08T07:05:58.775Z","layout":"post","photos":[],"link":"","_id":"clg0k2ac6001ht26fzgt2ggl9","content":"<h2 id=\"概念和意义\"><a href=\"#概念和意义\" class=\"headerlink\" title=\"概念和意义\"></a>概念和意义</h2><h3 id=\"数字签名\"><a href=\"#数字签名\" class=\"headerlink\" title=\"数字签名\"></a>数字签名</h3><p>数字签名，简单来说就是通过提供可鉴别的数字信息验证自身身份的一种方式。一套数字签名通常定义两种互补的运算，一个用于签名，另一个用于验证。分别由 发送者持有能够代表自己身份 的 私钥 (私钥不可泄露),由接受者持有与私钥对应的公钥，能够在接受到来自发送者信息时用于验证其身份。</p>\n<h3 id=\"加密和解密\"><a href=\"#加密和解密\" class=\"headerlink\" title=\"加密和解密\"></a>加密和解密</h3><p>数据加密的基本过程，就是对原来为明文的文件或数据按某种算法进行处理，使其成为不可读 的一段代码，通常称为“密文”。通过这样的途径，来达到保护数据不被非法人窃取、阅读的目的。<br>加密的逆过程为解密，即将该编码信息转化为其原来数据的过程。</p>\n<p>加密算法分对称加密和非对称加密，其中对称加密算法的加密与解密密钥相同，非对称加密算法的加密密钥与解密密钥不同，此外，还有一类不需要密钥的散列算法。<br>常见的对称加密算法主要有DES、3DES、AES 等，常见的非对称算法主要有RSA、DSA等，散列算法主要有SHA-1、MD5等。</p>\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3><ol>\n<li>签名的作用是确认信息来源。A对信息签名的作用是确认这个信息是A发出的。</li>\n<li>加密是对内容进行机密性保护，主要保证信息内容不会被其他人获取，只有B可以解密。也就能保证整个过程端到端的唯一确定性，就算被截获，他人也不能获取信息的具体内容。</li>\n</ol>\n<h2 id=\"加解密的过程\"><a href=\"#加解密的过程\" class=\"headerlink\" title=\"加解密的过程\"></a>加解密的过程</h2><p>通常公钥是公开出去的，私钥自己持有。<br>需要发给对端的信息，用对端的公钥加密，对端用私钥解密。但是签名是对端确定你的身份，所以你要用自己的私钥加密，对端用你的公钥解签。这样对端就能得到明文的信息了。</p>\n","site":{"data":{}},"more":"<h2 id=\"概念和意义\"><a href=\"#概念和意义\" class=\"headerlink\" title=\"概念和意义\"></a>概念和意义</h2><h3 id=\"数字签名\"><a href=\"#数字签名\" class=\"headerlink\" title=\"数字签名\"></a>数字签名</h3><p>数字签名，简单来说就是通过提供可鉴别的数字信息验证自身身份的一种方式。一套数字签名通常定义两种互补的运算，一个用于签名，另一个用于验证。分别由 发送者持有能够代表自己身份 的 私钥 (私钥不可泄露),由接受者持有与私钥对应的公钥，能够在接受到来自发送者信息时用于验证其身份。</p>\n<h3 id=\"加密和解密\"><a href=\"#加密和解密\" class=\"headerlink\" title=\"加密和解密\"></a>加密和解密</h3><p>数据加密的基本过程，就是对原来为明文的文件或数据按某种算法进行处理，使其成为不可读 的一段代码，通常称为“密文”。通过这样的途径，来达到保护数据不被非法人窃取、阅读的目的。<br>加密的逆过程为解密，即将该编码信息转化为其原来数据的过程。</p>\n<p>加密算法分对称加密和非对称加密，其中对称加密算法的加密与解密密钥相同，非对称加密算法的加密密钥与解密密钥不同，此外，还有一类不需要密钥的散列算法。<br>常见的对称加密算法主要有DES、3DES、AES 等，常见的非对称算法主要有RSA、DSA等，散列算法主要有SHA-1、MD5等。</p>\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3><ol>\n<li>签名的作用是确认信息来源。A对信息签名的作用是确认这个信息是A发出的。</li>\n<li>加密是对内容进行机密性保护，主要保证信息内容不会被其他人获取，只有B可以解密。也就能保证整个过程端到端的唯一确定性，就算被截获，他人也不能获取信息的具体内容。</li>\n</ol>\n<h2 id=\"加解密的过程\"><a href=\"#加解密的过程\" class=\"headerlink\" title=\"加解密的过程\"></a>加解密的过程</h2><p>通常公钥是公开出去的，私钥自己持有。<br>需要发给对端的信息，用对端的公钥加密，对端用私钥解密。但是签名是对端确定你的身份，所以你要用自己的私钥加密，对端用你的公钥解签。这样对端就能得到明文的信息了。</p>\n"},{"title":"nohup和&","date":"2019-06-05T05:52:46.000Z","comments":1,"_content":"\n昨天申请休年假，但是组长表示让我别休年假，给我两天调休，所以今天就开始休息了。。。\n闲来无事，想起一个困扰多年的问题，RocketMQ启动时使用nohup和&命令，&我知道时后台运行，可以在后台进程中找到运行的程序，而且经常被程序的输出搞得无法执行下一条命令。。。今天就来总结一下。\n\n### 使用&后台运行程序\n- 结果会输出到终端\n- 使用Ctrl + C发送SIGINT信号，程序免疫\n- 关闭session发送SIGHUP信号，程序关闭\n\n### 使用nohup运行程序\n- 结果默认会输出到nohup.out\n- 使用Ctrl + C发送SIGINT信号，程序关闭\n- 关闭session发送SIGHUP信号，程序免疫\n\n### 使用nohup和&配合来启动程序\n- 同时免疫SIGINT和SIGHUP信号\n","source":"_posts/2019-06-05-kongzheng1993-nohup和&.md","raw":"---\ntitle: nohup和&\ndate: 2019-06-05 13:52:46\ntags: [Linux]\ncategories: [Linux]\ncomments: true\n---\n\n昨天申请休年假，但是组长表示让我别休年假，给我两天调休，所以今天就开始休息了。。。\n闲来无事，想起一个困扰多年的问题，RocketMQ启动时使用nohup和&命令，&我知道时后台运行，可以在后台进程中找到运行的程序，而且经常被程序的输出搞得无法执行下一条命令。。。今天就来总结一下。\n\n### 使用&后台运行程序\n- 结果会输出到终端\n- 使用Ctrl + C发送SIGINT信号，程序免疫\n- 关闭session发送SIGHUP信号，程序关闭\n\n### 使用nohup运行程序\n- 结果默认会输出到nohup.out\n- 使用Ctrl + C发送SIGINT信号，程序关闭\n- 关闭session发送SIGHUP信号，程序免疫\n\n### 使用nohup和&配合来启动程序\n- 同时免疫SIGINT和SIGHUP信号\n","slug":"kongzheng1993-nohup和&","published":1,"updated":"2023-03-08T07:05:58.775Z","layout":"post","photos":[],"link":"","_id":"clg0k2acf001kt26ftqr9zz50","content":"<p>昨天申请休年假，但是组长表示让我别休年假，给我两天调休，所以今天就开始休息了。。。<br>闲来无事，想起一个困扰多年的问题，RocketMQ启动时使用nohup和&amp;命令，&amp;我知道时后台运行，可以在后台进程中找到运行的程序，而且经常被程序的输出搞得无法执行下一条命令。。。今天就来总结一下。</p>\n<h3 id=\"使用-amp-后台运行程序\"><a href=\"#使用-amp-后台运行程序\" class=\"headerlink\" title=\"使用&amp;后台运行程序\"></a>使用&amp;后台运行程序</h3><ul>\n<li>结果会输出到终端</li>\n<li>使用Ctrl + C发送SIGINT信号，程序免疫</li>\n<li>关闭session发送SIGHUP信号，程序关闭</li>\n</ul>\n<h3 id=\"使用nohup运行程序\"><a href=\"#使用nohup运行程序\" class=\"headerlink\" title=\"使用nohup运行程序\"></a>使用nohup运行程序</h3><ul>\n<li>结果默认会输出到nohup.out</li>\n<li>使用Ctrl + C发送SIGINT信号，程序关闭</li>\n<li>关闭session发送SIGHUP信号，程序免疫</li>\n</ul>\n<h3 id=\"使用nohup和-amp-配合来启动程序\"><a href=\"#使用nohup和-amp-配合来启动程序\" class=\"headerlink\" title=\"使用nohup和&amp;配合来启动程序\"></a>使用nohup和&amp;配合来启动程序</h3><ul>\n<li>同时免疫SIGINT和SIGHUP信号</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p>昨天申请休年假，但是组长表示让我别休年假，给我两天调休，所以今天就开始休息了。。。<br>闲来无事，想起一个困扰多年的问题，RocketMQ启动时使用nohup和&amp;命令，&amp;我知道时后台运行，可以在后台进程中找到运行的程序，而且经常被程序的输出搞得无法执行下一条命令。。。今天就来总结一下。</p>\n<h3 id=\"使用-amp-后台运行程序\"><a href=\"#使用-amp-后台运行程序\" class=\"headerlink\" title=\"使用&amp;后台运行程序\"></a>使用&amp;后台运行程序</h3><ul>\n<li>结果会输出到终端</li>\n<li>使用Ctrl + C发送SIGINT信号，程序免疫</li>\n<li>关闭session发送SIGHUP信号，程序关闭</li>\n</ul>\n<h3 id=\"使用nohup运行程序\"><a href=\"#使用nohup运行程序\" class=\"headerlink\" title=\"使用nohup运行程序\"></a>使用nohup运行程序</h3><ul>\n<li>结果默认会输出到nohup.out</li>\n<li>使用Ctrl + C发送SIGINT信号，程序关闭</li>\n<li>关闭session发送SIGHUP信号，程序免疫</li>\n</ul>\n<h3 id=\"使用nohup和-amp-配合来启动程序\"><a href=\"#使用nohup和-amp-配合来启动程序\" class=\"headerlink\" title=\"使用nohup和&amp;配合来启动程序\"></a>使用nohup和&amp;配合来启动程序</h3><ul>\n<li>同时免疫SIGINT和SIGHUP信号</li>\n</ul>\n"},{"title":"关于学习业务的思考","date":"2019-06-05T06:02:45.000Z","comments":1,"_content":"\n## 事情经过\n昨天申请休年假了，之前做好的一个需求，已经交给测试人员了。BA下午通知我要去和五楼的客户过一个需求，这个客户要求看一下我们的代码。我心想：这客户厉害了啊，都会看代码了。之后了解到这个人是从我们公司去到甲方的。\n\n带着电脑来到五楼，见到了她，一个四十多岁的大妈，穿的很接地气，和我们三楼的甲方小姐姐天壤之别，虽然我们三楼的甲方小姐姐都很难解释通需求问题。\n\n她让我找出来我写的代码，然后让我给他解释代码逻辑。我就开始讲啊：“这里是一个开关，存在数据库，有缓存，1为开，0为关，然后判断……”。我像之前给三楼小姐姐讲代码一样去讲。突然她让我等一下，然后抢过去我的电脑去看，说：“你这个方式是去调接口吧”，我说对，然后她继续说：“把你调这个方法的地方全都找出来”。我find useage一下。“你这不对啊，咱们要修改的地方有五个，你这方法调用怎么只有当前这个类啊”。我开始懵逼，转头看ba，ba小姐姐也是一脸懵。我翻出来需求文档，说我就是按需求文档来的。大妈开始对ba说了一大堆，关于业务的，我全程懵逼。后来我离了一下，客户要求的是修改不良信息相关的五个地方，包括加解黑、不良信息处理、一级客服不良信息、开关机和一个后台task。但是需求文档上写的是修改不良信息处理，我就以为是只修改不良信息处理一个地方。然后客户要求我找到这五个地方的代码给他看一下。我找不出。。。\n\n最后ba打圆场，我们先撤了。\n\n## 总结\n对于客服系统，我并不感冒，一直页没有认真对待，因为中国移动的业务太复杂了，我不想浪费事件在业务上面，我心里一直只有技术。\n\n所以看到ba写的需求文档，我想也不想，就按这文档去做，不会去考虑业务。\n\n通过这件事，我知道我错了，我要重新理清技术和业务的关系了。\n\n知乎上有人说：只会写代码的人叫码农，技术过硬又精通业务才能称得上工程师。之前我一直认为，确认需求是ba的事儿，跟我没有关系，我只需要写代码。如果你只会写代码，你不是不可替代的，你是可有可无的，因为这个世界上不缺会写代码的人，毕竟程序员一抓一大把。多了解业务会让我们的思想高一个层次，不是只停留在能用就行的层面，而是让我们找到更好的解决方案，作出更完美的产品。积累业务能力，也能让我们更加了解行业，对职业发展有助力。","source":"_posts/2019-06-05-kongzheng1993-关于学习业务的思考.md","raw":"---\ntitle: 关于学习业务的思考\ndate: 2019-06-05 14:02:45\ntags: [职业,业务,学习]\ncomments: true\n---\n\n## 事情经过\n昨天申请休年假了，之前做好的一个需求，已经交给测试人员了。BA下午通知我要去和五楼的客户过一个需求，这个客户要求看一下我们的代码。我心想：这客户厉害了啊，都会看代码了。之后了解到这个人是从我们公司去到甲方的。\n\n带着电脑来到五楼，见到了她，一个四十多岁的大妈，穿的很接地气，和我们三楼的甲方小姐姐天壤之别，虽然我们三楼的甲方小姐姐都很难解释通需求问题。\n\n她让我找出来我写的代码，然后让我给他解释代码逻辑。我就开始讲啊：“这里是一个开关，存在数据库，有缓存，1为开，0为关，然后判断……”。我像之前给三楼小姐姐讲代码一样去讲。突然她让我等一下，然后抢过去我的电脑去看，说：“你这个方式是去调接口吧”，我说对，然后她继续说：“把你调这个方法的地方全都找出来”。我find useage一下。“你这不对啊，咱们要修改的地方有五个，你这方法调用怎么只有当前这个类啊”。我开始懵逼，转头看ba，ba小姐姐也是一脸懵。我翻出来需求文档，说我就是按需求文档来的。大妈开始对ba说了一大堆，关于业务的，我全程懵逼。后来我离了一下，客户要求的是修改不良信息相关的五个地方，包括加解黑、不良信息处理、一级客服不良信息、开关机和一个后台task。但是需求文档上写的是修改不良信息处理，我就以为是只修改不良信息处理一个地方。然后客户要求我找到这五个地方的代码给他看一下。我找不出。。。\n\n最后ba打圆场，我们先撤了。\n\n## 总结\n对于客服系统，我并不感冒，一直页没有认真对待，因为中国移动的业务太复杂了，我不想浪费事件在业务上面，我心里一直只有技术。\n\n所以看到ba写的需求文档，我想也不想，就按这文档去做，不会去考虑业务。\n\n通过这件事，我知道我错了，我要重新理清技术和业务的关系了。\n\n知乎上有人说：只会写代码的人叫码农，技术过硬又精通业务才能称得上工程师。之前我一直认为，确认需求是ba的事儿，跟我没有关系，我只需要写代码。如果你只会写代码，你不是不可替代的，你是可有可无的，因为这个世界上不缺会写代码的人，毕竟程序员一抓一大把。多了解业务会让我们的思想高一个层次，不是只停留在能用就行的层面，而是让我们找到更好的解决方案，作出更完美的产品。积累业务能力，也能让我们更加了解行业，对职业发展有助力。","slug":"kongzheng1993-关于学习业务的思考","published":1,"updated":"2023-03-08T07:05:58.775Z","layout":"post","photos":[],"link":"","_id":"clg0k2acj001nt26fckvz3bpf","content":"<h2 id=\"事情经过\"><a href=\"#事情经过\" class=\"headerlink\" title=\"事情经过\"></a>事情经过</h2><p>昨天申请休年假了，之前做好的一个需求，已经交给测试人员了。BA下午通知我要去和五楼的客户过一个需求，这个客户要求看一下我们的代码。我心想：这客户厉害了啊，都会看代码了。之后了解到这个人是从我们公司去到甲方的。</p>\n<p>带着电脑来到五楼，见到了她，一个四十多岁的大妈，穿的很接地气，和我们三楼的甲方小姐姐天壤之别，虽然我们三楼的甲方小姐姐都很难解释通需求问题。</p>\n<p>她让我找出来我写的代码，然后让我给他解释代码逻辑。我就开始讲啊：“这里是一个开关，存在数据库，有缓存，1为开，0为关，然后判断……”。我像之前给三楼小姐姐讲代码一样去讲。突然她让我等一下，然后抢过去我的电脑去看，说：“你这个方式是去调接口吧”，我说对，然后她继续说：“把你调这个方法的地方全都找出来”。我find useage一下。“你这不对啊，咱们要修改的地方有五个，你这方法调用怎么只有当前这个类啊”。我开始懵逼，转头看ba，ba小姐姐也是一脸懵。我翻出来需求文档，说我就是按需求文档来的。大妈开始对ba说了一大堆，关于业务的，我全程懵逼。后来我离了一下，客户要求的是修改不良信息相关的五个地方，包括加解黑、不良信息处理、一级客服不良信息、开关机和一个后台task。但是需求文档上写的是修改不良信息处理，我就以为是只修改不良信息处理一个地方。然后客户要求我找到这五个地方的代码给他看一下。我找不出。。。</p>\n<p>最后ba打圆场，我们先撤了。</p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>对于客服系统，我并不感冒，一直页没有认真对待，因为中国移动的业务太复杂了，我不想浪费事件在业务上面，我心里一直只有技术。</p>\n<p>所以看到ba写的需求文档，我想也不想，就按这文档去做，不会去考虑业务。</p>\n<p>通过这件事，我知道我错了，我要重新理清技术和业务的关系了。</p>\n<p>知乎上有人说：只会写代码的人叫码农，技术过硬又精通业务才能称得上工程师。之前我一直认为，确认需求是ba的事儿，跟我没有关系，我只需要写代码。如果你只会写代码，你不是不可替代的，你是可有可无的，因为这个世界上不缺会写代码的人，毕竟程序员一抓一大把。多了解业务会让我们的思想高一个层次，不是只停留在能用就行的层面，而是让我们找到更好的解决方案，作出更完美的产品。积累业务能力，也能让我们更加了解行业，对职业发展有助力。</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"事情经过\"><a href=\"#事情经过\" class=\"headerlink\" title=\"事情经过\"></a>事情经过</h2><p>昨天申请休年假了，之前做好的一个需求，已经交给测试人员了。BA下午通知我要去和五楼的客户过一个需求，这个客户要求看一下我们的代码。我心想：这客户厉害了啊，都会看代码了。之后了解到这个人是从我们公司去到甲方的。</p>\n<p>带着电脑来到五楼，见到了她，一个四十多岁的大妈，穿的很接地气，和我们三楼的甲方小姐姐天壤之别，虽然我们三楼的甲方小姐姐都很难解释通需求问题。</p>\n<p>她让我找出来我写的代码，然后让我给他解释代码逻辑。我就开始讲啊：“这里是一个开关，存在数据库，有缓存，1为开，0为关，然后判断……”。我像之前给三楼小姐姐讲代码一样去讲。突然她让我等一下，然后抢过去我的电脑去看，说：“你这个方式是去调接口吧”，我说对，然后她继续说：“把你调这个方法的地方全都找出来”。我find useage一下。“你这不对啊，咱们要修改的地方有五个，你这方法调用怎么只有当前这个类啊”。我开始懵逼，转头看ba，ba小姐姐也是一脸懵。我翻出来需求文档，说我就是按需求文档来的。大妈开始对ba说了一大堆，关于业务的，我全程懵逼。后来我离了一下，客户要求的是修改不良信息相关的五个地方，包括加解黑、不良信息处理、一级客服不良信息、开关机和一个后台task。但是需求文档上写的是修改不良信息处理，我就以为是只修改不良信息处理一个地方。然后客户要求我找到这五个地方的代码给他看一下。我找不出。。。</p>\n<p>最后ba打圆场，我们先撤了。</p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>对于客服系统，我并不感冒，一直页没有认真对待，因为中国移动的业务太复杂了，我不想浪费事件在业务上面，我心里一直只有技术。</p>\n<p>所以看到ba写的需求文档，我想也不想，就按这文档去做，不会去考虑业务。</p>\n<p>通过这件事，我知道我错了，我要重新理清技术和业务的关系了。</p>\n<p>知乎上有人说：只会写代码的人叫码农，技术过硬又精通业务才能称得上工程师。之前我一直认为，确认需求是ba的事儿，跟我没有关系，我只需要写代码。如果你只会写代码，你不是不可替代的，你是可有可无的，因为这个世界上不缺会写代码的人，毕竟程序员一抓一大把。多了解业务会让我们的思想高一个层次，不是只停留在能用就行的层面，而是让我们找到更好的解决方案，作出更完美的产品。积累业务能力，也能让我们更加了解行业，对职业发展有助力。</p>\n"},{"title":"mysql超过最大连接数一次生产问题定位.md","date":"2019-06-14T04:34:44.000Z","excerpt":"","comments":1,"_content":"\n今天营业厅一体机小姐姐又来找我了，生产又有问题了。。。\n\n我查了下日志：\n\n```java\n\nCaused by: com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: User ngcrmpf_bj already has more than 'max_user_connections' active connections\n    at sun.reflect.GeneratedConstructorAccessor266.newInstance(Unknown Source)\n    at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n    at java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n    at com.mysql.jdbc.Util.handleNewInstance(Util.java:404)\n\n```\n\n连接数超了。。。\n\n之前听同事说经常遇见这个问题，每次都是把服务器最大连接数调大一些，然后就好了。。。\n\n我想：就算每次都调大连接数上限，也终会达到最大连接数啊。为什么呢？ 应该是我们定期发布，重启tomcat后会断开所有连接，如果我们长时间不发布，就会到达上限。\n\n然后我开始翻代码，看到配置的最大连接数：\n\n```java\nngcrmpf_bj.jdbc.maxActive=5\n```\n\n只有5条啊，8台tomcat加起来也就是四十条啊，为什么服务器设置1200还会超呢。。。。\n\n仔细看报错信息，发现有一个方法，不知道是哪位大哥写的，竟然自己写了jdbc，而且没有关闭连接。。。mmp。。。\n\n我们的接口参数都会加密传输，密钥存在mysql，他竟然用jdbc去数据库查密钥，而且没关闭连接。。。为什么不去redis？为什么不用mybatis？再不济，为什么不关闭连接。。。\n\n苍天啊，大地啊，我真的不知道怎么和客户解释。。。\n\n唉。。。\n","source":"_posts/2019-06-14-kongzheng1993-mysql超过最大连接数-一次生产问题定位.md","raw":"---\ntitle: mysql超过最大连接数一次生产问题定位.md\ndate: 2019-06-14 12:34:44\nexcerpt: \"mysql\"\ntags: [mysql,java]\ncategories: [mysql,java]\ncomments: true\n---\n\n今天营业厅一体机小姐姐又来找我了，生产又有问题了。。。\n\n我查了下日志：\n\n```java\n\nCaused by: com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: User ngcrmpf_bj already has more than 'max_user_connections' active connections\n    at sun.reflect.GeneratedConstructorAccessor266.newInstance(Unknown Source)\n    at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n    at java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n    at com.mysql.jdbc.Util.handleNewInstance(Util.java:404)\n\n```\n\n连接数超了。。。\n\n之前听同事说经常遇见这个问题，每次都是把服务器最大连接数调大一些，然后就好了。。。\n\n我想：就算每次都调大连接数上限，也终会达到最大连接数啊。为什么呢？ 应该是我们定期发布，重启tomcat后会断开所有连接，如果我们长时间不发布，就会到达上限。\n\n然后我开始翻代码，看到配置的最大连接数：\n\n```java\nngcrmpf_bj.jdbc.maxActive=5\n```\n\n只有5条啊，8台tomcat加起来也就是四十条啊，为什么服务器设置1200还会超呢。。。。\n\n仔细看报错信息，发现有一个方法，不知道是哪位大哥写的，竟然自己写了jdbc，而且没有关闭连接。。。mmp。。。\n\n我们的接口参数都会加密传输，密钥存在mysql，他竟然用jdbc去数据库查密钥，而且没关闭连接。。。为什么不去redis？为什么不用mybatis？再不济，为什么不关闭连接。。。\n\n苍天啊，大地啊，我真的不知道怎么和客户解释。。。\n\n唉。。。\n","slug":"kongzheng1993-mysql超过最大连接数-一次生产问题定位","published":1,"updated":"2023-03-08T07:05:58.775Z","layout":"post","photos":[],"link":"","_id":"clg0k2acl001qt26fpykbpbv0","content":"<p>今天营业厅一体机小姐姐又来找我了，生产又有问题了。。。</p>\n<p>我查了下日志：</p>\n<pre><code class=\"java\">\nCaused by: com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: User ngcrmpf_bj already has more than &#39;max_user_connections&#39; active connections\n    at sun.reflect.GeneratedConstructorAccessor266.newInstance(Unknown Source)\n    at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n    at java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n    at com.mysql.jdbc.Util.handleNewInstance(Util.java:404)\n</code></pre>\n<p>连接数超了。。。</p>\n<p>之前听同事说经常遇见这个问题，每次都是把服务器最大连接数调大一些，然后就好了。。。</p>\n<p>我想：就算每次都调大连接数上限，也终会达到最大连接数啊。为什么呢？ 应该是我们定期发布，重启tomcat后会断开所有连接，如果我们长时间不发布，就会到达上限。</p>\n<p>然后我开始翻代码，看到配置的最大连接数：</p>\n<pre><code class=\"java\">ngcrmpf_bj.jdbc.maxActive=5</code></pre>\n<p>只有5条啊，8台tomcat加起来也就是四十条啊，为什么服务器设置1200还会超呢。。。。</p>\n<p>仔细看报错信息，发现有一个方法，不知道是哪位大哥写的，竟然自己写了jdbc，而且没有关闭连接。。。mmp。。。</p>\n<p>我们的接口参数都会加密传输，密钥存在mysql，他竟然用jdbc去数据库查密钥，而且没关闭连接。。。为什么不去redis？为什么不用mybatis？再不济，为什么不关闭连接。。。</p>\n<p>苍天啊，大地啊，我真的不知道怎么和客户解释。。。</p>\n<p>唉。。。</p>\n","site":{"data":{}},"more":"<p>今天营业厅一体机小姐姐又来找我了，生产又有问题了。。。</p>\n<p>我查了下日志：</p>\n<pre><code class=\"java\">\nCaused by: com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: User ngcrmpf_bj already has more than &#39;max_user_connections&#39; active connections\n    at sun.reflect.GeneratedConstructorAccessor266.newInstance(Unknown Source)\n    at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n    at java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n    at com.mysql.jdbc.Util.handleNewInstance(Util.java:404)\n</code></pre>\n<p>连接数超了。。。</p>\n<p>之前听同事说经常遇见这个问题，每次都是把服务器最大连接数调大一些，然后就好了。。。</p>\n<p>我想：就算每次都调大连接数上限，也终会达到最大连接数啊。为什么呢？ 应该是我们定期发布，重启tomcat后会断开所有连接，如果我们长时间不发布，就会到达上限。</p>\n<p>然后我开始翻代码，看到配置的最大连接数：</p>\n<pre><code class=\"java\">ngcrmpf_bj.jdbc.maxActive=5</code></pre>\n<p>只有5条啊，8台tomcat加起来也就是四十条啊，为什么服务器设置1200还会超呢。。。。</p>\n<p>仔细看报错信息，发现有一个方法，不知道是哪位大哥写的，竟然自己写了jdbc，而且没有关闭连接。。。mmp。。。</p>\n<p>我们的接口参数都会加密传输，密钥存在mysql，他竟然用jdbc去数据库查密钥，而且没关闭连接。。。为什么不去redis？为什么不用mybatis？再不济，为什么不关闭连接。。。</p>\n<p>苍天啊，大地啊，我真的不知道怎么和客户解释。。。</p>\n<p>唉。。。</p>\n"},{"title":"NIO&BIO","excerpt":"","comments":1,"date":"2019-09-11T10:30:52.000Z","_content":"\n## BIO\n\n同步非阻塞， blocking I/O，服务器实现模式为一个连接一个线程，即客户端有连接请求时服务器就需要启动一个线程进行处理，如果这个连接不做任何事情就会造成不必要的线程开销。这种情况可以通过线程池机制改善。tomcat bio就是通过线程池实现的，默认200并发。\n\n```java\n\n\n```\n","source":"_posts/2019-09-11-kongzheng1993-NIO&BIO.md","raw":"---\ntitle: NIO&BIO\nexcerpt: 'NIO BIO'\ntags: [NIO BIO IO]\ncategories: [NIO BIO IO]\ncomments: true\ndate: 2019-09-11 18:30:52\n---\n\n## BIO\n\n同步非阻塞， blocking I/O，服务器实现模式为一个连接一个线程，即客户端有连接请求时服务器就需要启动一个线程进行处理，如果这个连接不做任何事情就会造成不必要的线程开销。这种情况可以通过线程池机制改善。tomcat bio就是通过线程池实现的，默认200并发。\n\n```java\n\n\n```\n","slug":"kongzheng1993-NIO&BIO","published":1,"updated":"2023-03-08T07:05:58.776Z","layout":"post","photos":[],"link":"","_id":"clg0k2acm001st26fti0sj2ba","content":"<h2 id=\"BIO\"><a href=\"#BIO\" class=\"headerlink\" title=\"BIO\"></a>BIO</h2><p>同步非阻塞， blocking I/O，服务器实现模式为一个连接一个线程，即客户端有连接请求时服务器就需要启动一个线程进行处理，如果这个连接不做任何事情就会造成不必要的线程开销。这种情况可以通过线程池机制改善。tomcat bio就是通过线程池实现的，默认200并发。</p>\n<pre><code class=\"java\">\n</code></pre>\n","site":{"data":{}},"more":"<h2 id=\"BIO\"><a href=\"#BIO\" class=\"headerlink\" title=\"BIO\"></a>BIO</h2><p>同步非阻塞， blocking I/O，服务器实现模式为一个连接一个线程，即客户端有连接请求时服务器就需要启动一个线程进行处理，如果这个连接不做任何事情就会造成不必要的线程开销。这种情况可以通过线程池机制改善。tomcat bio就是通过线程池实现的，默认200并发。</p>\n<pre><code class=\"java\">\n</code></pre>\n"},{"title":"Guava","excerpt":"","comments":1,"date":"2020-03-05T16:30:52.000Z","_content":"\n# Guava（一）\n## Guava是什么\nGuava项目包含一些我们在基于Java的项目中依赖的Google核心库：集合，缓存，原语支持，并发库，通用批注，字符串处理，I/O等。这些工具中的每一种确实每天都会被Google员工用于生产服务中。\n\n更详细的介绍可以去[github/guava](https://github.com/google/guava/wiki)的Wiki了解。\n\n## 引入Guava\n```xml\n<dependency>\n    <groupId>com.google.guava</groupId>\n    <artifactId>guava</artifactId>\n    <version>19.0</version>\n</dependency>\n```\n\n## Guava工具类\n### 集合\n普通的集合：\n```java\nList<String> list = Lists.newArrayList();\nSet<String> set = Sets.newHashSet();\nMap<String, String> map = Maps.newHashMap();\n```\n不可变集合：\n```java\nImmutableList<String> iList = ImmutableList.of(\"a\", \"b\", \"c\");\nImmutableSet<String> iSet = ImmutableSet.of(\"e1\", \"e2\");\nImmutableMap<String, String> iMap = ImmutableMap.of(\"k1\", \"v1\", \"k2\", \"v2\");\n```\n    什么是不可变？\n    - 在多线程操作下，是线程安全的。\n    - 所有不可变集合会比可变集合更有效的利用资源。\n    - 中途不可改变\n\n#### 一个简单的对比\n我们搞一个Map中嵌套List的对象要几步？\n```java\nMap<String,List<Integer>> map = new HashMap<String,List<Integer>>();\nList<Integer> list = new ArrayList<Integer>();\nlist.add(1);\nlist.add(2);\nmap.put(\"test\", list);\n```\n如果用了Guava呢？\n```java\nMultimap<String,Integer> mapM = ArrayListMultimap.create();\nmapM.put(\"test\",1);\nmapM.put(\"test\",2);\n```\n哪个方便？\n    \n    代码量少了并不是简简单单的节省时间而已，而是减少了人为错误的机会，少一行代码就少一点犯错误的可能！\n\n### 字符串连接\n连接多个字符串，追加到StringBuilder\n```java\nStringBuilder stringBuilder = new StringBuilder(\"你好！，\");\n// 字符串连接器，以|为分隔符，同时去掉null元素\nJoiner joiner1 = Joiner.on(\"|\").skipNulls();\n// 构成一个字符串jim|jack|kevin并添加到stringBuilder\nstringBuilder = joiner1.appendTo(stringBuilder, \"jim\", \"jack\", null, \"kevin\");\nSystem.out.println(stringBuilder); \n// 执行结果：嗨，jim|jack|kevin\n```\n可以看到这里过滤了null\n\n### Map&字符串互转\n```java\nMap<String, String> testMap = Maps.newLinkedHashMap();\ntestMap.put(\"Cookies\", \"12332\");\ntestMap.put(\"Content-Length\", \"30000\");\ntestMap.put(\"Date\", \"2018.07.04\");\ntestMap.put(\"Mime\", \"text/html\");\n// 用:分割键值对，并用#分割每个元素，返回字符串\nString returnedString = Joiner.on(\"#\").withKeyValueSeparator(\":\").joi(testMap);\nSystem.out.println(returnedString);\n// 执行结果：Cookies:12332#Content-Length:30000#Date:2018.07.04#Mime:text/html\n```\n\n```java\n// 接上一个，内部类的引用，得到分割器，将字符串解析为map\nSplitter.MapSplitter ms = Splitter.on(\"#\").withKeyValueSeparator(':');\nMap<String, String> ret = ms.split(returnedString);\nfor (String it2 : ret.keySet()) {\n    System.out.println(it2 + \" -> \" + ret.get(it2));\n}\n```\n\n### 字符串工具类\n```java\nSystem.out.println(Strings.isNullOrEmpty(\"\")); // true\nSystem.out.println(Strings.isNullOrEmpty(null)); // true\nSystem.out.println(Strings.isNullOrEmpty(\"hello\")); // false\n// 将null转化为\"\"\n System.out.println(Strings.nullToEmpty(null)); // \"\" \n// 从尾部不断补充T只到总共8个字符，如果源字符串已经达到或操作，则原样返回。类似的有padStart\nSystem.out.println(Strings.padEnd(\"hello\", 8, 'T')); // helloTTT\n```\n\n### 字符匹配器CharMatcher\n```java\n// 空白回车换行对应换成一个#，一对一换\nString stringWithLinebreaks = \"hello world\\r\\r\\ryou are here\\n\\ntake it\\t\\t\\teasy\";\nString s6 = CharMatcher.BREAKING_WHITESPACE.replaceFrom(stringWithLinebreaks,'#');\nSystem.out.println(s6); \n//执行结果：hello#world###you#are#here##take#it###easy\n```\n\n### 连续空白替换成一个字符\n```java\n// 将所有连在一起的空白回车换行字符换成一个#，倒塌\nString tabString = \"  hello   \\n\\t\\tworld   you\\r\\nare             here  \";\nString tabRet = CharMatcher.WHITESPACE.collapseFrom(tabString, '#');\nSystem.out.println(tabRet); \n```\n\n### 去掉前后空白和缩成一个字符\n```java\n// 在前面的基础上去掉字符串的前后空白，并将空白换成一个#\nString trimRet = CharMatcher.WHITESPACE.trimAndCollapseFrom(tabString, '#');\nSystem.out.println(trimRet);\n//执行结果： hello#world#you#are#here\n```\n\n### 只保留数字\n```java\nString letterAndNumber = \"1234abcdABCD56789\";\n// 保留数字\nString number = CharMatcher.JAVA_DIGIT.retainFrom(letterAndNumber);\nSystem.out.println(number);//123456789\n```\n\n## 总结\n使用Guava可以极大减少我们的代码量，减少犯错机会，提高工作效率。这次我们先介绍这些，下一篇我们深入Guava Caching！","source":"_posts/2020-03-06-kongzheng1993-Guava.md","raw":"---\ntitle: Guava\nexcerpt: ''\ntags: [Guava]\ncategories: [Java]\ncomments: true\ndate: 2020-03-06 00:30:52\n---\n\n# Guava（一）\n## Guava是什么\nGuava项目包含一些我们在基于Java的项目中依赖的Google核心库：集合，缓存，原语支持，并发库，通用批注，字符串处理，I/O等。这些工具中的每一种确实每天都会被Google员工用于生产服务中。\n\n更详细的介绍可以去[github/guava](https://github.com/google/guava/wiki)的Wiki了解。\n\n## 引入Guava\n```xml\n<dependency>\n    <groupId>com.google.guava</groupId>\n    <artifactId>guava</artifactId>\n    <version>19.0</version>\n</dependency>\n```\n\n## Guava工具类\n### 集合\n普通的集合：\n```java\nList<String> list = Lists.newArrayList();\nSet<String> set = Sets.newHashSet();\nMap<String, String> map = Maps.newHashMap();\n```\n不可变集合：\n```java\nImmutableList<String> iList = ImmutableList.of(\"a\", \"b\", \"c\");\nImmutableSet<String> iSet = ImmutableSet.of(\"e1\", \"e2\");\nImmutableMap<String, String> iMap = ImmutableMap.of(\"k1\", \"v1\", \"k2\", \"v2\");\n```\n    什么是不可变？\n    - 在多线程操作下，是线程安全的。\n    - 所有不可变集合会比可变集合更有效的利用资源。\n    - 中途不可改变\n\n#### 一个简单的对比\n我们搞一个Map中嵌套List的对象要几步？\n```java\nMap<String,List<Integer>> map = new HashMap<String,List<Integer>>();\nList<Integer> list = new ArrayList<Integer>();\nlist.add(1);\nlist.add(2);\nmap.put(\"test\", list);\n```\n如果用了Guava呢？\n```java\nMultimap<String,Integer> mapM = ArrayListMultimap.create();\nmapM.put(\"test\",1);\nmapM.put(\"test\",2);\n```\n哪个方便？\n    \n    代码量少了并不是简简单单的节省时间而已，而是减少了人为错误的机会，少一行代码就少一点犯错误的可能！\n\n### 字符串连接\n连接多个字符串，追加到StringBuilder\n```java\nStringBuilder stringBuilder = new StringBuilder(\"你好！，\");\n// 字符串连接器，以|为分隔符，同时去掉null元素\nJoiner joiner1 = Joiner.on(\"|\").skipNulls();\n// 构成一个字符串jim|jack|kevin并添加到stringBuilder\nstringBuilder = joiner1.appendTo(stringBuilder, \"jim\", \"jack\", null, \"kevin\");\nSystem.out.println(stringBuilder); \n// 执行结果：嗨，jim|jack|kevin\n```\n可以看到这里过滤了null\n\n### Map&字符串互转\n```java\nMap<String, String> testMap = Maps.newLinkedHashMap();\ntestMap.put(\"Cookies\", \"12332\");\ntestMap.put(\"Content-Length\", \"30000\");\ntestMap.put(\"Date\", \"2018.07.04\");\ntestMap.put(\"Mime\", \"text/html\");\n// 用:分割键值对，并用#分割每个元素，返回字符串\nString returnedString = Joiner.on(\"#\").withKeyValueSeparator(\":\").joi(testMap);\nSystem.out.println(returnedString);\n// 执行结果：Cookies:12332#Content-Length:30000#Date:2018.07.04#Mime:text/html\n```\n\n```java\n// 接上一个，内部类的引用，得到分割器，将字符串解析为map\nSplitter.MapSplitter ms = Splitter.on(\"#\").withKeyValueSeparator(':');\nMap<String, String> ret = ms.split(returnedString);\nfor (String it2 : ret.keySet()) {\n    System.out.println(it2 + \" -> \" + ret.get(it2));\n}\n```\n\n### 字符串工具类\n```java\nSystem.out.println(Strings.isNullOrEmpty(\"\")); // true\nSystem.out.println(Strings.isNullOrEmpty(null)); // true\nSystem.out.println(Strings.isNullOrEmpty(\"hello\")); // false\n// 将null转化为\"\"\n System.out.println(Strings.nullToEmpty(null)); // \"\" \n// 从尾部不断补充T只到总共8个字符，如果源字符串已经达到或操作，则原样返回。类似的有padStart\nSystem.out.println(Strings.padEnd(\"hello\", 8, 'T')); // helloTTT\n```\n\n### 字符匹配器CharMatcher\n```java\n// 空白回车换行对应换成一个#，一对一换\nString stringWithLinebreaks = \"hello world\\r\\r\\ryou are here\\n\\ntake it\\t\\t\\teasy\";\nString s6 = CharMatcher.BREAKING_WHITESPACE.replaceFrom(stringWithLinebreaks,'#');\nSystem.out.println(s6); \n//执行结果：hello#world###you#are#here##take#it###easy\n```\n\n### 连续空白替换成一个字符\n```java\n// 将所有连在一起的空白回车换行字符换成一个#，倒塌\nString tabString = \"  hello   \\n\\t\\tworld   you\\r\\nare             here  \";\nString tabRet = CharMatcher.WHITESPACE.collapseFrom(tabString, '#');\nSystem.out.println(tabRet); \n```\n\n### 去掉前后空白和缩成一个字符\n```java\n// 在前面的基础上去掉字符串的前后空白，并将空白换成一个#\nString trimRet = CharMatcher.WHITESPACE.trimAndCollapseFrom(tabString, '#');\nSystem.out.println(trimRet);\n//执行结果： hello#world#you#are#here\n```\n\n### 只保留数字\n```java\nString letterAndNumber = \"1234abcdABCD56789\";\n// 保留数字\nString number = CharMatcher.JAVA_DIGIT.retainFrom(letterAndNumber);\nSystem.out.println(number);//123456789\n```\n\n## 总结\n使用Guava可以极大减少我们的代码量，减少犯错机会，提高工作效率。这次我们先介绍这些，下一篇我们深入Guava Caching！","slug":"kongzheng1993-Guava","published":1,"updated":"2023-03-08T07:05:58.776Z","layout":"post","photos":[],"link":"","_id":"clg0k2ad4001vt26f2e5xqk3d","content":"<h1 id=\"Guava（一）\"><a href=\"#Guava（一）\" class=\"headerlink\" title=\"Guava（一）\"></a>Guava（一）</h1><h2 id=\"Guava是什么\"><a href=\"#Guava是什么\" class=\"headerlink\" title=\"Guava是什么\"></a>Guava是什么</h2><p>Guava项目包含一些我们在基于Java的项目中依赖的Google核心库：集合，缓存，原语支持，并发库，通用批注，字符串处理，I/O等。这些工具中的每一种确实每天都会被Google员工用于生产服务中。</p>\n<p>更详细的介绍可以去<a href=\"https://github.com/google/guava/wiki\" target=\"_blank\" rel=\"noopener\">github/guava</a>的Wiki了解。</p>\n<h2 id=\"引入Guava\"><a href=\"#引入Guava\" class=\"headerlink\" title=\"引入Guava\"></a>引入Guava</h2><pre><code class=\"xml\">&lt;dependency&gt;\n    &lt;groupId&gt;com.google.guava&lt;/groupId&gt;\n    &lt;artifactId&gt;guava&lt;/artifactId&gt;\n    &lt;version&gt;19.0&lt;/version&gt;\n&lt;/dependency&gt;</code></pre>\n<h2 id=\"Guava工具类\"><a href=\"#Guava工具类\" class=\"headerlink\" title=\"Guava工具类\"></a>Guava工具类</h2><h3 id=\"集合\"><a href=\"#集合\" class=\"headerlink\" title=\"集合\"></a>集合</h3><p>普通的集合：</p>\n<pre><code class=\"java\">List&lt;String&gt; list = Lists.newArrayList();\nSet&lt;String&gt; set = Sets.newHashSet();\nMap&lt;String, String&gt; map = Maps.newHashMap();</code></pre>\n<p>不可变集合：</p>\n<pre><code class=\"java\">ImmutableList&lt;String&gt; iList = ImmutableList.of(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;);\nImmutableSet&lt;String&gt; iSet = ImmutableSet.of(&quot;e1&quot;, &quot;e2&quot;);\nImmutableMap&lt;String, String&gt; iMap = ImmutableMap.of(&quot;k1&quot;, &quot;v1&quot;, &quot;k2&quot;, &quot;v2&quot;);</code></pre>\n<pre><code>什么是不可变？\n- 在多线程操作下，是线程安全的。\n- 所有不可变集合会比可变集合更有效的利用资源。\n- 中途不可改变</code></pre><h4 id=\"一个简单的对比\"><a href=\"#一个简单的对比\" class=\"headerlink\" title=\"一个简单的对比\"></a>一个简单的对比</h4><p>我们搞一个Map中嵌套List的对象要几步？</p>\n<pre><code class=\"java\">Map&lt;String,List&lt;Integer&gt;&gt; map = new HashMap&lt;String,List&lt;Integer&gt;&gt;();\nList&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;();\nlist.add(1);\nlist.add(2);\nmap.put(&quot;test&quot;, list);</code></pre>\n<p>如果用了Guava呢？</p>\n<pre><code class=\"java\">Multimap&lt;String,Integer&gt; mapM = ArrayListMultimap.create();\nmapM.put(&quot;test&quot;,1);\nmapM.put(&quot;test&quot;,2);</code></pre>\n<p>哪个方便？</p>\n<pre><code>代码量少了并不是简简单单的节省时间而已，而是减少了人为错误的机会，少一行代码就少一点犯错误的可能！</code></pre><h3 id=\"字符串连接\"><a href=\"#字符串连接\" class=\"headerlink\" title=\"字符串连接\"></a>字符串连接</h3><p>连接多个字符串，追加到StringBuilder</p>\n<pre><code class=\"java\">StringBuilder stringBuilder = new StringBuilder(&quot;你好！，&quot;);\n// 字符串连接器，以|为分隔符，同时去掉null元素\nJoiner joiner1 = Joiner.on(&quot;|&quot;).skipNulls();\n// 构成一个字符串jim|jack|kevin并添加到stringBuilder\nstringBuilder = joiner1.appendTo(stringBuilder, &quot;jim&quot;, &quot;jack&quot;, null, &quot;kevin&quot;);\nSystem.out.println(stringBuilder); \n// 执行结果：嗨，jim|jack|kevin</code></pre>\n<p>可以看到这里过滤了null</p>\n<h3 id=\"Map-amp-字符串互转\"><a href=\"#Map-amp-字符串互转\" class=\"headerlink\" title=\"Map&amp;字符串互转\"></a>Map&amp;字符串互转</h3><pre><code class=\"java\">Map&lt;String, String&gt; testMap = Maps.newLinkedHashMap();\ntestMap.put(&quot;Cookies&quot;, &quot;12332&quot;);\ntestMap.put(&quot;Content-Length&quot;, &quot;30000&quot;);\ntestMap.put(&quot;Date&quot;, &quot;2018.07.04&quot;);\ntestMap.put(&quot;Mime&quot;, &quot;text/html&quot;);\n// 用:分割键值对，并用#分割每个元素，返回字符串\nString returnedString = Joiner.on(&quot;#&quot;).withKeyValueSeparator(&quot;:&quot;).joi(testMap);\nSystem.out.println(returnedString);\n// 执行结果：Cookies:12332#Content-Length:30000#Date:2018.07.04#Mime:text/html</code></pre>\n<pre><code class=\"java\">// 接上一个，内部类的引用，得到分割器，将字符串解析为map\nSplitter.MapSplitter ms = Splitter.on(&quot;#&quot;).withKeyValueSeparator(&#39;:&#39;);\nMap&lt;String, String&gt; ret = ms.split(returnedString);\nfor (String it2 : ret.keySet()) {\n    System.out.println(it2 + &quot; -&gt; &quot; + ret.get(it2));\n}</code></pre>\n<h3 id=\"字符串工具类\"><a href=\"#字符串工具类\" class=\"headerlink\" title=\"字符串工具类\"></a>字符串工具类</h3><pre><code class=\"java\">System.out.println(Strings.isNullOrEmpty(&quot;&quot;)); // true\nSystem.out.println(Strings.isNullOrEmpty(null)); // true\nSystem.out.println(Strings.isNullOrEmpty(&quot;hello&quot;)); // false\n// 将null转化为&quot;&quot;\n System.out.println(Strings.nullToEmpty(null)); // &quot;&quot; \n// 从尾部不断补充T只到总共8个字符，如果源字符串已经达到或操作，则原样返回。类似的有padStart\nSystem.out.println(Strings.padEnd(&quot;hello&quot;, 8, &#39;T&#39;)); // helloTTT</code></pre>\n<h3 id=\"字符匹配器CharMatcher\"><a href=\"#字符匹配器CharMatcher\" class=\"headerlink\" title=\"字符匹配器CharMatcher\"></a>字符匹配器CharMatcher</h3><pre><code class=\"java\">// 空白回车换行对应换成一个#，一对一换\nString stringWithLinebreaks = &quot;hello world\\r\\r\\ryou are here\\n\\ntake it\\t\\t\\teasy&quot;;\nString s6 = CharMatcher.BREAKING_WHITESPACE.replaceFrom(stringWithLinebreaks,&#39;#&#39;);\nSystem.out.println(s6); \n//执行结果：hello#world###you#are#here##take#it###easy</code></pre>\n<h3 id=\"连续空白替换成一个字符\"><a href=\"#连续空白替换成一个字符\" class=\"headerlink\" title=\"连续空白替换成一个字符\"></a>连续空白替换成一个字符</h3><pre><code class=\"java\">// 将所有连在一起的空白回车换行字符换成一个#，倒塌\nString tabString = &quot;  hello   \\n\\t\\tworld   you\\r\\nare             here  &quot;;\nString tabRet = CharMatcher.WHITESPACE.collapseFrom(tabString, &#39;#&#39;);\nSystem.out.println(tabRet); </code></pre>\n<h3 id=\"去掉前后空白和缩成一个字符\"><a href=\"#去掉前后空白和缩成一个字符\" class=\"headerlink\" title=\"去掉前后空白和缩成一个字符\"></a>去掉前后空白和缩成一个字符</h3><pre><code class=\"java\">// 在前面的基础上去掉字符串的前后空白，并将空白换成一个#\nString trimRet = CharMatcher.WHITESPACE.trimAndCollapseFrom(tabString, &#39;#&#39;);\nSystem.out.println(trimRet);\n//执行结果： hello#world#you#are#here</code></pre>\n<h3 id=\"只保留数字\"><a href=\"#只保留数字\" class=\"headerlink\" title=\"只保留数字\"></a>只保留数字</h3><pre><code class=\"java\">String letterAndNumber = &quot;1234abcdABCD56789&quot;;\n// 保留数字\nString number = CharMatcher.JAVA_DIGIT.retainFrom(letterAndNumber);\nSystem.out.println(number);//123456789</code></pre>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>使用Guava可以极大减少我们的代码量，减少犯错机会，提高工作效率。这次我们先介绍这些，下一篇我们深入Guava Caching！</p>\n","site":{"data":{}},"more":"<h1 id=\"Guava（一）\"><a href=\"#Guava（一）\" class=\"headerlink\" title=\"Guava（一）\"></a>Guava（一）</h1><h2 id=\"Guava是什么\"><a href=\"#Guava是什么\" class=\"headerlink\" title=\"Guava是什么\"></a>Guava是什么</h2><p>Guava项目包含一些我们在基于Java的项目中依赖的Google核心库：集合，缓存，原语支持，并发库，通用批注，字符串处理，I/O等。这些工具中的每一种确实每天都会被Google员工用于生产服务中。</p>\n<p>更详细的介绍可以去<a href=\"https://github.com/google/guava/wiki\" target=\"_blank\" rel=\"noopener\">github/guava</a>的Wiki了解。</p>\n<h2 id=\"引入Guava\"><a href=\"#引入Guava\" class=\"headerlink\" title=\"引入Guava\"></a>引入Guava</h2><pre><code class=\"xml\">&lt;dependency&gt;\n    &lt;groupId&gt;com.google.guava&lt;/groupId&gt;\n    &lt;artifactId&gt;guava&lt;/artifactId&gt;\n    &lt;version&gt;19.0&lt;/version&gt;\n&lt;/dependency&gt;</code></pre>\n<h2 id=\"Guava工具类\"><a href=\"#Guava工具类\" class=\"headerlink\" title=\"Guava工具类\"></a>Guava工具类</h2><h3 id=\"集合\"><a href=\"#集合\" class=\"headerlink\" title=\"集合\"></a>集合</h3><p>普通的集合：</p>\n<pre><code class=\"java\">List&lt;String&gt; list = Lists.newArrayList();\nSet&lt;String&gt; set = Sets.newHashSet();\nMap&lt;String, String&gt; map = Maps.newHashMap();</code></pre>\n<p>不可变集合：</p>\n<pre><code class=\"java\">ImmutableList&lt;String&gt; iList = ImmutableList.of(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;);\nImmutableSet&lt;String&gt; iSet = ImmutableSet.of(&quot;e1&quot;, &quot;e2&quot;);\nImmutableMap&lt;String, String&gt; iMap = ImmutableMap.of(&quot;k1&quot;, &quot;v1&quot;, &quot;k2&quot;, &quot;v2&quot;);</code></pre>\n<pre><code>什么是不可变？\n- 在多线程操作下，是线程安全的。\n- 所有不可变集合会比可变集合更有效的利用资源。\n- 中途不可改变</code></pre><h4 id=\"一个简单的对比\"><a href=\"#一个简单的对比\" class=\"headerlink\" title=\"一个简单的对比\"></a>一个简单的对比</h4><p>我们搞一个Map中嵌套List的对象要几步？</p>\n<pre><code class=\"java\">Map&lt;String,List&lt;Integer&gt;&gt; map = new HashMap&lt;String,List&lt;Integer&gt;&gt;();\nList&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;();\nlist.add(1);\nlist.add(2);\nmap.put(&quot;test&quot;, list);</code></pre>\n<p>如果用了Guava呢？</p>\n<pre><code class=\"java\">Multimap&lt;String,Integer&gt; mapM = ArrayListMultimap.create();\nmapM.put(&quot;test&quot;,1);\nmapM.put(&quot;test&quot;,2);</code></pre>\n<p>哪个方便？</p>\n<pre><code>代码量少了并不是简简单单的节省时间而已，而是减少了人为错误的机会，少一行代码就少一点犯错误的可能！</code></pre><h3 id=\"字符串连接\"><a href=\"#字符串连接\" class=\"headerlink\" title=\"字符串连接\"></a>字符串连接</h3><p>连接多个字符串，追加到StringBuilder</p>\n<pre><code class=\"java\">StringBuilder stringBuilder = new StringBuilder(&quot;你好！，&quot;);\n// 字符串连接器，以|为分隔符，同时去掉null元素\nJoiner joiner1 = Joiner.on(&quot;|&quot;).skipNulls();\n// 构成一个字符串jim|jack|kevin并添加到stringBuilder\nstringBuilder = joiner1.appendTo(stringBuilder, &quot;jim&quot;, &quot;jack&quot;, null, &quot;kevin&quot;);\nSystem.out.println(stringBuilder); \n// 执行结果：嗨，jim|jack|kevin</code></pre>\n<p>可以看到这里过滤了null</p>\n<h3 id=\"Map-amp-字符串互转\"><a href=\"#Map-amp-字符串互转\" class=\"headerlink\" title=\"Map&amp;字符串互转\"></a>Map&amp;字符串互转</h3><pre><code class=\"java\">Map&lt;String, String&gt; testMap = Maps.newLinkedHashMap();\ntestMap.put(&quot;Cookies&quot;, &quot;12332&quot;);\ntestMap.put(&quot;Content-Length&quot;, &quot;30000&quot;);\ntestMap.put(&quot;Date&quot;, &quot;2018.07.04&quot;);\ntestMap.put(&quot;Mime&quot;, &quot;text/html&quot;);\n// 用:分割键值对，并用#分割每个元素，返回字符串\nString returnedString = Joiner.on(&quot;#&quot;).withKeyValueSeparator(&quot;:&quot;).joi(testMap);\nSystem.out.println(returnedString);\n// 执行结果：Cookies:12332#Content-Length:30000#Date:2018.07.04#Mime:text/html</code></pre>\n<pre><code class=\"java\">// 接上一个，内部类的引用，得到分割器，将字符串解析为map\nSplitter.MapSplitter ms = Splitter.on(&quot;#&quot;).withKeyValueSeparator(&#39;:&#39;);\nMap&lt;String, String&gt; ret = ms.split(returnedString);\nfor (String it2 : ret.keySet()) {\n    System.out.println(it2 + &quot; -&gt; &quot; + ret.get(it2));\n}</code></pre>\n<h3 id=\"字符串工具类\"><a href=\"#字符串工具类\" class=\"headerlink\" title=\"字符串工具类\"></a>字符串工具类</h3><pre><code class=\"java\">System.out.println(Strings.isNullOrEmpty(&quot;&quot;)); // true\nSystem.out.println(Strings.isNullOrEmpty(null)); // true\nSystem.out.println(Strings.isNullOrEmpty(&quot;hello&quot;)); // false\n// 将null转化为&quot;&quot;\n System.out.println(Strings.nullToEmpty(null)); // &quot;&quot; \n// 从尾部不断补充T只到总共8个字符，如果源字符串已经达到或操作，则原样返回。类似的有padStart\nSystem.out.println(Strings.padEnd(&quot;hello&quot;, 8, &#39;T&#39;)); // helloTTT</code></pre>\n<h3 id=\"字符匹配器CharMatcher\"><a href=\"#字符匹配器CharMatcher\" class=\"headerlink\" title=\"字符匹配器CharMatcher\"></a>字符匹配器CharMatcher</h3><pre><code class=\"java\">// 空白回车换行对应换成一个#，一对一换\nString stringWithLinebreaks = &quot;hello world\\r\\r\\ryou are here\\n\\ntake it\\t\\t\\teasy&quot;;\nString s6 = CharMatcher.BREAKING_WHITESPACE.replaceFrom(stringWithLinebreaks,&#39;#&#39;);\nSystem.out.println(s6); \n//执行结果：hello#world###you#are#here##take#it###easy</code></pre>\n<h3 id=\"连续空白替换成一个字符\"><a href=\"#连续空白替换成一个字符\" class=\"headerlink\" title=\"连续空白替换成一个字符\"></a>连续空白替换成一个字符</h3><pre><code class=\"java\">// 将所有连在一起的空白回车换行字符换成一个#，倒塌\nString tabString = &quot;  hello   \\n\\t\\tworld   you\\r\\nare             here  &quot;;\nString tabRet = CharMatcher.WHITESPACE.collapseFrom(tabString, &#39;#&#39;);\nSystem.out.println(tabRet); </code></pre>\n<h3 id=\"去掉前后空白和缩成一个字符\"><a href=\"#去掉前后空白和缩成一个字符\" class=\"headerlink\" title=\"去掉前后空白和缩成一个字符\"></a>去掉前后空白和缩成一个字符</h3><pre><code class=\"java\">// 在前面的基础上去掉字符串的前后空白，并将空白换成一个#\nString trimRet = CharMatcher.WHITESPACE.trimAndCollapseFrom(tabString, &#39;#&#39;);\nSystem.out.println(trimRet);\n//执行结果： hello#world#you#are#here</code></pre>\n<h3 id=\"只保留数字\"><a href=\"#只保留数字\" class=\"headerlink\" title=\"只保留数字\"></a>只保留数字</h3><pre><code class=\"java\">String letterAndNumber = &quot;1234abcdABCD56789&quot;;\n// 保留数字\nString number = CharMatcher.JAVA_DIGIT.retainFrom(letterAndNumber);\nSystem.out.println(number);//123456789</code></pre>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>使用Guava可以极大减少我们的代码量，减少犯错机会，提高工作效率。这次我们先介绍这些，下一篇我们深入Guava Caching！</p>\n"},{"title":"关于Map遍历的几种方法总结","excerpt":"","comments":1,"date":"2020-03-07T16:30:52.000Z","_content":"\n## 关于Map遍历的几种方法总结\n\n在java中所有的map都实现了Map接口，因此所有的Map（如HashMap, TreeMap, LinkedHashMap, Hashtable等）都可以用以下的方式去遍历。\n\n- 方法一：在for循环中使用Entry实现Map的遍历：\n\n```java\n/**\n* 最常见也是大多数情况下用的最多的，一般在键值对都需要使用\n */\nMap <String,String>map = new HashMap<String,String>();\nmap.put(\"Spring技术内幕\", \"计文柯\");\nmap.put(\"架构探险\", \"黄勇\");\nfor(Map.Entry<String, String> entry : map.entrySet()){\n    String mapKey = entry.getKey();\n    String mapValue = entry.getValue();\n    System.out.println(mapKey+\":\"+mapValue);\n}\n```\n\n- 方法二：在for循环中遍历key或者values，一般适用于只需要map中的key或者value时使用，在性能上比使用entrySet较好；\n\n```java\nMap <String,String>map = new HashMap<String,String>();\nmap.put(\"Spring技术内幕\", \"计文柯\");\nmap.put(\"架构探险\", \"黄勇\");\n//key\nfor(String key : map.keySet()){\n    System.out.println(key);\n}\n//value\nfor(String value : map.values()){\n    System.out.println(value);\n}\n```\n\n- 方法三：通过Iterator遍历；\n\n```java\nIterator<Entry<String, String>> entries = map.entrySet().iterator();\nwhile(entries.hasNext()){\n    Entry<String, String> entry = entries.next();\n    String key = entry.getKey();\n    String value = entry.getValue();\n    System.out.println(key+\":\"+value);\n}\n```\n\n- 方法四：通过键找值遍历，这种方式的效率比较低，因为本身从键取值是耗时的操作；\n\n```java\nfor(String key : map.keySet()){\n    String value = map.get(key);\n    System.out.println(key+\":\"+value);\n}\n```\n\n### 总结\n\n如果绝大多数数据都要用到，那么我们最好使用Entry来遍历，像方法四，每次都拿着key去map里查一次value，开销是比较大的。\n","source":"_posts/2020-03-08-kongzheng1993-Map遍历的几种方法.md","raw":"---\ntitle: 关于Map遍历的几种方法总结\nexcerpt: ''\ntags: [Java]\ncategories: [Java]\ncomments: true\ndate: 2020-03-08 00:30:52\n---\n\n## 关于Map遍历的几种方法总结\n\n在java中所有的map都实现了Map接口，因此所有的Map（如HashMap, TreeMap, LinkedHashMap, Hashtable等）都可以用以下的方式去遍历。\n\n- 方法一：在for循环中使用Entry实现Map的遍历：\n\n```java\n/**\n* 最常见也是大多数情况下用的最多的，一般在键值对都需要使用\n */\nMap <String,String>map = new HashMap<String,String>();\nmap.put(\"Spring技术内幕\", \"计文柯\");\nmap.put(\"架构探险\", \"黄勇\");\nfor(Map.Entry<String, String> entry : map.entrySet()){\n    String mapKey = entry.getKey();\n    String mapValue = entry.getValue();\n    System.out.println(mapKey+\":\"+mapValue);\n}\n```\n\n- 方法二：在for循环中遍历key或者values，一般适用于只需要map中的key或者value时使用，在性能上比使用entrySet较好；\n\n```java\nMap <String,String>map = new HashMap<String,String>();\nmap.put(\"Spring技术内幕\", \"计文柯\");\nmap.put(\"架构探险\", \"黄勇\");\n//key\nfor(String key : map.keySet()){\n    System.out.println(key);\n}\n//value\nfor(String value : map.values()){\n    System.out.println(value);\n}\n```\n\n- 方法三：通过Iterator遍历；\n\n```java\nIterator<Entry<String, String>> entries = map.entrySet().iterator();\nwhile(entries.hasNext()){\n    Entry<String, String> entry = entries.next();\n    String key = entry.getKey();\n    String value = entry.getValue();\n    System.out.println(key+\":\"+value);\n}\n```\n\n- 方法四：通过键找值遍历，这种方式的效率比较低，因为本身从键取值是耗时的操作；\n\n```java\nfor(String key : map.keySet()){\n    String value = map.get(key);\n    System.out.println(key+\":\"+value);\n}\n```\n\n### 总结\n\n如果绝大多数数据都要用到，那么我们最好使用Entry来遍历，像方法四，每次都拿着key去map里查一次value，开销是比较大的。\n","slug":"kongzheng1993-Map遍历的几种方法","published":1,"updated":"2023-03-08T07:05:58.776Z","layout":"post","photos":[],"link":"","_id":"clg0k2ad9001wt26f8r2mvodp","content":"<h2 id=\"关于Map遍历的几种方法总结\"><a href=\"#关于Map遍历的几种方法总结\" class=\"headerlink\" title=\"关于Map遍历的几种方法总结\"></a>关于Map遍历的几种方法总结</h2><p>在java中所有的map都实现了Map接口，因此所有的Map（如HashMap, TreeMap, LinkedHashMap, Hashtable等）都可以用以下的方式去遍历。</p>\n<ul>\n<li>方法一：在for循环中使用Entry实现Map的遍历：</li>\n</ul>\n<pre><code class=\"java\">/**\n* 最常见也是大多数情况下用的最多的，一般在键值对都需要使用\n */\nMap &lt;String,String&gt;map = new HashMap&lt;String,String&gt;();\nmap.put(&quot;Spring技术内幕&quot;, &quot;计文柯&quot;);\nmap.put(&quot;架构探险&quot;, &quot;黄勇&quot;);\nfor(Map.Entry&lt;String, String&gt; entry : map.entrySet()){\n    String mapKey = entry.getKey();\n    String mapValue = entry.getValue();\n    System.out.println(mapKey+&quot;:&quot;+mapValue);\n}</code></pre>\n<ul>\n<li>方法二：在for循环中遍历key或者values，一般适用于只需要map中的key或者value时使用，在性能上比使用entrySet较好；</li>\n</ul>\n<pre><code class=\"java\">Map &lt;String,String&gt;map = new HashMap&lt;String,String&gt;();\nmap.put(&quot;Spring技术内幕&quot;, &quot;计文柯&quot;);\nmap.put(&quot;架构探险&quot;, &quot;黄勇&quot;);\n//key\nfor(String key : map.keySet()){\n    System.out.println(key);\n}\n//value\nfor(String value : map.values()){\n    System.out.println(value);\n}</code></pre>\n<ul>\n<li>方法三：通过Iterator遍历；</li>\n</ul>\n<pre><code class=\"java\">Iterator&lt;Entry&lt;String, String&gt;&gt; entries = map.entrySet().iterator();\nwhile(entries.hasNext()){\n    Entry&lt;String, String&gt; entry = entries.next();\n    String key = entry.getKey();\n    String value = entry.getValue();\n    System.out.println(key+&quot;:&quot;+value);\n}</code></pre>\n<ul>\n<li>方法四：通过键找值遍历，这种方式的效率比较低，因为本身从键取值是耗时的操作；</li>\n</ul>\n<pre><code class=\"java\">for(String key : map.keySet()){\n    String value = map.get(key);\n    System.out.println(key+&quot;:&quot;+value);\n}</code></pre>\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3><p>如果绝大多数数据都要用到，那么我们最好使用Entry来遍历，像方法四，每次都拿着key去map里查一次value，开销是比较大的。</p>\n","site":{"data":{}},"more":"<h2 id=\"关于Map遍历的几种方法总结\"><a href=\"#关于Map遍历的几种方法总结\" class=\"headerlink\" title=\"关于Map遍历的几种方法总结\"></a>关于Map遍历的几种方法总结</h2><p>在java中所有的map都实现了Map接口，因此所有的Map（如HashMap, TreeMap, LinkedHashMap, Hashtable等）都可以用以下的方式去遍历。</p>\n<ul>\n<li>方法一：在for循环中使用Entry实现Map的遍历：</li>\n</ul>\n<pre><code class=\"java\">/**\n* 最常见也是大多数情况下用的最多的，一般在键值对都需要使用\n */\nMap &lt;String,String&gt;map = new HashMap&lt;String,String&gt;();\nmap.put(&quot;Spring技术内幕&quot;, &quot;计文柯&quot;);\nmap.put(&quot;架构探险&quot;, &quot;黄勇&quot;);\nfor(Map.Entry&lt;String, String&gt; entry : map.entrySet()){\n    String mapKey = entry.getKey();\n    String mapValue = entry.getValue();\n    System.out.println(mapKey+&quot;:&quot;+mapValue);\n}</code></pre>\n<ul>\n<li>方法二：在for循环中遍历key或者values，一般适用于只需要map中的key或者value时使用，在性能上比使用entrySet较好；</li>\n</ul>\n<pre><code class=\"java\">Map &lt;String,String&gt;map = new HashMap&lt;String,String&gt;();\nmap.put(&quot;Spring技术内幕&quot;, &quot;计文柯&quot;);\nmap.put(&quot;架构探险&quot;, &quot;黄勇&quot;);\n//key\nfor(String key : map.keySet()){\n    System.out.println(key);\n}\n//value\nfor(String value : map.values()){\n    System.out.println(value);\n}</code></pre>\n<ul>\n<li>方法三：通过Iterator遍历；</li>\n</ul>\n<pre><code class=\"java\">Iterator&lt;Entry&lt;String, String&gt;&gt; entries = map.entrySet().iterator();\nwhile(entries.hasNext()){\n    Entry&lt;String, String&gt; entry = entries.next();\n    String key = entry.getKey();\n    String value = entry.getValue();\n    System.out.println(key+&quot;:&quot;+value);\n}</code></pre>\n<ul>\n<li>方法四：通过键找值遍历，这种方式的效率比较低，因为本身从键取值是耗时的操作；</li>\n</ul>\n<pre><code class=\"java\">for(String key : map.keySet()){\n    String value = map.get(key);\n    System.out.println(key+&quot;:&quot;+value);\n}</code></pre>\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3><p>如果绝大多数数据都要用到，那么我们最好使用Entry来遍历，像方法四，每次都拿着key去map里查一次value，开销是比较大的。</p>\n"},{"title":"jhat","excerpt":"","comments":1,"date":"2020-03-07T16:30:52.000Z","_content":"\n# jhat\n\n分析Java堆。此命令是实验性的，不受支持。\n\n## 概要\n\n```jhat [ options ] heap-dump-file```\n\n## 选项\n\n命令行选项。\n\n- -stack false | true\n关闭跟踪对象分配调用堆栈。如果堆转储中没有分配站点信息，则必须将此标志设置为false。默认值为true。\n\n- -refs false | true\n关闭对对象引用的跟踪。默认值为true。默认情况下，将为堆中的所有对象计算后向指针，即指向指定对象的对象，例如引用程序或传入引用。\n\n- -port 端口号\n设置jhatHTTP服务器的端口。默认值为7000。\n\n- -exclude exclude-file\n指定一个文件，该文件列出了应从可达对象查询中排除的数据成员。例如，如果文件列出java.lang.String.value，则无论何时o计算从特定对象可访问的对象列表，java.lang.String.value都不会考虑涉及字段的引用路径。\n\n- -baseline exclude-file\n指定基线堆转储。两个堆转储中具有相同对象ID的对象都标记为不是新对象。其他对象被标记为新对象。这对于比较两个不同的堆转储很有用。\n\n- -debug int\n设置此工具的调试级别。级别0表示没有调试输出。为更多详细模式设置较高的值。\n\n- -version\n报告发布编号并退出\n\n- -h\n显示帮助消息并退出。\n\n- -help\n显示帮助消息并退出。\n\n- -Jflag\n传递flag到在其jhat上运行命令的Java虚拟机。例如，-J-Xmx512m使用最大堆大小为512 MB。\n\n## 堆转储文件\n\n要浏览的Java二进制堆转储文件。对于包含多个堆转储的转储文件，您可以通过#<number>在文件名后附加名称来指定文件中的哪个转储myfile.hprof#3。\n\n## 描述\n\n该jhat命令解析Java堆转储文件并启动Web服务器。该jhat命令使您可以使用自己喜欢的Web浏览器浏览堆转储。该jhat命令支持预先设计的查询，例如显示已知类的所有实例MyClass以及对象查询语言（OQL）。OQL与SQL相似，除了查询堆转储。可从jhat命令显示的OQL帮助页面获得OQL帮助。使用默认端口，可以从http://localhost:7000/oqlhelp /获得OQL帮助。\n\n有几种方法可以生成Java堆转储：\n\n- 使用该jmap -dump选项在运行时获取堆转储。参见jmap（1）。\n- 使用该jconsole选项HotSpotDiagnosticMXBean在运行时获取堆转储。请参阅jconsole（1）和HotSpotDiagnosticMXBean接口说明，网址为\nhttp://docs.oracle.com/javase/8/docs/jre/api/management/extension/com/sun/management/HotSpotDiagnosticMXBean.html\n- OutOfMemoryError通过指定-XX:+HeapDumpOnOutOfMemoryErrorJava虚拟机（JVM）选项引发时，将生成堆转储。\n- 使用hprof命令。请参阅HPROF：堆/ CPU分析工具，网址为：\nhttp://docs.oracle.com/javase/8/docs/technotes/samples/hprof.html\n","source":"_posts/2020-03-08-kongzheng1993-jhat.md","raw":"---\ntitle: jhat\nexcerpt: ''\ntags: [jvm]\ncategories: [jvm]\ncomments: true\ndate: 2020-03-08 00:30:52\n---\n\n# jhat\n\n分析Java堆。此命令是实验性的，不受支持。\n\n## 概要\n\n```jhat [ options ] heap-dump-file```\n\n## 选项\n\n命令行选项。\n\n- -stack false | true\n关闭跟踪对象分配调用堆栈。如果堆转储中没有分配站点信息，则必须将此标志设置为false。默认值为true。\n\n- -refs false | true\n关闭对对象引用的跟踪。默认值为true。默认情况下，将为堆中的所有对象计算后向指针，即指向指定对象的对象，例如引用程序或传入引用。\n\n- -port 端口号\n设置jhatHTTP服务器的端口。默认值为7000。\n\n- -exclude exclude-file\n指定一个文件，该文件列出了应从可达对象查询中排除的数据成员。例如，如果文件列出java.lang.String.value，则无论何时o计算从特定对象可访问的对象列表，java.lang.String.value都不会考虑涉及字段的引用路径。\n\n- -baseline exclude-file\n指定基线堆转储。两个堆转储中具有相同对象ID的对象都标记为不是新对象。其他对象被标记为新对象。这对于比较两个不同的堆转储很有用。\n\n- -debug int\n设置此工具的调试级别。级别0表示没有调试输出。为更多详细模式设置较高的值。\n\n- -version\n报告发布编号并退出\n\n- -h\n显示帮助消息并退出。\n\n- -help\n显示帮助消息并退出。\n\n- -Jflag\n传递flag到在其jhat上运行命令的Java虚拟机。例如，-J-Xmx512m使用最大堆大小为512 MB。\n\n## 堆转储文件\n\n要浏览的Java二进制堆转储文件。对于包含多个堆转储的转储文件，您可以通过#<number>在文件名后附加名称来指定文件中的哪个转储myfile.hprof#3。\n\n## 描述\n\n该jhat命令解析Java堆转储文件并启动Web服务器。该jhat命令使您可以使用自己喜欢的Web浏览器浏览堆转储。该jhat命令支持预先设计的查询，例如显示已知类的所有实例MyClass以及对象查询语言（OQL）。OQL与SQL相似，除了查询堆转储。可从jhat命令显示的OQL帮助页面获得OQL帮助。使用默认端口，可以从http://localhost:7000/oqlhelp /获得OQL帮助。\n\n有几种方法可以生成Java堆转储：\n\n- 使用该jmap -dump选项在运行时获取堆转储。参见jmap（1）。\n- 使用该jconsole选项HotSpotDiagnosticMXBean在运行时获取堆转储。请参阅jconsole（1）和HotSpotDiagnosticMXBean接口说明，网址为\nhttp://docs.oracle.com/javase/8/docs/jre/api/management/extension/com/sun/management/HotSpotDiagnosticMXBean.html\n- OutOfMemoryError通过指定-XX:+HeapDumpOnOutOfMemoryErrorJava虚拟机（JVM）选项引发时，将生成堆转储。\n- 使用hprof命令。请参阅HPROF：堆/ CPU分析工具，网址为：\nhttp://docs.oracle.com/javase/8/docs/technotes/samples/hprof.html\n","slug":"kongzheng1993-jhat","published":1,"updated":"2023-03-08T07:05:58.777Z","layout":"post","photos":[],"link":"","_id":"clg0k2ada0020t26fvjyyypwr","content":"<h1 id=\"jhat\"><a href=\"#jhat\" class=\"headerlink\" title=\"jhat\"></a>jhat</h1><p>分析Java堆。此命令是实验性的，不受支持。</p>\n<h2 id=\"概要\"><a href=\"#概要\" class=\"headerlink\" title=\"概要\"></a>概要</h2><p><code>jhat [ options ] heap-dump-file</code></p>\n<h2 id=\"选项\"><a href=\"#选项\" class=\"headerlink\" title=\"选项\"></a>选项</h2><p>命令行选项。</p>\n<ul>\n<li><p>-stack false | true<br>关闭跟踪对象分配调用堆栈。如果堆转储中没有分配站点信息，则必须将此标志设置为false。默认值为true。</p>\n</li>\n<li><p>-refs false | true<br>关闭对对象引用的跟踪。默认值为true。默认情况下，将为堆中的所有对象计算后向指针，即指向指定对象的对象，例如引用程序或传入引用。</p>\n</li>\n<li><p>-port 端口号<br>设置jhatHTTP服务器的端口。默认值为7000。</p>\n</li>\n<li><p>-exclude exclude-file<br>指定一个文件，该文件列出了应从可达对象查询中排除的数据成员。例如，如果文件列出java.lang.String.value，则无论何时o计算从特定对象可访问的对象列表，java.lang.String.value都不会考虑涉及字段的引用路径。</p>\n</li>\n<li><p>-baseline exclude-file<br>指定基线堆转储。两个堆转储中具有相同对象ID的对象都标记为不是新对象。其他对象被标记为新对象。这对于比较两个不同的堆转储很有用。</p>\n</li>\n<li><p>-debug int<br>设置此工具的调试级别。级别0表示没有调试输出。为更多详细模式设置较高的值。</p>\n</li>\n<li><p>-version<br>报告发布编号并退出</p>\n</li>\n<li><p>-h<br>显示帮助消息并退出。</p>\n</li>\n<li><p>-help<br>显示帮助消息并退出。</p>\n</li>\n<li><p>-Jflag<br>传递flag到在其jhat上运行命令的Java虚拟机。例如，-J-Xmx512m使用最大堆大小为512 MB。</p>\n</li>\n</ul>\n<h2 id=\"堆转储文件\"><a href=\"#堆转储文件\" class=\"headerlink\" title=\"堆转储文件\"></a>堆转储文件</h2><p>要浏览的Java二进制堆转储文件。对于包含多个堆转储的转储文件，您可以通过#<number>在文件名后附加名称来指定文件中的哪个转储myfile.hprof#3。</number></p>\n<h2 id=\"描述\"><a href=\"#描述\" class=\"headerlink\" title=\"描述\"></a>描述</h2><p>该jhat命令解析Java堆转储文件并启动Web服务器。该jhat命令使您可以使用自己喜欢的Web浏览器浏览堆转储。该jhat命令支持预先设计的查询，例如显示已知类的所有实例MyClass以及对象查询语言（OQL）。OQL与SQL相似，除了查询堆转储。可从jhat命令显示的OQL帮助页面获得OQL帮助。使用默认端口，可以从<a href=\"http://localhost:7000/oqlhelp\" target=\"_blank\" rel=\"noopener\">http://localhost:7000/oqlhelp</a> /获得OQL帮助。</p>\n<p>有几种方法可以生成Java堆转储：</p>\n<ul>\n<li>使用该jmap -dump选项在运行时获取堆转储。参见jmap（1）。</li>\n<li>使用该jconsole选项HotSpotDiagnosticMXBean在运行时获取堆转储。请参阅jconsole（1）和HotSpotDiagnosticMXBean接口说明，网址为<br><a href=\"http://docs.oracle.com/javase/8/docs/jre/api/management/extension/com/sun/management/HotSpotDiagnosticMXBean.html\" target=\"_blank\" rel=\"noopener\">http://docs.oracle.com/javase/8/docs/jre/api/management/extension/com/sun/management/HotSpotDiagnosticMXBean.html</a></li>\n<li>OutOfMemoryError通过指定-XX:+HeapDumpOnOutOfMemoryErrorJava虚拟机（JVM）选项引发时，将生成堆转储。</li>\n<li>使用hprof命令。请参阅HPROF：堆/ CPU分析工具，网址为：<br><a href=\"http://docs.oracle.com/javase/8/docs/technotes/samples/hprof.html\" target=\"_blank\" rel=\"noopener\">http://docs.oracle.com/javase/8/docs/technotes/samples/hprof.html</a></li>\n</ul>\n","site":{"data":{}},"more":"<h1 id=\"jhat\"><a href=\"#jhat\" class=\"headerlink\" title=\"jhat\"></a>jhat</h1><p>分析Java堆。此命令是实验性的，不受支持。</p>\n<h2 id=\"概要\"><a href=\"#概要\" class=\"headerlink\" title=\"概要\"></a>概要</h2><p><code>jhat [ options ] heap-dump-file</code></p>\n<h2 id=\"选项\"><a href=\"#选项\" class=\"headerlink\" title=\"选项\"></a>选项</h2><p>命令行选项。</p>\n<ul>\n<li><p>-stack false | true<br>关闭跟踪对象分配调用堆栈。如果堆转储中没有分配站点信息，则必须将此标志设置为false。默认值为true。</p>\n</li>\n<li><p>-refs false | true<br>关闭对对象引用的跟踪。默认值为true。默认情况下，将为堆中的所有对象计算后向指针，即指向指定对象的对象，例如引用程序或传入引用。</p>\n</li>\n<li><p>-port 端口号<br>设置jhatHTTP服务器的端口。默认值为7000。</p>\n</li>\n<li><p>-exclude exclude-file<br>指定一个文件，该文件列出了应从可达对象查询中排除的数据成员。例如，如果文件列出java.lang.String.value，则无论何时o计算从特定对象可访问的对象列表，java.lang.String.value都不会考虑涉及字段的引用路径。</p>\n</li>\n<li><p>-baseline exclude-file<br>指定基线堆转储。两个堆转储中具有相同对象ID的对象都标记为不是新对象。其他对象被标记为新对象。这对于比较两个不同的堆转储很有用。</p>\n</li>\n<li><p>-debug int<br>设置此工具的调试级别。级别0表示没有调试输出。为更多详细模式设置较高的值。</p>\n</li>\n<li><p>-version<br>报告发布编号并退出</p>\n</li>\n<li><p>-h<br>显示帮助消息并退出。</p>\n</li>\n<li><p>-help<br>显示帮助消息并退出。</p>\n</li>\n<li><p>-Jflag<br>传递flag到在其jhat上运行命令的Java虚拟机。例如，-J-Xmx512m使用最大堆大小为512 MB。</p>\n</li>\n</ul>\n<h2 id=\"堆转储文件\"><a href=\"#堆转储文件\" class=\"headerlink\" title=\"堆转储文件\"></a>堆转储文件</h2><p>要浏览的Java二进制堆转储文件。对于包含多个堆转储的转储文件，您可以通过#<number>在文件名后附加名称来指定文件中的哪个转储myfile.hprof#3。</number></p>\n<h2 id=\"描述\"><a href=\"#描述\" class=\"headerlink\" title=\"描述\"></a>描述</h2><p>该jhat命令解析Java堆转储文件并启动Web服务器。该jhat命令使您可以使用自己喜欢的Web浏览器浏览堆转储。该jhat命令支持预先设计的查询，例如显示已知类的所有实例MyClass以及对象查询语言（OQL）。OQL与SQL相似，除了查询堆转储。可从jhat命令显示的OQL帮助页面获得OQL帮助。使用默认端口，可以从<a href=\"http://localhost:7000/oqlhelp\" target=\"_blank\" rel=\"noopener\">http://localhost:7000/oqlhelp</a> /获得OQL帮助。</p>\n<p>有几种方法可以生成Java堆转储：</p>\n<ul>\n<li>使用该jmap -dump选项在运行时获取堆转储。参见jmap（1）。</li>\n<li>使用该jconsole选项HotSpotDiagnosticMXBean在运行时获取堆转储。请参阅jconsole（1）和HotSpotDiagnosticMXBean接口说明，网址为<br><a href=\"http://docs.oracle.com/javase/8/docs/jre/api/management/extension/com/sun/management/HotSpotDiagnosticMXBean.html\" target=\"_blank\" rel=\"noopener\">http://docs.oracle.com/javase/8/docs/jre/api/management/extension/com/sun/management/HotSpotDiagnosticMXBean.html</a></li>\n<li>OutOfMemoryError通过指定-XX:+HeapDumpOnOutOfMemoryErrorJava虚拟机（JVM）选项引发时，将生成堆转储。</li>\n<li>使用hprof命令。请参阅HPROF：堆/ CPU分析工具，网址为：<br><a href=\"http://docs.oracle.com/javase/8/docs/technotes/samples/hprof.html\" target=\"_blank\" rel=\"noopener\">http://docs.oracle.com/javase/8/docs/technotes/samples/hprof.html</a></li>\n</ul>\n"},{"title":"jmap","excerpt":"","comments":1,"date":"2020-03-07T16:30:52.000Z","_content":"\n## jmap\n打印进程，核心文件或远程调试服务器的共享对象内存映射或堆内存详细信息。此命令是实验性的，不受支持。\n\n### 概要\n\n```shell\njmap [ 选项 ] pid\njmap [ options ] 可执行 核心\njmap [ 选项 ] [ pid ] 服务器ID @] remote-hostname-or-IP\n```\n#### 选项\n命令行选项。\n- <无选择>\n不使用任何选项时，该jmap命令将打印共享对象映射。对于目标JVM中加载的每个共享对象，将打印共享对象文件的开始地址，映射的大小和完整路径。此行为类似于Oracle Solaris pmap实用程序。\n\n- -dump：[live，]format=b，file=filename\n将Java堆以hprof二进制格式转储到filename。的live子选项是可选的，但是当指定时，仅在堆活动对象被倾倒。要浏览堆转储，可以使用jhat（1）命令读取生成的文件。\n\n- -finalizerinfo\n打印有关正在等待完成的对象的信息。\n\n- -heap\n打印所用垃圾收集的堆摘要，头配置和逐代堆使用情况。此外，还会打印实习字符串的数量和大小。\n\n- -histo [：live]\n打印堆的直方图。对于每个Java类，将打印对象数量，以字节为单位的内存大小以及完全限定的类名称。JVM内部类名称打印有星号（*）前缀。如果live指定了子选项，则仅计算活动对象。\n\n- -clstats\n打印Java堆的类加载器明智的统计信息。对于每个类加载器，将打印其名称，活动程度，地址，父类加载器以及已加载的类的数量和大小。\n\n- -F\n力。当pid不响应时，将此选项与jmap -dump或选项一起使用jmap -histo。该live子选项并不在此模式下支持。\n\n- -h\n打印帮助信息。\n\n- -help\n打印帮助信息。\n\n- -Jflag\n传递flag到jmap运行命令的Java虚拟机。\n\n#### pid\n要为其打印内存映射的进程ID。该进程必须是Java进程。要获取机器上运行的Java进程的列表，请使用jps（1）命令。\n\n#### 可执行文件\n生成核心转储的Java可执行文件。\n\n#### 核心\n要为其打印内存映射的核心文件。\n\n#### 远程主机名或IP\n远程调试服务器hostname或IP地址。参见jsadebugd（1）。\n\n#### 服务器ID\n当多个调试服务器在同一远程主机上运行时使用的可选唯一ID。\n\n### 描述\n该jmap命令显示指定进程，核心文件或远程调试服务器的共享对象内存映射或堆内存详细信息。如果指定的进程在64位Java虚拟机（JVM）上运行，则可能需要指定该-J-d64选项，例如：jmap -J-d64 -heap pid。\n\n    注意：此实用程序不受支持，在以后的JDK版本中可能不可用。在dbgeng.dll不存在该文件的Windows系统上，必须安装Windows调试工具才能使这些工具正常工作。在PATH环境变量中应包含的位置jvm.dll所使用的目标进程或从中故障转储文件被产生，例如位置的文件：set PATH=%JDK_HOME%\\jre\\bin\\client;%PATH%。\n\n","source":"_posts/2020-03-08-kongzheng1993-jmap.md","raw":"---\ntitle: jmap\nexcerpt: ''\ntags: [jvm]\ncategories: [jvm]\ncomments: true\ndate: 2020-03-08 00:30:52\n---\n\n## jmap\n打印进程，核心文件或远程调试服务器的共享对象内存映射或堆内存详细信息。此命令是实验性的，不受支持。\n\n### 概要\n\n```shell\njmap [ 选项 ] pid\njmap [ options ] 可执行 核心\njmap [ 选项 ] [ pid ] 服务器ID @] remote-hostname-or-IP\n```\n#### 选项\n命令行选项。\n- <无选择>\n不使用任何选项时，该jmap命令将打印共享对象映射。对于目标JVM中加载的每个共享对象，将打印共享对象文件的开始地址，映射的大小和完整路径。此行为类似于Oracle Solaris pmap实用程序。\n\n- -dump：[live，]format=b，file=filename\n将Java堆以hprof二进制格式转储到filename。的live子选项是可选的，但是当指定时，仅在堆活动对象被倾倒。要浏览堆转储，可以使用jhat（1）命令读取生成的文件。\n\n- -finalizerinfo\n打印有关正在等待完成的对象的信息。\n\n- -heap\n打印所用垃圾收集的堆摘要，头配置和逐代堆使用情况。此外，还会打印实习字符串的数量和大小。\n\n- -histo [：live]\n打印堆的直方图。对于每个Java类，将打印对象数量，以字节为单位的内存大小以及完全限定的类名称。JVM内部类名称打印有星号（*）前缀。如果live指定了子选项，则仅计算活动对象。\n\n- -clstats\n打印Java堆的类加载器明智的统计信息。对于每个类加载器，将打印其名称，活动程度，地址，父类加载器以及已加载的类的数量和大小。\n\n- -F\n力。当pid不响应时，将此选项与jmap -dump或选项一起使用jmap -histo。该live子选项并不在此模式下支持。\n\n- -h\n打印帮助信息。\n\n- -help\n打印帮助信息。\n\n- -Jflag\n传递flag到jmap运行命令的Java虚拟机。\n\n#### pid\n要为其打印内存映射的进程ID。该进程必须是Java进程。要获取机器上运行的Java进程的列表，请使用jps（1）命令。\n\n#### 可执行文件\n生成核心转储的Java可执行文件。\n\n#### 核心\n要为其打印内存映射的核心文件。\n\n#### 远程主机名或IP\n远程调试服务器hostname或IP地址。参见jsadebugd（1）。\n\n#### 服务器ID\n当多个调试服务器在同一远程主机上运行时使用的可选唯一ID。\n\n### 描述\n该jmap命令显示指定进程，核心文件或远程调试服务器的共享对象内存映射或堆内存详细信息。如果指定的进程在64位Java虚拟机（JVM）上运行，则可能需要指定该-J-d64选项，例如：jmap -J-d64 -heap pid。\n\n    注意：此实用程序不受支持，在以后的JDK版本中可能不可用。在dbgeng.dll不存在该文件的Windows系统上，必须安装Windows调试工具才能使这些工具正常工作。在PATH环境变量中应包含的位置jvm.dll所使用的目标进程或从中故障转储文件被产生，例如位置的文件：set PATH=%JDK_HOME%\\jre\\bin\\client;%PATH%。\n\n","slug":"kongzheng1993-jmap","published":1,"updated":"2023-03-08T07:05:58.777Z","layout":"post","photos":[],"link":"","_id":"clg0k2adb0021t26fntuez238","content":"<h2 id=\"jmap\"><a href=\"#jmap\" class=\"headerlink\" title=\"jmap\"></a>jmap</h2><p>打印进程，核心文件或远程调试服务器的共享对象内存映射或堆内存详细信息。此命令是实验性的，不受支持。</p>\n<h3 id=\"概要\"><a href=\"#概要\" class=\"headerlink\" title=\"概要\"></a>概要</h3><pre><code class=\"shell\">jmap [ 选项 ] pid\njmap [ options ] 可执行 核心\njmap [ 选项 ] [ pid ] 服务器ID @] remote-hostname-or-IP</code></pre>\n<h4 id=\"选项\"><a href=\"#选项\" class=\"headerlink\" title=\"选项\"></a>选项</h4><p>命令行选项。</p>\n<ul>\n<li><p>&lt;无选择&gt;<br>不使用任何选项时，该jmap命令将打印共享对象映射。对于目标JVM中加载的每个共享对象，将打印共享对象文件的开始地址，映射的大小和完整路径。此行为类似于Oracle Solaris pmap实用程序。</p>\n</li>\n<li><p>-dump：[live，]format=b，file=filename<br>将Java堆以hprof二进制格式转储到filename。的live子选项是可选的，但是当指定时，仅在堆活动对象被倾倒。要浏览堆转储，可以使用jhat（1）命令读取生成的文件。</p>\n</li>\n<li><p>-finalizerinfo<br>打印有关正在等待完成的对象的信息。</p>\n</li>\n<li><p>-heap<br>打印所用垃圾收集的堆摘要，头配置和逐代堆使用情况。此外，还会打印实习字符串的数量和大小。</p>\n</li>\n<li><p>-histo [：live]<br>打印堆的直方图。对于每个Java类，将打印对象数量，以字节为单位的内存大小以及完全限定的类名称。JVM内部类名称打印有星号（*）前缀。如果live指定了子选项，则仅计算活动对象。</p>\n</li>\n<li><p>-clstats<br>打印Java堆的类加载器明智的统计信息。对于每个类加载器，将打印其名称，活动程度，地址，父类加载器以及已加载的类的数量和大小。</p>\n</li>\n<li><p>-F<br>力。当pid不响应时，将此选项与jmap -dump或选项一起使用jmap -histo。该live子选项并不在此模式下支持。</p>\n</li>\n<li><p>-h<br>打印帮助信息。</p>\n</li>\n<li><p>-help<br>打印帮助信息。</p>\n</li>\n<li><p>-Jflag<br>传递flag到jmap运行命令的Java虚拟机。</p>\n</li>\n</ul>\n<h4 id=\"pid\"><a href=\"#pid\" class=\"headerlink\" title=\"pid\"></a>pid</h4><p>要为其打印内存映射的进程ID。该进程必须是Java进程。要获取机器上运行的Java进程的列表，请使用jps（1）命令。</p>\n<h4 id=\"可执行文件\"><a href=\"#可执行文件\" class=\"headerlink\" title=\"可执行文件\"></a>可执行文件</h4><p>生成核心转储的Java可执行文件。</p>\n<h4 id=\"核心\"><a href=\"#核心\" class=\"headerlink\" title=\"核心\"></a>核心</h4><p>要为其打印内存映射的核心文件。</p>\n<h4 id=\"远程主机名或IP\"><a href=\"#远程主机名或IP\" class=\"headerlink\" title=\"远程主机名或IP\"></a>远程主机名或IP</h4><p>远程调试服务器hostname或IP地址。参见jsadebugd（1）。</p>\n<h4 id=\"服务器ID\"><a href=\"#服务器ID\" class=\"headerlink\" title=\"服务器ID\"></a>服务器ID</h4><p>当多个调试服务器在同一远程主机上运行时使用的可选唯一ID。</p>\n<h3 id=\"描述\"><a href=\"#描述\" class=\"headerlink\" title=\"描述\"></a>描述</h3><p>该jmap命令显示指定进程，核心文件或远程调试服务器的共享对象内存映射或堆内存详细信息。如果指定的进程在64位Java虚拟机（JVM）上运行，则可能需要指定该-J-d64选项，例如：jmap -J-d64 -heap pid。</p>\n<pre><code>注意：此实用程序不受支持，在以后的JDK版本中可能不可用。在dbgeng.dll不存在该文件的Windows系统上，必须安装Windows调试工具才能使这些工具正常工作。在PATH环境变量中应包含的位置jvm.dll所使用的目标进程或从中故障转储文件被产生，例如位置的文件：set PATH=%JDK_HOME%\\jre\\bin\\client;%PATH%。</code></pre>","site":{"data":{}},"more":"<h2 id=\"jmap\"><a href=\"#jmap\" class=\"headerlink\" title=\"jmap\"></a>jmap</h2><p>打印进程，核心文件或远程调试服务器的共享对象内存映射或堆内存详细信息。此命令是实验性的，不受支持。</p>\n<h3 id=\"概要\"><a href=\"#概要\" class=\"headerlink\" title=\"概要\"></a>概要</h3><pre><code class=\"shell\">jmap [ 选项 ] pid\njmap [ options ] 可执行 核心\njmap [ 选项 ] [ pid ] 服务器ID @] remote-hostname-or-IP</code></pre>\n<h4 id=\"选项\"><a href=\"#选项\" class=\"headerlink\" title=\"选项\"></a>选项</h4><p>命令行选项。</p>\n<ul>\n<li><p>&lt;无选择&gt;<br>不使用任何选项时，该jmap命令将打印共享对象映射。对于目标JVM中加载的每个共享对象，将打印共享对象文件的开始地址，映射的大小和完整路径。此行为类似于Oracle Solaris pmap实用程序。</p>\n</li>\n<li><p>-dump：[live，]format=b，file=filename<br>将Java堆以hprof二进制格式转储到filename。的live子选项是可选的，但是当指定时，仅在堆活动对象被倾倒。要浏览堆转储，可以使用jhat（1）命令读取生成的文件。</p>\n</li>\n<li><p>-finalizerinfo<br>打印有关正在等待完成的对象的信息。</p>\n</li>\n<li><p>-heap<br>打印所用垃圾收集的堆摘要，头配置和逐代堆使用情况。此外，还会打印实习字符串的数量和大小。</p>\n</li>\n<li><p>-histo [：live]<br>打印堆的直方图。对于每个Java类，将打印对象数量，以字节为单位的内存大小以及完全限定的类名称。JVM内部类名称打印有星号（*）前缀。如果live指定了子选项，则仅计算活动对象。</p>\n</li>\n<li><p>-clstats<br>打印Java堆的类加载器明智的统计信息。对于每个类加载器，将打印其名称，活动程度，地址，父类加载器以及已加载的类的数量和大小。</p>\n</li>\n<li><p>-F<br>力。当pid不响应时，将此选项与jmap -dump或选项一起使用jmap -histo。该live子选项并不在此模式下支持。</p>\n</li>\n<li><p>-h<br>打印帮助信息。</p>\n</li>\n<li><p>-help<br>打印帮助信息。</p>\n</li>\n<li><p>-Jflag<br>传递flag到jmap运行命令的Java虚拟机。</p>\n</li>\n</ul>\n<h4 id=\"pid\"><a href=\"#pid\" class=\"headerlink\" title=\"pid\"></a>pid</h4><p>要为其打印内存映射的进程ID。该进程必须是Java进程。要获取机器上运行的Java进程的列表，请使用jps（1）命令。</p>\n<h4 id=\"可执行文件\"><a href=\"#可执行文件\" class=\"headerlink\" title=\"可执行文件\"></a>可执行文件</h4><p>生成核心转储的Java可执行文件。</p>\n<h4 id=\"核心\"><a href=\"#核心\" class=\"headerlink\" title=\"核心\"></a>核心</h4><p>要为其打印内存映射的核心文件。</p>\n<h4 id=\"远程主机名或IP\"><a href=\"#远程主机名或IP\" class=\"headerlink\" title=\"远程主机名或IP\"></a>远程主机名或IP</h4><p>远程调试服务器hostname或IP地址。参见jsadebugd（1）。</p>\n<h4 id=\"服务器ID\"><a href=\"#服务器ID\" class=\"headerlink\" title=\"服务器ID\"></a>服务器ID</h4><p>当多个调试服务器在同一远程主机上运行时使用的可选唯一ID。</p>\n<h3 id=\"描述\"><a href=\"#描述\" class=\"headerlink\" title=\"描述\"></a>描述</h3><p>该jmap命令显示指定进程，核心文件或远程调试服务器的共享对象内存映射或堆内存详细信息。如果指定的进程在64位Java虚拟机（JVM）上运行，则可能需要指定该-J-d64选项，例如：jmap -J-d64 -heap pid。</p>\n<pre><code>注意：此实用程序不受支持，在以后的JDK版本中可能不可用。在dbgeng.dll不存在该文件的Windows系统上，必须安装Windows调试工具才能使这些工具正常工作。在PATH环境变量中应包含的位置jvm.dll所使用的目标进程或从中故障转储文件被产生，例如位置的文件：set PATH=%JDK_HOME%\\jre\\bin\\client;%PATH%。</code></pre>"},{"title":"定时消息示例","excerpt":"","comments":1,"date":"2020-03-24T16:30:52.000Z","_content":"\n\n# 定时消息示例\n\n## 什么是定时消息\n\n预定的消息与正常的消息的不同之处在于，它们要等到指定的时间后才能传递。\n\nRocketMQ 支持定时消息，但是不支持任意时间精度，仅支持特定的 level，例如定时 5s， 10s， 1m 等。其中，level=0 级表示不延时，level=1 表示 1 级延时，level=2 表示 2 级延时，以此类推。\n\n**如何配置：**\n在服务器端（rocketmq-broker端）的属性配置文件中加入以下行：\n\n```txt\nmessageDelayLevel=1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h\n```\n\n描述了各级别与延时时间的对应映射关系。\n\n这个配置项配置了从1级开始各级延时的时间，如1表示延时1s，2表示延时5s，14表示延时10m，可以修改这个指定级别的延时时间。\n\n- 时间单位支持：s、m、h、d，分别表示秒、分、时、天\n- 默认值就是上面声明的，可手工调整\n- 默认值已经够用，不建议调整\n\n## 应用\n\n- 启动消费者等待传入的订阅消息\n\n```java\nimport org.apache.rocketmq.client.consumer.DefaultMQPushConsumer;\n import org.apache.rocketmq.client.consumer.listener.ConsumeConcurrentlyContext;\n import org.apache.rocketmq.client.consumer.listener.ConsumeConcurrentlyStatus;\n import org.apache.rocketmq.client.consumer.listener.MessageListenerConcurrently;\n import org.apache.rocketmq.common.message.MessageExt;\n import java.util.List;\n    \n public class ScheduledMessageConsumer {\n    \n     public static void main(String[] args) throws Exception {\n         // Instantiate message consumer\n         DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(\"ExampleConsumer\");\n         // Subscribe topics\n         consumer.subscribe(\"TestTopic\", \"*\");\n         // Register message listener\n         consumer.registerMessageListener(new MessageListenerConcurrently() {\n             @Override\n             public ConsumeConcurrentlyStatus consumeMessage(List<MessageExt> messages, ConsumeConcurrentlyContext context) {\n                 for (MessageExt message : messages) {\n                     // Print approximate delay time period\n                     System.out.println(\"Receive message[msgId=\" + message.getMsgId() + \"] \"\n                             + (System.currentTimeMillis() - message.getStoreTimestamp()) + \"ms later\");\n                 }\n                 return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;\n             }\n         });\n         // Launch consumer\n         consumer.start();\n     }\n }\n```\n\n- 发送定时消息\n\n```java\nimport org.apache.rocketmq.client.producer.DefaultMQProducer;\nimport org.apache.rocketmq.common.message.Message;\npublic class ScheduledMessageProducer {\n     public static void main(String[] args) throws Exception {\n         // Instantiate a producer to send scheduled messages\n         DefaultMQProducer producer = new DefaultMQProducer(\"ExampleProducerGroup\");\n         // Launch producer\n         producer.start();\n         int totalMessagesToSend = 100;\n         for (int i = 0; i < totalMessagesToSend; i++) {\n             Message message = new Message(\"TestTopic\", (\"Hello scheduled message \" + i).getBytes());\n             // This message will be delivered to consumer 10 seconds later.\n             message.setDelayTimeLevel(3);\n             // Send the message\n             producer.send(message);\n         }    \n         // Shutdown producer after use.\n         producer.shutdown();\n     }\n }\n```\n\n- 验证\n\n可以看到，消息存储10s后才会消费消息。\n","source":"_posts/2020-03-25-kongzheng1993-RocketMQ定时消息示例.md","raw":"---\ntitle: 定时消息示例\nexcerpt: ''\ntags: [MQ]\ncategories: [MQ]\ncomments: true\ndate: 2020-03-25 00:30:52\n---\n\n\n# 定时消息示例\n\n## 什么是定时消息\n\n预定的消息与正常的消息的不同之处在于，它们要等到指定的时间后才能传递。\n\nRocketMQ 支持定时消息，但是不支持任意时间精度，仅支持特定的 level，例如定时 5s， 10s， 1m 等。其中，level=0 级表示不延时，level=1 表示 1 级延时，level=2 表示 2 级延时，以此类推。\n\n**如何配置：**\n在服务器端（rocketmq-broker端）的属性配置文件中加入以下行：\n\n```txt\nmessageDelayLevel=1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h\n```\n\n描述了各级别与延时时间的对应映射关系。\n\n这个配置项配置了从1级开始各级延时的时间，如1表示延时1s，2表示延时5s，14表示延时10m，可以修改这个指定级别的延时时间。\n\n- 时间单位支持：s、m、h、d，分别表示秒、分、时、天\n- 默认值就是上面声明的，可手工调整\n- 默认值已经够用，不建议调整\n\n## 应用\n\n- 启动消费者等待传入的订阅消息\n\n```java\nimport org.apache.rocketmq.client.consumer.DefaultMQPushConsumer;\n import org.apache.rocketmq.client.consumer.listener.ConsumeConcurrentlyContext;\n import org.apache.rocketmq.client.consumer.listener.ConsumeConcurrentlyStatus;\n import org.apache.rocketmq.client.consumer.listener.MessageListenerConcurrently;\n import org.apache.rocketmq.common.message.MessageExt;\n import java.util.List;\n    \n public class ScheduledMessageConsumer {\n    \n     public static void main(String[] args) throws Exception {\n         // Instantiate message consumer\n         DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(\"ExampleConsumer\");\n         // Subscribe topics\n         consumer.subscribe(\"TestTopic\", \"*\");\n         // Register message listener\n         consumer.registerMessageListener(new MessageListenerConcurrently() {\n             @Override\n             public ConsumeConcurrentlyStatus consumeMessage(List<MessageExt> messages, ConsumeConcurrentlyContext context) {\n                 for (MessageExt message : messages) {\n                     // Print approximate delay time period\n                     System.out.println(\"Receive message[msgId=\" + message.getMsgId() + \"] \"\n                             + (System.currentTimeMillis() - message.getStoreTimestamp()) + \"ms later\");\n                 }\n                 return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;\n             }\n         });\n         // Launch consumer\n         consumer.start();\n     }\n }\n```\n\n- 发送定时消息\n\n```java\nimport org.apache.rocketmq.client.producer.DefaultMQProducer;\nimport org.apache.rocketmq.common.message.Message;\npublic class ScheduledMessageProducer {\n     public static void main(String[] args) throws Exception {\n         // Instantiate a producer to send scheduled messages\n         DefaultMQProducer producer = new DefaultMQProducer(\"ExampleProducerGroup\");\n         // Launch producer\n         producer.start();\n         int totalMessagesToSend = 100;\n         for (int i = 0; i < totalMessagesToSend; i++) {\n             Message message = new Message(\"TestTopic\", (\"Hello scheduled message \" + i).getBytes());\n             // This message will be delivered to consumer 10 seconds later.\n             message.setDelayTimeLevel(3);\n             // Send the message\n             producer.send(message);\n         }    \n         // Shutdown producer after use.\n         producer.shutdown();\n     }\n }\n```\n\n- 验证\n\n可以看到，消息存储10s后才会消费消息。\n","slug":"kongzheng1993-RocketMQ定时消息示例","published":1,"updated":"2023-03-08T07:05:58.783Z","layout":"post","photos":[],"link":"","_id":"clg0k2adl0024t26fzx9xc7s9","content":"<h1 id=\"定时消息示例\"><a href=\"#定时消息示例\" class=\"headerlink\" title=\"定时消息示例\"></a>定时消息示例</h1><h2 id=\"什么是定时消息\"><a href=\"#什么是定时消息\" class=\"headerlink\" title=\"什么是定时消息\"></a>什么是定时消息</h2><p>预定的消息与正常的消息的不同之处在于，它们要等到指定的时间后才能传递。</p>\n<p>RocketMQ 支持定时消息，但是不支持任意时间精度，仅支持特定的 level，例如定时 5s， 10s， 1m 等。其中，level=0 级表示不延时，level=1 表示 1 级延时，level=2 表示 2 级延时，以此类推。</p>\n<p><strong>如何配置：</strong><br>在服务器端（rocketmq-broker端）的属性配置文件中加入以下行：</p>\n<pre><code class=\"txt\">messageDelayLevel=1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h</code></pre>\n<p>描述了各级别与延时时间的对应映射关系。</p>\n<p>这个配置项配置了从1级开始各级延时的时间，如1表示延时1s，2表示延时5s，14表示延时10m，可以修改这个指定级别的延时时间。</p>\n<ul>\n<li>时间单位支持：s、m、h、d，分别表示秒、分、时、天</li>\n<li>默认值就是上面声明的，可手工调整</li>\n<li>默认值已经够用，不建议调整</li>\n</ul>\n<h2 id=\"应用\"><a href=\"#应用\" class=\"headerlink\" title=\"应用\"></a>应用</h2><ul>\n<li>启动消费者等待传入的订阅消息</li>\n</ul>\n<pre><code class=\"java\">import org.apache.rocketmq.client.consumer.DefaultMQPushConsumer;\n import org.apache.rocketmq.client.consumer.listener.ConsumeConcurrentlyContext;\n import org.apache.rocketmq.client.consumer.listener.ConsumeConcurrentlyStatus;\n import org.apache.rocketmq.client.consumer.listener.MessageListenerConcurrently;\n import org.apache.rocketmq.common.message.MessageExt;\n import java.util.List;\n\n public class ScheduledMessageConsumer {\n\n     public static void main(String[] args) throws Exception {\n         // Instantiate message consumer\n         DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(&quot;ExampleConsumer&quot;);\n         // Subscribe topics\n         consumer.subscribe(&quot;TestTopic&quot;, &quot;*&quot;);\n         // Register message listener\n         consumer.registerMessageListener(new MessageListenerConcurrently() {\n             @Override\n             public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; messages, ConsumeConcurrentlyContext context) {\n                 for (MessageExt message : messages) {\n                     // Print approximate delay time period\n                     System.out.println(&quot;Receive message[msgId=&quot; + message.getMsgId() + &quot;] &quot;\n                             + (System.currentTimeMillis() - message.getStoreTimestamp()) + &quot;ms later&quot;);\n                 }\n                 return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;\n             }\n         });\n         // Launch consumer\n         consumer.start();\n     }\n }</code></pre>\n<ul>\n<li>发送定时消息</li>\n</ul>\n<pre><code class=\"java\">import org.apache.rocketmq.client.producer.DefaultMQProducer;\nimport org.apache.rocketmq.common.message.Message;\npublic class ScheduledMessageProducer {\n     public static void main(String[] args) throws Exception {\n         // Instantiate a producer to send scheduled messages\n         DefaultMQProducer producer = new DefaultMQProducer(&quot;ExampleProducerGroup&quot;);\n         // Launch producer\n         producer.start();\n         int totalMessagesToSend = 100;\n         for (int i = 0; i &lt; totalMessagesToSend; i++) {\n             Message message = new Message(&quot;TestTopic&quot;, (&quot;Hello scheduled message &quot; + i).getBytes());\n             // This message will be delivered to consumer 10 seconds later.\n             message.setDelayTimeLevel(3);\n             // Send the message\n             producer.send(message);\n         }    \n         // Shutdown producer after use.\n         producer.shutdown();\n     }\n }</code></pre>\n<ul>\n<li>验证</li>\n</ul>\n<p>可以看到，消息存储10s后才会消费消息。</p>\n","site":{"data":{}},"more":"<h1 id=\"定时消息示例\"><a href=\"#定时消息示例\" class=\"headerlink\" title=\"定时消息示例\"></a>定时消息示例</h1><h2 id=\"什么是定时消息\"><a href=\"#什么是定时消息\" class=\"headerlink\" title=\"什么是定时消息\"></a>什么是定时消息</h2><p>预定的消息与正常的消息的不同之处在于，它们要等到指定的时间后才能传递。</p>\n<p>RocketMQ 支持定时消息，但是不支持任意时间精度，仅支持特定的 level，例如定时 5s， 10s， 1m 等。其中，level=0 级表示不延时，level=1 表示 1 级延时，level=2 表示 2 级延时，以此类推。</p>\n<p><strong>如何配置：</strong><br>在服务器端（rocketmq-broker端）的属性配置文件中加入以下行：</p>\n<pre><code class=\"txt\">messageDelayLevel=1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h</code></pre>\n<p>描述了各级别与延时时间的对应映射关系。</p>\n<p>这个配置项配置了从1级开始各级延时的时间，如1表示延时1s，2表示延时5s，14表示延时10m，可以修改这个指定级别的延时时间。</p>\n<ul>\n<li>时间单位支持：s、m、h、d，分别表示秒、分、时、天</li>\n<li>默认值就是上面声明的，可手工调整</li>\n<li>默认值已经够用，不建议调整</li>\n</ul>\n<h2 id=\"应用\"><a href=\"#应用\" class=\"headerlink\" title=\"应用\"></a>应用</h2><ul>\n<li>启动消费者等待传入的订阅消息</li>\n</ul>\n<pre><code class=\"java\">import org.apache.rocketmq.client.consumer.DefaultMQPushConsumer;\n import org.apache.rocketmq.client.consumer.listener.ConsumeConcurrentlyContext;\n import org.apache.rocketmq.client.consumer.listener.ConsumeConcurrentlyStatus;\n import org.apache.rocketmq.client.consumer.listener.MessageListenerConcurrently;\n import org.apache.rocketmq.common.message.MessageExt;\n import java.util.List;\n\n public class ScheduledMessageConsumer {\n\n     public static void main(String[] args) throws Exception {\n         // Instantiate message consumer\n         DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(&quot;ExampleConsumer&quot;);\n         // Subscribe topics\n         consumer.subscribe(&quot;TestTopic&quot;, &quot;*&quot;);\n         // Register message listener\n         consumer.registerMessageListener(new MessageListenerConcurrently() {\n             @Override\n             public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; messages, ConsumeConcurrentlyContext context) {\n                 for (MessageExt message : messages) {\n                     // Print approximate delay time period\n                     System.out.println(&quot;Receive message[msgId=&quot; + message.getMsgId() + &quot;] &quot;\n                             + (System.currentTimeMillis() - message.getStoreTimestamp()) + &quot;ms later&quot;);\n                 }\n                 return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;\n             }\n         });\n         // Launch consumer\n         consumer.start();\n     }\n }</code></pre>\n<ul>\n<li>发送定时消息</li>\n</ul>\n<pre><code class=\"java\">import org.apache.rocketmq.client.producer.DefaultMQProducer;\nimport org.apache.rocketmq.common.message.Message;\npublic class ScheduledMessageProducer {\n     public static void main(String[] args) throws Exception {\n         // Instantiate a producer to send scheduled messages\n         DefaultMQProducer producer = new DefaultMQProducer(&quot;ExampleProducerGroup&quot;);\n         // Launch producer\n         producer.start();\n         int totalMessagesToSend = 100;\n         for (int i = 0; i &lt; totalMessagesToSend; i++) {\n             Message message = new Message(&quot;TestTopic&quot;, (&quot;Hello scheduled message &quot; + i).getBytes());\n             // This message will be delivered to consumer 10 seconds later.\n             message.setDelayTimeLevel(3);\n             // Send the message\n             producer.send(message);\n         }    \n         // Shutdown producer after use.\n         producer.shutdown();\n     }\n }</code></pre>\n<ul>\n<li>验证</li>\n</ul>\n<p>可以看到，消息存储10s后才会消费消息。</p>\n"},{"title":"Future","excerpt":"","comments":1,"date":"2020-03-18T16:30:52.000Z","_content":"","source":"_posts/2020-03-19-kongzheng1993-Future.md","raw":"---\ntitle: Future\nexcerpt: ''\ntags: [Java]\ncategories: [Java]\ncomments: true\ndate: 2020-03-19 00:30:52\n---","slug":"kongzheng1993-Future","published":1,"updated":"2023-03-08T07:05:58.783Z","layout":"post","photos":[],"link":"","_id":"clg0k2adm0026t26f9iuzoj7b","content":"","site":{"data":{}},"more":""},{"title":"带你撸一台免费云服务器","excerpt":"","comments":1,"date":"2020-03-07T16:30:52.000Z","_content":"\n# 申请亚马逊AWS账户\n\n访问aws.amazon.com，注册账户\n\n<img src=\"1.png\">\n\n登陆成功后，进入AWS管理控制台\n\n如果没有梯子，可能会有点慢\n\n点击启动虚拟机，新建ec2\n\n<img src=\"2.png\">\n\n\n选择系统，我熟悉ubuntu，选择了ubuntu，注意符合条件的免费套餐\n\n<img src=\"3.png\">\n\n\n选择实例类型，注意符合条件的免费套餐，点击`审核和启动`\n<img src=\"5.png\">\n\n点击`启动`\n\n<img src=\"6.png\">\n\n\n选择创建新的密码对，输入一个密码对名称\n\n<img src=\"10.png\">\n\n\n点击下载密钥对，保存好，这是连接服务器需要的密钥文件。点击启动实例\n\n<img src=\"9.png\">\n\n启动成功，可以创建账单警报，以免费用超过免费套餐，点击`查看实例`\n\n<img src=\"11.png\">\n\n可以看到我们的实例状态时running\n\n<img src=\"12.png\">\n\n\n点击连接\n\n<img src=\"13.png\">\n\n复制命令本地执行即可\n\n","source":"_posts/2020-03-08-kongzheng1993-带你撸一台免费云服务器.md","raw":"---\ntitle: 带你撸一台免费云服务器\nexcerpt: ''\ntags: [other]\ncategories: [other]\ncomments: true\ndate: 2020-03-08 00:30:52\n---\n\n# 申请亚马逊AWS账户\n\n访问aws.amazon.com，注册账户\n\n<img src=\"1.png\">\n\n登陆成功后，进入AWS管理控制台\n\n如果没有梯子，可能会有点慢\n\n点击启动虚拟机，新建ec2\n\n<img src=\"2.png\">\n\n\n选择系统，我熟悉ubuntu，选择了ubuntu，注意符合条件的免费套餐\n\n<img src=\"3.png\">\n\n\n选择实例类型，注意符合条件的免费套餐，点击`审核和启动`\n<img src=\"5.png\">\n\n点击`启动`\n\n<img src=\"6.png\">\n\n\n选择创建新的密码对，输入一个密码对名称\n\n<img src=\"10.png\">\n\n\n点击下载密钥对，保存好，这是连接服务器需要的密钥文件。点击启动实例\n\n<img src=\"9.png\">\n\n启动成功，可以创建账单警报，以免费用超过免费套餐，点击`查看实例`\n\n<img src=\"11.png\">\n\n可以看到我们的实例状态时running\n\n<img src=\"12.png\">\n\n\n点击连接\n\n<img src=\"13.png\">\n\n复制命令本地执行即可\n\n","slug":"kongzheng1993-带你撸一台免费云服务器","published":1,"updated":"2023-03-08T07:05:58.777Z","layout":"post","photos":[],"link":"","_id":"clg0k2adn0029t26fxuhl9tfz","content":"<h1 id=\"申请亚马逊AWS账户\"><a href=\"#申请亚马逊AWS账户\" class=\"headerlink\" title=\"申请亚马逊AWS账户\"></a>申请亚马逊AWS账户</h1><p>访问aws.amazon.com，注册账户</p>\n<img src=\"/2020/03/08/kongzheng1993-带你撸一台免费云服务器/1.png\">\n\n<p>登陆成功后，进入AWS管理控制台</p>\n<p>如果没有梯子，可能会有点慢</p>\n<p>点击启动虚拟机，新建ec2</p>\n<img src=\"/2020/03/08/kongzheng1993-带你撸一台免费云服务器/2.png\">\n\n\n<p>选择系统，我熟悉ubuntu，选择了ubuntu，注意符合条件的免费套餐</p>\n<img src=\"/2020/03/08/kongzheng1993-带你撸一台免费云服务器/3.png\">\n\n\n<p>选择实例类型，注意符合条件的免费套餐，点击<code>审核和启动</code><br><img src=\"/2020/03/08/kongzheng1993-带你撸一台免费云服务器/5.png\"></p>\n<p>点击<code>启动</code></p>\n<img src=\"/2020/03/08/kongzheng1993-带你撸一台免费云服务器/6.png\">\n\n\n<p>选择创建新的密码对，输入一个密码对名称</p>\n<img src=\"/2020/03/08/kongzheng1993-带你撸一台免费云服务器/10.png\">\n\n\n<p>点击下载密钥对，保存好，这是连接服务器需要的密钥文件。点击启动实例</p>\n<img src=\"/2020/03/08/kongzheng1993-带你撸一台免费云服务器/9.png\">\n\n<p>启动成功，可以创建账单警报，以免费用超过免费套餐，点击<code>查看实例</code></p>\n<img src=\"/2020/03/08/kongzheng1993-带你撸一台免费云服务器/11.png\">\n\n<p>可以看到我们的实例状态时running</p>\n<img src=\"/2020/03/08/kongzheng1993-带你撸一台免费云服务器/12.png\">\n\n\n<p>点击连接</p>\n<img src=\"/2020/03/08/kongzheng1993-带你撸一台免费云服务器/13.png\">\n\n<p>复制命令本地执行即可</p>\n","site":{"data":{}},"more":"<h1 id=\"申请亚马逊AWS账户\"><a href=\"#申请亚马逊AWS账户\" class=\"headerlink\" title=\"申请亚马逊AWS账户\"></a>申请亚马逊AWS账户</h1><p>访问aws.amazon.com，注册账户</p>\n<img src=\"/2020/03/08/kongzheng1993-带你撸一台免费云服务器/1.png\">\n\n<p>登陆成功后，进入AWS管理控制台</p>\n<p>如果没有梯子，可能会有点慢</p>\n<p>点击启动虚拟机，新建ec2</p>\n<img src=\"/2020/03/08/kongzheng1993-带你撸一台免费云服务器/2.png\">\n\n\n<p>选择系统，我熟悉ubuntu，选择了ubuntu，注意符合条件的免费套餐</p>\n<img src=\"/2020/03/08/kongzheng1993-带你撸一台免费云服务器/3.png\">\n\n\n<p>选择实例类型，注意符合条件的免费套餐，点击<code>审核和启动</code><br><img src=\"/2020/03/08/kongzheng1993-带你撸一台免费云服务器/5.png\"></p>\n<p>点击<code>启动</code></p>\n<img src=\"/2020/03/08/kongzheng1993-带你撸一台免费云服务器/6.png\">\n\n\n<p>选择创建新的密码对，输入一个密码对名称</p>\n<img src=\"/2020/03/08/kongzheng1993-带你撸一台免费云服务器/10.png\">\n\n\n<p>点击下载密钥对，保存好，这是连接服务器需要的密钥文件。点击启动实例</p>\n<img src=\"/2020/03/08/kongzheng1993-带你撸一台免费云服务器/9.png\">\n\n<p>启动成功，可以创建账单警报，以免费用超过免费套餐，点击<code>查看实例</code></p>\n<img src=\"/2020/03/08/kongzheng1993-带你撸一台免费云服务器/11.png\">\n\n<p>可以看到我们的实例状态时running</p>\n<img src=\"/2020/03/08/kongzheng1993-带你撸一台免费云服务器/12.png\">\n\n\n<p>点击连接</p>\n<img src=\"/2020/03/08/kongzheng1993-带你撸一台免费云服务器/13.png\">\n\n<p>复制命令本地执行即可</p>\n"},{"title":"记一次老代码优化2","excerpt":"","comments":1,"top":2,"date":"2020-03-29T16:30:52.000Z","_content":"\n# 记一次老代码优化2\n\n## 又发现了一个问题\n\n上次的优化结果：\n\n- 老版本的转换方法用了204ms\n- 每次去查数据库因为要多次连接数据库进行查询操作，需要531ms\n- 而使用了缓存的方法，第一次我们还没有加载缓存，需要500ms，而第二次直接在缓存中读取，24ms，只用了之前方法的1/10。\n\n让我们看一下上次优化的版本：\n\n```java\npublic static String ospInOutParmConvert2(String str) {\n    Matcher m=p1.matcher(str);\n    String strTmp = \"\";\n    String strTmp1= \"\";\n    String nkKey = \"\";\n    String camelKey = \"\";\n    final Map<String, String> unSaveKeys = Maps.newHashMap();\n    while(m.find()){\n        strTmp = m.group();\n        nkKey = strTmp.replace(\"\\\"\", \"\").replace(\":\", \"\");\n        camelKey = nkCamelKeyCacheService.getCamelKeyByNKKey(nkKey);\n        if (StringUtils.isNotBlank(camelKey)) {\n            str = str.replace(nkKey, camelKey);\n            continue;\n        } else {\n            camelKey = nkKey.toLowerCase();\n            str = str.replace(strTmp, strTmp.toLowerCase());\n            if (StringUtil.isNotEmpty(strTmp) && strTmp != \"null\") {\n                strTmp1= strTmp.toLowerCase();\n                if (strTmp1.indexOf(\"_\") > 0) {\n                    String[] strTmp1s = strTmp1.split(\"_\");\n                    for(int i=0; i<strTmp1s.length-1; i++){\n                        int subInt = strTmp1.indexOf(\"_\");\n                        camelKey = camelKey.replace(strTmp1.substring(subInt,subInt + 2),strTmp1.substring(subInt + 1, subInt + 2).toUpperCase());\n                        if(strTmp1s.length>1){\n                            strTmp1 = strTmp1.substring(subInt+1);\n                        }\n                    }\n                    str = str.replace(nkKey, camelKey);\n                }\n                unSaveKeys.put(nkKey, camelKey);\n            }\n        }\n    }\n    if (unSaveKeys.size() > 0) {\n        new Thread(new Runnable() {\n            @Override\n            public void run() {\n                LocalJDBCUtil.addNkCamelKeys(unSaveKeys);\n            }\n        }).start();\n    }\n    return str;\n}\n```\n\n这一版没有对之前的算法进行优化，以为之前写代码的是个大佬，算法上应该没什么瑕疵。今天闲来无事仔细看了一下，发现一个问题：\n\n如果根据正则匹配到一个key，就进行转换。\n\n问题是，如果json中有`List<Map>`，那么list中的每条数据的map中的key都是相同的，每个都进行一遍运算会浪费很多资源。\n\n## 怎么优化\n\n这个问题是进行了不必要的运算，我们要记住哪些key已经计算并替换过了，当再次匹配到这些key的时候，直接跳过。\n\n```java\npublic static String ospInOutParmConvert(String str) {\n    Matcher m = p1.matcher(str);\n    String strTmp = \"\";//双引号+冒号的key\n    String strTmp1 = \"\";//转换为小写的双引号+冒号的key\n    String nkKey = \"\";//能开key\n    String camelKey = \"\";//驼峰key\n    final Map<String, String> unSaveKeys = Maps.newHashMap();\n    Set<String> finishKeys = Sets.newHashSet();\n    while (m.find()) {\n        strTmp = m.group();\n        nkKey = strTmp.replace(\"\\\"\", \"\").replace(\":\", \"\");\n        camelKey = nkCamelKeyCacheService.getCamelKeyByNKKey(nkKey);\n        if (finishKeys.contains(nkKey)) {\n            continue;//这个key已经替换过，跳过\n        } else if (StringUtils.isNotBlank(camelKey)) {\n            str = str.replace(\"\\\"\" + nkKey + \"\\\"\", \"\\\"\" + camelKey + \"\\\"\");\n            finishKeys.add(nkKey);\n            continue;\n        } else {\n            camelKey = nkKey.toLowerCase();//如果没有_，那么这里转成小写就处理完了\n            if (StringUtil.isNotEmpty(strTmp) && strTmp != \"null\") {\n                strTmp1 = strTmp.toLowerCase();\n                if (strTmp1.indexOf(\"_\") > 0) {\n                    String[] strTmp1s = strTmp1.split(\"_\");\n                    for (int i = 0; i < strTmp1s.length - 1; i++) {\n                        int subInt = strTmp1.indexOf(\"_\");\n                        camelKey = camelKey.replace(strTmp1.substring(subInt, subInt + 2), strTmp1.substring(subInt + 1, subInt + 2).toUpperCase());\n                        if (strTmp1s.length > 1) {\n                            strTmp1 = strTmp1.substring(subInt + 1);\n                        }\n                    }\n                }\n                str = str.replace(\"\\\"\" + nkKey + \"\\\"\", \"\\\"\" + camelKey + \"\\\"\");\n                finishKeys.add(nkKey);\n                unSaveKeys.put(nkKey, camelKey);\n            }\n        }\n    }\n    if (unSaveKeys.size() > 0) {\n        new Thread(new Runnable() {\n            @Override\n            public void run() {\n                LocalJDBCUtil.addNkCamelKeys(unSaveKeys);\n            }\n        }).start();\n    }\n    return str;\n}\n```\n\n在这一版本中我用了一个`finishKeys`的`Set`来存放已经转换过的key，在计算前判断这个key是不是包含在`finishKeys`中，如果包含，说明已经转换过，直接跳过。\n\n## 测试\n\n还是之前的测试用例。\n不过这次新方法第二次跑完的时间是17ms！！！","source":"_posts/2020-03-30-kongzheng1993-一次老代码优化2.md","raw":"---\ntitle: 记一次老代码优化2\nexcerpt: ''\ntags: [Java]\ncategories: [Java]\ncomments: true\ntop: 2\ndate: 2020-03-30 00:30:52\n---\n\n# 记一次老代码优化2\n\n## 又发现了一个问题\n\n上次的优化结果：\n\n- 老版本的转换方法用了204ms\n- 每次去查数据库因为要多次连接数据库进行查询操作，需要531ms\n- 而使用了缓存的方法，第一次我们还没有加载缓存，需要500ms，而第二次直接在缓存中读取，24ms，只用了之前方法的1/10。\n\n让我们看一下上次优化的版本：\n\n```java\npublic static String ospInOutParmConvert2(String str) {\n    Matcher m=p1.matcher(str);\n    String strTmp = \"\";\n    String strTmp1= \"\";\n    String nkKey = \"\";\n    String camelKey = \"\";\n    final Map<String, String> unSaveKeys = Maps.newHashMap();\n    while(m.find()){\n        strTmp = m.group();\n        nkKey = strTmp.replace(\"\\\"\", \"\").replace(\":\", \"\");\n        camelKey = nkCamelKeyCacheService.getCamelKeyByNKKey(nkKey);\n        if (StringUtils.isNotBlank(camelKey)) {\n            str = str.replace(nkKey, camelKey);\n            continue;\n        } else {\n            camelKey = nkKey.toLowerCase();\n            str = str.replace(strTmp, strTmp.toLowerCase());\n            if (StringUtil.isNotEmpty(strTmp) && strTmp != \"null\") {\n                strTmp1= strTmp.toLowerCase();\n                if (strTmp1.indexOf(\"_\") > 0) {\n                    String[] strTmp1s = strTmp1.split(\"_\");\n                    for(int i=0; i<strTmp1s.length-1; i++){\n                        int subInt = strTmp1.indexOf(\"_\");\n                        camelKey = camelKey.replace(strTmp1.substring(subInt,subInt + 2),strTmp1.substring(subInt + 1, subInt + 2).toUpperCase());\n                        if(strTmp1s.length>1){\n                            strTmp1 = strTmp1.substring(subInt+1);\n                        }\n                    }\n                    str = str.replace(nkKey, camelKey);\n                }\n                unSaveKeys.put(nkKey, camelKey);\n            }\n        }\n    }\n    if (unSaveKeys.size() > 0) {\n        new Thread(new Runnable() {\n            @Override\n            public void run() {\n                LocalJDBCUtil.addNkCamelKeys(unSaveKeys);\n            }\n        }).start();\n    }\n    return str;\n}\n```\n\n这一版没有对之前的算法进行优化，以为之前写代码的是个大佬，算法上应该没什么瑕疵。今天闲来无事仔细看了一下，发现一个问题：\n\n如果根据正则匹配到一个key，就进行转换。\n\n问题是，如果json中有`List<Map>`，那么list中的每条数据的map中的key都是相同的，每个都进行一遍运算会浪费很多资源。\n\n## 怎么优化\n\n这个问题是进行了不必要的运算，我们要记住哪些key已经计算并替换过了，当再次匹配到这些key的时候，直接跳过。\n\n```java\npublic static String ospInOutParmConvert(String str) {\n    Matcher m = p1.matcher(str);\n    String strTmp = \"\";//双引号+冒号的key\n    String strTmp1 = \"\";//转换为小写的双引号+冒号的key\n    String nkKey = \"\";//能开key\n    String camelKey = \"\";//驼峰key\n    final Map<String, String> unSaveKeys = Maps.newHashMap();\n    Set<String> finishKeys = Sets.newHashSet();\n    while (m.find()) {\n        strTmp = m.group();\n        nkKey = strTmp.replace(\"\\\"\", \"\").replace(\":\", \"\");\n        camelKey = nkCamelKeyCacheService.getCamelKeyByNKKey(nkKey);\n        if (finishKeys.contains(nkKey)) {\n            continue;//这个key已经替换过，跳过\n        } else if (StringUtils.isNotBlank(camelKey)) {\n            str = str.replace(\"\\\"\" + nkKey + \"\\\"\", \"\\\"\" + camelKey + \"\\\"\");\n            finishKeys.add(nkKey);\n            continue;\n        } else {\n            camelKey = nkKey.toLowerCase();//如果没有_，那么这里转成小写就处理完了\n            if (StringUtil.isNotEmpty(strTmp) && strTmp != \"null\") {\n                strTmp1 = strTmp.toLowerCase();\n                if (strTmp1.indexOf(\"_\") > 0) {\n                    String[] strTmp1s = strTmp1.split(\"_\");\n                    for (int i = 0; i < strTmp1s.length - 1; i++) {\n                        int subInt = strTmp1.indexOf(\"_\");\n                        camelKey = camelKey.replace(strTmp1.substring(subInt, subInt + 2), strTmp1.substring(subInt + 1, subInt + 2).toUpperCase());\n                        if (strTmp1s.length > 1) {\n                            strTmp1 = strTmp1.substring(subInt + 1);\n                        }\n                    }\n                }\n                str = str.replace(\"\\\"\" + nkKey + \"\\\"\", \"\\\"\" + camelKey + \"\\\"\");\n                finishKeys.add(nkKey);\n                unSaveKeys.put(nkKey, camelKey);\n            }\n        }\n    }\n    if (unSaveKeys.size() > 0) {\n        new Thread(new Runnable() {\n            @Override\n            public void run() {\n                LocalJDBCUtil.addNkCamelKeys(unSaveKeys);\n            }\n        }).start();\n    }\n    return str;\n}\n```\n\n在这一版本中我用了一个`finishKeys`的`Set`来存放已经转换过的key，在计算前判断这个key是不是包含在`finishKeys`中，如果包含，说明已经转换过，直接跳过。\n\n## 测试\n\n还是之前的测试用例。\n不过这次新方法第二次跑完的时间是17ms！！！","slug":"kongzheng1993-一次老代码优化2","published":1,"updated":"2023-03-08T07:05:58.783Z","layout":"post","photos":[],"link":"","_id":"clg0k2adn002ct26fbii4b5z1","content":"<h1 id=\"记一次老代码优化2\"><a href=\"#记一次老代码优化2\" class=\"headerlink\" title=\"记一次老代码优化2\"></a>记一次老代码优化2</h1><h2 id=\"又发现了一个问题\"><a href=\"#又发现了一个问题\" class=\"headerlink\" title=\"又发现了一个问题\"></a>又发现了一个问题</h2><p>上次的优化结果：</p>\n<ul>\n<li>老版本的转换方法用了204ms</li>\n<li>每次去查数据库因为要多次连接数据库进行查询操作，需要531ms</li>\n<li>而使用了缓存的方法，第一次我们还没有加载缓存，需要500ms，而第二次直接在缓存中读取，24ms，只用了之前方法的1/10。</li>\n</ul>\n<p>让我们看一下上次优化的版本：</p>\n<pre><code class=\"java\">public static String ospInOutParmConvert2(String str) {\n    Matcher m=p1.matcher(str);\n    String strTmp = &quot;&quot;;\n    String strTmp1= &quot;&quot;;\n    String nkKey = &quot;&quot;;\n    String camelKey = &quot;&quot;;\n    final Map&lt;String, String&gt; unSaveKeys = Maps.newHashMap();\n    while(m.find()){\n        strTmp = m.group();\n        nkKey = strTmp.replace(&quot;\\&quot;&quot;, &quot;&quot;).replace(&quot;:&quot;, &quot;&quot;);\n        camelKey = nkCamelKeyCacheService.getCamelKeyByNKKey(nkKey);\n        if (StringUtils.isNotBlank(camelKey)) {\n            str = str.replace(nkKey, camelKey);\n            continue;\n        } else {\n            camelKey = nkKey.toLowerCase();\n            str = str.replace(strTmp, strTmp.toLowerCase());\n            if (StringUtil.isNotEmpty(strTmp) &amp;&amp; strTmp != &quot;null&quot;) {\n                strTmp1= strTmp.toLowerCase();\n                if (strTmp1.indexOf(&quot;_&quot;) &gt; 0) {\n                    String[] strTmp1s = strTmp1.split(&quot;_&quot;);\n                    for(int i=0; i&lt;strTmp1s.length-1; i++){\n                        int subInt = strTmp1.indexOf(&quot;_&quot;);\n                        camelKey = camelKey.replace(strTmp1.substring(subInt,subInt + 2),strTmp1.substring(subInt + 1, subInt + 2).toUpperCase());\n                        if(strTmp1s.length&gt;1){\n                            strTmp1 = strTmp1.substring(subInt+1);\n                        }\n                    }\n                    str = str.replace(nkKey, camelKey);\n                }\n                unSaveKeys.put(nkKey, camelKey);\n            }\n        }\n    }\n    if (unSaveKeys.size() &gt; 0) {\n        new Thread(new Runnable() {\n            @Override\n            public void run() {\n                LocalJDBCUtil.addNkCamelKeys(unSaveKeys);\n            }\n        }).start();\n    }\n    return str;\n}</code></pre>\n<p>这一版没有对之前的算法进行优化，以为之前写代码的是个大佬，算法上应该没什么瑕疵。今天闲来无事仔细看了一下，发现一个问题：</p>\n<p>如果根据正则匹配到一个key，就进行转换。</p>\n<p>问题是，如果json中有<code>List&lt;Map&gt;</code>，那么list中的每条数据的map中的key都是相同的，每个都进行一遍运算会浪费很多资源。</p>\n<h2 id=\"怎么优化\"><a href=\"#怎么优化\" class=\"headerlink\" title=\"怎么优化\"></a>怎么优化</h2><p>这个问题是进行了不必要的运算，我们要记住哪些key已经计算并替换过了，当再次匹配到这些key的时候，直接跳过。</p>\n<pre><code class=\"java\">public static String ospInOutParmConvert(String str) {\n    Matcher m = p1.matcher(str);\n    String strTmp = &quot;&quot;;//双引号+冒号的key\n    String strTmp1 = &quot;&quot;;//转换为小写的双引号+冒号的key\n    String nkKey = &quot;&quot;;//能开key\n    String camelKey = &quot;&quot;;//驼峰key\n    final Map&lt;String, String&gt; unSaveKeys = Maps.newHashMap();\n    Set&lt;String&gt; finishKeys = Sets.newHashSet();\n    while (m.find()) {\n        strTmp = m.group();\n        nkKey = strTmp.replace(&quot;\\&quot;&quot;, &quot;&quot;).replace(&quot;:&quot;, &quot;&quot;);\n        camelKey = nkCamelKeyCacheService.getCamelKeyByNKKey(nkKey);\n        if (finishKeys.contains(nkKey)) {\n            continue;//这个key已经替换过，跳过\n        } else if (StringUtils.isNotBlank(camelKey)) {\n            str = str.replace(&quot;\\&quot;&quot; + nkKey + &quot;\\&quot;&quot;, &quot;\\&quot;&quot; + camelKey + &quot;\\&quot;&quot;);\n            finishKeys.add(nkKey);\n            continue;\n        } else {\n            camelKey = nkKey.toLowerCase();//如果没有_，那么这里转成小写就处理完了\n            if (StringUtil.isNotEmpty(strTmp) &amp;&amp; strTmp != &quot;null&quot;) {\n                strTmp1 = strTmp.toLowerCase();\n                if (strTmp1.indexOf(&quot;_&quot;) &gt; 0) {\n                    String[] strTmp1s = strTmp1.split(&quot;_&quot;);\n                    for (int i = 0; i &lt; strTmp1s.length - 1; i++) {\n                        int subInt = strTmp1.indexOf(&quot;_&quot;);\n                        camelKey = camelKey.replace(strTmp1.substring(subInt, subInt + 2), strTmp1.substring(subInt + 1, subInt + 2).toUpperCase());\n                        if (strTmp1s.length &gt; 1) {\n                            strTmp1 = strTmp1.substring(subInt + 1);\n                        }\n                    }\n                }\n                str = str.replace(&quot;\\&quot;&quot; + nkKey + &quot;\\&quot;&quot;, &quot;\\&quot;&quot; + camelKey + &quot;\\&quot;&quot;);\n                finishKeys.add(nkKey);\n                unSaveKeys.put(nkKey, camelKey);\n            }\n        }\n    }\n    if (unSaveKeys.size() &gt; 0) {\n        new Thread(new Runnable() {\n            @Override\n            public void run() {\n                LocalJDBCUtil.addNkCamelKeys(unSaveKeys);\n            }\n        }).start();\n    }\n    return str;\n}</code></pre>\n<p>在这一版本中我用了一个<code>finishKeys</code>的<code>Set</code>来存放已经转换过的key，在计算前判断这个key是不是包含在<code>finishKeys</code>中，如果包含，说明已经转换过，直接跳过。</p>\n<h2 id=\"测试\"><a href=\"#测试\" class=\"headerlink\" title=\"测试\"></a>测试</h2><p>还是之前的测试用例。<br>不过这次新方法第二次跑完的时间是17ms！！！</p>\n","site":{"data":{}},"more":"<h1 id=\"记一次老代码优化2\"><a href=\"#记一次老代码优化2\" class=\"headerlink\" title=\"记一次老代码优化2\"></a>记一次老代码优化2</h1><h2 id=\"又发现了一个问题\"><a href=\"#又发现了一个问题\" class=\"headerlink\" title=\"又发现了一个问题\"></a>又发现了一个问题</h2><p>上次的优化结果：</p>\n<ul>\n<li>老版本的转换方法用了204ms</li>\n<li>每次去查数据库因为要多次连接数据库进行查询操作，需要531ms</li>\n<li>而使用了缓存的方法，第一次我们还没有加载缓存，需要500ms，而第二次直接在缓存中读取，24ms，只用了之前方法的1/10。</li>\n</ul>\n<p>让我们看一下上次优化的版本：</p>\n<pre><code class=\"java\">public static String ospInOutParmConvert2(String str) {\n    Matcher m=p1.matcher(str);\n    String strTmp = &quot;&quot;;\n    String strTmp1= &quot;&quot;;\n    String nkKey = &quot;&quot;;\n    String camelKey = &quot;&quot;;\n    final Map&lt;String, String&gt; unSaveKeys = Maps.newHashMap();\n    while(m.find()){\n        strTmp = m.group();\n        nkKey = strTmp.replace(&quot;\\&quot;&quot;, &quot;&quot;).replace(&quot;:&quot;, &quot;&quot;);\n        camelKey = nkCamelKeyCacheService.getCamelKeyByNKKey(nkKey);\n        if (StringUtils.isNotBlank(camelKey)) {\n            str = str.replace(nkKey, camelKey);\n            continue;\n        } else {\n            camelKey = nkKey.toLowerCase();\n            str = str.replace(strTmp, strTmp.toLowerCase());\n            if (StringUtil.isNotEmpty(strTmp) &amp;&amp; strTmp != &quot;null&quot;) {\n                strTmp1= strTmp.toLowerCase();\n                if (strTmp1.indexOf(&quot;_&quot;) &gt; 0) {\n                    String[] strTmp1s = strTmp1.split(&quot;_&quot;);\n                    for(int i=0; i&lt;strTmp1s.length-1; i++){\n                        int subInt = strTmp1.indexOf(&quot;_&quot;);\n                        camelKey = camelKey.replace(strTmp1.substring(subInt,subInt + 2),strTmp1.substring(subInt + 1, subInt + 2).toUpperCase());\n                        if(strTmp1s.length&gt;1){\n                            strTmp1 = strTmp1.substring(subInt+1);\n                        }\n                    }\n                    str = str.replace(nkKey, camelKey);\n                }\n                unSaveKeys.put(nkKey, camelKey);\n            }\n        }\n    }\n    if (unSaveKeys.size() &gt; 0) {\n        new Thread(new Runnable() {\n            @Override\n            public void run() {\n                LocalJDBCUtil.addNkCamelKeys(unSaveKeys);\n            }\n        }).start();\n    }\n    return str;\n}</code></pre>\n<p>这一版没有对之前的算法进行优化，以为之前写代码的是个大佬，算法上应该没什么瑕疵。今天闲来无事仔细看了一下，发现一个问题：</p>\n<p>如果根据正则匹配到一个key，就进行转换。</p>\n<p>问题是，如果json中有<code>List&lt;Map&gt;</code>，那么list中的每条数据的map中的key都是相同的，每个都进行一遍运算会浪费很多资源。</p>\n<h2 id=\"怎么优化\"><a href=\"#怎么优化\" class=\"headerlink\" title=\"怎么优化\"></a>怎么优化</h2><p>这个问题是进行了不必要的运算，我们要记住哪些key已经计算并替换过了，当再次匹配到这些key的时候，直接跳过。</p>\n<pre><code class=\"java\">public static String ospInOutParmConvert(String str) {\n    Matcher m = p1.matcher(str);\n    String strTmp = &quot;&quot;;//双引号+冒号的key\n    String strTmp1 = &quot;&quot;;//转换为小写的双引号+冒号的key\n    String nkKey = &quot;&quot;;//能开key\n    String camelKey = &quot;&quot;;//驼峰key\n    final Map&lt;String, String&gt; unSaveKeys = Maps.newHashMap();\n    Set&lt;String&gt; finishKeys = Sets.newHashSet();\n    while (m.find()) {\n        strTmp = m.group();\n        nkKey = strTmp.replace(&quot;\\&quot;&quot;, &quot;&quot;).replace(&quot;:&quot;, &quot;&quot;);\n        camelKey = nkCamelKeyCacheService.getCamelKeyByNKKey(nkKey);\n        if (finishKeys.contains(nkKey)) {\n            continue;//这个key已经替换过，跳过\n        } else if (StringUtils.isNotBlank(camelKey)) {\n            str = str.replace(&quot;\\&quot;&quot; + nkKey + &quot;\\&quot;&quot;, &quot;\\&quot;&quot; + camelKey + &quot;\\&quot;&quot;);\n            finishKeys.add(nkKey);\n            continue;\n        } else {\n            camelKey = nkKey.toLowerCase();//如果没有_，那么这里转成小写就处理完了\n            if (StringUtil.isNotEmpty(strTmp) &amp;&amp; strTmp != &quot;null&quot;) {\n                strTmp1 = strTmp.toLowerCase();\n                if (strTmp1.indexOf(&quot;_&quot;) &gt; 0) {\n                    String[] strTmp1s = strTmp1.split(&quot;_&quot;);\n                    for (int i = 0; i &lt; strTmp1s.length - 1; i++) {\n                        int subInt = strTmp1.indexOf(&quot;_&quot;);\n                        camelKey = camelKey.replace(strTmp1.substring(subInt, subInt + 2), strTmp1.substring(subInt + 1, subInt + 2).toUpperCase());\n                        if (strTmp1s.length &gt; 1) {\n                            strTmp1 = strTmp1.substring(subInt + 1);\n                        }\n                    }\n                }\n                str = str.replace(&quot;\\&quot;&quot; + nkKey + &quot;\\&quot;&quot;, &quot;\\&quot;&quot; + camelKey + &quot;\\&quot;&quot;);\n                finishKeys.add(nkKey);\n                unSaveKeys.put(nkKey, camelKey);\n            }\n        }\n    }\n    if (unSaveKeys.size() &gt; 0) {\n        new Thread(new Runnable() {\n            @Override\n            public void run() {\n                LocalJDBCUtil.addNkCamelKeys(unSaveKeys);\n            }\n        }).start();\n    }\n    return str;\n}</code></pre>\n<p>在这一版本中我用了一个<code>finishKeys</code>的<code>Set</code>来存放已经转换过的key，在计算前判断这个key是不是包含在<code>finishKeys</code>中，如果包含，说明已经转换过，直接跳过。</p>\n<h2 id=\"测试\"><a href=\"#测试\" class=\"headerlink\" title=\"测试\"></a>测试</h2><p>还是之前的测试用例。<br>不过这次新方法第二次跑完的时间是17ms！！！</p>\n"},{"title":"Thread和Runnable","excerpt":"","comments":1,"date":"2020-03-18T16:30:52.000Z","_content":"\n\n# Thread和Runnable\n\n我们都知道Java中创建线程有两种方式，继承Thread类和实现Runnable接口。其实呢，我们看了Thread的源码就能了解到：Thread实现了Runnable，其实也是个Runnable。\n\nThread的构造方法中有一个是：\n\n![image-20200319172854321](C:\\Users\\kongz\\AppData\\Roaming\\Typora\\typora-user-images\\image-20200319172854321.png)\n\n这里传入的是一个Runnable，而继续往下执行，到了最后也是执行的这个target的`run()`方法。\n\n如果我们不传入Runnable呢？\n\n![image-20200319173106843](C:\\Users\\kongz\\AppData\\Roaming\\Typora\\typora-user-images\\image-20200319173106843.png)\n\n可以看到这个方法target是null。最后执行的是Thread重写的`run()`方法。\n\n所以看到这里可以了解到：\n\n- Runnable就是个接口，写一个类实现Runnable接口，它并不能执行，它要提交到一个线程（Thread），在Thread实例化调用它的构造方法的时候，才会触发Runnable的run方法。\n\n- 继承Thread来创建线程，重写了`run()`方法，当我们实例化这个类的时候，将会调用到父类，也就是Thread的无参构造函数，也就会执行我们这里重写的`run()`方法了。而这里的Thread实现了Runnable接口，所以它其实也是个Runnable。\n\n## 重要属性\n\n### 优先级\n\n```java\nprivate int  priority;\npublic final static int MIN_PRIORITY = 1;\npublic final static int NORM_PRIORITY = 5;\npublic final static int MAX_PRIORITY = 10;\n   public final void setPriority(int newPriority) {\n        ThreadGroup g;\n        checkAccess();\n        if (newPriority > MAX_PRIORITY || newPriority < MIN_PRIORITY) {\n            throw new IllegalArgumentException();\n        }\n        if((g = getThreadGroup()) != null) {\n            if (newPriority > g.getMaxPriority()) {\n                newPriority = g.getMaxPriority();\n            }\n            setPriority0(priority = newPriority);\n        }\n    }\n    public final int getPriority() {\n        return priority;\n    }\n```\n\n### 线程的状态\n\n```java\npublic enum State {\n        NEW,\n        RUNNABLE,\n        BLOCKED,\n        WAITING,\n        TIMED_WAITING,\n        TERMINATED;\n    }\n      public State getState() {\n        return sun.misc.VM.toThreadState(threadStatus);\n    }\n```\n\n网上找到的图：\n\n![image-20200319181144600](C:\\Users\\kongz\\AppData\\Roaming\\Typora\\typora-user-images\\image-20200319181144600.png)\n\n### 主要方法\n\n- 本地方法获取当前线程\n\n  ```java\n  public static native Thread currentThread();\n  ```\n\n- run()\n\n  ```java\n  public void run() {\n          if (target != null) {\n              target.run();\n          }\n      }\n  ```\n\n  这里就是上面说的，如果是传入Runnable的话，这里target就不会是null了，如果没有传入target，就不会执行什么，但是一般我们不传入target，就会重写`run()`方法了。\n\n- start()\n\n  ```java\n  public synchronized void start() {\n          /**\n           * This method is not invoked for the main method thread or \"system\"\n           * group threads created/set up by the VM. Any new functionality added\n           * to this method in the future may have to also be added to the VM.\n           *\n           * A zero status value corresponds to state \"NEW\".\n           */\n          if (threadStatus != 0)\n              throw new IllegalThreadStateException();\n  \n          /* Notify the group that this thread is about to be started\n           * so that it can be added to the group's list of threads\n           * and the group's unstarted count can be decremented. */\n          group.add(this);\n  \n          boolean started = false;\n          try {\n              start0();\n              started = true;\n          } finally {\n              try {\n                  if (!started) {\n                      group.threadStartFailed(this);\n                  }\n              } catch (Throwable ignore) {\n                  /* do nothing. If start0 threw a Throwable then\n                    it will be passed up the call stack */\n              }\n          }\n      }\n  \n      private native void start0();\n  ```\n\n  这里会调用一个本地方法`start0()`，应该会起一个线程执行`run()`方法。\n\n- boolean interrupted() & void interrupt() & boolean isInterrupted()\n\n  **interrupt()**:中断本线程(将中断状态标记为true)\n  **isInterrupted()**:检测本线程是否已经中断 。如果已经中断，则返回true，否则false。中断状态不受该方法的影响。 如果中断调用时线程已经不处于活动状态，则返回false。\n  **interrupted()**:检测当前线程是否已经中断 。如果当前线程存在中断，返回true，并且修改标记为false。再调用isIterruoted()会返回false。如果当前线程没有中断标记，返回false，不会修改中断标记。\n\n- void sleep(long millis) & void sleep(long millis, int nanos)\n\n  ```java\n  public static native void sleep(long millis) throws InterruptedException;\n  \n      /**\n       * Causes the currently executing thread to sleep (temporarily cease\n       * execution) for the specified number of milliseconds plus the specified\n       * number of nanoseconds, subject to the precision and accuracy of system\n       * timers and schedulers. The thread does not lose ownership of any\n       * monitors.\n       *\n       * @param  millis\n       *         the length of time to sleep in milliseconds\n       *\n       * @param  nanos\n       *         {@code 0-999999} additional nanoseconds to sleep\n       *\n       * @throws  IllegalArgumentException\n       *          if the value of {@code millis} is negative, or the value of\n       *          {@code nanos} is not in the range {@code 0-999999}\n       *\n       * @throws  InterruptedException\n       *          if any thread has interrupted the current thread. The\n       *          <i>interrupted status</i> of the current thread is\n       *          cleared when this exception is thrown.\n       */\n      public static void sleep(long millis, int nanos)\n      throws InterruptedException {\n          if (millis < 0) {\n              throw new IllegalArgumentException(\"timeout value is negative\");\n          }\n  \n          if (nanos < 0 || nanos > 999999) {\n              throw new IllegalArgumentException(\n                                  \"nanosecond timeout value out of range\");\n          }\n  \n          if (nanos >= 500000 || (nanos != 0 && millis == 0)) {\n              millis++;\n          }\n  \n          sleep(millis);\n      }\n  ```\n\n  两个参数的sleep只是将nanos转为millis(四舍五入转换)，调用sleep(millis)方法。\n  sleep(millis)是本地方法，让当前线程休眠指定时间。\n  sleep不释放锁。\n\n- void join() & void join(long millis) & void join(long millis, int nanos)\n\n  将线程加入到当前线程中，使父线程等待子线程执行完毕再继续执行。\n\n  ","source":"_posts/2020-03-19-kongzheng1993-Thread和Runnable.md","raw":"---\ntitle: Thread和Runnable\nexcerpt: ''\ntags: [Java]\ncategories: [Java]\ncomments: true\ndate: 2020-03-19 00:30:52\n---\n\n\n# Thread和Runnable\n\n我们都知道Java中创建线程有两种方式，继承Thread类和实现Runnable接口。其实呢，我们看了Thread的源码就能了解到：Thread实现了Runnable，其实也是个Runnable。\n\nThread的构造方法中有一个是：\n\n![image-20200319172854321](C:\\Users\\kongz\\AppData\\Roaming\\Typora\\typora-user-images\\image-20200319172854321.png)\n\n这里传入的是一个Runnable，而继续往下执行，到了最后也是执行的这个target的`run()`方法。\n\n如果我们不传入Runnable呢？\n\n![image-20200319173106843](C:\\Users\\kongz\\AppData\\Roaming\\Typora\\typora-user-images\\image-20200319173106843.png)\n\n可以看到这个方法target是null。最后执行的是Thread重写的`run()`方法。\n\n所以看到这里可以了解到：\n\n- Runnable就是个接口，写一个类实现Runnable接口，它并不能执行，它要提交到一个线程（Thread），在Thread实例化调用它的构造方法的时候，才会触发Runnable的run方法。\n\n- 继承Thread来创建线程，重写了`run()`方法，当我们实例化这个类的时候，将会调用到父类，也就是Thread的无参构造函数，也就会执行我们这里重写的`run()`方法了。而这里的Thread实现了Runnable接口，所以它其实也是个Runnable。\n\n## 重要属性\n\n### 优先级\n\n```java\nprivate int  priority;\npublic final static int MIN_PRIORITY = 1;\npublic final static int NORM_PRIORITY = 5;\npublic final static int MAX_PRIORITY = 10;\n   public final void setPriority(int newPriority) {\n        ThreadGroup g;\n        checkAccess();\n        if (newPriority > MAX_PRIORITY || newPriority < MIN_PRIORITY) {\n            throw new IllegalArgumentException();\n        }\n        if((g = getThreadGroup()) != null) {\n            if (newPriority > g.getMaxPriority()) {\n                newPriority = g.getMaxPriority();\n            }\n            setPriority0(priority = newPriority);\n        }\n    }\n    public final int getPriority() {\n        return priority;\n    }\n```\n\n### 线程的状态\n\n```java\npublic enum State {\n        NEW,\n        RUNNABLE,\n        BLOCKED,\n        WAITING,\n        TIMED_WAITING,\n        TERMINATED;\n    }\n      public State getState() {\n        return sun.misc.VM.toThreadState(threadStatus);\n    }\n```\n\n网上找到的图：\n\n![image-20200319181144600](C:\\Users\\kongz\\AppData\\Roaming\\Typora\\typora-user-images\\image-20200319181144600.png)\n\n### 主要方法\n\n- 本地方法获取当前线程\n\n  ```java\n  public static native Thread currentThread();\n  ```\n\n- run()\n\n  ```java\n  public void run() {\n          if (target != null) {\n              target.run();\n          }\n      }\n  ```\n\n  这里就是上面说的，如果是传入Runnable的话，这里target就不会是null了，如果没有传入target，就不会执行什么，但是一般我们不传入target，就会重写`run()`方法了。\n\n- start()\n\n  ```java\n  public synchronized void start() {\n          /**\n           * This method is not invoked for the main method thread or \"system\"\n           * group threads created/set up by the VM. Any new functionality added\n           * to this method in the future may have to also be added to the VM.\n           *\n           * A zero status value corresponds to state \"NEW\".\n           */\n          if (threadStatus != 0)\n              throw new IllegalThreadStateException();\n  \n          /* Notify the group that this thread is about to be started\n           * so that it can be added to the group's list of threads\n           * and the group's unstarted count can be decremented. */\n          group.add(this);\n  \n          boolean started = false;\n          try {\n              start0();\n              started = true;\n          } finally {\n              try {\n                  if (!started) {\n                      group.threadStartFailed(this);\n                  }\n              } catch (Throwable ignore) {\n                  /* do nothing. If start0 threw a Throwable then\n                    it will be passed up the call stack */\n              }\n          }\n      }\n  \n      private native void start0();\n  ```\n\n  这里会调用一个本地方法`start0()`，应该会起一个线程执行`run()`方法。\n\n- boolean interrupted() & void interrupt() & boolean isInterrupted()\n\n  **interrupt()**:中断本线程(将中断状态标记为true)\n  **isInterrupted()**:检测本线程是否已经中断 。如果已经中断，则返回true，否则false。中断状态不受该方法的影响。 如果中断调用时线程已经不处于活动状态，则返回false。\n  **interrupted()**:检测当前线程是否已经中断 。如果当前线程存在中断，返回true，并且修改标记为false。再调用isIterruoted()会返回false。如果当前线程没有中断标记，返回false，不会修改中断标记。\n\n- void sleep(long millis) & void sleep(long millis, int nanos)\n\n  ```java\n  public static native void sleep(long millis) throws InterruptedException;\n  \n      /**\n       * Causes the currently executing thread to sleep (temporarily cease\n       * execution) for the specified number of milliseconds plus the specified\n       * number of nanoseconds, subject to the precision and accuracy of system\n       * timers and schedulers. The thread does not lose ownership of any\n       * monitors.\n       *\n       * @param  millis\n       *         the length of time to sleep in milliseconds\n       *\n       * @param  nanos\n       *         {@code 0-999999} additional nanoseconds to sleep\n       *\n       * @throws  IllegalArgumentException\n       *          if the value of {@code millis} is negative, or the value of\n       *          {@code nanos} is not in the range {@code 0-999999}\n       *\n       * @throws  InterruptedException\n       *          if any thread has interrupted the current thread. The\n       *          <i>interrupted status</i> of the current thread is\n       *          cleared when this exception is thrown.\n       */\n      public static void sleep(long millis, int nanos)\n      throws InterruptedException {\n          if (millis < 0) {\n              throw new IllegalArgumentException(\"timeout value is negative\");\n          }\n  \n          if (nanos < 0 || nanos > 999999) {\n              throw new IllegalArgumentException(\n                                  \"nanosecond timeout value out of range\");\n          }\n  \n          if (nanos >= 500000 || (nanos != 0 && millis == 0)) {\n              millis++;\n          }\n  \n          sleep(millis);\n      }\n  ```\n\n  两个参数的sleep只是将nanos转为millis(四舍五入转换)，调用sleep(millis)方法。\n  sleep(millis)是本地方法，让当前线程休眠指定时间。\n  sleep不释放锁。\n\n- void join() & void join(long millis) & void join(long millis, int nanos)\n\n  将线程加入到当前线程中，使父线程等待子线程执行完毕再继续执行。\n\n  ","slug":"kongzheng1993-Thread和Runnable","published":1,"updated":"2023-03-08T07:05:58.783Z","layout":"post","photos":[],"link":"","_id":"clg0k2ado002dt26fq7n6ir8m","content":"<h1 id=\"Thread和Runnable\"><a href=\"#Thread和Runnable\" class=\"headerlink\" title=\"Thread和Runnable\"></a>Thread和Runnable</h1><p>我们都知道Java中创建线程有两种方式，继承Thread类和实现Runnable接口。其实呢，我们看了Thread的源码就能了解到：Thread实现了Runnable，其实也是个Runnable。</p>\n<p>Thread的构造方法中有一个是：</p>\n<p><img src=\"/2020/03/19/kongzheng1993-Thread和Runnable/C:%5CUsers%5Ckongz%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200319172854321.png\" alt=\"image-20200319172854321\"></p>\n<p>这里传入的是一个Runnable，而继续往下执行，到了最后也是执行的这个target的<code>run()</code>方法。</p>\n<p>如果我们不传入Runnable呢？</p>\n<p><img src=\"/2020/03/19/kongzheng1993-Thread和Runnable/C:%5CUsers%5Ckongz%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200319173106843.png\" alt=\"image-20200319173106843\"></p>\n<p>可以看到这个方法target是null。最后执行的是Thread重写的<code>run()</code>方法。</p>\n<p>所以看到这里可以了解到：</p>\n<ul>\n<li><p>Runnable就是个接口，写一个类实现Runnable接口，它并不能执行，它要提交到一个线程（Thread），在Thread实例化调用它的构造方法的时候，才会触发Runnable的run方法。</p>\n</li>\n<li><p>继承Thread来创建线程，重写了<code>run()</code>方法，当我们实例化这个类的时候，将会调用到父类，也就是Thread的无参构造函数，也就会执行我们这里重写的<code>run()</code>方法了。而这里的Thread实现了Runnable接口，所以它其实也是个Runnable。</p>\n</li>\n</ul>\n<h2 id=\"重要属性\"><a href=\"#重要属性\" class=\"headerlink\" title=\"重要属性\"></a>重要属性</h2><h3 id=\"优先级\"><a href=\"#优先级\" class=\"headerlink\" title=\"优先级\"></a>优先级</h3><pre><code class=\"java\">private int  priority;\npublic final static int MIN_PRIORITY = 1;\npublic final static int NORM_PRIORITY = 5;\npublic final static int MAX_PRIORITY = 10;\n   public final void setPriority(int newPriority) {\n        ThreadGroup g;\n        checkAccess();\n        if (newPriority &gt; MAX_PRIORITY || newPriority &lt; MIN_PRIORITY) {\n            throw new IllegalArgumentException();\n        }\n        if((g = getThreadGroup()) != null) {\n            if (newPriority &gt; g.getMaxPriority()) {\n                newPriority = g.getMaxPriority();\n            }\n            setPriority0(priority = newPriority);\n        }\n    }\n    public final int getPriority() {\n        return priority;\n    }</code></pre>\n<h3 id=\"线程的状态\"><a href=\"#线程的状态\" class=\"headerlink\" title=\"线程的状态\"></a>线程的状态</h3><pre><code class=\"java\">public enum State {\n        NEW,\n        RUNNABLE,\n        BLOCKED,\n        WAITING,\n        TIMED_WAITING,\n        TERMINATED;\n    }\n      public State getState() {\n        return sun.misc.VM.toThreadState(threadStatus);\n    }</code></pre>\n<p>网上找到的图：</p>\n<p><img src=\"/2020/03/19/kongzheng1993-Thread和Runnable/C:%5CUsers%5Ckongz%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200319181144600.png\" alt=\"image-20200319181144600\"></p>\n<h3 id=\"主要方法\"><a href=\"#主要方法\" class=\"headerlink\" title=\"主要方法\"></a>主要方法</h3><ul>\n<li><p>本地方法获取当前线程</p>\n<pre><code class=\"java\">public static native Thread currentThread();</code></pre>\n</li>\n<li><p>run()</p>\n<pre><code class=\"java\">public void run() {\n        if (target != null) {\n            target.run();\n        }\n    }</code></pre>\n<p>这里就是上面说的，如果是传入Runnable的话，这里target就不会是null了，如果没有传入target，就不会执行什么，但是一般我们不传入target，就会重写<code>run()</code>方法了。</p>\n</li>\n<li><p>start()</p>\n<pre><code class=\"java\">public synchronized void start() {\n        /**\n         * This method is not invoked for the main method thread or &quot;system&quot;\n         * group threads created/set up by the VM. Any new functionality added\n         * to this method in the future may have to also be added to the VM.\n         *\n         * A zero status value corresponds to state &quot;NEW&quot;.\n         */\n        if (threadStatus != 0)\n            throw new IllegalThreadStateException();\n\n        /* Notify the group that this thread is about to be started\n         * so that it can be added to the group&#39;s list of threads\n         * and the group&#39;s unstarted count can be decremented. */\n        group.add(this);\n\n        boolean started = false;\n        try {\n            start0();\n            started = true;\n        } finally {\n            try {\n                if (!started) {\n                    group.threadStartFailed(this);\n                }\n            } catch (Throwable ignore) {\n                /* do nothing. If start0 threw a Throwable then\n                  it will be passed up the call stack */\n            }\n        }\n    }\n\n    private native void start0();</code></pre>\n<p>这里会调用一个本地方法<code>start0()</code>，应该会起一个线程执行<code>run()</code>方法。</p>\n</li>\n<li><p>boolean interrupted() &amp; void interrupt() &amp; boolean isInterrupted()</p>\n<p><strong>interrupt()</strong>:中断本线程(将中断状态标记为true)<br><strong>isInterrupted()</strong>:检测本线程是否已经中断 。如果已经中断，则返回true，否则false。中断状态不受该方法的影响。 如果中断调用时线程已经不处于活动状态，则返回false。<br><strong>interrupted()</strong>:检测当前线程是否已经中断 。如果当前线程存在中断，返回true，并且修改标记为false。再调用isIterruoted()会返回false。如果当前线程没有中断标记，返回false，不会修改中断标记。</p>\n</li>\n<li><p>void sleep(long millis) &amp; void sleep(long millis, int nanos)</p>\n<pre><code class=\"java\">public static native void sleep(long millis) throws InterruptedException;\n\n    /**\n     * Causes the currently executing thread to sleep (temporarily cease\n     * execution) for the specified number of milliseconds plus the specified\n     * number of nanoseconds, subject to the precision and accuracy of system\n     * timers and schedulers. The thread does not lose ownership of any\n     * monitors.\n     *\n     * @param  millis\n     *         the length of time to sleep in milliseconds\n     *\n     * @param  nanos\n     *         {@code 0-999999} additional nanoseconds to sleep\n     *\n     * @throws  IllegalArgumentException\n     *          if the value of {@code millis} is negative, or the value of\n     *          {@code nanos} is not in the range {@code 0-999999}\n     *\n     * @throws  InterruptedException\n     *          if any thread has interrupted the current thread. The\n     *          &lt;i&gt;interrupted status&lt;/i&gt; of the current thread is\n     *          cleared when this exception is thrown.\n     */\n    public static void sleep(long millis, int nanos)\n    throws InterruptedException {\n        if (millis &lt; 0) {\n            throw new IllegalArgumentException(&quot;timeout value is negative&quot;);\n        }\n\n        if (nanos &lt; 0 || nanos &gt; 999999) {\n            throw new IllegalArgumentException(\n                                &quot;nanosecond timeout value out of range&quot;);\n        }\n\n        if (nanos &gt;= 500000 || (nanos != 0 &amp;&amp; millis == 0)) {\n            millis++;\n        }\n\n        sleep(millis);\n    }</code></pre>\n<p>两个参数的sleep只是将nanos转为millis(四舍五入转换)，调用sleep(millis)方法。<br>sleep(millis)是本地方法，让当前线程休眠指定时间。<br>sleep不释放锁。</p>\n</li>\n<li><p>void join() &amp; void join(long millis) &amp; void join(long millis, int nanos)</p>\n<p>将线程加入到当前线程中，使父线程等待子线程执行完毕再继续执行。</p>\n</li>\n</ul>\n","site":{"data":{}},"more":"<h1 id=\"Thread和Runnable\"><a href=\"#Thread和Runnable\" class=\"headerlink\" title=\"Thread和Runnable\"></a>Thread和Runnable</h1><p>我们都知道Java中创建线程有两种方式，继承Thread类和实现Runnable接口。其实呢，我们看了Thread的源码就能了解到：Thread实现了Runnable，其实也是个Runnable。</p>\n<p>Thread的构造方法中有一个是：</p>\n<p><img src=\"/2020/03/19/kongzheng1993-Thread和Runnable/C:%5CUsers%5Ckongz%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200319172854321.png\" alt=\"image-20200319172854321\"></p>\n<p>这里传入的是一个Runnable，而继续往下执行，到了最后也是执行的这个target的<code>run()</code>方法。</p>\n<p>如果我们不传入Runnable呢？</p>\n<p><img src=\"/2020/03/19/kongzheng1993-Thread和Runnable/C:%5CUsers%5Ckongz%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200319173106843.png\" alt=\"image-20200319173106843\"></p>\n<p>可以看到这个方法target是null。最后执行的是Thread重写的<code>run()</code>方法。</p>\n<p>所以看到这里可以了解到：</p>\n<ul>\n<li><p>Runnable就是个接口，写一个类实现Runnable接口，它并不能执行，它要提交到一个线程（Thread），在Thread实例化调用它的构造方法的时候，才会触发Runnable的run方法。</p>\n</li>\n<li><p>继承Thread来创建线程，重写了<code>run()</code>方法，当我们实例化这个类的时候，将会调用到父类，也就是Thread的无参构造函数，也就会执行我们这里重写的<code>run()</code>方法了。而这里的Thread实现了Runnable接口，所以它其实也是个Runnable。</p>\n</li>\n</ul>\n<h2 id=\"重要属性\"><a href=\"#重要属性\" class=\"headerlink\" title=\"重要属性\"></a>重要属性</h2><h3 id=\"优先级\"><a href=\"#优先级\" class=\"headerlink\" title=\"优先级\"></a>优先级</h3><pre><code class=\"java\">private int  priority;\npublic final static int MIN_PRIORITY = 1;\npublic final static int NORM_PRIORITY = 5;\npublic final static int MAX_PRIORITY = 10;\n   public final void setPriority(int newPriority) {\n        ThreadGroup g;\n        checkAccess();\n        if (newPriority &gt; MAX_PRIORITY || newPriority &lt; MIN_PRIORITY) {\n            throw new IllegalArgumentException();\n        }\n        if((g = getThreadGroup()) != null) {\n            if (newPriority &gt; g.getMaxPriority()) {\n                newPriority = g.getMaxPriority();\n            }\n            setPriority0(priority = newPriority);\n        }\n    }\n    public final int getPriority() {\n        return priority;\n    }</code></pre>\n<h3 id=\"线程的状态\"><a href=\"#线程的状态\" class=\"headerlink\" title=\"线程的状态\"></a>线程的状态</h3><pre><code class=\"java\">public enum State {\n        NEW,\n        RUNNABLE,\n        BLOCKED,\n        WAITING,\n        TIMED_WAITING,\n        TERMINATED;\n    }\n      public State getState() {\n        return sun.misc.VM.toThreadState(threadStatus);\n    }</code></pre>\n<p>网上找到的图：</p>\n<p><img src=\"/2020/03/19/kongzheng1993-Thread和Runnable/C:%5CUsers%5Ckongz%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200319181144600.png\" alt=\"image-20200319181144600\"></p>\n<h3 id=\"主要方法\"><a href=\"#主要方法\" class=\"headerlink\" title=\"主要方法\"></a>主要方法</h3><ul>\n<li><p>本地方法获取当前线程</p>\n<pre><code class=\"java\">public static native Thread currentThread();</code></pre>\n</li>\n<li><p>run()</p>\n<pre><code class=\"java\">public void run() {\n        if (target != null) {\n            target.run();\n        }\n    }</code></pre>\n<p>这里就是上面说的，如果是传入Runnable的话，这里target就不会是null了，如果没有传入target，就不会执行什么，但是一般我们不传入target，就会重写<code>run()</code>方法了。</p>\n</li>\n<li><p>start()</p>\n<pre><code class=\"java\">public synchronized void start() {\n        /**\n         * This method is not invoked for the main method thread or &quot;system&quot;\n         * group threads created/set up by the VM. Any new functionality added\n         * to this method in the future may have to also be added to the VM.\n         *\n         * A zero status value corresponds to state &quot;NEW&quot;.\n         */\n        if (threadStatus != 0)\n            throw new IllegalThreadStateException();\n\n        /* Notify the group that this thread is about to be started\n         * so that it can be added to the group&#39;s list of threads\n         * and the group&#39;s unstarted count can be decremented. */\n        group.add(this);\n\n        boolean started = false;\n        try {\n            start0();\n            started = true;\n        } finally {\n            try {\n                if (!started) {\n                    group.threadStartFailed(this);\n                }\n            } catch (Throwable ignore) {\n                /* do nothing. If start0 threw a Throwable then\n                  it will be passed up the call stack */\n            }\n        }\n    }\n\n    private native void start0();</code></pre>\n<p>这里会调用一个本地方法<code>start0()</code>，应该会起一个线程执行<code>run()</code>方法。</p>\n</li>\n<li><p>boolean interrupted() &amp; void interrupt() &amp; boolean isInterrupted()</p>\n<p><strong>interrupt()</strong>:中断本线程(将中断状态标记为true)<br><strong>isInterrupted()</strong>:检测本线程是否已经中断 。如果已经中断，则返回true，否则false。中断状态不受该方法的影响。 如果中断调用时线程已经不处于活动状态，则返回false。<br><strong>interrupted()</strong>:检测当前线程是否已经中断 。如果当前线程存在中断，返回true，并且修改标记为false。再调用isIterruoted()会返回false。如果当前线程没有中断标记，返回false，不会修改中断标记。</p>\n</li>\n<li><p>void sleep(long millis) &amp; void sleep(long millis, int nanos)</p>\n<pre><code class=\"java\">public static native void sleep(long millis) throws InterruptedException;\n\n    /**\n     * Causes the currently executing thread to sleep (temporarily cease\n     * execution) for the specified number of milliseconds plus the specified\n     * number of nanoseconds, subject to the precision and accuracy of system\n     * timers and schedulers. The thread does not lose ownership of any\n     * monitors.\n     *\n     * @param  millis\n     *         the length of time to sleep in milliseconds\n     *\n     * @param  nanos\n     *         {@code 0-999999} additional nanoseconds to sleep\n     *\n     * @throws  IllegalArgumentException\n     *          if the value of {@code millis} is negative, or the value of\n     *          {@code nanos} is not in the range {@code 0-999999}\n     *\n     * @throws  InterruptedException\n     *          if any thread has interrupted the current thread. The\n     *          &lt;i&gt;interrupted status&lt;/i&gt; of the current thread is\n     *          cleared when this exception is thrown.\n     */\n    public static void sleep(long millis, int nanos)\n    throws InterruptedException {\n        if (millis &lt; 0) {\n            throw new IllegalArgumentException(&quot;timeout value is negative&quot;);\n        }\n\n        if (nanos &lt; 0 || nanos &gt; 999999) {\n            throw new IllegalArgumentException(\n                                &quot;nanosecond timeout value out of range&quot;);\n        }\n\n        if (nanos &gt;= 500000 || (nanos != 0 &amp;&amp; millis == 0)) {\n            millis++;\n        }\n\n        sleep(millis);\n    }</code></pre>\n<p>两个参数的sleep只是将nanos转为millis(四舍五入转换)，调用sleep(millis)方法。<br>sleep(millis)是本地方法，让当前线程休眠指定时间。<br>sleep不释放锁。</p>\n</li>\n<li><p>void join() &amp; void join(long millis) &amp; void join(long millis, int nanos)</p>\n<p>将线程加入到当前线程中，使父线程等待子线程执行完毕再继续执行。</p>\n</li>\n</ul>\n"},{"title":"localStorage","excerpt":"","comments":1,"date":"2020-03-29T16:30:52.000Z","_content":"\n# Window.localStorage\n\n只读的`localStorage`属性允许你访问一个`Document`源（origin）的对象`Storage`；存储的数据将保存在浏览器会话中。`localStorage` 类似 `sessionStorage`，但其区别在于：存储在 localStorage 的数据可以长期保留；而当页面会话结束——也就是说，当页面被关闭时，存储在 sessionStorage 的数据会被清除 。\n\n应注意，无论数据存储在 localStorage 还是 sessionStorage ，它们都特定于页面的协议。\n\n另外，localStorage 中的键值对总是以字符串的形式存储。 (需要注意, 和js对象相比, 键值对总是以字符串的形式存储意味着数值类型会自动转化为字符串类型)","source":"_posts/2020-04-02-kongzheng1993-localStorage.md","raw":"---\ntitle: localStorage\nexcerpt: ''\ntags: [Web]\ncategories: [Web]\ncomments: true\ndate: 2020-03-30 00:30:52\n---\n\n# Window.localStorage\n\n只读的`localStorage`属性允许你访问一个`Document`源（origin）的对象`Storage`；存储的数据将保存在浏览器会话中。`localStorage` 类似 `sessionStorage`，但其区别在于：存储在 localStorage 的数据可以长期保留；而当页面会话结束——也就是说，当页面被关闭时，存储在 sessionStorage 的数据会被清除 。\n\n应注意，无论数据存储在 localStorage 还是 sessionStorage ，它们都特定于页面的协议。\n\n另外，localStorage 中的键值对总是以字符串的形式存储。 (需要注意, 和js对象相比, 键值对总是以字符串的形式存储意味着数值类型会自动转化为字符串类型)","slug":"kongzheng1993-localStorage","published":1,"updated":"2023-03-08T07:05:58.785Z","layout":"post","photos":[],"link":"","_id":"clg0k2ae3002gt26fmj9inlg9","content":"<h1 id=\"Window-localStorage\"><a href=\"#Window-localStorage\" class=\"headerlink\" title=\"Window.localStorage\"></a>Window.localStorage</h1><p>只读的<code>localStorage</code>属性允许你访问一个<code>Document</code>源（origin）的对象<code>Storage</code>；存储的数据将保存在浏览器会话中。<code>localStorage</code> 类似 <code>sessionStorage</code>，但其区别在于：存储在 localStorage 的数据可以长期保留；而当页面会话结束——也就是说，当页面被关闭时，存储在 sessionStorage 的数据会被清除 。</p>\n<p>应注意，无论数据存储在 localStorage 还是 sessionStorage ，它们都特定于页面的协议。</p>\n<p>另外，localStorage 中的键值对总是以字符串的形式存储。 (需要注意, 和js对象相比, 键值对总是以字符串的形式存储意味着数值类型会自动转化为字符串类型)</p>\n","site":{"data":{}},"more":"<h1 id=\"Window-localStorage\"><a href=\"#Window-localStorage\" class=\"headerlink\" title=\"Window.localStorage\"></a>Window.localStorage</h1><p>只读的<code>localStorage</code>属性允许你访问一个<code>Document</code>源（origin）的对象<code>Storage</code>；存储的数据将保存在浏览器会话中。<code>localStorage</code> 类似 <code>sessionStorage</code>，但其区别在于：存储在 localStorage 的数据可以长期保留；而当页面会话结束——也就是说，当页面被关闭时，存储在 sessionStorage 的数据会被清除 。</p>\n<p>应注意，无论数据存储在 localStorage 还是 sessionStorage ，它们都特定于页面的协议。</p>\n<p>另外，localStorage 中的键值对总是以字符串的形式存储。 (需要注意, 和js对象相比, 键值对总是以字符串的形式存储意味着数值类型会自动转化为字符串类型)</p>\n"},{"title":"用node.js做一个测试api服务","excerpt":"","comments":1,"top":3,"date":"2020-03-29T16:30:52.000Z","_content":"\n\n# 用node.js做一个测试api服务\n\n前两天被安排做一体机的项目。这可是个大坑，兄弟们都不想搞。我和他们不一样了，迎难而上，哈哈。这个是嵌入到营业厅一体机或者pad的一个系统，为什么说这是一个大坑呢？没有测试环境，只能生产联调。要是平时，可以在公司搭一个测试环境嘛，可是疫情期间在家办公，诸多不便。还有一个问题是，没有后台系统啊，所有接口都不通，盲写代码？\n\n## 怎么快速搞一个工具获得我想要的接口呢\n\n记得之前看过一本书《架构探险 轻量级微服务架构》，阿里大佬黄勇老师的书，内容通俗易懂，是我很喜欢的风格。里面有一章用node.js讲解并实现微服务网关，npm安装node.js第三方模块，快速实现功能，就像Python和pip，当时就让我对node.js产生了浓厚的兴趣，js统一前后端了，哈哈。所以我想用node.js来实现一个简单的根据url来返回特定json的工具，并用这个工具来进行一体机项目的开发。\n\n## 开始搞\n\n1. 修改npm为淘宝镜像\n\n```shell\nnpm install cnpm -g --registry=http://registry.npm.taobao.org\n```\n\n<img src='cnpm.bmp'>\n\n2. 安装express\n\nexpress是一款基于node.js的web应用框架，提供了大量的工具函数与中间件，使web应用开发效率更加高效。\n\n```shell\nnpm install express\n```\n<img src='express.bmp'>\n\n3. 编码\n\n打开vscode，开始撸\n\n```js\nvar express = require('express');\nvar port = 8080;\n\nvar app = express();\napp.use(express.static('.'));\n\napp.get('/querywriteCardBasicData', function (req, res) {\n    res.send('{\"id\":\"123\",name:\"jack\",arg:11111}')\n});\n\napp.post('/querywriteCardBasicData', function (req, res) {\n    res.send('{\"id\":\"123\",name:\"jack\",arg:11111}')\n});\n\napp.post('/querywriteCardBasicData', function (req, res) {\n    res.send('{\"id\":\"123\",name:\"jack\",arg:11111}')\n});\n\napp.listen(port, function () {\n    console.log('server is running at %d', port);\n});\n```\n\n4. 运行\n\n```shell\nnode app.js\n```\n\n<img src='run.bmp'>\n\n5. 测试\n\n浏览器访问`http://localhost:8080/querywriteCardBasicData`\n\n<img src='test.bmp'>\n\n## 总结\n\nNode.js 是一个基于 Chrome V8 引擎的 JavaScript 运行环境。Node.js 使用了一个事件驱动、非阻塞式 I/O 的模型,使其轻量又高效。\n我喜欢写一些小工具，之前因为工作上的需要，写过许多小工具，比如Python写的接口配置工具、文件下载工具、sql脚本生成工具。这些小工具都得到了同事和领导的好评，我也收获了极大的满足。我喜欢用工具完成一些简单但是重复的工作，如果有一个特别麻烦的事儿挡在我面前，我一定会在第一时间思考，怎么搞个工具，哈哈，加油。","source":"_posts/2020-03-30-kongzheng1993-用nodejs做一个测试api服务.md","raw":"---\ntitle: 用node.js做一个测试api服务\nexcerpt: ''\ntags: [node.js]\ncategories: [node.js]\ncomments: true\ntop: 3\ndate: 2020-03-30 00:30:52\n---\n\n\n# 用node.js做一个测试api服务\n\n前两天被安排做一体机的项目。这可是个大坑，兄弟们都不想搞。我和他们不一样了，迎难而上，哈哈。这个是嵌入到营业厅一体机或者pad的一个系统，为什么说这是一个大坑呢？没有测试环境，只能生产联调。要是平时，可以在公司搭一个测试环境嘛，可是疫情期间在家办公，诸多不便。还有一个问题是，没有后台系统啊，所有接口都不通，盲写代码？\n\n## 怎么快速搞一个工具获得我想要的接口呢\n\n记得之前看过一本书《架构探险 轻量级微服务架构》，阿里大佬黄勇老师的书，内容通俗易懂，是我很喜欢的风格。里面有一章用node.js讲解并实现微服务网关，npm安装node.js第三方模块，快速实现功能，就像Python和pip，当时就让我对node.js产生了浓厚的兴趣，js统一前后端了，哈哈。所以我想用node.js来实现一个简单的根据url来返回特定json的工具，并用这个工具来进行一体机项目的开发。\n\n## 开始搞\n\n1. 修改npm为淘宝镜像\n\n```shell\nnpm install cnpm -g --registry=http://registry.npm.taobao.org\n```\n\n<img src='cnpm.bmp'>\n\n2. 安装express\n\nexpress是一款基于node.js的web应用框架，提供了大量的工具函数与中间件，使web应用开发效率更加高效。\n\n```shell\nnpm install express\n```\n<img src='express.bmp'>\n\n3. 编码\n\n打开vscode，开始撸\n\n```js\nvar express = require('express');\nvar port = 8080;\n\nvar app = express();\napp.use(express.static('.'));\n\napp.get('/querywriteCardBasicData', function (req, res) {\n    res.send('{\"id\":\"123\",name:\"jack\",arg:11111}')\n});\n\napp.post('/querywriteCardBasicData', function (req, res) {\n    res.send('{\"id\":\"123\",name:\"jack\",arg:11111}')\n});\n\napp.post('/querywriteCardBasicData', function (req, res) {\n    res.send('{\"id\":\"123\",name:\"jack\",arg:11111}')\n});\n\napp.listen(port, function () {\n    console.log('server is running at %d', port);\n});\n```\n\n4. 运行\n\n```shell\nnode app.js\n```\n\n<img src='run.bmp'>\n\n5. 测试\n\n浏览器访问`http://localhost:8080/querywriteCardBasicData`\n\n<img src='test.bmp'>\n\n## 总结\n\nNode.js 是一个基于 Chrome V8 引擎的 JavaScript 运行环境。Node.js 使用了一个事件驱动、非阻塞式 I/O 的模型,使其轻量又高效。\n我喜欢写一些小工具，之前因为工作上的需要，写过许多小工具，比如Python写的接口配置工具、文件下载工具、sql脚本生成工具。这些小工具都得到了同事和领导的好评，我也收获了极大的满足。我喜欢用工具完成一些简单但是重复的工作，如果有一个特别麻烦的事儿挡在我面前，我一定会在第一时间思考，怎么搞个工具，哈哈，加油。","slug":"kongzheng1993-用nodejs做一个测试api服务","published":1,"updated":"2023-03-08T07:05:58.784Z","layout":"post","photos":[],"link":"","_id":"clg0k2ae4002it26fo67pkj8c","content":"<h1 id=\"用node-js做一个测试api服务\"><a href=\"#用node-js做一个测试api服务\" class=\"headerlink\" title=\"用node.js做一个测试api服务\"></a>用node.js做一个测试api服务</h1><p>前两天被安排做一体机的项目。这可是个大坑，兄弟们都不想搞。我和他们不一样了，迎难而上，哈哈。这个是嵌入到营业厅一体机或者pad的一个系统，为什么说这是一个大坑呢？没有测试环境，只能生产联调。要是平时，可以在公司搭一个测试环境嘛，可是疫情期间在家办公，诸多不便。还有一个问题是，没有后台系统啊，所有接口都不通，盲写代码？</p>\n<h2 id=\"怎么快速搞一个工具获得我想要的接口呢\"><a href=\"#怎么快速搞一个工具获得我想要的接口呢\" class=\"headerlink\" title=\"怎么快速搞一个工具获得我想要的接口呢\"></a>怎么快速搞一个工具获得我想要的接口呢</h2><p>记得之前看过一本书《架构探险 轻量级微服务架构》，阿里大佬黄勇老师的书，内容通俗易懂，是我很喜欢的风格。里面有一章用node.js讲解并实现微服务网关，npm安装node.js第三方模块，快速实现功能，就像Python和pip，当时就让我对node.js产生了浓厚的兴趣，js统一前后端了，哈哈。所以我想用node.js来实现一个简单的根据url来返回特定json的工具，并用这个工具来进行一体机项目的开发。</p>\n<h2 id=\"开始搞\"><a href=\"#开始搞\" class=\"headerlink\" title=\"开始搞\"></a>开始搞</h2><ol>\n<li>修改npm为淘宝镜像</li>\n</ol>\n<pre><code class=\"shell\">npm install cnpm -g --registry=http://registry.npm.taobao.org</code></pre>\n<img src=\"/2020/03/30/kongzheng1993-用nodejs做一个测试api服务/cnpm.bmp\">\n\n<ol start=\"2\">\n<li>安装express</li>\n</ol>\n<p>express是一款基于node.js的web应用框架，提供了大量的工具函数与中间件，使web应用开发效率更加高效。</p>\n<pre><code class=\"shell\">npm install express</code></pre>\n<img src=\"/2020/03/30/kongzheng1993-用nodejs做一个测试api服务/express.bmp\">\n\n<ol start=\"3\">\n<li>编码</li>\n</ol>\n<p>打开vscode，开始撸</p>\n<pre><code class=\"js\">var express = require(&#39;express&#39;);\nvar port = 8080;\n\nvar app = express();\napp.use(express.static(&#39;.&#39;));\n\napp.get(&#39;/querywriteCardBasicData&#39;, function (req, res) {\n    res.send(&#39;{&quot;id&quot;:&quot;123&quot;,name:&quot;jack&quot;,arg:11111}&#39;)\n});\n\napp.post(&#39;/querywriteCardBasicData&#39;, function (req, res) {\n    res.send(&#39;{&quot;id&quot;:&quot;123&quot;,name:&quot;jack&quot;,arg:11111}&#39;)\n});\n\napp.post(&#39;/querywriteCardBasicData&#39;, function (req, res) {\n    res.send(&#39;{&quot;id&quot;:&quot;123&quot;,name:&quot;jack&quot;,arg:11111}&#39;)\n});\n\napp.listen(port, function () {\n    console.log(&#39;server is running at %d&#39;, port);\n});</code></pre>\n<ol start=\"4\">\n<li>运行</li>\n</ol>\n<pre><code class=\"shell\">node app.js</code></pre>\n<img src=\"/2020/03/30/kongzheng1993-用nodejs做一个测试api服务/run.bmp\">\n\n<ol start=\"5\">\n<li>测试</li>\n</ol>\n<p>浏览器访问<code>http://localhost:8080/querywriteCardBasicData</code></p>\n<img src=\"/2020/03/30/kongzheng1993-用nodejs做一个测试api服务/test.bmp\">\n\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>Node.js 是一个基于 Chrome V8 引擎的 JavaScript 运行环境。Node.js 使用了一个事件驱动、非阻塞式 I/O 的模型,使其轻量又高效。<br>我喜欢写一些小工具，之前因为工作上的需要，写过许多小工具，比如Python写的接口配置工具、文件下载工具、sql脚本生成工具。这些小工具都得到了同事和领导的好评，我也收获了极大的满足。我喜欢用工具完成一些简单但是重复的工作，如果有一个特别麻烦的事儿挡在我面前，我一定会在第一时间思考，怎么搞个工具，哈哈，加油。</p>\n","site":{"data":{}},"more":"<h1 id=\"用node-js做一个测试api服务\"><a href=\"#用node-js做一个测试api服务\" class=\"headerlink\" title=\"用node.js做一个测试api服务\"></a>用node.js做一个测试api服务</h1><p>前两天被安排做一体机的项目。这可是个大坑，兄弟们都不想搞。我和他们不一样了，迎难而上，哈哈。这个是嵌入到营业厅一体机或者pad的一个系统，为什么说这是一个大坑呢？没有测试环境，只能生产联调。要是平时，可以在公司搭一个测试环境嘛，可是疫情期间在家办公，诸多不便。还有一个问题是，没有后台系统啊，所有接口都不通，盲写代码？</p>\n<h2 id=\"怎么快速搞一个工具获得我想要的接口呢\"><a href=\"#怎么快速搞一个工具获得我想要的接口呢\" class=\"headerlink\" title=\"怎么快速搞一个工具获得我想要的接口呢\"></a>怎么快速搞一个工具获得我想要的接口呢</h2><p>记得之前看过一本书《架构探险 轻量级微服务架构》，阿里大佬黄勇老师的书，内容通俗易懂，是我很喜欢的风格。里面有一章用node.js讲解并实现微服务网关，npm安装node.js第三方模块，快速实现功能，就像Python和pip，当时就让我对node.js产生了浓厚的兴趣，js统一前后端了，哈哈。所以我想用node.js来实现一个简单的根据url来返回特定json的工具，并用这个工具来进行一体机项目的开发。</p>\n<h2 id=\"开始搞\"><a href=\"#开始搞\" class=\"headerlink\" title=\"开始搞\"></a>开始搞</h2><ol>\n<li>修改npm为淘宝镜像</li>\n</ol>\n<pre><code class=\"shell\">npm install cnpm -g --registry=http://registry.npm.taobao.org</code></pre>\n<img src=\"/2020/03/30/kongzheng1993-用nodejs做一个测试api服务/cnpm.bmp\">\n\n<ol start=\"2\">\n<li>安装express</li>\n</ol>\n<p>express是一款基于node.js的web应用框架，提供了大量的工具函数与中间件，使web应用开发效率更加高效。</p>\n<pre><code class=\"shell\">npm install express</code></pre>\n<img src=\"/2020/03/30/kongzheng1993-用nodejs做一个测试api服务/express.bmp\">\n\n<ol start=\"3\">\n<li>编码</li>\n</ol>\n<p>打开vscode，开始撸</p>\n<pre><code class=\"js\">var express = require(&#39;express&#39;);\nvar port = 8080;\n\nvar app = express();\napp.use(express.static(&#39;.&#39;));\n\napp.get(&#39;/querywriteCardBasicData&#39;, function (req, res) {\n    res.send(&#39;{&quot;id&quot;:&quot;123&quot;,name:&quot;jack&quot;,arg:11111}&#39;)\n});\n\napp.post(&#39;/querywriteCardBasicData&#39;, function (req, res) {\n    res.send(&#39;{&quot;id&quot;:&quot;123&quot;,name:&quot;jack&quot;,arg:11111}&#39;)\n});\n\napp.post(&#39;/querywriteCardBasicData&#39;, function (req, res) {\n    res.send(&#39;{&quot;id&quot;:&quot;123&quot;,name:&quot;jack&quot;,arg:11111}&#39;)\n});\n\napp.listen(port, function () {\n    console.log(&#39;server is running at %d&#39;, port);\n});</code></pre>\n<ol start=\"4\">\n<li>运行</li>\n</ol>\n<pre><code class=\"shell\">node app.js</code></pre>\n<img src=\"/2020/03/30/kongzheng1993-用nodejs做一个测试api服务/run.bmp\">\n\n<ol start=\"5\">\n<li>测试</li>\n</ol>\n<p>浏览器访问<code>http://localhost:8080/querywriteCardBasicData</code></p>\n<img src=\"/2020/03/30/kongzheng1993-用nodejs做一个测试api服务/test.bmp\">\n\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>Node.js 是一个基于 Chrome V8 引擎的 JavaScript 运行环境。Node.js 使用了一个事件驱动、非阻塞式 I/O 的模型,使其轻量又高效。<br>我喜欢写一些小工具，之前因为工作上的需要，写过许多小工具，比如Python写的接口配置工具、文件下载工具、sql脚本生成工具。这些小工具都得到了同事和领导的好评，我也收获了极大的满足。我喜欢用工具完成一些简单但是重复的工作，如果有一个特别麻烦的事儿挡在我面前，我一定会在第一时间思考，怎么搞个工具，哈哈，加油。</p>\n"},{"title":"Effectiv Java学习笔记（一）","excerpt":"","comments":1,"date":"2020-04-06T16:30:52.000Z","_content":"\n# 创建和销毁对象\n\n## 1.考虑使用静态工厂方法代替构造器\n\n我们平时创建对象都是new一个，而new会调用类对应的构造器。但是还有一个方法，就是**静态工厂方法**。\n\n```java\npublic static Boolean valueOf(boolean b) {\n    return b ? Boolean.TRUE : Boolean.FALSE;\n}\n```\n\n上面是一个典型的示例。\n\n优点：\n\n- **静态工厂方法有方法名。** 新建对象可以通过参数列表不同来调用不通的构造器，但是这样没有文字描述，调用者很难一下理解构造器做了哪些操作。\n- **每次调用不必都创建一个新对象。** 这使得不可变类可以使用预先构造好的示例，或者将构建好的示例缓存起来，重复利用，从而避免创建不必要的重复对象。像上面的例子，就没有创建对象。这样有利于提高性能。单例的对象也能在这样的方法里得以实现。\n- **可以返回原返回类型的任何子类型。** 可以返回对象，同时又不会使对象的类变成公有的。这种技术适用于基于接口的框架。\n- **在创建参数化类型示例的时候，使代码变得更加简洁。**\n\n缺点：\n\n- **类如果不含共有的或者受保护的构造器，就不能被子类化。**\n- **静态工厂方法与其他静态方法实际上没有任何区别。** 大家都知道用构造器实例化对象，却不能一眼看出这个静态方法是用来实例化对象的。\n\n静态工厂方法惯用名：\n\n- **valueOf**----主要用于类型转换。\n- **of**----valueOf的简洁方案。\n- **getInstance**----返回的示例是通过参数来描述的，对于Singleton来说，该方法应该没有参数，直接返回唯一实例。\n- **newInstance**----返回一个新的实例。\n\n## 2.遇到多个构造器参数时要考虑使用构造器\n\n这里讲了把生活中一个对象抽象成类，我们实例化对象的三种设计思路：\n\n- **重叠构造器模式** 编写各种成员变量组合的构造器，实例化时选择我们需要的来。但是参数太多的话，构造器的数量就太多了，难以编写。\n- **JavaBean模式** 通过setter方法来设置参数，但是这样无法实现不可变对象，引发线程安全问题。\n- **Builder模式** 通过一个Builder内部类，实现setter赋值，然后再构造函数里将Builder的成员赋给我们实例化的对象。\n\n**Builder模式**：\n```java\n\n/**\n * @Description:\n * @Author: kongz\n * @Date: 2020/4/7 18:55\n */\npublic class People {\n\n    private String name;\n    private int age;\n    private String gender;\n\n    public People(Builder builder) {\n        name = builder.name;\n        age = builder.age;\n        gender = builder.gender;\n    }\n\n    public static class Builder {\n\n        private String name;\n        private int age;\n        private String gender;\n\n        public Builder(String name) {\n            this.name = name;\n        }\n\n        public Builder age(int age) {\n            this.age = age;\n            return this;\n        }\n\n        public Builder gender(String gender) {\n            this.gender = gender;\n            return this;\n        }\n\n        public People build() {\n            return new People(this);\n        }\n\n    }\n\n    @Override\n    public String toString() {\n        return this.name + \"--\" + this.age + \"--\" + this.gender;\n    }\n\n    public static void main(String[] args) {\n        People people = new Builder(\"kongz\").age(20).gender(\"男\").build();\n        System.out.println(people.toString());\n    }\n\n}\n```\n\nBuilder模式的确也有不足，创建对象必须要先创建它的构造器，这也会浪费一些资源，虽然不是那么明显，但是比重叠构造器更加冗长。\n\n## 3.用私有构造器或者枚举类型强化Singleton属性\n\n在Java 1.5之前有两种方法实现Singleton，这两种方法都要把构造器保持为私有的，并导出共有的静态变量，以便客户端能够访问该类的唯一实例。\n\n1. 第一种方法中，公有静态成员是个final域：\n\n```java\n//singleton with public final field\npublic class Elvis {\n    public static final Elvis INSTANCE = new Elvis();\n\n    private Elvis(){ ... }\n\n    public void leaveTheBuilding() {\n        ...\n    }\n}\n```\n\n私有构造器仅被调用一次，用来实例化公有的静态final域Elvis.INSTANCE。由于外界无法调用构造器，所以保证了Elvis的全局唯一。**但是想有特权的客户端可以通过AccessibleObject.setAccessable方法，通过反射机制调用私有构造器。如果要抵御这种攻击，可以修改构造器，让它在被要求创建第二个实例的时候抛出异常。**\n\n2. 第二种方法中，公有的成员是个静态工厂方法。\n\n```java\n//singleton with static factory\npublic class Elvis {\n    private static final Elvis INSTANCE = new Elvis();\n    private Elvis(){ ... }\n    public static Elvis getInstance() { return INSTANCE; }\n\n    public void leaveTheBuilding() { ... }\n}\n```\n\n对于静态方法Elvis.getInstance方法每次调用都会返回同一个对象引用，所以永远不会创建其他的Elvis对象。\n\n工厂方法的优势：\n\n- **提供了灵活性：** 在不改变api的前提下，可以改变该类是否应该为singleton的想法，因为客户都都是通过`getInstance`方法获取对象的。\n- **泛型**\n\n上面两种方法要实现singleton类变成可序列化（Serializable），仅仅在生命中加上`implements Serializable`是不够的。**为了维护并保证Singleton，必须声明所有的实例域都是瞬时（transient）的，并提供一个`readResolve`方法，否则每次反序列化一个序列化的实例时，都会创建一个新的实例。**\n\n```java\n//readResolve method to preserve singleton property\nprivate Object readResolve() {\n    //Return the one true Elvis and let the garbage collector\n    //take care of the Elvis impersonator\n    return INSTANCE;\n}\n```\n\n    在jdk中ObjectInputStream的类中有readUnshared（）方法，上面详细解释了原因。\n    我简单描述一下，那就是如果被反序列化的对象的类存在readResolve这个方法，\n    他会调用这个方法来返回一个“array”（我也不明白），然后浅拷贝一份，作为返回值，\n    并且无视掉反序列化的值，即使那个字节码已经被解析。\n    ————————————————\n    版权声明：本文为CSDN博主「无始之名」的原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接及本声明。\n    原文链接：https://blog.csdn.net/u011499747/java/article/details/50982956\n\n一个单例模式：\n\n```java\npublic class Elvis {\n    private static final Elvis INSTANCE = new Elvis();\n    private Elvis(){ ... }\n    public static Elvis getInstance() { return INSTANCE; }\n\n    public void leaveTheBuilding() { ... }\n    private Object readResolve() {\n        return INSTANCE;\n    }\n}\n```\n","source":"_posts/2020-04-06-kongzheng1993-Effective_Java学习笔记1.md","raw":"---\ntitle: Effectiv Java学习笔记（一）\nexcerpt: ''\ntags: [Java]\ncategories: [Java]\ncomments: true\ndate: 2020-04-07 00:30:52\n---\n\n# 创建和销毁对象\n\n## 1.考虑使用静态工厂方法代替构造器\n\n我们平时创建对象都是new一个，而new会调用类对应的构造器。但是还有一个方法，就是**静态工厂方法**。\n\n```java\npublic static Boolean valueOf(boolean b) {\n    return b ? Boolean.TRUE : Boolean.FALSE;\n}\n```\n\n上面是一个典型的示例。\n\n优点：\n\n- **静态工厂方法有方法名。** 新建对象可以通过参数列表不同来调用不通的构造器，但是这样没有文字描述，调用者很难一下理解构造器做了哪些操作。\n- **每次调用不必都创建一个新对象。** 这使得不可变类可以使用预先构造好的示例，或者将构建好的示例缓存起来，重复利用，从而避免创建不必要的重复对象。像上面的例子，就没有创建对象。这样有利于提高性能。单例的对象也能在这样的方法里得以实现。\n- **可以返回原返回类型的任何子类型。** 可以返回对象，同时又不会使对象的类变成公有的。这种技术适用于基于接口的框架。\n- **在创建参数化类型示例的时候，使代码变得更加简洁。**\n\n缺点：\n\n- **类如果不含共有的或者受保护的构造器，就不能被子类化。**\n- **静态工厂方法与其他静态方法实际上没有任何区别。** 大家都知道用构造器实例化对象，却不能一眼看出这个静态方法是用来实例化对象的。\n\n静态工厂方法惯用名：\n\n- **valueOf**----主要用于类型转换。\n- **of**----valueOf的简洁方案。\n- **getInstance**----返回的示例是通过参数来描述的，对于Singleton来说，该方法应该没有参数，直接返回唯一实例。\n- **newInstance**----返回一个新的实例。\n\n## 2.遇到多个构造器参数时要考虑使用构造器\n\n这里讲了把生活中一个对象抽象成类，我们实例化对象的三种设计思路：\n\n- **重叠构造器模式** 编写各种成员变量组合的构造器，实例化时选择我们需要的来。但是参数太多的话，构造器的数量就太多了，难以编写。\n- **JavaBean模式** 通过setter方法来设置参数，但是这样无法实现不可变对象，引发线程安全问题。\n- **Builder模式** 通过一个Builder内部类，实现setter赋值，然后再构造函数里将Builder的成员赋给我们实例化的对象。\n\n**Builder模式**：\n```java\n\n/**\n * @Description:\n * @Author: kongz\n * @Date: 2020/4/7 18:55\n */\npublic class People {\n\n    private String name;\n    private int age;\n    private String gender;\n\n    public People(Builder builder) {\n        name = builder.name;\n        age = builder.age;\n        gender = builder.gender;\n    }\n\n    public static class Builder {\n\n        private String name;\n        private int age;\n        private String gender;\n\n        public Builder(String name) {\n            this.name = name;\n        }\n\n        public Builder age(int age) {\n            this.age = age;\n            return this;\n        }\n\n        public Builder gender(String gender) {\n            this.gender = gender;\n            return this;\n        }\n\n        public People build() {\n            return new People(this);\n        }\n\n    }\n\n    @Override\n    public String toString() {\n        return this.name + \"--\" + this.age + \"--\" + this.gender;\n    }\n\n    public static void main(String[] args) {\n        People people = new Builder(\"kongz\").age(20).gender(\"男\").build();\n        System.out.println(people.toString());\n    }\n\n}\n```\n\nBuilder模式的确也有不足，创建对象必须要先创建它的构造器，这也会浪费一些资源，虽然不是那么明显，但是比重叠构造器更加冗长。\n\n## 3.用私有构造器或者枚举类型强化Singleton属性\n\n在Java 1.5之前有两种方法实现Singleton，这两种方法都要把构造器保持为私有的，并导出共有的静态变量，以便客户端能够访问该类的唯一实例。\n\n1. 第一种方法中，公有静态成员是个final域：\n\n```java\n//singleton with public final field\npublic class Elvis {\n    public static final Elvis INSTANCE = new Elvis();\n\n    private Elvis(){ ... }\n\n    public void leaveTheBuilding() {\n        ...\n    }\n}\n```\n\n私有构造器仅被调用一次，用来实例化公有的静态final域Elvis.INSTANCE。由于外界无法调用构造器，所以保证了Elvis的全局唯一。**但是想有特权的客户端可以通过AccessibleObject.setAccessable方法，通过反射机制调用私有构造器。如果要抵御这种攻击，可以修改构造器，让它在被要求创建第二个实例的时候抛出异常。**\n\n2. 第二种方法中，公有的成员是个静态工厂方法。\n\n```java\n//singleton with static factory\npublic class Elvis {\n    private static final Elvis INSTANCE = new Elvis();\n    private Elvis(){ ... }\n    public static Elvis getInstance() { return INSTANCE; }\n\n    public void leaveTheBuilding() { ... }\n}\n```\n\n对于静态方法Elvis.getInstance方法每次调用都会返回同一个对象引用，所以永远不会创建其他的Elvis对象。\n\n工厂方法的优势：\n\n- **提供了灵活性：** 在不改变api的前提下，可以改变该类是否应该为singleton的想法，因为客户都都是通过`getInstance`方法获取对象的。\n- **泛型**\n\n上面两种方法要实现singleton类变成可序列化（Serializable），仅仅在生命中加上`implements Serializable`是不够的。**为了维护并保证Singleton，必须声明所有的实例域都是瞬时（transient）的，并提供一个`readResolve`方法，否则每次反序列化一个序列化的实例时，都会创建一个新的实例。**\n\n```java\n//readResolve method to preserve singleton property\nprivate Object readResolve() {\n    //Return the one true Elvis and let the garbage collector\n    //take care of the Elvis impersonator\n    return INSTANCE;\n}\n```\n\n    在jdk中ObjectInputStream的类中有readUnshared（）方法，上面详细解释了原因。\n    我简单描述一下，那就是如果被反序列化的对象的类存在readResolve这个方法，\n    他会调用这个方法来返回一个“array”（我也不明白），然后浅拷贝一份，作为返回值，\n    并且无视掉反序列化的值，即使那个字节码已经被解析。\n    ————————————————\n    版权声明：本文为CSDN博主「无始之名」的原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接及本声明。\n    原文链接：https://blog.csdn.net/u011499747/java/article/details/50982956\n\n一个单例模式：\n\n```java\npublic class Elvis {\n    private static final Elvis INSTANCE = new Elvis();\n    private Elvis(){ ... }\n    public static Elvis getInstance() { return INSTANCE; }\n\n    public void leaveTheBuilding() { ... }\n    private Object readResolve() {\n        return INSTANCE;\n    }\n}\n```\n","slug":"kongzheng1993-Effective_Java学习笔记1","published":1,"updated":"2023-03-08T07:05:58.790Z","layout":"post","photos":[],"link":"","_id":"clg0k2ae5002mt26f3lbdtea0","content":"<h1 id=\"创建和销毁对象\"><a href=\"#创建和销毁对象\" class=\"headerlink\" title=\"创建和销毁对象\"></a>创建和销毁对象</h1><h2 id=\"1-考虑使用静态工厂方法代替构造器\"><a href=\"#1-考虑使用静态工厂方法代替构造器\" class=\"headerlink\" title=\"1.考虑使用静态工厂方法代替构造器\"></a>1.考虑使用静态工厂方法代替构造器</h2><p>我们平时创建对象都是new一个，而new会调用类对应的构造器。但是还有一个方法，就是<strong>静态工厂方法</strong>。</p>\n<pre><code class=\"java\">public static Boolean valueOf(boolean b) {\n    return b ? Boolean.TRUE : Boolean.FALSE;\n}</code></pre>\n<p>上面是一个典型的示例。</p>\n<p>优点：</p>\n<ul>\n<li><strong>静态工厂方法有方法名。</strong> 新建对象可以通过参数列表不同来调用不通的构造器，但是这样没有文字描述，调用者很难一下理解构造器做了哪些操作。</li>\n<li><strong>每次调用不必都创建一个新对象。</strong> 这使得不可变类可以使用预先构造好的示例，或者将构建好的示例缓存起来，重复利用，从而避免创建不必要的重复对象。像上面的例子，就没有创建对象。这样有利于提高性能。单例的对象也能在这样的方法里得以实现。</li>\n<li><strong>可以返回原返回类型的任何子类型。</strong> 可以返回对象，同时又不会使对象的类变成公有的。这种技术适用于基于接口的框架。</li>\n<li><strong>在创建参数化类型示例的时候，使代码变得更加简洁。</strong></li>\n</ul>\n<p>缺点：</p>\n<ul>\n<li><strong>类如果不含共有的或者受保护的构造器，就不能被子类化。</strong></li>\n<li><strong>静态工厂方法与其他静态方法实际上没有任何区别。</strong> 大家都知道用构造器实例化对象，却不能一眼看出这个静态方法是用来实例化对象的。</li>\n</ul>\n<p>静态工厂方法惯用名：</p>\n<ul>\n<li><strong>valueOf</strong>—-主要用于类型转换。</li>\n<li><strong>of</strong>—-valueOf的简洁方案。</li>\n<li><strong>getInstance</strong>—-返回的示例是通过参数来描述的，对于Singleton来说，该方法应该没有参数，直接返回唯一实例。</li>\n<li><strong>newInstance</strong>—-返回一个新的实例。</li>\n</ul>\n<h2 id=\"2-遇到多个构造器参数时要考虑使用构造器\"><a href=\"#2-遇到多个构造器参数时要考虑使用构造器\" class=\"headerlink\" title=\"2.遇到多个构造器参数时要考虑使用构造器\"></a>2.遇到多个构造器参数时要考虑使用构造器</h2><p>这里讲了把生活中一个对象抽象成类，我们实例化对象的三种设计思路：</p>\n<ul>\n<li><strong>重叠构造器模式</strong> 编写各种成员变量组合的构造器，实例化时选择我们需要的来。但是参数太多的话，构造器的数量就太多了，难以编写。</li>\n<li><strong>JavaBean模式</strong> 通过setter方法来设置参数，但是这样无法实现不可变对象，引发线程安全问题。</li>\n<li><strong>Builder模式</strong> 通过一个Builder内部类，实现setter赋值，然后再构造函数里将Builder的成员赋给我们实例化的对象。</li>\n</ul>\n<p><strong>Builder模式</strong>：</p>\n<pre><code class=\"java\">\n/**\n * @Description:\n * @Author: kongz\n * @Date: 2020/4/7 18:55\n */\npublic class People {\n\n    private String name;\n    private int age;\n    private String gender;\n\n    public People(Builder builder) {\n        name = builder.name;\n        age = builder.age;\n        gender = builder.gender;\n    }\n\n    public static class Builder {\n\n        private String name;\n        private int age;\n        private String gender;\n\n        public Builder(String name) {\n            this.name = name;\n        }\n\n        public Builder age(int age) {\n            this.age = age;\n            return this;\n        }\n\n        public Builder gender(String gender) {\n            this.gender = gender;\n            return this;\n        }\n\n        public People build() {\n            return new People(this);\n        }\n\n    }\n\n    @Override\n    public String toString() {\n        return this.name + &quot;--&quot; + this.age + &quot;--&quot; + this.gender;\n    }\n\n    public static void main(String[] args) {\n        People people = new Builder(&quot;kongz&quot;).age(20).gender(&quot;男&quot;).build();\n        System.out.println(people.toString());\n    }\n\n}</code></pre>\n<p>Builder模式的确也有不足，创建对象必须要先创建它的构造器，这也会浪费一些资源，虽然不是那么明显，但是比重叠构造器更加冗长。</p>\n<h2 id=\"3-用私有构造器或者枚举类型强化Singleton属性\"><a href=\"#3-用私有构造器或者枚举类型强化Singleton属性\" class=\"headerlink\" title=\"3.用私有构造器或者枚举类型强化Singleton属性\"></a>3.用私有构造器或者枚举类型强化Singleton属性</h2><p>在Java 1.5之前有两种方法实现Singleton，这两种方法都要把构造器保持为私有的，并导出共有的静态变量，以便客户端能够访问该类的唯一实例。</p>\n<ol>\n<li>第一种方法中，公有静态成员是个final域：</li>\n</ol>\n<pre><code class=\"java\">//singleton with public final field\npublic class Elvis {\n    public static final Elvis INSTANCE = new Elvis();\n\n    private Elvis(){ ... }\n\n    public void leaveTheBuilding() {\n        ...\n    }\n}</code></pre>\n<p>私有构造器仅被调用一次，用来实例化公有的静态final域Elvis.INSTANCE。由于外界无法调用构造器，所以保证了Elvis的全局唯一。<strong>但是想有特权的客户端可以通过AccessibleObject.setAccessable方法，通过反射机制调用私有构造器。如果要抵御这种攻击，可以修改构造器，让它在被要求创建第二个实例的时候抛出异常。</strong></p>\n<ol start=\"2\">\n<li>第二种方法中，公有的成员是个静态工厂方法。</li>\n</ol>\n<pre><code class=\"java\">//singleton with static factory\npublic class Elvis {\n    private static final Elvis INSTANCE = new Elvis();\n    private Elvis(){ ... }\n    public static Elvis getInstance() { return INSTANCE; }\n\n    public void leaveTheBuilding() { ... }\n}</code></pre>\n<p>对于静态方法Elvis.getInstance方法每次调用都会返回同一个对象引用，所以永远不会创建其他的Elvis对象。</p>\n<p>工厂方法的优势：</p>\n<ul>\n<li><strong>提供了灵活性：</strong> 在不改变api的前提下，可以改变该类是否应该为singleton的想法，因为客户都都是通过<code>getInstance</code>方法获取对象的。</li>\n<li><strong>泛型</strong></li>\n</ul>\n<p>上面两种方法要实现singleton类变成可序列化（Serializable），仅仅在生命中加上<code>implements Serializable</code>是不够的。<strong>为了维护并保证Singleton，必须声明所有的实例域都是瞬时（transient）的，并提供一个<code>readResolve</code>方法，否则每次反序列化一个序列化的实例时，都会创建一个新的实例。</strong></p>\n<pre><code class=\"java\">//readResolve method to preserve singleton property\nprivate Object readResolve() {\n    //Return the one true Elvis and let the garbage collector\n    //take care of the Elvis impersonator\n    return INSTANCE;\n}</code></pre>\n<pre><code>在jdk中ObjectInputStream的类中有readUnshared（）方法，上面详细解释了原因。\n我简单描述一下，那就是如果被反序列化的对象的类存在readResolve这个方法，\n他会调用这个方法来返回一个“array”（我也不明白），然后浅拷贝一份，作为返回值，\n并且无视掉反序列化的值，即使那个字节码已经被解析。\n————————————————\n版权声明：本文为CSDN博主「无始之名」的原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接及本声明。\n原文链接：https://blog.csdn.net/u011499747/java/article/details/50982956</code></pre><p>一个单例模式：</p>\n<pre><code class=\"java\">public class Elvis {\n    private static final Elvis INSTANCE = new Elvis();\n    private Elvis(){ ... }\n    public static Elvis getInstance() { return INSTANCE; }\n\n    public void leaveTheBuilding() { ... }\n    private Object readResolve() {\n        return INSTANCE;\n    }\n}</code></pre>\n","site":{"data":{}},"more":"<h1 id=\"创建和销毁对象\"><a href=\"#创建和销毁对象\" class=\"headerlink\" title=\"创建和销毁对象\"></a>创建和销毁对象</h1><h2 id=\"1-考虑使用静态工厂方法代替构造器\"><a href=\"#1-考虑使用静态工厂方法代替构造器\" class=\"headerlink\" title=\"1.考虑使用静态工厂方法代替构造器\"></a>1.考虑使用静态工厂方法代替构造器</h2><p>我们平时创建对象都是new一个，而new会调用类对应的构造器。但是还有一个方法，就是<strong>静态工厂方法</strong>。</p>\n<pre><code class=\"java\">public static Boolean valueOf(boolean b) {\n    return b ? Boolean.TRUE : Boolean.FALSE;\n}</code></pre>\n<p>上面是一个典型的示例。</p>\n<p>优点：</p>\n<ul>\n<li><strong>静态工厂方法有方法名。</strong> 新建对象可以通过参数列表不同来调用不通的构造器，但是这样没有文字描述，调用者很难一下理解构造器做了哪些操作。</li>\n<li><strong>每次调用不必都创建一个新对象。</strong> 这使得不可变类可以使用预先构造好的示例，或者将构建好的示例缓存起来，重复利用，从而避免创建不必要的重复对象。像上面的例子，就没有创建对象。这样有利于提高性能。单例的对象也能在这样的方法里得以实现。</li>\n<li><strong>可以返回原返回类型的任何子类型。</strong> 可以返回对象，同时又不会使对象的类变成公有的。这种技术适用于基于接口的框架。</li>\n<li><strong>在创建参数化类型示例的时候，使代码变得更加简洁。</strong></li>\n</ul>\n<p>缺点：</p>\n<ul>\n<li><strong>类如果不含共有的或者受保护的构造器，就不能被子类化。</strong></li>\n<li><strong>静态工厂方法与其他静态方法实际上没有任何区别。</strong> 大家都知道用构造器实例化对象，却不能一眼看出这个静态方法是用来实例化对象的。</li>\n</ul>\n<p>静态工厂方法惯用名：</p>\n<ul>\n<li><strong>valueOf</strong>—-主要用于类型转换。</li>\n<li><strong>of</strong>—-valueOf的简洁方案。</li>\n<li><strong>getInstance</strong>—-返回的示例是通过参数来描述的，对于Singleton来说，该方法应该没有参数，直接返回唯一实例。</li>\n<li><strong>newInstance</strong>—-返回一个新的实例。</li>\n</ul>\n<h2 id=\"2-遇到多个构造器参数时要考虑使用构造器\"><a href=\"#2-遇到多个构造器参数时要考虑使用构造器\" class=\"headerlink\" title=\"2.遇到多个构造器参数时要考虑使用构造器\"></a>2.遇到多个构造器参数时要考虑使用构造器</h2><p>这里讲了把生活中一个对象抽象成类，我们实例化对象的三种设计思路：</p>\n<ul>\n<li><strong>重叠构造器模式</strong> 编写各种成员变量组合的构造器，实例化时选择我们需要的来。但是参数太多的话，构造器的数量就太多了，难以编写。</li>\n<li><strong>JavaBean模式</strong> 通过setter方法来设置参数，但是这样无法实现不可变对象，引发线程安全问题。</li>\n<li><strong>Builder模式</strong> 通过一个Builder内部类，实现setter赋值，然后再构造函数里将Builder的成员赋给我们实例化的对象。</li>\n</ul>\n<p><strong>Builder模式</strong>：</p>\n<pre><code class=\"java\">\n/**\n * @Description:\n * @Author: kongz\n * @Date: 2020/4/7 18:55\n */\npublic class People {\n\n    private String name;\n    private int age;\n    private String gender;\n\n    public People(Builder builder) {\n        name = builder.name;\n        age = builder.age;\n        gender = builder.gender;\n    }\n\n    public static class Builder {\n\n        private String name;\n        private int age;\n        private String gender;\n\n        public Builder(String name) {\n            this.name = name;\n        }\n\n        public Builder age(int age) {\n            this.age = age;\n            return this;\n        }\n\n        public Builder gender(String gender) {\n            this.gender = gender;\n            return this;\n        }\n\n        public People build() {\n            return new People(this);\n        }\n\n    }\n\n    @Override\n    public String toString() {\n        return this.name + &quot;--&quot; + this.age + &quot;--&quot; + this.gender;\n    }\n\n    public static void main(String[] args) {\n        People people = new Builder(&quot;kongz&quot;).age(20).gender(&quot;男&quot;).build();\n        System.out.println(people.toString());\n    }\n\n}</code></pre>\n<p>Builder模式的确也有不足，创建对象必须要先创建它的构造器，这也会浪费一些资源，虽然不是那么明显，但是比重叠构造器更加冗长。</p>\n<h2 id=\"3-用私有构造器或者枚举类型强化Singleton属性\"><a href=\"#3-用私有构造器或者枚举类型强化Singleton属性\" class=\"headerlink\" title=\"3.用私有构造器或者枚举类型强化Singleton属性\"></a>3.用私有构造器或者枚举类型强化Singleton属性</h2><p>在Java 1.5之前有两种方法实现Singleton，这两种方法都要把构造器保持为私有的，并导出共有的静态变量，以便客户端能够访问该类的唯一实例。</p>\n<ol>\n<li>第一种方法中，公有静态成员是个final域：</li>\n</ol>\n<pre><code class=\"java\">//singleton with public final field\npublic class Elvis {\n    public static final Elvis INSTANCE = new Elvis();\n\n    private Elvis(){ ... }\n\n    public void leaveTheBuilding() {\n        ...\n    }\n}</code></pre>\n<p>私有构造器仅被调用一次，用来实例化公有的静态final域Elvis.INSTANCE。由于外界无法调用构造器，所以保证了Elvis的全局唯一。<strong>但是想有特权的客户端可以通过AccessibleObject.setAccessable方法，通过反射机制调用私有构造器。如果要抵御这种攻击，可以修改构造器，让它在被要求创建第二个实例的时候抛出异常。</strong></p>\n<ol start=\"2\">\n<li>第二种方法中，公有的成员是个静态工厂方法。</li>\n</ol>\n<pre><code class=\"java\">//singleton with static factory\npublic class Elvis {\n    private static final Elvis INSTANCE = new Elvis();\n    private Elvis(){ ... }\n    public static Elvis getInstance() { return INSTANCE; }\n\n    public void leaveTheBuilding() { ... }\n}</code></pre>\n<p>对于静态方法Elvis.getInstance方法每次调用都会返回同一个对象引用，所以永远不会创建其他的Elvis对象。</p>\n<p>工厂方法的优势：</p>\n<ul>\n<li><strong>提供了灵活性：</strong> 在不改变api的前提下，可以改变该类是否应该为singleton的想法，因为客户都都是通过<code>getInstance</code>方法获取对象的。</li>\n<li><strong>泛型</strong></li>\n</ul>\n<p>上面两种方法要实现singleton类变成可序列化（Serializable），仅仅在生命中加上<code>implements Serializable</code>是不够的。<strong>为了维护并保证Singleton，必须声明所有的实例域都是瞬时（transient）的，并提供一个<code>readResolve</code>方法，否则每次反序列化一个序列化的实例时，都会创建一个新的实例。</strong></p>\n<pre><code class=\"java\">//readResolve method to preserve singleton property\nprivate Object readResolve() {\n    //Return the one true Elvis and let the garbage collector\n    //take care of the Elvis impersonator\n    return INSTANCE;\n}</code></pre>\n<pre><code>在jdk中ObjectInputStream的类中有readUnshared（）方法，上面详细解释了原因。\n我简单描述一下，那就是如果被反序列化的对象的类存在readResolve这个方法，\n他会调用这个方法来返回一个“array”（我也不明白），然后浅拷贝一份，作为返回值，\n并且无视掉反序列化的值，即使那个字节码已经被解析。\n————————————————\n版权声明：本文为CSDN博主「无始之名」的原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接及本声明。\n原文链接：https://blog.csdn.net/u011499747/java/article/details/50982956</code></pre><p>一个单例模式：</p>\n<pre><code class=\"java\">public class Elvis {\n    private static final Elvis INSTANCE = new Elvis();\n    private Elvis(){ ... }\n    public static Elvis getInstance() { return INSTANCE; }\n\n    public void leaveTheBuilding() { ... }\n    private Object readResolve() {\n        return INSTANCE;\n    }\n}</code></pre>\n"},{"title":"CAS","excerpt":"","comments":1,"date":"2020-04-15T16:30:52.000Z","_content":"\n## 什么是CAS\n\nCAS是compare and swap的简称，字面意思就是比较并交换，这里的交换其实就是更新的意思，是线程本地缓存和系统内存之间的数据交换。从内存上取值A，和预期值B比较，如果内存值A和预期值B结果相同，那么我们就把新值C更新到内存，如果不想等，就重复上述过程直到操作成功为止。\n\n## CAS过程\n\n以AtomicInteger为例：\n\n```java\n    public final int incrementAndGet() {\n        return unsafe.getAndAddInt(this, valueOffset, 1) + 1;\n    }\n```\n\n这是AtomicInteger的自增方法，返回自增后的值。\n\n看到这里调用的是Unsafe类的方法`getAndAddInt`。\n\nUnsafe 类是个跟底层硬件CPU指令通讯的复制工具类。Unsafe类提供了硬件级别的原子操作，主要有以下功能：\n- 分配内存、释放内存：类中提供的3个本地方法`allocateMemory`、`reallocateMemory`、`freeMemory`分别用于分配内存，扩充内存和释放内存，与C语言中的3个方法对应。\n- 可以定位对象某字段的内存位置，也可以修改对象的字段值，即使它是私有的。\n  - 字段的定位：JAVA中对象的字段的定位可能通过`staticFieldOffset`方法实现，该方法返回给定field的内存地址偏移量，这个值对于给定的filed是唯一的且是固定不变的。`getIntVolatile`方法获取对象中offset偏移地址对应的整型field的值,支持volatile load语义。`getLong`方法获取对象中offset偏移地址对应的long型field的值\n  - 数组元素定位：Unsafe类中有很多以BASE_OFFSET结尾的常量，比如ARRAY_INT_BASE_OFFSET，ARRAY_BYTE_BASE_OFFSET等，这些常量值是通过`arrayBaseOffset`方法得到的。`arrayBaseOffset`方法是一个本地方法，可以获取数组第一个元素的偏移地址。Unsafe类中还有很多以INDEX_SCALE结尾的常量，比如 ARRAY_INT_INDEX_SCALE ， ARRAY_BYTE_INDEX_SCALE等，这些常量值是通过`arrayIndexScale`方法得到的。`arrayIndexScale`方法也是一个本地方法，可以获取数组的转换因子，也就是数组中元素的增量地址。将`arrayBaseOffset`与`arrayIndexScale`配合使用，可以定位数组中每个元素在内存中的位置。\n- 挂起与恢复。将一个线程进行挂起是通过`park`方法实现的，调用`park`后，线程将一直阻塞直到超时或者中断等条件出现。`unpark`可以终止一个挂起的线程，使其恢复正常。整个并发框架中对线程的挂起操作被封装在`LockSupport`类中，`LockSupport`类中有各种版本`pack`方法，但最终都调用了`Unsafe.park()`方法。\n- CAS操作。是通过`compareAndSwapXXX`方法实现的。\n\n\n\n下面是`getAndAddInt`方法：\n```java\n    public final int getAndAddInt(Object var1, long var2, int var4) {\n        int var5;\n        do {\n            var5 = this.getIntVolatile(var1, var2);\n        } while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4));\n\n        return var5;\n    }\n```\n这里是一个循环，通过`getIntVolatile`获取var1对象中var2偏移地址对应的field的值，循环的条件是`compareAndSwapInt`方法返回false，如果`compareAndSwapInt`方法一直返回false，则继续调用`getIntVolatile`。\n\n这里看一下`compareAndSwapInt`的参数列表：\n1. this，Unsafe 对象本身，需要通过这个类来获取 value 的内存偏移地址。这里是var1。\n2. valueOffset，value 变量的内存偏移地址。这里是var2。\n3. expect，期望更新的值。这里是var5。\n4. update，要更新的最新值。这里是var5+var4。\n\n在这个方法里，如果expect期望值与field的当前值相同，CPU会设置field的值为update这个新值。否则不做任何操作。无论哪种情况，它都会在CAS指令之前返回该位置的值。\n\n下面是c++实现代码:\n\n```cpp\nstatic inline bool\ncompareAndSwap (volatile jint *addr, jint old, jint new_val)\n{\n  jboolean result = false;\n  spinlock lock;\n  if ((result = (*addr == old)))\n    *addr = new_val;\n  return result;\n}\n```\n\n这里很关键的一个变量就是valueOffset。\n\n```java\n// setup to use Unsafe.compareAndSwapInt for updates\n    private static final Unsafe unsafe = Unsafe.getUnsafe();\n    private static final long valueOffset;\n\n    static {\n        try {\n            valueOffset = unsafe.objectFieldOffset\n                (AtomicInteger.class.getDeclaredField(\"value\"));\n        } catch (Exception ex) { throw new Error(ex); }\n    }\n\n    private volatile int value;\n```\n\nAtomicInteger类在rt.jar包下，所以AtomicInteger类是通过Bootstrap根类加载器进行加载的。\n\n```java\n@CallerSensitive\n    public static Unsafe getUnsafe() {\n        Class var0 = Reflection.getCallerClass();\n        if (!VM.isSystemDomainLoader(var0.getClassLoader())) {\n            throw new SecurityException(\"Unsafe\");\n        } else {\n            return theUnsafe;\n        }\n    }\n```\n\n类加载器委托关系：\n```mermaid\ngraph BT\nA(Application ClassLoader) --> B(Extension ClassLoader)\n    B --> C(BootStrap ClassLoader)\n```\n\n当AtomicInteger加载当时候，静态代码块会执行，通过`Unsafe.getUnsafe()`获取到unsafe实例，通过反射获取到保存着实际值的value字段对象，然后通过`objectFieldOffset`获取到这个value字段对象对应的offset。这样后面的cas操作就可以正常使用了。","source":"_posts/2020-04-14-kongzheng1993-CAS.md","raw":"---\ntitle: CAS\nexcerpt: ''\ntags: [Java]\ncategories: [Java]\ncomments: true\ndate: 2020-04-16 00:30:52\n---\n\n## 什么是CAS\n\nCAS是compare and swap的简称，字面意思就是比较并交换，这里的交换其实就是更新的意思，是线程本地缓存和系统内存之间的数据交换。从内存上取值A，和预期值B比较，如果内存值A和预期值B结果相同，那么我们就把新值C更新到内存，如果不想等，就重复上述过程直到操作成功为止。\n\n## CAS过程\n\n以AtomicInteger为例：\n\n```java\n    public final int incrementAndGet() {\n        return unsafe.getAndAddInt(this, valueOffset, 1) + 1;\n    }\n```\n\n这是AtomicInteger的自增方法，返回自增后的值。\n\n看到这里调用的是Unsafe类的方法`getAndAddInt`。\n\nUnsafe 类是个跟底层硬件CPU指令通讯的复制工具类。Unsafe类提供了硬件级别的原子操作，主要有以下功能：\n- 分配内存、释放内存：类中提供的3个本地方法`allocateMemory`、`reallocateMemory`、`freeMemory`分别用于分配内存，扩充内存和释放内存，与C语言中的3个方法对应。\n- 可以定位对象某字段的内存位置，也可以修改对象的字段值，即使它是私有的。\n  - 字段的定位：JAVA中对象的字段的定位可能通过`staticFieldOffset`方法实现，该方法返回给定field的内存地址偏移量，这个值对于给定的filed是唯一的且是固定不变的。`getIntVolatile`方法获取对象中offset偏移地址对应的整型field的值,支持volatile load语义。`getLong`方法获取对象中offset偏移地址对应的long型field的值\n  - 数组元素定位：Unsafe类中有很多以BASE_OFFSET结尾的常量，比如ARRAY_INT_BASE_OFFSET，ARRAY_BYTE_BASE_OFFSET等，这些常量值是通过`arrayBaseOffset`方法得到的。`arrayBaseOffset`方法是一个本地方法，可以获取数组第一个元素的偏移地址。Unsafe类中还有很多以INDEX_SCALE结尾的常量，比如 ARRAY_INT_INDEX_SCALE ， ARRAY_BYTE_INDEX_SCALE等，这些常量值是通过`arrayIndexScale`方法得到的。`arrayIndexScale`方法也是一个本地方法，可以获取数组的转换因子，也就是数组中元素的增量地址。将`arrayBaseOffset`与`arrayIndexScale`配合使用，可以定位数组中每个元素在内存中的位置。\n- 挂起与恢复。将一个线程进行挂起是通过`park`方法实现的，调用`park`后，线程将一直阻塞直到超时或者中断等条件出现。`unpark`可以终止一个挂起的线程，使其恢复正常。整个并发框架中对线程的挂起操作被封装在`LockSupport`类中，`LockSupport`类中有各种版本`pack`方法，但最终都调用了`Unsafe.park()`方法。\n- CAS操作。是通过`compareAndSwapXXX`方法实现的。\n\n\n\n下面是`getAndAddInt`方法：\n```java\n    public final int getAndAddInt(Object var1, long var2, int var4) {\n        int var5;\n        do {\n            var5 = this.getIntVolatile(var1, var2);\n        } while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4));\n\n        return var5;\n    }\n```\n这里是一个循环，通过`getIntVolatile`获取var1对象中var2偏移地址对应的field的值，循环的条件是`compareAndSwapInt`方法返回false，如果`compareAndSwapInt`方法一直返回false，则继续调用`getIntVolatile`。\n\n这里看一下`compareAndSwapInt`的参数列表：\n1. this，Unsafe 对象本身，需要通过这个类来获取 value 的内存偏移地址。这里是var1。\n2. valueOffset，value 变量的内存偏移地址。这里是var2。\n3. expect，期望更新的值。这里是var5。\n4. update，要更新的最新值。这里是var5+var4。\n\n在这个方法里，如果expect期望值与field的当前值相同，CPU会设置field的值为update这个新值。否则不做任何操作。无论哪种情况，它都会在CAS指令之前返回该位置的值。\n\n下面是c++实现代码:\n\n```cpp\nstatic inline bool\ncompareAndSwap (volatile jint *addr, jint old, jint new_val)\n{\n  jboolean result = false;\n  spinlock lock;\n  if ((result = (*addr == old)))\n    *addr = new_val;\n  return result;\n}\n```\n\n这里很关键的一个变量就是valueOffset。\n\n```java\n// setup to use Unsafe.compareAndSwapInt for updates\n    private static final Unsafe unsafe = Unsafe.getUnsafe();\n    private static final long valueOffset;\n\n    static {\n        try {\n            valueOffset = unsafe.objectFieldOffset\n                (AtomicInteger.class.getDeclaredField(\"value\"));\n        } catch (Exception ex) { throw new Error(ex); }\n    }\n\n    private volatile int value;\n```\n\nAtomicInteger类在rt.jar包下，所以AtomicInteger类是通过Bootstrap根类加载器进行加载的。\n\n```java\n@CallerSensitive\n    public static Unsafe getUnsafe() {\n        Class var0 = Reflection.getCallerClass();\n        if (!VM.isSystemDomainLoader(var0.getClassLoader())) {\n            throw new SecurityException(\"Unsafe\");\n        } else {\n            return theUnsafe;\n        }\n    }\n```\n\n类加载器委托关系：\n```mermaid\ngraph BT\nA(Application ClassLoader) --> B(Extension ClassLoader)\n    B --> C(BootStrap ClassLoader)\n```\n\n当AtomicInteger加载当时候，静态代码块会执行，通过`Unsafe.getUnsafe()`获取到unsafe实例，通过反射获取到保存着实际值的value字段对象，然后通过`objectFieldOffset`获取到这个value字段对象对应的offset。这样后面的cas操作就可以正常使用了。","slug":"kongzheng1993-CAS","published":1,"updated":"2023-03-08T07:05:58.794Z","layout":"post","photos":[],"link":"","_id":"clg0k2ae5002ot26fukqznvri","content":"<h2 id=\"什么是CAS\"><a href=\"#什么是CAS\" class=\"headerlink\" title=\"什么是CAS\"></a>什么是CAS</h2><p>CAS是compare and swap的简称，字面意思就是比较并交换，这里的交换其实就是更新的意思，是线程本地缓存和系统内存之间的数据交换。从内存上取值A，和预期值B比较，如果内存值A和预期值B结果相同，那么我们就把新值C更新到内存，如果不想等，就重复上述过程直到操作成功为止。</p>\n<h2 id=\"CAS过程\"><a href=\"#CAS过程\" class=\"headerlink\" title=\"CAS过程\"></a>CAS过程</h2><p>以AtomicInteger为例：</p>\n<pre><code class=\"java\">    public final int incrementAndGet() {\n        return unsafe.getAndAddInt(this, valueOffset, 1) + 1;\n    }</code></pre>\n<p>这是AtomicInteger的自增方法，返回自增后的值。</p>\n<p>看到这里调用的是Unsafe类的方法<code>getAndAddInt</code>。</p>\n<p>Unsafe 类是个跟底层硬件CPU指令通讯的复制工具类。Unsafe类提供了硬件级别的原子操作，主要有以下功能：</p>\n<ul>\n<li>分配内存、释放内存：类中提供的3个本地方法<code>allocateMemory</code>、<code>reallocateMemory</code>、<code>freeMemory</code>分别用于分配内存，扩充内存和释放内存，与C语言中的3个方法对应。</li>\n<li>可以定位对象某字段的内存位置，也可以修改对象的字段值，即使它是私有的。<ul>\n<li>字段的定位：JAVA中对象的字段的定位可能通过<code>staticFieldOffset</code>方法实现，该方法返回给定field的内存地址偏移量，这个值对于给定的filed是唯一的且是固定不变的。<code>getIntVolatile</code>方法获取对象中offset偏移地址对应的整型field的值,支持volatile load语义。<code>getLong</code>方法获取对象中offset偏移地址对应的long型field的值</li>\n<li>数组元素定位：Unsafe类中有很多以BASE_OFFSET结尾的常量，比如ARRAY_INT_BASE_OFFSET，ARRAY_BYTE_BASE_OFFSET等，这些常量值是通过<code>arrayBaseOffset</code>方法得到的。<code>arrayBaseOffset</code>方法是一个本地方法，可以获取数组第一个元素的偏移地址。Unsafe类中还有很多以INDEX_SCALE结尾的常量，比如 ARRAY_INT_INDEX_SCALE ， ARRAY_BYTE_INDEX_SCALE等，这些常量值是通过<code>arrayIndexScale</code>方法得到的。<code>arrayIndexScale</code>方法也是一个本地方法，可以获取数组的转换因子，也就是数组中元素的增量地址。将<code>arrayBaseOffset</code>与<code>arrayIndexScale</code>配合使用，可以定位数组中每个元素在内存中的位置。</li>\n</ul>\n</li>\n<li>挂起与恢复。将一个线程进行挂起是通过<code>park</code>方法实现的，调用<code>park</code>后，线程将一直阻塞直到超时或者中断等条件出现。<code>unpark</code>可以终止一个挂起的线程，使其恢复正常。整个并发框架中对线程的挂起操作被封装在<code>LockSupport</code>类中，<code>LockSupport</code>类中有各种版本<code>pack</code>方法，但最终都调用了<code>Unsafe.park()</code>方法。</li>\n<li>CAS操作。是通过<code>compareAndSwapXXX</code>方法实现的。</li>\n</ul>\n<p>下面是<code>getAndAddInt</code>方法：</p>\n<pre><code class=\"java\">    public final int getAndAddInt(Object var1, long var2, int var4) {\n        int var5;\n        do {\n            var5 = this.getIntVolatile(var1, var2);\n        } while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4));\n\n        return var5;\n    }</code></pre>\n<p>这里是一个循环，通过<code>getIntVolatile</code>获取var1对象中var2偏移地址对应的field的值，循环的条件是<code>compareAndSwapInt</code>方法返回false，如果<code>compareAndSwapInt</code>方法一直返回false，则继续调用<code>getIntVolatile</code>。</p>\n<p>这里看一下<code>compareAndSwapInt</code>的参数列表：</p>\n<ol>\n<li>this，Unsafe 对象本身，需要通过这个类来获取 value 的内存偏移地址。这里是var1。</li>\n<li>valueOffset，value 变量的内存偏移地址。这里是var2。</li>\n<li>expect，期望更新的值。这里是var5。</li>\n<li>update，要更新的最新值。这里是var5+var4。</li>\n</ol>\n<p>在这个方法里，如果expect期望值与field的当前值相同，CPU会设置field的值为update这个新值。否则不做任何操作。无论哪种情况，它都会在CAS指令之前返回该位置的值。</p>\n<p>下面是c++实现代码:</p>\n<pre><code class=\"cpp\">static inline bool\ncompareAndSwap (volatile jint *addr, jint old, jint new_val)\n{\n  jboolean result = false;\n  spinlock lock;\n  if ((result = (*addr == old)))\n    *addr = new_val;\n  return result;\n}</code></pre>\n<p>这里很关键的一个变量就是valueOffset。</p>\n<pre><code class=\"java\">// setup to use Unsafe.compareAndSwapInt for updates\n    private static final Unsafe unsafe = Unsafe.getUnsafe();\n    private static final long valueOffset;\n\n    static {\n        try {\n            valueOffset = unsafe.objectFieldOffset\n                (AtomicInteger.class.getDeclaredField(&quot;value&quot;));\n        } catch (Exception ex) { throw new Error(ex); }\n    }\n\n    private volatile int value;</code></pre>\n<p>AtomicInteger类在rt.jar包下，所以AtomicInteger类是通过Bootstrap根类加载器进行加载的。</p>\n<pre><code class=\"java\">@CallerSensitive\n    public static Unsafe getUnsafe() {\n        Class var0 = Reflection.getCallerClass();\n        if (!VM.isSystemDomainLoader(var0.getClassLoader())) {\n            throw new SecurityException(&quot;Unsafe&quot;);\n        } else {\n            return theUnsafe;\n        }\n    }</code></pre>\n<p>类加载器委托关系：</p>\n<pre><code class=\"mermaid\">graph BT\nA(Application ClassLoader) --&gt; B(Extension ClassLoader)\n    B --&gt; C(BootStrap ClassLoader)</code></pre>\n<p>当AtomicInteger加载当时候，静态代码块会执行，通过<code>Unsafe.getUnsafe()</code>获取到unsafe实例，通过反射获取到保存着实际值的value字段对象，然后通过<code>objectFieldOffset</code>获取到这个value字段对象对应的offset。这样后面的cas操作就可以正常使用了。</p>\n","site":{"data":{}},"more":"<h2 id=\"什么是CAS\"><a href=\"#什么是CAS\" class=\"headerlink\" title=\"什么是CAS\"></a>什么是CAS</h2><p>CAS是compare and swap的简称，字面意思就是比较并交换，这里的交换其实就是更新的意思，是线程本地缓存和系统内存之间的数据交换。从内存上取值A，和预期值B比较，如果内存值A和预期值B结果相同，那么我们就把新值C更新到内存，如果不想等，就重复上述过程直到操作成功为止。</p>\n<h2 id=\"CAS过程\"><a href=\"#CAS过程\" class=\"headerlink\" title=\"CAS过程\"></a>CAS过程</h2><p>以AtomicInteger为例：</p>\n<pre><code class=\"java\">    public final int incrementAndGet() {\n        return unsafe.getAndAddInt(this, valueOffset, 1) + 1;\n    }</code></pre>\n<p>这是AtomicInteger的自增方法，返回自增后的值。</p>\n<p>看到这里调用的是Unsafe类的方法<code>getAndAddInt</code>。</p>\n<p>Unsafe 类是个跟底层硬件CPU指令通讯的复制工具类。Unsafe类提供了硬件级别的原子操作，主要有以下功能：</p>\n<ul>\n<li>分配内存、释放内存：类中提供的3个本地方法<code>allocateMemory</code>、<code>reallocateMemory</code>、<code>freeMemory</code>分别用于分配内存，扩充内存和释放内存，与C语言中的3个方法对应。</li>\n<li>可以定位对象某字段的内存位置，也可以修改对象的字段值，即使它是私有的。<ul>\n<li>字段的定位：JAVA中对象的字段的定位可能通过<code>staticFieldOffset</code>方法实现，该方法返回给定field的内存地址偏移量，这个值对于给定的filed是唯一的且是固定不变的。<code>getIntVolatile</code>方法获取对象中offset偏移地址对应的整型field的值,支持volatile load语义。<code>getLong</code>方法获取对象中offset偏移地址对应的long型field的值</li>\n<li>数组元素定位：Unsafe类中有很多以BASE_OFFSET结尾的常量，比如ARRAY_INT_BASE_OFFSET，ARRAY_BYTE_BASE_OFFSET等，这些常量值是通过<code>arrayBaseOffset</code>方法得到的。<code>arrayBaseOffset</code>方法是一个本地方法，可以获取数组第一个元素的偏移地址。Unsafe类中还有很多以INDEX_SCALE结尾的常量，比如 ARRAY_INT_INDEX_SCALE ， ARRAY_BYTE_INDEX_SCALE等，这些常量值是通过<code>arrayIndexScale</code>方法得到的。<code>arrayIndexScale</code>方法也是一个本地方法，可以获取数组的转换因子，也就是数组中元素的增量地址。将<code>arrayBaseOffset</code>与<code>arrayIndexScale</code>配合使用，可以定位数组中每个元素在内存中的位置。</li>\n</ul>\n</li>\n<li>挂起与恢复。将一个线程进行挂起是通过<code>park</code>方法实现的，调用<code>park</code>后，线程将一直阻塞直到超时或者中断等条件出现。<code>unpark</code>可以终止一个挂起的线程，使其恢复正常。整个并发框架中对线程的挂起操作被封装在<code>LockSupport</code>类中，<code>LockSupport</code>类中有各种版本<code>pack</code>方法，但最终都调用了<code>Unsafe.park()</code>方法。</li>\n<li>CAS操作。是通过<code>compareAndSwapXXX</code>方法实现的。</li>\n</ul>\n<p>下面是<code>getAndAddInt</code>方法：</p>\n<pre><code class=\"java\">    public final int getAndAddInt(Object var1, long var2, int var4) {\n        int var5;\n        do {\n            var5 = this.getIntVolatile(var1, var2);\n        } while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4));\n\n        return var5;\n    }</code></pre>\n<p>这里是一个循环，通过<code>getIntVolatile</code>获取var1对象中var2偏移地址对应的field的值，循环的条件是<code>compareAndSwapInt</code>方法返回false，如果<code>compareAndSwapInt</code>方法一直返回false，则继续调用<code>getIntVolatile</code>。</p>\n<p>这里看一下<code>compareAndSwapInt</code>的参数列表：</p>\n<ol>\n<li>this，Unsafe 对象本身，需要通过这个类来获取 value 的内存偏移地址。这里是var1。</li>\n<li>valueOffset，value 变量的内存偏移地址。这里是var2。</li>\n<li>expect，期望更新的值。这里是var5。</li>\n<li>update，要更新的最新值。这里是var5+var4。</li>\n</ol>\n<p>在这个方法里，如果expect期望值与field的当前值相同，CPU会设置field的值为update这个新值。否则不做任何操作。无论哪种情况，它都会在CAS指令之前返回该位置的值。</p>\n<p>下面是c++实现代码:</p>\n<pre><code class=\"cpp\">static inline bool\ncompareAndSwap (volatile jint *addr, jint old, jint new_val)\n{\n  jboolean result = false;\n  spinlock lock;\n  if ((result = (*addr == old)))\n    *addr = new_val;\n  return result;\n}</code></pre>\n<p>这里很关键的一个变量就是valueOffset。</p>\n<pre><code class=\"java\">// setup to use Unsafe.compareAndSwapInt for updates\n    private static final Unsafe unsafe = Unsafe.getUnsafe();\n    private static final long valueOffset;\n\n    static {\n        try {\n            valueOffset = unsafe.objectFieldOffset\n                (AtomicInteger.class.getDeclaredField(&quot;value&quot;));\n        } catch (Exception ex) { throw new Error(ex); }\n    }\n\n    private volatile int value;</code></pre>\n<p>AtomicInteger类在rt.jar包下，所以AtomicInteger类是通过Bootstrap根类加载器进行加载的。</p>\n<pre><code class=\"java\">@CallerSensitive\n    public static Unsafe getUnsafe() {\n        Class var0 = Reflection.getCallerClass();\n        if (!VM.isSystemDomainLoader(var0.getClassLoader())) {\n            throw new SecurityException(&quot;Unsafe&quot;);\n        } else {\n            return theUnsafe;\n        }\n    }</code></pre>\n<p>类加载器委托关系：</p>\n<pre><code class=\"mermaid\">graph BT\nA(Application ClassLoader) --&gt; B(Extension ClassLoader)\n    B --&gt; C(BootStrap ClassLoader)</code></pre>\n<p>当AtomicInteger加载当时候，静态代码块会执行，通过<code>Unsafe.getUnsafe()</code>获取到unsafe实例，通过反射获取到保存着实际值的value字段对象，然后通过<code>objectFieldOffset</code>获取到这个value字段对象对应的offset。这样后面的cas操作就可以正常使用了。</p>\n"},{"title":"Java对象头","excerpt":"","comments":1,"date":"2020-04-13T16:30:52.000Z","_content":"\n## Java对象\n\n在JVM中，实例对象在内存中的布局分为三块区域：对象头、实例变量和填充数据。如下：\n\n<img src=\"Java_Monitor.png\">\n　　　　\n\n**实例变量：** 存放类的属性数据信息，包括父类的属性信息，如果是数组的实例部分还包括数组的长度，这部分内存按4字节对齐。其实就是在java代码中能看到的属性和他们的值。 \n\n**填充数据：** 由于虚拟机要求对象起始地址必须是8字节的整数倍。填充数据不是必须存在的，仅仅是为了字节对齐，这点了解即可。\n\n**对象头：** Hotspot虚拟机的对象头主要包括两部分数据：Mark Word（标记字段）、Klass Pointer（类型指针）、Array length（数组长度，只有数组类型才有）。其中Klass Point【Class Metadata Address 】是对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例，Mark Word用于存储对象自身的运行时数据，它是实现轻量级锁和偏向锁的关键。\n\n### 对象头-Mark Word（标记字段）\n\n- Mark Word记录了对象和锁有关的信息，当这个对象被synchronized关键字当成同步锁时，围绕这个锁的一系列操作都和Mark Word有关。\n- Mark Word在32位JVM中的长度是32bit，在64位JVM中长度是64bit。\n- Mark Word在不同的锁状态下存储的内容不同。\n\n<table border=\"1\" cellspacing=\"0\">\n<tbody>\n<tr>\n<td style=\"background-color: #bfbfbf; width: 71pt;\" rowspan=\"2\">\n<p style=\"margin-left: 0cm;\">锁状态</p>\n</td>\n<td style=\"background-color: #bfbfbf; width: 142pt;\" colspan=\"2\">\n<p style=\"margin-left: 0cm;\">25bit</p>\n</td>\n<td style=\"background-color: #bfbfbf; width: 71pt;\" rowspan=\"2\">\n<p style=\"margin-left: 0cm;\">4bit</p>\n</td>\n<td style=\"background-color: #bfbfbf; width: 71.05pt;\">\n<p style=\"margin-left: 0cm;\">1bit</p>\n</td>\n<td style=\"background-color: #bfbfbf; width: 71.05pt;\">\n<p style=\"margin-left: 0cm;\">2bit</p>\n</td>\n</tr>\n<tr>\n<td style=\"background-color: #bfbfbf; width: 71pt;\">\n<p style=\"margin-left: 0cm;\">23bit</p>\n</td>\n<td style=\"background-color: #bfbfbf; width: 71pt;\">\n<p style=\"margin-left: 0cm;\">2bit</p>\n</td>\n<td style=\"background-color: #bfbfbf; width: 71.05pt;\">\n<p style=\"margin-left: 0cm;\">是否偏向锁</p>\n</td>\n<td style=\"background-color: #bfbfbf; width: 71.05pt;\">\n<p style=\"margin-left: 0cm;\">锁标志位</p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: top; width: 71pt;\">\n<p style=\"margin-left: 0cm;\">无锁</p>\n</td>\n<td style=\"vertical-align: top; width: 142pt;\" colspan=\"2\">\n<p style=\"margin-left: 0cm;\">对象的HashCode</p>\n</td>\n<td style=\"vertical-align: top; width: 71pt;\">\n<p style=\"margin-left: 0cm;\">分代年龄</p>\n</td>\n<td style=\"vertical-align: top; width: 71.05pt;\">\n<p style=\"margin-left: 0cm;\">0</p>\n</td>\n<td style=\"vertical-align: top; width: 71.05pt;\">\n<p style=\"margin-left: 0cm;\">01</p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: top; width: 71pt;\">\n<p style=\"margin-left: 0cm;\">偏向锁</p>\n</td>\n<td style=\"vertical-align: top; width: 71pt;\">\n<p style=\"margin-left: 0cm;\">线程ID</p>\n</td>\n<td style=\"vertical-align: top; width: 71pt;\">\n<p style=\"margin-left: 0cm;\">Epoch</p>\n</td>\n<td style=\"vertical-align: top; width: 71pt;\">\n<p style=\"margin-left: 0cm;\">分代年龄</p>\n</td>\n<td style=\"vertical-align: top; width: 71.05pt;\">\n<p style=\"margin-left: 0cm;\">1</p>\n</td>\n<td style=\"vertical-align: top; width: 71.05pt;\">\n<p style=\"margin-left: 0cm;\">01</p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: top; width: 71pt;\">\n<p style=\"margin-left: 0cm;\">轻量级锁</p>\n</td>\n<td style=\"vertical-align: top; width: 284.05pt;\" colspan=\"4\">\n<p style=\"margin-left: 0cm;\">指向栈中锁记录的指针</p>\n</td>\n<td style=\"vertical-align: top; width: 71.05pt;\">\n<p style=\"margin-left: 0cm;\">00</p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: top; width: 71pt;\">\n<p style=\"margin-left: 0cm;\">重量级锁</p>\n</td>\n<td style=\"vertical-align: top; width: 284.05pt;\" colspan=\"4\">\n<p style=\"margin-left: 0cm;\">指向重量级锁的指针</p>\n</td>\n<td style=\"vertical-align: top; width: 71.05pt;\">\n<p style=\"margin-left: 0cm;\">10</p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: top; width: 71pt;\">\n<p style=\"margin-left: 0cm;\">GC标记</p>\n</td>\n<td style=\"vertical-align: top; width: 284.05pt;\" colspan=\"4\">\n<p style=\"margin-left: 0cm;\">空</p>\n</td>\n<td style=\"vertical-align: top; width: 71.05pt;\">\n<p style=\"margin-left: 0cm;\">11</p>\n</td>\n</tr>\n</tbody>\n</table>\n\n**锁的级别从低到高：无锁、偏向锁、轻量级锁、重量级锁。**\n\n其中无锁和偏向锁的锁标志位都是01，只是在前面的1bit区分了这是无锁状态还是偏向锁状态。\n\nJDK1.6以后的版本在处理同步锁时存在锁升级的概念，JVM对于同步锁的处理是从偏向锁开始的，随着竞争越来越激烈，处理方式从偏向锁升级到轻量级锁，最终升级到重量级锁。\n\nJVM一般是这样使用锁和Mark Word的：\n1. 当没有被当成锁时，这就是一个普通的对象，Mark Word记录对象的HashCode，锁标志位是01，是否偏向锁那一位是0。\n2. 当对象被当做同步锁并有一个线程A抢到了锁时，锁标志位还是01，但是否偏向锁那一位改成1，前23bit记录抢到锁的线程id，表示进入偏向锁状态。\n3. 当线程A再次试图来获得锁时，JVM发现同步锁对象的标志位是01，是否偏向锁是1，也就是偏向状态，Mark Word中记录的线程id就是线程A自己的id，表示线程A已经获得了这个偏向锁，可以执行同步锁的代码。\n4. 当线程B试图获得这个锁时，JVM发现同步锁处于偏向状态，但是Mark Word中的线程id记录的不是B，那么线程B会先用`CAS`操作试图获得锁，这里的获得锁操作是有可能成功的，因为线程A一般不会自动释放偏向锁。如果抢锁成功，就把Mark Word里的线程id改为线程B的id，代表线程B获得了这个偏向锁，可以执行同步锁代码。如果抢锁失败，则继续执行步骤5。\n5. 偏向锁状态抢锁失败，代表当前锁有一定的竞争，偏向锁将升级为轻量级锁。JVM会在当前线程的线程栈中开辟一块单独的空间，里面保存指向对象锁Mark Word的指针，同时在对象锁Mark Word中保存指向这片空间的指针。上述两个保存操作都是`CAS`操作，如果保存成功，代表线程抢到了同步锁，就把Mark Word中的锁标志位改成00，可以执行同步锁代码。如果保存失败，表示抢锁失败，竞争太激烈，继续执行步骤6。\n6. 轻量级锁抢锁失败，JVM会使用自旋锁，**自旋锁不是一个锁状态，只是代表不断的重试**，尝试抢锁。从JDK1.7开始，自旋锁默认启用，自旋次数由JVM决定。如果抢锁成功则执行同步锁代码，如果失败则继续执行步骤7。\n7. 自旋锁重试之后如果抢锁依然失败，同步锁会升级至重量级锁，锁标志位改为10。在这个状态下，未抢到锁的线程都会被阻塞。\n\n### 对象头-指向类的指针\n\n该指针在32位JVM中的长度是32bit，在64位JVM中长度是64bit。\nJava对象的类数据保存在方法区。\n\n### 对象头-数组长度\n\n只有数组对象保存了这部分数据。\n该数据在32位和64位JVM中长度都是32bit。\n\n## 查看java对象头\n\n我们想要看Java对象的Mark Word，先要加载一个jar包，在pom.xml添加即可。\n\n```xml\n<dependency>\n    <groupId>org.openjdk.jol</groupId>\n    <artifactId>jol-core</artifactId>\n    <version>0.9</version>\n</dependency>\n```\n\n新建一个对象A，拥有初始值为666的变量x。\n\n```java\npublic class A {\n    private int x=666;\n}\n```\n\n新建一个测试类test，这涉及到刚才加载的jar，我们打印Java对象。\n\n```java\nimport org.openjdk.jol.info.ClassLayout;\n\npublic class test {\n    public static void main(String[] args) {\n        A a=new A();\n        System.out.println( ClassLayout.parseInstance(a).toPrintable());\n    }\n}\n```","source":"_posts/2020-04-14-kongzheng1993-JavaObjectHeader.md","raw":"---\ntitle: Java对象头\nexcerpt: ''\ntags: [Java]\ncategories: [Java]\ncomments: true\ndate: 2020-04-14 00:30:52\n---\n\n## Java对象\n\n在JVM中，实例对象在内存中的布局分为三块区域：对象头、实例变量和填充数据。如下：\n\n<img src=\"Java_Monitor.png\">\n　　　　\n\n**实例变量：** 存放类的属性数据信息，包括父类的属性信息，如果是数组的实例部分还包括数组的长度，这部分内存按4字节对齐。其实就是在java代码中能看到的属性和他们的值。 \n\n**填充数据：** 由于虚拟机要求对象起始地址必须是8字节的整数倍。填充数据不是必须存在的，仅仅是为了字节对齐，这点了解即可。\n\n**对象头：** Hotspot虚拟机的对象头主要包括两部分数据：Mark Word（标记字段）、Klass Pointer（类型指针）、Array length（数组长度，只有数组类型才有）。其中Klass Point【Class Metadata Address 】是对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例，Mark Word用于存储对象自身的运行时数据，它是实现轻量级锁和偏向锁的关键。\n\n### 对象头-Mark Word（标记字段）\n\n- Mark Word记录了对象和锁有关的信息，当这个对象被synchronized关键字当成同步锁时，围绕这个锁的一系列操作都和Mark Word有关。\n- Mark Word在32位JVM中的长度是32bit，在64位JVM中长度是64bit。\n- Mark Word在不同的锁状态下存储的内容不同。\n\n<table border=\"1\" cellspacing=\"0\">\n<tbody>\n<tr>\n<td style=\"background-color: #bfbfbf; width: 71pt;\" rowspan=\"2\">\n<p style=\"margin-left: 0cm;\">锁状态</p>\n</td>\n<td style=\"background-color: #bfbfbf; width: 142pt;\" colspan=\"2\">\n<p style=\"margin-left: 0cm;\">25bit</p>\n</td>\n<td style=\"background-color: #bfbfbf; width: 71pt;\" rowspan=\"2\">\n<p style=\"margin-left: 0cm;\">4bit</p>\n</td>\n<td style=\"background-color: #bfbfbf; width: 71.05pt;\">\n<p style=\"margin-left: 0cm;\">1bit</p>\n</td>\n<td style=\"background-color: #bfbfbf; width: 71.05pt;\">\n<p style=\"margin-left: 0cm;\">2bit</p>\n</td>\n</tr>\n<tr>\n<td style=\"background-color: #bfbfbf; width: 71pt;\">\n<p style=\"margin-left: 0cm;\">23bit</p>\n</td>\n<td style=\"background-color: #bfbfbf; width: 71pt;\">\n<p style=\"margin-left: 0cm;\">2bit</p>\n</td>\n<td style=\"background-color: #bfbfbf; width: 71.05pt;\">\n<p style=\"margin-left: 0cm;\">是否偏向锁</p>\n</td>\n<td style=\"background-color: #bfbfbf; width: 71.05pt;\">\n<p style=\"margin-left: 0cm;\">锁标志位</p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: top; width: 71pt;\">\n<p style=\"margin-left: 0cm;\">无锁</p>\n</td>\n<td style=\"vertical-align: top; width: 142pt;\" colspan=\"2\">\n<p style=\"margin-left: 0cm;\">对象的HashCode</p>\n</td>\n<td style=\"vertical-align: top; width: 71pt;\">\n<p style=\"margin-left: 0cm;\">分代年龄</p>\n</td>\n<td style=\"vertical-align: top; width: 71.05pt;\">\n<p style=\"margin-left: 0cm;\">0</p>\n</td>\n<td style=\"vertical-align: top; width: 71.05pt;\">\n<p style=\"margin-left: 0cm;\">01</p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: top; width: 71pt;\">\n<p style=\"margin-left: 0cm;\">偏向锁</p>\n</td>\n<td style=\"vertical-align: top; width: 71pt;\">\n<p style=\"margin-left: 0cm;\">线程ID</p>\n</td>\n<td style=\"vertical-align: top; width: 71pt;\">\n<p style=\"margin-left: 0cm;\">Epoch</p>\n</td>\n<td style=\"vertical-align: top; width: 71pt;\">\n<p style=\"margin-left: 0cm;\">分代年龄</p>\n</td>\n<td style=\"vertical-align: top; width: 71.05pt;\">\n<p style=\"margin-left: 0cm;\">1</p>\n</td>\n<td style=\"vertical-align: top; width: 71.05pt;\">\n<p style=\"margin-left: 0cm;\">01</p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: top; width: 71pt;\">\n<p style=\"margin-left: 0cm;\">轻量级锁</p>\n</td>\n<td style=\"vertical-align: top; width: 284.05pt;\" colspan=\"4\">\n<p style=\"margin-left: 0cm;\">指向栈中锁记录的指针</p>\n</td>\n<td style=\"vertical-align: top; width: 71.05pt;\">\n<p style=\"margin-left: 0cm;\">00</p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: top; width: 71pt;\">\n<p style=\"margin-left: 0cm;\">重量级锁</p>\n</td>\n<td style=\"vertical-align: top; width: 284.05pt;\" colspan=\"4\">\n<p style=\"margin-left: 0cm;\">指向重量级锁的指针</p>\n</td>\n<td style=\"vertical-align: top; width: 71.05pt;\">\n<p style=\"margin-left: 0cm;\">10</p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: top; width: 71pt;\">\n<p style=\"margin-left: 0cm;\">GC标记</p>\n</td>\n<td style=\"vertical-align: top; width: 284.05pt;\" colspan=\"4\">\n<p style=\"margin-left: 0cm;\">空</p>\n</td>\n<td style=\"vertical-align: top; width: 71.05pt;\">\n<p style=\"margin-left: 0cm;\">11</p>\n</td>\n</tr>\n</tbody>\n</table>\n\n**锁的级别从低到高：无锁、偏向锁、轻量级锁、重量级锁。**\n\n其中无锁和偏向锁的锁标志位都是01，只是在前面的1bit区分了这是无锁状态还是偏向锁状态。\n\nJDK1.6以后的版本在处理同步锁时存在锁升级的概念，JVM对于同步锁的处理是从偏向锁开始的，随着竞争越来越激烈，处理方式从偏向锁升级到轻量级锁，最终升级到重量级锁。\n\nJVM一般是这样使用锁和Mark Word的：\n1. 当没有被当成锁时，这就是一个普通的对象，Mark Word记录对象的HashCode，锁标志位是01，是否偏向锁那一位是0。\n2. 当对象被当做同步锁并有一个线程A抢到了锁时，锁标志位还是01，但是否偏向锁那一位改成1，前23bit记录抢到锁的线程id，表示进入偏向锁状态。\n3. 当线程A再次试图来获得锁时，JVM发现同步锁对象的标志位是01，是否偏向锁是1，也就是偏向状态，Mark Word中记录的线程id就是线程A自己的id，表示线程A已经获得了这个偏向锁，可以执行同步锁的代码。\n4. 当线程B试图获得这个锁时，JVM发现同步锁处于偏向状态，但是Mark Word中的线程id记录的不是B，那么线程B会先用`CAS`操作试图获得锁，这里的获得锁操作是有可能成功的，因为线程A一般不会自动释放偏向锁。如果抢锁成功，就把Mark Word里的线程id改为线程B的id，代表线程B获得了这个偏向锁，可以执行同步锁代码。如果抢锁失败，则继续执行步骤5。\n5. 偏向锁状态抢锁失败，代表当前锁有一定的竞争，偏向锁将升级为轻量级锁。JVM会在当前线程的线程栈中开辟一块单独的空间，里面保存指向对象锁Mark Word的指针，同时在对象锁Mark Word中保存指向这片空间的指针。上述两个保存操作都是`CAS`操作，如果保存成功，代表线程抢到了同步锁，就把Mark Word中的锁标志位改成00，可以执行同步锁代码。如果保存失败，表示抢锁失败，竞争太激烈，继续执行步骤6。\n6. 轻量级锁抢锁失败，JVM会使用自旋锁，**自旋锁不是一个锁状态，只是代表不断的重试**，尝试抢锁。从JDK1.7开始，自旋锁默认启用，自旋次数由JVM决定。如果抢锁成功则执行同步锁代码，如果失败则继续执行步骤7。\n7. 自旋锁重试之后如果抢锁依然失败，同步锁会升级至重量级锁，锁标志位改为10。在这个状态下，未抢到锁的线程都会被阻塞。\n\n### 对象头-指向类的指针\n\n该指针在32位JVM中的长度是32bit，在64位JVM中长度是64bit。\nJava对象的类数据保存在方法区。\n\n### 对象头-数组长度\n\n只有数组对象保存了这部分数据。\n该数据在32位和64位JVM中长度都是32bit。\n\n## 查看java对象头\n\n我们想要看Java对象的Mark Word，先要加载一个jar包，在pom.xml添加即可。\n\n```xml\n<dependency>\n    <groupId>org.openjdk.jol</groupId>\n    <artifactId>jol-core</artifactId>\n    <version>0.9</version>\n</dependency>\n```\n\n新建一个对象A，拥有初始值为666的变量x。\n\n```java\npublic class A {\n    private int x=666;\n}\n```\n\n新建一个测试类test，这涉及到刚才加载的jar，我们打印Java对象。\n\n```java\nimport org.openjdk.jol.info.ClassLayout;\n\npublic class test {\n    public static void main(String[] args) {\n        A a=new A();\n        System.out.println( ClassLayout.parseInstance(a).toPrintable());\n    }\n}\n```","slug":"kongzheng1993-JavaObjectHeader","published":1,"updated":"2023-03-08T07:05:58.795Z","layout":"post","photos":[],"link":"","_id":"clg0k2aek002rt26fcacispvg","content":"<h2 id=\"Java对象\"><a href=\"#Java对象\" class=\"headerlink\" title=\"Java对象\"></a>Java对象</h2><p>在JVM中，实例对象在内存中的布局分为三块区域：对象头、实例变量和填充数据。如下：</p>\n<img src=\"/2020/04/14/kongzheng1993-JavaObjectHeader/Java_Monitor.png\">\n　　　　\n\n<p><strong>实例变量：</strong> 存放类的属性数据信息，包括父类的属性信息，如果是数组的实例部分还包括数组的长度，这部分内存按4字节对齐。其实就是在java代码中能看到的属性和他们的值。 </p>\n<p><strong>填充数据：</strong> 由于虚拟机要求对象起始地址必须是8字节的整数倍。填充数据不是必须存在的，仅仅是为了字节对齐，这点了解即可。</p>\n<p><strong>对象头：</strong> Hotspot虚拟机的对象头主要包括两部分数据：Mark Word（标记字段）、Klass Pointer（类型指针）、Array length（数组长度，只有数组类型才有）。其中Klass Point【Class Metadata Address 】是对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例，Mark Word用于存储对象自身的运行时数据，它是实现轻量级锁和偏向锁的关键。</p>\n<h3 id=\"对象头-Mark-Word（标记字段）\"><a href=\"#对象头-Mark-Word（标记字段）\" class=\"headerlink\" title=\"对象头-Mark Word（标记字段）\"></a>对象头-Mark Word（标记字段）</h3><ul>\n<li>Mark Word记录了对象和锁有关的信息，当这个对象被synchronized关键字当成同步锁时，围绕这个锁的一系列操作都和Mark Word有关。</li>\n<li>Mark Word在32位JVM中的长度是32bit，在64位JVM中长度是64bit。</li>\n<li>Mark Word在不同的锁状态下存储的内容不同。</li>\n</ul>\n<table border=\"1\" cellspacing=\"0\">\n<tbody>\n<tr>\n<td style=\"background-color: #bfbfbf; width: 71pt;\" rowspan=\"2\">\n<p style=\"margin-left: 0cm;\">锁状态</p>\n</td>\n<td style=\"background-color: #bfbfbf; width: 142pt;\" colspan=\"2\">\n<p style=\"margin-left: 0cm;\">25bit</p>\n</td>\n<td style=\"background-color: #bfbfbf; width: 71pt;\" rowspan=\"2\">\n<p style=\"margin-left: 0cm;\">4bit</p>\n</td>\n<td style=\"background-color: #bfbfbf; width: 71.05pt;\">\n<p style=\"margin-left: 0cm;\">1bit</p>\n</td>\n<td style=\"background-color: #bfbfbf; width: 71.05pt;\">\n<p style=\"margin-left: 0cm;\">2bit</p>\n</td>\n</tr>\n<tr>\n<td style=\"background-color: #bfbfbf; width: 71pt;\">\n<p style=\"margin-left: 0cm;\">23bit</p>\n</td>\n<td style=\"background-color: #bfbfbf; width: 71pt;\">\n<p style=\"margin-left: 0cm;\">2bit</p>\n</td>\n<td style=\"background-color: #bfbfbf; width: 71.05pt;\">\n<p style=\"margin-left: 0cm;\">是否偏向锁</p>\n</td>\n<td style=\"background-color: #bfbfbf; width: 71.05pt;\">\n<p style=\"margin-left: 0cm;\">锁标志位</p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: top; width: 71pt;\">\n<p style=\"margin-left: 0cm;\">无锁</p>\n</td>\n<td style=\"vertical-align: top; width: 142pt;\" colspan=\"2\">\n<p style=\"margin-left: 0cm;\">对象的HashCode</p>\n</td>\n<td style=\"vertical-align: top; width: 71pt;\">\n<p style=\"margin-left: 0cm;\">分代年龄</p>\n</td>\n<td style=\"vertical-align: top; width: 71.05pt;\">\n<p style=\"margin-left: 0cm;\">0</p>\n</td>\n<td style=\"vertical-align: top; width: 71.05pt;\">\n<p style=\"margin-left: 0cm;\">01</p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: top; width: 71pt;\">\n<p style=\"margin-left: 0cm;\">偏向锁</p>\n</td>\n<td style=\"vertical-align: top; width: 71pt;\">\n<p style=\"margin-left: 0cm;\">线程ID</p>\n</td>\n<td style=\"vertical-align: top; width: 71pt;\">\n<p style=\"margin-left: 0cm;\">Epoch</p>\n</td>\n<td style=\"vertical-align: top; width: 71pt;\">\n<p style=\"margin-left: 0cm;\">分代年龄</p>\n</td>\n<td style=\"vertical-align: top; width: 71.05pt;\">\n<p style=\"margin-left: 0cm;\">1</p>\n</td>\n<td style=\"vertical-align: top; width: 71.05pt;\">\n<p style=\"margin-left: 0cm;\">01</p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: top; width: 71pt;\">\n<p style=\"margin-left: 0cm;\">轻量级锁</p>\n</td>\n<td style=\"vertical-align: top; width: 284.05pt;\" colspan=\"4\">\n<p style=\"margin-left: 0cm;\">指向栈中锁记录的指针</p>\n</td>\n<td style=\"vertical-align: top; width: 71.05pt;\">\n<p style=\"margin-left: 0cm;\">00</p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: top; width: 71pt;\">\n<p style=\"margin-left: 0cm;\">重量级锁</p>\n</td>\n<td style=\"vertical-align: top; width: 284.05pt;\" colspan=\"4\">\n<p style=\"margin-left: 0cm;\">指向重量级锁的指针</p>\n</td>\n<td style=\"vertical-align: top; width: 71.05pt;\">\n<p style=\"margin-left: 0cm;\">10</p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: top; width: 71pt;\">\n<p style=\"margin-left: 0cm;\">GC标记</p>\n</td>\n<td style=\"vertical-align: top; width: 284.05pt;\" colspan=\"4\">\n<p style=\"margin-left: 0cm;\">空</p>\n</td>\n<td style=\"vertical-align: top; width: 71.05pt;\">\n<p style=\"margin-left: 0cm;\">11</p>\n</td>\n</tr>\n</tbody>\n</table>\n\n<p><strong>锁的级别从低到高：无锁、偏向锁、轻量级锁、重量级锁。</strong></p>\n<p>其中无锁和偏向锁的锁标志位都是01，只是在前面的1bit区分了这是无锁状态还是偏向锁状态。</p>\n<p>JDK1.6以后的版本在处理同步锁时存在锁升级的概念，JVM对于同步锁的处理是从偏向锁开始的，随着竞争越来越激烈，处理方式从偏向锁升级到轻量级锁，最终升级到重量级锁。</p>\n<p>JVM一般是这样使用锁和Mark Word的：</p>\n<ol>\n<li>当没有被当成锁时，这就是一个普通的对象，Mark Word记录对象的HashCode，锁标志位是01，是否偏向锁那一位是0。</li>\n<li>当对象被当做同步锁并有一个线程A抢到了锁时，锁标志位还是01，但是否偏向锁那一位改成1，前23bit记录抢到锁的线程id，表示进入偏向锁状态。</li>\n<li>当线程A再次试图来获得锁时，JVM发现同步锁对象的标志位是01，是否偏向锁是1，也就是偏向状态，Mark Word中记录的线程id就是线程A自己的id，表示线程A已经获得了这个偏向锁，可以执行同步锁的代码。</li>\n<li>当线程B试图获得这个锁时，JVM发现同步锁处于偏向状态，但是Mark Word中的线程id记录的不是B，那么线程B会先用<code>CAS</code>操作试图获得锁，这里的获得锁操作是有可能成功的，因为线程A一般不会自动释放偏向锁。如果抢锁成功，就把Mark Word里的线程id改为线程B的id，代表线程B获得了这个偏向锁，可以执行同步锁代码。如果抢锁失败，则继续执行步骤5。</li>\n<li>偏向锁状态抢锁失败，代表当前锁有一定的竞争，偏向锁将升级为轻量级锁。JVM会在当前线程的线程栈中开辟一块单独的空间，里面保存指向对象锁Mark Word的指针，同时在对象锁Mark Word中保存指向这片空间的指针。上述两个保存操作都是<code>CAS</code>操作，如果保存成功，代表线程抢到了同步锁，就把Mark Word中的锁标志位改成00，可以执行同步锁代码。如果保存失败，表示抢锁失败，竞争太激烈，继续执行步骤6。</li>\n<li>轻量级锁抢锁失败，JVM会使用自旋锁，<strong>自旋锁不是一个锁状态，只是代表不断的重试</strong>，尝试抢锁。从JDK1.7开始，自旋锁默认启用，自旋次数由JVM决定。如果抢锁成功则执行同步锁代码，如果失败则继续执行步骤7。</li>\n<li>自旋锁重试之后如果抢锁依然失败，同步锁会升级至重量级锁，锁标志位改为10。在这个状态下，未抢到锁的线程都会被阻塞。</li>\n</ol>\n<h3 id=\"对象头-指向类的指针\"><a href=\"#对象头-指向类的指针\" class=\"headerlink\" title=\"对象头-指向类的指针\"></a>对象头-指向类的指针</h3><p>该指针在32位JVM中的长度是32bit，在64位JVM中长度是64bit。<br>Java对象的类数据保存在方法区。</p>\n<h3 id=\"对象头-数组长度\"><a href=\"#对象头-数组长度\" class=\"headerlink\" title=\"对象头-数组长度\"></a>对象头-数组长度</h3><p>只有数组对象保存了这部分数据。<br>该数据在32位和64位JVM中长度都是32bit。</p>\n<h2 id=\"查看java对象头\"><a href=\"#查看java对象头\" class=\"headerlink\" title=\"查看java对象头\"></a>查看java对象头</h2><p>我们想要看Java对象的Mark Word，先要加载一个jar包，在pom.xml添加即可。</p>\n<pre><code class=\"xml\">&lt;dependency&gt;\n    &lt;groupId&gt;org.openjdk.jol&lt;/groupId&gt;\n    &lt;artifactId&gt;jol-core&lt;/artifactId&gt;\n    &lt;version&gt;0.9&lt;/version&gt;\n&lt;/dependency&gt;</code></pre>\n<p>新建一个对象A，拥有初始值为666的变量x。</p>\n<pre><code class=\"java\">public class A {\n    private int x=666;\n}</code></pre>\n<p>新建一个测试类test，这涉及到刚才加载的jar，我们打印Java对象。</p>\n<pre><code class=\"java\">import org.openjdk.jol.info.ClassLayout;\n\npublic class test {\n    public static void main(String[] args) {\n        A a=new A();\n        System.out.println( ClassLayout.parseInstance(a).toPrintable());\n    }\n}</code></pre>\n","site":{"data":{}},"more":"<h2 id=\"Java对象\"><a href=\"#Java对象\" class=\"headerlink\" title=\"Java对象\"></a>Java对象</h2><p>在JVM中，实例对象在内存中的布局分为三块区域：对象头、实例变量和填充数据。如下：</p>\n<img src=\"/2020/04/14/kongzheng1993-JavaObjectHeader/Java_Monitor.png\">\n　　　　\n\n<p><strong>实例变量：</strong> 存放类的属性数据信息，包括父类的属性信息，如果是数组的实例部分还包括数组的长度，这部分内存按4字节对齐。其实就是在java代码中能看到的属性和他们的值。 </p>\n<p><strong>填充数据：</strong> 由于虚拟机要求对象起始地址必须是8字节的整数倍。填充数据不是必须存在的，仅仅是为了字节对齐，这点了解即可。</p>\n<p><strong>对象头：</strong> Hotspot虚拟机的对象头主要包括两部分数据：Mark Word（标记字段）、Klass Pointer（类型指针）、Array length（数组长度，只有数组类型才有）。其中Klass Point【Class Metadata Address 】是对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例，Mark Word用于存储对象自身的运行时数据，它是实现轻量级锁和偏向锁的关键。</p>\n<h3 id=\"对象头-Mark-Word（标记字段）\"><a href=\"#对象头-Mark-Word（标记字段）\" class=\"headerlink\" title=\"对象头-Mark Word（标记字段）\"></a>对象头-Mark Word（标记字段）</h3><ul>\n<li>Mark Word记录了对象和锁有关的信息，当这个对象被synchronized关键字当成同步锁时，围绕这个锁的一系列操作都和Mark Word有关。</li>\n<li>Mark Word在32位JVM中的长度是32bit，在64位JVM中长度是64bit。</li>\n<li>Mark Word在不同的锁状态下存储的内容不同。</li>\n</ul>\n<table border=\"1\" cellspacing=\"0\">\n<tbody>\n<tr>\n<td style=\"background-color: #bfbfbf; width: 71pt;\" rowspan=\"2\">\n<p style=\"margin-left: 0cm;\">锁状态</p>\n</td>\n<td style=\"background-color: #bfbfbf; width: 142pt;\" colspan=\"2\">\n<p style=\"margin-left: 0cm;\">25bit</p>\n</td>\n<td style=\"background-color: #bfbfbf; width: 71pt;\" rowspan=\"2\">\n<p style=\"margin-left: 0cm;\">4bit</p>\n</td>\n<td style=\"background-color: #bfbfbf; width: 71.05pt;\">\n<p style=\"margin-left: 0cm;\">1bit</p>\n</td>\n<td style=\"background-color: #bfbfbf; width: 71.05pt;\">\n<p style=\"margin-left: 0cm;\">2bit</p>\n</td>\n</tr>\n<tr>\n<td style=\"background-color: #bfbfbf; width: 71pt;\">\n<p style=\"margin-left: 0cm;\">23bit</p>\n</td>\n<td style=\"background-color: #bfbfbf; width: 71pt;\">\n<p style=\"margin-left: 0cm;\">2bit</p>\n</td>\n<td style=\"background-color: #bfbfbf; width: 71.05pt;\">\n<p style=\"margin-left: 0cm;\">是否偏向锁</p>\n</td>\n<td style=\"background-color: #bfbfbf; width: 71.05pt;\">\n<p style=\"margin-left: 0cm;\">锁标志位</p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: top; width: 71pt;\">\n<p style=\"margin-left: 0cm;\">无锁</p>\n</td>\n<td style=\"vertical-align: top; width: 142pt;\" colspan=\"2\">\n<p style=\"margin-left: 0cm;\">对象的HashCode</p>\n</td>\n<td style=\"vertical-align: top; width: 71pt;\">\n<p style=\"margin-left: 0cm;\">分代年龄</p>\n</td>\n<td style=\"vertical-align: top; width: 71.05pt;\">\n<p style=\"margin-left: 0cm;\">0</p>\n</td>\n<td style=\"vertical-align: top; width: 71.05pt;\">\n<p style=\"margin-left: 0cm;\">01</p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: top; width: 71pt;\">\n<p style=\"margin-left: 0cm;\">偏向锁</p>\n</td>\n<td style=\"vertical-align: top; width: 71pt;\">\n<p style=\"margin-left: 0cm;\">线程ID</p>\n</td>\n<td style=\"vertical-align: top; width: 71pt;\">\n<p style=\"margin-left: 0cm;\">Epoch</p>\n</td>\n<td style=\"vertical-align: top; width: 71pt;\">\n<p style=\"margin-left: 0cm;\">分代年龄</p>\n</td>\n<td style=\"vertical-align: top; width: 71.05pt;\">\n<p style=\"margin-left: 0cm;\">1</p>\n</td>\n<td style=\"vertical-align: top; width: 71.05pt;\">\n<p style=\"margin-left: 0cm;\">01</p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: top; width: 71pt;\">\n<p style=\"margin-left: 0cm;\">轻量级锁</p>\n</td>\n<td style=\"vertical-align: top; width: 284.05pt;\" colspan=\"4\">\n<p style=\"margin-left: 0cm;\">指向栈中锁记录的指针</p>\n</td>\n<td style=\"vertical-align: top; width: 71.05pt;\">\n<p style=\"margin-left: 0cm;\">00</p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: top; width: 71pt;\">\n<p style=\"margin-left: 0cm;\">重量级锁</p>\n</td>\n<td style=\"vertical-align: top; width: 284.05pt;\" colspan=\"4\">\n<p style=\"margin-left: 0cm;\">指向重量级锁的指针</p>\n</td>\n<td style=\"vertical-align: top; width: 71.05pt;\">\n<p style=\"margin-left: 0cm;\">10</p>\n</td>\n</tr>\n<tr>\n<td style=\"vertical-align: top; width: 71pt;\">\n<p style=\"margin-left: 0cm;\">GC标记</p>\n</td>\n<td style=\"vertical-align: top; width: 284.05pt;\" colspan=\"4\">\n<p style=\"margin-left: 0cm;\">空</p>\n</td>\n<td style=\"vertical-align: top; width: 71.05pt;\">\n<p style=\"margin-left: 0cm;\">11</p>\n</td>\n</tr>\n</tbody>\n</table>\n\n<p><strong>锁的级别从低到高：无锁、偏向锁、轻量级锁、重量级锁。</strong></p>\n<p>其中无锁和偏向锁的锁标志位都是01，只是在前面的1bit区分了这是无锁状态还是偏向锁状态。</p>\n<p>JDK1.6以后的版本在处理同步锁时存在锁升级的概念，JVM对于同步锁的处理是从偏向锁开始的，随着竞争越来越激烈，处理方式从偏向锁升级到轻量级锁，最终升级到重量级锁。</p>\n<p>JVM一般是这样使用锁和Mark Word的：</p>\n<ol>\n<li>当没有被当成锁时，这就是一个普通的对象，Mark Word记录对象的HashCode，锁标志位是01，是否偏向锁那一位是0。</li>\n<li>当对象被当做同步锁并有一个线程A抢到了锁时，锁标志位还是01，但是否偏向锁那一位改成1，前23bit记录抢到锁的线程id，表示进入偏向锁状态。</li>\n<li>当线程A再次试图来获得锁时，JVM发现同步锁对象的标志位是01，是否偏向锁是1，也就是偏向状态，Mark Word中记录的线程id就是线程A自己的id，表示线程A已经获得了这个偏向锁，可以执行同步锁的代码。</li>\n<li>当线程B试图获得这个锁时，JVM发现同步锁处于偏向状态，但是Mark Word中的线程id记录的不是B，那么线程B会先用<code>CAS</code>操作试图获得锁，这里的获得锁操作是有可能成功的，因为线程A一般不会自动释放偏向锁。如果抢锁成功，就把Mark Word里的线程id改为线程B的id，代表线程B获得了这个偏向锁，可以执行同步锁代码。如果抢锁失败，则继续执行步骤5。</li>\n<li>偏向锁状态抢锁失败，代表当前锁有一定的竞争，偏向锁将升级为轻量级锁。JVM会在当前线程的线程栈中开辟一块单独的空间，里面保存指向对象锁Mark Word的指针，同时在对象锁Mark Word中保存指向这片空间的指针。上述两个保存操作都是<code>CAS</code>操作，如果保存成功，代表线程抢到了同步锁，就把Mark Word中的锁标志位改成00，可以执行同步锁代码。如果保存失败，表示抢锁失败，竞争太激烈，继续执行步骤6。</li>\n<li>轻量级锁抢锁失败，JVM会使用自旋锁，<strong>自旋锁不是一个锁状态，只是代表不断的重试</strong>，尝试抢锁。从JDK1.7开始，自旋锁默认启用，自旋次数由JVM决定。如果抢锁成功则执行同步锁代码，如果失败则继续执行步骤7。</li>\n<li>自旋锁重试之后如果抢锁依然失败，同步锁会升级至重量级锁，锁标志位改为10。在这个状态下，未抢到锁的线程都会被阻塞。</li>\n</ol>\n<h3 id=\"对象头-指向类的指针\"><a href=\"#对象头-指向类的指针\" class=\"headerlink\" title=\"对象头-指向类的指针\"></a>对象头-指向类的指针</h3><p>该指针在32位JVM中的长度是32bit，在64位JVM中长度是64bit。<br>Java对象的类数据保存在方法区。</p>\n<h3 id=\"对象头-数组长度\"><a href=\"#对象头-数组长度\" class=\"headerlink\" title=\"对象头-数组长度\"></a>对象头-数组长度</h3><p>只有数组对象保存了这部分数据。<br>该数据在32位和64位JVM中长度都是32bit。</p>\n<h2 id=\"查看java对象头\"><a href=\"#查看java对象头\" class=\"headerlink\" title=\"查看java对象头\"></a>查看java对象头</h2><p>我们想要看Java对象的Mark Word，先要加载一个jar包，在pom.xml添加即可。</p>\n<pre><code class=\"xml\">&lt;dependency&gt;\n    &lt;groupId&gt;org.openjdk.jol&lt;/groupId&gt;\n    &lt;artifactId&gt;jol-core&lt;/artifactId&gt;\n    &lt;version&gt;0.9&lt;/version&gt;\n&lt;/dependency&gt;</code></pre>\n<p>新建一个对象A，拥有初始值为666的变量x。</p>\n<pre><code class=\"java\">public class A {\n    private int x=666;\n}</code></pre>\n<p>新建一个测试类test，这涉及到刚才加载的jar，我们打印Java对象。</p>\n<pre><code class=\"java\">import org.openjdk.jol.info.ClassLayout;\n\npublic class test {\n    public static void main(String[] args) {\n        A a=new A();\n        System.out.println( ClassLayout.parseInstance(a).toPrintable());\n    }\n}</code></pre>\n"},{"title":"RocketMQ OpenMessaging Example","excerpt":"","comments":1,"date":"2020-04-08T16:30:52.000Z","_content":"\n# OpenMessaging\n\nOpenMessaging，包括建立行业指南和消息传递，流式传输规范，从而为金融，电子商务，物联网和大数据领域提供通用框架。在分布式异构环境中，设计原则是面向云，简单，灵活且独立于语言。符合这些规范将使跨所有主要平台和操作系统开发异构消息应用程序成为可能。\n\nRocketMQ提供了OpenMessaging 0.1.0-alpha的部分实现，以下示例演示了如何基于OpenMessaging访问RocketMQ。\n\n**OMS生产者**\n以下示例显示了如何以同步，异步或单向传输将消息发送到RocketMQ代理。\n\n```java\npublic class OMSProducer {\n    public static void main(String[] args) {\n        final MessagingAccessPoint messagingAccessPoint = MessagingAccessPointFactory\n            .getMessagingAccessPoint(\"openmessaging:rocketmq://IP1:9876,IP2:9876/namespace\");\n\n        final Producer producer = messagingAccessPoint.createProducer();\n\n        messagingAccessPoint.startup();\n        System.out.printf(\"MessagingAccessPoint startup OK%n\");\n\n        producer.startup();\n        System.out.printf(\"Producer startup OK%n\");\n\n        {\n            Message message = producer.createBytesMessageToTopic(\"OMS_HELLO_TOPIC\", \"OMS_HELLO_BODY\".getBytes(Charset.forName(\"UTF-8\")));\n            SendResult sendResult = producer.send(message);\n            System.out.printf(\"Send sync message OK, msgId: %s%n\", sendResult.messageId());\n        }\n\n        {\n            final Promise<SendResult> result = producer.sendAsync(producer.createBytesMessageToTopic(\"OMS_HELLO_TOPIC\", \"OMS_HELLO_BODY\".getBytes(Charset.forName(\"UTF-8\"))));\n            result.addListener(new PromiseListener<SendResult>() {\n                @Override\n                public void operationCompleted(Promise<SendResult> promise) {\n                    System.out.printf(\"Send async message OK, msgId: %s%n\", promise.get().messageId());\n                }\n\n                @Override\n                public void operationFailed(Promise<SendResult> promise) {\n                    System.out.printf(\"Send async message Failed, error: %s%n\", promise.getThrowable().getMessage());\n                }\n            });\n        }\n\n        {\n            producer.sendOneway(producer.createBytesMessageToTopic(\"OMS_HELLO_TOPIC\", \"OMS_HELLO_BODY\".getBytes(Charset.forName(\"UTF-8\"))));\n            System.out.printf(\"Send oneway message OK%n\");\n        }\n\n        producer.shutdown();\n        messagingAccessPoint.shutdown();\n    }\n}\n```\n\n**OMSPull消费者**\n使用OMS PullConsumer轮询来自指定队列的消息。\n\n```java\npublic class OMSPullConsumer {\n    public static void main(String[] args) {\n        final MessagingAccessPoint messagingAccessPoint = MessagingAccessPointFactory\n            .getMessagingAccessPoint(\"openmessaging:rocketmq://IP1:9876,IP2:9876/namespace\");\n\n        final PullConsumer consumer = messagingAccessPoint.createPullConsumer(\"OMS_HELLO_TOPIC\",\n            OMS.newKeyValue().put(NonStandardKeys.CONSUMER_GROUP, \"OMS_CONSUMER\"));\n\n        messagingAccessPoint.startup();\n        System.out.printf(\"MessagingAccessPoint startup OK%n\");\n\n        consumer.startup();\n        System.out.printf(\"Consumer startup OK%n\");\n\n        Message message = consumer.poll();\n        if (message != null) {\n            String msgId = message.headers().getString(MessageHeader.MESSAGE_ID);\n            System.out.printf(\"Received one message: %s%n\", msgId);\n            consumer.ack(msgId);\n        }\n\n        consumer.shutdown();\n        messagingAccessPoint.shutdown();\n    }\n}\n```\n\n**OMSPushConsumer**\n将OMS PushConsumer附加到指定的队列，并通过MessageListener使用消息\n\n```java\npublic class OMSPushConsumer {\n    public static void main(String[] args) {\n        final MessagingAccessPoint messagingAccessPoint = MessagingAccessPointFactory\n            .getMessagingAccessPoint(\"openmessaging:rocketmq://IP1:9876,IP2:9876/namespace\");\n\n        final PushConsumer consumer = messagingAccessPoint.\n            createPushConsumer(OMS.newKeyValue().put(NonStandardKeys.CONSUMER_GROUP, \"OMS_CONSUMER\"));\n\n        messagingAccessPoint.startup();\n        System.out.printf(\"MessagingAccessPoint startup OK%n\");\n\n        Runtime.getRuntime().addShutdownHook(new Thread(new Runnable() {\n            @Override\n            public void run() {\n                consumer.shutdown();\n                messagingAccessPoint.shutdown();\n            }\n        }));\n\n        consumer.attachQueue(\"OMS_HELLO_TOPIC\", new MessageListener() {\n            @Override\n            public void onMessage(final Message message, final ReceivedMessageContext context) {\n                System.out.printf(\"Received one message: %s%n\", message.headers().getString(MessageHeader.MESSAGE_ID));\n                context.ack();\n            }\n        });\n    }\n}\n```","source":"_posts/2020-04-09-kongzheng1993-TransactionMessage.md","raw":"---\ntitle: RocketMQ OpenMessaging Example\nexcerpt: ''\ntags: [RocketMQ]\ncategories: [RocketMQ]\ncomments: true\ndate: 2020-04-09 00:30:52\n---\n\n# OpenMessaging\n\nOpenMessaging，包括建立行业指南和消息传递，流式传输规范，从而为金融，电子商务，物联网和大数据领域提供通用框架。在分布式异构环境中，设计原则是面向云，简单，灵活且独立于语言。符合这些规范将使跨所有主要平台和操作系统开发异构消息应用程序成为可能。\n\nRocketMQ提供了OpenMessaging 0.1.0-alpha的部分实现，以下示例演示了如何基于OpenMessaging访问RocketMQ。\n\n**OMS生产者**\n以下示例显示了如何以同步，异步或单向传输将消息发送到RocketMQ代理。\n\n```java\npublic class OMSProducer {\n    public static void main(String[] args) {\n        final MessagingAccessPoint messagingAccessPoint = MessagingAccessPointFactory\n            .getMessagingAccessPoint(\"openmessaging:rocketmq://IP1:9876,IP2:9876/namespace\");\n\n        final Producer producer = messagingAccessPoint.createProducer();\n\n        messagingAccessPoint.startup();\n        System.out.printf(\"MessagingAccessPoint startup OK%n\");\n\n        producer.startup();\n        System.out.printf(\"Producer startup OK%n\");\n\n        {\n            Message message = producer.createBytesMessageToTopic(\"OMS_HELLO_TOPIC\", \"OMS_HELLO_BODY\".getBytes(Charset.forName(\"UTF-8\")));\n            SendResult sendResult = producer.send(message);\n            System.out.printf(\"Send sync message OK, msgId: %s%n\", sendResult.messageId());\n        }\n\n        {\n            final Promise<SendResult> result = producer.sendAsync(producer.createBytesMessageToTopic(\"OMS_HELLO_TOPIC\", \"OMS_HELLO_BODY\".getBytes(Charset.forName(\"UTF-8\"))));\n            result.addListener(new PromiseListener<SendResult>() {\n                @Override\n                public void operationCompleted(Promise<SendResult> promise) {\n                    System.out.printf(\"Send async message OK, msgId: %s%n\", promise.get().messageId());\n                }\n\n                @Override\n                public void operationFailed(Promise<SendResult> promise) {\n                    System.out.printf(\"Send async message Failed, error: %s%n\", promise.getThrowable().getMessage());\n                }\n            });\n        }\n\n        {\n            producer.sendOneway(producer.createBytesMessageToTopic(\"OMS_HELLO_TOPIC\", \"OMS_HELLO_BODY\".getBytes(Charset.forName(\"UTF-8\"))));\n            System.out.printf(\"Send oneway message OK%n\");\n        }\n\n        producer.shutdown();\n        messagingAccessPoint.shutdown();\n    }\n}\n```\n\n**OMSPull消费者**\n使用OMS PullConsumer轮询来自指定队列的消息。\n\n```java\npublic class OMSPullConsumer {\n    public static void main(String[] args) {\n        final MessagingAccessPoint messagingAccessPoint = MessagingAccessPointFactory\n            .getMessagingAccessPoint(\"openmessaging:rocketmq://IP1:9876,IP2:9876/namespace\");\n\n        final PullConsumer consumer = messagingAccessPoint.createPullConsumer(\"OMS_HELLO_TOPIC\",\n            OMS.newKeyValue().put(NonStandardKeys.CONSUMER_GROUP, \"OMS_CONSUMER\"));\n\n        messagingAccessPoint.startup();\n        System.out.printf(\"MessagingAccessPoint startup OK%n\");\n\n        consumer.startup();\n        System.out.printf(\"Consumer startup OK%n\");\n\n        Message message = consumer.poll();\n        if (message != null) {\n            String msgId = message.headers().getString(MessageHeader.MESSAGE_ID);\n            System.out.printf(\"Received one message: %s%n\", msgId);\n            consumer.ack(msgId);\n        }\n\n        consumer.shutdown();\n        messagingAccessPoint.shutdown();\n    }\n}\n```\n\n**OMSPushConsumer**\n将OMS PushConsumer附加到指定的队列，并通过MessageListener使用消息\n\n```java\npublic class OMSPushConsumer {\n    public static void main(String[] args) {\n        final MessagingAccessPoint messagingAccessPoint = MessagingAccessPointFactory\n            .getMessagingAccessPoint(\"openmessaging:rocketmq://IP1:9876,IP2:9876/namespace\");\n\n        final PushConsumer consumer = messagingAccessPoint.\n            createPushConsumer(OMS.newKeyValue().put(NonStandardKeys.CONSUMER_GROUP, \"OMS_CONSUMER\"));\n\n        messagingAccessPoint.startup();\n        System.out.printf(\"MessagingAccessPoint startup OK%n\");\n\n        Runtime.getRuntime().addShutdownHook(new Thread(new Runnable() {\n            @Override\n            public void run() {\n                consumer.shutdown();\n                messagingAccessPoint.shutdown();\n            }\n        }));\n\n        consumer.attachQueue(\"OMS_HELLO_TOPIC\", new MessageListener() {\n            @Override\n            public void onMessage(final Message message, final ReceivedMessageContext context) {\n                System.out.printf(\"Received one message: %s%n\", message.headers().getString(MessageHeader.MESSAGE_ID));\n                context.ack();\n            }\n        });\n    }\n}\n```","slug":"kongzheng1993-TransactionMessage","published":1,"updated":"2023-03-08T07:05:58.794Z","layout":"post","photos":[],"link":"","_id":"clg0k2afe002ut26f8818sn1e","content":"<h1 id=\"OpenMessaging\"><a href=\"#OpenMessaging\" class=\"headerlink\" title=\"OpenMessaging\"></a>OpenMessaging</h1><p>OpenMessaging，包括建立行业指南和消息传递，流式传输规范，从而为金融，电子商务，物联网和大数据领域提供通用框架。在分布式异构环境中，设计原则是面向云，简单，灵活且独立于语言。符合这些规范将使跨所有主要平台和操作系统开发异构消息应用程序成为可能。</p>\n<p>RocketMQ提供了OpenMessaging 0.1.0-alpha的部分实现，以下示例演示了如何基于OpenMessaging访问RocketMQ。</p>\n<p><strong>OMS生产者</strong><br>以下示例显示了如何以同步，异步或单向传输将消息发送到RocketMQ代理。</p>\n<pre><code class=\"java\">public class OMSProducer {\n    public static void main(String[] args) {\n        final MessagingAccessPoint messagingAccessPoint = MessagingAccessPointFactory\n            .getMessagingAccessPoint(&quot;openmessaging:rocketmq://IP1:9876,IP2:9876/namespace&quot;);\n\n        final Producer producer = messagingAccessPoint.createProducer();\n\n        messagingAccessPoint.startup();\n        System.out.printf(&quot;MessagingAccessPoint startup OK%n&quot;);\n\n        producer.startup();\n        System.out.printf(&quot;Producer startup OK%n&quot;);\n\n        {\n            Message message = producer.createBytesMessageToTopic(&quot;OMS_HELLO_TOPIC&quot;, &quot;OMS_HELLO_BODY&quot;.getBytes(Charset.forName(&quot;UTF-8&quot;)));\n            SendResult sendResult = producer.send(message);\n            System.out.printf(&quot;Send sync message OK, msgId: %s%n&quot;, sendResult.messageId());\n        }\n\n        {\n            final Promise&lt;SendResult&gt; result = producer.sendAsync(producer.createBytesMessageToTopic(&quot;OMS_HELLO_TOPIC&quot;, &quot;OMS_HELLO_BODY&quot;.getBytes(Charset.forName(&quot;UTF-8&quot;))));\n            result.addListener(new PromiseListener&lt;SendResult&gt;() {\n                @Override\n                public void operationCompleted(Promise&lt;SendResult&gt; promise) {\n                    System.out.printf(&quot;Send async message OK, msgId: %s%n&quot;, promise.get().messageId());\n                }\n\n                @Override\n                public void operationFailed(Promise&lt;SendResult&gt; promise) {\n                    System.out.printf(&quot;Send async message Failed, error: %s%n&quot;, promise.getThrowable().getMessage());\n                }\n            });\n        }\n\n        {\n            producer.sendOneway(producer.createBytesMessageToTopic(&quot;OMS_HELLO_TOPIC&quot;, &quot;OMS_HELLO_BODY&quot;.getBytes(Charset.forName(&quot;UTF-8&quot;))));\n            System.out.printf(&quot;Send oneway message OK%n&quot;);\n        }\n\n        producer.shutdown();\n        messagingAccessPoint.shutdown();\n    }\n}</code></pre>\n<p><strong>OMSPull消费者</strong><br>使用OMS PullConsumer轮询来自指定队列的消息。</p>\n<pre><code class=\"java\">public class OMSPullConsumer {\n    public static void main(String[] args) {\n        final MessagingAccessPoint messagingAccessPoint = MessagingAccessPointFactory\n            .getMessagingAccessPoint(&quot;openmessaging:rocketmq://IP1:9876,IP2:9876/namespace&quot;);\n\n        final PullConsumer consumer = messagingAccessPoint.createPullConsumer(&quot;OMS_HELLO_TOPIC&quot;,\n            OMS.newKeyValue().put(NonStandardKeys.CONSUMER_GROUP, &quot;OMS_CONSUMER&quot;));\n\n        messagingAccessPoint.startup();\n        System.out.printf(&quot;MessagingAccessPoint startup OK%n&quot;);\n\n        consumer.startup();\n        System.out.printf(&quot;Consumer startup OK%n&quot;);\n\n        Message message = consumer.poll();\n        if (message != null) {\n            String msgId = message.headers().getString(MessageHeader.MESSAGE_ID);\n            System.out.printf(&quot;Received one message: %s%n&quot;, msgId);\n            consumer.ack(msgId);\n        }\n\n        consumer.shutdown();\n        messagingAccessPoint.shutdown();\n    }\n}</code></pre>\n<p><strong>OMSPushConsumer</strong><br>将OMS PushConsumer附加到指定的队列，并通过MessageListener使用消息</p>\n<pre><code class=\"java\">public class OMSPushConsumer {\n    public static void main(String[] args) {\n        final MessagingAccessPoint messagingAccessPoint = MessagingAccessPointFactory\n            .getMessagingAccessPoint(&quot;openmessaging:rocketmq://IP1:9876,IP2:9876/namespace&quot;);\n\n        final PushConsumer consumer = messagingAccessPoint.\n            createPushConsumer(OMS.newKeyValue().put(NonStandardKeys.CONSUMER_GROUP, &quot;OMS_CONSUMER&quot;));\n\n        messagingAccessPoint.startup();\n        System.out.printf(&quot;MessagingAccessPoint startup OK%n&quot;);\n\n        Runtime.getRuntime().addShutdownHook(new Thread(new Runnable() {\n            @Override\n            public void run() {\n                consumer.shutdown();\n                messagingAccessPoint.shutdown();\n            }\n        }));\n\n        consumer.attachQueue(&quot;OMS_HELLO_TOPIC&quot;, new MessageListener() {\n            @Override\n            public void onMessage(final Message message, final ReceivedMessageContext context) {\n                System.out.printf(&quot;Received one message: %s%n&quot;, message.headers().getString(MessageHeader.MESSAGE_ID));\n                context.ack();\n            }\n        });\n    }\n}</code></pre>\n","site":{"data":{}},"more":"<h1 id=\"OpenMessaging\"><a href=\"#OpenMessaging\" class=\"headerlink\" title=\"OpenMessaging\"></a>OpenMessaging</h1><p>OpenMessaging，包括建立行业指南和消息传递，流式传输规范，从而为金融，电子商务，物联网和大数据领域提供通用框架。在分布式异构环境中，设计原则是面向云，简单，灵活且独立于语言。符合这些规范将使跨所有主要平台和操作系统开发异构消息应用程序成为可能。</p>\n<p>RocketMQ提供了OpenMessaging 0.1.0-alpha的部分实现，以下示例演示了如何基于OpenMessaging访问RocketMQ。</p>\n<p><strong>OMS生产者</strong><br>以下示例显示了如何以同步，异步或单向传输将消息发送到RocketMQ代理。</p>\n<pre><code class=\"java\">public class OMSProducer {\n    public static void main(String[] args) {\n        final MessagingAccessPoint messagingAccessPoint = MessagingAccessPointFactory\n            .getMessagingAccessPoint(&quot;openmessaging:rocketmq://IP1:9876,IP2:9876/namespace&quot;);\n\n        final Producer producer = messagingAccessPoint.createProducer();\n\n        messagingAccessPoint.startup();\n        System.out.printf(&quot;MessagingAccessPoint startup OK%n&quot;);\n\n        producer.startup();\n        System.out.printf(&quot;Producer startup OK%n&quot;);\n\n        {\n            Message message = producer.createBytesMessageToTopic(&quot;OMS_HELLO_TOPIC&quot;, &quot;OMS_HELLO_BODY&quot;.getBytes(Charset.forName(&quot;UTF-8&quot;)));\n            SendResult sendResult = producer.send(message);\n            System.out.printf(&quot;Send sync message OK, msgId: %s%n&quot;, sendResult.messageId());\n        }\n\n        {\n            final Promise&lt;SendResult&gt; result = producer.sendAsync(producer.createBytesMessageToTopic(&quot;OMS_HELLO_TOPIC&quot;, &quot;OMS_HELLO_BODY&quot;.getBytes(Charset.forName(&quot;UTF-8&quot;))));\n            result.addListener(new PromiseListener&lt;SendResult&gt;() {\n                @Override\n                public void operationCompleted(Promise&lt;SendResult&gt; promise) {\n                    System.out.printf(&quot;Send async message OK, msgId: %s%n&quot;, promise.get().messageId());\n                }\n\n                @Override\n                public void operationFailed(Promise&lt;SendResult&gt; promise) {\n                    System.out.printf(&quot;Send async message Failed, error: %s%n&quot;, promise.getThrowable().getMessage());\n                }\n            });\n        }\n\n        {\n            producer.sendOneway(producer.createBytesMessageToTopic(&quot;OMS_HELLO_TOPIC&quot;, &quot;OMS_HELLO_BODY&quot;.getBytes(Charset.forName(&quot;UTF-8&quot;))));\n            System.out.printf(&quot;Send oneway message OK%n&quot;);\n        }\n\n        producer.shutdown();\n        messagingAccessPoint.shutdown();\n    }\n}</code></pre>\n<p><strong>OMSPull消费者</strong><br>使用OMS PullConsumer轮询来自指定队列的消息。</p>\n<pre><code class=\"java\">public class OMSPullConsumer {\n    public static void main(String[] args) {\n        final MessagingAccessPoint messagingAccessPoint = MessagingAccessPointFactory\n            .getMessagingAccessPoint(&quot;openmessaging:rocketmq://IP1:9876,IP2:9876/namespace&quot;);\n\n        final PullConsumer consumer = messagingAccessPoint.createPullConsumer(&quot;OMS_HELLO_TOPIC&quot;,\n            OMS.newKeyValue().put(NonStandardKeys.CONSUMER_GROUP, &quot;OMS_CONSUMER&quot;));\n\n        messagingAccessPoint.startup();\n        System.out.printf(&quot;MessagingAccessPoint startup OK%n&quot;);\n\n        consumer.startup();\n        System.out.printf(&quot;Consumer startup OK%n&quot;);\n\n        Message message = consumer.poll();\n        if (message != null) {\n            String msgId = message.headers().getString(MessageHeader.MESSAGE_ID);\n            System.out.printf(&quot;Received one message: %s%n&quot;, msgId);\n            consumer.ack(msgId);\n        }\n\n        consumer.shutdown();\n        messagingAccessPoint.shutdown();\n    }\n}</code></pre>\n<p><strong>OMSPushConsumer</strong><br>将OMS PushConsumer附加到指定的队列，并通过MessageListener使用消息</p>\n<pre><code class=\"java\">public class OMSPushConsumer {\n    public static void main(String[] args) {\n        final MessagingAccessPoint messagingAccessPoint = MessagingAccessPointFactory\n            .getMessagingAccessPoint(&quot;openmessaging:rocketmq://IP1:9876,IP2:9876/namespace&quot;);\n\n        final PushConsumer consumer = messagingAccessPoint.\n            createPushConsumer(OMS.newKeyValue().put(NonStandardKeys.CONSUMER_GROUP, &quot;OMS_CONSUMER&quot;));\n\n        messagingAccessPoint.startup();\n        System.out.printf(&quot;MessagingAccessPoint startup OK%n&quot;);\n\n        Runtime.getRuntime().addShutdownHook(new Thread(new Runnable() {\n            @Override\n            public void run() {\n                consumer.shutdown();\n                messagingAccessPoint.shutdown();\n            }\n        }));\n\n        consumer.attachQueue(&quot;OMS_HELLO_TOPIC&quot;, new MessageListener() {\n            @Override\n            public void onMessage(final Message message, final ReceivedMessageContext context) {\n                System.out.printf(&quot;Received one message: %s%n&quot;, message.headers().getString(MessageHeader.MESSAGE_ID));\n                context.ack();\n            }\n        });\n    }\n}</code></pre>\n"},{"title":"序列化与反序列化","excerpt":"","comments":1,"date":"2020-04-11T16:30:52.000Z","_content":"\n## 什么是序列化\n\n当两个进程远程通信时，彼此可以发送各种类型的数据。无论是何种类型的数据，都会以二进制序列的形式在网络上传送。比如，我们可以通过http协议发送字符串信息，我们也可以在网络上直接发送Java对象。发送方需要把这个Java对象转换为字节序列，才能在网络上传送，接收方则需要把字节序列再恢复为Java对象才能正常读取。\n\n- **序列化：** 对象序列化的最主要的用处就是在传递和保存对象的时候，保证对象的完整性和可传递性。序列化是把对象转换成有序字节流，以便在网络上传输或者保存在本地文件中。核心作用是对象状态的保存与重建。\n- **反序列化：** 客户端从文件中或网络上获得序列化后的对象字节流，根据字节流中所保存的对象状态及描述信息，通过反序列化重建对象。\n\n## 为什么要序列化\n\n1. **持久化：** 把对象的字节序列永久地保存到硬盘上，通常存放在一个文件中，比如：休眠的实现。以后服务器session管理，hibernate将对象持久化实现。\n\n2. **网络通信：** 在网络上传送对象的字节序列。比如：服务器之间的数据通信、对象传递。\n\n## 怎样来序列化\n\n在Java中，想实现序列化，有两种方法：\n\n1. **实现`Serializable`接口**\n   一个对象想要被序列化，那么它的类就要实现此接口或者它的子接口。这个对象的所有属性（包括private属性、包括其引用的对象）都可以被序列化和反序列化来保存、传递。不想序列化的字段可以使用`transient`修饰。由于Serializable对象完全以它存储的二进制位为基础来构造，因此并不会调用任何构造函数，因此Serializable类无需默认构造函数，但是当Serializable类的父类没有实现Serializable接口时，反序列化过程会调用父类的默认构造函数，因此该父类必须有默认构造函数，否则会抛异常。使用`transient`关键字阻止序列化虽然简单方便，但被它修饰的属性被完全隔离在序列化机制之外，导致了在反序列化时无法获取该属性的值，而通过在需要序列化的对象的Java类里加入`writeObject()`方法与`readObject()`方法可以控制如何序列化各属性，甚至完全不序列化某些属性或者加密序列化某些属性。\n\n2. **实现`Externalizable`接口**\n    它是Serializable接口的子类，用户要实现的`writeExternal()`和`readExternal()`方法，用来决定如何序列化和反序列化。因为序列化和反序列化方法需要自己实现，因此可以指定序列化哪些属性，而`transient`在这里无效。对Externalizable对象反序列化时，会先调用类的无参构造方法，这是有别于默认反序列方式的。如果把类的不带参数的构造方法删除，或者把该构造方法的访问权限设置为private、默认或protected级别，会抛出`java.io.InvalidException: no valid constructor`异常，因此Externalizable对象必须有默认构造函数，而且必须是public的。\n\n\n**序列化版本：**\n\n序列化过程中可以控制序列化的版本，该字段为被序列化对象中的serialVersionUID字段。\n\n```java\npublic class Test implements Serializable {\n    private static final long serialVersionUID = 1L;\n}\n```\n反序列化时会讲序列化串中的serialVersionUID与当前对象中的序列化版本比较，如果一致才能成功反序列化。\n\n如果没有显式的声明serialVersionUID，系统会自动生成一个，类名、类及其属性修饰符、接口及接口顺序、属性、静态初始化、构造器中任何一样发生变化，都会导致serialVersionUID改变。所以还是显式的声明比较好。\n\n\n","source":"_posts/2020-04-09-kongzheng1993-序列化与反序列化.md","raw":"---\ntitle: 序列化与反序列化\nexcerpt: ''\ntags: [Java]\ncategories: [Java]\ncomments: true\ndate: 2020-04-12 00:30:52\n---\n\n## 什么是序列化\n\n当两个进程远程通信时，彼此可以发送各种类型的数据。无论是何种类型的数据，都会以二进制序列的形式在网络上传送。比如，我们可以通过http协议发送字符串信息，我们也可以在网络上直接发送Java对象。发送方需要把这个Java对象转换为字节序列，才能在网络上传送，接收方则需要把字节序列再恢复为Java对象才能正常读取。\n\n- **序列化：** 对象序列化的最主要的用处就是在传递和保存对象的时候，保证对象的完整性和可传递性。序列化是把对象转换成有序字节流，以便在网络上传输或者保存在本地文件中。核心作用是对象状态的保存与重建。\n- **反序列化：** 客户端从文件中或网络上获得序列化后的对象字节流，根据字节流中所保存的对象状态及描述信息，通过反序列化重建对象。\n\n## 为什么要序列化\n\n1. **持久化：** 把对象的字节序列永久地保存到硬盘上，通常存放在一个文件中，比如：休眠的实现。以后服务器session管理，hibernate将对象持久化实现。\n\n2. **网络通信：** 在网络上传送对象的字节序列。比如：服务器之间的数据通信、对象传递。\n\n## 怎样来序列化\n\n在Java中，想实现序列化，有两种方法：\n\n1. **实现`Serializable`接口**\n   一个对象想要被序列化，那么它的类就要实现此接口或者它的子接口。这个对象的所有属性（包括private属性、包括其引用的对象）都可以被序列化和反序列化来保存、传递。不想序列化的字段可以使用`transient`修饰。由于Serializable对象完全以它存储的二进制位为基础来构造，因此并不会调用任何构造函数，因此Serializable类无需默认构造函数，但是当Serializable类的父类没有实现Serializable接口时，反序列化过程会调用父类的默认构造函数，因此该父类必须有默认构造函数，否则会抛异常。使用`transient`关键字阻止序列化虽然简单方便，但被它修饰的属性被完全隔离在序列化机制之外，导致了在反序列化时无法获取该属性的值，而通过在需要序列化的对象的Java类里加入`writeObject()`方法与`readObject()`方法可以控制如何序列化各属性，甚至完全不序列化某些属性或者加密序列化某些属性。\n\n2. **实现`Externalizable`接口**\n    它是Serializable接口的子类，用户要实现的`writeExternal()`和`readExternal()`方法，用来决定如何序列化和反序列化。因为序列化和反序列化方法需要自己实现，因此可以指定序列化哪些属性，而`transient`在这里无效。对Externalizable对象反序列化时，会先调用类的无参构造方法，这是有别于默认反序列方式的。如果把类的不带参数的构造方法删除，或者把该构造方法的访问权限设置为private、默认或protected级别，会抛出`java.io.InvalidException: no valid constructor`异常，因此Externalizable对象必须有默认构造函数，而且必须是public的。\n\n\n**序列化版本：**\n\n序列化过程中可以控制序列化的版本，该字段为被序列化对象中的serialVersionUID字段。\n\n```java\npublic class Test implements Serializable {\n    private static final long serialVersionUID = 1L;\n}\n```\n反序列化时会讲序列化串中的serialVersionUID与当前对象中的序列化版本比较，如果一致才能成功反序列化。\n\n如果没有显式的声明serialVersionUID，系统会自动生成一个，类名、类及其属性修饰符、接口及接口顺序、属性、静态初始化、构造器中任何一样发生变化，都会导致serialVersionUID改变。所以还是显式的声明比较好。\n\n\n","slug":"kongzheng1993-序列化与反序列化","published":1,"updated":"2023-03-08T07:05:58.794Z","layout":"post","photos":[],"link":"","_id":"clg0k2ag3002yt26fpkui29gr","content":"<h2 id=\"什么是序列化\"><a href=\"#什么是序列化\" class=\"headerlink\" title=\"什么是序列化\"></a>什么是序列化</h2><p>当两个进程远程通信时，彼此可以发送各种类型的数据。无论是何种类型的数据，都会以二进制序列的形式在网络上传送。比如，我们可以通过http协议发送字符串信息，我们也可以在网络上直接发送Java对象。发送方需要把这个Java对象转换为字节序列，才能在网络上传送，接收方则需要把字节序列再恢复为Java对象才能正常读取。</p>\n<ul>\n<li><strong>序列化：</strong> 对象序列化的最主要的用处就是在传递和保存对象的时候，保证对象的完整性和可传递性。序列化是把对象转换成有序字节流，以便在网络上传输或者保存在本地文件中。核心作用是对象状态的保存与重建。</li>\n<li><strong>反序列化：</strong> 客户端从文件中或网络上获得序列化后的对象字节流，根据字节流中所保存的对象状态及描述信息，通过反序列化重建对象。</li>\n</ul>\n<h2 id=\"为什么要序列化\"><a href=\"#为什么要序列化\" class=\"headerlink\" title=\"为什么要序列化\"></a>为什么要序列化</h2><ol>\n<li><p><strong>持久化：</strong> 把对象的字节序列永久地保存到硬盘上，通常存放在一个文件中，比如：休眠的实现。以后服务器session管理，hibernate将对象持久化实现。</p>\n</li>\n<li><p><strong>网络通信：</strong> 在网络上传送对象的字节序列。比如：服务器之间的数据通信、对象传递。</p>\n</li>\n</ol>\n<h2 id=\"怎样来序列化\"><a href=\"#怎样来序列化\" class=\"headerlink\" title=\"怎样来序列化\"></a>怎样来序列化</h2><p>在Java中，想实现序列化，有两种方法：</p>\n<ol>\n<li><p><strong>实现<code>Serializable</code>接口</strong><br>一个对象想要被序列化，那么它的类就要实现此接口或者它的子接口。这个对象的所有属性（包括private属性、包括其引用的对象）都可以被序列化和反序列化来保存、传递。不想序列化的字段可以使用<code>transient</code>修饰。由于Serializable对象完全以它存储的二进制位为基础来构造，因此并不会调用任何构造函数，因此Serializable类无需默认构造函数，但是当Serializable类的父类没有实现Serializable接口时，反序列化过程会调用父类的默认构造函数，因此该父类必须有默认构造函数，否则会抛异常。使用<code>transient</code>关键字阻止序列化虽然简单方便，但被它修饰的属性被完全隔离在序列化机制之外，导致了在反序列化时无法获取该属性的值，而通过在需要序列化的对象的Java类里加入<code>writeObject()</code>方法与<code>readObject()</code>方法可以控制如何序列化各属性，甚至完全不序列化某些属性或者加密序列化某些属性。</p>\n</li>\n<li><p><strong>实现<code>Externalizable</code>接口</strong><br> 它是Serializable接口的子类，用户要实现的<code>writeExternal()</code>和<code>readExternal()</code>方法，用来决定如何序列化和反序列化。因为序列化和反序列化方法需要自己实现，因此可以指定序列化哪些属性，而<code>transient</code>在这里无效。对Externalizable对象反序列化时，会先调用类的无参构造方法，这是有别于默认反序列方式的。如果把类的不带参数的构造方法删除，或者把该构造方法的访问权限设置为private、默认或protected级别，会抛出<code>java.io.InvalidException: no valid constructor</code>异常，因此Externalizable对象必须有默认构造函数，而且必须是public的。</p>\n</li>\n</ol>\n<p><strong>序列化版本：</strong></p>\n<p>序列化过程中可以控制序列化的版本，该字段为被序列化对象中的serialVersionUID字段。</p>\n<pre><code class=\"java\">public class Test implements Serializable {\n    private static final long serialVersionUID = 1L;\n}</code></pre>\n<p>反序列化时会讲序列化串中的serialVersionUID与当前对象中的序列化版本比较，如果一致才能成功反序列化。</p>\n<p>如果没有显式的声明serialVersionUID，系统会自动生成一个，类名、类及其属性修饰符、接口及接口顺序、属性、静态初始化、构造器中任何一样发生变化，都会导致serialVersionUID改变。所以还是显式的声明比较好。</p>\n","site":{"data":{}},"more":"<h2 id=\"什么是序列化\"><a href=\"#什么是序列化\" class=\"headerlink\" title=\"什么是序列化\"></a>什么是序列化</h2><p>当两个进程远程通信时，彼此可以发送各种类型的数据。无论是何种类型的数据，都会以二进制序列的形式在网络上传送。比如，我们可以通过http协议发送字符串信息，我们也可以在网络上直接发送Java对象。发送方需要把这个Java对象转换为字节序列，才能在网络上传送，接收方则需要把字节序列再恢复为Java对象才能正常读取。</p>\n<ul>\n<li><strong>序列化：</strong> 对象序列化的最主要的用处就是在传递和保存对象的时候，保证对象的完整性和可传递性。序列化是把对象转换成有序字节流，以便在网络上传输或者保存在本地文件中。核心作用是对象状态的保存与重建。</li>\n<li><strong>反序列化：</strong> 客户端从文件中或网络上获得序列化后的对象字节流，根据字节流中所保存的对象状态及描述信息，通过反序列化重建对象。</li>\n</ul>\n<h2 id=\"为什么要序列化\"><a href=\"#为什么要序列化\" class=\"headerlink\" title=\"为什么要序列化\"></a>为什么要序列化</h2><ol>\n<li><p><strong>持久化：</strong> 把对象的字节序列永久地保存到硬盘上，通常存放在一个文件中，比如：休眠的实现。以后服务器session管理，hibernate将对象持久化实现。</p>\n</li>\n<li><p><strong>网络通信：</strong> 在网络上传送对象的字节序列。比如：服务器之间的数据通信、对象传递。</p>\n</li>\n</ol>\n<h2 id=\"怎样来序列化\"><a href=\"#怎样来序列化\" class=\"headerlink\" title=\"怎样来序列化\"></a>怎样来序列化</h2><p>在Java中，想实现序列化，有两种方法：</p>\n<ol>\n<li><p><strong>实现<code>Serializable</code>接口</strong><br>一个对象想要被序列化，那么它的类就要实现此接口或者它的子接口。这个对象的所有属性（包括private属性、包括其引用的对象）都可以被序列化和反序列化来保存、传递。不想序列化的字段可以使用<code>transient</code>修饰。由于Serializable对象完全以它存储的二进制位为基础来构造，因此并不会调用任何构造函数，因此Serializable类无需默认构造函数，但是当Serializable类的父类没有实现Serializable接口时，反序列化过程会调用父类的默认构造函数，因此该父类必须有默认构造函数，否则会抛异常。使用<code>transient</code>关键字阻止序列化虽然简单方便，但被它修饰的属性被完全隔离在序列化机制之外，导致了在反序列化时无法获取该属性的值，而通过在需要序列化的对象的Java类里加入<code>writeObject()</code>方法与<code>readObject()</code>方法可以控制如何序列化各属性，甚至完全不序列化某些属性或者加密序列化某些属性。</p>\n</li>\n<li><p><strong>实现<code>Externalizable</code>接口</strong><br> 它是Serializable接口的子类，用户要实现的<code>writeExternal()</code>和<code>readExternal()</code>方法，用来决定如何序列化和反序列化。因为序列化和反序列化方法需要自己实现，因此可以指定序列化哪些属性，而<code>transient</code>在这里无效。对Externalizable对象反序列化时，会先调用类的无参构造方法，这是有别于默认反序列方式的。如果把类的不带参数的构造方法删除，或者把该构造方法的访问权限设置为private、默认或protected级别，会抛出<code>java.io.InvalidException: no valid constructor</code>异常，因此Externalizable对象必须有默认构造函数，而且必须是public的。</p>\n</li>\n</ol>\n<p><strong>序列化版本：</strong></p>\n<p>序列化过程中可以控制序列化的版本，该字段为被序列化对象中的serialVersionUID字段。</p>\n<pre><code class=\"java\">public class Test implements Serializable {\n    private static final long serialVersionUID = 1L;\n}</code></pre>\n<p>反序列化时会讲序列化串中的serialVersionUID与当前对象中的序列化版本比较，如果一致才能成功反序列化。</p>\n<p>如果没有显式的声明serialVersionUID，系统会自动生成一个，类名、类及其属性修饰符、接口及接口顺序、属性、静态初始化、构造器中任何一样发生变化，都会导致serialVersionUID改变。所以还是显式的声明比较好。</p>\n"},{"title":"交易消息示例","excerpt":"","comments":1,"date":"2020-04-09T16:30:52.000Z","_content":"\n# 交易消息示例\n\n## 什么是交易消息\n\n可以将其视为两阶段提交消息实现，以确保分布式系统中的最终一致性。事务性消息可确保本地事务的执行和消息的发送能以原子方式执行。\n\n## 使用限制\n\n1. 事务消息没有时间表和批处理支持。\n2. 为了避免对单个消息进行过多的检查并导致半个队列的消息堆积，我们默认将单个消息的检查数量限制为15次，但是用户可以通过更改`transactionCheckMax`来更改此限制。如果一条消息经过`transactionCheckMax`次检查，默认情况下，代理将丢弃此消息并同时打印错误日志。用户可以通过覆盖`AbstractTransactionCheckListener`类来更改此行为。\n3. 将`broker`配置中由参数`transactionTimeout`来确定一定时间后检查交易消息。用户还可以在发送事务消息时通过设置用户属性`CHECK_IMMUNITY_TIME_IN_SECONDS`来更改此限制，该参数优先于`transactionMsgTimeout`参数。\n4. 交易消息可能被检查或消耗了不止一次。\n5. 提交给用户目标主题的已提交消息可能会失败。目前，它取决于日志记录。RocketMQ本身的高可用性机制可确保高可用性。如果要确保事务消息不会丢失并且事务完整性得到保证，建议使用同步双写机制。\n6. 事务性消息的生产者ID不能与其他类型的消息的生产者ID共享。与其他类型的消息不同，事务性消息允许向后查询。MQ服务器通过生产者ID查询客户端。\n\n## 应用\n\n### 1，交易状态\n\n事务消息有三种状态：\n\n- TransactionStatus.CommitTransaction：提交事务，表示允许使用者使用此消息。\n- TransactionStatus.RollbackTransaction：回滚事务，表示该消息将被删除且不允许使用。\n- TransactionStatus.Unknown：中间状态，表示需要MQ进行回溯以确定状态。\n\n### 2，发送交易信息\n\n#### 2，1 创建事务生产方\n\n使用`TransactionMQProducer`类创建生产方客户端，并指定唯一的`producerGroup`，然后可以设置自定义线程池来处理检查请求。执行本地事务后，需要根据执行结果对MQ进行回复，回复状态如上节所述。\n\n```java\nimport org.apache.rocketmq.client.consumer.DefaultMQPushConsumer;\nimport org.apache.rocketmq.client.consumer.listener.ConsumeConcurrentlyContext;\nimport org.apache.rocketmq.client.consumer.listener.ConsumeConcurrentlyStatus;\nimport org.apache.rocketmq.client.consumer.listener.MessageListenerConcurrently;\nimport org.apache.rocketmq.common.message.MessageExt;\nimport java.util.List;\n\npublic class TransactionProducer {\n    public static void main(String[] args) throws MQClientException, InterruptedException {\n        TransactionListener transactionListener = new TransactionListenerImpl();\n        TransactionMQProducer producer = new TransactionMQProducer(\"please_rename_unique_group_name\");\n        ExecutorService executorService = new ThreadPoolExecutor(2, 5, 100, TimeUnit.SECONDS, new ArrayBlockingQueue<Runnable>(2000), new ThreadFactory() {\n            @Override\n            public Thread newThread(Runnable r) {\n                Thread thread = new Thread(r);\n                thread.setName(\"client-transaction-msg-check-thread\");\n                return thread;\n            }\n        });\n\n        producer.setExecutorService(executorService);\n        producer.setTransactionListener(transactionListener);\n        producer.start();\n\n        String[] tags = new String[] {\"TagA\", \"TagB\", \"TagC\", \"TagD\", \"TagE\"};\n        for (int i = 0; i < 10; i++) {\n            try {\n                Message msg =\n                    new Message(\"TopicTest1234\", tags[i % tags.length], \"KEY\" + i,\n                        (\"Hello RocketMQ \" + i).getBytes(RemotingHelper.DEFAULT_CHARSET));\n                SendResult sendResult = producer.sendMessageInTransaction(msg, null);\n                System.out.printf(\"%s%n\", sendResult);\n\n                Thread.sleep(10);\n            } catch (MQClientException | UnsupportedEncodingException e) {\n                e.printStackTrace();\n            }\n        }\n\n        for (int i = 0; i < 100000; i++) {\n            Thread.sleep(1000);\n        }\n        producer.shutdown();\n    }\n}\n```\n\n#### 2，2实现TransactionListener接口\n\n当发送一半消息成功时，使用`executeLocalTransaction`方法执行本地事务。它返回上一部分中提到的三个事务状态之一。\n`checkLocalTransaction`方法用于检查本地事务状态并响应MQ检查请求。它还返回上一部分中提到的三个事务状态之一。\n\n```java\npublic class TransactionListenerImpl implements TransactionListener {\n   private AtomicInteger transactionIndex = new AtomicInteger(0);\n      private ConcurrentHashMap<String, Integer> localTrans = new ConcurrentHashMap<>();\n      @Override\n   public LocalTransactionState executeLocalTransaction(Message msg, Object arg) {\n       int value = transactionIndex.getAndIncrement();\n       int status = value % 3;\n       localTrans.put(msg.getTransactionId(), status);\n       return LocalTransactionState.UNKNOW;\n   }\n      @Override\n   public LocalTransactionState checkLocalTransaction(MessageExt msg) {\n       Integer status = localTrans.get(msg.getTransactionId());\n       if (null != status) {\n           switch (status) {\n               case 0:\n                   return LocalTransactionState.UNKNOW;\n               case 1:\n                   return LocalTransactionState.COMMIT_MESSAGE;\n               case 2:\n                   return LocalTransactionState.ROLLBACK_MESSAGE;\n           }\n       }\n       return LocalTransactionState.COMMIT_MESSAGE;\n   }\n```\n","source":"_posts/2020-04-09-kongzheng1993-OpenMessageing_Example.md","raw":"---\ntitle: 交易消息示例\nexcerpt: ''\ntags: [RocketMQ]\ncategories: [RocketMQ]\ncomments: true\ndate: 2020-04-10 00:30:52\n---\n\n# 交易消息示例\n\n## 什么是交易消息\n\n可以将其视为两阶段提交消息实现，以确保分布式系统中的最终一致性。事务性消息可确保本地事务的执行和消息的发送能以原子方式执行。\n\n## 使用限制\n\n1. 事务消息没有时间表和批处理支持。\n2. 为了避免对单个消息进行过多的检查并导致半个队列的消息堆积，我们默认将单个消息的检查数量限制为15次，但是用户可以通过更改`transactionCheckMax`来更改此限制。如果一条消息经过`transactionCheckMax`次检查，默认情况下，代理将丢弃此消息并同时打印错误日志。用户可以通过覆盖`AbstractTransactionCheckListener`类来更改此行为。\n3. 将`broker`配置中由参数`transactionTimeout`来确定一定时间后检查交易消息。用户还可以在发送事务消息时通过设置用户属性`CHECK_IMMUNITY_TIME_IN_SECONDS`来更改此限制，该参数优先于`transactionMsgTimeout`参数。\n4. 交易消息可能被检查或消耗了不止一次。\n5. 提交给用户目标主题的已提交消息可能会失败。目前，它取决于日志记录。RocketMQ本身的高可用性机制可确保高可用性。如果要确保事务消息不会丢失并且事务完整性得到保证，建议使用同步双写机制。\n6. 事务性消息的生产者ID不能与其他类型的消息的生产者ID共享。与其他类型的消息不同，事务性消息允许向后查询。MQ服务器通过生产者ID查询客户端。\n\n## 应用\n\n### 1，交易状态\n\n事务消息有三种状态：\n\n- TransactionStatus.CommitTransaction：提交事务，表示允许使用者使用此消息。\n- TransactionStatus.RollbackTransaction：回滚事务，表示该消息将被删除且不允许使用。\n- TransactionStatus.Unknown：中间状态，表示需要MQ进行回溯以确定状态。\n\n### 2，发送交易信息\n\n#### 2，1 创建事务生产方\n\n使用`TransactionMQProducer`类创建生产方客户端，并指定唯一的`producerGroup`，然后可以设置自定义线程池来处理检查请求。执行本地事务后，需要根据执行结果对MQ进行回复，回复状态如上节所述。\n\n```java\nimport org.apache.rocketmq.client.consumer.DefaultMQPushConsumer;\nimport org.apache.rocketmq.client.consumer.listener.ConsumeConcurrentlyContext;\nimport org.apache.rocketmq.client.consumer.listener.ConsumeConcurrentlyStatus;\nimport org.apache.rocketmq.client.consumer.listener.MessageListenerConcurrently;\nimport org.apache.rocketmq.common.message.MessageExt;\nimport java.util.List;\n\npublic class TransactionProducer {\n    public static void main(String[] args) throws MQClientException, InterruptedException {\n        TransactionListener transactionListener = new TransactionListenerImpl();\n        TransactionMQProducer producer = new TransactionMQProducer(\"please_rename_unique_group_name\");\n        ExecutorService executorService = new ThreadPoolExecutor(2, 5, 100, TimeUnit.SECONDS, new ArrayBlockingQueue<Runnable>(2000), new ThreadFactory() {\n            @Override\n            public Thread newThread(Runnable r) {\n                Thread thread = new Thread(r);\n                thread.setName(\"client-transaction-msg-check-thread\");\n                return thread;\n            }\n        });\n\n        producer.setExecutorService(executorService);\n        producer.setTransactionListener(transactionListener);\n        producer.start();\n\n        String[] tags = new String[] {\"TagA\", \"TagB\", \"TagC\", \"TagD\", \"TagE\"};\n        for (int i = 0; i < 10; i++) {\n            try {\n                Message msg =\n                    new Message(\"TopicTest1234\", tags[i % tags.length], \"KEY\" + i,\n                        (\"Hello RocketMQ \" + i).getBytes(RemotingHelper.DEFAULT_CHARSET));\n                SendResult sendResult = producer.sendMessageInTransaction(msg, null);\n                System.out.printf(\"%s%n\", sendResult);\n\n                Thread.sleep(10);\n            } catch (MQClientException | UnsupportedEncodingException e) {\n                e.printStackTrace();\n            }\n        }\n\n        for (int i = 0; i < 100000; i++) {\n            Thread.sleep(1000);\n        }\n        producer.shutdown();\n    }\n}\n```\n\n#### 2，2实现TransactionListener接口\n\n当发送一半消息成功时，使用`executeLocalTransaction`方法执行本地事务。它返回上一部分中提到的三个事务状态之一。\n`checkLocalTransaction`方法用于检查本地事务状态并响应MQ检查请求。它还返回上一部分中提到的三个事务状态之一。\n\n```java\npublic class TransactionListenerImpl implements TransactionListener {\n   private AtomicInteger transactionIndex = new AtomicInteger(0);\n      private ConcurrentHashMap<String, Integer> localTrans = new ConcurrentHashMap<>();\n      @Override\n   public LocalTransactionState executeLocalTransaction(Message msg, Object arg) {\n       int value = transactionIndex.getAndIncrement();\n       int status = value % 3;\n       localTrans.put(msg.getTransactionId(), status);\n       return LocalTransactionState.UNKNOW;\n   }\n      @Override\n   public LocalTransactionState checkLocalTransaction(MessageExt msg) {\n       Integer status = localTrans.get(msg.getTransactionId());\n       if (null != status) {\n           switch (status) {\n               case 0:\n                   return LocalTransactionState.UNKNOW;\n               case 1:\n                   return LocalTransactionState.COMMIT_MESSAGE;\n               case 2:\n                   return LocalTransactionState.ROLLBACK_MESSAGE;\n           }\n       }\n       return LocalTransactionState.COMMIT_MESSAGE;\n   }\n```\n","slug":"kongzheng1993-OpenMessageing_Example","published":1,"updated":"2023-03-08T07:05:58.794Z","layout":"post","photos":[],"link":"","_id":"clg0k2agn0030t26ffp0qo0cu","content":"<h1 id=\"交易消息示例\"><a href=\"#交易消息示例\" class=\"headerlink\" title=\"交易消息示例\"></a>交易消息示例</h1><h2 id=\"什么是交易消息\"><a href=\"#什么是交易消息\" class=\"headerlink\" title=\"什么是交易消息\"></a>什么是交易消息</h2><p>可以将其视为两阶段提交消息实现，以确保分布式系统中的最终一致性。事务性消息可确保本地事务的执行和消息的发送能以原子方式执行。</p>\n<h2 id=\"使用限制\"><a href=\"#使用限制\" class=\"headerlink\" title=\"使用限制\"></a>使用限制</h2><ol>\n<li>事务消息没有时间表和批处理支持。</li>\n<li>为了避免对单个消息进行过多的检查并导致半个队列的消息堆积，我们默认将单个消息的检查数量限制为15次，但是用户可以通过更改<code>transactionCheckMax</code>来更改此限制。如果一条消息经过<code>transactionCheckMax</code>次检查，默认情况下，代理将丢弃此消息并同时打印错误日志。用户可以通过覆盖<code>AbstractTransactionCheckListener</code>类来更改此行为。</li>\n<li>将<code>broker</code>配置中由参数<code>transactionTimeout</code>来确定一定时间后检查交易消息。用户还可以在发送事务消息时通过设置用户属性<code>CHECK_IMMUNITY_TIME_IN_SECONDS</code>来更改此限制，该参数优先于<code>transactionMsgTimeout</code>参数。</li>\n<li>交易消息可能被检查或消耗了不止一次。</li>\n<li>提交给用户目标主题的已提交消息可能会失败。目前，它取决于日志记录。RocketMQ本身的高可用性机制可确保高可用性。如果要确保事务消息不会丢失并且事务完整性得到保证，建议使用同步双写机制。</li>\n<li>事务性消息的生产者ID不能与其他类型的消息的生产者ID共享。与其他类型的消息不同，事务性消息允许向后查询。MQ服务器通过生产者ID查询客户端。</li>\n</ol>\n<h2 id=\"应用\"><a href=\"#应用\" class=\"headerlink\" title=\"应用\"></a>应用</h2><h3 id=\"1，交易状态\"><a href=\"#1，交易状态\" class=\"headerlink\" title=\"1，交易状态\"></a>1，交易状态</h3><p>事务消息有三种状态：</p>\n<ul>\n<li>TransactionStatus.CommitTransaction：提交事务，表示允许使用者使用此消息。</li>\n<li>TransactionStatus.RollbackTransaction：回滚事务，表示该消息将被删除且不允许使用。</li>\n<li>TransactionStatus.Unknown：中间状态，表示需要MQ进行回溯以确定状态。</li>\n</ul>\n<h3 id=\"2，发送交易信息\"><a href=\"#2，发送交易信息\" class=\"headerlink\" title=\"2，发送交易信息\"></a>2，发送交易信息</h3><h4 id=\"2，1-创建事务生产方\"><a href=\"#2，1-创建事务生产方\" class=\"headerlink\" title=\"2，1 创建事务生产方\"></a>2，1 创建事务生产方</h4><p>使用<code>TransactionMQProducer</code>类创建生产方客户端，并指定唯一的<code>producerGroup</code>，然后可以设置自定义线程池来处理检查请求。执行本地事务后，需要根据执行结果对MQ进行回复，回复状态如上节所述。</p>\n<pre><code class=\"java\">import org.apache.rocketmq.client.consumer.DefaultMQPushConsumer;\nimport org.apache.rocketmq.client.consumer.listener.ConsumeConcurrentlyContext;\nimport org.apache.rocketmq.client.consumer.listener.ConsumeConcurrentlyStatus;\nimport org.apache.rocketmq.client.consumer.listener.MessageListenerConcurrently;\nimport org.apache.rocketmq.common.message.MessageExt;\nimport java.util.List;\n\npublic class TransactionProducer {\n    public static void main(String[] args) throws MQClientException, InterruptedException {\n        TransactionListener transactionListener = new TransactionListenerImpl();\n        TransactionMQProducer producer = new TransactionMQProducer(&quot;please_rename_unique_group_name&quot;);\n        ExecutorService executorService = new ThreadPoolExecutor(2, 5, 100, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;Runnable&gt;(2000), new ThreadFactory() {\n            @Override\n            public Thread newThread(Runnable r) {\n                Thread thread = new Thread(r);\n                thread.setName(&quot;client-transaction-msg-check-thread&quot;);\n                return thread;\n            }\n        });\n\n        producer.setExecutorService(executorService);\n        producer.setTransactionListener(transactionListener);\n        producer.start();\n\n        String[] tags = new String[] {&quot;TagA&quot;, &quot;TagB&quot;, &quot;TagC&quot;, &quot;TagD&quot;, &quot;TagE&quot;};\n        for (int i = 0; i &lt; 10; i++) {\n            try {\n                Message msg =\n                    new Message(&quot;TopicTest1234&quot;, tags[i % tags.length], &quot;KEY&quot; + i,\n                        (&quot;Hello RocketMQ &quot; + i).getBytes(RemotingHelper.DEFAULT_CHARSET));\n                SendResult sendResult = producer.sendMessageInTransaction(msg, null);\n                System.out.printf(&quot;%s%n&quot;, sendResult);\n\n                Thread.sleep(10);\n            } catch (MQClientException | UnsupportedEncodingException e) {\n                e.printStackTrace();\n            }\n        }\n\n        for (int i = 0; i &lt; 100000; i++) {\n            Thread.sleep(1000);\n        }\n        producer.shutdown();\n    }\n}</code></pre>\n<h4 id=\"2，2实现TransactionListener接口\"><a href=\"#2，2实现TransactionListener接口\" class=\"headerlink\" title=\"2，2实现TransactionListener接口\"></a>2，2实现TransactionListener接口</h4><p>当发送一半消息成功时，使用<code>executeLocalTransaction</code>方法执行本地事务。它返回上一部分中提到的三个事务状态之一。<br><code>checkLocalTransaction</code>方法用于检查本地事务状态并响应MQ检查请求。它还返回上一部分中提到的三个事务状态之一。</p>\n<pre><code class=\"java\">public class TransactionListenerImpl implements TransactionListener {\n   private AtomicInteger transactionIndex = new AtomicInteger(0);\n      private ConcurrentHashMap&lt;String, Integer&gt; localTrans = new ConcurrentHashMap&lt;&gt;();\n      @Override\n   public LocalTransactionState executeLocalTransaction(Message msg, Object arg) {\n       int value = transactionIndex.getAndIncrement();\n       int status = value % 3;\n       localTrans.put(msg.getTransactionId(), status);\n       return LocalTransactionState.UNKNOW;\n   }\n      @Override\n   public LocalTransactionState checkLocalTransaction(MessageExt msg) {\n       Integer status = localTrans.get(msg.getTransactionId());\n       if (null != status) {\n           switch (status) {\n               case 0:\n                   return LocalTransactionState.UNKNOW;\n               case 1:\n                   return LocalTransactionState.COMMIT_MESSAGE;\n               case 2:\n                   return LocalTransactionState.ROLLBACK_MESSAGE;\n           }\n       }\n       return LocalTransactionState.COMMIT_MESSAGE;\n   }</code></pre>\n","site":{"data":{}},"more":"<h1 id=\"交易消息示例\"><a href=\"#交易消息示例\" class=\"headerlink\" title=\"交易消息示例\"></a>交易消息示例</h1><h2 id=\"什么是交易消息\"><a href=\"#什么是交易消息\" class=\"headerlink\" title=\"什么是交易消息\"></a>什么是交易消息</h2><p>可以将其视为两阶段提交消息实现，以确保分布式系统中的最终一致性。事务性消息可确保本地事务的执行和消息的发送能以原子方式执行。</p>\n<h2 id=\"使用限制\"><a href=\"#使用限制\" class=\"headerlink\" title=\"使用限制\"></a>使用限制</h2><ol>\n<li>事务消息没有时间表和批处理支持。</li>\n<li>为了避免对单个消息进行过多的检查并导致半个队列的消息堆积，我们默认将单个消息的检查数量限制为15次，但是用户可以通过更改<code>transactionCheckMax</code>来更改此限制。如果一条消息经过<code>transactionCheckMax</code>次检查，默认情况下，代理将丢弃此消息并同时打印错误日志。用户可以通过覆盖<code>AbstractTransactionCheckListener</code>类来更改此行为。</li>\n<li>将<code>broker</code>配置中由参数<code>transactionTimeout</code>来确定一定时间后检查交易消息。用户还可以在发送事务消息时通过设置用户属性<code>CHECK_IMMUNITY_TIME_IN_SECONDS</code>来更改此限制，该参数优先于<code>transactionMsgTimeout</code>参数。</li>\n<li>交易消息可能被检查或消耗了不止一次。</li>\n<li>提交给用户目标主题的已提交消息可能会失败。目前，它取决于日志记录。RocketMQ本身的高可用性机制可确保高可用性。如果要确保事务消息不会丢失并且事务完整性得到保证，建议使用同步双写机制。</li>\n<li>事务性消息的生产者ID不能与其他类型的消息的生产者ID共享。与其他类型的消息不同，事务性消息允许向后查询。MQ服务器通过生产者ID查询客户端。</li>\n</ol>\n<h2 id=\"应用\"><a href=\"#应用\" class=\"headerlink\" title=\"应用\"></a>应用</h2><h3 id=\"1，交易状态\"><a href=\"#1，交易状态\" class=\"headerlink\" title=\"1，交易状态\"></a>1，交易状态</h3><p>事务消息有三种状态：</p>\n<ul>\n<li>TransactionStatus.CommitTransaction：提交事务，表示允许使用者使用此消息。</li>\n<li>TransactionStatus.RollbackTransaction：回滚事务，表示该消息将被删除且不允许使用。</li>\n<li>TransactionStatus.Unknown：中间状态，表示需要MQ进行回溯以确定状态。</li>\n</ul>\n<h3 id=\"2，发送交易信息\"><a href=\"#2，发送交易信息\" class=\"headerlink\" title=\"2，发送交易信息\"></a>2，发送交易信息</h3><h4 id=\"2，1-创建事务生产方\"><a href=\"#2，1-创建事务生产方\" class=\"headerlink\" title=\"2，1 创建事务生产方\"></a>2，1 创建事务生产方</h4><p>使用<code>TransactionMQProducer</code>类创建生产方客户端，并指定唯一的<code>producerGroup</code>，然后可以设置自定义线程池来处理检查请求。执行本地事务后，需要根据执行结果对MQ进行回复，回复状态如上节所述。</p>\n<pre><code class=\"java\">import org.apache.rocketmq.client.consumer.DefaultMQPushConsumer;\nimport org.apache.rocketmq.client.consumer.listener.ConsumeConcurrentlyContext;\nimport org.apache.rocketmq.client.consumer.listener.ConsumeConcurrentlyStatus;\nimport org.apache.rocketmq.client.consumer.listener.MessageListenerConcurrently;\nimport org.apache.rocketmq.common.message.MessageExt;\nimport java.util.List;\n\npublic class TransactionProducer {\n    public static void main(String[] args) throws MQClientException, InterruptedException {\n        TransactionListener transactionListener = new TransactionListenerImpl();\n        TransactionMQProducer producer = new TransactionMQProducer(&quot;please_rename_unique_group_name&quot;);\n        ExecutorService executorService = new ThreadPoolExecutor(2, 5, 100, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;Runnable&gt;(2000), new ThreadFactory() {\n            @Override\n            public Thread newThread(Runnable r) {\n                Thread thread = new Thread(r);\n                thread.setName(&quot;client-transaction-msg-check-thread&quot;);\n                return thread;\n            }\n        });\n\n        producer.setExecutorService(executorService);\n        producer.setTransactionListener(transactionListener);\n        producer.start();\n\n        String[] tags = new String[] {&quot;TagA&quot;, &quot;TagB&quot;, &quot;TagC&quot;, &quot;TagD&quot;, &quot;TagE&quot;};\n        for (int i = 0; i &lt; 10; i++) {\n            try {\n                Message msg =\n                    new Message(&quot;TopicTest1234&quot;, tags[i % tags.length], &quot;KEY&quot; + i,\n                        (&quot;Hello RocketMQ &quot; + i).getBytes(RemotingHelper.DEFAULT_CHARSET));\n                SendResult sendResult = producer.sendMessageInTransaction(msg, null);\n                System.out.printf(&quot;%s%n&quot;, sendResult);\n\n                Thread.sleep(10);\n            } catch (MQClientException | UnsupportedEncodingException e) {\n                e.printStackTrace();\n            }\n        }\n\n        for (int i = 0; i &lt; 100000; i++) {\n            Thread.sleep(1000);\n        }\n        producer.shutdown();\n    }\n}</code></pre>\n<h4 id=\"2，2实现TransactionListener接口\"><a href=\"#2，2实现TransactionListener接口\" class=\"headerlink\" title=\"2，2实现TransactionListener接口\"></a>2，2实现TransactionListener接口</h4><p>当发送一半消息成功时，使用<code>executeLocalTransaction</code>方法执行本地事务。它返回上一部分中提到的三个事务状态之一。<br><code>checkLocalTransaction</code>方法用于检查本地事务状态并响应MQ检查请求。它还返回上一部分中提到的三个事务状态之一。</p>\n<pre><code class=\"java\">public class TransactionListenerImpl implements TransactionListener {\n   private AtomicInteger transactionIndex = new AtomicInteger(0);\n      private ConcurrentHashMap&lt;String, Integer&gt; localTrans = new ConcurrentHashMap&lt;&gt;();\n      @Override\n   public LocalTransactionState executeLocalTransaction(Message msg, Object arg) {\n       int value = transactionIndex.getAndIncrement();\n       int status = value % 3;\n       localTrans.put(msg.getTransactionId(), status);\n       return LocalTransactionState.UNKNOW;\n   }\n      @Override\n   public LocalTransactionState checkLocalTransaction(MessageExt msg) {\n       Integer status = localTrans.get(msg.getTransactionId());\n       if (null != status) {\n           switch (status) {\n               case 0:\n                   return LocalTransactionState.UNKNOW;\n               case 1:\n                   return LocalTransactionState.COMMIT_MESSAGE;\n               case 2:\n                   return LocalTransactionState.ROLLBACK_MESSAGE;\n           }\n       }\n       return LocalTransactionState.COMMIT_MESSAGE;\n   }</code></pre>\n"},{"title":"Java Monitor","excerpt":"","comments":1,"date":"2020-04-16T16:30:52.000Z","_content":"\n## 什么是Monitor\n\nMonitor可以理解为一种同步工具，也可理解为一种同步机制，常常被描述为一个Java对象，也叫**管程**。\n\n管程（Monitor）是一种和信号量（Sophomore）等价的同步机制。它在Java并发编程中也非常重要，虽然程序员没有直接接触管程，但它确实是synchronized和wait()/notify()等线程同步和线程间协作工具的基石：当我们在使用这些工具时，其实是它在背后提供了支持。简单来说：管程使用锁（lock）确保了在任何情况下管程中只有一个活跃的线程，即确保线程互斥访问临界区管程使用条件变量（Condition Variable）提供的等待队列（Waiting Set）实现线程间协作，当线程暂时不能获得所需资源时，进入队列等待，当线程可以获得所需资源时，从等待队列中唤醒。\n\n**总结：**\n\n- 互斥：一个Monitor在一个时刻只能被一个线程持有，即Monitor中的所有方法都是互斥的。\n\n- signal机制：如果条件变量不满足，允许一个正在持有Monitor的线程暂时释放持有权，当条件变量满足时，当前线程可以唤醒正在等待该条件变量的线程，然后重新获取Monitor的持有权。\n\n所有的Java对象是天生的Monitor，每一个Java对象都有成为Monitor的潜质，因为在Java的设计中 ，每一个Java对象自打娘胎里出来就带了一把看不见的锁，它叫做内部锁或者Monitor锁。\n\nMonitor的本质是依赖于底层操作系统的Mutex Lock实现，操作系统实现线程之间的切换需要从用户态到内核态的转换，成本非常高。\n\nMonitor 是线程私有的数据结构，每一个线程都有一个可用monitor record列表，同时还有一个全局的可用列表。每一个被锁住的对象都会和一个monitor关联（对象头的MarkWord中的LockWord指向monitor的起始地址），同时monitor中有一个Owner字段存放拥有该锁的线程的唯一标识，表示该锁被这个线程占用。其结构如下：\n\n<img src=\"1.png\">\n\n- Owner字段：初始时为NULL表示当前没有任何线程拥有该monitor record，当线程成功拥有该锁后保存线程唯一标识，当锁被释放时又设置为NULL\n- EntryQ字段：关联一个系统互斥锁（semaphore），阻塞所有试图锁住monitor record失败的线程\n- RcThis字段：表示blocked或waiting在该monitor record上的所有线程的个数\n- Nest字段：用来实现重入锁的计数\n- HashCode字段：保存从对象头拷贝过来的HashCode值（可能还包含GC age）\n- Candidate字段：用来避免不必要的阻塞或等待线程唤醒，因为每一次只有一个线程能够成功拥有锁，如果每次前一个释放锁的线程唤醒所有正在阻塞或等待的线程，会引起不必要的上下文切换（从阻塞到就绪然后因为竞争锁失败又被阻塞）从而导致性能严重下降；Candidate只有两种可能的值0表示没有需要唤醒的线程1表示要唤醒一个继任线程来竞争锁\n\n## Monitor具体实现方式\n\n1. Monitor是在jvm底层实现的，底层代码是c++\n2. Monitor的enter方法：获取锁\n3. Monitor的exit方法：释放锁\n4. Monitor的wait方法：为java的Object的wait方法提供支持\n5. Monitor的notify方法：为java的Object的notify方法提供支持\n6. Monitor的notifyAll方法：为java的Object的notifyAll方法提供支持\n\n## Monitor机制\n\n见下图：\n<img src=\"2.png\">\n\nMonitor可以类比为一个特殊的房间，这个房间中有一些被保护的数据，Monitor保证每次只能有一个线程能进入这个房间进行访问被保护的数据，进入房间即为持有Monitor，退出房间即为释放Monitor。\n\n当一个线程需要访问受保护的数据（即需要获取对象的Monitor）时，它会首先在entry-set入口队列中排队（这里并不是真正的按照排队顺序），如果没有其他线程正在持有对象的Monitor，那么它会和entry-set队列和wait-set队列中的被唤醒的其他线程进行竞争（即通过CPU调度），选出一个线程来获取对象的Monitor，执行受保护的代码段，执行完毕后释放Monitor，如果已经有线程持有对象的Monitor，那么需要等待其释放Monitor后再进行竞争。\n\n再说一下wait-set队列。当一个线程拥有Monitor后，经过某些条件的判断（比如用户取钱发现账户没钱），这个时候需要调用Object的wait方法，线程就释放了Monitor，进入wait-set队列，等待Object的notify方法（比如用户向账户里面存钱）。当该对象调用了notify方法或者notifyAll方法后，wait-set中的线程就会被唤醒，然后在wait-set队列中被唤醒的线程和entry-set队列中的线程一起通过CPU调度来竞争对象的Monitor，最终只有一个线程能获取对象的Monitor。\n\n**注意：**\n当一个线程在wait-set中被唤醒后，并不一定会立刻获取Monitor，它需要和其他线程去竞争\n如果一个线程是从wait-set队列中唤醒后，获取到的Monitor，它会去读取它自己保存的PC计数器中的地址，从它调用wait方法的地方开始执行。\n2.3、Monitor与java对象以及线程是如何关联 \n1.如果一个java对象被某个线程锁住，则该java对象的Mark Word字段中LockWord指向monitor的起始地址\n2.Monitor的Owner字段会存放拥有相关联对象锁的线程id","source":"_posts/2020-04-17-kongzheng1993-Java_Monitor.md","raw":"---\ntitle: Java Monitor\nexcerpt: ''\ntags: [Java]\ncategories: [Java]\ncomments: true\ndate: 2020-04-17 00:30:52\n---\n\n## 什么是Monitor\n\nMonitor可以理解为一种同步工具，也可理解为一种同步机制，常常被描述为一个Java对象，也叫**管程**。\n\n管程（Monitor）是一种和信号量（Sophomore）等价的同步机制。它在Java并发编程中也非常重要，虽然程序员没有直接接触管程，但它确实是synchronized和wait()/notify()等线程同步和线程间协作工具的基石：当我们在使用这些工具时，其实是它在背后提供了支持。简单来说：管程使用锁（lock）确保了在任何情况下管程中只有一个活跃的线程，即确保线程互斥访问临界区管程使用条件变量（Condition Variable）提供的等待队列（Waiting Set）实现线程间协作，当线程暂时不能获得所需资源时，进入队列等待，当线程可以获得所需资源时，从等待队列中唤醒。\n\n**总结：**\n\n- 互斥：一个Monitor在一个时刻只能被一个线程持有，即Monitor中的所有方法都是互斥的。\n\n- signal机制：如果条件变量不满足，允许一个正在持有Monitor的线程暂时释放持有权，当条件变量满足时，当前线程可以唤醒正在等待该条件变量的线程，然后重新获取Monitor的持有权。\n\n所有的Java对象是天生的Monitor，每一个Java对象都有成为Monitor的潜质，因为在Java的设计中 ，每一个Java对象自打娘胎里出来就带了一把看不见的锁，它叫做内部锁或者Monitor锁。\n\nMonitor的本质是依赖于底层操作系统的Mutex Lock实现，操作系统实现线程之间的切换需要从用户态到内核态的转换，成本非常高。\n\nMonitor 是线程私有的数据结构，每一个线程都有一个可用monitor record列表，同时还有一个全局的可用列表。每一个被锁住的对象都会和一个monitor关联（对象头的MarkWord中的LockWord指向monitor的起始地址），同时monitor中有一个Owner字段存放拥有该锁的线程的唯一标识，表示该锁被这个线程占用。其结构如下：\n\n<img src=\"1.png\">\n\n- Owner字段：初始时为NULL表示当前没有任何线程拥有该monitor record，当线程成功拥有该锁后保存线程唯一标识，当锁被释放时又设置为NULL\n- EntryQ字段：关联一个系统互斥锁（semaphore），阻塞所有试图锁住monitor record失败的线程\n- RcThis字段：表示blocked或waiting在该monitor record上的所有线程的个数\n- Nest字段：用来实现重入锁的计数\n- HashCode字段：保存从对象头拷贝过来的HashCode值（可能还包含GC age）\n- Candidate字段：用来避免不必要的阻塞或等待线程唤醒，因为每一次只有一个线程能够成功拥有锁，如果每次前一个释放锁的线程唤醒所有正在阻塞或等待的线程，会引起不必要的上下文切换（从阻塞到就绪然后因为竞争锁失败又被阻塞）从而导致性能严重下降；Candidate只有两种可能的值0表示没有需要唤醒的线程1表示要唤醒一个继任线程来竞争锁\n\n## Monitor具体实现方式\n\n1. Monitor是在jvm底层实现的，底层代码是c++\n2. Monitor的enter方法：获取锁\n3. Monitor的exit方法：释放锁\n4. Monitor的wait方法：为java的Object的wait方法提供支持\n5. Monitor的notify方法：为java的Object的notify方法提供支持\n6. Monitor的notifyAll方法：为java的Object的notifyAll方法提供支持\n\n## Monitor机制\n\n见下图：\n<img src=\"2.png\">\n\nMonitor可以类比为一个特殊的房间，这个房间中有一些被保护的数据，Monitor保证每次只能有一个线程能进入这个房间进行访问被保护的数据，进入房间即为持有Monitor，退出房间即为释放Monitor。\n\n当一个线程需要访问受保护的数据（即需要获取对象的Monitor）时，它会首先在entry-set入口队列中排队（这里并不是真正的按照排队顺序），如果没有其他线程正在持有对象的Monitor，那么它会和entry-set队列和wait-set队列中的被唤醒的其他线程进行竞争（即通过CPU调度），选出一个线程来获取对象的Monitor，执行受保护的代码段，执行完毕后释放Monitor，如果已经有线程持有对象的Monitor，那么需要等待其释放Monitor后再进行竞争。\n\n再说一下wait-set队列。当一个线程拥有Monitor后，经过某些条件的判断（比如用户取钱发现账户没钱），这个时候需要调用Object的wait方法，线程就释放了Monitor，进入wait-set队列，等待Object的notify方法（比如用户向账户里面存钱）。当该对象调用了notify方法或者notifyAll方法后，wait-set中的线程就会被唤醒，然后在wait-set队列中被唤醒的线程和entry-set队列中的线程一起通过CPU调度来竞争对象的Monitor，最终只有一个线程能获取对象的Monitor。\n\n**注意：**\n当一个线程在wait-set中被唤醒后，并不一定会立刻获取Monitor，它需要和其他线程去竞争\n如果一个线程是从wait-set队列中唤醒后，获取到的Monitor，它会去读取它自己保存的PC计数器中的地址，从它调用wait方法的地方开始执行。\n2.3、Monitor与java对象以及线程是如何关联 \n1.如果一个java对象被某个线程锁住，则该java对象的Mark Word字段中LockWord指向monitor的起始地址\n2.Monitor的Owner字段会存放拥有相关联对象锁的线程id","slug":"kongzheng1993-Java_Monitor","published":1,"updated":"2023-03-08T07:05:58.795Z","layout":"post","photos":[],"link":"","_id":"clg0k2agu0033t26fqpf54ccu","content":"<h2 id=\"什么是Monitor\"><a href=\"#什么是Monitor\" class=\"headerlink\" title=\"什么是Monitor\"></a>什么是Monitor</h2><p>Monitor可以理解为一种同步工具，也可理解为一种同步机制，常常被描述为一个Java对象，也叫<strong>管程</strong>。</p>\n<p>管程（Monitor）是一种和信号量（Sophomore）等价的同步机制。它在Java并发编程中也非常重要，虽然程序员没有直接接触管程，但它确实是synchronized和wait()/notify()等线程同步和线程间协作工具的基石：当我们在使用这些工具时，其实是它在背后提供了支持。简单来说：管程使用锁（lock）确保了在任何情况下管程中只有一个活跃的线程，即确保线程互斥访问临界区管程使用条件变量（Condition Variable）提供的等待队列（Waiting Set）实现线程间协作，当线程暂时不能获得所需资源时，进入队列等待，当线程可以获得所需资源时，从等待队列中唤醒。</p>\n<p><strong>总结：</strong></p>\n<ul>\n<li><p>互斥：一个Monitor在一个时刻只能被一个线程持有，即Monitor中的所有方法都是互斥的。</p>\n</li>\n<li><p>signal机制：如果条件变量不满足，允许一个正在持有Monitor的线程暂时释放持有权，当条件变量满足时，当前线程可以唤醒正在等待该条件变量的线程，然后重新获取Monitor的持有权。</p>\n</li>\n</ul>\n<p>所有的Java对象是天生的Monitor，每一个Java对象都有成为Monitor的潜质，因为在Java的设计中 ，每一个Java对象自打娘胎里出来就带了一把看不见的锁，它叫做内部锁或者Monitor锁。</p>\n<p>Monitor的本质是依赖于底层操作系统的Mutex Lock实现，操作系统实现线程之间的切换需要从用户态到内核态的转换，成本非常高。</p>\n<p>Monitor 是线程私有的数据结构，每一个线程都有一个可用monitor record列表，同时还有一个全局的可用列表。每一个被锁住的对象都会和一个monitor关联（对象头的MarkWord中的LockWord指向monitor的起始地址），同时monitor中有一个Owner字段存放拥有该锁的线程的唯一标识，表示该锁被这个线程占用。其结构如下：</p>\n<img src=\"/2020/04/17/kongzheng1993-Java_Monitor/1.png\">\n\n<ul>\n<li>Owner字段：初始时为NULL表示当前没有任何线程拥有该monitor record，当线程成功拥有该锁后保存线程唯一标识，当锁被释放时又设置为NULL</li>\n<li>EntryQ字段：关联一个系统互斥锁（semaphore），阻塞所有试图锁住monitor record失败的线程</li>\n<li>RcThis字段：表示blocked或waiting在该monitor record上的所有线程的个数</li>\n<li>Nest字段：用来实现重入锁的计数</li>\n<li>HashCode字段：保存从对象头拷贝过来的HashCode值（可能还包含GC age）</li>\n<li>Candidate字段：用来避免不必要的阻塞或等待线程唤醒，因为每一次只有一个线程能够成功拥有锁，如果每次前一个释放锁的线程唤醒所有正在阻塞或等待的线程，会引起不必要的上下文切换（从阻塞到就绪然后因为竞争锁失败又被阻塞）从而导致性能严重下降；Candidate只有两种可能的值0表示没有需要唤醒的线程1表示要唤醒一个继任线程来竞争锁</li>\n</ul>\n<h2 id=\"Monitor具体实现方式\"><a href=\"#Monitor具体实现方式\" class=\"headerlink\" title=\"Monitor具体实现方式\"></a>Monitor具体实现方式</h2><ol>\n<li>Monitor是在jvm底层实现的，底层代码是c++</li>\n<li>Monitor的enter方法：获取锁</li>\n<li>Monitor的exit方法：释放锁</li>\n<li>Monitor的wait方法：为java的Object的wait方法提供支持</li>\n<li>Monitor的notify方法：为java的Object的notify方法提供支持</li>\n<li>Monitor的notifyAll方法：为java的Object的notifyAll方法提供支持</li>\n</ol>\n<h2 id=\"Monitor机制\"><a href=\"#Monitor机制\" class=\"headerlink\" title=\"Monitor机制\"></a>Monitor机制</h2><p>见下图：<br><img src=\"/2020/04/17/kongzheng1993-Java_Monitor/2.png\"></p>\n<p>Monitor可以类比为一个特殊的房间，这个房间中有一些被保护的数据，Monitor保证每次只能有一个线程能进入这个房间进行访问被保护的数据，进入房间即为持有Monitor，退出房间即为释放Monitor。</p>\n<p>当一个线程需要访问受保护的数据（即需要获取对象的Monitor）时，它会首先在entry-set入口队列中排队（这里并不是真正的按照排队顺序），如果没有其他线程正在持有对象的Monitor，那么它会和entry-set队列和wait-set队列中的被唤醒的其他线程进行竞争（即通过CPU调度），选出一个线程来获取对象的Monitor，执行受保护的代码段，执行完毕后释放Monitor，如果已经有线程持有对象的Monitor，那么需要等待其释放Monitor后再进行竞争。</p>\n<p>再说一下wait-set队列。当一个线程拥有Monitor后，经过某些条件的判断（比如用户取钱发现账户没钱），这个时候需要调用Object的wait方法，线程就释放了Monitor，进入wait-set队列，等待Object的notify方法（比如用户向账户里面存钱）。当该对象调用了notify方法或者notifyAll方法后，wait-set中的线程就会被唤醒，然后在wait-set队列中被唤醒的线程和entry-set队列中的线程一起通过CPU调度来竞争对象的Monitor，最终只有一个线程能获取对象的Monitor。</p>\n<p><strong>注意：</strong><br>当一个线程在wait-set中被唤醒后，并不一定会立刻获取Monitor，它需要和其他线程去竞争<br>如果一个线程是从wait-set队列中唤醒后，获取到的Monitor，它会去读取它自己保存的PC计数器中的地址，从它调用wait方法的地方开始执行。<br>2.3、Monitor与java对象以及线程是如何关联<br>1.如果一个java对象被某个线程锁住，则该java对象的Mark Word字段中LockWord指向monitor的起始地址<br>2.Monitor的Owner字段会存放拥有相关联对象锁的线程id</p>\n","site":{"data":{}},"more":"<h2 id=\"什么是Monitor\"><a href=\"#什么是Monitor\" class=\"headerlink\" title=\"什么是Monitor\"></a>什么是Monitor</h2><p>Monitor可以理解为一种同步工具，也可理解为一种同步机制，常常被描述为一个Java对象，也叫<strong>管程</strong>。</p>\n<p>管程（Monitor）是一种和信号量（Sophomore）等价的同步机制。它在Java并发编程中也非常重要，虽然程序员没有直接接触管程，但它确实是synchronized和wait()/notify()等线程同步和线程间协作工具的基石：当我们在使用这些工具时，其实是它在背后提供了支持。简单来说：管程使用锁（lock）确保了在任何情况下管程中只有一个活跃的线程，即确保线程互斥访问临界区管程使用条件变量（Condition Variable）提供的等待队列（Waiting Set）实现线程间协作，当线程暂时不能获得所需资源时，进入队列等待，当线程可以获得所需资源时，从等待队列中唤醒。</p>\n<p><strong>总结：</strong></p>\n<ul>\n<li><p>互斥：一个Monitor在一个时刻只能被一个线程持有，即Monitor中的所有方法都是互斥的。</p>\n</li>\n<li><p>signal机制：如果条件变量不满足，允许一个正在持有Monitor的线程暂时释放持有权，当条件变量满足时，当前线程可以唤醒正在等待该条件变量的线程，然后重新获取Monitor的持有权。</p>\n</li>\n</ul>\n<p>所有的Java对象是天生的Monitor，每一个Java对象都有成为Monitor的潜质，因为在Java的设计中 ，每一个Java对象自打娘胎里出来就带了一把看不见的锁，它叫做内部锁或者Monitor锁。</p>\n<p>Monitor的本质是依赖于底层操作系统的Mutex Lock实现，操作系统实现线程之间的切换需要从用户态到内核态的转换，成本非常高。</p>\n<p>Monitor 是线程私有的数据结构，每一个线程都有一个可用monitor record列表，同时还有一个全局的可用列表。每一个被锁住的对象都会和一个monitor关联（对象头的MarkWord中的LockWord指向monitor的起始地址），同时monitor中有一个Owner字段存放拥有该锁的线程的唯一标识，表示该锁被这个线程占用。其结构如下：</p>\n<img src=\"/2020/04/17/kongzheng1993-Java_Monitor/1.png\">\n\n<ul>\n<li>Owner字段：初始时为NULL表示当前没有任何线程拥有该monitor record，当线程成功拥有该锁后保存线程唯一标识，当锁被释放时又设置为NULL</li>\n<li>EntryQ字段：关联一个系统互斥锁（semaphore），阻塞所有试图锁住monitor record失败的线程</li>\n<li>RcThis字段：表示blocked或waiting在该monitor record上的所有线程的个数</li>\n<li>Nest字段：用来实现重入锁的计数</li>\n<li>HashCode字段：保存从对象头拷贝过来的HashCode值（可能还包含GC age）</li>\n<li>Candidate字段：用来避免不必要的阻塞或等待线程唤醒，因为每一次只有一个线程能够成功拥有锁，如果每次前一个释放锁的线程唤醒所有正在阻塞或等待的线程，会引起不必要的上下文切换（从阻塞到就绪然后因为竞争锁失败又被阻塞）从而导致性能严重下降；Candidate只有两种可能的值0表示没有需要唤醒的线程1表示要唤醒一个继任线程来竞争锁</li>\n</ul>\n<h2 id=\"Monitor具体实现方式\"><a href=\"#Monitor具体实现方式\" class=\"headerlink\" title=\"Monitor具体实现方式\"></a>Monitor具体实现方式</h2><ol>\n<li>Monitor是在jvm底层实现的，底层代码是c++</li>\n<li>Monitor的enter方法：获取锁</li>\n<li>Monitor的exit方法：释放锁</li>\n<li>Monitor的wait方法：为java的Object的wait方法提供支持</li>\n<li>Monitor的notify方法：为java的Object的notify方法提供支持</li>\n<li>Monitor的notifyAll方法：为java的Object的notifyAll方法提供支持</li>\n</ol>\n<h2 id=\"Monitor机制\"><a href=\"#Monitor机制\" class=\"headerlink\" title=\"Monitor机制\"></a>Monitor机制</h2><p>见下图：<br><img src=\"/2020/04/17/kongzheng1993-Java_Monitor/2.png\"></p>\n<p>Monitor可以类比为一个特殊的房间，这个房间中有一些被保护的数据，Monitor保证每次只能有一个线程能进入这个房间进行访问被保护的数据，进入房间即为持有Monitor，退出房间即为释放Monitor。</p>\n<p>当一个线程需要访问受保护的数据（即需要获取对象的Monitor）时，它会首先在entry-set入口队列中排队（这里并不是真正的按照排队顺序），如果没有其他线程正在持有对象的Monitor，那么它会和entry-set队列和wait-set队列中的被唤醒的其他线程进行竞争（即通过CPU调度），选出一个线程来获取对象的Monitor，执行受保护的代码段，执行完毕后释放Monitor，如果已经有线程持有对象的Monitor，那么需要等待其释放Monitor后再进行竞争。</p>\n<p>再说一下wait-set队列。当一个线程拥有Monitor后，经过某些条件的判断（比如用户取钱发现账户没钱），这个时候需要调用Object的wait方法，线程就释放了Monitor，进入wait-set队列，等待Object的notify方法（比如用户向账户里面存钱）。当该对象调用了notify方法或者notifyAll方法后，wait-set中的线程就会被唤醒，然后在wait-set队列中被唤醒的线程和entry-set队列中的线程一起通过CPU调度来竞争对象的Monitor，最终只有一个线程能获取对象的Monitor。</p>\n<p><strong>注意：</strong><br>当一个线程在wait-set中被唤醒后，并不一定会立刻获取Monitor，它需要和其他线程去竞争<br>如果一个线程是从wait-set队列中唤醒后，获取到的Monitor，它会去读取它自己保存的PC计数器中的地址，从它调用wait方法的地方开始执行。<br>2.3、Monitor与java对象以及线程是如何关联<br>1.如果一个java对象被某个线程锁住，则该java对象的Mark Word字段中LockWord指向monitor的起始地址<br>2.Monitor的Owner字段会存放拥有相关联对象锁的线程id</p>\n"},{"title":"MySQL事务隔离级别","excerpt":"","comments":1,"date":"2020-04-16T16:30:52.000Z","_content":"\n\n## 什么是事务\n\n事务是应用程序中一系列操作，所有操作必须全部完成，若有一个操作失败，都会使所有的操作撤销。\n\n## ACID\n\n事务具有四个特性：**原子性（ Atomicity ）、一致性（ Consistency ）、隔离性（ Isolation ）和持续性（ Durability ）**。\n\n- 原子性。事务是数据库的逻辑工作单位，事务中包含的各操作要么都做，要么都不做。\n- 一致性。事务执行的结果必须是使数据库从一个一致性状态变到另一个一致性状态。因此当数据库只包含成功事务提交的结果时，就说数据库处于一致性状态。如果数据库系统运行中发生故障，有些事务尚未完成就被迫中断，这些未完成事务对数据库所做的修改有一部分已写入物理数据库，这时数据库就处于一种不正确的状态，或者说是**不一致的状态**。\n- 隔离性。一个事务的执行不能其它事务干扰。即一个事务内部的操作及使用的数据对其它并发事务是隔离的，并发执行的各个事务之间不能互相干扰。\n- 持续性。也称永久性，指一个事务一旦提交，它对数据库中的数据的改变就应该是永久性的。接下来的其它操作或故障不应该对其执行结果有任何影响。\n\n## MySQL的四种隔离级别\n\nSQL标准定义了四种隔离级别，低级别的隔离一般支持更高的并发处理，并拥有更低的系统开销。\n\n### Read Uncommitted （读取未提交内容）\n\n在这个隔离级别，所有事务都可以看到其他未提交事务的执行结果。本隔离级别很少用于实际应用，因为他的性能也不比其他隔离级别好多少。读取未提交的数据，也被称之为脏读（Dirty Read）。\n\n### Read Committed （读取提交内容）\n\n这个隔离级别是大多数数据库默认隔离级别（不是MySQL默认的）。它满足了隔离的简单定义：一个事务只能看见已经提交事务所做的改变。\n\n这种隔离级别也支持所谓的**不可重复读（Nonrepeatable Read）**，因为同一事务的其他实例在该实例处理期间可能会有新的commit，所以同一select可能返回不同结果。\n\n### Repeatable Read （可重读）\n\n这个是MySQL的默认事务隔离级别，它确保同一事务的多个实例在并发读取数据时，会看到同样的数据行，不过理论上，这会导致**幻读（Phantom Read）**\n\n幻读是指当用户读取某一范围的数据行时，另一个事务又在该范围内插入了新的数据行，当用户在读取该范围的数据行时，会发现有新的“幻影”行。InnoDB和Falcon存储引擎通过多版本并发控制（MVCC,Multiversion Concurrency Control）机制解决了该问题。\n\n### Serializable （可串行化）\n\n这是最高的隔离级别，它通过强制事务排序，使之不可能相互冲突，从而解决幻读问题。简言之，它是在每个读的数据行上加上共享锁。在这个级别，可能导致大量的超时现象和锁竞争。\n\n**备注：**\n\n这四种隔离级别采取不同的锁类型来实现，若读取的是同一个数据的话，就容易发生问题。例如：\n\n- 脏读指的是读到了其他事务未提交的数据，未提交意味着这些数据可能会回滚，也就是可能最终不会存到数据库中，也就是不存在的数据。读到了并一定最终存在的数据，这就是脏读。\n- 可重复读指的是在一个事务内，最开始读到的数据和事务结束前的任意时刻读到的同一批数据都是一致的。通常针对数据更新（UPDATE）操作。\n- 对比可重复读，不可重复读指的是在同一事务内，不同的时刻读到的同一批数据可能是不一样的，可能会受到其他事务的影响，比如其他事务改了这批数据并提交了。通常针对数据更新（UPDATE）操作。\n- 幻读是针对数据插入（INSERT）操作来说的。假设事务A对某些行的内容作了更改，但是还未提交，此时事务B插入了与事务A更改前的记录相同的记录行，并且在事务A提交之前先提交了，而这时，在事务A中查询，会发现好像刚刚的更改对于某些数据未起作用，但其实是事务B刚插入进来的，让用户感觉很魔幻，感觉出现了幻觉，这就叫幻读。\n\n**在MySQL中，四种隔离级别，分别有可能产生的问题：**\n\n隔离级别|脏读|不可重复读|幻读\n-|:-:|:-:|:-:\nRead uncommited|√|√|√\nRead commited|×|√|√\nRepeatable read|×|×|√\nSerializable|×|×|×\n","source":"_posts/2020-04-17-kongzheng1993-MySQL事务隔离级别.md","raw":"---\ntitle: MySQL事务隔离级别\nexcerpt: ''\ntags: [Mysql]\ncategories: [Mysql]\ncomments: true\ndate: 2020-04-17 00:30:52\n---\n\n\n## 什么是事务\n\n事务是应用程序中一系列操作，所有操作必须全部完成，若有一个操作失败，都会使所有的操作撤销。\n\n## ACID\n\n事务具有四个特性：**原子性（ Atomicity ）、一致性（ Consistency ）、隔离性（ Isolation ）和持续性（ Durability ）**。\n\n- 原子性。事务是数据库的逻辑工作单位，事务中包含的各操作要么都做，要么都不做。\n- 一致性。事务执行的结果必须是使数据库从一个一致性状态变到另一个一致性状态。因此当数据库只包含成功事务提交的结果时，就说数据库处于一致性状态。如果数据库系统运行中发生故障，有些事务尚未完成就被迫中断，这些未完成事务对数据库所做的修改有一部分已写入物理数据库，这时数据库就处于一种不正确的状态，或者说是**不一致的状态**。\n- 隔离性。一个事务的执行不能其它事务干扰。即一个事务内部的操作及使用的数据对其它并发事务是隔离的，并发执行的各个事务之间不能互相干扰。\n- 持续性。也称永久性，指一个事务一旦提交，它对数据库中的数据的改变就应该是永久性的。接下来的其它操作或故障不应该对其执行结果有任何影响。\n\n## MySQL的四种隔离级别\n\nSQL标准定义了四种隔离级别，低级别的隔离一般支持更高的并发处理，并拥有更低的系统开销。\n\n### Read Uncommitted （读取未提交内容）\n\n在这个隔离级别，所有事务都可以看到其他未提交事务的执行结果。本隔离级别很少用于实际应用，因为他的性能也不比其他隔离级别好多少。读取未提交的数据，也被称之为脏读（Dirty Read）。\n\n### Read Committed （读取提交内容）\n\n这个隔离级别是大多数数据库默认隔离级别（不是MySQL默认的）。它满足了隔离的简单定义：一个事务只能看见已经提交事务所做的改变。\n\n这种隔离级别也支持所谓的**不可重复读（Nonrepeatable Read）**，因为同一事务的其他实例在该实例处理期间可能会有新的commit，所以同一select可能返回不同结果。\n\n### Repeatable Read （可重读）\n\n这个是MySQL的默认事务隔离级别，它确保同一事务的多个实例在并发读取数据时，会看到同样的数据行，不过理论上，这会导致**幻读（Phantom Read）**\n\n幻读是指当用户读取某一范围的数据行时，另一个事务又在该范围内插入了新的数据行，当用户在读取该范围的数据行时，会发现有新的“幻影”行。InnoDB和Falcon存储引擎通过多版本并发控制（MVCC,Multiversion Concurrency Control）机制解决了该问题。\n\n### Serializable （可串行化）\n\n这是最高的隔离级别，它通过强制事务排序，使之不可能相互冲突，从而解决幻读问题。简言之，它是在每个读的数据行上加上共享锁。在这个级别，可能导致大量的超时现象和锁竞争。\n\n**备注：**\n\n这四种隔离级别采取不同的锁类型来实现，若读取的是同一个数据的话，就容易发生问题。例如：\n\n- 脏读指的是读到了其他事务未提交的数据，未提交意味着这些数据可能会回滚，也就是可能最终不会存到数据库中，也就是不存在的数据。读到了并一定最终存在的数据，这就是脏读。\n- 可重复读指的是在一个事务内，最开始读到的数据和事务结束前的任意时刻读到的同一批数据都是一致的。通常针对数据更新（UPDATE）操作。\n- 对比可重复读，不可重复读指的是在同一事务内，不同的时刻读到的同一批数据可能是不一样的，可能会受到其他事务的影响，比如其他事务改了这批数据并提交了。通常针对数据更新（UPDATE）操作。\n- 幻读是针对数据插入（INSERT）操作来说的。假设事务A对某些行的内容作了更改，但是还未提交，此时事务B插入了与事务A更改前的记录相同的记录行，并且在事务A提交之前先提交了，而这时，在事务A中查询，会发现好像刚刚的更改对于某些数据未起作用，但其实是事务B刚插入进来的，让用户感觉很魔幻，感觉出现了幻觉，这就叫幻读。\n\n**在MySQL中，四种隔离级别，分别有可能产生的问题：**\n\n隔离级别|脏读|不可重复读|幻读\n-|:-:|:-:|:-:\nRead uncommited|√|√|√\nRead commited|×|√|√\nRepeatable read|×|×|√\nSerializable|×|×|×\n","slug":"kongzheng1993-MySQL事务隔离级别","published":1,"updated":"2023-03-08T07:05:58.795Z","layout":"post","photos":[],"link":"","_id":"clg0k2ah90036t26fbe2neeb6","content":"<h2 id=\"什么是事务\"><a href=\"#什么是事务\" class=\"headerlink\" title=\"什么是事务\"></a>什么是事务</h2><p>事务是应用程序中一系列操作，所有操作必须全部完成，若有一个操作失败，都会使所有的操作撤销。</p>\n<h2 id=\"ACID\"><a href=\"#ACID\" class=\"headerlink\" title=\"ACID\"></a>ACID</h2><p>事务具有四个特性：<strong>原子性（ Atomicity ）、一致性（ Consistency ）、隔离性（ Isolation ）和持续性（ Durability ）</strong>。</p>\n<ul>\n<li>原子性。事务是数据库的逻辑工作单位，事务中包含的各操作要么都做，要么都不做。</li>\n<li>一致性。事务执行的结果必须是使数据库从一个一致性状态变到另一个一致性状态。因此当数据库只包含成功事务提交的结果时，就说数据库处于一致性状态。如果数据库系统运行中发生故障，有些事务尚未完成就被迫中断，这些未完成事务对数据库所做的修改有一部分已写入物理数据库，这时数据库就处于一种不正确的状态，或者说是<strong>不一致的状态</strong>。</li>\n<li>隔离性。一个事务的执行不能其它事务干扰。即一个事务内部的操作及使用的数据对其它并发事务是隔离的，并发执行的各个事务之间不能互相干扰。</li>\n<li>持续性。也称永久性，指一个事务一旦提交，它对数据库中的数据的改变就应该是永久性的。接下来的其它操作或故障不应该对其执行结果有任何影响。</li>\n</ul>\n<h2 id=\"MySQL的四种隔离级别\"><a href=\"#MySQL的四种隔离级别\" class=\"headerlink\" title=\"MySQL的四种隔离级别\"></a>MySQL的四种隔离级别</h2><p>SQL标准定义了四种隔离级别，低级别的隔离一般支持更高的并发处理，并拥有更低的系统开销。</p>\n<h3 id=\"Read-Uncommitted-（读取未提交内容）\"><a href=\"#Read-Uncommitted-（读取未提交内容）\" class=\"headerlink\" title=\"Read Uncommitted （读取未提交内容）\"></a>Read Uncommitted （读取未提交内容）</h3><p>在这个隔离级别，所有事务都可以看到其他未提交事务的执行结果。本隔离级别很少用于实际应用，因为他的性能也不比其他隔离级别好多少。读取未提交的数据，也被称之为脏读（Dirty Read）。</p>\n<h3 id=\"Read-Committed-（读取提交内容）\"><a href=\"#Read-Committed-（读取提交内容）\" class=\"headerlink\" title=\"Read Committed （读取提交内容）\"></a>Read Committed （读取提交内容）</h3><p>这个隔离级别是大多数数据库默认隔离级别（不是MySQL默认的）。它满足了隔离的简单定义：一个事务只能看见已经提交事务所做的改变。</p>\n<p>这种隔离级别也支持所谓的<strong>不可重复读（Nonrepeatable Read）</strong>，因为同一事务的其他实例在该实例处理期间可能会有新的commit，所以同一select可能返回不同结果。</p>\n<h3 id=\"Repeatable-Read-（可重读）\"><a href=\"#Repeatable-Read-（可重读）\" class=\"headerlink\" title=\"Repeatable Read （可重读）\"></a>Repeatable Read （可重读）</h3><p>这个是MySQL的默认事务隔离级别，它确保同一事务的多个实例在并发读取数据时，会看到同样的数据行，不过理论上，这会导致<strong>幻读（Phantom Read）</strong></p>\n<p>幻读是指当用户读取某一范围的数据行时，另一个事务又在该范围内插入了新的数据行，当用户在读取该范围的数据行时，会发现有新的“幻影”行。InnoDB和Falcon存储引擎通过多版本并发控制（MVCC,Multiversion Concurrency Control）机制解决了该问题。</p>\n<h3 id=\"Serializable-（可串行化）\"><a href=\"#Serializable-（可串行化）\" class=\"headerlink\" title=\"Serializable （可串行化）\"></a>Serializable （可串行化）</h3><p>这是最高的隔离级别，它通过强制事务排序，使之不可能相互冲突，从而解决幻读问题。简言之，它是在每个读的数据行上加上共享锁。在这个级别，可能导致大量的超时现象和锁竞争。</p>\n<p><strong>备注：</strong></p>\n<p>这四种隔离级别采取不同的锁类型来实现，若读取的是同一个数据的话，就容易发生问题。例如：</p>\n<ul>\n<li>脏读指的是读到了其他事务未提交的数据，未提交意味着这些数据可能会回滚，也就是可能最终不会存到数据库中，也就是不存在的数据。读到了并一定最终存在的数据，这就是脏读。</li>\n<li>可重复读指的是在一个事务内，最开始读到的数据和事务结束前的任意时刻读到的同一批数据都是一致的。通常针对数据更新（UPDATE）操作。</li>\n<li>对比可重复读，不可重复读指的是在同一事务内，不同的时刻读到的同一批数据可能是不一样的，可能会受到其他事务的影响，比如其他事务改了这批数据并提交了。通常针对数据更新（UPDATE）操作。</li>\n<li>幻读是针对数据插入（INSERT）操作来说的。假设事务A对某些行的内容作了更改，但是还未提交，此时事务B插入了与事务A更改前的记录相同的记录行，并且在事务A提交之前先提交了，而这时，在事务A中查询，会发现好像刚刚的更改对于某些数据未起作用，但其实是事务B刚插入进来的，让用户感觉很魔幻，感觉出现了幻觉，这就叫幻读。</li>\n</ul>\n<p><strong>在MySQL中，四种隔离级别，分别有可能产生的问题：</strong></p>\n<table>\n<thead>\n<tr>\n<th>隔离级别</th>\n<th align=\"center\">脏读</th>\n<th align=\"center\">不可重复读</th>\n<th align=\"center\">幻读</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Read uncommited</td>\n<td align=\"center\">√</td>\n<td align=\"center\">√</td>\n<td align=\"center\">√</td>\n</tr>\n<tr>\n<td>Read commited</td>\n<td align=\"center\">×</td>\n<td align=\"center\">√</td>\n<td align=\"center\">√</td>\n</tr>\n<tr>\n<td>Repeatable read</td>\n<td align=\"center\">×</td>\n<td align=\"center\">×</td>\n<td align=\"center\">√</td>\n</tr>\n<tr>\n<td>Serializable</td>\n<td align=\"center\">×</td>\n<td align=\"center\">×</td>\n<td align=\"center\">×</td>\n</tr>\n</tbody></table>\n","site":{"data":{}},"more":"<h2 id=\"什么是事务\"><a href=\"#什么是事务\" class=\"headerlink\" title=\"什么是事务\"></a>什么是事务</h2><p>事务是应用程序中一系列操作，所有操作必须全部完成，若有一个操作失败，都会使所有的操作撤销。</p>\n<h2 id=\"ACID\"><a href=\"#ACID\" class=\"headerlink\" title=\"ACID\"></a>ACID</h2><p>事务具有四个特性：<strong>原子性（ Atomicity ）、一致性（ Consistency ）、隔离性（ Isolation ）和持续性（ Durability ）</strong>。</p>\n<ul>\n<li>原子性。事务是数据库的逻辑工作单位，事务中包含的各操作要么都做，要么都不做。</li>\n<li>一致性。事务执行的结果必须是使数据库从一个一致性状态变到另一个一致性状态。因此当数据库只包含成功事务提交的结果时，就说数据库处于一致性状态。如果数据库系统运行中发生故障，有些事务尚未完成就被迫中断，这些未完成事务对数据库所做的修改有一部分已写入物理数据库，这时数据库就处于一种不正确的状态，或者说是<strong>不一致的状态</strong>。</li>\n<li>隔离性。一个事务的执行不能其它事务干扰。即一个事务内部的操作及使用的数据对其它并发事务是隔离的，并发执行的各个事务之间不能互相干扰。</li>\n<li>持续性。也称永久性，指一个事务一旦提交，它对数据库中的数据的改变就应该是永久性的。接下来的其它操作或故障不应该对其执行结果有任何影响。</li>\n</ul>\n<h2 id=\"MySQL的四种隔离级别\"><a href=\"#MySQL的四种隔离级别\" class=\"headerlink\" title=\"MySQL的四种隔离级别\"></a>MySQL的四种隔离级别</h2><p>SQL标准定义了四种隔离级别，低级别的隔离一般支持更高的并发处理，并拥有更低的系统开销。</p>\n<h3 id=\"Read-Uncommitted-（读取未提交内容）\"><a href=\"#Read-Uncommitted-（读取未提交内容）\" class=\"headerlink\" title=\"Read Uncommitted （读取未提交内容）\"></a>Read Uncommitted （读取未提交内容）</h3><p>在这个隔离级别，所有事务都可以看到其他未提交事务的执行结果。本隔离级别很少用于实际应用，因为他的性能也不比其他隔离级别好多少。读取未提交的数据，也被称之为脏读（Dirty Read）。</p>\n<h3 id=\"Read-Committed-（读取提交内容）\"><a href=\"#Read-Committed-（读取提交内容）\" class=\"headerlink\" title=\"Read Committed （读取提交内容）\"></a>Read Committed （读取提交内容）</h3><p>这个隔离级别是大多数数据库默认隔离级别（不是MySQL默认的）。它满足了隔离的简单定义：一个事务只能看见已经提交事务所做的改变。</p>\n<p>这种隔离级别也支持所谓的<strong>不可重复读（Nonrepeatable Read）</strong>，因为同一事务的其他实例在该实例处理期间可能会有新的commit，所以同一select可能返回不同结果。</p>\n<h3 id=\"Repeatable-Read-（可重读）\"><a href=\"#Repeatable-Read-（可重读）\" class=\"headerlink\" title=\"Repeatable Read （可重读）\"></a>Repeatable Read （可重读）</h3><p>这个是MySQL的默认事务隔离级别，它确保同一事务的多个实例在并发读取数据时，会看到同样的数据行，不过理论上，这会导致<strong>幻读（Phantom Read）</strong></p>\n<p>幻读是指当用户读取某一范围的数据行时，另一个事务又在该范围内插入了新的数据行，当用户在读取该范围的数据行时，会发现有新的“幻影”行。InnoDB和Falcon存储引擎通过多版本并发控制（MVCC,Multiversion Concurrency Control）机制解决了该问题。</p>\n<h3 id=\"Serializable-（可串行化）\"><a href=\"#Serializable-（可串行化）\" class=\"headerlink\" title=\"Serializable （可串行化）\"></a>Serializable （可串行化）</h3><p>这是最高的隔离级别，它通过强制事务排序，使之不可能相互冲突，从而解决幻读问题。简言之，它是在每个读的数据行上加上共享锁。在这个级别，可能导致大量的超时现象和锁竞争。</p>\n<p><strong>备注：</strong></p>\n<p>这四种隔离级别采取不同的锁类型来实现，若读取的是同一个数据的话，就容易发生问题。例如：</p>\n<ul>\n<li>脏读指的是读到了其他事务未提交的数据，未提交意味着这些数据可能会回滚，也就是可能最终不会存到数据库中，也就是不存在的数据。读到了并一定最终存在的数据，这就是脏读。</li>\n<li>可重复读指的是在一个事务内，最开始读到的数据和事务结束前的任意时刻读到的同一批数据都是一致的。通常针对数据更新（UPDATE）操作。</li>\n<li>对比可重复读，不可重复读指的是在同一事务内，不同的时刻读到的同一批数据可能是不一样的，可能会受到其他事务的影响，比如其他事务改了这批数据并提交了。通常针对数据更新（UPDATE）操作。</li>\n<li>幻读是针对数据插入（INSERT）操作来说的。假设事务A对某些行的内容作了更改，但是还未提交，此时事务B插入了与事务A更改前的记录相同的记录行，并且在事务A提交之前先提交了，而这时，在事务A中查询，会发现好像刚刚的更改对于某些数据未起作用，但其实是事务B刚插入进来的，让用户感觉很魔幻，感觉出现了幻觉，这就叫幻读。</li>\n</ul>\n<p><strong>在MySQL中，四种隔离级别，分别有可能产生的问题：</strong></p>\n<table>\n<thead>\n<tr>\n<th>隔离级别</th>\n<th align=\"center\">脏读</th>\n<th align=\"center\">不可重复读</th>\n<th align=\"center\">幻读</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Read uncommited</td>\n<td align=\"center\">√</td>\n<td align=\"center\">√</td>\n<td align=\"center\">√</td>\n</tr>\n<tr>\n<td>Read commited</td>\n<td align=\"center\">×</td>\n<td align=\"center\">√</td>\n<td align=\"center\">√</td>\n</tr>\n<tr>\n<td>Repeatable read</td>\n<td align=\"center\">×</td>\n<td align=\"center\">×</td>\n<td align=\"center\">√</td>\n</tr>\n<tr>\n<td>Serializable</td>\n<td align=\"center\">×</td>\n<td align=\"center\">×</td>\n<td align=\"center\">×</td>\n</tr>\n</tbody></table>\n"},{"title":"Java是值传递的！","excerpt":"","comments":1,"date":"2020-04-18T16:30:52.000Z","_content":"\n上周五边喝茶边吃瓜子在家办公，写一个接口，调用方请求过来之后，我需要在请求报文一个节点下加入两个字段，然后继续调用底层接口。随手就写下了下面的代码：\n\n```java\nMap params = inputObject.getParams();\nMap reqInfoMap = params.get(\"reqInfo\");\nreqInfoMap.put(\"xxx\", \"XXX\");\nreqInfoMap.put(\"yyy\", \"YYY\");\n\nservice.invoke(params);\n```\n\n我这里直接在请求实体对象中取出`params`，然后在`params`中取出`reqInfo`节点，接着在`reqInfo`节点下加入两个字段，紧接着就调用了底层服务，将`params`传出去了，后面测试我这也没有问题，两个字段都加上了。\n\n可是大学我们就知道Java是值传递的了，我这里从`params`里get出来的值应该是一个`对象副本`啊，不应该是那个真正的对象啊，我对`对象副本`做出的修改，不应该影响原来的对象啊。。。\n\n- **值传递（pass by value）** 是指在调用函数时将实际参数复制一份传递到函数中，这样在函数中如果对参数进行修改，将不会影响到实际参数。\n- **引用传递（pass by reference）** 是指在调用函数时将实际参数的地址直接传递到函数中，那么在函数中对参数所进行的修改，将影响到实际参数。\n\n\n这里一阵慌张，难道jvm自己优化了？查了很多资料也没发现jvm对这块有啥优化。\n\n我决定深挖一下Java参数传递的秘密。\n\n看了阿里大佬[Hollis](https://www.zhihu.com/people/hollis-11)在知乎的回答，一下子恍然大悟。\n\n**所以说，Java中其实还是值传递的，只不过对于对象参数，值的内容是对象的引用。**\n\n其实很多人的疑惑都是对象的传递问题，对象的传递给人的感觉就像是引用传递似的。\n\n下面两张图可以说明：\n\n<img src=\"2.png\">\n<br>\n<br>\n<img src=\"1.jpg\">\n\n如果上面没有new这个动作，也就是没有把user这个变量指向一个新的内存地址，那么函数内的操作都是针对原内存地址的。但是这里new了一下，user指向了一个新的内存地址，后面针对user的操作都是针对新的内存地址的，所以原来的对象就不会受到影响了。\n\n无论是值传递还是引用传递，其实都是一种求值策略(Evaluation strategy)。在求值策略中，还有一种叫做**按共享传递(call by sharing)**。**其实Java中的参数传递严格意义上说应该是按共享传递**。\n\n按共享传递，是指在调用函数时，传递给函数的是**实参的地址的拷贝（如果实参在栈中，则直接拷贝该值）**。在函数内部对参数进行操作时，需要先拷贝的地址寻找到具体的值，再进行操作。如果该值在栈中，那么因为是直接拷贝的值，所以函数内部对参数进行操作不会对外部变量产生影响。如果原来拷贝的是原值在堆中的地址，那么需要先根据该地址找到堆中对应的位置，再进行操作。因为传递的是地址的拷贝所以函数内对值的操作对外部变量是可见的。简单点说，Java中的传递，是值传递，而这个值，实际上是对象的引用。而按共享传递其实只是按值传递的一个特例罢了。所以我们可以说Java的传递是按共享传递，或者说Java中的传递是值传递。\n\n这里要注意String作为对象，传入方法后，在方法中执行类似`str = \"ttt\";`的代码，并不会改变实际参数的值，这是因为`str = \"ttt\";`其实执行了`str = new String(\"ttt\");`，是新创建了一个对象，而不是修改之前的对象，所以实际参数并没有被修改。","source":"_posts/2020-04-19-kongzheng1993-Java就是值传递的.md","raw":"---\ntitle: Java是值传递的！\nexcerpt: ''\ntags: [Java]\ncategories: [Java]\ncomments: true\ndate: 2020-04-19 00:30:52\n---\n\n上周五边喝茶边吃瓜子在家办公，写一个接口，调用方请求过来之后，我需要在请求报文一个节点下加入两个字段，然后继续调用底层接口。随手就写下了下面的代码：\n\n```java\nMap params = inputObject.getParams();\nMap reqInfoMap = params.get(\"reqInfo\");\nreqInfoMap.put(\"xxx\", \"XXX\");\nreqInfoMap.put(\"yyy\", \"YYY\");\n\nservice.invoke(params);\n```\n\n我这里直接在请求实体对象中取出`params`，然后在`params`中取出`reqInfo`节点，接着在`reqInfo`节点下加入两个字段，紧接着就调用了底层服务，将`params`传出去了，后面测试我这也没有问题，两个字段都加上了。\n\n可是大学我们就知道Java是值传递的了，我这里从`params`里get出来的值应该是一个`对象副本`啊，不应该是那个真正的对象啊，我对`对象副本`做出的修改，不应该影响原来的对象啊。。。\n\n- **值传递（pass by value）** 是指在调用函数时将实际参数复制一份传递到函数中，这样在函数中如果对参数进行修改，将不会影响到实际参数。\n- **引用传递（pass by reference）** 是指在调用函数时将实际参数的地址直接传递到函数中，那么在函数中对参数所进行的修改，将影响到实际参数。\n\n\n这里一阵慌张，难道jvm自己优化了？查了很多资料也没发现jvm对这块有啥优化。\n\n我决定深挖一下Java参数传递的秘密。\n\n看了阿里大佬[Hollis](https://www.zhihu.com/people/hollis-11)在知乎的回答，一下子恍然大悟。\n\n**所以说，Java中其实还是值传递的，只不过对于对象参数，值的内容是对象的引用。**\n\n其实很多人的疑惑都是对象的传递问题，对象的传递给人的感觉就像是引用传递似的。\n\n下面两张图可以说明：\n\n<img src=\"2.png\">\n<br>\n<br>\n<img src=\"1.jpg\">\n\n如果上面没有new这个动作，也就是没有把user这个变量指向一个新的内存地址，那么函数内的操作都是针对原内存地址的。但是这里new了一下，user指向了一个新的内存地址，后面针对user的操作都是针对新的内存地址的，所以原来的对象就不会受到影响了。\n\n无论是值传递还是引用传递，其实都是一种求值策略(Evaluation strategy)。在求值策略中，还有一种叫做**按共享传递(call by sharing)**。**其实Java中的参数传递严格意义上说应该是按共享传递**。\n\n按共享传递，是指在调用函数时，传递给函数的是**实参的地址的拷贝（如果实参在栈中，则直接拷贝该值）**。在函数内部对参数进行操作时，需要先拷贝的地址寻找到具体的值，再进行操作。如果该值在栈中，那么因为是直接拷贝的值，所以函数内部对参数进行操作不会对外部变量产生影响。如果原来拷贝的是原值在堆中的地址，那么需要先根据该地址找到堆中对应的位置，再进行操作。因为传递的是地址的拷贝所以函数内对值的操作对外部变量是可见的。简单点说，Java中的传递，是值传递，而这个值，实际上是对象的引用。而按共享传递其实只是按值传递的一个特例罢了。所以我们可以说Java的传递是按共享传递，或者说Java中的传递是值传递。\n\n这里要注意String作为对象，传入方法后，在方法中执行类似`str = \"ttt\";`的代码，并不会改变实际参数的值，这是因为`str = \"ttt\";`其实执行了`str = new String(\"ttt\");`，是新创建了一个对象，而不是修改之前的对象，所以实际参数并没有被修改。","slug":"kongzheng1993-Java就是值传递的","published":1,"updated":"2023-03-08T07:05:58.795Z","layout":"post","photos":[],"link":"","_id":"clg0k2ahn0039t26fdgst541q","content":"<p>上周五边喝茶边吃瓜子在家办公，写一个接口，调用方请求过来之后，我需要在请求报文一个节点下加入两个字段，然后继续调用底层接口。随手就写下了下面的代码：</p>\n<pre><code class=\"java\">Map params = inputObject.getParams();\nMap reqInfoMap = params.get(&quot;reqInfo&quot;);\nreqInfoMap.put(&quot;xxx&quot;, &quot;XXX&quot;);\nreqInfoMap.put(&quot;yyy&quot;, &quot;YYY&quot;);\n\nservice.invoke(params);</code></pre>\n<p>我这里直接在请求实体对象中取出<code>params</code>，然后在<code>params</code>中取出<code>reqInfo</code>节点，接着在<code>reqInfo</code>节点下加入两个字段，紧接着就调用了底层服务，将<code>params</code>传出去了，后面测试我这也没有问题，两个字段都加上了。</p>\n<p>可是大学我们就知道Java是值传递的了，我这里从<code>params</code>里get出来的值应该是一个<code>对象副本</code>啊，不应该是那个真正的对象啊，我对<code>对象副本</code>做出的修改，不应该影响原来的对象啊。。。</p>\n<ul>\n<li><strong>值传递（pass by value）</strong> 是指在调用函数时将实际参数复制一份传递到函数中，这样在函数中如果对参数进行修改，将不会影响到实际参数。</li>\n<li><strong>引用传递（pass by reference）</strong> 是指在调用函数时将实际参数的地址直接传递到函数中，那么在函数中对参数所进行的修改，将影响到实际参数。</li>\n</ul>\n<p>这里一阵慌张，难道jvm自己优化了？查了很多资料也没发现jvm对这块有啥优化。</p>\n<p>我决定深挖一下Java参数传递的秘密。</p>\n<p>看了阿里大佬<a href=\"https://www.zhihu.com/people/hollis-11\" target=\"_blank\" rel=\"noopener\">Hollis</a>在知乎的回答，一下子恍然大悟。</p>\n<p><strong>所以说，Java中其实还是值传递的，只不过对于对象参数，值的内容是对象的引用。</strong></p>\n<p>其实很多人的疑惑都是对象的传递问题，对象的传递给人的感觉就像是引用传递似的。</p>\n<p>下面两张图可以说明：</p>\n<img src=\"/2020/04/19/kongzheng1993-Java就是值传递的/2.png\">\n<br>\n<br>\n<img src=\"/2020/04/19/kongzheng1993-Java就是值传递的/1.jpg\">\n\n<p>如果上面没有new这个动作，也就是没有把user这个变量指向一个新的内存地址，那么函数内的操作都是针对原内存地址的。但是这里new了一下，user指向了一个新的内存地址，后面针对user的操作都是针对新的内存地址的，所以原来的对象就不会受到影响了。</p>\n<p>无论是值传递还是引用传递，其实都是一种求值策略(Evaluation strategy)。在求值策略中，还有一种叫做<strong>按共享传递(call by sharing)</strong>。<strong>其实Java中的参数传递严格意义上说应该是按共享传递</strong>。</p>\n<p>按共享传递，是指在调用函数时，传递给函数的是<strong>实参的地址的拷贝（如果实参在栈中，则直接拷贝该值）</strong>。在函数内部对参数进行操作时，需要先拷贝的地址寻找到具体的值，再进行操作。如果该值在栈中，那么因为是直接拷贝的值，所以函数内部对参数进行操作不会对外部变量产生影响。如果原来拷贝的是原值在堆中的地址，那么需要先根据该地址找到堆中对应的位置，再进行操作。因为传递的是地址的拷贝所以函数内对值的操作对外部变量是可见的。简单点说，Java中的传递，是值传递，而这个值，实际上是对象的引用。而按共享传递其实只是按值传递的一个特例罢了。所以我们可以说Java的传递是按共享传递，或者说Java中的传递是值传递。</p>\n<p>这里要注意String作为对象，传入方法后，在方法中执行类似<code>str = &quot;ttt&quot;;</code>的代码，并不会改变实际参数的值，这是因为<code>str = &quot;ttt&quot;;</code>其实执行了<code>str = new String(&quot;ttt&quot;);</code>，是新创建了一个对象，而不是修改之前的对象，所以实际参数并没有被修改。</p>\n","site":{"data":{}},"more":"<p>上周五边喝茶边吃瓜子在家办公，写一个接口，调用方请求过来之后，我需要在请求报文一个节点下加入两个字段，然后继续调用底层接口。随手就写下了下面的代码：</p>\n<pre><code class=\"java\">Map params = inputObject.getParams();\nMap reqInfoMap = params.get(&quot;reqInfo&quot;);\nreqInfoMap.put(&quot;xxx&quot;, &quot;XXX&quot;);\nreqInfoMap.put(&quot;yyy&quot;, &quot;YYY&quot;);\n\nservice.invoke(params);</code></pre>\n<p>我这里直接在请求实体对象中取出<code>params</code>，然后在<code>params</code>中取出<code>reqInfo</code>节点，接着在<code>reqInfo</code>节点下加入两个字段，紧接着就调用了底层服务，将<code>params</code>传出去了，后面测试我这也没有问题，两个字段都加上了。</p>\n<p>可是大学我们就知道Java是值传递的了，我这里从<code>params</code>里get出来的值应该是一个<code>对象副本</code>啊，不应该是那个真正的对象啊，我对<code>对象副本</code>做出的修改，不应该影响原来的对象啊。。。</p>\n<ul>\n<li><strong>值传递（pass by value）</strong> 是指在调用函数时将实际参数复制一份传递到函数中，这样在函数中如果对参数进行修改，将不会影响到实际参数。</li>\n<li><strong>引用传递（pass by reference）</strong> 是指在调用函数时将实际参数的地址直接传递到函数中，那么在函数中对参数所进行的修改，将影响到实际参数。</li>\n</ul>\n<p>这里一阵慌张，难道jvm自己优化了？查了很多资料也没发现jvm对这块有啥优化。</p>\n<p>我决定深挖一下Java参数传递的秘密。</p>\n<p>看了阿里大佬<a href=\"https://www.zhihu.com/people/hollis-11\" target=\"_blank\" rel=\"noopener\">Hollis</a>在知乎的回答，一下子恍然大悟。</p>\n<p><strong>所以说，Java中其实还是值传递的，只不过对于对象参数，值的内容是对象的引用。</strong></p>\n<p>其实很多人的疑惑都是对象的传递问题，对象的传递给人的感觉就像是引用传递似的。</p>\n<p>下面两张图可以说明：</p>\n<img src=\"/2020/04/19/kongzheng1993-Java就是值传递的/2.png\">\n<br>\n<br>\n<img src=\"/2020/04/19/kongzheng1993-Java就是值传递的/1.jpg\">\n\n<p>如果上面没有new这个动作，也就是没有把user这个变量指向一个新的内存地址，那么函数内的操作都是针对原内存地址的。但是这里new了一下，user指向了一个新的内存地址，后面针对user的操作都是针对新的内存地址的，所以原来的对象就不会受到影响了。</p>\n<p>无论是值传递还是引用传递，其实都是一种求值策略(Evaluation strategy)。在求值策略中，还有一种叫做<strong>按共享传递(call by sharing)</strong>。<strong>其实Java中的参数传递严格意义上说应该是按共享传递</strong>。</p>\n<p>按共享传递，是指在调用函数时，传递给函数的是<strong>实参的地址的拷贝（如果实参在栈中，则直接拷贝该值）</strong>。在函数内部对参数进行操作时，需要先拷贝的地址寻找到具体的值，再进行操作。如果该值在栈中，那么因为是直接拷贝的值，所以函数内部对参数进行操作不会对外部变量产生影响。如果原来拷贝的是原值在堆中的地址，那么需要先根据该地址找到堆中对应的位置，再进行操作。因为传递的是地址的拷贝所以函数内对值的操作对外部变量是可见的。简单点说，Java中的传递，是值传递，而这个值，实际上是对象的引用。而按共享传递其实只是按值传递的一个特例罢了。所以我们可以说Java的传递是按共享传递，或者说Java中的传递是值传递。</p>\n<p>这里要注意String作为对象，传入方法后，在方法中执行类似<code>str = &quot;ttt&quot;;</code>的代码，并不会改变实际参数的值，这是因为<code>str = &quot;ttt&quot;;</code>其实执行了<code>str = new String(&quot;ttt&quot;);</code>，是新创建了一个对象，而不是修改之前的对象，所以实际参数并没有被修改。</p>\n"},{"title":"synchronized锁升级","excerpt":"","comments":1,"date":"2020-04-20T16:30:52.000Z","_content":"\n[本文整理自知乎](https://zhuanlan.zhihu.com/p/115561832)\n\n## 可见性\n\n使用synchronized的代码块或方法中使用变量，会发生以下：\n\n1. 获取同步锁\n2. 清空自己的工作内存的变量副本\n3. 从主存获取最新的值，并加载到工作内存中\n4. 对变量进行操作。\n\n所以使用synchronized会从主存中取最新的值，从而保证可见性。\n\n## 原子性\n\n最常见的例子，启动多个线程将一个静态变量执行`++`操作，最终结果并不是所有线程`++`次数之和。\n\n使用synchronized会在操作前monitorenter和操作后monitorexit，保证synchronized中的代码是原子的。\n\n## 有序性\n\n代码中程序执行的顺序，Java在编译和运行时会对代码进行优化，这样会导致我们最终的执行顺序并不是我们编写代码的书写顺序。\n\n咱先来看一个概念,重排序，也就是语句的执行顺序会被重新安排。其主要分为三种：\n\n1. 编译器优化的重排序：可以重新安排语句的执行顺序。\n2. 指令级并行的重排序：现代处理器采用指令级并行技术，将多条指令重叠执行。\n3. 内存系统的重排序：由于处理器使用缓存和读写缓冲区，所以看上去可能是乱序的。\n\n`A a = new A();`可能被被JVM分解成如下代码：\n\n```java\n// 可以分解为以下三个步骤\n1 memory=allocate();// 分配内存 相当于c的malloc\n2 ctorInstanc(memory) //初始化对象\n3 s=memory //设置s指向刚分配的地址\n// 上述三个步骤可能会被重排序为 1-3-2，也就是：\n1 memory=allocate();// 分配内存 相当于c的malloc\n3 s=memory //设置s指向刚分配的地址\n2 ctorInstanc(memory) //初始化对象  \n```\n\n一旦假设发生了这样的重排序，比如线程A在执行了步骤1和步骤3，但是步骤2还没有执行完。这个时候线程B进入了第一个语句，它会判断a不为空，即直接返回了a。其实这是一个未初始化完成的a，即会出现问题。\n\n**synchronized如何解决有序性问题**\n给上面的三个步骤加上一个synchronized关键字，即使发生重排序也不会出现问题。线程A在执行步骤1和步骤3时，线程B因为没法获取到锁，所以也不能进入第一个语句。只有线程A都执行完，释放锁，线程B才能重新获取锁，再执行相关操作。\n\n## synchronized的常见使用方式\n\n- 修饰代码块（同步代码块）\n\n```java\nsynchronized (object) {\n      //具体代码\n}\n```\n\n- 修饰方法\n\n```java\nsynchronized void test(){\n  //具体代码\n}\n```\n\n- 修饰静态方法\n\n```java\nsynchronized static void test(){\n   //具体代码\n}\n```\n\n- 修饰类\n\n```java\nsynchronized (Example2.class) {\n    //具体代码\n }\n```\n\n## synchronized继承\n\n假设父类test方法是synchronized修饰的。\n\n- 如果子类继承父类，没有重写test方法，那么子类test方法也是同步的。\n- 如果子类继承父类，重写了test方法，但是没有使用synchronized修饰，那么子类test不是同步的。\n- 如果子类继承父类，重写了test方法，并且用synchronized修饰，是同步。\n\n## 锁升级\n\n<img src=\"v2-8f405804cd55a26b34d59fefc002dc08_r.jpg\">\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/2020-04-21-kongzheng1993-synchronized锁升级.md","raw":"---\ntitle: synchronized锁升级\nexcerpt: ''\ntags: [Java]\ncategories: [Java]\ncomments: true\ndate: 2020-04-21 00:30:52\n---\n\n[本文整理自知乎](https://zhuanlan.zhihu.com/p/115561832)\n\n## 可见性\n\n使用synchronized的代码块或方法中使用变量，会发生以下：\n\n1. 获取同步锁\n2. 清空自己的工作内存的变量副本\n3. 从主存获取最新的值，并加载到工作内存中\n4. 对变量进行操作。\n\n所以使用synchronized会从主存中取最新的值，从而保证可见性。\n\n## 原子性\n\n最常见的例子，启动多个线程将一个静态变量执行`++`操作，最终结果并不是所有线程`++`次数之和。\n\n使用synchronized会在操作前monitorenter和操作后monitorexit，保证synchronized中的代码是原子的。\n\n## 有序性\n\n代码中程序执行的顺序，Java在编译和运行时会对代码进行优化，这样会导致我们最终的执行顺序并不是我们编写代码的书写顺序。\n\n咱先来看一个概念,重排序，也就是语句的执行顺序会被重新安排。其主要分为三种：\n\n1. 编译器优化的重排序：可以重新安排语句的执行顺序。\n2. 指令级并行的重排序：现代处理器采用指令级并行技术，将多条指令重叠执行。\n3. 内存系统的重排序：由于处理器使用缓存和读写缓冲区，所以看上去可能是乱序的。\n\n`A a = new A();`可能被被JVM分解成如下代码：\n\n```java\n// 可以分解为以下三个步骤\n1 memory=allocate();// 分配内存 相当于c的malloc\n2 ctorInstanc(memory) //初始化对象\n3 s=memory //设置s指向刚分配的地址\n// 上述三个步骤可能会被重排序为 1-3-2，也就是：\n1 memory=allocate();// 分配内存 相当于c的malloc\n3 s=memory //设置s指向刚分配的地址\n2 ctorInstanc(memory) //初始化对象  \n```\n\n一旦假设发生了这样的重排序，比如线程A在执行了步骤1和步骤3，但是步骤2还没有执行完。这个时候线程B进入了第一个语句，它会判断a不为空，即直接返回了a。其实这是一个未初始化完成的a，即会出现问题。\n\n**synchronized如何解决有序性问题**\n给上面的三个步骤加上一个synchronized关键字，即使发生重排序也不会出现问题。线程A在执行步骤1和步骤3时，线程B因为没法获取到锁，所以也不能进入第一个语句。只有线程A都执行完，释放锁，线程B才能重新获取锁，再执行相关操作。\n\n## synchronized的常见使用方式\n\n- 修饰代码块（同步代码块）\n\n```java\nsynchronized (object) {\n      //具体代码\n}\n```\n\n- 修饰方法\n\n```java\nsynchronized void test(){\n  //具体代码\n}\n```\n\n- 修饰静态方法\n\n```java\nsynchronized static void test(){\n   //具体代码\n}\n```\n\n- 修饰类\n\n```java\nsynchronized (Example2.class) {\n    //具体代码\n }\n```\n\n## synchronized继承\n\n假设父类test方法是synchronized修饰的。\n\n- 如果子类继承父类，没有重写test方法，那么子类test方法也是同步的。\n- 如果子类继承父类，重写了test方法，但是没有使用synchronized修饰，那么子类test不是同步的。\n- 如果子类继承父类，重写了test方法，并且用synchronized修饰，是同步。\n\n## 锁升级\n\n<img src=\"v2-8f405804cd55a26b34d59fefc002dc08_r.jpg\">\n\n\n\n\n\n\n\n\n\n\n","slug":"kongzheng1993-synchronized锁升级","published":1,"updated":"2023-03-08T07:05:58.796Z","layout":"post","photos":[],"link":"","_id":"clg0k2ai1003dt26ft523oo54","content":"<p><a href=\"https://zhuanlan.zhihu.com/p/115561832\" target=\"_blank\" rel=\"noopener\">本文整理自知乎</a></p>\n<h2 id=\"可见性\"><a href=\"#可见性\" class=\"headerlink\" title=\"可见性\"></a>可见性</h2><p>使用synchronized的代码块或方法中使用变量，会发生以下：</p>\n<ol>\n<li>获取同步锁</li>\n<li>清空自己的工作内存的变量副本</li>\n<li>从主存获取最新的值，并加载到工作内存中</li>\n<li>对变量进行操作。</li>\n</ol>\n<p>所以使用synchronized会从主存中取最新的值，从而保证可见性。</p>\n<h2 id=\"原子性\"><a href=\"#原子性\" class=\"headerlink\" title=\"原子性\"></a>原子性</h2><p>最常见的例子，启动多个线程将一个静态变量执行<code>++</code>操作，最终结果并不是所有线程<code>++</code>次数之和。</p>\n<p>使用synchronized会在操作前monitorenter和操作后monitorexit，保证synchronized中的代码是原子的。</p>\n<h2 id=\"有序性\"><a href=\"#有序性\" class=\"headerlink\" title=\"有序性\"></a>有序性</h2><p>代码中程序执行的顺序，Java在编译和运行时会对代码进行优化，这样会导致我们最终的执行顺序并不是我们编写代码的书写顺序。</p>\n<p>咱先来看一个概念,重排序，也就是语句的执行顺序会被重新安排。其主要分为三种：</p>\n<ol>\n<li>编译器优化的重排序：可以重新安排语句的执行顺序。</li>\n<li>指令级并行的重排序：现代处理器采用指令级并行技术，将多条指令重叠执行。</li>\n<li>内存系统的重排序：由于处理器使用缓存和读写缓冲区，所以看上去可能是乱序的。</li>\n</ol>\n<p><code>A a = new A();</code>可能被被JVM分解成如下代码：</p>\n<pre><code class=\"java\">// 可以分解为以下三个步骤\n1 memory=allocate();// 分配内存 相当于c的malloc\n2 ctorInstanc(memory) //初始化对象\n3 s=memory //设置s指向刚分配的地址\n// 上述三个步骤可能会被重排序为 1-3-2，也就是：\n1 memory=allocate();// 分配内存 相当于c的malloc\n3 s=memory //设置s指向刚分配的地址\n2 ctorInstanc(memory) //初始化对象  </code></pre>\n<p>一旦假设发生了这样的重排序，比如线程A在执行了步骤1和步骤3，但是步骤2还没有执行完。这个时候线程B进入了第一个语句，它会判断a不为空，即直接返回了a。其实这是一个未初始化完成的a，即会出现问题。</p>\n<p><strong>synchronized如何解决有序性问题</strong><br>给上面的三个步骤加上一个synchronized关键字，即使发生重排序也不会出现问题。线程A在执行步骤1和步骤3时，线程B因为没法获取到锁，所以也不能进入第一个语句。只有线程A都执行完，释放锁，线程B才能重新获取锁，再执行相关操作。</p>\n<h2 id=\"synchronized的常见使用方式\"><a href=\"#synchronized的常见使用方式\" class=\"headerlink\" title=\"synchronized的常见使用方式\"></a>synchronized的常见使用方式</h2><ul>\n<li>修饰代码块（同步代码块）</li>\n</ul>\n<pre><code class=\"java\">synchronized (object) {\n      //具体代码\n}</code></pre>\n<ul>\n<li>修饰方法</li>\n</ul>\n<pre><code class=\"java\">synchronized void test(){\n  //具体代码\n}</code></pre>\n<ul>\n<li>修饰静态方法</li>\n</ul>\n<pre><code class=\"java\">synchronized static void test(){\n   //具体代码\n}</code></pre>\n<ul>\n<li>修饰类</li>\n</ul>\n<pre><code class=\"java\">synchronized (Example2.class) {\n    //具体代码\n }</code></pre>\n<h2 id=\"synchronized继承\"><a href=\"#synchronized继承\" class=\"headerlink\" title=\"synchronized继承\"></a>synchronized继承</h2><p>假设父类test方法是synchronized修饰的。</p>\n<ul>\n<li>如果子类继承父类，没有重写test方法，那么子类test方法也是同步的。</li>\n<li>如果子类继承父类，重写了test方法，但是没有使用synchronized修饰，那么子类test不是同步的。</li>\n<li>如果子类继承父类，重写了test方法，并且用synchronized修饰，是同步。</li>\n</ul>\n<h2 id=\"锁升级\"><a href=\"#锁升级\" class=\"headerlink\" title=\"锁升级\"></a>锁升级</h2><img src=\"/2020/04/21/kongzheng1993-synchronized锁升级/v2-8f405804cd55a26b34d59fefc002dc08_r.jpg\">\n\n\n\n\n\n\n\n\n\n\n","site":{"data":{}},"more":"<p><a href=\"https://zhuanlan.zhihu.com/p/115561832\" target=\"_blank\" rel=\"noopener\">本文整理自知乎</a></p>\n<h2 id=\"可见性\"><a href=\"#可见性\" class=\"headerlink\" title=\"可见性\"></a>可见性</h2><p>使用synchronized的代码块或方法中使用变量，会发生以下：</p>\n<ol>\n<li>获取同步锁</li>\n<li>清空自己的工作内存的变量副本</li>\n<li>从主存获取最新的值，并加载到工作内存中</li>\n<li>对变量进行操作。</li>\n</ol>\n<p>所以使用synchronized会从主存中取最新的值，从而保证可见性。</p>\n<h2 id=\"原子性\"><a href=\"#原子性\" class=\"headerlink\" title=\"原子性\"></a>原子性</h2><p>最常见的例子，启动多个线程将一个静态变量执行<code>++</code>操作，最终结果并不是所有线程<code>++</code>次数之和。</p>\n<p>使用synchronized会在操作前monitorenter和操作后monitorexit，保证synchronized中的代码是原子的。</p>\n<h2 id=\"有序性\"><a href=\"#有序性\" class=\"headerlink\" title=\"有序性\"></a>有序性</h2><p>代码中程序执行的顺序，Java在编译和运行时会对代码进行优化，这样会导致我们最终的执行顺序并不是我们编写代码的书写顺序。</p>\n<p>咱先来看一个概念,重排序，也就是语句的执行顺序会被重新安排。其主要分为三种：</p>\n<ol>\n<li>编译器优化的重排序：可以重新安排语句的执行顺序。</li>\n<li>指令级并行的重排序：现代处理器采用指令级并行技术，将多条指令重叠执行。</li>\n<li>内存系统的重排序：由于处理器使用缓存和读写缓冲区，所以看上去可能是乱序的。</li>\n</ol>\n<p><code>A a = new A();</code>可能被被JVM分解成如下代码：</p>\n<pre><code class=\"java\">// 可以分解为以下三个步骤\n1 memory=allocate();// 分配内存 相当于c的malloc\n2 ctorInstanc(memory) //初始化对象\n3 s=memory //设置s指向刚分配的地址\n// 上述三个步骤可能会被重排序为 1-3-2，也就是：\n1 memory=allocate();// 分配内存 相当于c的malloc\n3 s=memory //设置s指向刚分配的地址\n2 ctorInstanc(memory) //初始化对象  </code></pre>\n<p>一旦假设发生了这样的重排序，比如线程A在执行了步骤1和步骤3，但是步骤2还没有执行完。这个时候线程B进入了第一个语句，它会判断a不为空，即直接返回了a。其实这是一个未初始化完成的a，即会出现问题。</p>\n<p><strong>synchronized如何解决有序性问题</strong><br>给上面的三个步骤加上一个synchronized关键字，即使发生重排序也不会出现问题。线程A在执行步骤1和步骤3时，线程B因为没法获取到锁，所以也不能进入第一个语句。只有线程A都执行完，释放锁，线程B才能重新获取锁，再执行相关操作。</p>\n<h2 id=\"synchronized的常见使用方式\"><a href=\"#synchronized的常见使用方式\" class=\"headerlink\" title=\"synchronized的常见使用方式\"></a>synchronized的常见使用方式</h2><ul>\n<li>修饰代码块（同步代码块）</li>\n</ul>\n<pre><code class=\"java\">synchronized (object) {\n      //具体代码\n}</code></pre>\n<ul>\n<li>修饰方法</li>\n</ul>\n<pre><code class=\"java\">synchronized void test(){\n  //具体代码\n}</code></pre>\n<ul>\n<li>修饰静态方法</li>\n</ul>\n<pre><code class=\"java\">synchronized static void test(){\n   //具体代码\n}</code></pre>\n<ul>\n<li>修饰类</li>\n</ul>\n<pre><code class=\"java\">synchronized (Example2.class) {\n    //具体代码\n }</code></pre>\n<h2 id=\"synchronized继承\"><a href=\"#synchronized继承\" class=\"headerlink\" title=\"synchronized继承\"></a>synchronized继承</h2><p>假设父类test方法是synchronized修饰的。</p>\n<ul>\n<li>如果子类继承父类，没有重写test方法，那么子类test方法也是同步的。</li>\n<li>如果子类继承父类，重写了test方法，但是没有使用synchronized修饰，那么子类test不是同步的。</li>\n<li>如果子类继承父类，重写了test方法，并且用synchronized修饰，是同步。</li>\n</ul>\n<h2 id=\"锁升级\"><a href=\"#锁升级\" class=\"headerlink\" title=\"锁升级\"></a>锁升级</h2><img src=\"/2020/04/21/kongzheng1993-synchronized锁升级/v2-8f405804cd55a26b34d59fefc002dc08_r.jpg\">\n\n\n\n\n\n\n\n\n\n\n"},{"title":"SQL优化整理","excerpt":"","comments":1,"date":"2020-04-21T16:30:52.000Z","_content":"\n[本文整理自CSDN](https://blog.csdn.net/jie_liang/article/details/77340905)\n\n\n1. 对查询进行优化，应尽量避免全表扫描，首先应考虑在 `where` 及 `order by` 涉及的列上建立索引。\n\n2. 应尽量避免在 `where` 子句中使用`!=`或`<>`操作符，否则将引擎放弃使用索引而进行全表扫描。\n\n3. 应尽量避免在 `where` 子句中对字段进行 `null` 值判断，否则将导致引擎放弃使用索引而进行全表扫描，如：\n\n```sql\nselect id from t where num is null\n#可以在num上设置默认值0，确保表中num列没有null值，然后这样查询：\nselect id from t where num=0\n```\n\n4. 应尽量避免在 `where` 子句中使用 `or` 来连接条件，否则将导致引擎放弃使用索引而进行全表扫描，如：\n\n```sql\nselect id from t where num=10 or num=20\n#可以这样查询：\nselect id from t where num=10\nunion all\nselect id from t where num=20\n```\n\n5. 下面的查询也将导致全表扫描：\n\n```sql\nselect id from t where name like '%abc%'\n#若要提高效率，可以考虑全文检索。\n```\n\n6. `in` 和 `not in` 也要慎用，否则会导致全表扫描，如：\n\n```sql\nselect id from t where num in(1,2,3)\n#对于连续的数值，能用 between 就不要用 in 了：\nselect id from t where num between 1 and 3\n```\n\n7. 如果在 `where` 子句中使用参数，也会导致全表扫描。因为SQL只有在运行时才会解析局部变量，但优化程序不能将访问计划的选择推迟到运行时；它必须在编译时进行选择。然而，如果在编译时建立访问计划，变量的值还是未知的，因而无法作为索引选择的输入项。如下面语句将进行全表扫描：\n\n```sql\nselect id from t where num=@num\n#可以改为强制查询使用索引：\nselect id from t with(index(索引名)) where num=@num\n```\n\n8. 应尽量避免在 `where` 子句中对字段进行表达式操作，这将导致引擎放弃使用索引而进行全表扫描。如：\n\n```sql\nselect id from t where num/2=100\n#应改为:\nselect id from t where num=100*2\n```\n\n9. 应尽量避免在 `where` 子句中对字段进行函数操作，这将导致引擎放弃使用索引而进行全表扫描。如：\n\n```sql\nselect id from t where substring(name,1,3)='abc'\n--name以abc开头的id\nselect id from t where datediff(day,createdate,'2005-11-30')=0\n--'2005-11-30'生成的id\n#应改为:\nselect id from t where name like 'abc%'\nselect id from t where createdate>='2005-11-30' and createdate<'2005-12-1'\n```\n\n10. 不要在 `where` 子句中的“=”左边进行函数、算术运算或其他表达式运算，否则系统将不能正确使用索引。\n\n11. 在使用索引字段作为条件时，如果该索引是复合索引，那么必须使用到该索引中的第一个字段作为条件时才能保证系统使用该索引，否则该索引将不会被使用，并且应尽可能的让字段顺序与索引顺序相一致。(**最左原则**)\n\n12. 不要写一些没有意义的查询，如需要生成一个空表结构：\n\n```sql\nselect col1,col2 into #t from t where 1=0\n#这类代码不会返回任何结果集，但是会消耗系统资源的，应改成这样：\ncreate table #t(...)\n```\n\n13. 很多时候用 `exists` 代替 `in` 是一个好的选择：\n\n```sql\nselect num from a where num in(select num from b)\n#用下面的语句替换：\nselect num from a where exists(select 1 from b where num=a.num)\n```\n\n14. 并不是所有索引对查询都有效，SQL是根据表中数据来进行查询优化的，当索引列有大量数据重复时，SQL查询可能不会去利用索引，如一表中有字段sex，male、female几乎各一半，那么即使在sex上建了索引也对查询效率起不了作用。\n\n15. 索引并不是越多越好，索引固然可以提高相应的 `select` 的效率，但同时也降低了 `insert` 及 `update` 的效率，因为 `insert` 或 `update` 时有可能会重建索引，所以怎样建索引需要慎重考虑，视具体情况而定。一个表的索引数最好不要超过`6`个，若太多则应考虑一些不常使用到的列上建的索引是否有必要。\n\n16. 应尽可能的避免更新 `clustered索引` 数据列，因为 `clustered索引` 数据列的顺序就是表记录的物理存储顺序，一旦该列值改变将导致整个表记录的顺序的调整，会耗费相当大的资源。若应用系统需要频繁更新 `clustered索引` 数据列，那么需要考虑是否应将该索引建为 `clustered索引`（聚合索引）。\n\n17. 尽量使用`数字型`字段，若只含数值信息的字段尽量不要设计为字符型，这会 **降低查询和连接的性能，并会增加存储开销** 。这是因为**引擎在处理查询和连接时会逐个比较字符串中每一个字符，而对于数字型而言只需要比较一次就够了**。\n\n18. 尽可能的使用 `varchar/nvarchar` 代替 `char/nchar` ，因为首先`变长字段`存储空间小，可以节省存储空间，其次对于查询来说，在一个相对较小的字段内搜索效率显然要高些。\n\n19. 任何地方都不要使用 `select * from t` ，用具体的`字段列`表代替“*”，不要返回用不到的任何字段。\n\n20. 尽量使用表变量来代替临时表。如果表变量包含大量数据，请注意索引非常有限（只有主键索引）。\n\n21. 避免频繁创建和删除临时表，以减少系统表资源的消耗。\n\n22. 临时表并不是不可使用，适当地使用它们可以使某些例程更有效，例如，当需要重复引用大型表或常用表中的某个数据集时。但是，对于一次性事件，最好使用导出表。\n\n23. 在新建临时表时，如果一次性插入数据量很大，那么可以使用 `select into` 代替 `create table`，避免造成大量 `log` ，以提高速度；如果数据量不大，为了缓和系统表的资源，应先`create table`，然后`insert`。\n\n24. 如果使用到了临时表，在存储过程的最后务必将所有的临时表显式删除，先 `truncate table` ，然后 `drop table` ，这样可以避免系统表的较长时间锁定。（先truncate可以释放表空间）。\n\n25. 尽量避免使用游标，因为游标的效率较差，如果游标操作的数据超过1万行，那么就应该考虑改写。\n\n26. 使用基于游标的方法或临时表方法之前，应先寻找基于集的解决方案来解决问题，基于集的方法通常更有效。\n\n27. 与临时表一样，游标并不是不可使用。对小型数据集使用 `FAST_FORWARD` 游标通常要优于其他逐行处理方法，尤其是在必须引用几个表才能获得所需的数据时。在结果集中包括“合计”的例程通常要比使用游标执行的速度快。如果开发时间允许，基于游标的方法和基于集的方法都可以尝试一下，看哪一种方法的效果更好。\n\n28. 在所有的存储过程和触发器的开始处设置 `SET NOCOUNT ON` ，在结束时设置 `SET NOCOUNT OFF` 。无需在执行存储过程和触发器的每个语句后向客户端发送 `DONE_IN_PROC` 消息。\n\n29. 尽量避免向客户端返回大数据量，若数据量过大，应该考虑相应需求是否合理。\n\n30. 尽量避免大事务操作，提高系统并发能力。\n\n\n\n\n\n\n\n\n\n","source":"_posts/2020-04-22-kongzheng1993-SQL优化.md","raw":"---\ntitle: SQL优化整理\nexcerpt: ''\ntags: [SQL]\ncategories: [SQL]\ncomments: true\ndate: 2020-04-22 00:30:52\n---\n\n[本文整理自CSDN](https://blog.csdn.net/jie_liang/article/details/77340905)\n\n\n1. 对查询进行优化，应尽量避免全表扫描，首先应考虑在 `where` 及 `order by` 涉及的列上建立索引。\n\n2. 应尽量避免在 `where` 子句中使用`!=`或`<>`操作符，否则将引擎放弃使用索引而进行全表扫描。\n\n3. 应尽量避免在 `where` 子句中对字段进行 `null` 值判断，否则将导致引擎放弃使用索引而进行全表扫描，如：\n\n```sql\nselect id from t where num is null\n#可以在num上设置默认值0，确保表中num列没有null值，然后这样查询：\nselect id from t where num=0\n```\n\n4. 应尽量避免在 `where` 子句中使用 `or` 来连接条件，否则将导致引擎放弃使用索引而进行全表扫描，如：\n\n```sql\nselect id from t where num=10 or num=20\n#可以这样查询：\nselect id from t where num=10\nunion all\nselect id from t where num=20\n```\n\n5. 下面的查询也将导致全表扫描：\n\n```sql\nselect id from t where name like '%abc%'\n#若要提高效率，可以考虑全文检索。\n```\n\n6. `in` 和 `not in` 也要慎用，否则会导致全表扫描，如：\n\n```sql\nselect id from t where num in(1,2,3)\n#对于连续的数值，能用 between 就不要用 in 了：\nselect id from t where num between 1 and 3\n```\n\n7. 如果在 `where` 子句中使用参数，也会导致全表扫描。因为SQL只有在运行时才会解析局部变量，但优化程序不能将访问计划的选择推迟到运行时；它必须在编译时进行选择。然而，如果在编译时建立访问计划，变量的值还是未知的，因而无法作为索引选择的输入项。如下面语句将进行全表扫描：\n\n```sql\nselect id from t where num=@num\n#可以改为强制查询使用索引：\nselect id from t with(index(索引名)) where num=@num\n```\n\n8. 应尽量避免在 `where` 子句中对字段进行表达式操作，这将导致引擎放弃使用索引而进行全表扫描。如：\n\n```sql\nselect id from t where num/2=100\n#应改为:\nselect id from t where num=100*2\n```\n\n9. 应尽量避免在 `where` 子句中对字段进行函数操作，这将导致引擎放弃使用索引而进行全表扫描。如：\n\n```sql\nselect id from t where substring(name,1,3)='abc'\n--name以abc开头的id\nselect id from t where datediff(day,createdate,'2005-11-30')=0\n--'2005-11-30'生成的id\n#应改为:\nselect id from t where name like 'abc%'\nselect id from t where createdate>='2005-11-30' and createdate<'2005-12-1'\n```\n\n10. 不要在 `where` 子句中的“=”左边进行函数、算术运算或其他表达式运算，否则系统将不能正确使用索引。\n\n11. 在使用索引字段作为条件时，如果该索引是复合索引，那么必须使用到该索引中的第一个字段作为条件时才能保证系统使用该索引，否则该索引将不会被使用，并且应尽可能的让字段顺序与索引顺序相一致。(**最左原则**)\n\n12. 不要写一些没有意义的查询，如需要生成一个空表结构：\n\n```sql\nselect col1,col2 into #t from t where 1=0\n#这类代码不会返回任何结果集，但是会消耗系统资源的，应改成这样：\ncreate table #t(...)\n```\n\n13. 很多时候用 `exists` 代替 `in` 是一个好的选择：\n\n```sql\nselect num from a where num in(select num from b)\n#用下面的语句替换：\nselect num from a where exists(select 1 from b where num=a.num)\n```\n\n14. 并不是所有索引对查询都有效，SQL是根据表中数据来进行查询优化的，当索引列有大量数据重复时，SQL查询可能不会去利用索引，如一表中有字段sex，male、female几乎各一半，那么即使在sex上建了索引也对查询效率起不了作用。\n\n15. 索引并不是越多越好，索引固然可以提高相应的 `select` 的效率，但同时也降低了 `insert` 及 `update` 的效率，因为 `insert` 或 `update` 时有可能会重建索引，所以怎样建索引需要慎重考虑，视具体情况而定。一个表的索引数最好不要超过`6`个，若太多则应考虑一些不常使用到的列上建的索引是否有必要。\n\n16. 应尽可能的避免更新 `clustered索引` 数据列，因为 `clustered索引` 数据列的顺序就是表记录的物理存储顺序，一旦该列值改变将导致整个表记录的顺序的调整，会耗费相当大的资源。若应用系统需要频繁更新 `clustered索引` 数据列，那么需要考虑是否应将该索引建为 `clustered索引`（聚合索引）。\n\n17. 尽量使用`数字型`字段，若只含数值信息的字段尽量不要设计为字符型，这会 **降低查询和连接的性能，并会增加存储开销** 。这是因为**引擎在处理查询和连接时会逐个比较字符串中每一个字符，而对于数字型而言只需要比较一次就够了**。\n\n18. 尽可能的使用 `varchar/nvarchar` 代替 `char/nchar` ，因为首先`变长字段`存储空间小，可以节省存储空间，其次对于查询来说，在一个相对较小的字段内搜索效率显然要高些。\n\n19. 任何地方都不要使用 `select * from t` ，用具体的`字段列`表代替“*”，不要返回用不到的任何字段。\n\n20. 尽量使用表变量来代替临时表。如果表变量包含大量数据，请注意索引非常有限（只有主键索引）。\n\n21. 避免频繁创建和删除临时表，以减少系统表资源的消耗。\n\n22. 临时表并不是不可使用，适当地使用它们可以使某些例程更有效，例如，当需要重复引用大型表或常用表中的某个数据集时。但是，对于一次性事件，最好使用导出表。\n\n23. 在新建临时表时，如果一次性插入数据量很大，那么可以使用 `select into` 代替 `create table`，避免造成大量 `log` ，以提高速度；如果数据量不大，为了缓和系统表的资源，应先`create table`，然后`insert`。\n\n24. 如果使用到了临时表，在存储过程的最后务必将所有的临时表显式删除，先 `truncate table` ，然后 `drop table` ，这样可以避免系统表的较长时间锁定。（先truncate可以释放表空间）。\n\n25. 尽量避免使用游标，因为游标的效率较差，如果游标操作的数据超过1万行，那么就应该考虑改写。\n\n26. 使用基于游标的方法或临时表方法之前，应先寻找基于集的解决方案来解决问题，基于集的方法通常更有效。\n\n27. 与临时表一样，游标并不是不可使用。对小型数据集使用 `FAST_FORWARD` 游标通常要优于其他逐行处理方法，尤其是在必须引用几个表才能获得所需的数据时。在结果集中包括“合计”的例程通常要比使用游标执行的速度快。如果开发时间允许，基于游标的方法和基于集的方法都可以尝试一下，看哪一种方法的效果更好。\n\n28. 在所有的存储过程和触发器的开始处设置 `SET NOCOUNT ON` ，在结束时设置 `SET NOCOUNT OFF` 。无需在执行存储过程和触发器的每个语句后向客户端发送 `DONE_IN_PROC` 消息。\n\n29. 尽量避免向客户端返回大数据量，若数据量过大，应该考虑相应需求是否合理。\n\n30. 尽量避免大事务操作，提高系统并发能力。\n\n\n\n\n\n\n\n\n\n","slug":"kongzheng1993-SQL优化","published":1,"updated":"2023-03-08T07:05:58.797Z","layout":"post","photos":[],"link":"","_id":"clg0k2ain003ft26ftr9z1yku","content":"<p><a href=\"https://blog.csdn.net/jie_liang/article/details/77340905\" target=\"_blank\" rel=\"noopener\">本文整理自CSDN</a></p>\n<ol>\n<li><p>对查询进行优化，应尽量避免全表扫描，首先应考虑在 <code>where</code> 及 <code>order by</code> 涉及的列上建立索引。</p>\n</li>\n<li><p>应尽量避免在 <code>where</code> 子句中使用<code>!=</code>或<code>&lt;&gt;</code>操作符，否则将引擎放弃使用索引而进行全表扫描。</p>\n</li>\n<li><p>应尽量避免在 <code>where</code> 子句中对字段进行 <code>null</code> 值判断，否则将导致引擎放弃使用索引而进行全表扫描，如：</p>\n</li>\n</ol>\n<pre><code class=\"sql\">select id from t where num is null\n#可以在num上设置默认值0，确保表中num列没有null值，然后这样查询：\nselect id from t where num=0</code></pre>\n<ol start=\"4\">\n<li>应尽量避免在 <code>where</code> 子句中使用 <code>or</code> 来连接条件，否则将导致引擎放弃使用索引而进行全表扫描，如：</li>\n</ol>\n<pre><code class=\"sql\">select id from t where num=10 or num=20\n#可以这样查询：\nselect id from t where num=10\nunion all\nselect id from t where num=20</code></pre>\n<ol start=\"5\">\n<li>下面的查询也将导致全表扫描：</li>\n</ol>\n<pre><code class=\"sql\">select id from t where name like &#39;%abc%&#39;\n#若要提高效率，可以考虑全文检索。</code></pre>\n<ol start=\"6\">\n<li><code>in</code> 和 <code>not in</code> 也要慎用，否则会导致全表扫描，如：</li>\n</ol>\n<pre><code class=\"sql\">select id from t where num in(1,2,3)\n#对于连续的数值，能用 between 就不要用 in 了：\nselect id from t where num between 1 and 3</code></pre>\n<ol start=\"7\">\n<li>如果在 <code>where</code> 子句中使用参数，也会导致全表扫描。因为SQL只有在运行时才会解析局部变量，但优化程序不能将访问计划的选择推迟到运行时；它必须在编译时进行选择。然而，如果在编译时建立访问计划，变量的值还是未知的，因而无法作为索引选择的输入项。如下面语句将进行全表扫描：</li>\n</ol>\n<pre><code class=\"sql\">select id from t where num=@num\n#可以改为强制查询使用索引：\nselect id from t with(index(索引名)) where num=@num</code></pre>\n<ol start=\"8\">\n<li>应尽量避免在 <code>where</code> 子句中对字段进行表达式操作，这将导致引擎放弃使用索引而进行全表扫描。如：</li>\n</ol>\n<pre><code class=\"sql\">select id from t where num/2=100\n#应改为:\nselect id from t where num=100*2</code></pre>\n<ol start=\"9\">\n<li>应尽量避免在 <code>where</code> 子句中对字段进行函数操作，这将导致引擎放弃使用索引而进行全表扫描。如：</li>\n</ol>\n<pre><code class=\"sql\">select id from t where substring(name,1,3)=&#39;abc&#39;\n--name以abc开头的id\nselect id from t where datediff(day,createdate,&#39;2005-11-30&#39;)=0\n--&#39;2005-11-30&#39;生成的id\n#应改为:\nselect id from t where name like &#39;abc%&#39;\nselect id from t where createdate&gt;=&#39;2005-11-30&#39; and createdate&lt;&#39;2005-12-1&#39;</code></pre>\n<ol start=\"10\">\n<li><p>不要在 <code>where</code> 子句中的“=”左边进行函数、算术运算或其他表达式运算，否则系统将不能正确使用索引。</p>\n</li>\n<li><p>在使用索引字段作为条件时，如果该索引是复合索引，那么必须使用到该索引中的第一个字段作为条件时才能保证系统使用该索引，否则该索引将不会被使用，并且应尽可能的让字段顺序与索引顺序相一致。(<strong>最左原则</strong>)</p>\n</li>\n<li><p>不要写一些没有意义的查询，如需要生成一个空表结构：</p>\n</li>\n</ol>\n<pre><code class=\"sql\">select col1,col2 into #t from t where 1=0\n#这类代码不会返回任何结果集，但是会消耗系统资源的，应改成这样：\ncreate table #t(...)</code></pre>\n<ol start=\"13\">\n<li>很多时候用 <code>exists</code> 代替 <code>in</code> 是一个好的选择：</li>\n</ol>\n<pre><code class=\"sql\">select num from a where num in(select num from b)\n#用下面的语句替换：\nselect num from a where exists(select 1 from b where num=a.num)</code></pre>\n<ol start=\"14\">\n<li><p>并不是所有索引对查询都有效，SQL是根据表中数据来进行查询优化的，当索引列有大量数据重复时，SQL查询可能不会去利用索引，如一表中有字段sex，male、female几乎各一半，那么即使在sex上建了索引也对查询效率起不了作用。</p>\n</li>\n<li><p>索引并不是越多越好，索引固然可以提高相应的 <code>select</code> 的效率，但同时也降低了 <code>insert</code> 及 <code>update</code> 的效率，因为 <code>insert</code> 或 <code>update</code> 时有可能会重建索引，所以怎样建索引需要慎重考虑，视具体情况而定。一个表的索引数最好不要超过<code>6</code>个，若太多则应考虑一些不常使用到的列上建的索引是否有必要。</p>\n</li>\n<li><p>应尽可能的避免更新 <code>clustered索引</code> 数据列，因为 <code>clustered索引</code> 数据列的顺序就是表记录的物理存储顺序，一旦该列值改变将导致整个表记录的顺序的调整，会耗费相当大的资源。若应用系统需要频繁更新 <code>clustered索引</code> 数据列，那么需要考虑是否应将该索引建为 <code>clustered索引</code>（聚合索引）。</p>\n</li>\n<li><p>尽量使用<code>数字型</code>字段，若只含数值信息的字段尽量不要设计为字符型，这会 <strong>降低查询和连接的性能，并会增加存储开销</strong> 。这是因为<strong>引擎在处理查询和连接时会逐个比较字符串中每一个字符，而对于数字型而言只需要比较一次就够了</strong>。</p>\n</li>\n<li><p>尽可能的使用 <code>varchar/nvarchar</code> 代替 <code>char/nchar</code> ，因为首先<code>变长字段</code>存储空间小，可以节省存储空间，其次对于查询来说，在一个相对较小的字段内搜索效率显然要高些。</p>\n</li>\n<li><p>任何地方都不要使用 <code>select * from t</code> ，用具体的<code>字段列</code>表代替“*”，不要返回用不到的任何字段。</p>\n</li>\n<li><p>尽量使用表变量来代替临时表。如果表变量包含大量数据，请注意索引非常有限（只有主键索引）。</p>\n</li>\n<li><p>避免频繁创建和删除临时表，以减少系统表资源的消耗。</p>\n</li>\n<li><p>临时表并不是不可使用，适当地使用它们可以使某些例程更有效，例如，当需要重复引用大型表或常用表中的某个数据集时。但是，对于一次性事件，最好使用导出表。</p>\n</li>\n<li><p>在新建临时表时，如果一次性插入数据量很大，那么可以使用 <code>select into</code> 代替 <code>create table</code>，避免造成大量 <code>log</code> ，以提高速度；如果数据量不大，为了缓和系统表的资源，应先<code>create table</code>，然后<code>insert</code>。</p>\n</li>\n<li><p>如果使用到了临时表，在存储过程的最后务必将所有的临时表显式删除，先 <code>truncate table</code> ，然后 <code>drop table</code> ，这样可以避免系统表的较长时间锁定。（先truncate可以释放表空间）。</p>\n</li>\n<li><p>尽量避免使用游标，因为游标的效率较差，如果游标操作的数据超过1万行，那么就应该考虑改写。</p>\n</li>\n<li><p>使用基于游标的方法或临时表方法之前，应先寻找基于集的解决方案来解决问题，基于集的方法通常更有效。</p>\n</li>\n<li><p>与临时表一样，游标并不是不可使用。对小型数据集使用 <code>FAST_FORWARD</code> 游标通常要优于其他逐行处理方法，尤其是在必须引用几个表才能获得所需的数据时。在结果集中包括“合计”的例程通常要比使用游标执行的速度快。如果开发时间允许，基于游标的方法和基于集的方法都可以尝试一下，看哪一种方法的效果更好。</p>\n</li>\n<li><p>在所有的存储过程和触发器的开始处设置 <code>SET NOCOUNT ON</code> ，在结束时设置 <code>SET NOCOUNT OFF</code> 。无需在执行存储过程和触发器的每个语句后向客户端发送 <code>DONE_IN_PROC</code> 消息。</p>\n</li>\n<li><p>尽量避免向客户端返回大数据量，若数据量过大，应该考虑相应需求是否合理。</p>\n</li>\n<li><p>尽量避免大事务操作，提高系统并发能力。</p>\n</li>\n</ol>\n","site":{"data":{}},"more":"<p><a href=\"https://blog.csdn.net/jie_liang/article/details/77340905\" target=\"_blank\" rel=\"noopener\">本文整理自CSDN</a></p>\n<ol>\n<li><p>对查询进行优化，应尽量避免全表扫描，首先应考虑在 <code>where</code> 及 <code>order by</code> 涉及的列上建立索引。</p>\n</li>\n<li><p>应尽量避免在 <code>where</code> 子句中使用<code>!=</code>或<code>&lt;&gt;</code>操作符，否则将引擎放弃使用索引而进行全表扫描。</p>\n</li>\n<li><p>应尽量避免在 <code>where</code> 子句中对字段进行 <code>null</code> 值判断，否则将导致引擎放弃使用索引而进行全表扫描，如：</p>\n</li>\n</ol>\n<pre><code class=\"sql\">select id from t where num is null\n#可以在num上设置默认值0，确保表中num列没有null值，然后这样查询：\nselect id from t where num=0</code></pre>\n<ol start=\"4\">\n<li>应尽量避免在 <code>where</code> 子句中使用 <code>or</code> 来连接条件，否则将导致引擎放弃使用索引而进行全表扫描，如：</li>\n</ol>\n<pre><code class=\"sql\">select id from t where num=10 or num=20\n#可以这样查询：\nselect id from t where num=10\nunion all\nselect id from t where num=20</code></pre>\n<ol start=\"5\">\n<li>下面的查询也将导致全表扫描：</li>\n</ol>\n<pre><code class=\"sql\">select id from t where name like &#39;%abc%&#39;\n#若要提高效率，可以考虑全文检索。</code></pre>\n<ol start=\"6\">\n<li><code>in</code> 和 <code>not in</code> 也要慎用，否则会导致全表扫描，如：</li>\n</ol>\n<pre><code class=\"sql\">select id from t where num in(1,2,3)\n#对于连续的数值，能用 between 就不要用 in 了：\nselect id from t where num between 1 and 3</code></pre>\n<ol start=\"7\">\n<li>如果在 <code>where</code> 子句中使用参数，也会导致全表扫描。因为SQL只有在运行时才会解析局部变量，但优化程序不能将访问计划的选择推迟到运行时；它必须在编译时进行选择。然而，如果在编译时建立访问计划，变量的值还是未知的，因而无法作为索引选择的输入项。如下面语句将进行全表扫描：</li>\n</ol>\n<pre><code class=\"sql\">select id from t where num=@num\n#可以改为强制查询使用索引：\nselect id from t with(index(索引名)) where num=@num</code></pre>\n<ol start=\"8\">\n<li>应尽量避免在 <code>where</code> 子句中对字段进行表达式操作，这将导致引擎放弃使用索引而进行全表扫描。如：</li>\n</ol>\n<pre><code class=\"sql\">select id from t where num/2=100\n#应改为:\nselect id from t where num=100*2</code></pre>\n<ol start=\"9\">\n<li>应尽量避免在 <code>where</code> 子句中对字段进行函数操作，这将导致引擎放弃使用索引而进行全表扫描。如：</li>\n</ol>\n<pre><code class=\"sql\">select id from t where substring(name,1,3)=&#39;abc&#39;\n--name以abc开头的id\nselect id from t where datediff(day,createdate,&#39;2005-11-30&#39;)=0\n--&#39;2005-11-30&#39;生成的id\n#应改为:\nselect id from t where name like &#39;abc%&#39;\nselect id from t where createdate&gt;=&#39;2005-11-30&#39; and createdate&lt;&#39;2005-12-1&#39;</code></pre>\n<ol start=\"10\">\n<li><p>不要在 <code>where</code> 子句中的“=”左边进行函数、算术运算或其他表达式运算，否则系统将不能正确使用索引。</p>\n</li>\n<li><p>在使用索引字段作为条件时，如果该索引是复合索引，那么必须使用到该索引中的第一个字段作为条件时才能保证系统使用该索引，否则该索引将不会被使用，并且应尽可能的让字段顺序与索引顺序相一致。(<strong>最左原则</strong>)</p>\n</li>\n<li><p>不要写一些没有意义的查询，如需要生成一个空表结构：</p>\n</li>\n</ol>\n<pre><code class=\"sql\">select col1,col2 into #t from t where 1=0\n#这类代码不会返回任何结果集，但是会消耗系统资源的，应改成这样：\ncreate table #t(...)</code></pre>\n<ol start=\"13\">\n<li>很多时候用 <code>exists</code> 代替 <code>in</code> 是一个好的选择：</li>\n</ol>\n<pre><code class=\"sql\">select num from a where num in(select num from b)\n#用下面的语句替换：\nselect num from a where exists(select 1 from b where num=a.num)</code></pre>\n<ol start=\"14\">\n<li><p>并不是所有索引对查询都有效，SQL是根据表中数据来进行查询优化的，当索引列有大量数据重复时，SQL查询可能不会去利用索引，如一表中有字段sex，male、female几乎各一半，那么即使在sex上建了索引也对查询效率起不了作用。</p>\n</li>\n<li><p>索引并不是越多越好，索引固然可以提高相应的 <code>select</code> 的效率，但同时也降低了 <code>insert</code> 及 <code>update</code> 的效率，因为 <code>insert</code> 或 <code>update</code> 时有可能会重建索引，所以怎样建索引需要慎重考虑，视具体情况而定。一个表的索引数最好不要超过<code>6</code>个，若太多则应考虑一些不常使用到的列上建的索引是否有必要。</p>\n</li>\n<li><p>应尽可能的避免更新 <code>clustered索引</code> 数据列，因为 <code>clustered索引</code> 数据列的顺序就是表记录的物理存储顺序，一旦该列值改变将导致整个表记录的顺序的调整，会耗费相当大的资源。若应用系统需要频繁更新 <code>clustered索引</code> 数据列，那么需要考虑是否应将该索引建为 <code>clustered索引</code>（聚合索引）。</p>\n</li>\n<li><p>尽量使用<code>数字型</code>字段，若只含数值信息的字段尽量不要设计为字符型，这会 <strong>降低查询和连接的性能，并会增加存储开销</strong> 。这是因为<strong>引擎在处理查询和连接时会逐个比较字符串中每一个字符，而对于数字型而言只需要比较一次就够了</strong>。</p>\n</li>\n<li><p>尽可能的使用 <code>varchar/nvarchar</code> 代替 <code>char/nchar</code> ，因为首先<code>变长字段</code>存储空间小，可以节省存储空间，其次对于查询来说，在一个相对较小的字段内搜索效率显然要高些。</p>\n</li>\n<li><p>任何地方都不要使用 <code>select * from t</code> ，用具体的<code>字段列</code>表代替“*”，不要返回用不到的任何字段。</p>\n</li>\n<li><p>尽量使用表变量来代替临时表。如果表变量包含大量数据，请注意索引非常有限（只有主键索引）。</p>\n</li>\n<li><p>避免频繁创建和删除临时表，以减少系统表资源的消耗。</p>\n</li>\n<li><p>临时表并不是不可使用，适当地使用它们可以使某些例程更有效，例如，当需要重复引用大型表或常用表中的某个数据集时。但是，对于一次性事件，最好使用导出表。</p>\n</li>\n<li><p>在新建临时表时，如果一次性插入数据量很大，那么可以使用 <code>select into</code> 代替 <code>create table</code>，避免造成大量 <code>log</code> ，以提高速度；如果数据量不大，为了缓和系统表的资源，应先<code>create table</code>，然后<code>insert</code>。</p>\n</li>\n<li><p>如果使用到了临时表，在存储过程的最后务必将所有的临时表显式删除，先 <code>truncate table</code> ，然后 <code>drop table</code> ，这样可以避免系统表的较长时间锁定。（先truncate可以释放表空间）。</p>\n</li>\n<li><p>尽量避免使用游标，因为游标的效率较差，如果游标操作的数据超过1万行，那么就应该考虑改写。</p>\n</li>\n<li><p>使用基于游标的方法或临时表方法之前，应先寻找基于集的解决方案来解决问题，基于集的方法通常更有效。</p>\n</li>\n<li><p>与临时表一样，游标并不是不可使用。对小型数据集使用 <code>FAST_FORWARD</code> 游标通常要优于其他逐行处理方法，尤其是在必须引用几个表才能获得所需的数据时。在结果集中包括“合计”的例程通常要比使用游标执行的速度快。如果开发时间允许，基于游标的方法和基于集的方法都可以尝试一下，看哪一种方法的效果更好。</p>\n</li>\n<li><p>在所有的存储过程和触发器的开始处设置 <code>SET NOCOUNT ON</code> ，在结束时设置 <code>SET NOCOUNT OFF</code> 。无需在执行存储过程和触发器的每个语句后向客户端发送 <code>DONE_IN_PROC</code> 消息。</p>\n</li>\n<li><p>尽量避免向客户端返回大数据量，若数据量过大，应该考虑相应需求是否合理。</p>\n</li>\n<li><p>尽量避免大事务操作，提高系统并发能力。</p>\n</li>\n</ol>\n"},{"title":"JVM结构","excerpt":"","comments":1,"date":"2020-04-19T16:30:52.000Z","_content":"\n\n## JVM结构图\n\n<img src=\"20170513134212845.png\">\n\n## 解析\n\n### 四大部分\n\n- **Class Loader（类加载器）** 就是将Class文件加载到内存，再说的详细一点就是，把描述类的数据从Class文件加载到内存，并对数据进行校验、转换解析和初始化，最终形成可以被虚拟机直接使用的Java类型。\n\n- **Run Data Area（运行时数据区）** 就是我们常说的JVM管理的内存了，也是我们这里主要讨论的部分。运行数据区是整个JVM的重点。我们所有写的程序都被加载到这里，之后才开始运行。这部分也是我们这里将要讨论的重点。\n\n- **Execution engine（执行引擎）** 是Java虚拟机最核心的组成部分之一。执行引擎用于执行指令，不同的java虚拟机内部实现中，执行引擎在执行Java代码的时候可能有解释执行（解释器执行）和编译执行（通过即时编译器产生本地代码执行，例如BEA JRockit），也有可能两者兼备。任何JVM specification实现(JDK)的核心都是Execution engine，不同的JDK例如Sun 的JDK 和IBM的JDK好坏主要就取决于他们各自实现的Execution engine的好坏。\n\n- **Native interface** 与native libraries交互，是其它编程语言交互的接口。当调用native方法的时候，就进入了一个全新的并且不再受虚拟机限制的世界，所以也很容易出现JVM无法控制的native heap OutOfMemory。\n\n### Run Data Area\n\n|数据|描述|\n-|-|\n|Program Counter Register|程序计数器， 线程私有、指向下一条要很执行的指令|\n|Java Stack|Java虚拟机栈， 线程私有，生命周期与线程相同。描述的是Java方法执行的内存模型：每个方法被执行的时候都会同时创建一个栈帧（Stack Frame）用于 存储局部变量表、操作栈、动态链接、方法出口|\n|Native Method Stack|为虚拟机使用到的Native 方法服务|\n|Heap|线程共享，由于现在收集器基本采用的分代收集算法，所以Java堆中还可以细分：新生代和老生代；更细致一点的有Eden空间、From Survivor空间、To Survivor空间等。 所有的对象实例以及数组都要在堆上分配，是垃圾收集器管理的主要区域|\n|Method Area|方法区，别名叫做非堆(Non-Heap)， 线程共享的内存区域。目的是与Java堆区分开来， 存储类信息、常量、静态变量、即时编译器编译后的代码。 \n方法区存放的信息包括： \nA 类的基本信息： \n1.每个类的全限定名 \n2.每个类的直接超类的全限定名(可约束类型转换) \n3.该类是类还是接口 \n4.该类型的访问修饰符 \n5.直接超接口的全限定名的有序列表 \nB 已装载类的详细信息 \n1.运行时常量池：在方法区中，每个类型都对应一个常量池，存放该类型所用到的所有常量，常量池中存储了诸如文字字符串、final变量值、类名和方法名常量。它们以数组形式通过索引被访 问，是外部调用与类联系及类型对象化的桥梁。（存的可能是个普通的字符串，然后经过常量池解析，则变成指向某个类的引用） \n2.字段信息：字段信息存放类中声明的每一个字段的信息，包括字段的名、类型、修饰符。字段名称指的是类或接口的实例变量或类变量，字段的描述符是一个指示字段的类型的字符串，如private A a=null;则a为字段名，A为描述符，private为修饰符。 \n3.方法信息：类中声明的每一个方法的信息，包括方法名、返回值类型、参数类型、修饰符、异常、方法的字节码。(在编译的时候，就已经将方法的局部变量、操作数栈大小等确定并存放在字节码中，在装载的时候，随着类一起装入方法区。) \n4.静态变量：就是类变量，类的所有实例都共享，我们只需知道，在方法区有个静态区，静态区专门存放静态变量和静态块。 \n5.到类classloader的引用：到该类的类装载器的引用。 \n6.到类class 的引用：jvm为每个加载的类型(译者：包括类和接口)都创建一个java.lang.Class的实例。而jvm必须以某种方式把Class的这个实例和存储在方法区中的类型数据联系起来。|\n                                                     \n\n\n\n","source":"_posts/2020-04-20-kongzheng1993-JVM.md","raw":"---\ntitle: JVM结构\nexcerpt: ''\ntags: [Java]\ncategories: [Java]\ncomments: true\ndate: 2020-04-20 00:30:52\n---\n\n\n## JVM结构图\n\n<img src=\"20170513134212845.png\">\n\n## 解析\n\n### 四大部分\n\n- **Class Loader（类加载器）** 就是将Class文件加载到内存，再说的详细一点就是，把描述类的数据从Class文件加载到内存，并对数据进行校验、转换解析和初始化，最终形成可以被虚拟机直接使用的Java类型。\n\n- **Run Data Area（运行时数据区）** 就是我们常说的JVM管理的内存了，也是我们这里主要讨论的部分。运行数据区是整个JVM的重点。我们所有写的程序都被加载到这里，之后才开始运行。这部分也是我们这里将要讨论的重点。\n\n- **Execution engine（执行引擎）** 是Java虚拟机最核心的组成部分之一。执行引擎用于执行指令，不同的java虚拟机内部实现中，执行引擎在执行Java代码的时候可能有解释执行（解释器执行）和编译执行（通过即时编译器产生本地代码执行，例如BEA JRockit），也有可能两者兼备。任何JVM specification实现(JDK)的核心都是Execution engine，不同的JDK例如Sun 的JDK 和IBM的JDK好坏主要就取决于他们各自实现的Execution engine的好坏。\n\n- **Native interface** 与native libraries交互，是其它编程语言交互的接口。当调用native方法的时候，就进入了一个全新的并且不再受虚拟机限制的世界，所以也很容易出现JVM无法控制的native heap OutOfMemory。\n\n### Run Data Area\n\n|数据|描述|\n-|-|\n|Program Counter Register|程序计数器， 线程私有、指向下一条要很执行的指令|\n|Java Stack|Java虚拟机栈， 线程私有，生命周期与线程相同。描述的是Java方法执行的内存模型：每个方法被执行的时候都会同时创建一个栈帧（Stack Frame）用于 存储局部变量表、操作栈、动态链接、方法出口|\n|Native Method Stack|为虚拟机使用到的Native 方法服务|\n|Heap|线程共享，由于现在收集器基本采用的分代收集算法，所以Java堆中还可以细分：新生代和老生代；更细致一点的有Eden空间、From Survivor空间、To Survivor空间等。 所有的对象实例以及数组都要在堆上分配，是垃圾收集器管理的主要区域|\n|Method Area|方法区，别名叫做非堆(Non-Heap)， 线程共享的内存区域。目的是与Java堆区分开来， 存储类信息、常量、静态变量、即时编译器编译后的代码。 \n方法区存放的信息包括： \nA 类的基本信息： \n1.每个类的全限定名 \n2.每个类的直接超类的全限定名(可约束类型转换) \n3.该类是类还是接口 \n4.该类型的访问修饰符 \n5.直接超接口的全限定名的有序列表 \nB 已装载类的详细信息 \n1.运行时常量池：在方法区中，每个类型都对应一个常量池，存放该类型所用到的所有常量，常量池中存储了诸如文字字符串、final变量值、类名和方法名常量。它们以数组形式通过索引被访 问，是外部调用与类联系及类型对象化的桥梁。（存的可能是个普通的字符串，然后经过常量池解析，则变成指向某个类的引用） \n2.字段信息：字段信息存放类中声明的每一个字段的信息，包括字段的名、类型、修饰符。字段名称指的是类或接口的实例变量或类变量，字段的描述符是一个指示字段的类型的字符串，如private A a=null;则a为字段名，A为描述符，private为修饰符。 \n3.方法信息：类中声明的每一个方法的信息，包括方法名、返回值类型、参数类型、修饰符、异常、方法的字节码。(在编译的时候，就已经将方法的局部变量、操作数栈大小等确定并存放在字节码中，在装载的时候，随着类一起装入方法区。) \n4.静态变量：就是类变量，类的所有实例都共享，我们只需知道，在方法区有个静态区，静态区专门存放静态变量和静态块。 \n5.到类classloader的引用：到该类的类装载器的引用。 \n6.到类class 的引用：jvm为每个加载的类型(译者：包括类和接口)都创建一个java.lang.Class的实例。而jvm必须以某种方式把Class的这个实例和存储在方法区中的类型数据联系起来。|\n                                                     \n\n\n\n","slug":"kongzheng1993-JVM","published":1,"updated":"2023-03-08T07:05:58.796Z","layout":"post","photos":[],"link":"","_id":"clg0k2ajd003jt26fm9uuxwvy","content":"<h2 id=\"JVM结构图\"><a href=\"#JVM结构图\" class=\"headerlink\" title=\"JVM结构图\"></a>JVM结构图</h2><img src=\"/2020/04/20/kongzheng1993-JVM/20170513134212845.png\">\n\n<h2 id=\"解析\"><a href=\"#解析\" class=\"headerlink\" title=\"解析\"></a>解析</h2><h3 id=\"四大部分\"><a href=\"#四大部分\" class=\"headerlink\" title=\"四大部分\"></a>四大部分</h3><ul>\n<li><p><strong>Class Loader（类加载器）</strong> 就是将Class文件加载到内存，再说的详细一点就是，把描述类的数据从Class文件加载到内存，并对数据进行校验、转换解析和初始化，最终形成可以被虚拟机直接使用的Java类型。</p>\n</li>\n<li><p><strong>Run Data Area（运行时数据区）</strong> 就是我们常说的JVM管理的内存了，也是我们这里主要讨论的部分。运行数据区是整个JVM的重点。我们所有写的程序都被加载到这里，之后才开始运行。这部分也是我们这里将要讨论的重点。</p>\n</li>\n<li><p><strong>Execution engine（执行引擎）</strong> 是Java虚拟机最核心的组成部分之一。执行引擎用于执行指令，不同的java虚拟机内部实现中，执行引擎在执行Java代码的时候可能有解释执行（解释器执行）和编译执行（通过即时编译器产生本地代码执行，例如BEA JRockit），也有可能两者兼备。任何JVM specification实现(JDK)的核心都是Execution engine，不同的JDK例如Sun 的JDK 和IBM的JDK好坏主要就取决于他们各自实现的Execution engine的好坏。</p>\n</li>\n<li><p><strong>Native interface</strong> 与native libraries交互，是其它编程语言交互的接口。当调用native方法的时候，就进入了一个全新的并且不再受虚拟机限制的世界，所以也很容易出现JVM无法控制的native heap OutOfMemory。</p>\n</li>\n</ul>\n<h3 id=\"Run-Data-Area\"><a href=\"#Run-Data-Area\" class=\"headerlink\" title=\"Run Data Area\"></a>Run Data Area</h3><table>\n<thead>\n<tr>\n<th>数据</th>\n<th>描述</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Program Counter Register</td>\n<td>程序计数器， 线程私有、指向下一条要很执行的指令</td>\n</tr>\n<tr>\n<td>Java Stack</td>\n<td>Java虚拟机栈， 线程私有，生命周期与线程相同。描述的是Java方法执行的内存模型：每个方法被执行的时候都会同时创建一个栈帧（Stack Frame）用于 存储局部变量表、操作栈、动态链接、方法出口</td>\n</tr>\n<tr>\n<td>Native Method Stack</td>\n<td>为虚拟机使用到的Native 方法服务</td>\n</tr>\n<tr>\n<td>Heap</td>\n<td>线程共享，由于现在收集器基本采用的分代收集算法，所以Java堆中还可以细分：新生代和老生代；更细致一点的有Eden空间、From Survivor空间、To Survivor空间等。 所有的对象实例以及数组都要在堆上分配，是垃圾收集器管理的主要区域</td>\n</tr>\n<tr>\n<td>Method Area</td>\n<td>方法区，别名叫做非堆(Non-Heap)， 线程共享的内存区域。目的是与Java堆区分开来， 存储类信息、常量、静态变量、即时编译器编译后的代码。</td>\n</tr>\n<tr>\n<td>方法区存放的信息包括：</td>\n<td></td>\n</tr>\n<tr>\n<td>A 类的基本信息：</td>\n<td></td>\n</tr>\n<tr>\n<td>1.每个类的全限定名</td>\n<td></td>\n</tr>\n<tr>\n<td>2.每个类的直接超类的全限定名(可约束类型转换)</td>\n<td></td>\n</tr>\n<tr>\n<td>3.该类是类还是接口</td>\n<td></td>\n</tr>\n<tr>\n<td>4.该类型的访问修饰符</td>\n<td></td>\n</tr>\n<tr>\n<td>5.直接超接口的全限定名的有序列表</td>\n<td></td>\n</tr>\n<tr>\n<td>B 已装载类的详细信息</td>\n<td></td>\n</tr>\n<tr>\n<td>1.运行时常量池：在方法区中，每个类型都对应一个常量池，存放该类型所用到的所有常量，常量池中存储了诸如文字字符串、final变量值、类名和方法名常量。它们以数组形式通过索引被访 问，是外部调用与类联系及类型对象化的桥梁。（存的可能是个普通的字符串，然后经过常量池解析，则变成指向某个类的引用）</td>\n<td></td>\n</tr>\n<tr>\n<td>2.字段信息：字段信息存放类中声明的每一个字段的信息，包括字段的名、类型、修饰符。字段名称指的是类或接口的实例变量或类变量，字段的描述符是一个指示字段的类型的字符串，如private A a=null;则a为字段名，A为描述符，private为修饰符。</td>\n<td></td>\n</tr>\n<tr>\n<td>3.方法信息：类中声明的每一个方法的信息，包括方法名、返回值类型、参数类型、修饰符、异常、方法的字节码。(在编译的时候，就已经将方法的局部变量、操作数栈大小等确定并存放在字节码中，在装载的时候，随着类一起装入方法区。)</td>\n<td></td>\n</tr>\n<tr>\n<td>4.静态变量：就是类变量，类的所有实例都共享，我们只需知道，在方法区有个静态区，静态区专门存放静态变量和静态块。</td>\n<td></td>\n</tr>\n<tr>\n<td>5.到类classloader的引用：到该类的类装载器的引用。</td>\n<td></td>\n</tr>\n<tr>\n<td>6.到类class 的引用：jvm为每个加载的类型(译者：包括类和接口)都创建一个java.lang.Class的实例。而jvm必须以某种方式把Class的这个实例和存储在方法区中的类型数据联系起来。</td>\n<td></td>\n</tr>\n</tbody></table>\n","site":{"data":{}},"more":"<h2 id=\"JVM结构图\"><a href=\"#JVM结构图\" class=\"headerlink\" title=\"JVM结构图\"></a>JVM结构图</h2><img src=\"/2020/04/20/kongzheng1993-JVM/20170513134212845.png\">\n\n<h2 id=\"解析\"><a href=\"#解析\" class=\"headerlink\" title=\"解析\"></a>解析</h2><h3 id=\"四大部分\"><a href=\"#四大部分\" class=\"headerlink\" title=\"四大部分\"></a>四大部分</h3><ul>\n<li><p><strong>Class Loader（类加载器）</strong> 就是将Class文件加载到内存，再说的详细一点就是，把描述类的数据从Class文件加载到内存，并对数据进行校验、转换解析和初始化，最终形成可以被虚拟机直接使用的Java类型。</p>\n</li>\n<li><p><strong>Run Data Area（运行时数据区）</strong> 就是我们常说的JVM管理的内存了，也是我们这里主要讨论的部分。运行数据区是整个JVM的重点。我们所有写的程序都被加载到这里，之后才开始运行。这部分也是我们这里将要讨论的重点。</p>\n</li>\n<li><p><strong>Execution engine（执行引擎）</strong> 是Java虚拟机最核心的组成部分之一。执行引擎用于执行指令，不同的java虚拟机内部实现中，执行引擎在执行Java代码的时候可能有解释执行（解释器执行）和编译执行（通过即时编译器产生本地代码执行，例如BEA JRockit），也有可能两者兼备。任何JVM specification实现(JDK)的核心都是Execution engine，不同的JDK例如Sun 的JDK 和IBM的JDK好坏主要就取决于他们各自实现的Execution engine的好坏。</p>\n</li>\n<li><p><strong>Native interface</strong> 与native libraries交互，是其它编程语言交互的接口。当调用native方法的时候，就进入了一个全新的并且不再受虚拟机限制的世界，所以也很容易出现JVM无法控制的native heap OutOfMemory。</p>\n</li>\n</ul>\n<h3 id=\"Run-Data-Area\"><a href=\"#Run-Data-Area\" class=\"headerlink\" title=\"Run Data Area\"></a>Run Data Area</h3><table>\n<thead>\n<tr>\n<th>数据</th>\n<th>描述</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Program Counter Register</td>\n<td>程序计数器， 线程私有、指向下一条要很执行的指令</td>\n</tr>\n<tr>\n<td>Java Stack</td>\n<td>Java虚拟机栈， 线程私有，生命周期与线程相同。描述的是Java方法执行的内存模型：每个方法被执行的时候都会同时创建一个栈帧（Stack Frame）用于 存储局部变量表、操作栈、动态链接、方法出口</td>\n</tr>\n<tr>\n<td>Native Method Stack</td>\n<td>为虚拟机使用到的Native 方法服务</td>\n</tr>\n<tr>\n<td>Heap</td>\n<td>线程共享，由于现在收集器基本采用的分代收集算法，所以Java堆中还可以细分：新生代和老生代；更细致一点的有Eden空间、From Survivor空间、To Survivor空间等。 所有的对象实例以及数组都要在堆上分配，是垃圾收集器管理的主要区域</td>\n</tr>\n<tr>\n<td>Method Area</td>\n<td>方法区，别名叫做非堆(Non-Heap)， 线程共享的内存区域。目的是与Java堆区分开来， 存储类信息、常量、静态变量、即时编译器编译后的代码。</td>\n</tr>\n<tr>\n<td>方法区存放的信息包括：</td>\n<td></td>\n</tr>\n<tr>\n<td>A 类的基本信息：</td>\n<td></td>\n</tr>\n<tr>\n<td>1.每个类的全限定名</td>\n<td></td>\n</tr>\n<tr>\n<td>2.每个类的直接超类的全限定名(可约束类型转换)</td>\n<td></td>\n</tr>\n<tr>\n<td>3.该类是类还是接口</td>\n<td></td>\n</tr>\n<tr>\n<td>4.该类型的访问修饰符</td>\n<td></td>\n</tr>\n<tr>\n<td>5.直接超接口的全限定名的有序列表</td>\n<td></td>\n</tr>\n<tr>\n<td>B 已装载类的详细信息</td>\n<td></td>\n</tr>\n<tr>\n<td>1.运行时常量池：在方法区中，每个类型都对应一个常量池，存放该类型所用到的所有常量，常量池中存储了诸如文字字符串、final变量值、类名和方法名常量。它们以数组形式通过索引被访 问，是外部调用与类联系及类型对象化的桥梁。（存的可能是个普通的字符串，然后经过常量池解析，则变成指向某个类的引用）</td>\n<td></td>\n</tr>\n<tr>\n<td>2.字段信息：字段信息存放类中声明的每一个字段的信息，包括字段的名、类型、修饰符。字段名称指的是类或接口的实例变量或类变量，字段的描述符是一个指示字段的类型的字符串，如private A a=null;则a为字段名，A为描述符，private为修饰符。</td>\n<td></td>\n</tr>\n<tr>\n<td>3.方法信息：类中声明的每一个方法的信息，包括方法名、返回值类型、参数类型、修饰符、异常、方法的字节码。(在编译的时候，就已经将方法的局部变量、操作数栈大小等确定并存放在字节码中，在装载的时候，随着类一起装入方法区。)</td>\n<td></td>\n</tr>\n<tr>\n<td>4.静态变量：就是类变量，类的所有实例都共享，我们只需知道，在方法区有个静态区，静态区专门存放静态变量和静态块。</td>\n<td></td>\n</tr>\n<tr>\n<td>5.到类classloader的引用：到该类的类装载器的引用。</td>\n<td></td>\n</tr>\n<tr>\n<td>6.到类class 的引用：jvm为每个加载的类型(译者：包括类和接口)都创建一个java.lang.Class的实例。而jvm必须以某种方式把Class的这个实例和存储在方法区中的类型数据联系起来。</td>\n<td></td>\n</tr>\n</tbody></table>\n"},{"title":"SPI","excerpt":"","comments":1,"date":"2020-04-23T16:30:52.000Z","_content":"\n## 什么是SPI\n\n**SPI（Service Provider Interface）**，是JDK内置的一种服务提供发现机制，可以用来启用框架扩展和替换组件，主要是被框架的开发人员使用，比如java.sql.Driver接口，其他不同厂商可以针对同一接口做出不同的实现，MySQL和PostgreSQL都有不同的实现提供给用户，而Java的SPI机制可以为某个接口寻找服务实现。Java中SPI机制主要思想是将装配的控制权移到程序之外，在模块化设计中这个机制尤其重要，其核心思想就是解耦。\n\n**SPI和API**\n\nstackoverflow原文：\n- The API is the description of classes/interfaces/methods/... that you call and use to achieve a goal;\n- The SPI is the description of classes/interfaces/methods/... that you extend and implement to achieve a goal.\n\n翻译过来就是：\n- API是调用并用于达到目标的类、接口、方法等的描述；\n- SPI是扩展和实现以达到目标的类、接口、方法等的描述；\n\n## SPI机制\n\n<img src=\"v2-a4598f8b9ab46951b190cc9ce059eee0_720w.jpg\">\n\nSPI流程：\n\n1. 有关组织和公式定义接口标准\n2. 第三方提供具体实现: 实现具体方法, 配置 META-INF/services/${interface_name} 文件\n3. 开发者使用\n\n当服务的提供者提供了一种接口的实现之后，需要在`classpath`下的`META-INF/services/`目录里创建一个以服务接口命名的文件，这个文件里的内容就是这个接口的具体的实现类。当其他的程序需要这个服务的时候，就可以通过查找这个jar包（一般都是以jar包做依赖）的`META-INF/services/`中的配置文件，配置文件中有接口的具体实现类名，可以根据这个类名进行加载实例化，就可以使用该服务了。JDK中查找服务的实现的工具类是：`java.util.ServiceLoader`。\n\n## 应用场景\n\n你有个工程A，有个接口A，接口A在工程A是没有实现类的,那么问题来了,系统运行时,怎么给接口A选择一个实现类呢?你可以自己搞一个jar包，`META-INF/services/`,放上一个文件,文件名即接口名--接口A，文件内容就是你的实现类：\n```properties\ncom.xxx.service.实现类A2\ncom.xxx.service.实现类A3\n```\n让工程A来依赖你的jar包,然后在系统运行时,工程A跑起来,对于接口A,就会扫描依赖的jar包,看看有没有`META-INF/services`文件夹,如果有,看再看有没有名为`接口A`的文件,如果有,在里面找一下指定的`接口A`的实现是你的jar包里的哪个类!\n\n当然，也可以设置多个实现类，如果配置多个实现类，需要我们自己来选择使用哪一个实现类的实例。\n\n比如JDBC场景下：\n\n首先在Java中定义了接口java.sql.Driver，并没有具体的实现，具体的实现都是由不同厂商提供。\n在MySQL的jar包mysql-connector-java-6.0.6.jar中，可以找到META-INF/services目录，该目录下会有一个名字为java.sql.Driver的文件，文件内容是com.mysql.cj.jdbc.Driver，这里面的内容就是针对Java中定义的接口的实现。\n同样在PostgreSQL的jar包PostgreSQL-42.0.0.jar中，也可以找到同样的配置文件，文件内容是org.postgresql.Driver，这是PostgreSQL对Java的java.sql.Driver的实现。\n\n\n## 分析\n\n1. ServiceLoader实现了Iterable接口，所以它有迭代器的属性，这里主要都是实现了迭代器的hasNext和next方法。这里主要都是调用的lookupIterator的相应hasNext和next方法，lookupIterator是懒加载迭代器。\n\n2. LazyIterator中的hasNext方法，静态变量PREFIX就是”META-INF/services/”目录，这也就是为什么需要在classpath下的META-INF/services/目录里创建一个以服务接口命名的文件。\n\n3. 通过反射方法Class.forName()加载类对象，并用newInstance方法将类实例化，并把实例化后的类缓存到providers对象中，(LinkedHashMap<String,S>类型） 然后返回实例对象。\n\n## JDK原生SPI存在的问题\n\n1. 不能按需加载，需要遍历所有实现类并实例化，然后在循环中才能找到我们需要的实现。这里所有实现类都要实例化，浪费资源。\n2. 获取某个实现类的方式不够灵活，只能通过Iterator来遍历。\n3. ServiceLoader线程不安全。\n   \n## Dubbo中的SPI\n\nDubbo没有使用Java SPI，而是自己实现了一套功能更强的SPI机制，Dubbo称为`扩展`。Dubbo SPI 的相关逻辑被封装在了 `ExtensionLoader` 类中，通过 `ExtensionLoader`，我们可以加载指定的实现类。Dubbo SPI 所需的配置文件需放置在 `META-INF/dubbo` 路径下。\n\n下面是Dubbo协议的扩展：\n\n```\nsrc\n |-main\n    |-java\n        |-com\n            |-xxx\n                |-XxxProtocol.java (实现Protocol接口)\n                |-XxxExporter.java (实现Exporter接口)\n                |-XxxInvoker.java (实现Invoker接口)\n    |-resources\n        |-META-INF\n            |-dubbo\n                |-org.apache.dubbo.rpc.Protocol (纯文本文件，内容为：xxx=com.xxx.XxxProtocol)\n```\n\nDubbo的`扩展`就可以通过key来确认实现类了。\n","source":"_posts/2020-04-24-kongzheng1993-SPI.md","raw":"---\ntitle: SPI\nexcerpt: ''\ntags: [Java]\ncategories: [Java]\ncomments: true\ndate: 2020-04-24 00:30:52\n---\n\n## 什么是SPI\n\n**SPI（Service Provider Interface）**，是JDK内置的一种服务提供发现机制，可以用来启用框架扩展和替换组件，主要是被框架的开发人员使用，比如java.sql.Driver接口，其他不同厂商可以针对同一接口做出不同的实现，MySQL和PostgreSQL都有不同的实现提供给用户，而Java的SPI机制可以为某个接口寻找服务实现。Java中SPI机制主要思想是将装配的控制权移到程序之外，在模块化设计中这个机制尤其重要，其核心思想就是解耦。\n\n**SPI和API**\n\nstackoverflow原文：\n- The API is the description of classes/interfaces/methods/... that you call and use to achieve a goal;\n- The SPI is the description of classes/interfaces/methods/... that you extend and implement to achieve a goal.\n\n翻译过来就是：\n- API是调用并用于达到目标的类、接口、方法等的描述；\n- SPI是扩展和实现以达到目标的类、接口、方法等的描述；\n\n## SPI机制\n\n<img src=\"v2-a4598f8b9ab46951b190cc9ce059eee0_720w.jpg\">\n\nSPI流程：\n\n1. 有关组织和公式定义接口标准\n2. 第三方提供具体实现: 实现具体方法, 配置 META-INF/services/${interface_name} 文件\n3. 开发者使用\n\n当服务的提供者提供了一种接口的实现之后，需要在`classpath`下的`META-INF/services/`目录里创建一个以服务接口命名的文件，这个文件里的内容就是这个接口的具体的实现类。当其他的程序需要这个服务的时候，就可以通过查找这个jar包（一般都是以jar包做依赖）的`META-INF/services/`中的配置文件，配置文件中有接口的具体实现类名，可以根据这个类名进行加载实例化，就可以使用该服务了。JDK中查找服务的实现的工具类是：`java.util.ServiceLoader`。\n\n## 应用场景\n\n你有个工程A，有个接口A，接口A在工程A是没有实现类的,那么问题来了,系统运行时,怎么给接口A选择一个实现类呢?你可以自己搞一个jar包，`META-INF/services/`,放上一个文件,文件名即接口名--接口A，文件内容就是你的实现类：\n```properties\ncom.xxx.service.实现类A2\ncom.xxx.service.实现类A3\n```\n让工程A来依赖你的jar包,然后在系统运行时,工程A跑起来,对于接口A,就会扫描依赖的jar包,看看有没有`META-INF/services`文件夹,如果有,看再看有没有名为`接口A`的文件,如果有,在里面找一下指定的`接口A`的实现是你的jar包里的哪个类!\n\n当然，也可以设置多个实现类，如果配置多个实现类，需要我们自己来选择使用哪一个实现类的实例。\n\n比如JDBC场景下：\n\n首先在Java中定义了接口java.sql.Driver，并没有具体的实现，具体的实现都是由不同厂商提供。\n在MySQL的jar包mysql-connector-java-6.0.6.jar中，可以找到META-INF/services目录，该目录下会有一个名字为java.sql.Driver的文件，文件内容是com.mysql.cj.jdbc.Driver，这里面的内容就是针对Java中定义的接口的实现。\n同样在PostgreSQL的jar包PostgreSQL-42.0.0.jar中，也可以找到同样的配置文件，文件内容是org.postgresql.Driver，这是PostgreSQL对Java的java.sql.Driver的实现。\n\n\n## 分析\n\n1. ServiceLoader实现了Iterable接口，所以它有迭代器的属性，这里主要都是实现了迭代器的hasNext和next方法。这里主要都是调用的lookupIterator的相应hasNext和next方法，lookupIterator是懒加载迭代器。\n\n2. LazyIterator中的hasNext方法，静态变量PREFIX就是”META-INF/services/”目录，这也就是为什么需要在classpath下的META-INF/services/目录里创建一个以服务接口命名的文件。\n\n3. 通过反射方法Class.forName()加载类对象，并用newInstance方法将类实例化，并把实例化后的类缓存到providers对象中，(LinkedHashMap<String,S>类型） 然后返回实例对象。\n\n## JDK原生SPI存在的问题\n\n1. 不能按需加载，需要遍历所有实现类并实例化，然后在循环中才能找到我们需要的实现。这里所有实现类都要实例化，浪费资源。\n2. 获取某个实现类的方式不够灵活，只能通过Iterator来遍历。\n3. ServiceLoader线程不安全。\n   \n## Dubbo中的SPI\n\nDubbo没有使用Java SPI，而是自己实现了一套功能更强的SPI机制，Dubbo称为`扩展`。Dubbo SPI 的相关逻辑被封装在了 `ExtensionLoader` 类中，通过 `ExtensionLoader`，我们可以加载指定的实现类。Dubbo SPI 所需的配置文件需放置在 `META-INF/dubbo` 路径下。\n\n下面是Dubbo协议的扩展：\n\n```\nsrc\n |-main\n    |-java\n        |-com\n            |-xxx\n                |-XxxProtocol.java (实现Protocol接口)\n                |-XxxExporter.java (实现Exporter接口)\n                |-XxxInvoker.java (实现Invoker接口)\n    |-resources\n        |-META-INF\n            |-dubbo\n                |-org.apache.dubbo.rpc.Protocol (纯文本文件，内容为：xxx=com.xxx.XxxProtocol)\n```\n\nDubbo的`扩展`就可以通过key来确认实现类了。\n","slug":"kongzheng1993-SPI","published":1,"updated":"2023-03-08T07:05:58.797Z","layout":"post","photos":[],"link":"","_id":"clg0k2aji003kt26fik5ktvwf","content":"<h2 id=\"什么是SPI\"><a href=\"#什么是SPI\" class=\"headerlink\" title=\"什么是SPI\"></a>什么是SPI</h2><p><strong>SPI（Service Provider Interface）</strong>，是JDK内置的一种服务提供发现机制，可以用来启用框架扩展和替换组件，主要是被框架的开发人员使用，比如java.sql.Driver接口，其他不同厂商可以针对同一接口做出不同的实现，MySQL和PostgreSQL都有不同的实现提供给用户，而Java的SPI机制可以为某个接口寻找服务实现。Java中SPI机制主要思想是将装配的控制权移到程序之外，在模块化设计中这个机制尤其重要，其核心思想就是解耦。</p>\n<p><strong>SPI和API</strong></p>\n<p>stackoverflow原文：</p>\n<ul>\n<li>The API is the description of classes/interfaces/methods/… that you call and use to achieve a goal;</li>\n<li>The SPI is the description of classes/interfaces/methods/… that you extend and implement to achieve a goal.</li>\n</ul>\n<p>翻译过来就是：</p>\n<ul>\n<li>API是调用并用于达到目标的类、接口、方法等的描述；</li>\n<li>SPI是扩展和实现以达到目标的类、接口、方法等的描述；</li>\n</ul>\n<h2 id=\"SPI机制\"><a href=\"#SPI机制\" class=\"headerlink\" title=\"SPI机制\"></a>SPI机制</h2><img src=\"/2020/04/24/kongzheng1993-SPI/v2-a4598f8b9ab46951b190cc9ce059eee0_720w.jpg\">\n\n<p>SPI流程：</p>\n<ol>\n<li>有关组织和公式定义接口标准</li>\n<li>第三方提供具体实现: 实现具体方法, 配置 META-INF/services/${interface_name} 文件</li>\n<li>开发者使用</li>\n</ol>\n<p>当服务的提供者提供了一种接口的实现之后，需要在<code>classpath</code>下的<code>META-INF/services/</code>目录里创建一个以服务接口命名的文件，这个文件里的内容就是这个接口的具体的实现类。当其他的程序需要这个服务的时候，就可以通过查找这个jar包（一般都是以jar包做依赖）的<code>META-INF/services/</code>中的配置文件，配置文件中有接口的具体实现类名，可以根据这个类名进行加载实例化，就可以使用该服务了。JDK中查找服务的实现的工具类是：<code>java.util.ServiceLoader</code>。</p>\n<h2 id=\"应用场景\"><a href=\"#应用场景\" class=\"headerlink\" title=\"应用场景\"></a>应用场景</h2><p>你有个工程A，有个接口A，接口A在工程A是没有实现类的,那么问题来了,系统运行时,怎么给接口A选择一个实现类呢?你可以自己搞一个jar包，<code>META-INF/services/</code>,放上一个文件,文件名即接口名–接口A，文件内容就是你的实现类：</p>\n<pre><code class=\"properties\">com.xxx.service.实现类A2\ncom.xxx.service.实现类A3</code></pre>\n<p>让工程A来依赖你的jar包,然后在系统运行时,工程A跑起来,对于接口A,就会扫描依赖的jar包,看看有没有<code>META-INF/services</code>文件夹,如果有,看再看有没有名为<code>接口A</code>的文件,如果有,在里面找一下指定的<code>接口A</code>的实现是你的jar包里的哪个类!</p>\n<p>当然，也可以设置多个实现类，如果配置多个实现类，需要我们自己来选择使用哪一个实现类的实例。</p>\n<p>比如JDBC场景下：</p>\n<p>首先在Java中定义了接口java.sql.Driver，并没有具体的实现，具体的实现都是由不同厂商提供。<br>在MySQL的jar包mysql-connector-java-6.0.6.jar中，可以找到META-INF/services目录，该目录下会有一个名字为java.sql.Driver的文件，文件内容是com.mysql.cj.jdbc.Driver，这里面的内容就是针对Java中定义的接口的实现。<br>同样在PostgreSQL的jar包PostgreSQL-42.0.0.jar中，也可以找到同样的配置文件，文件内容是org.postgresql.Driver，这是PostgreSQL对Java的java.sql.Driver的实现。</p>\n<h2 id=\"分析\"><a href=\"#分析\" class=\"headerlink\" title=\"分析\"></a>分析</h2><ol>\n<li><p>ServiceLoader实现了Iterable接口，所以它有迭代器的属性，这里主要都是实现了迭代器的hasNext和next方法。这里主要都是调用的lookupIterator的相应hasNext和next方法，lookupIterator是懒加载迭代器。</p>\n</li>\n<li><p>LazyIterator中的hasNext方法，静态变量PREFIX就是”META-INF/services/”目录，这也就是为什么需要在classpath下的META-INF/services/目录里创建一个以服务接口命名的文件。</p>\n</li>\n<li><p>通过反射方法Class.forName()加载类对象，并用newInstance方法将类实例化，并把实例化后的类缓存到providers对象中，(LinkedHashMap&lt;String,S&gt;类型） 然后返回实例对象。</p>\n</li>\n</ol>\n<h2 id=\"JDK原生SPI存在的问题\"><a href=\"#JDK原生SPI存在的问题\" class=\"headerlink\" title=\"JDK原生SPI存在的问题\"></a>JDK原生SPI存在的问题</h2><ol>\n<li>不能按需加载，需要遍历所有实现类并实例化，然后在循环中才能找到我们需要的实现。这里所有实现类都要实例化，浪费资源。</li>\n<li>获取某个实现类的方式不够灵活，只能通过Iterator来遍历。</li>\n<li>ServiceLoader线程不安全。</li>\n</ol>\n<h2 id=\"Dubbo中的SPI\"><a href=\"#Dubbo中的SPI\" class=\"headerlink\" title=\"Dubbo中的SPI\"></a>Dubbo中的SPI</h2><p>Dubbo没有使用Java SPI，而是自己实现了一套功能更强的SPI机制，Dubbo称为<code>扩展</code>。Dubbo SPI 的相关逻辑被封装在了 <code>ExtensionLoader</code> 类中，通过 <code>ExtensionLoader</code>，我们可以加载指定的实现类。Dubbo SPI 所需的配置文件需放置在 <code>META-INF/dubbo</code> 路径下。</p>\n<p>下面是Dubbo协议的扩展：</p>\n<pre><code>src\n |-main\n    |-java\n        |-com\n            |-xxx\n                |-XxxProtocol.java (实现Protocol接口)\n                |-XxxExporter.java (实现Exporter接口)\n                |-XxxInvoker.java (实现Invoker接口)\n    |-resources\n        |-META-INF\n            |-dubbo\n                |-org.apache.dubbo.rpc.Protocol (纯文本文件，内容为：xxx=com.xxx.XxxProtocol)</code></pre><p>Dubbo的<code>扩展</code>就可以通过key来确认实现类了。</p>\n","site":{"data":{}},"more":"<h2 id=\"什么是SPI\"><a href=\"#什么是SPI\" class=\"headerlink\" title=\"什么是SPI\"></a>什么是SPI</h2><p><strong>SPI（Service Provider Interface）</strong>，是JDK内置的一种服务提供发现机制，可以用来启用框架扩展和替换组件，主要是被框架的开发人员使用，比如java.sql.Driver接口，其他不同厂商可以针对同一接口做出不同的实现，MySQL和PostgreSQL都有不同的实现提供给用户，而Java的SPI机制可以为某个接口寻找服务实现。Java中SPI机制主要思想是将装配的控制权移到程序之外，在模块化设计中这个机制尤其重要，其核心思想就是解耦。</p>\n<p><strong>SPI和API</strong></p>\n<p>stackoverflow原文：</p>\n<ul>\n<li>The API is the description of classes/interfaces/methods/… that you call and use to achieve a goal;</li>\n<li>The SPI is the description of classes/interfaces/methods/… that you extend and implement to achieve a goal.</li>\n</ul>\n<p>翻译过来就是：</p>\n<ul>\n<li>API是调用并用于达到目标的类、接口、方法等的描述；</li>\n<li>SPI是扩展和实现以达到目标的类、接口、方法等的描述；</li>\n</ul>\n<h2 id=\"SPI机制\"><a href=\"#SPI机制\" class=\"headerlink\" title=\"SPI机制\"></a>SPI机制</h2><img src=\"/2020/04/24/kongzheng1993-SPI/v2-a4598f8b9ab46951b190cc9ce059eee0_720w.jpg\">\n\n<p>SPI流程：</p>\n<ol>\n<li>有关组织和公式定义接口标准</li>\n<li>第三方提供具体实现: 实现具体方法, 配置 META-INF/services/${interface_name} 文件</li>\n<li>开发者使用</li>\n</ol>\n<p>当服务的提供者提供了一种接口的实现之后，需要在<code>classpath</code>下的<code>META-INF/services/</code>目录里创建一个以服务接口命名的文件，这个文件里的内容就是这个接口的具体的实现类。当其他的程序需要这个服务的时候，就可以通过查找这个jar包（一般都是以jar包做依赖）的<code>META-INF/services/</code>中的配置文件，配置文件中有接口的具体实现类名，可以根据这个类名进行加载实例化，就可以使用该服务了。JDK中查找服务的实现的工具类是：<code>java.util.ServiceLoader</code>。</p>\n<h2 id=\"应用场景\"><a href=\"#应用场景\" class=\"headerlink\" title=\"应用场景\"></a>应用场景</h2><p>你有个工程A，有个接口A，接口A在工程A是没有实现类的,那么问题来了,系统运行时,怎么给接口A选择一个实现类呢?你可以自己搞一个jar包，<code>META-INF/services/</code>,放上一个文件,文件名即接口名–接口A，文件内容就是你的实现类：</p>\n<pre><code class=\"properties\">com.xxx.service.实现类A2\ncom.xxx.service.实现类A3</code></pre>\n<p>让工程A来依赖你的jar包,然后在系统运行时,工程A跑起来,对于接口A,就会扫描依赖的jar包,看看有没有<code>META-INF/services</code>文件夹,如果有,看再看有没有名为<code>接口A</code>的文件,如果有,在里面找一下指定的<code>接口A</code>的实现是你的jar包里的哪个类!</p>\n<p>当然，也可以设置多个实现类，如果配置多个实现类，需要我们自己来选择使用哪一个实现类的实例。</p>\n<p>比如JDBC场景下：</p>\n<p>首先在Java中定义了接口java.sql.Driver，并没有具体的实现，具体的实现都是由不同厂商提供。<br>在MySQL的jar包mysql-connector-java-6.0.6.jar中，可以找到META-INF/services目录，该目录下会有一个名字为java.sql.Driver的文件，文件内容是com.mysql.cj.jdbc.Driver，这里面的内容就是针对Java中定义的接口的实现。<br>同样在PostgreSQL的jar包PostgreSQL-42.0.0.jar中，也可以找到同样的配置文件，文件内容是org.postgresql.Driver，这是PostgreSQL对Java的java.sql.Driver的实现。</p>\n<h2 id=\"分析\"><a href=\"#分析\" class=\"headerlink\" title=\"分析\"></a>分析</h2><ol>\n<li><p>ServiceLoader实现了Iterable接口，所以它有迭代器的属性，这里主要都是实现了迭代器的hasNext和next方法。这里主要都是调用的lookupIterator的相应hasNext和next方法，lookupIterator是懒加载迭代器。</p>\n</li>\n<li><p>LazyIterator中的hasNext方法，静态变量PREFIX就是”META-INF/services/”目录，这也就是为什么需要在classpath下的META-INF/services/目录里创建一个以服务接口命名的文件。</p>\n</li>\n<li><p>通过反射方法Class.forName()加载类对象，并用newInstance方法将类实例化，并把实例化后的类缓存到providers对象中，(LinkedHashMap&lt;String,S&gt;类型） 然后返回实例对象。</p>\n</li>\n</ol>\n<h2 id=\"JDK原生SPI存在的问题\"><a href=\"#JDK原生SPI存在的问题\" class=\"headerlink\" title=\"JDK原生SPI存在的问题\"></a>JDK原生SPI存在的问题</h2><ol>\n<li>不能按需加载，需要遍历所有实现类并实例化，然后在循环中才能找到我们需要的实现。这里所有实现类都要实例化，浪费资源。</li>\n<li>获取某个实现类的方式不够灵活，只能通过Iterator来遍历。</li>\n<li>ServiceLoader线程不安全。</li>\n</ol>\n<h2 id=\"Dubbo中的SPI\"><a href=\"#Dubbo中的SPI\" class=\"headerlink\" title=\"Dubbo中的SPI\"></a>Dubbo中的SPI</h2><p>Dubbo没有使用Java SPI，而是自己实现了一套功能更强的SPI机制，Dubbo称为<code>扩展</code>。Dubbo SPI 的相关逻辑被封装在了 <code>ExtensionLoader</code> 类中，通过 <code>ExtensionLoader</code>，我们可以加载指定的实现类。Dubbo SPI 所需的配置文件需放置在 <code>META-INF/dubbo</code> 路径下。</p>\n<p>下面是Dubbo协议的扩展：</p>\n<pre><code>src\n |-main\n    |-java\n        |-com\n            |-xxx\n                |-XxxProtocol.java (实现Protocol接口)\n                |-XxxExporter.java (实现Exporter接口)\n                |-XxxInvoker.java (实现Invoker接口)\n    |-resources\n        |-META-INF\n            |-dubbo\n                |-org.apache.dubbo.rpc.Protocol (纯文本文件，内容为：xxx=com.xxx.XxxProtocol)</code></pre><p>Dubbo的<code>扩展</code>就可以通过key来确认实现类了。</p>\n"},{"title":"银行家算法","excerpt":"","comments":1,"date":"2020-04-24T16:30:52.000Z","_content":"\n## 银行家算法\n\n**银行家算法**（Banker's Algorithm）是一个避免死锁（Deadlock）的著名算法，是由艾兹格·迪杰斯特拉在1965年为T.H.E系统设计的一种避免死锁产生的算法。它以银行借贷系统的分配策略为基础，判断并保证系统的安全运行。\n\n## 来源\n\n在银行中，客户申请贷款的数量是有限的，每个客户在第一次申请贷款时要声明完成该项目所需的最大资金量，在满足所有贷款要求时，客户应及时归还。银行家在客户申请的贷款数量不超过自己拥有的最大值时，都应尽量满足客户的需要。在这样的描述中，银行家就好比操作系统，资金就是资源，客户就相当于要申请资源的进程。\n银行家算法是一种最有代表性的避免死锁的算法。在避免死锁方法中允许进程动态地申请资源，但系统在进行资源分配之前，应先计算此次分配资源的安全性，若分配不会导致系统进入不安全状态，则分配，否则等待。为实现银行家算法，系统必须设置若干数据结构。\n要解释银行家算法，必须先解释**操作系统安全状态**和不安全状态。\n安全序列是指一个进程序列{P1，…，Pn}是安全的，即对于每一个进程Pi(1≤i≤n），它以后尚需要的资源量不超过系统当前剩余资源量与所有进程Pj (j < i )当前占有资源量之和。\n\n### 安全状态\n\n如果存在一个由系统中所有进程构成的安全序列P1，…，Pn，则系统处于安全状态。安全状态一定是没有死锁发生。\n\n### 不安全状态\n\n不存在一个安全序列。不安全状态不一定导致死锁。\n\n## 数据结构\n\n- **可利用资源向量Available** 是个含有m个元素的数组，其中的每一个元素代表一类可利用的资源数目。如果Available[j]=K，则表示系统中现有Rj类资源K个。\n- **最大需求矩阵Max** 这是一个n*m的矩阵，它定义了系统中n个进程中的每一个进程对m类资源的最大需求。如果Max[i,j]=K，则表示进程i需要Rj类资源的最大数目为K。\n- **分配矩阵Allocation** 这也是一个n*m的矩阵，它定义了系统中每一类资源当前已分配给每一进程的资源数。如果Allocation[i,j]=K，则表示进程i当前已分得Rj类资源的 数目为K。\n- **需求矩阵Need** 这也是一个n*m的矩阵，用以表示每一个进程尚需的各类资源数。如果Need[i,j]=K，则表示进程i还需要Rj类资源K个，方能完成其任务。`Need[i,j]=Max[i,j]-Allocation[i,j]`\n\n## 原理\n\n我们可以把操作系统看作是银行家，操作系统管理的资源相当于银行家管理的资金，进程向操作系统请求分配资源相当于用户向银行家贷款。\n为保证资金的安全，银行家规定：\n1. 当一个顾客对资金的最大需求量不超过银行家现有的资金时就可接纳该顾客；\n2. 顾客可以分期贷款，但贷款的总数不能超过最大需求量；\n3. 当银行家现有的资金不能满足顾客尚需的贷款数额时，对顾客的贷款可推迟支付，但总能使顾客在有限的时间里得到贷款；\n4. 当顾客得到所需的全部资金后，一定能在有限的时间里归还所有的资金.\n\n操作系统按照银行家制定的规则为进程分配资源，当进程首次申请资源时，要测试该进程对资源的最大需求量，如果系统现存的资源可以满足它的最大需求量则按当前的申请量分配资源，否则就**推迟分配**。当进程在执行中继续申请资源时，先测试该进程本次申请的资源数是否超过了该资源所剩余的总量，若能满足则按当前的申请量分配资源，否则也要**推迟分配**。\n\n## 算法描述\n\n设Request是进程Pi的请求向量，如果 Requesti[j] = K，表示进程Pi需要K个Rj类型的资源。当Pi发出资源请求后，系统按下述步骤进行检査:\n1. 如果 Requesti[j] ≤ Need[i,j]便转向步骤(2)；否则认为出错，因为它所需要的资源数已超过它所宣布的最大值。\n2. 如果 Requesti[j] ≤ Available[j]，便转向步骤(3)；否则，表示尚无足够资源，Pi须等待。\n3. 系统试探着把资源分配给进程Pi，并修改下面数据结构中的数值\n    ```\n    Available[j] = Available[j] - Requesti[j];\n    Allocation[i,j] = Allocation[i,j] + Requesti[j];\n    Need[i,j] = Need[i,j] - Requesti[j];\n    ```\n4. 系统执行安全性算法，检查此次资源分配后系统是否处于安全状态。若安全，才正式将资源分配给进程Pi，以完成本次分配；否则，将本次的试探分配作废，恢复原来的资源分配状态，让进程Pi等待。","source":"_posts/2020-04-26-kongzheng1993-银行家算法.md","raw":"---\ntitle: 银行家算法\nexcerpt: ''\ntags: [多线程, 算法]\ncategories: [多线程]\ncomments: true\ndate: 2020-04-25 00:30:52\n---\n\n## 银行家算法\n\n**银行家算法**（Banker's Algorithm）是一个避免死锁（Deadlock）的著名算法，是由艾兹格·迪杰斯特拉在1965年为T.H.E系统设计的一种避免死锁产生的算法。它以银行借贷系统的分配策略为基础，判断并保证系统的安全运行。\n\n## 来源\n\n在银行中，客户申请贷款的数量是有限的，每个客户在第一次申请贷款时要声明完成该项目所需的最大资金量，在满足所有贷款要求时，客户应及时归还。银行家在客户申请的贷款数量不超过自己拥有的最大值时，都应尽量满足客户的需要。在这样的描述中，银行家就好比操作系统，资金就是资源，客户就相当于要申请资源的进程。\n银行家算法是一种最有代表性的避免死锁的算法。在避免死锁方法中允许进程动态地申请资源，但系统在进行资源分配之前，应先计算此次分配资源的安全性，若分配不会导致系统进入不安全状态，则分配，否则等待。为实现银行家算法，系统必须设置若干数据结构。\n要解释银行家算法，必须先解释**操作系统安全状态**和不安全状态。\n安全序列是指一个进程序列{P1，…，Pn}是安全的，即对于每一个进程Pi(1≤i≤n），它以后尚需要的资源量不超过系统当前剩余资源量与所有进程Pj (j < i )当前占有资源量之和。\n\n### 安全状态\n\n如果存在一个由系统中所有进程构成的安全序列P1，…，Pn，则系统处于安全状态。安全状态一定是没有死锁发生。\n\n### 不安全状态\n\n不存在一个安全序列。不安全状态不一定导致死锁。\n\n## 数据结构\n\n- **可利用资源向量Available** 是个含有m个元素的数组，其中的每一个元素代表一类可利用的资源数目。如果Available[j]=K，则表示系统中现有Rj类资源K个。\n- **最大需求矩阵Max** 这是一个n*m的矩阵，它定义了系统中n个进程中的每一个进程对m类资源的最大需求。如果Max[i,j]=K，则表示进程i需要Rj类资源的最大数目为K。\n- **分配矩阵Allocation** 这也是一个n*m的矩阵，它定义了系统中每一类资源当前已分配给每一进程的资源数。如果Allocation[i,j]=K，则表示进程i当前已分得Rj类资源的 数目为K。\n- **需求矩阵Need** 这也是一个n*m的矩阵，用以表示每一个进程尚需的各类资源数。如果Need[i,j]=K，则表示进程i还需要Rj类资源K个，方能完成其任务。`Need[i,j]=Max[i,j]-Allocation[i,j]`\n\n## 原理\n\n我们可以把操作系统看作是银行家，操作系统管理的资源相当于银行家管理的资金，进程向操作系统请求分配资源相当于用户向银行家贷款。\n为保证资金的安全，银行家规定：\n1. 当一个顾客对资金的最大需求量不超过银行家现有的资金时就可接纳该顾客；\n2. 顾客可以分期贷款，但贷款的总数不能超过最大需求量；\n3. 当银行家现有的资金不能满足顾客尚需的贷款数额时，对顾客的贷款可推迟支付，但总能使顾客在有限的时间里得到贷款；\n4. 当顾客得到所需的全部资金后，一定能在有限的时间里归还所有的资金.\n\n操作系统按照银行家制定的规则为进程分配资源，当进程首次申请资源时，要测试该进程对资源的最大需求量，如果系统现存的资源可以满足它的最大需求量则按当前的申请量分配资源，否则就**推迟分配**。当进程在执行中继续申请资源时，先测试该进程本次申请的资源数是否超过了该资源所剩余的总量，若能满足则按当前的申请量分配资源，否则也要**推迟分配**。\n\n## 算法描述\n\n设Request是进程Pi的请求向量，如果 Requesti[j] = K，表示进程Pi需要K个Rj类型的资源。当Pi发出资源请求后，系统按下述步骤进行检査:\n1. 如果 Requesti[j] ≤ Need[i,j]便转向步骤(2)；否则认为出错，因为它所需要的资源数已超过它所宣布的最大值。\n2. 如果 Requesti[j] ≤ Available[j]，便转向步骤(3)；否则，表示尚无足够资源，Pi须等待。\n3. 系统试探着把资源分配给进程Pi，并修改下面数据结构中的数值\n    ```\n    Available[j] = Available[j] - Requesti[j];\n    Allocation[i,j] = Allocation[i,j] + Requesti[j];\n    Need[i,j] = Need[i,j] - Requesti[j];\n    ```\n4. 系统执行安全性算法，检查此次资源分配后系统是否处于安全状态。若安全，才正式将资源分配给进程Pi，以完成本次分配；否则，将本次的试探分配作废，恢复原来的资源分配状态，让进程Pi等待。","slug":"kongzheng1993-银行家算法","published":1,"updated":"2023-03-08T07:05:58.798Z","layout":"post","photos":[],"link":"","_id":"clg0k2ajl003nt26f1387vxd4","content":"<h2 id=\"银行家算法\"><a href=\"#银行家算法\" class=\"headerlink\" title=\"银行家算法\"></a>银行家算法</h2><p><strong>银行家算法</strong>（Banker’s Algorithm）是一个避免死锁（Deadlock）的著名算法，是由艾兹格·迪杰斯特拉在1965年为T.H.E系统设计的一种避免死锁产生的算法。它以银行借贷系统的分配策略为基础，判断并保证系统的安全运行。</p>\n<h2 id=\"来源\"><a href=\"#来源\" class=\"headerlink\" title=\"来源\"></a>来源</h2><p>在银行中，客户申请贷款的数量是有限的，每个客户在第一次申请贷款时要声明完成该项目所需的最大资金量，在满足所有贷款要求时，客户应及时归还。银行家在客户申请的贷款数量不超过自己拥有的最大值时，都应尽量满足客户的需要。在这样的描述中，银行家就好比操作系统，资金就是资源，客户就相当于要申请资源的进程。<br>银行家算法是一种最有代表性的避免死锁的算法。在避免死锁方法中允许进程动态地申请资源，但系统在进行资源分配之前，应先计算此次分配资源的安全性，若分配不会导致系统进入不安全状态，则分配，否则等待。为实现银行家算法，系统必须设置若干数据结构。<br>要解释银行家算法，必须先解释<strong>操作系统安全状态</strong>和不安全状态。<br>安全序列是指一个进程序列{P1，…，Pn}是安全的，即对于每一个进程Pi(1≤i≤n），它以后尚需要的资源量不超过系统当前剩余资源量与所有进程Pj (j &lt; i )当前占有资源量之和。</p>\n<h3 id=\"安全状态\"><a href=\"#安全状态\" class=\"headerlink\" title=\"安全状态\"></a>安全状态</h3><p>如果存在一个由系统中所有进程构成的安全序列P1，…，Pn，则系统处于安全状态。安全状态一定是没有死锁发生。</p>\n<h3 id=\"不安全状态\"><a href=\"#不安全状态\" class=\"headerlink\" title=\"不安全状态\"></a>不安全状态</h3><p>不存在一个安全序列。不安全状态不一定导致死锁。</p>\n<h2 id=\"数据结构\"><a href=\"#数据结构\" class=\"headerlink\" title=\"数据结构\"></a>数据结构</h2><ul>\n<li><strong>可利用资源向量Available</strong> 是个含有m个元素的数组，其中的每一个元素代表一类可利用的资源数目。如果Available[j]=K，则表示系统中现有Rj类资源K个。</li>\n<li><strong>最大需求矩阵Max</strong> 这是一个n*m的矩阵，它定义了系统中n个进程中的每一个进程对m类资源的最大需求。如果Max[i,j]=K，则表示进程i需要Rj类资源的最大数目为K。</li>\n<li><strong>分配矩阵Allocation</strong> 这也是一个n*m的矩阵，它定义了系统中每一类资源当前已分配给每一进程的资源数。如果Allocation[i,j]=K，则表示进程i当前已分得Rj类资源的 数目为K。</li>\n<li><strong>需求矩阵Need</strong> 这也是一个n*m的矩阵，用以表示每一个进程尚需的各类资源数。如果Need[i,j]=K，则表示进程i还需要Rj类资源K个，方能完成其任务。<code>Need[i,j]=Max[i,j]-Allocation[i,j]</code></li>\n</ul>\n<h2 id=\"原理\"><a href=\"#原理\" class=\"headerlink\" title=\"原理\"></a>原理</h2><p>我们可以把操作系统看作是银行家，操作系统管理的资源相当于银行家管理的资金，进程向操作系统请求分配资源相当于用户向银行家贷款。<br>为保证资金的安全，银行家规定：</p>\n<ol>\n<li>当一个顾客对资金的最大需求量不超过银行家现有的资金时就可接纳该顾客；</li>\n<li>顾客可以分期贷款，但贷款的总数不能超过最大需求量；</li>\n<li>当银行家现有的资金不能满足顾客尚需的贷款数额时，对顾客的贷款可推迟支付，但总能使顾客在有限的时间里得到贷款；</li>\n<li>当顾客得到所需的全部资金后，一定能在有限的时间里归还所有的资金.</li>\n</ol>\n<p>操作系统按照银行家制定的规则为进程分配资源，当进程首次申请资源时，要测试该进程对资源的最大需求量，如果系统现存的资源可以满足它的最大需求量则按当前的申请量分配资源，否则就<strong>推迟分配</strong>。当进程在执行中继续申请资源时，先测试该进程本次申请的资源数是否超过了该资源所剩余的总量，若能满足则按当前的申请量分配资源，否则也要<strong>推迟分配</strong>。</p>\n<h2 id=\"算法描述\"><a href=\"#算法描述\" class=\"headerlink\" title=\"算法描述\"></a>算法描述</h2><p>设Request是进程Pi的请求向量，如果 Requesti[j] = K，表示进程Pi需要K个Rj类型的资源。当Pi发出资源请求后，系统按下述步骤进行检査:</p>\n<ol>\n<li>如果 Requesti[j] ≤ Need[i,j]便转向步骤(2)；否则认为出错，因为它所需要的资源数已超过它所宣布的最大值。</li>\n<li>如果 Requesti[j] ≤ Available[j]，便转向步骤(3)；否则，表示尚无足够资源，Pi须等待。</li>\n<li>系统试探着把资源分配给进程Pi，并修改下面数据结构中的数值<pre><code> Available[j] = Available[j] - Requesti[j];\n Allocation[i,j] = Allocation[i,j] + Requesti[j];\n Need[i,j] = Need[i,j] - Requesti[j];</code></pre></li>\n<li>系统执行安全性算法，检查此次资源分配后系统是否处于安全状态。若安全，才正式将资源分配给进程Pi，以完成本次分配；否则，将本次的试探分配作废，恢复原来的资源分配状态，让进程Pi等待。</li>\n</ol>\n","site":{"data":{}},"more":"<h2 id=\"银行家算法\"><a href=\"#银行家算法\" class=\"headerlink\" title=\"银行家算法\"></a>银行家算法</h2><p><strong>银行家算法</strong>（Banker’s Algorithm）是一个避免死锁（Deadlock）的著名算法，是由艾兹格·迪杰斯特拉在1965年为T.H.E系统设计的一种避免死锁产生的算法。它以银行借贷系统的分配策略为基础，判断并保证系统的安全运行。</p>\n<h2 id=\"来源\"><a href=\"#来源\" class=\"headerlink\" title=\"来源\"></a>来源</h2><p>在银行中，客户申请贷款的数量是有限的，每个客户在第一次申请贷款时要声明完成该项目所需的最大资金量，在满足所有贷款要求时，客户应及时归还。银行家在客户申请的贷款数量不超过自己拥有的最大值时，都应尽量满足客户的需要。在这样的描述中，银行家就好比操作系统，资金就是资源，客户就相当于要申请资源的进程。<br>银行家算法是一种最有代表性的避免死锁的算法。在避免死锁方法中允许进程动态地申请资源，但系统在进行资源分配之前，应先计算此次分配资源的安全性，若分配不会导致系统进入不安全状态，则分配，否则等待。为实现银行家算法，系统必须设置若干数据结构。<br>要解释银行家算法，必须先解释<strong>操作系统安全状态</strong>和不安全状态。<br>安全序列是指一个进程序列{P1，…，Pn}是安全的，即对于每一个进程Pi(1≤i≤n），它以后尚需要的资源量不超过系统当前剩余资源量与所有进程Pj (j &lt; i )当前占有资源量之和。</p>\n<h3 id=\"安全状态\"><a href=\"#安全状态\" class=\"headerlink\" title=\"安全状态\"></a>安全状态</h3><p>如果存在一个由系统中所有进程构成的安全序列P1，…，Pn，则系统处于安全状态。安全状态一定是没有死锁发生。</p>\n<h3 id=\"不安全状态\"><a href=\"#不安全状态\" class=\"headerlink\" title=\"不安全状态\"></a>不安全状态</h3><p>不存在一个安全序列。不安全状态不一定导致死锁。</p>\n<h2 id=\"数据结构\"><a href=\"#数据结构\" class=\"headerlink\" title=\"数据结构\"></a>数据结构</h2><ul>\n<li><strong>可利用资源向量Available</strong> 是个含有m个元素的数组，其中的每一个元素代表一类可利用的资源数目。如果Available[j]=K，则表示系统中现有Rj类资源K个。</li>\n<li><strong>最大需求矩阵Max</strong> 这是一个n*m的矩阵，它定义了系统中n个进程中的每一个进程对m类资源的最大需求。如果Max[i,j]=K，则表示进程i需要Rj类资源的最大数目为K。</li>\n<li><strong>分配矩阵Allocation</strong> 这也是一个n*m的矩阵，它定义了系统中每一类资源当前已分配给每一进程的资源数。如果Allocation[i,j]=K，则表示进程i当前已分得Rj类资源的 数目为K。</li>\n<li><strong>需求矩阵Need</strong> 这也是一个n*m的矩阵，用以表示每一个进程尚需的各类资源数。如果Need[i,j]=K，则表示进程i还需要Rj类资源K个，方能完成其任务。<code>Need[i,j]=Max[i,j]-Allocation[i,j]</code></li>\n</ul>\n<h2 id=\"原理\"><a href=\"#原理\" class=\"headerlink\" title=\"原理\"></a>原理</h2><p>我们可以把操作系统看作是银行家，操作系统管理的资源相当于银行家管理的资金，进程向操作系统请求分配资源相当于用户向银行家贷款。<br>为保证资金的安全，银行家规定：</p>\n<ol>\n<li>当一个顾客对资金的最大需求量不超过银行家现有的资金时就可接纳该顾客；</li>\n<li>顾客可以分期贷款，但贷款的总数不能超过最大需求量；</li>\n<li>当银行家现有的资金不能满足顾客尚需的贷款数额时，对顾客的贷款可推迟支付，但总能使顾客在有限的时间里得到贷款；</li>\n<li>当顾客得到所需的全部资金后，一定能在有限的时间里归还所有的资金.</li>\n</ol>\n<p>操作系统按照银行家制定的规则为进程分配资源，当进程首次申请资源时，要测试该进程对资源的最大需求量，如果系统现存的资源可以满足它的最大需求量则按当前的申请量分配资源，否则就<strong>推迟分配</strong>。当进程在执行中继续申请资源时，先测试该进程本次申请的资源数是否超过了该资源所剩余的总量，若能满足则按当前的申请量分配资源，否则也要<strong>推迟分配</strong>。</p>\n<h2 id=\"算法描述\"><a href=\"#算法描述\" class=\"headerlink\" title=\"算法描述\"></a>算法描述</h2><p>设Request是进程Pi的请求向量，如果 Requesti[j] = K，表示进程Pi需要K个Rj类型的资源。当Pi发出资源请求后，系统按下述步骤进行检査:</p>\n<ol>\n<li>如果 Requesti[j] ≤ Need[i,j]便转向步骤(2)；否则认为出错，因为它所需要的资源数已超过它所宣布的最大值。</li>\n<li>如果 Requesti[j] ≤ Available[j]，便转向步骤(3)；否则，表示尚无足够资源，Pi须等待。</li>\n<li>系统试探着把资源分配给进程Pi，并修改下面数据结构中的数值<pre><code> Available[j] = Available[j] - Requesti[j];\n Allocation[i,j] = Allocation[i,j] + Requesti[j];\n Need[i,j] = Need[i,j] - Requesti[j];</code></pre></li>\n<li>系统执行安全性算法，检查此次资源分配后系统是否处于安全状态。若安全，才正式将资源分配给进程Pi，以完成本次分配；否则，将本次的试探分配作废，恢复原来的资源分配状态，让进程Pi等待。</li>\n</ol>\n"},{"title":"springboot devtools","excerpt":"","comments":1,"date":"2020-04-27T16:30:52.000Z","_content":"\n## devtools是什么\n\ndebug代码的时候，发现是个小bug，都不值得劳资手动重启应用怎么办？\n\nspringboot提供了一个`spring-boot-devtools`的工具，让我们在上述场景中提升效率。\n\n它可以监控`classpath`下的资源，一旦classpath下有变动，就会触发应用重启。\n\n## 如何使用devtools\n\n在项目中添加`spring-boot-devtools`依赖：\n\n```xml\n<dependencies>\n    <dependency>\n        <groupId>org.springframework.boot</groupId>\n        <artifactId>spring-boot-devtools</artifactId>\n        <optional>true</optional>\n    </dependency>\n</dependencies>\n```\n\n这里设置optional为true，是因为`spring-boot-devtools`一般只使用于开发环境，在生产环境是需要禁用的。这样我们通过`java -jar`去启动应用，就不会启用devtools了，当然也可以防止devtools传递给依赖本应用的应用。\n\n#### 如何触发应用重启？\n\nEclipse，对源文件修改并保存，就会触发重启。\nIDEA，构建项目触发重启，`Build -> Build Project`。\n\n当然如果你的机器配置高，IDEA勾选下图选项，可以在你修改文件后一定时间自动重启。\n\n<img src=\"截屏2020-04-28下午6.51.22.png\">\n\n机器好可以这么玩，性能差就算了，因为devtools重启的时候，你的机器可能还没变编译完，就是起来了，也是个不完整的应用，比如controller没加载，调接口直接404……**不要问我为什么知道，问就是我踩过**。\n\n不过这也能操作，毕竟原因我们知道了，就是还没构建完成，devtools就重启了呗，那咱们就让devtools晚会儿重启呗。。\n\n```yml\nspring:\n    devtools:\n        restart:\n            poll-interval: 3s\n```\n\n这里设置devtools检测周期长一点，我3s够了，你不够再长点呗。。\n\n**有几点需要注意：**\n- devtools 将会使用独立的类加载器。\n- devtools 依赖应用程序关闭钩子，如果你的应用禁用了关闭钩子（SpringApplication.setRegisterShutdownHook(false)），devtools 将会失效。\n- 在决定是否应该触发重启时，devtools 将会自动忽略名为 spring-boot ， spring-boot-devtools ， spring-boot-autoconfigure ， spring-boot-actuator 和 spring-boot-starter 的项目。\n\n\n\n","source":"_posts/2020-04-28-kongzheng1993-devtools.md","raw":"---\ntitle: springboot devtools\nexcerpt: ''\ntags: [tools, Java]\ncategories: [Java]\ncomments: true\ndate: 2020-04-28 00:30:52\n---\n\n## devtools是什么\n\ndebug代码的时候，发现是个小bug，都不值得劳资手动重启应用怎么办？\n\nspringboot提供了一个`spring-boot-devtools`的工具，让我们在上述场景中提升效率。\n\n它可以监控`classpath`下的资源，一旦classpath下有变动，就会触发应用重启。\n\n## 如何使用devtools\n\n在项目中添加`spring-boot-devtools`依赖：\n\n```xml\n<dependencies>\n    <dependency>\n        <groupId>org.springframework.boot</groupId>\n        <artifactId>spring-boot-devtools</artifactId>\n        <optional>true</optional>\n    </dependency>\n</dependencies>\n```\n\n这里设置optional为true，是因为`spring-boot-devtools`一般只使用于开发环境，在生产环境是需要禁用的。这样我们通过`java -jar`去启动应用，就不会启用devtools了，当然也可以防止devtools传递给依赖本应用的应用。\n\n#### 如何触发应用重启？\n\nEclipse，对源文件修改并保存，就会触发重启。\nIDEA，构建项目触发重启，`Build -> Build Project`。\n\n当然如果你的机器配置高，IDEA勾选下图选项，可以在你修改文件后一定时间自动重启。\n\n<img src=\"截屏2020-04-28下午6.51.22.png\">\n\n机器好可以这么玩，性能差就算了，因为devtools重启的时候，你的机器可能还没变编译完，就是起来了，也是个不完整的应用，比如controller没加载，调接口直接404……**不要问我为什么知道，问就是我踩过**。\n\n不过这也能操作，毕竟原因我们知道了，就是还没构建完成，devtools就重启了呗，那咱们就让devtools晚会儿重启呗。。\n\n```yml\nspring:\n    devtools:\n        restart:\n            poll-interval: 3s\n```\n\n这里设置devtools检测周期长一点，我3s够了，你不够再长点呗。。\n\n**有几点需要注意：**\n- devtools 将会使用独立的类加载器。\n- devtools 依赖应用程序关闭钩子，如果你的应用禁用了关闭钩子（SpringApplication.setRegisterShutdownHook(false)），devtools 将会失效。\n- 在决定是否应该触发重启时，devtools 将会自动忽略名为 spring-boot ， spring-boot-devtools ， spring-boot-autoconfigure ， spring-boot-actuator 和 spring-boot-starter 的项目。\n\n\n\n","slug":"kongzheng1993-devtools","published":1,"updated":"2023-03-08T07:05:58.798Z","layout":"post","photos":[],"link":"","_id":"clg0k2ajq003qt26fm252khmm","content":"<h2 id=\"devtools是什么\"><a href=\"#devtools是什么\" class=\"headerlink\" title=\"devtools是什么\"></a>devtools是什么</h2><p>debug代码的时候，发现是个小bug，都不值得劳资手动重启应用怎么办？</p>\n<p>springboot提供了一个<code>spring-boot-devtools</code>的工具，让我们在上述场景中提升效率。</p>\n<p>它可以监控<code>classpath</code>下的资源，一旦classpath下有变动，就会触发应用重启。</p>\n<h2 id=\"如何使用devtools\"><a href=\"#如何使用devtools\" class=\"headerlink\" title=\"如何使用devtools\"></a>如何使用devtools</h2><p>在项目中添加<code>spring-boot-devtools</code>依赖：</p>\n<pre><code class=\"xml\">&lt;dependencies&gt;\n    &lt;dependency&gt;\n        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n        &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt;\n        &lt;optional&gt;true&lt;/optional&gt;\n    &lt;/dependency&gt;\n&lt;/dependencies&gt;</code></pre>\n<p>这里设置optional为true，是因为<code>spring-boot-devtools</code>一般只使用于开发环境，在生产环境是需要禁用的。这样我们通过<code>java -jar</code>去启动应用，就不会启用devtools了，当然也可以防止devtools传递给依赖本应用的应用。</p>\n<h4 id=\"如何触发应用重启？\"><a href=\"#如何触发应用重启？\" class=\"headerlink\" title=\"如何触发应用重启？\"></a>如何触发应用重启？</h4><p>Eclipse，对源文件修改并保存，就会触发重启。<br>IDEA，构建项目触发重启，<code>Build -&gt; Build Project</code>。</p>\n<p>当然如果你的机器配置高，IDEA勾选下图选项，可以在你修改文件后一定时间自动重启。</p>\n<img src=\"/2020/04/28/kongzheng1993-devtools/截屏2020-04-28下午6.51.22.png\">\n\n<p>机器好可以这么玩，性能差就算了，因为devtools重启的时候，你的机器可能还没变编译完，就是起来了，也是个不完整的应用，比如controller没加载，调接口直接404……<strong>不要问我为什么知道，问就是我踩过</strong>。</p>\n<p>不过这也能操作，毕竟原因我们知道了，就是还没构建完成，devtools就重启了呗，那咱们就让devtools晚会儿重启呗。。</p>\n<pre><code class=\"yml\">spring:\n    devtools:\n        restart:\n            poll-interval: 3s</code></pre>\n<p>这里设置devtools检测周期长一点，我3s够了，你不够再长点呗。。</p>\n<p><strong>有几点需要注意：</strong></p>\n<ul>\n<li>devtools 将会使用独立的类加载器。</li>\n<li>devtools 依赖应用程序关闭钩子，如果你的应用禁用了关闭钩子（SpringApplication.setRegisterShutdownHook(false)），devtools 将会失效。</li>\n<li>在决定是否应该触发重启时，devtools 将会自动忽略名为 spring-boot ， spring-boot-devtools ， spring-boot-autoconfigure ， spring-boot-actuator 和 spring-boot-starter 的项目。</li>\n</ul>\n","site":{"data":{}},"more":"<h2 id=\"devtools是什么\"><a href=\"#devtools是什么\" class=\"headerlink\" title=\"devtools是什么\"></a>devtools是什么</h2><p>debug代码的时候，发现是个小bug，都不值得劳资手动重启应用怎么办？</p>\n<p>springboot提供了一个<code>spring-boot-devtools</code>的工具，让我们在上述场景中提升效率。</p>\n<p>它可以监控<code>classpath</code>下的资源，一旦classpath下有变动，就会触发应用重启。</p>\n<h2 id=\"如何使用devtools\"><a href=\"#如何使用devtools\" class=\"headerlink\" title=\"如何使用devtools\"></a>如何使用devtools</h2><p>在项目中添加<code>spring-boot-devtools</code>依赖：</p>\n<pre><code class=\"xml\">&lt;dependencies&gt;\n    &lt;dependency&gt;\n        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n        &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt;\n        &lt;optional&gt;true&lt;/optional&gt;\n    &lt;/dependency&gt;\n&lt;/dependencies&gt;</code></pre>\n<p>这里设置optional为true，是因为<code>spring-boot-devtools</code>一般只使用于开发环境，在生产环境是需要禁用的。这样我们通过<code>java -jar</code>去启动应用，就不会启用devtools了，当然也可以防止devtools传递给依赖本应用的应用。</p>\n<h4 id=\"如何触发应用重启？\"><a href=\"#如何触发应用重启？\" class=\"headerlink\" title=\"如何触发应用重启？\"></a>如何触发应用重启？</h4><p>Eclipse，对源文件修改并保存，就会触发重启。<br>IDEA，构建项目触发重启，<code>Build -&gt; Build Project</code>。</p>\n<p>当然如果你的机器配置高，IDEA勾选下图选项，可以在你修改文件后一定时间自动重启。</p>\n<img src=\"/2020/04/28/kongzheng1993-devtools/截屏2020-04-28下午6.51.22.png\">\n\n<p>机器好可以这么玩，性能差就算了，因为devtools重启的时候，你的机器可能还没变编译完，就是起来了，也是个不完整的应用，比如controller没加载，调接口直接404……<strong>不要问我为什么知道，问就是我踩过</strong>。</p>\n<p>不过这也能操作，毕竟原因我们知道了，就是还没构建完成，devtools就重启了呗，那咱们就让devtools晚会儿重启呗。。</p>\n<pre><code class=\"yml\">spring:\n    devtools:\n        restart:\n            poll-interval: 3s</code></pre>\n<p>这里设置devtools检测周期长一点，我3s够了，你不够再长点呗。。</p>\n<p><strong>有几点需要注意：</strong></p>\n<ul>\n<li>devtools 将会使用独立的类加载器。</li>\n<li>devtools 依赖应用程序关闭钩子，如果你的应用禁用了关闭钩子（SpringApplication.setRegisterShutdownHook(false)），devtools 将会失效。</li>\n<li>在决定是否应该触发重启时，devtools 将会自动忽略名为 spring-boot ， spring-boot-devtools ， spring-boot-autoconfigure ， spring-boot-actuator 和 spring-boot-starter 的项目。</li>\n</ul>\n"},{"title":"死锁","excerpt":"","comments":1,"date":"2020-04-24T16:30:52.000Z","_content":"\n## 什么是死锁\n\n<img src=\"v2-fccd6ccc07c0caf2643f324cdb7856e7_b.jpg\">\n\n死锁的本质，举个例子如果此时有一个线程 A ，按照先获持有锁 a 再获取锁 b的顺序获得锁，同时另外一个线程 B，按照先获取锁 b 再获取锁 a 的顺序获取锁。它们都像申请对方的资源却不得，所以会相互等待，进入死锁状态。\n\n## 条件\n\n产生死锁必须具备以下四个条件：\n\n- **互斥条件**：该资源同一时刻只能由一个线程占用。\n- **请求与保持条件**：一个进程因为请求资源而阻塞时，不会释放已经获得的资源。\n- **不可剥夺条件**：线程已经获得的资源在未主动释放前不能被其他线程强行剥夺。\n- **循环等待条件**：若干个线程之间形成一种头尾相接的循环等待资源关系。\n\n## 如何避免死锁问题\n\n我们只要破坏了死锁必须的四个条件之一就可以避免产生死锁问题。\n\n- 破坏互斥条件：这里很难做到，毕竟线程安全问题就是要让线程对资源的访问互斥，不然干嘛用锁呢。\n- 破坏请求与保持条件：可以让线程一次性申请到它需要的全部资源。这样会严重降低资源利用率。\n- 破坏不可剥夺条件：申请新的资源前先释放掉之前占有的资源，如果后面还需要之前的资源，到时候再申请。也可以在申请新资源时判断，申请到继续执行，申请不到主动释放持有的资源，不要阻塞其他线程。\n- 破坏循环等待条件：资源排序，按照一定的顺序申请资源，反序释放资源。\n  \n## 排查死锁问题\n\n1. `jps`或`ps -ef | grep java`查看java进程\n2. `jstack`查看线程堆栈信息，如果有`Found one Java-level deadlock`等字样，表示我们写的程序发生了死锁。查看并记录发生死锁等代码位置。\n3. 优化代码。\n\n**其他工具：**\n\n- **jconsole**：jdk提供了一个可视化等工具，可以排查一些程序问题\n- **jvisualvm**：jdk提供等可视化问题排查工具。可以生成dump来查看堆栈信息。","source":"_posts/2020-04-25-kongzheng1993-死锁.md","raw":"---\ntitle: 死锁\nexcerpt: ''\ntags: [多线程]\ncategories: [多线程]\ncomments: true\ndate: 2020-04-25 00:30:52\n---\n\n## 什么是死锁\n\n<img src=\"v2-fccd6ccc07c0caf2643f324cdb7856e7_b.jpg\">\n\n死锁的本质，举个例子如果此时有一个线程 A ，按照先获持有锁 a 再获取锁 b的顺序获得锁，同时另外一个线程 B，按照先获取锁 b 再获取锁 a 的顺序获取锁。它们都像申请对方的资源却不得，所以会相互等待，进入死锁状态。\n\n## 条件\n\n产生死锁必须具备以下四个条件：\n\n- **互斥条件**：该资源同一时刻只能由一个线程占用。\n- **请求与保持条件**：一个进程因为请求资源而阻塞时，不会释放已经获得的资源。\n- **不可剥夺条件**：线程已经获得的资源在未主动释放前不能被其他线程强行剥夺。\n- **循环等待条件**：若干个线程之间形成一种头尾相接的循环等待资源关系。\n\n## 如何避免死锁问题\n\n我们只要破坏了死锁必须的四个条件之一就可以避免产生死锁问题。\n\n- 破坏互斥条件：这里很难做到，毕竟线程安全问题就是要让线程对资源的访问互斥，不然干嘛用锁呢。\n- 破坏请求与保持条件：可以让线程一次性申请到它需要的全部资源。这样会严重降低资源利用率。\n- 破坏不可剥夺条件：申请新的资源前先释放掉之前占有的资源，如果后面还需要之前的资源，到时候再申请。也可以在申请新资源时判断，申请到继续执行，申请不到主动释放持有的资源，不要阻塞其他线程。\n- 破坏循环等待条件：资源排序，按照一定的顺序申请资源，反序释放资源。\n  \n## 排查死锁问题\n\n1. `jps`或`ps -ef | grep java`查看java进程\n2. `jstack`查看线程堆栈信息，如果有`Found one Java-level deadlock`等字样，表示我们写的程序发生了死锁。查看并记录发生死锁等代码位置。\n3. 优化代码。\n\n**其他工具：**\n\n- **jconsole**：jdk提供了一个可视化等工具，可以排查一些程序问题\n- **jvisualvm**：jdk提供等可视化问题排查工具。可以生成dump来查看堆栈信息。","slug":"kongzheng1993-死锁","published":1,"updated":"2023-03-08T07:05:58.798Z","layout":"post","photos":[],"link":"","_id":"clg0k2aju003tt26fst305u6t","content":"<h2 id=\"什么是死锁\"><a href=\"#什么是死锁\" class=\"headerlink\" title=\"什么是死锁\"></a>什么是死锁</h2><img src=\"/2020/04/25/kongzheng1993-死锁/v2-fccd6ccc07c0caf2643f324cdb7856e7_b.jpg\">\n\n<p>死锁的本质，举个例子如果此时有一个线程 A ，按照先获持有锁 a 再获取锁 b的顺序获得锁，同时另外一个线程 B，按照先获取锁 b 再获取锁 a 的顺序获取锁。它们都像申请对方的资源却不得，所以会相互等待，进入死锁状态。</p>\n<h2 id=\"条件\"><a href=\"#条件\" class=\"headerlink\" title=\"条件\"></a>条件</h2><p>产生死锁必须具备以下四个条件：</p>\n<ul>\n<li><strong>互斥条件</strong>：该资源同一时刻只能由一个线程占用。</li>\n<li><strong>请求与保持条件</strong>：一个进程因为请求资源而阻塞时，不会释放已经获得的资源。</li>\n<li><strong>不可剥夺条件</strong>：线程已经获得的资源在未主动释放前不能被其他线程强行剥夺。</li>\n<li><strong>循环等待条件</strong>：若干个线程之间形成一种头尾相接的循环等待资源关系。</li>\n</ul>\n<h2 id=\"如何避免死锁问题\"><a href=\"#如何避免死锁问题\" class=\"headerlink\" title=\"如何避免死锁问题\"></a>如何避免死锁问题</h2><p>我们只要破坏了死锁必须的四个条件之一就可以避免产生死锁问题。</p>\n<ul>\n<li>破坏互斥条件：这里很难做到，毕竟线程安全问题就是要让线程对资源的访问互斥，不然干嘛用锁呢。</li>\n<li>破坏请求与保持条件：可以让线程一次性申请到它需要的全部资源。这样会严重降低资源利用率。</li>\n<li>破坏不可剥夺条件：申请新的资源前先释放掉之前占有的资源，如果后面还需要之前的资源，到时候再申请。也可以在申请新资源时判断，申请到继续执行，申请不到主动释放持有的资源，不要阻塞其他线程。</li>\n<li>破坏循环等待条件：资源排序，按照一定的顺序申请资源，反序释放资源。</li>\n</ul>\n<h2 id=\"排查死锁问题\"><a href=\"#排查死锁问题\" class=\"headerlink\" title=\"排查死锁问题\"></a>排查死锁问题</h2><ol>\n<li><code>jps</code>或<code>ps -ef | grep java</code>查看java进程</li>\n<li><code>jstack</code>查看线程堆栈信息，如果有<code>Found one Java-level deadlock</code>等字样，表示我们写的程序发生了死锁。查看并记录发生死锁等代码位置。</li>\n<li>优化代码。</li>\n</ol>\n<p><strong>其他工具：</strong></p>\n<ul>\n<li><strong>jconsole</strong>：jdk提供了一个可视化等工具，可以排查一些程序问题</li>\n<li><strong>jvisualvm</strong>：jdk提供等可视化问题排查工具。可以生成dump来查看堆栈信息。</li>\n</ul>\n","site":{"data":{}},"more":"<h2 id=\"什么是死锁\"><a href=\"#什么是死锁\" class=\"headerlink\" title=\"什么是死锁\"></a>什么是死锁</h2><img src=\"/2020/04/25/kongzheng1993-死锁/v2-fccd6ccc07c0caf2643f324cdb7856e7_b.jpg\">\n\n<p>死锁的本质，举个例子如果此时有一个线程 A ，按照先获持有锁 a 再获取锁 b的顺序获得锁，同时另外一个线程 B，按照先获取锁 b 再获取锁 a 的顺序获取锁。它们都像申请对方的资源却不得，所以会相互等待，进入死锁状态。</p>\n<h2 id=\"条件\"><a href=\"#条件\" class=\"headerlink\" title=\"条件\"></a>条件</h2><p>产生死锁必须具备以下四个条件：</p>\n<ul>\n<li><strong>互斥条件</strong>：该资源同一时刻只能由一个线程占用。</li>\n<li><strong>请求与保持条件</strong>：一个进程因为请求资源而阻塞时，不会释放已经获得的资源。</li>\n<li><strong>不可剥夺条件</strong>：线程已经获得的资源在未主动释放前不能被其他线程强行剥夺。</li>\n<li><strong>循环等待条件</strong>：若干个线程之间形成一种头尾相接的循环等待资源关系。</li>\n</ul>\n<h2 id=\"如何避免死锁问题\"><a href=\"#如何避免死锁问题\" class=\"headerlink\" title=\"如何避免死锁问题\"></a>如何避免死锁问题</h2><p>我们只要破坏了死锁必须的四个条件之一就可以避免产生死锁问题。</p>\n<ul>\n<li>破坏互斥条件：这里很难做到，毕竟线程安全问题就是要让线程对资源的访问互斥，不然干嘛用锁呢。</li>\n<li>破坏请求与保持条件：可以让线程一次性申请到它需要的全部资源。这样会严重降低资源利用率。</li>\n<li>破坏不可剥夺条件：申请新的资源前先释放掉之前占有的资源，如果后面还需要之前的资源，到时候再申请。也可以在申请新资源时判断，申请到继续执行，申请不到主动释放持有的资源，不要阻塞其他线程。</li>\n<li>破坏循环等待条件：资源排序，按照一定的顺序申请资源，反序释放资源。</li>\n</ul>\n<h2 id=\"排查死锁问题\"><a href=\"#排查死锁问题\" class=\"headerlink\" title=\"排查死锁问题\"></a>排查死锁问题</h2><ol>\n<li><code>jps</code>或<code>ps -ef | grep java</code>查看java进程</li>\n<li><code>jstack</code>查看线程堆栈信息，如果有<code>Found one Java-level deadlock</code>等字样，表示我们写的程序发生了死锁。查看并记录发生死锁等代码位置。</li>\n<li>优化代码。</li>\n</ol>\n<p><strong>其他工具：</strong></p>\n<ul>\n<li><strong>jconsole</strong>：jdk提供了一个可视化等工具，可以排查一些程序问题</li>\n<li><strong>jvisualvm</strong>：jdk提供等可视化问题排查工具。可以生成dump来查看堆栈信息。</li>\n</ul>\n"},{"title":"java.lang.IllegalMonitorStateException","excerpt":"","comments":1,"date":"2020-04-26T16:30:52.000Z","_content":"\n## java.lang.IllegalMonitorStateException\n\n从JDK源码开始看：\n\n```java\n/**\n * Thrown to indicate that a thread has attempted to wait on an\n * object's monitor or to notify other threads waiting on an object's\n * monitor without owning the specified monitor.\n *\n * @author  unascribed\n * @see     java.lang.Object#notify()\n * @see     java.lang.Object#notifyAll()\n * @see     java.lang.Object#wait()\n * @see     java.lang.Object#wait(long)\n * @see     java.lang.Object#wait(long, int)\n * @since   JDK1.0\n */\npublic\nclass IllegalMonitorStateException extends RuntimeException {\n    private static final long serialVersionUID = 3713306369498869069L;\n\n    /**\n     * Constructs an <code>IllegalMonitorStateException</code> with no\n     * detail message.\n     */\n    public IllegalMonitorStateException() {\n        super();\n    }\n\n    /**\n     * Constructs an <code>IllegalMonitorStateException</code> with the\n     * specified detail message.\n     *\n     * @param   s   the detail message.\n     */\n    public IllegalMonitorStateException(String s) {\n        super(s);\n    }\n}\n```\n\n从注释部分可以了解到：当我们在没有拥有指定对象的监视器时，就去等待这个对象的监视器或者通知其他线程去等待这个对象的监视器，就会抛出`IllegalMonitorStateException`。\n\n换句话说，我们要想调用一个对象的`wait()`、`notify()`等方法来实现线程通信，就要先获取这个对象的监视器。也就是要用`synchronized`修饰这个代码块。\n\n我们知道`synchronized`修饰的代码块编译后会被`monitorenter`和`monitorexit`包围，这两个虚拟机命令就是获取和释放对象的监视器。\n\n所以Object自带的`wait()`、`notify()`等方法，是让我们在使用`synchronized`时进行线程通信用的。\n\n```java\nimport java.lang.Runnable;\nimport java.util.concurrent.locks.Lock;\nimport java.util.concurrent.locks.ReentrantLock;\n\npublic class Test {\n\n    private int i = 0;\n\n    Object obj = new Object();\n\n    public void odd() {\n        synchronized (obj) {\n            while (i < 3) {\n                if (i % 2 == 1) {\n                    System.out.println(Thread.currentThread().getName() + \"打印：\" + i);\n                    i++;\n                    System.out.println(\"odd before notify\");\n                    obj.notify();\n                    System.out.println(\"odd after notify\");\n                } else {\n                    try {\n                        System.out.println(\"odd before wait\");\n                        obj.wait();\n                        System.out.println(\"odd after wait\");\n                    } catch (Exception e) {\n\n                    }\n                }\n                System.out.println(\"odd exit while\");\n            }\n            System.out.println(\"odd exit synchronized\");\n        }\n    }\n\n    public void even() {\n        synchronized (obj) {\n            while (i < 3) {\n                if (i % 2 == 0) {\n                    System.out.println(Thread.currentThread().getName() + \"打印：\" + i);\n                    i++;\n                    System.out.println(\"even before notify\");\n                    obj.notify();\n                    System.out.println(\"even after notify\");\n                } else {\n                    try {\n                        System.out.println(\"even before wait\");\n                        obj.wait();\n                        System.out.println(\"even after wait\");\n                    } catch (Exception e) {\n\n                    }\n                }\n                System.out.println(\"even exit while\");\n            }\n            System.out.println(\"even exit synchronized\");\n        }\n    }\n\n    public static void main(String[] args) {\n\n        Test test = new Test();\n\n        Thread thread1 = new Thread(new Runnable() {\n\n            @Override\n            public void run() {\n                test.odd();\n            }\n        }, \"奇数\");\n\n        Thread thread2 = new Thread(new Runnable() {\n\n            @Override\n            public void run() {\n                test.even();\n            }\n        }, \"偶数\");\n\n        thread1.start();\n        thread2.start();\n    }\n}\n```\n\n运行结果：\n\n```\nodd before wait\n偶数打印：0\neven before notify\neven after notify\neven exit while\neven before wait\nodd after wait\nodd exit while\n奇数打印：1\nodd before notify\nodd after notify\nodd exit while\nodd before wait\neven after wait\neven exit while\n偶数打印：2\neven before notify\neven after notify\neven exit while\neven exit synchronized\nodd after wait\nodd exit while\nodd exit synchronized\n```\n\n- **wait()**：使当前执行代码的线程进行等待，wait()方法是Object类的方法，该方法用来将当前线程置入“预执行队列”中，并且在wait()所在的代码行处停止执行，直到接到通知或被中断为止。在调用wait()之前，线程必须获得该对象的对象级别锁，即只能在同步方法或同步块中调用wait()方法。在执行wait()方法后，当前线程释放锁。在从wait()返回前，线程与其他线程竞争重新获得锁。如果调用wait()方法时没有持有适当的锁，则抛出IllegalMonitorStateException异常,它是RuntimeException的一个子类，因此，不需要try-catch语句进行捕捉异常。\n\n- **notify()**：也要在同步方法或同步块中调用，即在调用前，线程也必须获得该对象的对象级别锁。如调用notify()时没有持有适当的锁，也会抛出IllegalMonitorStateException。该方法用来通知那些可能等待该对象的对象锁的其他线程，如果有多个线程等待，则由线程规划器随机挑选出其中一个呈wait状态的线程，对其发出通知notify，并使它等待获取该对象的对象锁。需要说明的是，在执行notify()方法后，当前线程不会马上释放该对象锁，呈wait状态的线程也并不能马上获取该对象锁，到等到执行notify()方法的线程将程序执行完，也就是退出synchronized代码块后，当前线程才会释放锁，而呈wait状态所在的线程才可以获取该对象锁。当第一个获得了该对象锁的wait线程运行完毕以后，它会释放掉该对象锁，此时如果该对象没有再次使用notify语句，则即便该对象已经空闲，其他wait状态等待的线程由于没有得到该对象的通知，还会继续阻塞在wait状态，直到这个对象发出一个notify或notifyAll。\n\n如果我们用了显式锁`Lock`，就不要用Object自带的这套机制了。比如`ReentrantLock`依赖`CAS`和`LockSupport`来实现，`LockSupport`提供了`park`和`unpark`。\n\n- 调用`park`方法会使得当前线程丢失CPU使用权，从Runnable状态转变为Waiting状态。\n- 调用`unpark`方法则反过来让Waiting状态的某个线程转变状态为Runnable，等待操作系统调度。\n\n","source":"_posts/2020-04-27-kongzheng1993-java.lang.IllegalMonitorStateException.md","raw":"---\ntitle: java.lang.IllegalMonitorStateException\nexcerpt: ''\ntags: [多线程, Java]\ncategories: [Java]\ncomments: true\ndate: 2020-04-27 00:30:52\n---\n\n## java.lang.IllegalMonitorStateException\n\n从JDK源码开始看：\n\n```java\n/**\n * Thrown to indicate that a thread has attempted to wait on an\n * object's monitor or to notify other threads waiting on an object's\n * monitor without owning the specified monitor.\n *\n * @author  unascribed\n * @see     java.lang.Object#notify()\n * @see     java.lang.Object#notifyAll()\n * @see     java.lang.Object#wait()\n * @see     java.lang.Object#wait(long)\n * @see     java.lang.Object#wait(long, int)\n * @since   JDK1.0\n */\npublic\nclass IllegalMonitorStateException extends RuntimeException {\n    private static final long serialVersionUID = 3713306369498869069L;\n\n    /**\n     * Constructs an <code>IllegalMonitorStateException</code> with no\n     * detail message.\n     */\n    public IllegalMonitorStateException() {\n        super();\n    }\n\n    /**\n     * Constructs an <code>IllegalMonitorStateException</code> with the\n     * specified detail message.\n     *\n     * @param   s   the detail message.\n     */\n    public IllegalMonitorStateException(String s) {\n        super(s);\n    }\n}\n```\n\n从注释部分可以了解到：当我们在没有拥有指定对象的监视器时，就去等待这个对象的监视器或者通知其他线程去等待这个对象的监视器，就会抛出`IllegalMonitorStateException`。\n\n换句话说，我们要想调用一个对象的`wait()`、`notify()`等方法来实现线程通信，就要先获取这个对象的监视器。也就是要用`synchronized`修饰这个代码块。\n\n我们知道`synchronized`修饰的代码块编译后会被`monitorenter`和`monitorexit`包围，这两个虚拟机命令就是获取和释放对象的监视器。\n\n所以Object自带的`wait()`、`notify()`等方法，是让我们在使用`synchronized`时进行线程通信用的。\n\n```java\nimport java.lang.Runnable;\nimport java.util.concurrent.locks.Lock;\nimport java.util.concurrent.locks.ReentrantLock;\n\npublic class Test {\n\n    private int i = 0;\n\n    Object obj = new Object();\n\n    public void odd() {\n        synchronized (obj) {\n            while (i < 3) {\n                if (i % 2 == 1) {\n                    System.out.println(Thread.currentThread().getName() + \"打印：\" + i);\n                    i++;\n                    System.out.println(\"odd before notify\");\n                    obj.notify();\n                    System.out.println(\"odd after notify\");\n                } else {\n                    try {\n                        System.out.println(\"odd before wait\");\n                        obj.wait();\n                        System.out.println(\"odd after wait\");\n                    } catch (Exception e) {\n\n                    }\n                }\n                System.out.println(\"odd exit while\");\n            }\n            System.out.println(\"odd exit synchronized\");\n        }\n    }\n\n    public void even() {\n        synchronized (obj) {\n            while (i < 3) {\n                if (i % 2 == 0) {\n                    System.out.println(Thread.currentThread().getName() + \"打印：\" + i);\n                    i++;\n                    System.out.println(\"even before notify\");\n                    obj.notify();\n                    System.out.println(\"even after notify\");\n                } else {\n                    try {\n                        System.out.println(\"even before wait\");\n                        obj.wait();\n                        System.out.println(\"even after wait\");\n                    } catch (Exception e) {\n\n                    }\n                }\n                System.out.println(\"even exit while\");\n            }\n            System.out.println(\"even exit synchronized\");\n        }\n    }\n\n    public static void main(String[] args) {\n\n        Test test = new Test();\n\n        Thread thread1 = new Thread(new Runnable() {\n\n            @Override\n            public void run() {\n                test.odd();\n            }\n        }, \"奇数\");\n\n        Thread thread2 = new Thread(new Runnable() {\n\n            @Override\n            public void run() {\n                test.even();\n            }\n        }, \"偶数\");\n\n        thread1.start();\n        thread2.start();\n    }\n}\n```\n\n运行结果：\n\n```\nodd before wait\n偶数打印：0\neven before notify\neven after notify\neven exit while\neven before wait\nodd after wait\nodd exit while\n奇数打印：1\nodd before notify\nodd after notify\nodd exit while\nodd before wait\neven after wait\neven exit while\n偶数打印：2\neven before notify\neven after notify\neven exit while\neven exit synchronized\nodd after wait\nodd exit while\nodd exit synchronized\n```\n\n- **wait()**：使当前执行代码的线程进行等待，wait()方法是Object类的方法，该方法用来将当前线程置入“预执行队列”中，并且在wait()所在的代码行处停止执行，直到接到通知或被中断为止。在调用wait()之前，线程必须获得该对象的对象级别锁，即只能在同步方法或同步块中调用wait()方法。在执行wait()方法后，当前线程释放锁。在从wait()返回前，线程与其他线程竞争重新获得锁。如果调用wait()方法时没有持有适当的锁，则抛出IllegalMonitorStateException异常,它是RuntimeException的一个子类，因此，不需要try-catch语句进行捕捉异常。\n\n- **notify()**：也要在同步方法或同步块中调用，即在调用前，线程也必须获得该对象的对象级别锁。如调用notify()时没有持有适当的锁，也会抛出IllegalMonitorStateException。该方法用来通知那些可能等待该对象的对象锁的其他线程，如果有多个线程等待，则由线程规划器随机挑选出其中一个呈wait状态的线程，对其发出通知notify，并使它等待获取该对象的对象锁。需要说明的是，在执行notify()方法后，当前线程不会马上释放该对象锁，呈wait状态的线程也并不能马上获取该对象锁，到等到执行notify()方法的线程将程序执行完，也就是退出synchronized代码块后，当前线程才会释放锁，而呈wait状态所在的线程才可以获取该对象锁。当第一个获得了该对象锁的wait线程运行完毕以后，它会释放掉该对象锁，此时如果该对象没有再次使用notify语句，则即便该对象已经空闲，其他wait状态等待的线程由于没有得到该对象的通知，还会继续阻塞在wait状态，直到这个对象发出一个notify或notifyAll。\n\n如果我们用了显式锁`Lock`，就不要用Object自带的这套机制了。比如`ReentrantLock`依赖`CAS`和`LockSupport`来实现，`LockSupport`提供了`park`和`unpark`。\n\n- 调用`park`方法会使得当前线程丢失CPU使用权，从Runnable状态转变为Waiting状态。\n- 调用`unpark`方法则反过来让Waiting状态的某个线程转变状态为Runnable，等待操作系统调度。\n\n","slug":"kongzheng1993-java.lang.IllegalMonitorStateException","published":1,"updated":"2023-03-08T07:05:58.798Z","layout":"post","photos":[],"link":"","_id":"clg0k2ajy003wt26f7xyyoyyr","content":"<h2 id=\"java-lang-IllegalMonitorStateException\"><a href=\"#java-lang-IllegalMonitorStateException\" class=\"headerlink\" title=\"java.lang.IllegalMonitorStateException\"></a>java.lang.IllegalMonitorStateException</h2><p>从JDK源码开始看：</p>\n<pre><code class=\"java\">/**\n * Thrown to indicate that a thread has attempted to wait on an\n * object&#39;s monitor or to notify other threads waiting on an object&#39;s\n * monitor without owning the specified monitor.\n *\n * @author  unascribed\n * @see     java.lang.Object#notify()\n * @see     java.lang.Object#notifyAll()\n * @see     java.lang.Object#wait()\n * @see     java.lang.Object#wait(long)\n * @see     java.lang.Object#wait(long, int)\n * @since   JDK1.0\n */\npublic\nclass IllegalMonitorStateException extends RuntimeException {\n    private static final long serialVersionUID = 3713306369498869069L;\n\n    /**\n     * Constructs an &lt;code&gt;IllegalMonitorStateException&lt;/code&gt; with no\n     * detail message.\n     */\n    public IllegalMonitorStateException() {\n        super();\n    }\n\n    /**\n     * Constructs an &lt;code&gt;IllegalMonitorStateException&lt;/code&gt; with the\n     * specified detail message.\n     *\n     * @param   s   the detail message.\n     */\n    public IllegalMonitorStateException(String s) {\n        super(s);\n    }\n}</code></pre>\n<p>从注释部分可以了解到：当我们在没有拥有指定对象的监视器时，就去等待这个对象的监视器或者通知其他线程去等待这个对象的监视器，就会抛出<code>IllegalMonitorStateException</code>。</p>\n<p>换句话说，我们要想调用一个对象的<code>wait()</code>、<code>notify()</code>等方法来实现线程通信，就要先获取这个对象的监视器。也就是要用<code>synchronized</code>修饰这个代码块。</p>\n<p>我们知道<code>synchronized</code>修饰的代码块编译后会被<code>monitorenter</code>和<code>monitorexit</code>包围，这两个虚拟机命令就是获取和释放对象的监视器。</p>\n<p>所以Object自带的<code>wait()</code>、<code>notify()</code>等方法，是让我们在使用<code>synchronized</code>时进行线程通信用的。</p>\n<pre><code class=\"java\">import java.lang.Runnable;\nimport java.util.concurrent.locks.Lock;\nimport java.util.concurrent.locks.ReentrantLock;\n\npublic class Test {\n\n    private int i = 0;\n\n    Object obj = new Object();\n\n    public void odd() {\n        synchronized (obj) {\n            while (i &lt; 3) {\n                if (i % 2 == 1) {\n                    System.out.println(Thread.currentThread().getName() + &quot;打印：&quot; + i);\n                    i++;\n                    System.out.println(&quot;odd before notify&quot;);\n                    obj.notify();\n                    System.out.println(&quot;odd after notify&quot;);\n                } else {\n                    try {\n                        System.out.println(&quot;odd before wait&quot;);\n                        obj.wait();\n                        System.out.println(&quot;odd after wait&quot;);\n                    } catch (Exception e) {\n\n                    }\n                }\n                System.out.println(&quot;odd exit while&quot;);\n            }\n            System.out.println(&quot;odd exit synchronized&quot;);\n        }\n    }\n\n    public void even() {\n        synchronized (obj) {\n            while (i &lt; 3) {\n                if (i % 2 == 0) {\n                    System.out.println(Thread.currentThread().getName() + &quot;打印：&quot; + i);\n                    i++;\n                    System.out.println(&quot;even before notify&quot;);\n                    obj.notify();\n                    System.out.println(&quot;even after notify&quot;);\n                } else {\n                    try {\n                        System.out.println(&quot;even before wait&quot;);\n                        obj.wait();\n                        System.out.println(&quot;even after wait&quot;);\n                    } catch (Exception e) {\n\n                    }\n                }\n                System.out.println(&quot;even exit while&quot;);\n            }\n            System.out.println(&quot;even exit synchronized&quot;);\n        }\n    }\n\n    public static void main(String[] args) {\n\n        Test test = new Test();\n\n        Thread thread1 = new Thread(new Runnable() {\n\n            @Override\n            public void run() {\n                test.odd();\n            }\n        }, &quot;奇数&quot;);\n\n        Thread thread2 = new Thread(new Runnable() {\n\n            @Override\n            public void run() {\n                test.even();\n            }\n        }, &quot;偶数&quot;);\n\n        thread1.start();\n        thread2.start();\n    }\n}</code></pre>\n<p>运行结果：</p>\n<pre><code>odd before wait\n偶数打印：0\neven before notify\neven after notify\neven exit while\neven before wait\nodd after wait\nodd exit while\n奇数打印：1\nodd before notify\nodd after notify\nodd exit while\nodd before wait\neven after wait\neven exit while\n偶数打印：2\neven before notify\neven after notify\neven exit while\neven exit synchronized\nodd after wait\nodd exit while\nodd exit synchronized</code></pre><ul>\n<li><p><strong>wait()</strong>：使当前执行代码的线程进行等待，wait()方法是Object类的方法，该方法用来将当前线程置入“预执行队列”中，并且在wait()所在的代码行处停止执行，直到接到通知或被中断为止。在调用wait()之前，线程必须获得该对象的对象级别锁，即只能在同步方法或同步块中调用wait()方法。在执行wait()方法后，当前线程释放锁。在从wait()返回前，线程与其他线程竞争重新获得锁。如果调用wait()方法时没有持有适当的锁，则抛出IllegalMonitorStateException异常,它是RuntimeException的一个子类，因此，不需要try-catch语句进行捕捉异常。</p>\n</li>\n<li><p><strong>notify()</strong>：也要在同步方法或同步块中调用，即在调用前，线程也必须获得该对象的对象级别锁。如调用notify()时没有持有适当的锁，也会抛出IllegalMonitorStateException。该方法用来通知那些可能等待该对象的对象锁的其他线程，如果有多个线程等待，则由线程规划器随机挑选出其中一个呈wait状态的线程，对其发出通知notify，并使它等待获取该对象的对象锁。需要说明的是，在执行notify()方法后，当前线程不会马上释放该对象锁，呈wait状态的线程也并不能马上获取该对象锁，到等到执行notify()方法的线程将程序执行完，也就是退出synchronized代码块后，当前线程才会释放锁，而呈wait状态所在的线程才可以获取该对象锁。当第一个获得了该对象锁的wait线程运行完毕以后，它会释放掉该对象锁，此时如果该对象没有再次使用notify语句，则即便该对象已经空闲，其他wait状态等待的线程由于没有得到该对象的通知，还会继续阻塞在wait状态，直到这个对象发出一个notify或notifyAll。</p>\n</li>\n</ul>\n<p>如果我们用了显式锁<code>Lock</code>，就不要用Object自带的这套机制了。比如<code>ReentrantLock</code>依赖<code>CAS</code>和<code>LockSupport</code>来实现，<code>LockSupport</code>提供了<code>park</code>和<code>unpark</code>。</p>\n<ul>\n<li>调用<code>park</code>方法会使得当前线程丢失CPU使用权，从Runnable状态转变为Waiting状态。</li>\n<li>调用<code>unpark</code>方法则反过来让Waiting状态的某个线程转变状态为Runnable，等待操作系统调度。</li>\n</ul>\n","site":{"data":{}},"more":"<h2 id=\"java-lang-IllegalMonitorStateException\"><a href=\"#java-lang-IllegalMonitorStateException\" class=\"headerlink\" title=\"java.lang.IllegalMonitorStateException\"></a>java.lang.IllegalMonitorStateException</h2><p>从JDK源码开始看：</p>\n<pre><code class=\"java\">/**\n * Thrown to indicate that a thread has attempted to wait on an\n * object&#39;s monitor or to notify other threads waiting on an object&#39;s\n * monitor without owning the specified monitor.\n *\n * @author  unascribed\n * @see     java.lang.Object#notify()\n * @see     java.lang.Object#notifyAll()\n * @see     java.lang.Object#wait()\n * @see     java.lang.Object#wait(long)\n * @see     java.lang.Object#wait(long, int)\n * @since   JDK1.0\n */\npublic\nclass IllegalMonitorStateException extends RuntimeException {\n    private static final long serialVersionUID = 3713306369498869069L;\n\n    /**\n     * Constructs an &lt;code&gt;IllegalMonitorStateException&lt;/code&gt; with no\n     * detail message.\n     */\n    public IllegalMonitorStateException() {\n        super();\n    }\n\n    /**\n     * Constructs an &lt;code&gt;IllegalMonitorStateException&lt;/code&gt; with the\n     * specified detail message.\n     *\n     * @param   s   the detail message.\n     */\n    public IllegalMonitorStateException(String s) {\n        super(s);\n    }\n}</code></pre>\n<p>从注释部分可以了解到：当我们在没有拥有指定对象的监视器时，就去等待这个对象的监视器或者通知其他线程去等待这个对象的监视器，就会抛出<code>IllegalMonitorStateException</code>。</p>\n<p>换句话说，我们要想调用一个对象的<code>wait()</code>、<code>notify()</code>等方法来实现线程通信，就要先获取这个对象的监视器。也就是要用<code>synchronized</code>修饰这个代码块。</p>\n<p>我们知道<code>synchronized</code>修饰的代码块编译后会被<code>monitorenter</code>和<code>monitorexit</code>包围，这两个虚拟机命令就是获取和释放对象的监视器。</p>\n<p>所以Object自带的<code>wait()</code>、<code>notify()</code>等方法，是让我们在使用<code>synchronized</code>时进行线程通信用的。</p>\n<pre><code class=\"java\">import java.lang.Runnable;\nimport java.util.concurrent.locks.Lock;\nimport java.util.concurrent.locks.ReentrantLock;\n\npublic class Test {\n\n    private int i = 0;\n\n    Object obj = new Object();\n\n    public void odd() {\n        synchronized (obj) {\n            while (i &lt; 3) {\n                if (i % 2 == 1) {\n                    System.out.println(Thread.currentThread().getName() + &quot;打印：&quot; + i);\n                    i++;\n                    System.out.println(&quot;odd before notify&quot;);\n                    obj.notify();\n                    System.out.println(&quot;odd after notify&quot;);\n                } else {\n                    try {\n                        System.out.println(&quot;odd before wait&quot;);\n                        obj.wait();\n                        System.out.println(&quot;odd after wait&quot;);\n                    } catch (Exception e) {\n\n                    }\n                }\n                System.out.println(&quot;odd exit while&quot;);\n            }\n            System.out.println(&quot;odd exit synchronized&quot;);\n        }\n    }\n\n    public void even() {\n        synchronized (obj) {\n            while (i &lt; 3) {\n                if (i % 2 == 0) {\n                    System.out.println(Thread.currentThread().getName() + &quot;打印：&quot; + i);\n                    i++;\n                    System.out.println(&quot;even before notify&quot;);\n                    obj.notify();\n                    System.out.println(&quot;even after notify&quot;);\n                } else {\n                    try {\n                        System.out.println(&quot;even before wait&quot;);\n                        obj.wait();\n                        System.out.println(&quot;even after wait&quot;);\n                    } catch (Exception e) {\n\n                    }\n                }\n                System.out.println(&quot;even exit while&quot;);\n            }\n            System.out.println(&quot;even exit synchronized&quot;);\n        }\n    }\n\n    public static void main(String[] args) {\n\n        Test test = new Test();\n\n        Thread thread1 = new Thread(new Runnable() {\n\n            @Override\n            public void run() {\n                test.odd();\n            }\n        }, &quot;奇数&quot;);\n\n        Thread thread2 = new Thread(new Runnable() {\n\n            @Override\n            public void run() {\n                test.even();\n            }\n        }, &quot;偶数&quot;);\n\n        thread1.start();\n        thread2.start();\n    }\n}</code></pre>\n<p>运行结果：</p>\n<pre><code>odd before wait\n偶数打印：0\neven before notify\neven after notify\neven exit while\neven before wait\nodd after wait\nodd exit while\n奇数打印：1\nodd before notify\nodd after notify\nodd exit while\nodd before wait\neven after wait\neven exit while\n偶数打印：2\neven before notify\neven after notify\neven exit while\neven exit synchronized\nodd after wait\nodd exit while\nodd exit synchronized</code></pre><ul>\n<li><p><strong>wait()</strong>：使当前执行代码的线程进行等待，wait()方法是Object类的方法，该方法用来将当前线程置入“预执行队列”中，并且在wait()所在的代码行处停止执行，直到接到通知或被中断为止。在调用wait()之前，线程必须获得该对象的对象级别锁，即只能在同步方法或同步块中调用wait()方法。在执行wait()方法后，当前线程释放锁。在从wait()返回前，线程与其他线程竞争重新获得锁。如果调用wait()方法时没有持有适当的锁，则抛出IllegalMonitorStateException异常,它是RuntimeException的一个子类，因此，不需要try-catch语句进行捕捉异常。</p>\n</li>\n<li><p><strong>notify()</strong>：也要在同步方法或同步块中调用，即在调用前，线程也必须获得该对象的对象级别锁。如调用notify()时没有持有适当的锁，也会抛出IllegalMonitorStateException。该方法用来通知那些可能等待该对象的对象锁的其他线程，如果有多个线程等待，则由线程规划器随机挑选出其中一个呈wait状态的线程，对其发出通知notify，并使它等待获取该对象的对象锁。需要说明的是，在执行notify()方法后，当前线程不会马上释放该对象锁，呈wait状态的线程也并不能马上获取该对象锁，到等到执行notify()方法的线程将程序执行完，也就是退出synchronized代码块后，当前线程才会释放锁，而呈wait状态所在的线程才可以获取该对象锁。当第一个获得了该对象锁的wait线程运行完毕以后，它会释放掉该对象锁，此时如果该对象没有再次使用notify语句，则即便该对象已经空闲，其他wait状态等待的线程由于没有得到该对象的通知，还会继续阻塞在wait状态，直到这个对象发出一个notify或notifyAll。</p>\n</li>\n</ul>\n<p>如果我们用了显式锁<code>Lock</code>，就不要用Object自带的这套机制了。比如<code>ReentrantLock</code>依赖<code>CAS</code>和<code>LockSupport</code>来实现，<code>LockSupport</code>提供了<code>park</code>和<code>unpark</code>。</p>\n<ul>\n<li>调用<code>park</code>方法会使得当前线程丢失CPU使用权，从Runnable状态转变为Waiting状态。</li>\n<li>调用<code>unpark</code>方法则反过来让Waiting状态的某个线程转变状态为Runnable，等待操作系统调度。</li>\n</ul>\n"},{"title":"各种索引？","excerpt":"","comments":1,"date":"2020-04-28T16:30:52.000Z","_content":"\n## 各种索引？\n\n总有面试官问，来说说索引种类？\n\n索引种类？根据什么分类的？？？\n\n“您说的是`单列索引`和`组合索引`？”\n“回去等消息吧。。”\n\n摸不透他在想什么。。\n\n您倒是说个分类依据嘛。。\n\n## 索引是什么？\n\n索引类似大学图书馆建书目索引，可以提高数据检索的效率，降低数据库的IO成本。MySQL在300万条记录左右性能开始逐渐下降，虽然官方文档说500~800w记录，所以大数据量建立索引是非常有必要的。MySQL提供了Explain，用于显示SQL执行的详细信息，可以进行索引的优化。\n\n之前看过一个网课，老师说的一句话让我醍醐灌顶，“索引说到底就是数据结构”，如果从这句话看，索引种类好像是有的说呢，也各种数据结构实现的索引。\n\n**索引就是排序之后的数据结构，有顺序所以好查找喽**\n\n## 几种查找方式\n\n- **顺序查找：** 最基本的查询算法-复杂度O(n)，大数据量此算法效率糟糕。\n\n- **二叉树查找(binary tree search)：** O(log2n)，数据本身的组织结构不可能完全满足各种数据结构。如果数据是单边增长的情况，就和顺序查找一样了。。如下图：\n<img src=\"1216484-20190825001255129-2032384167.png\">\n\n- **hash索引：** 无法满足范围查找。哈希索引基于哈希表实现，只有精确匹配索引所有列的查询才有效。每一行会产生一个hash值，而且是唯一的，哈希索引将所有的哈希值存储在索引中，同时保存指向每个数据行的指针，这样就可以根据，索引中寻找对于哈希值，然后在根据对应指针，返回到数据行。这种高效是有条件的，即只在“=”和“in”条件下高效，对于范围查询、排序及组合索引仍然效率不高。\n\n- **红黑树(二叉平衡树)：** [复杂度O(h)]导致树高度非常高(平衡二叉树一个节点只能有左子树和右子树),逻辑上很近的节点（父子）物理上可能很远，无法利用局部性，IO次数多查找慢,效率低。todo 逻辑上相邻节点没法直接通过顺序指针关联，可能需要迭代回到上层节点重复向下遍历找到对应节点，效率低。比二叉树好的是，可以限制单边增长的问题。\n\n- **B-TREE(B树)：** 每个节点都是一个二元数组: [key, data]，所有节点都可以存储数据。key为索引key,data为除key之外的数据。\n  - 检索原理：首先从根节点进行二分查找，如果找到则返回对应节点的data，否则对相应区间的指针指向的节点递归进行查找，直到找到节点或未找到节点返回null指针。\n  - 缺点：\n    1. 插入删除新的数据记录会破坏B-Tree的性质，因此在插入删除时，需要对树进行一个分裂、合并、转移等操作以保持B-Tree性质。造成IO操作频繁。\n    2. 区间查找可能需要返回上层节点重复遍历，IO操作繁琐。\n\n    <img src=\"v2-2c2264cc1c6c603dfeca4f84a2575901_r.jpg\">\n\n- **B+Tree：** B-Tree的变种。与B-Tree相比，B+Tree有以下不同点：非叶子节点不存储data，只存储索引key；只有叶子节点才存储data。Mysql中B+Tree，在经典B+Tree的基础上进行了优化，增加了顺序访问指针。在B+Tree的每个叶子节点增加一个指向相邻叶子节点的指针，就形成了带有顺序访问指针的B+Tree。这样就提高了区间访问性能。\n  - 特点：\n    1. B+树的层级更少：相较于B树B+每个非叶子节点存储的关键字数更多，树的层级更少所以查询数据更快；\n    2. B+树查询速度更稳定：B+所有关键字数据地址都存在叶子节点上，所以每次查找的次数都相同所以查询速度要比B树更稳定;\n    3. B+树天然具备排序功能：B+树所有的叶子节点数据构成了一个有序链表，在查询大小区间的数据时候更方便，数据紧密性很高，缓存的命中率也会比B树高。\n    4. B+树全节点遍历更快：B+树遍历整棵树只需要遍历所有的叶子节点即可，，而不需要像B树一样需要对每一层进行遍历，这有利于数据库做全表扫描。\n<img src=\"v2-5f069fd820637db1b877fdd6799a2b67_r.jpg\">\n\n## MySQL索引类型\n\nMysql目前主要有以下几种索引类型：FULLTEXT，HASH，BTREE，RTREE。\n\n1. FULLTEXT：即为全文索引，目前只有MyISAM引擎支持。其可以在CREATE TABLE ，ALTER TABLE ，CREATE INDEX 使用，不过目前只有 CHAR、VARCHAR ，TEXT 列上可以创建全文索引。全文索引并不是和MyISAM一起诞生的，它的出现是为了解决WHERE name LIKE “%word%\"这类针对文本的模糊查询效率较低的问题。\n\n2. HASH：由于HASH的唯一（几乎100%的唯一）及类似键值对的形式，很适合作为索引。HASH索引可以一次定位，不需要像树形索引那样逐层查找,因此具有极高的效率。但是，这种高效是有条件的，即只在“=”和“in”条件下高效，对于范围查询、排序及组合索引仍然效率不高。\n\n3. BTREE：BTREE索引就是一种将索引值按一定的算法，存入一个树形的数据结构中（二叉树），每次查询都是从树的入口root开始，依次遍历node，获取leaf。这是MySQL里默认和最常用的索引类型。\n\n4. RTREE：RTREE在MySQL很少使用，仅支持geometry数据类型，支持该类型的存储引擎只有MyISAM、BDb、InnoDb、NDb、Archive几种。相对于BTREE，RTREE的优势在于范围查找。\n\n\n## MySQL索引种类：\n\n1. 普通索引：仅加速查询\n2. 唯一索引：加速查询、列值唯一（可以有null）\n3. 主键索引：加速查询、列值唯一（不可以有null）、表中只有一个主键索引\n4. 组合索引：多列值组成一个索引，专门用于组合搜索，其效率大于索引合并。\n5. 全文索引：对文本的内容进行分词，进行搜索，老版本只能用在MyISAM，新版本InnoDB也有了\n\n```\n索引合并：使用多个单列索引组合搜索\n覆盖索引：select的数据列只用从索引中就能够取得，不必读取数据行，换句话说查询列要被所建的索引覆盖\n```\n\n```sql\n--创建普通索引\nCREATE INDEX index_name ON table_name(col_name);\n--创建唯一索引\nCREATE UNIQUE INDEX index_name ON table_name(col_name);\n--创建主键索引\nALTER TABLE table_name ADD PRIMARY KEY (column);\n--创建普通组合索引\nCREATE INDEX index_name ON table_name(col_name_1,col_name_2);\n--创建唯一组合索引\nCREATE UNIQUE INDEX index_name ON table_name(col_name_1,col_name_2);\n--创建全文索引\nCREATE FULLTEXT INDEX ft_email_name ON student(name)；\n```\n\n## 索引带来的问题\n\n- 创建索引是为产生索引文件的，占用磁盘空间\n- 索引文件是一个二叉树类型的文件，可想而知我们的dml操作同样也会对索引文件进行修改，所以性能会下降\n- 。。。\n  \n所以我们应该根据实际情况建立索引，不能盲目。","source":"_posts/2020-04-29-kongzheng1993-各种索引.md","raw":"---\ntitle: 各种索引？\nexcerpt: ''\ntags: [MySQL]\ncategories: [MySQL]\ncomments: true\ndate: 2020-04-29 00:30:52\n---\n\n## 各种索引？\n\n总有面试官问，来说说索引种类？\n\n索引种类？根据什么分类的？？？\n\n“您说的是`单列索引`和`组合索引`？”\n“回去等消息吧。。”\n\n摸不透他在想什么。。\n\n您倒是说个分类依据嘛。。\n\n## 索引是什么？\n\n索引类似大学图书馆建书目索引，可以提高数据检索的效率，降低数据库的IO成本。MySQL在300万条记录左右性能开始逐渐下降，虽然官方文档说500~800w记录，所以大数据量建立索引是非常有必要的。MySQL提供了Explain，用于显示SQL执行的详细信息，可以进行索引的优化。\n\n之前看过一个网课，老师说的一句话让我醍醐灌顶，“索引说到底就是数据结构”，如果从这句话看，索引种类好像是有的说呢，也各种数据结构实现的索引。\n\n**索引就是排序之后的数据结构，有顺序所以好查找喽**\n\n## 几种查找方式\n\n- **顺序查找：** 最基本的查询算法-复杂度O(n)，大数据量此算法效率糟糕。\n\n- **二叉树查找(binary tree search)：** O(log2n)，数据本身的组织结构不可能完全满足各种数据结构。如果数据是单边增长的情况，就和顺序查找一样了。。如下图：\n<img src=\"1216484-20190825001255129-2032384167.png\">\n\n- **hash索引：** 无法满足范围查找。哈希索引基于哈希表实现，只有精确匹配索引所有列的查询才有效。每一行会产生一个hash值，而且是唯一的，哈希索引将所有的哈希值存储在索引中，同时保存指向每个数据行的指针，这样就可以根据，索引中寻找对于哈希值，然后在根据对应指针，返回到数据行。这种高效是有条件的，即只在“=”和“in”条件下高效，对于范围查询、排序及组合索引仍然效率不高。\n\n- **红黑树(二叉平衡树)：** [复杂度O(h)]导致树高度非常高(平衡二叉树一个节点只能有左子树和右子树),逻辑上很近的节点（父子）物理上可能很远，无法利用局部性，IO次数多查找慢,效率低。todo 逻辑上相邻节点没法直接通过顺序指针关联，可能需要迭代回到上层节点重复向下遍历找到对应节点，效率低。比二叉树好的是，可以限制单边增长的问题。\n\n- **B-TREE(B树)：** 每个节点都是一个二元数组: [key, data]，所有节点都可以存储数据。key为索引key,data为除key之外的数据。\n  - 检索原理：首先从根节点进行二分查找，如果找到则返回对应节点的data，否则对相应区间的指针指向的节点递归进行查找，直到找到节点或未找到节点返回null指针。\n  - 缺点：\n    1. 插入删除新的数据记录会破坏B-Tree的性质，因此在插入删除时，需要对树进行一个分裂、合并、转移等操作以保持B-Tree性质。造成IO操作频繁。\n    2. 区间查找可能需要返回上层节点重复遍历，IO操作繁琐。\n\n    <img src=\"v2-2c2264cc1c6c603dfeca4f84a2575901_r.jpg\">\n\n- **B+Tree：** B-Tree的变种。与B-Tree相比，B+Tree有以下不同点：非叶子节点不存储data，只存储索引key；只有叶子节点才存储data。Mysql中B+Tree，在经典B+Tree的基础上进行了优化，增加了顺序访问指针。在B+Tree的每个叶子节点增加一个指向相邻叶子节点的指针，就形成了带有顺序访问指针的B+Tree。这样就提高了区间访问性能。\n  - 特点：\n    1. B+树的层级更少：相较于B树B+每个非叶子节点存储的关键字数更多，树的层级更少所以查询数据更快；\n    2. B+树查询速度更稳定：B+所有关键字数据地址都存在叶子节点上，所以每次查找的次数都相同所以查询速度要比B树更稳定;\n    3. B+树天然具备排序功能：B+树所有的叶子节点数据构成了一个有序链表，在查询大小区间的数据时候更方便，数据紧密性很高，缓存的命中率也会比B树高。\n    4. B+树全节点遍历更快：B+树遍历整棵树只需要遍历所有的叶子节点即可，，而不需要像B树一样需要对每一层进行遍历，这有利于数据库做全表扫描。\n<img src=\"v2-5f069fd820637db1b877fdd6799a2b67_r.jpg\">\n\n## MySQL索引类型\n\nMysql目前主要有以下几种索引类型：FULLTEXT，HASH，BTREE，RTREE。\n\n1. FULLTEXT：即为全文索引，目前只有MyISAM引擎支持。其可以在CREATE TABLE ，ALTER TABLE ，CREATE INDEX 使用，不过目前只有 CHAR、VARCHAR ，TEXT 列上可以创建全文索引。全文索引并不是和MyISAM一起诞生的，它的出现是为了解决WHERE name LIKE “%word%\"这类针对文本的模糊查询效率较低的问题。\n\n2. HASH：由于HASH的唯一（几乎100%的唯一）及类似键值对的形式，很适合作为索引。HASH索引可以一次定位，不需要像树形索引那样逐层查找,因此具有极高的效率。但是，这种高效是有条件的，即只在“=”和“in”条件下高效，对于范围查询、排序及组合索引仍然效率不高。\n\n3. BTREE：BTREE索引就是一种将索引值按一定的算法，存入一个树形的数据结构中（二叉树），每次查询都是从树的入口root开始，依次遍历node，获取leaf。这是MySQL里默认和最常用的索引类型。\n\n4. RTREE：RTREE在MySQL很少使用，仅支持geometry数据类型，支持该类型的存储引擎只有MyISAM、BDb、InnoDb、NDb、Archive几种。相对于BTREE，RTREE的优势在于范围查找。\n\n\n## MySQL索引种类：\n\n1. 普通索引：仅加速查询\n2. 唯一索引：加速查询、列值唯一（可以有null）\n3. 主键索引：加速查询、列值唯一（不可以有null）、表中只有一个主键索引\n4. 组合索引：多列值组成一个索引，专门用于组合搜索，其效率大于索引合并。\n5. 全文索引：对文本的内容进行分词，进行搜索，老版本只能用在MyISAM，新版本InnoDB也有了\n\n```\n索引合并：使用多个单列索引组合搜索\n覆盖索引：select的数据列只用从索引中就能够取得，不必读取数据行，换句话说查询列要被所建的索引覆盖\n```\n\n```sql\n--创建普通索引\nCREATE INDEX index_name ON table_name(col_name);\n--创建唯一索引\nCREATE UNIQUE INDEX index_name ON table_name(col_name);\n--创建主键索引\nALTER TABLE table_name ADD PRIMARY KEY (column);\n--创建普通组合索引\nCREATE INDEX index_name ON table_name(col_name_1,col_name_2);\n--创建唯一组合索引\nCREATE UNIQUE INDEX index_name ON table_name(col_name_1,col_name_2);\n--创建全文索引\nCREATE FULLTEXT INDEX ft_email_name ON student(name)；\n```\n\n## 索引带来的问题\n\n- 创建索引是为产生索引文件的，占用磁盘空间\n- 索引文件是一个二叉树类型的文件，可想而知我们的dml操作同样也会对索引文件进行修改，所以性能会下降\n- 。。。\n  \n所以我们应该根据实际情况建立索引，不能盲目。","slug":"kongzheng1993-各种索引","published":1,"updated":"2023-03-08T07:05:58.799Z","layout":"post","photos":[],"link":"","_id":"clg0k2ak10040t26fodpu4vaq","content":"<h2 id=\"各种索引？\"><a href=\"#各种索引？\" class=\"headerlink\" title=\"各种索引？\"></a>各种索引？</h2><p>总有面试官问，来说说索引种类？</p>\n<p>索引种类？根据什么分类的？？？</p>\n<p>“您说的是<code>单列索引</code>和<code>组合索引</code>？”<br>“回去等消息吧。。”</p>\n<p>摸不透他在想什么。。</p>\n<p>您倒是说个分类依据嘛。。</p>\n<h2 id=\"索引是什么？\"><a href=\"#索引是什么？\" class=\"headerlink\" title=\"索引是什么？\"></a>索引是什么？</h2><p>索引类似大学图书馆建书目索引，可以提高数据检索的效率，降低数据库的IO成本。MySQL在300万条记录左右性能开始逐渐下降，虽然官方文档说500~800w记录，所以大数据量建立索引是非常有必要的。MySQL提供了Explain，用于显示SQL执行的详细信息，可以进行索引的优化。</p>\n<p>之前看过一个网课，老师说的一句话让我醍醐灌顶，“索引说到底就是数据结构”，如果从这句话看，索引种类好像是有的说呢，也各种数据结构实现的索引。</p>\n<p><strong>索引就是排序之后的数据结构，有顺序所以好查找喽</strong></p>\n<h2 id=\"几种查找方式\"><a href=\"#几种查找方式\" class=\"headerlink\" title=\"几种查找方式\"></a>几种查找方式</h2><ul>\n<li><p><strong>顺序查找：</strong> 最基本的查询算法-复杂度O(n)，大数据量此算法效率糟糕。</p>\n</li>\n<li><p><strong>二叉树查找(binary tree search)：</strong> O(log2n)，数据本身的组织结构不可能完全满足各种数据结构。如果数据是单边增长的情况，就和顺序查找一样了。。如下图：</p>\n<img src=\"/2020/04/29/kongzheng1993-各种索引/1216484-20190825001255129-2032384167.png\">\n</li>\n<li><p><strong>hash索引：</strong> 无法满足范围查找。哈希索引基于哈希表实现，只有精确匹配索引所有列的查询才有效。每一行会产生一个hash值，而且是唯一的，哈希索引将所有的哈希值存储在索引中，同时保存指向每个数据行的指针，这样就可以根据，索引中寻找对于哈希值，然后在根据对应指针，返回到数据行。这种高效是有条件的，即只在“=”和“in”条件下高效，对于范围查询、排序及组合索引仍然效率不高。</p>\n</li>\n<li><p><strong>红黑树(二叉平衡树)：</strong> [复杂度O(h)]导致树高度非常高(平衡二叉树一个节点只能有左子树和右子树),逻辑上很近的节点（父子）物理上可能很远，无法利用局部性，IO次数多查找慢,效率低。todo 逻辑上相邻节点没法直接通过顺序指针关联，可能需要迭代回到上层节点重复向下遍历找到对应节点，效率低。比二叉树好的是，可以限制单边增长的问题。</p>\n</li>\n<li><p><strong>B-TREE(B树)：</strong> 每个节点都是一个二元数组: [key, data]，所有节点都可以存储数据。key为索引key,data为除key之外的数据。</p>\n<ul>\n<li><p>检索原理：首先从根节点进行二分查找，如果找到则返回对应节点的data，否则对相应区间的指针指向的节点递归进行查找，直到找到节点或未找到节点返回null指针。</p>\n</li>\n<li><p>缺点：</p>\n<ol>\n<li>插入删除新的数据记录会破坏B-Tree的性质，因此在插入删除时，需要对树进行一个分裂、合并、转移等操作以保持B-Tree性质。造成IO操作频繁。</li>\n<li>区间查找可能需要返回上层节点重复遍历，IO操作繁琐。</li>\n</ol>\n<img src=\"/2020/04/29/kongzheng1993-各种索引/v2-2c2264cc1c6c603dfeca4f84a2575901_r.jpg\">\n</li>\n</ul>\n</li>\n<li><p><strong>B+Tree：</strong> B-Tree的变种。与B-Tree相比，B+Tree有以下不同点：非叶子节点不存储data，只存储索引key；只有叶子节点才存储data。Mysql中B+Tree，在经典B+Tree的基础上进行了优化，增加了顺序访问指针。在B+Tree的每个叶子节点增加一个指向相邻叶子节点的指针，就形成了带有顺序访问指针的B+Tree。这样就提高了区间访问性能。</p>\n<ul>\n<li>特点：<ol>\n<li>B+树的层级更少：相较于B树B+每个非叶子节点存储的关键字数更多，树的层级更少所以查询数据更快；</li>\n<li>B+树查询速度更稳定：B+所有关键字数据地址都存在叶子节点上，所以每次查找的次数都相同所以查询速度要比B树更稳定;</li>\n<li>B+树天然具备排序功能：B+树所有的叶子节点数据构成了一个有序链表，在查询大小区间的数据时候更方便，数据紧密性很高，缓存的命中率也会比B树高。</li>\n<li>B+树全节点遍历更快：B+树遍历整棵树只需要遍历所有的叶子节点即可，，而不需要像B树一样需要对每一层进行遍历，这有利于数据库做全表扫描。<img src=\"/2020/04/29/kongzheng1993-各种索引/v2-5f069fd820637db1b877fdd6799a2b67_r.jpg\">\n\n</li>\n</ol>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"MySQL索引类型\"><a href=\"#MySQL索引类型\" class=\"headerlink\" title=\"MySQL索引类型\"></a>MySQL索引类型</h2><p>Mysql目前主要有以下几种索引类型：FULLTEXT，HASH，BTREE，RTREE。</p>\n<ol>\n<li><p>FULLTEXT：即为全文索引，目前只有MyISAM引擎支持。其可以在CREATE TABLE ，ALTER TABLE ，CREATE INDEX 使用，不过目前只有 CHAR、VARCHAR ，TEXT 列上可以创建全文索引。全文索引并不是和MyISAM一起诞生的，它的出现是为了解决WHERE name LIKE “%word%”这类针对文本的模糊查询效率较低的问题。</p>\n</li>\n<li><p>HASH：由于HASH的唯一（几乎100%的唯一）及类似键值对的形式，很适合作为索引。HASH索引可以一次定位，不需要像树形索引那样逐层查找,因此具有极高的效率。但是，这种高效是有条件的，即只在“=”和“in”条件下高效，对于范围查询、排序及组合索引仍然效率不高。</p>\n</li>\n<li><p>BTREE：BTREE索引就是一种将索引值按一定的算法，存入一个树形的数据结构中（二叉树），每次查询都是从树的入口root开始，依次遍历node，获取leaf。这是MySQL里默认和最常用的索引类型。</p>\n</li>\n<li><p>RTREE：RTREE在MySQL很少使用，仅支持geometry数据类型，支持该类型的存储引擎只有MyISAM、BDb、InnoDb、NDb、Archive几种。相对于BTREE，RTREE的优势在于范围查找。</p>\n</li>\n</ol>\n<h2 id=\"MySQL索引种类：\"><a href=\"#MySQL索引种类：\" class=\"headerlink\" title=\"MySQL索引种类：\"></a>MySQL索引种类：</h2><ol>\n<li>普通索引：仅加速查询</li>\n<li>唯一索引：加速查询、列值唯一（可以有null）</li>\n<li>主键索引：加速查询、列值唯一（不可以有null）、表中只有一个主键索引</li>\n<li>组合索引：多列值组成一个索引，专门用于组合搜索，其效率大于索引合并。</li>\n<li>全文索引：对文本的内容进行分词，进行搜索，老版本只能用在MyISAM，新版本InnoDB也有了</li>\n</ol>\n<pre><code>索引合并：使用多个单列索引组合搜索\n覆盖索引：select的数据列只用从索引中就能够取得，不必读取数据行，换句话说查询列要被所建的索引覆盖</code></pre><pre><code class=\"sql\">--创建普通索引\nCREATE INDEX index_name ON table_name(col_name);\n--创建唯一索引\nCREATE UNIQUE INDEX index_name ON table_name(col_name);\n--创建主键索引\nALTER TABLE table_name ADD PRIMARY KEY (column);\n--创建普通组合索引\nCREATE INDEX index_name ON table_name(col_name_1,col_name_2);\n--创建唯一组合索引\nCREATE UNIQUE INDEX index_name ON table_name(col_name_1,col_name_2);\n--创建全文索引\nCREATE FULLTEXT INDEX ft_email_name ON student(name)；</code></pre>\n<h2 id=\"索引带来的问题\"><a href=\"#索引带来的问题\" class=\"headerlink\" title=\"索引带来的问题\"></a>索引带来的问题</h2><ul>\n<li>创建索引是为产生索引文件的，占用磁盘空间</li>\n<li>索引文件是一个二叉树类型的文件，可想而知我们的dml操作同样也会对索引文件进行修改，所以性能会下降</li>\n<li>。。。</li>\n</ul>\n<p>所以我们应该根据实际情况建立索引，不能盲目。</p>\n","site":{"data":{}},"more":"<h2 id=\"各种索引？\"><a href=\"#各种索引？\" class=\"headerlink\" title=\"各种索引？\"></a>各种索引？</h2><p>总有面试官问，来说说索引种类？</p>\n<p>索引种类？根据什么分类的？？？</p>\n<p>“您说的是<code>单列索引</code>和<code>组合索引</code>？”<br>“回去等消息吧。。”</p>\n<p>摸不透他在想什么。。</p>\n<p>您倒是说个分类依据嘛。。</p>\n<h2 id=\"索引是什么？\"><a href=\"#索引是什么？\" class=\"headerlink\" title=\"索引是什么？\"></a>索引是什么？</h2><p>索引类似大学图书馆建书目索引，可以提高数据检索的效率，降低数据库的IO成本。MySQL在300万条记录左右性能开始逐渐下降，虽然官方文档说500~800w记录，所以大数据量建立索引是非常有必要的。MySQL提供了Explain，用于显示SQL执行的详细信息，可以进行索引的优化。</p>\n<p>之前看过一个网课，老师说的一句话让我醍醐灌顶，“索引说到底就是数据结构”，如果从这句话看，索引种类好像是有的说呢，也各种数据结构实现的索引。</p>\n<p><strong>索引就是排序之后的数据结构，有顺序所以好查找喽</strong></p>\n<h2 id=\"几种查找方式\"><a href=\"#几种查找方式\" class=\"headerlink\" title=\"几种查找方式\"></a>几种查找方式</h2><ul>\n<li><p><strong>顺序查找：</strong> 最基本的查询算法-复杂度O(n)，大数据量此算法效率糟糕。</p>\n</li>\n<li><p><strong>二叉树查找(binary tree search)：</strong> O(log2n)，数据本身的组织结构不可能完全满足各种数据结构。如果数据是单边增长的情况，就和顺序查找一样了。。如下图：</p>\n<img src=\"/2020/04/29/kongzheng1993-各种索引/1216484-20190825001255129-2032384167.png\">\n</li>\n<li><p><strong>hash索引：</strong> 无法满足范围查找。哈希索引基于哈希表实现，只有精确匹配索引所有列的查询才有效。每一行会产生一个hash值，而且是唯一的，哈希索引将所有的哈希值存储在索引中，同时保存指向每个数据行的指针，这样就可以根据，索引中寻找对于哈希值，然后在根据对应指针，返回到数据行。这种高效是有条件的，即只在“=”和“in”条件下高效，对于范围查询、排序及组合索引仍然效率不高。</p>\n</li>\n<li><p><strong>红黑树(二叉平衡树)：</strong> [复杂度O(h)]导致树高度非常高(平衡二叉树一个节点只能有左子树和右子树),逻辑上很近的节点（父子）物理上可能很远，无法利用局部性，IO次数多查找慢,效率低。todo 逻辑上相邻节点没法直接通过顺序指针关联，可能需要迭代回到上层节点重复向下遍历找到对应节点，效率低。比二叉树好的是，可以限制单边增长的问题。</p>\n</li>\n<li><p><strong>B-TREE(B树)：</strong> 每个节点都是一个二元数组: [key, data]，所有节点都可以存储数据。key为索引key,data为除key之外的数据。</p>\n<ul>\n<li><p>检索原理：首先从根节点进行二分查找，如果找到则返回对应节点的data，否则对相应区间的指针指向的节点递归进行查找，直到找到节点或未找到节点返回null指针。</p>\n</li>\n<li><p>缺点：</p>\n<ol>\n<li>插入删除新的数据记录会破坏B-Tree的性质，因此在插入删除时，需要对树进行一个分裂、合并、转移等操作以保持B-Tree性质。造成IO操作频繁。</li>\n<li>区间查找可能需要返回上层节点重复遍历，IO操作繁琐。</li>\n</ol>\n<img src=\"/2020/04/29/kongzheng1993-各种索引/v2-2c2264cc1c6c603dfeca4f84a2575901_r.jpg\">\n</li>\n</ul>\n</li>\n<li><p><strong>B+Tree：</strong> B-Tree的变种。与B-Tree相比，B+Tree有以下不同点：非叶子节点不存储data，只存储索引key；只有叶子节点才存储data。Mysql中B+Tree，在经典B+Tree的基础上进行了优化，增加了顺序访问指针。在B+Tree的每个叶子节点增加一个指向相邻叶子节点的指针，就形成了带有顺序访问指针的B+Tree。这样就提高了区间访问性能。</p>\n<ul>\n<li>特点：<ol>\n<li>B+树的层级更少：相较于B树B+每个非叶子节点存储的关键字数更多，树的层级更少所以查询数据更快；</li>\n<li>B+树查询速度更稳定：B+所有关键字数据地址都存在叶子节点上，所以每次查找的次数都相同所以查询速度要比B树更稳定;</li>\n<li>B+树天然具备排序功能：B+树所有的叶子节点数据构成了一个有序链表，在查询大小区间的数据时候更方便，数据紧密性很高，缓存的命中率也会比B树高。</li>\n<li>B+树全节点遍历更快：B+树遍历整棵树只需要遍历所有的叶子节点即可，，而不需要像B树一样需要对每一层进行遍历，这有利于数据库做全表扫描。<img src=\"/2020/04/29/kongzheng1993-各种索引/v2-5f069fd820637db1b877fdd6799a2b67_r.jpg\">\n\n</li>\n</ol>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"MySQL索引类型\"><a href=\"#MySQL索引类型\" class=\"headerlink\" title=\"MySQL索引类型\"></a>MySQL索引类型</h2><p>Mysql目前主要有以下几种索引类型：FULLTEXT，HASH，BTREE，RTREE。</p>\n<ol>\n<li><p>FULLTEXT：即为全文索引，目前只有MyISAM引擎支持。其可以在CREATE TABLE ，ALTER TABLE ，CREATE INDEX 使用，不过目前只有 CHAR、VARCHAR ，TEXT 列上可以创建全文索引。全文索引并不是和MyISAM一起诞生的，它的出现是为了解决WHERE name LIKE “%word%”这类针对文本的模糊查询效率较低的问题。</p>\n</li>\n<li><p>HASH：由于HASH的唯一（几乎100%的唯一）及类似键值对的形式，很适合作为索引。HASH索引可以一次定位，不需要像树形索引那样逐层查找,因此具有极高的效率。但是，这种高效是有条件的，即只在“=”和“in”条件下高效，对于范围查询、排序及组合索引仍然效率不高。</p>\n</li>\n<li><p>BTREE：BTREE索引就是一种将索引值按一定的算法，存入一个树形的数据结构中（二叉树），每次查询都是从树的入口root开始，依次遍历node，获取leaf。这是MySQL里默认和最常用的索引类型。</p>\n</li>\n<li><p>RTREE：RTREE在MySQL很少使用，仅支持geometry数据类型，支持该类型的存储引擎只有MyISAM、BDb、InnoDb、NDb、Archive几种。相对于BTREE，RTREE的优势在于范围查找。</p>\n</li>\n</ol>\n<h2 id=\"MySQL索引种类：\"><a href=\"#MySQL索引种类：\" class=\"headerlink\" title=\"MySQL索引种类：\"></a>MySQL索引种类：</h2><ol>\n<li>普通索引：仅加速查询</li>\n<li>唯一索引：加速查询、列值唯一（可以有null）</li>\n<li>主键索引：加速查询、列值唯一（不可以有null）、表中只有一个主键索引</li>\n<li>组合索引：多列值组成一个索引，专门用于组合搜索，其效率大于索引合并。</li>\n<li>全文索引：对文本的内容进行分词，进行搜索，老版本只能用在MyISAM，新版本InnoDB也有了</li>\n</ol>\n<pre><code>索引合并：使用多个单列索引组合搜索\n覆盖索引：select的数据列只用从索引中就能够取得，不必读取数据行，换句话说查询列要被所建的索引覆盖</code></pre><pre><code class=\"sql\">--创建普通索引\nCREATE INDEX index_name ON table_name(col_name);\n--创建唯一索引\nCREATE UNIQUE INDEX index_name ON table_name(col_name);\n--创建主键索引\nALTER TABLE table_name ADD PRIMARY KEY (column);\n--创建普通组合索引\nCREATE INDEX index_name ON table_name(col_name_1,col_name_2);\n--创建唯一组合索引\nCREATE UNIQUE INDEX index_name ON table_name(col_name_1,col_name_2);\n--创建全文索引\nCREATE FULLTEXT INDEX ft_email_name ON student(name)；</code></pre>\n<h2 id=\"索引带来的问题\"><a href=\"#索引带来的问题\" class=\"headerlink\" title=\"索引带来的问题\"></a>索引带来的问题</h2><ul>\n<li>创建索引是为产生索引文件的，占用磁盘空间</li>\n<li>索引文件是一个二叉树类型的文件，可想而知我们的dml操作同样也会对索引文件进行修改，所以性能会下降</li>\n<li>。。。</li>\n</ul>\n<p>所以我们应该根据实际情况建立索引，不能盲目。</p>\n"},{"title":"数据库设计范式","excerpt":"","comments":1,"date":"2020-05-08T16:30:52.000Z","_content":"\n范式（Normal Form），也就是规范化的形式。\n\n## 三大范式\n\n- **第一范式1NF：** 数据表中的每一列(字段)，必须是不可拆分的最小单元，也就是确保每一列的原子性，而不是集合。比如地址可以分成省、市、区等等。\n- **第二范式2NF：** 满足1NF的基础上，要求：表中的所有列，都必需依赖于主键，而不能有任何一列与主键没有关系（一个表只描述一件事情）。**第二范式消除表的无关数据。**\n- **第三范式3NF：** 满足2NF的基础上，任何非主属性不依赖于其它非主属性（**在2NF基础上消除传递依赖**）（也表明不允许数据存在冗余的现象）。比如订单表里有买家id，还有买家姓名啥的，这是订单表，所有的列应该都和订单id有直接关系，买家id和订单id又直接关系，但是买家姓名应该在用户表里，不应该出现在订单表里。\n\n## 五大约束\n\n1. 主键约束（Primary Key）：唯一、非空\n2. 唯一约束（Unique）：唯一、可空，但只能有一个空\n3. 检查约束（Check）：数据长度、格式的限制\n4. 默认约束（Default）：数据的默认值\n5. 外键约束（Foreign Key）：通过外键建立两张表的关系","source":"_posts/2020-05-09-kongzheng1993-数据库设计范式.md","raw":"---\ntitle: 数据库设计范式\nexcerpt: ''\ntags: [SQL]\ncategories: [SQL]\ncomments: true\ndate: 2020-05-09 00:30:52\n---\n\n范式（Normal Form），也就是规范化的形式。\n\n## 三大范式\n\n- **第一范式1NF：** 数据表中的每一列(字段)，必须是不可拆分的最小单元，也就是确保每一列的原子性，而不是集合。比如地址可以分成省、市、区等等。\n- **第二范式2NF：** 满足1NF的基础上，要求：表中的所有列，都必需依赖于主键，而不能有任何一列与主键没有关系（一个表只描述一件事情）。**第二范式消除表的无关数据。**\n- **第三范式3NF：** 满足2NF的基础上，任何非主属性不依赖于其它非主属性（**在2NF基础上消除传递依赖**）（也表明不允许数据存在冗余的现象）。比如订单表里有买家id，还有买家姓名啥的，这是订单表，所有的列应该都和订单id有直接关系，买家id和订单id又直接关系，但是买家姓名应该在用户表里，不应该出现在订单表里。\n\n## 五大约束\n\n1. 主键约束（Primary Key）：唯一、非空\n2. 唯一约束（Unique）：唯一、可空，但只能有一个空\n3. 检查约束（Check）：数据长度、格式的限制\n4. 默认约束（Default）：数据的默认值\n5. 外键约束（Foreign Key）：通过外键建立两张表的关系","slug":"kongzheng1993-数据库设计范式","published":1,"updated":"2023-03-08T07:05:58.801Z","layout":"post","photos":[],"link":"","_id":"clg0k2ak50044t26fjh3rijd0","content":"<p>范式（Normal Form），也就是规范化的形式。</p>\n<h2 id=\"三大范式\"><a href=\"#三大范式\" class=\"headerlink\" title=\"三大范式\"></a>三大范式</h2><ul>\n<li><strong>第一范式1NF：</strong> 数据表中的每一列(字段)，必须是不可拆分的最小单元，也就是确保每一列的原子性，而不是集合。比如地址可以分成省、市、区等等。</li>\n<li><strong>第二范式2NF：</strong> 满足1NF的基础上，要求：表中的所有列，都必需依赖于主键，而不能有任何一列与主键没有关系（一个表只描述一件事情）。<strong>第二范式消除表的无关数据。</strong></li>\n<li><strong>第三范式3NF：</strong> 满足2NF的基础上，任何非主属性不依赖于其它非主属性（<strong>在2NF基础上消除传递依赖</strong>）（也表明不允许数据存在冗余的现象）。比如订单表里有买家id，还有买家姓名啥的，这是订单表，所有的列应该都和订单id有直接关系，买家id和订单id又直接关系，但是买家姓名应该在用户表里，不应该出现在订单表里。</li>\n</ul>\n<h2 id=\"五大约束\"><a href=\"#五大约束\" class=\"headerlink\" title=\"五大约束\"></a>五大约束</h2><ol>\n<li>主键约束（Primary Key）：唯一、非空</li>\n<li>唯一约束（Unique）：唯一、可空，但只能有一个空</li>\n<li>检查约束（Check）：数据长度、格式的限制</li>\n<li>默认约束（Default）：数据的默认值</li>\n<li>外键约束（Foreign Key）：通过外键建立两张表的关系</li>\n</ol>\n","site":{"data":{}},"more":"<p>范式（Normal Form），也就是规范化的形式。</p>\n<h2 id=\"三大范式\"><a href=\"#三大范式\" class=\"headerlink\" title=\"三大范式\"></a>三大范式</h2><ul>\n<li><strong>第一范式1NF：</strong> 数据表中的每一列(字段)，必须是不可拆分的最小单元，也就是确保每一列的原子性，而不是集合。比如地址可以分成省、市、区等等。</li>\n<li><strong>第二范式2NF：</strong> 满足1NF的基础上，要求：表中的所有列，都必需依赖于主键，而不能有任何一列与主键没有关系（一个表只描述一件事情）。<strong>第二范式消除表的无关数据。</strong></li>\n<li><strong>第三范式3NF：</strong> 满足2NF的基础上，任何非主属性不依赖于其它非主属性（<strong>在2NF基础上消除传递依赖</strong>）（也表明不允许数据存在冗余的现象）。比如订单表里有买家id，还有买家姓名啥的，这是订单表，所有的列应该都和订单id有直接关系，买家id和订单id又直接关系，但是买家姓名应该在用户表里，不应该出现在订单表里。</li>\n</ul>\n<h2 id=\"五大约束\"><a href=\"#五大约束\" class=\"headerlink\" title=\"五大约束\"></a>五大约束</h2><ol>\n<li>主键约束（Primary Key）：唯一、非空</li>\n<li>唯一约束（Unique）：唯一、可空，但只能有一个空</li>\n<li>检查约束（Check）：数据长度、格式的限制</li>\n<li>默认约束（Default）：数据的默认值</li>\n<li>外键约束（Foreign Key）：通过外键建立两张表的关系</li>\n</ol>\n"},{"title":"一次服务器告警的处理","excerpt":"","comments":1,"date":"2020-04-29T16:30:52.000Z","_content":"\n## 一次服务器告警的处理\n\n今天客户在群里一阵@我，说是收到服务器告警短信了。\n\n```\nUsage disk is more than 90% on volume /home...\n```\n\n磁盘空间告急啊。\n\n### 分析\n\n这台机器上部署了应用和MySQL，日志文件和数据库文件应该是存储的大头，所以立即锁定目标。\n\n为了不泄漏公司机密，以下数据都是我本地的，**有内味就行了**\n\n我迅速连上公司vpn，ssh到目标主机。\n\n```shell\ntest@Evil:~$ df -h\nFilesystem      Size  Used Avail Use% Mounted on\nrootfs           59G   51G  7.7G  87% /\nnone             59G   51G  7.7G  87% /dev\nnone             59G   55G  7.7G  92% /home\n...\n```\n\n可以看到`/home`目录果然超过90%。\n\n```shell\ntest@Evil:~$ du -h -d 1 *\n37G    Mysql\n12G    logs/xxx\n12G    logs\n...\n```\n\n查看/home目录下文件的大小，可以看到确实是Mysql和logs占了使用空间的大头。。\n\n### 清理应用日志\n\n日志文件好整，我获得了客户的授权，一波删除带走\n\n```shell\nrm -rf logs/xxx/xx-2019-*.log\n```\n\n去年的日志一波带走\n\n```shell\ntest@Evil:~$ du -h -d 1 *\n37G    Mysql\n2G    logs/xxx\n2G    logs\n...\n```\n\n看到回了口血，一阵欣慰，毕竟在生产`rm -rf`的机会不多。。\n\n### mysql binlog\n\n接下来就是搞Mysql了\n\n我知道，它占用空间的大头，也就是数据库文件和binlog文件了，binlog好搞，先易后难。\n\n因为是单点的mysql，所以不用担心什么主备同步问题，带走。。\n\n```shell\nmysql> reset master; # 清空所有 binlog 文件\n```\n\n### mysql ibdata1\n\nmysql的数据文件，我真的是头疼，上次处理相似问题的时候，跟公司的dba讨论了一下，好像是得先导出数据，然后删除ibdata1文件，再启动mysql，导入数据。\n\n**大白天的怎么能干这种事儿呢？**\n\n只能先分析一波了。\n\n1. ibdata1是啥呢？\n   ibdata1是一个用来构建innodb系统表空间的文件，这个文件包含了innodb表的元数据、撤销记录、修改buffer和双写buffer。如果file-per-table选项打开的话，该文件则不一定包含所有表的数据。当innodb_file_per_table选项打开的话，新创建表的数据和索引则不会存在系统表空间中，而是存放在各自表的.ibd文件中。显然这个文件会越来越大，innodb_autoextend_increment选项则指定了该文件每次自动增长的步进，默认是8M.\n\n2. 他为啥会变大？\n   ibdata1存放数据，索引和缓存等，是MYSQL的最主要的数据。所以随着数据库越来越大，表也会越大，这个无法避免的。\n\n3. 怎么搞掉它？\n   首先我们把数据库备份下来，然后直接删除ibdata文件（为了保险起见最好先全备一次，做到数据安全和完整），然后再重新导入数据库文件即可！\n\n```shell\n#停止业务，备份一次全库\nmysqldump -u root -p password --all-databases  > all_mysql.sql\n#备份完成，停止数据库\nsystemctl stop mariadb 或者 service mysqld stop\n#修改配置文件\n#在[mysqld]下增加下面配置 innodb_file_per_table=1 \n\n#可以重启mysql后\nservice mysqld restart\n#验证\nmysql -u root -p password\n\nshow variables like '%per_table%';\n\n+-----------------------+-------+\n| Variable_name | Value |       |\n+-----------------------+-------+\n| innodb_file_per_table | ON    |\n+-----------------------+-------+\n\n1 row in set (0.00 sec)\n\ninnodb_file_per_table的状态变为ON\n\n5、删除ibdata1文件和日志\n\nrm -rf ibdata1\nrm -rf ib_logfile*\n\n6、恢复数据\nmysql -u user -p password\nsource all_mysql.sql\n```\n\n在MySQL的配置文件[mysqld]部分，增加innodb_file_per_table参数。可以修改InnoDB为独立表空间模式，每个数据库的每个表都会生成一个数据空间。\n\n**优点：**\n- 每个表都有自已独立的表空间。\n- 每个表的数据和索引都会存在自已的表空间中。\n- 可以实现单表在不同的数据库中移动。\n- 空间可以回收（除drop table操作处，表空不能自已回收）\n  - Drop table操作自动回收表空间，如果对于统计分析或是日值表，删除大量数据后可以通过`alter table TableName engine=innodb;`回缩不用的空间。\n  - 对于使innodb-plugin的Innodb使用turncate table也会使空间收缩。\n  - 对于使用独立表空间的表，不管怎么删除，表空间的碎片不会太严重的影响性能，而且还有机会处理。\n\n**缺点：**\n- 单表增加过大，如超过100个G。\n\n\n## 总结\n\nibdata得等晚上搞了，但愿顺利。\n不过这台机器的问题，这么搞也不是长久之际。数据库这块，之前会存日志到库表里，后来客户觉得有日志文件就不用了，写日志到文件的代码已经被我注释了。今晚搞一波ibdata，应该以后增速不会很快了。应用日志一天几百兆，这块得做个定时任务，定期删除日志文件，等下写个脚本，加到系统的crontab里。这样应该能消停了。\n","source":"_posts/2020-04-30-kongzheng1993-一次服务器告警的处理.md","raw":"---\ntitle: 一次服务器告警的处理\nexcerpt: ''\ntags: [Ohters]\ncategories: [Ohters]\ncomments: true\ndate: 2020-04-30 00:30:52\n---\n\n## 一次服务器告警的处理\n\n今天客户在群里一阵@我，说是收到服务器告警短信了。\n\n```\nUsage disk is more than 90% on volume /home...\n```\n\n磁盘空间告急啊。\n\n### 分析\n\n这台机器上部署了应用和MySQL，日志文件和数据库文件应该是存储的大头，所以立即锁定目标。\n\n为了不泄漏公司机密，以下数据都是我本地的，**有内味就行了**\n\n我迅速连上公司vpn，ssh到目标主机。\n\n```shell\ntest@Evil:~$ df -h\nFilesystem      Size  Used Avail Use% Mounted on\nrootfs           59G   51G  7.7G  87% /\nnone             59G   51G  7.7G  87% /dev\nnone             59G   55G  7.7G  92% /home\n...\n```\n\n可以看到`/home`目录果然超过90%。\n\n```shell\ntest@Evil:~$ du -h -d 1 *\n37G    Mysql\n12G    logs/xxx\n12G    logs\n...\n```\n\n查看/home目录下文件的大小，可以看到确实是Mysql和logs占了使用空间的大头。。\n\n### 清理应用日志\n\n日志文件好整，我获得了客户的授权，一波删除带走\n\n```shell\nrm -rf logs/xxx/xx-2019-*.log\n```\n\n去年的日志一波带走\n\n```shell\ntest@Evil:~$ du -h -d 1 *\n37G    Mysql\n2G    logs/xxx\n2G    logs\n...\n```\n\n看到回了口血，一阵欣慰，毕竟在生产`rm -rf`的机会不多。。\n\n### mysql binlog\n\n接下来就是搞Mysql了\n\n我知道，它占用空间的大头，也就是数据库文件和binlog文件了，binlog好搞，先易后难。\n\n因为是单点的mysql，所以不用担心什么主备同步问题，带走。。\n\n```shell\nmysql> reset master; # 清空所有 binlog 文件\n```\n\n### mysql ibdata1\n\nmysql的数据文件，我真的是头疼，上次处理相似问题的时候，跟公司的dba讨论了一下，好像是得先导出数据，然后删除ibdata1文件，再启动mysql，导入数据。\n\n**大白天的怎么能干这种事儿呢？**\n\n只能先分析一波了。\n\n1. ibdata1是啥呢？\n   ibdata1是一个用来构建innodb系统表空间的文件，这个文件包含了innodb表的元数据、撤销记录、修改buffer和双写buffer。如果file-per-table选项打开的话，该文件则不一定包含所有表的数据。当innodb_file_per_table选项打开的话，新创建表的数据和索引则不会存在系统表空间中，而是存放在各自表的.ibd文件中。显然这个文件会越来越大，innodb_autoextend_increment选项则指定了该文件每次自动增长的步进，默认是8M.\n\n2. 他为啥会变大？\n   ibdata1存放数据，索引和缓存等，是MYSQL的最主要的数据。所以随着数据库越来越大，表也会越大，这个无法避免的。\n\n3. 怎么搞掉它？\n   首先我们把数据库备份下来，然后直接删除ibdata文件（为了保险起见最好先全备一次，做到数据安全和完整），然后再重新导入数据库文件即可！\n\n```shell\n#停止业务，备份一次全库\nmysqldump -u root -p password --all-databases  > all_mysql.sql\n#备份完成，停止数据库\nsystemctl stop mariadb 或者 service mysqld stop\n#修改配置文件\n#在[mysqld]下增加下面配置 innodb_file_per_table=1 \n\n#可以重启mysql后\nservice mysqld restart\n#验证\nmysql -u root -p password\n\nshow variables like '%per_table%';\n\n+-----------------------+-------+\n| Variable_name | Value |       |\n+-----------------------+-------+\n| innodb_file_per_table | ON    |\n+-----------------------+-------+\n\n1 row in set (0.00 sec)\n\ninnodb_file_per_table的状态变为ON\n\n5、删除ibdata1文件和日志\n\nrm -rf ibdata1\nrm -rf ib_logfile*\n\n6、恢复数据\nmysql -u user -p password\nsource all_mysql.sql\n```\n\n在MySQL的配置文件[mysqld]部分，增加innodb_file_per_table参数。可以修改InnoDB为独立表空间模式，每个数据库的每个表都会生成一个数据空间。\n\n**优点：**\n- 每个表都有自已独立的表空间。\n- 每个表的数据和索引都会存在自已的表空间中。\n- 可以实现单表在不同的数据库中移动。\n- 空间可以回收（除drop table操作处，表空不能自已回收）\n  - Drop table操作自动回收表空间，如果对于统计分析或是日值表，删除大量数据后可以通过`alter table TableName engine=innodb;`回缩不用的空间。\n  - 对于使innodb-plugin的Innodb使用turncate table也会使空间收缩。\n  - 对于使用独立表空间的表，不管怎么删除，表空间的碎片不会太严重的影响性能，而且还有机会处理。\n\n**缺点：**\n- 单表增加过大，如超过100个G。\n\n\n## 总结\n\nibdata得等晚上搞了，但愿顺利。\n不过这台机器的问题，这么搞也不是长久之际。数据库这块，之前会存日志到库表里，后来客户觉得有日志文件就不用了，写日志到文件的代码已经被我注释了。今晚搞一波ibdata，应该以后增速不会很快了。应用日志一天几百兆，这块得做个定时任务，定期删除日志文件，等下写个脚本，加到系统的crontab里。这样应该能消停了。\n","slug":"kongzheng1993-一次服务器告警的处理","published":1,"updated":"2023-03-08T07:05:58.800Z","layout":"post","photos":[],"link":"","_id":"clg0k2ak80048t26f03zs5gk2","content":"<h2 id=\"一次服务器告警的处理\"><a href=\"#一次服务器告警的处理\" class=\"headerlink\" title=\"一次服务器告警的处理\"></a>一次服务器告警的处理</h2><p>今天客户在群里一阵@我，说是收到服务器告警短信了。</p>\n<pre><code>Usage disk is more than 90% on volume /home...</code></pre><p>磁盘空间告急啊。</p>\n<h3 id=\"分析\"><a href=\"#分析\" class=\"headerlink\" title=\"分析\"></a>分析</h3><p>这台机器上部署了应用和MySQL，日志文件和数据库文件应该是存储的大头，所以立即锁定目标。</p>\n<p>为了不泄漏公司机密，以下数据都是我本地的，<strong>有内味就行了</strong></p>\n<p>我迅速连上公司vpn，ssh到目标主机。</p>\n<pre><code class=\"shell\">test@Evil:~$ df -h\nFilesystem      Size  Used Avail Use% Mounted on\nrootfs           59G   51G  7.7G  87% /\nnone             59G   51G  7.7G  87% /dev\nnone             59G   55G  7.7G  92% /home\n...</code></pre>\n<p>可以看到<code>/home</code>目录果然超过90%。</p>\n<pre><code class=\"shell\">test@Evil:~$ du -h -d 1 *\n37G    Mysql\n12G    logs/xxx\n12G    logs\n...</code></pre>\n<p>查看/home目录下文件的大小，可以看到确实是Mysql和logs占了使用空间的大头。。</p>\n<h3 id=\"清理应用日志\"><a href=\"#清理应用日志\" class=\"headerlink\" title=\"清理应用日志\"></a>清理应用日志</h3><p>日志文件好整，我获得了客户的授权，一波删除带走</p>\n<pre><code class=\"shell\">rm -rf logs/xxx/xx-2019-*.log</code></pre>\n<p>去年的日志一波带走</p>\n<pre><code class=\"shell\">test@Evil:~$ du -h -d 1 *\n37G    Mysql\n2G    logs/xxx\n2G    logs\n...</code></pre>\n<p>看到回了口血，一阵欣慰，毕竟在生产<code>rm -rf</code>的机会不多。。</p>\n<h3 id=\"mysql-binlog\"><a href=\"#mysql-binlog\" class=\"headerlink\" title=\"mysql binlog\"></a>mysql binlog</h3><p>接下来就是搞Mysql了</p>\n<p>我知道，它占用空间的大头，也就是数据库文件和binlog文件了，binlog好搞，先易后难。</p>\n<p>因为是单点的mysql，所以不用担心什么主备同步问题，带走。。</p>\n<pre><code class=\"shell\">mysql&gt; reset master; # 清空所有 binlog 文件</code></pre>\n<h3 id=\"mysql-ibdata1\"><a href=\"#mysql-ibdata1\" class=\"headerlink\" title=\"mysql ibdata1\"></a>mysql ibdata1</h3><p>mysql的数据文件，我真的是头疼，上次处理相似问题的时候，跟公司的dba讨论了一下，好像是得先导出数据，然后删除ibdata1文件，再启动mysql，导入数据。</p>\n<p><strong>大白天的怎么能干这种事儿呢？</strong></p>\n<p>只能先分析一波了。</p>\n<ol>\n<li><p>ibdata1是啥呢？<br>ibdata1是一个用来构建innodb系统表空间的文件，这个文件包含了innodb表的元数据、撤销记录、修改buffer和双写buffer。如果file-per-table选项打开的话，该文件则不一定包含所有表的数据。当innodb_file_per_table选项打开的话，新创建表的数据和索引则不会存在系统表空间中，而是存放在各自表的.ibd文件中。显然这个文件会越来越大，innodb_autoextend_increment选项则指定了该文件每次自动增长的步进，默认是8M.</p>\n</li>\n<li><p>他为啥会变大？<br>ibdata1存放数据，索引和缓存等，是MYSQL的最主要的数据。所以随着数据库越来越大，表也会越大，这个无法避免的。</p>\n</li>\n<li><p>怎么搞掉它？<br>首先我们把数据库备份下来，然后直接删除ibdata文件（为了保险起见最好先全备一次，做到数据安全和完整），然后再重新导入数据库文件即可！</p>\n</li>\n</ol>\n<pre><code class=\"shell\">#停止业务，备份一次全库\nmysqldump -u root -p password --all-databases  &gt; all_mysql.sql\n#备份完成，停止数据库\nsystemctl stop mariadb 或者 service mysqld stop\n#修改配置文件\n#在[mysqld]下增加下面配置 innodb_file_per_table=1 \n\n#可以重启mysql后\nservice mysqld restart\n#验证\nmysql -u root -p password\n\nshow variables like &#39;%per_table%&#39;;\n\n+-----------------------+-------+\n| Variable_name | Value |       |\n+-----------------------+-------+\n| innodb_file_per_table | ON    |\n+-----------------------+-------+\n\n1 row in set (0.00 sec)\n\ninnodb_file_per_table的状态变为ON\n\n5、删除ibdata1文件和日志\n\nrm -rf ibdata1\nrm -rf ib_logfile*\n\n6、恢复数据\nmysql -u user -p password\nsource all_mysql.sql</code></pre>\n<p>在MySQL的配置文件[mysqld]部分，增加innodb_file_per_table参数。可以修改InnoDB为独立表空间模式，每个数据库的每个表都会生成一个数据空间。</p>\n<p><strong>优点：</strong></p>\n<ul>\n<li>每个表都有自已独立的表空间。</li>\n<li>每个表的数据和索引都会存在自已的表空间中。</li>\n<li>可以实现单表在不同的数据库中移动。</li>\n<li>空间可以回收（除drop table操作处，表空不能自已回收）<ul>\n<li>Drop table操作自动回收表空间，如果对于统计分析或是日值表，删除大量数据后可以通过<code>alter table TableName engine=innodb;</code>回缩不用的空间。</li>\n<li>对于使innodb-plugin的Innodb使用turncate table也会使空间收缩。</li>\n<li>对于使用独立表空间的表，不管怎么删除，表空间的碎片不会太严重的影响性能，而且还有机会处理。</li>\n</ul>\n</li>\n</ul>\n<p><strong>缺点：</strong></p>\n<ul>\n<li>单表增加过大，如超过100个G。</li>\n</ul>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>ibdata得等晚上搞了，但愿顺利。<br>不过这台机器的问题，这么搞也不是长久之际。数据库这块，之前会存日志到库表里，后来客户觉得有日志文件就不用了，写日志到文件的代码已经被我注释了。今晚搞一波ibdata，应该以后增速不会很快了。应用日志一天几百兆，这块得做个定时任务，定期删除日志文件，等下写个脚本，加到系统的crontab里。这样应该能消停了。</p>\n","site":{"data":{}},"more":"<h2 id=\"一次服务器告警的处理\"><a href=\"#一次服务器告警的处理\" class=\"headerlink\" title=\"一次服务器告警的处理\"></a>一次服务器告警的处理</h2><p>今天客户在群里一阵@我，说是收到服务器告警短信了。</p>\n<pre><code>Usage disk is more than 90% on volume /home...</code></pre><p>磁盘空间告急啊。</p>\n<h3 id=\"分析\"><a href=\"#分析\" class=\"headerlink\" title=\"分析\"></a>分析</h3><p>这台机器上部署了应用和MySQL，日志文件和数据库文件应该是存储的大头，所以立即锁定目标。</p>\n<p>为了不泄漏公司机密，以下数据都是我本地的，<strong>有内味就行了</strong></p>\n<p>我迅速连上公司vpn，ssh到目标主机。</p>\n<pre><code class=\"shell\">test@Evil:~$ df -h\nFilesystem      Size  Used Avail Use% Mounted on\nrootfs           59G   51G  7.7G  87% /\nnone             59G   51G  7.7G  87% /dev\nnone             59G   55G  7.7G  92% /home\n...</code></pre>\n<p>可以看到<code>/home</code>目录果然超过90%。</p>\n<pre><code class=\"shell\">test@Evil:~$ du -h -d 1 *\n37G    Mysql\n12G    logs/xxx\n12G    logs\n...</code></pre>\n<p>查看/home目录下文件的大小，可以看到确实是Mysql和logs占了使用空间的大头。。</p>\n<h3 id=\"清理应用日志\"><a href=\"#清理应用日志\" class=\"headerlink\" title=\"清理应用日志\"></a>清理应用日志</h3><p>日志文件好整，我获得了客户的授权，一波删除带走</p>\n<pre><code class=\"shell\">rm -rf logs/xxx/xx-2019-*.log</code></pre>\n<p>去年的日志一波带走</p>\n<pre><code class=\"shell\">test@Evil:~$ du -h -d 1 *\n37G    Mysql\n2G    logs/xxx\n2G    logs\n...</code></pre>\n<p>看到回了口血，一阵欣慰，毕竟在生产<code>rm -rf</code>的机会不多。。</p>\n<h3 id=\"mysql-binlog\"><a href=\"#mysql-binlog\" class=\"headerlink\" title=\"mysql binlog\"></a>mysql binlog</h3><p>接下来就是搞Mysql了</p>\n<p>我知道，它占用空间的大头，也就是数据库文件和binlog文件了，binlog好搞，先易后难。</p>\n<p>因为是单点的mysql，所以不用担心什么主备同步问题，带走。。</p>\n<pre><code class=\"shell\">mysql&gt; reset master; # 清空所有 binlog 文件</code></pre>\n<h3 id=\"mysql-ibdata1\"><a href=\"#mysql-ibdata1\" class=\"headerlink\" title=\"mysql ibdata1\"></a>mysql ibdata1</h3><p>mysql的数据文件，我真的是头疼，上次处理相似问题的时候，跟公司的dba讨论了一下，好像是得先导出数据，然后删除ibdata1文件，再启动mysql，导入数据。</p>\n<p><strong>大白天的怎么能干这种事儿呢？</strong></p>\n<p>只能先分析一波了。</p>\n<ol>\n<li><p>ibdata1是啥呢？<br>ibdata1是一个用来构建innodb系统表空间的文件，这个文件包含了innodb表的元数据、撤销记录、修改buffer和双写buffer。如果file-per-table选项打开的话，该文件则不一定包含所有表的数据。当innodb_file_per_table选项打开的话，新创建表的数据和索引则不会存在系统表空间中，而是存放在各自表的.ibd文件中。显然这个文件会越来越大，innodb_autoextend_increment选项则指定了该文件每次自动增长的步进，默认是8M.</p>\n</li>\n<li><p>他为啥会变大？<br>ibdata1存放数据，索引和缓存等，是MYSQL的最主要的数据。所以随着数据库越来越大，表也会越大，这个无法避免的。</p>\n</li>\n<li><p>怎么搞掉它？<br>首先我们把数据库备份下来，然后直接删除ibdata文件（为了保险起见最好先全备一次，做到数据安全和完整），然后再重新导入数据库文件即可！</p>\n</li>\n</ol>\n<pre><code class=\"shell\">#停止业务，备份一次全库\nmysqldump -u root -p password --all-databases  &gt; all_mysql.sql\n#备份完成，停止数据库\nsystemctl stop mariadb 或者 service mysqld stop\n#修改配置文件\n#在[mysqld]下增加下面配置 innodb_file_per_table=1 \n\n#可以重启mysql后\nservice mysqld restart\n#验证\nmysql -u root -p password\n\nshow variables like &#39;%per_table%&#39;;\n\n+-----------------------+-------+\n| Variable_name | Value |       |\n+-----------------------+-------+\n| innodb_file_per_table | ON    |\n+-----------------------+-------+\n\n1 row in set (0.00 sec)\n\ninnodb_file_per_table的状态变为ON\n\n5、删除ibdata1文件和日志\n\nrm -rf ibdata1\nrm -rf ib_logfile*\n\n6、恢复数据\nmysql -u user -p password\nsource all_mysql.sql</code></pre>\n<p>在MySQL的配置文件[mysqld]部分，增加innodb_file_per_table参数。可以修改InnoDB为独立表空间模式，每个数据库的每个表都会生成一个数据空间。</p>\n<p><strong>优点：</strong></p>\n<ul>\n<li>每个表都有自已独立的表空间。</li>\n<li>每个表的数据和索引都会存在自已的表空间中。</li>\n<li>可以实现单表在不同的数据库中移动。</li>\n<li>空间可以回收（除drop table操作处，表空不能自已回收）<ul>\n<li>Drop table操作自动回收表空间，如果对于统计分析或是日值表，删除大量数据后可以通过<code>alter table TableName engine=innodb;</code>回缩不用的空间。</li>\n<li>对于使innodb-plugin的Innodb使用turncate table也会使空间收缩。</li>\n<li>对于使用独立表空间的表，不管怎么删除，表空间的碎片不会太严重的影响性能，而且还有机会处理。</li>\n</ul>\n</li>\n</ul>\n<p><strong>缺点：</strong></p>\n<ul>\n<li>单表增加过大，如超过100个G。</li>\n</ul>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>ibdata得等晚上搞了，但愿顺利。<br>不过这台机器的问题，这么搞也不是长久之际。数据库这块，之前会存日志到库表里，后来客户觉得有日志文件就不用了，写日志到文件的代码已经被我注释了。今晚搞一波ibdata，应该以后增速不会很快了。应用日志一天几百兆，这块得做个定时任务，定期删除日志文件，等下写个脚本，加到系统的crontab里。这样应该能消停了。</p>\n"},{"title":"Linux文件句柄","excerpt":"","comments":1,"date":"2020-05-11T16:30:52.000Z","_content":"\n## 什么是文件句柄\n\n在文件I/O中，要从一个文件读取数据，应用程序首先要调用操作系统函数并传送文件名，并选一个到该文件的路径来打开文件。该函数取回一个顺序号，即**文件句柄（file handle）**。文件句柄，也叫文件描述符。**文件描述符（File Descriptor）** 是内核为了高效管理已被打开的文件所创建的索引，它是一个非负整数（通常是小整数），用于指代被打开的文件。所有的IO系统调用，包括socket的读写调用，都是通过文件描述符完成的。在Linux系统中，文件可分为：*普通文件、目录文件、链接文件和设备文件。*\n\n\n## 为什么要自己设置文件句柄\n\nLinux系统默认值为1024，也就是说，一个进程最多可以接受1024个socket连接。即使采用了最先进的模型，如果不进行合理的配置，也没有办法支撑百万级的网络连接并发。\n\n在Linux下，通过调用`ulimit`命令，可以看到单个进程能够打开的最大文件句柄数量，这个命令的具体使用方法是：\n\n```shell\nulimit -n\n```\n\n什么是`ulimit`命令呢？它是用来显示和修改当前用户进程一些基础限制的命令，`-n`命令选项用于引用或设置当前的文件句柄数量的限制值。Linux的系统默认值为1024。默认的数值为1024，对绝大多数应用（例如Apache、桌面应用程序）来说已经足够了。但是，是对于一些用户基数很大的**高并发**应用，则是远远不够的。一个高并发的应用，面临的并发连接数往往是十万级、百万级、千万级、甚至像腾讯QQ一样的上亿级。文件句柄数不够，会导致什么后果呢？当单个进程打开的文件句柄数量，超过了系统配置的上限值时，就会发出`Socket/File:Can't open so many files`的错误提示。对于高并发、高负载的应用，就必须要调整这个系统参数，以适应处理并发处理大量连接的应用场景。可以通过`ulimit`来设置这两个参数。方法如下：\n\n```shell\nulimit -n 1000000\n```\n\n在上面的命令中，n的设置值越大，可以打开的文件句柄数量就越大。建议以root用户来执行此命令。然而，使用`ulimit`命令来修改当前用户进程的一些基础限制，仅在当前用户环境有效。直白地说，就是在当前的终端工具连接当前shell期间，修改是有效的；一旦断开连接，用户退出后，它的数值就又变回系统默认的1024了。也就是说，`ulimit`只能作为临时修改，系统重启后，句柄数量又会恢复为默认值。如果想永久地把设置值保存下来，可以编辑`/etc/rc.local`开机启动文件，在文件中添加如下内容：\n\n```shell\nulimit -SHn 1000000\n```\n\n增加`-S`和`-H`两个命令选项。选项`-S`表示软性极限值，`-H`表示硬性极限值。硬性极限是实际的限制，就是最大可以是100万，不能再多了。软性极限是系统警告（Warning）的极限值，超过这个极限值，内核会发出警告。\n\n普通用户通过`ulimit`命令，可将软极限更改到硬极限的最大设置值。如果要更改硬极限，必须拥有**root**用户权限。终极解除Linux系统的最大文件打开数量的限制，可以通过编辑Linux的极限配置文件`/etc/security/limits.conf`来解决，修改此文件，加入如下内容：\n\n```shell\nsoft nofile 1000000\nhard nofile 1000000\n```\n\n`soft nofile`表示软性极限，`hard nofile`表示硬性极限。\n\n在使用和安装目前非常火的分布式搜索引擎——ElasticSearch，就必须去修改这个文件，增加最大的文件句柄数的极限值。如果mysql出现`Socket/File:Can't open so many files`的错误提示，也可以通过增加最大文件句柄数的极限值。在服务器运行Netty时，也需要去解除文件句柄数量的限制，修改/etc/security/limits.conf文件即可。","source":"_posts/2020-05-12-kongzheng1993-Linux文件句柄.md","raw":"---\ntitle: Linux文件句柄\nexcerpt: ''\ntags: [others]\ncategories: [others]\ncomments: true\ndate: 2020-05-12 00:30:52\n---\n\n## 什么是文件句柄\n\n在文件I/O中，要从一个文件读取数据，应用程序首先要调用操作系统函数并传送文件名，并选一个到该文件的路径来打开文件。该函数取回一个顺序号，即**文件句柄（file handle）**。文件句柄，也叫文件描述符。**文件描述符（File Descriptor）** 是内核为了高效管理已被打开的文件所创建的索引，它是一个非负整数（通常是小整数），用于指代被打开的文件。所有的IO系统调用，包括socket的读写调用，都是通过文件描述符完成的。在Linux系统中，文件可分为：*普通文件、目录文件、链接文件和设备文件。*\n\n\n## 为什么要自己设置文件句柄\n\nLinux系统默认值为1024，也就是说，一个进程最多可以接受1024个socket连接。即使采用了最先进的模型，如果不进行合理的配置，也没有办法支撑百万级的网络连接并发。\n\n在Linux下，通过调用`ulimit`命令，可以看到单个进程能够打开的最大文件句柄数量，这个命令的具体使用方法是：\n\n```shell\nulimit -n\n```\n\n什么是`ulimit`命令呢？它是用来显示和修改当前用户进程一些基础限制的命令，`-n`命令选项用于引用或设置当前的文件句柄数量的限制值。Linux的系统默认值为1024。默认的数值为1024，对绝大多数应用（例如Apache、桌面应用程序）来说已经足够了。但是，是对于一些用户基数很大的**高并发**应用，则是远远不够的。一个高并发的应用，面临的并发连接数往往是十万级、百万级、千万级、甚至像腾讯QQ一样的上亿级。文件句柄数不够，会导致什么后果呢？当单个进程打开的文件句柄数量，超过了系统配置的上限值时，就会发出`Socket/File:Can't open so many files`的错误提示。对于高并发、高负载的应用，就必须要调整这个系统参数，以适应处理并发处理大量连接的应用场景。可以通过`ulimit`来设置这两个参数。方法如下：\n\n```shell\nulimit -n 1000000\n```\n\n在上面的命令中，n的设置值越大，可以打开的文件句柄数量就越大。建议以root用户来执行此命令。然而，使用`ulimit`命令来修改当前用户进程的一些基础限制，仅在当前用户环境有效。直白地说，就是在当前的终端工具连接当前shell期间，修改是有效的；一旦断开连接，用户退出后，它的数值就又变回系统默认的1024了。也就是说，`ulimit`只能作为临时修改，系统重启后，句柄数量又会恢复为默认值。如果想永久地把设置值保存下来，可以编辑`/etc/rc.local`开机启动文件，在文件中添加如下内容：\n\n```shell\nulimit -SHn 1000000\n```\n\n增加`-S`和`-H`两个命令选项。选项`-S`表示软性极限值，`-H`表示硬性极限值。硬性极限是实际的限制，就是最大可以是100万，不能再多了。软性极限是系统警告（Warning）的极限值，超过这个极限值，内核会发出警告。\n\n普通用户通过`ulimit`命令，可将软极限更改到硬极限的最大设置值。如果要更改硬极限，必须拥有**root**用户权限。终极解除Linux系统的最大文件打开数量的限制，可以通过编辑Linux的极限配置文件`/etc/security/limits.conf`来解决，修改此文件，加入如下内容：\n\n```shell\nsoft nofile 1000000\nhard nofile 1000000\n```\n\n`soft nofile`表示软性极限，`hard nofile`表示硬性极限。\n\n在使用和安装目前非常火的分布式搜索引擎——ElasticSearch，就必须去修改这个文件，增加最大的文件句柄数的极限值。如果mysql出现`Socket/File:Can't open so many files`的错误提示，也可以通过增加最大文件句柄数的极限值。在服务器运行Netty时，也需要去解除文件句柄数量的限制，修改/etc/security/limits.conf文件即可。","slug":"kongzheng1993-Linux文件句柄","published":1,"updated":"2023-03-08T07:05:58.801Z","layout":"post","photos":[],"link":"","_id":"clg0k2ake004ct26f2miap5hq","content":"<h2 id=\"什么是文件句柄\"><a href=\"#什么是文件句柄\" class=\"headerlink\" title=\"什么是文件句柄\"></a>什么是文件句柄</h2><p>在文件I/O中，要从一个文件读取数据，应用程序首先要调用操作系统函数并传送文件名，并选一个到该文件的路径来打开文件。该函数取回一个顺序号，即<strong>文件句柄（file handle）</strong>。文件句柄，也叫文件描述符。<strong>文件描述符（File Descriptor）</strong> 是内核为了高效管理已被打开的文件所创建的索引，它是一个非负整数（通常是小整数），用于指代被打开的文件。所有的IO系统调用，包括socket的读写调用，都是通过文件描述符完成的。在Linux系统中，文件可分为：<em>普通文件、目录文件、链接文件和设备文件。</em></p>\n<h2 id=\"为什么要自己设置文件句柄\"><a href=\"#为什么要自己设置文件句柄\" class=\"headerlink\" title=\"为什么要自己设置文件句柄\"></a>为什么要自己设置文件句柄</h2><p>Linux系统默认值为1024，也就是说，一个进程最多可以接受1024个socket连接。即使采用了最先进的模型，如果不进行合理的配置，也没有办法支撑百万级的网络连接并发。</p>\n<p>在Linux下，通过调用<code>ulimit</code>命令，可以看到单个进程能够打开的最大文件句柄数量，这个命令的具体使用方法是：</p>\n<pre><code class=\"shell\">ulimit -n</code></pre>\n<p>什么是<code>ulimit</code>命令呢？它是用来显示和修改当前用户进程一些基础限制的命令，<code>-n</code>命令选项用于引用或设置当前的文件句柄数量的限制值。Linux的系统默认值为1024。默认的数值为1024，对绝大多数应用（例如Apache、桌面应用程序）来说已经足够了。但是，是对于一些用户基数很大的<strong>高并发</strong>应用，则是远远不够的。一个高并发的应用，面临的并发连接数往往是十万级、百万级、千万级、甚至像腾讯QQ一样的上亿级。文件句柄数不够，会导致什么后果呢？当单个进程打开的文件句柄数量，超过了系统配置的上限值时，就会发出<code>Socket/File:Can&#39;t open so many files</code>的错误提示。对于高并发、高负载的应用，就必须要调整这个系统参数，以适应处理并发处理大量连接的应用场景。可以通过<code>ulimit</code>来设置这两个参数。方法如下：</p>\n<pre><code class=\"shell\">ulimit -n 1000000</code></pre>\n<p>在上面的命令中，n的设置值越大，可以打开的文件句柄数量就越大。建议以root用户来执行此命令。然而，使用<code>ulimit</code>命令来修改当前用户进程的一些基础限制，仅在当前用户环境有效。直白地说，就是在当前的终端工具连接当前shell期间，修改是有效的；一旦断开连接，用户退出后，它的数值就又变回系统默认的1024了。也就是说，<code>ulimit</code>只能作为临时修改，系统重启后，句柄数量又会恢复为默认值。如果想永久地把设置值保存下来，可以编辑<code>/etc/rc.local</code>开机启动文件，在文件中添加如下内容：</p>\n<pre><code class=\"shell\">ulimit -SHn 1000000</code></pre>\n<p>增加<code>-S</code>和<code>-H</code>两个命令选项。选项<code>-S</code>表示软性极限值，<code>-H</code>表示硬性极限值。硬性极限是实际的限制，就是最大可以是100万，不能再多了。软性极限是系统警告（Warning）的极限值，超过这个极限值，内核会发出警告。</p>\n<p>普通用户通过<code>ulimit</code>命令，可将软极限更改到硬极限的最大设置值。如果要更改硬极限，必须拥有<strong>root</strong>用户权限。终极解除Linux系统的最大文件打开数量的限制，可以通过编辑Linux的极限配置文件<code>/etc/security/limits.conf</code>来解决，修改此文件，加入如下内容：</p>\n<pre><code class=\"shell\">soft nofile 1000000\nhard nofile 1000000</code></pre>\n<p><code>soft nofile</code>表示软性极限，<code>hard nofile</code>表示硬性极限。</p>\n<p>在使用和安装目前非常火的分布式搜索引擎——ElasticSearch，就必须去修改这个文件，增加最大的文件句柄数的极限值。如果mysql出现<code>Socket/File:Can&#39;t open so many files</code>的错误提示，也可以通过增加最大文件句柄数的极限值。在服务器运行Netty时，也需要去解除文件句柄数量的限制，修改/etc/security/limits.conf文件即可。</p>\n","site":{"data":{}},"more":"<h2 id=\"什么是文件句柄\"><a href=\"#什么是文件句柄\" class=\"headerlink\" title=\"什么是文件句柄\"></a>什么是文件句柄</h2><p>在文件I/O中，要从一个文件读取数据，应用程序首先要调用操作系统函数并传送文件名，并选一个到该文件的路径来打开文件。该函数取回一个顺序号，即<strong>文件句柄（file handle）</strong>。文件句柄，也叫文件描述符。<strong>文件描述符（File Descriptor）</strong> 是内核为了高效管理已被打开的文件所创建的索引，它是一个非负整数（通常是小整数），用于指代被打开的文件。所有的IO系统调用，包括socket的读写调用，都是通过文件描述符完成的。在Linux系统中，文件可分为：<em>普通文件、目录文件、链接文件和设备文件。</em></p>\n<h2 id=\"为什么要自己设置文件句柄\"><a href=\"#为什么要自己设置文件句柄\" class=\"headerlink\" title=\"为什么要自己设置文件句柄\"></a>为什么要自己设置文件句柄</h2><p>Linux系统默认值为1024，也就是说，一个进程最多可以接受1024个socket连接。即使采用了最先进的模型，如果不进行合理的配置，也没有办法支撑百万级的网络连接并发。</p>\n<p>在Linux下，通过调用<code>ulimit</code>命令，可以看到单个进程能够打开的最大文件句柄数量，这个命令的具体使用方法是：</p>\n<pre><code class=\"shell\">ulimit -n</code></pre>\n<p>什么是<code>ulimit</code>命令呢？它是用来显示和修改当前用户进程一些基础限制的命令，<code>-n</code>命令选项用于引用或设置当前的文件句柄数量的限制值。Linux的系统默认值为1024。默认的数值为1024，对绝大多数应用（例如Apache、桌面应用程序）来说已经足够了。但是，是对于一些用户基数很大的<strong>高并发</strong>应用，则是远远不够的。一个高并发的应用，面临的并发连接数往往是十万级、百万级、千万级、甚至像腾讯QQ一样的上亿级。文件句柄数不够，会导致什么后果呢？当单个进程打开的文件句柄数量，超过了系统配置的上限值时，就会发出<code>Socket/File:Can&#39;t open so many files</code>的错误提示。对于高并发、高负载的应用，就必须要调整这个系统参数，以适应处理并发处理大量连接的应用场景。可以通过<code>ulimit</code>来设置这两个参数。方法如下：</p>\n<pre><code class=\"shell\">ulimit -n 1000000</code></pre>\n<p>在上面的命令中，n的设置值越大，可以打开的文件句柄数量就越大。建议以root用户来执行此命令。然而，使用<code>ulimit</code>命令来修改当前用户进程的一些基础限制，仅在当前用户环境有效。直白地说，就是在当前的终端工具连接当前shell期间，修改是有效的；一旦断开连接，用户退出后，它的数值就又变回系统默认的1024了。也就是说，<code>ulimit</code>只能作为临时修改，系统重启后，句柄数量又会恢复为默认值。如果想永久地把设置值保存下来，可以编辑<code>/etc/rc.local</code>开机启动文件，在文件中添加如下内容：</p>\n<pre><code class=\"shell\">ulimit -SHn 1000000</code></pre>\n<p>增加<code>-S</code>和<code>-H</code>两个命令选项。选项<code>-S</code>表示软性极限值，<code>-H</code>表示硬性极限值。硬性极限是实际的限制，就是最大可以是100万，不能再多了。软性极限是系统警告（Warning）的极限值，超过这个极限值，内核会发出警告。</p>\n<p>普通用户通过<code>ulimit</code>命令，可将软极限更改到硬极限的最大设置值。如果要更改硬极限，必须拥有<strong>root</strong>用户权限。终极解除Linux系统的最大文件打开数量的限制，可以通过编辑Linux的极限配置文件<code>/etc/security/limits.conf</code>来解决，修改此文件，加入如下内容：</p>\n<pre><code class=\"shell\">soft nofile 1000000\nhard nofile 1000000</code></pre>\n<p><code>soft nofile</code>表示软性极限，<code>hard nofile</code>表示硬性极限。</p>\n<p>在使用和安装目前非常火的分布式搜索引擎——ElasticSearch，就必须去修改这个文件，增加最大的文件句柄数的极限值。如果mysql出现<code>Socket/File:Can&#39;t open so many files</code>的错误提示，也可以通过增加最大文件句柄数的极限值。在服务器运行Netty时，也需要去解除文件句柄数量的限制，修改/etc/security/limits.conf文件即可。</p>\n"},{"title":"记一次Maven冒险","excerpt":"","comments":1,"date":"2020-05-20T16:30:52.000Z","_content":"\n最近给框架升级，由于总部研发给的新框架是deploy到私有maven库，我们也都是在本地开发，到私有远程maven库网络是不通的，所以我也只能跳到那边把几个jar包下载，然后sftp到一台两边都通的服务器上，再搞到本地。。不就是mvn install嘛，我以为我可以系列，哈哈。。正好今天也查了很多资料，就记录下来，希望能帮到有缘人。。\n\n## mvn install\n\n将项目的主要工件以及生命周期中其他插件附带的任何其他工件安装到本地存储库。\n\n### 一般用法\n\n我脑海里记得到参数也就是这些了\n\n```shell\nmvn install:install-file -DgroupId=com.xxx -DartifactId=xxx -Dversion=1.0.0 -Dpackaging=jar -Dfile=you-jar-file-path\n```\n\n相关的参数可以查看[install:install-file](http://maven.apache.org/plugins/maven-install-plugin/install-file-mojo.html)\n\n这里的参数里`-Dfile`是必须的，毕竟没文件，你install个毛线。。\n其他参数都是可选的，毕竟jar文件如果也是maven工程，它会默认用父pom的`groupID`、`artifactId`、`version`参数。\n\n但就是这些可选参数，我们还是要记住几个的。。\n\n`groupID`、`artifactId`、`version`就不说了。\n\n比如`pomFile`这个参数我就瞎了眼，之前研究maven的时候就没好好记住，如果你install的jar依赖了很多东西，而jar文件里又没有pom文件，那就必须得用这个参数指定pom文件了，不然你install成功了，会有依赖它的时候，它依赖的东西啥都没有。\n\n再比如`packaging`参数，如果你install的只是一个pom的话，比如你install了`struts2-core`，它的父工程`struts2-parent`就是一个pom，`struts2-core`继承了父工程的依赖，你得install一下`struts2-parent`，尽管它只是个pom，这时候`packaging`就应该是pom，而不是jar了。\n\n唉，只能手动install真的难受，各种依赖，少什么我就得去公司内网下载回来install，整整一下午。。\n\n\n## 更新，关于maven本地库\n\n由于依赖太复杂，我服了，所以在可以连通maven远程库的机器Aclone了一份代码，make install，一波搞下来整个项目需要的所有依赖，然后把那边的本地库tar了个包通过跳板机搞到我本地了。想着一波把所有jar包复制到我本地库，该合并合并，该替换替换。。。\n\n在机器A`make install`的时候不管我怎么设置`settings.xml`文件，它都去找maven中向仓库！！！一度要疯。。\n\n后来找了几个博客看了下，了解到**所有的自定义pom都是继承自super pom的。也就是maven项目在需要下载metadata、pom和jar的时候会优先去中央仓库。** super pom文件内有配置`repositories`为中央仓库地址。\n\n所以我们需要在项目的pom文件里添加`repositories`来覆盖super pom的配置，让maven直接去我们自己的服务器下载。\n\n一顿操作，所有的依赖终于都下载到机器A了。sftp搞到我本地机器。\n\n**但是，却怎么都导不进来！！！**\n\n```text\n[WARNING]  The POM for com.xxx:xxx:jar:xxx is missing, no dependency information available...\n```\n\n所有的包都是上面这种报错，我本地库明明都有，怎么就不行呢。。\n\n原来当我们用maven来构建项目时，离线模式下，他会去我们的本地库找依赖的包，但是并不是有就会用，他会做一个`Verifying availability`，也就是校验下这些包是否可用。\n\n**Maven根据`xxx.repositories`、`xxx.lastUpdated`和`xxx.sha1`来校验的**\n\n- `***.repositories`，例如`_remote.repositories`文件会让maven优先从私服下载。\n- `***.lastUpdated`，当远程库根据我们pom文件的描述找不到对应的资源，或者因为网络原因导致下载失败或中断，都会生成一个lastUpdated文件。\n- `xxx.sha1`，和md5类似，生成的对应文件的加密摘要，sha1比md5长32位，更安全。\n\n一顿操作，删除本地库目录下的所有`repositories`和`lastUpdated`文件删除：\n\n```shell script\nkongzheng1993@Evil:~/workspace/java/ngcrmpf_bj$ find ./ -name *.repositories | xargs rm\nkongzheng1993@Evil:~/workspace/java/ngcrmpf_bj$ find ./ -name *.lastUpdated | xargs rm\n```\n\n成功了，皆大欢喜，之前看过maven实战，看来是啥也每记住啊～～\n有时间还得看看！","source":"_posts/2020-05-19-kongzheng1993-maven_install.md","raw":"---\ntitle: 记一次Maven冒险\nexcerpt: ''\ntags: [maven]\ncategories: [maven]\ncomments: true\ndate: 2020-05-21 00:30:52\n---\n\n最近给框架升级，由于总部研发给的新框架是deploy到私有maven库，我们也都是在本地开发，到私有远程maven库网络是不通的，所以我也只能跳到那边把几个jar包下载，然后sftp到一台两边都通的服务器上，再搞到本地。。不就是mvn install嘛，我以为我可以系列，哈哈。。正好今天也查了很多资料，就记录下来，希望能帮到有缘人。。\n\n## mvn install\n\n将项目的主要工件以及生命周期中其他插件附带的任何其他工件安装到本地存储库。\n\n### 一般用法\n\n我脑海里记得到参数也就是这些了\n\n```shell\nmvn install:install-file -DgroupId=com.xxx -DartifactId=xxx -Dversion=1.0.0 -Dpackaging=jar -Dfile=you-jar-file-path\n```\n\n相关的参数可以查看[install:install-file](http://maven.apache.org/plugins/maven-install-plugin/install-file-mojo.html)\n\n这里的参数里`-Dfile`是必须的，毕竟没文件，你install个毛线。。\n其他参数都是可选的，毕竟jar文件如果也是maven工程，它会默认用父pom的`groupID`、`artifactId`、`version`参数。\n\n但就是这些可选参数，我们还是要记住几个的。。\n\n`groupID`、`artifactId`、`version`就不说了。\n\n比如`pomFile`这个参数我就瞎了眼，之前研究maven的时候就没好好记住，如果你install的jar依赖了很多东西，而jar文件里又没有pom文件，那就必须得用这个参数指定pom文件了，不然你install成功了，会有依赖它的时候，它依赖的东西啥都没有。\n\n再比如`packaging`参数，如果你install的只是一个pom的话，比如你install了`struts2-core`，它的父工程`struts2-parent`就是一个pom，`struts2-core`继承了父工程的依赖，你得install一下`struts2-parent`，尽管它只是个pom，这时候`packaging`就应该是pom，而不是jar了。\n\n唉，只能手动install真的难受，各种依赖，少什么我就得去公司内网下载回来install，整整一下午。。\n\n\n## 更新，关于maven本地库\n\n由于依赖太复杂，我服了，所以在可以连通maven远程库的机器Aclone了一份代码，make install，一波搞下来整个项目需要的所有依赖，然后把那边的本地库tar了个包通过跳板机搞到我本地了。想着一波把所有jar包复制到我本地库，该合并合并，该替换替换。。。\n\n在机器A`make install`的时候不管我怎么设置`settings.xml`文件，它都去找maven中向仓库！！！一度要疯。。\n\n后来找了几个博客看了下，了解到**所有的自定义pom都是继承自super pom的。也就是maven项目在需要下载metadata、pom和jar的时候会优先去中央仓库。** super pom文件内有配置`repositories`为中央仓库地址。\n\n所以我们需要在项目的pom文件里添加`repositories`来覆盖super pom的配置，让maven直接去我们自己的服务器下载。\n\n一顿操作，所有的依赖终于都下载到机器A了。sftp搞到我本地机器。\n\n**但是，却怎么都导不进来！！！**\n\n```text\n[WARNING]  The POM for com.xxx:xxx:jar:xxx is missing, no dependency information available...\n```\n\n所有的包都是上面这种报错，我本地库明明都有，怎么就不行呢。。\n\n原来当我们用maven来构建项目时，离线模式下，他会去我们的本地库找依赖的包，但是并不是有就会用，他会做一个`Verifying availability`，也就是校验下这些包是否可用。\n\n**Maven根据`xxx.repositories`、`xxx.lastUpdated`和`xxx.sha1`来校验的**\n\n- `***.repositories`，例如`_remote.repositories`文件会让maven优先从私服下载。\n- `***.lastUpdated`，当远程库根据我们pom文件的描述找不到对应的资源，或者因为网络原因导致下载失败或中断，都会生成一个lastUpdated文件。\n- `xxx.sha1`，和md5类似，生成的对应文件的加密摘要，sha1比md5长32位，更安全。\n\n一顿操作，删除本地库目录下的所有`repositories`和`lastUpdated`文件删除：\n\n```shell script\nkongzheng1993@Evil:~/workspace/java/ngcrmpf_bj$ find ./ -name *.repositories | xargs rm\nkongzheng1993@Evil:~/workspace/java/ngcrmpf_bj$ find ./ -name *.lastUpdated | xargs rm\n```\n\n成功了，皆大欢喜，之前看过maven实战，看来是啥也每记住啊～～\n有时间还得看看！","slug":"kongzheng1993-maven_install","published":1,"updated":"2023-03-08T07:05:58.802Z","layout":"post","photos":[],"link":"","_id":"clg0k2akl004ft26f40unky7l","content":"<p>最近给框架升级，由于总部研发给的新框架是deploy到私有maven库，我们也都是在本地开发，到私有远程maven库网络是不通的，所以我也只能跳到那边把几个jar包下载，然后sftp到一台两边都通的服务器上，再搞到本地。。不就是mvn install嘛，我以为我可以系列，哈哈。。正好今天也查了很多资料，就记录下来，希望能帮到有缘人。。</p>\n<h2 id=\"mvn-install\"><a href=\"#mvn-install\" class=\"headerlink\" title=\"mvn install\"></a>mvn install</h2><p>将项目的主要工件以及生命周期中其他插件附带的任何其他工件安装到本地存储库。</p>\n<h3 id=\"一般用法\"><a href=\"#一般用法\" class=\"headerlink\" title=\"一般用法\"></a>一般用法</h3><p>我脑海里记得到参数也就是这些了</p>\n<pre><code class=\"shell\">mvn install:install-file -DgroupId=com.xxx -DartifactId=xxx -Dversion=1.0.0 -Dpackaging=jar -Dfile=you-jar-file-path</code></pre>\n<p>相关的参数可以查看<a href=\"http://maven.apache.org/plugins/maven-install-plugin/install-file-mojo.html\" target=\"_blank\" rel=\"noopener\">install:install-file</a></p>\n<p>这里的参数里<code>-Dfile</code>是必须的，毕竟没文件，你install个毛线。。<br>其他参数都是可选的，毕竟jar文件如果也是maven工程，它会默认用父pom的<code>groupID</code>、<code>artifactId</code>、<code>version</code>参数。</p>\n<p>但就是这些可选参数，我们还是要记住几个的。。</p>\n<p><code>groupID</code>、<code>artifactId</code>、<code>version</code>就不说了。</p>\n<p>比如<code>pomFile</code>这个参数我就瞎了眼，之前研究maven的时候就没好好记住，如果你install的jar依赖了很多东西，而jar文件里又没有pom文件，那就必须得用这个参数指定pom文件了，不然你install成功了，会有依赖它的时候，它依赖的东西啥都没有。</p>\n<p>再比如<code>packaging</code>参数，如果你install的只是一个pom的话，比如你install了<code>struts2-core</code>，它的父工程<code>struts2-parent</code>就是一个pom，<code>struts2-core</code>继承了父工程的依赖，你得install一下<code>struts2-parent</code>，尽管它只是个pom，这时候<code>packaging</code>就应该是pom，而不是jar了。</p>\n<p>唉，只能手动install真的难受，各种依赖，少什么我就得去公司内网下载回来install，整整一下午。。</p>\n<h2 id=\"更新，关于maven本地库\"><a href=\"#更新，关于maven本地库\" class=\"headerlink\" title=\"更新，关于maven本地库\"></a>更新，关于maven本地库</h2><p>由于依赖太复杂，我服了，所以在可以连通maven远程库的机器Aclone了一份代码，make install，一波搞下来整个项目需要的所有依赖，然后把那边的本地库tar了个包通过跳板机搞到我本地了。想着一波把所有jar包复制到我本地库，该合并合并，该替换替换。。。</p>\n<p>在机器A<code>make install</code>的时候不管我怎么设置<code>settings.xml</code>文件，它都去找maven中向仓库！！！一度要疯。。</p>\n<p>后来找了几个博客看了下，了解到<strong>所有的自定义pom都是继承自super pom的。也就是maven项目在需要下载metadata、pom和jar的时候会优先去中央仓库。</strong> super pom文件内有配置<code>repositories</code>为中央仓库地址。</p>\n<p>所以我们需要在项目的pom文件里添加<code>repositories</code>来覆盖super pom的配置，让maven直接去我们自己的服务器下载。</p>\n<p>一顿操作，所有的依赖终于都下载到机器A了。sftp搞到我本地机器。</p>\n<p><strong>但是，却怎么都导不进来！！！</strong></p>\n<pre><code class=\"text\">[WARNING]  The POM for com.xxx:xxx:jar:xxx is missing, no dependency information available...</code></pre>\n<p>所有的包都是上面这种报错，我本地库明明都有，怎么就不行呢。。</p>\n<p>原来当我们用maven来构建项目时，离线模式下，他会去我们的本地库找依赖的包，但是并不是有就会用，他会做一个<code>Verifying availability</code>，也就是校验下这些包是否可用。</p>\n<p><strong>Maven根据<code>xxx.repositories</code>、<code>xxx.lastUpdated</code>和<code>xxx.sha1</code>来校验的</strong></p>\n<ul>\n<li><code>***.repositories</code>，例如<code>_remote.repositories</code>文件会让maven优先从私服下载。</li>\n<li><code>***.lastUpdated</code>，当远程库根据我们pom文件的描述找不到对应的资源，或者因为网络原因导致下载失败或中断，都会生成一个lastUpdated文件。</li>\n<li><code>xxx.sha1</code>，和md5类似，生成的对应文件的加密摘要，sha1比md5长32位，更安全。</li>\n</ul>\n<p>一顿操作，删除本地库目录下的所有<code>repositories</code>和<code>lastUpdated</code>文件删除：</p>\n<pre><code class=\"shell\">kongzheng1993@Evil:~/workspace/java/ngcrmpf_bj$ find ./ -name *.repositories | xargs rm\nkongzheng1993@Evil:~/workspace/java/ngcrmpf_bj$ find ./ -name *.lastUpdated | xargs rm</code></pre>\n<p>成功了，皆大欢喜，之前看过maven实战，看来是啥也每记住啊～～<br>有时间还得看看！</p>\n","site":{"data":{}},"more":"<p>最近给框架升级，由于总部研发给的新框架是deploy到私有maven库，我们也都是在本地开发，到私有远程maven库网络是不通的，所以我也只能跳到那边把几个jar包下载，然后sftp到一台两边都通的服务器上，再搞到本地。。不就是mvn install嘛，我以为我可以系列，哈哈。。正好今天也查了很多资料，就记录下来，希望能帮到有缘人。。</p>\n<h2 id=\"mvn-install\"><a href=\"#mvn-install\" class=\"headerlink\" title=\"mvn install\"></a>mvn install</h2><p>将项目的主要工件以及生命周期中其他插件附带的任何其他工件安装到本地存储库。</p>\n<h3 id=\"一般用法\"><a href=\"#一般用法\" class=\"headerlink\" title=\"一般用法\"></a>一般用法</h3><p>我脑海里记得到参数也就是这些了</p>\n<pre><code class=\"shell\">mvn install:install-file -DgroupId=com.xxx -DartifactId=xxx -Dversion=1.0.0 -Dpackaging=jar -Dfile=you-jar-file-path</code></pre>\n<p>相关的参数可以查看<a href=\"http://maven.apache.org/plugins/maven-install-plugin/install-file-mojo.html\" target=\"_blank\" rel=\"noopener\">install:install-file</a></p>\n<p>这里的参数里<code>-Dfile</code>是必须的，毕竟没文件，你install个毛线。。<br>其他参数都是可选的，毕竟jar文件如果也是maven工程，它会默认用父pom的<code>groupID</code>、<code>artifactId</code>、<code>version</code>参数。</p>\n<p>但就是这些可选参数，我们还是要记住几个的。。</p>\n<p><code>groupID</code>、<code>artifactId</code>、<code>version</code>就不说了。</p>\n<p>比如<code>pomFile</code>这个参数我就瞎了眼，之前研究maven的时候就没好好记住，如果你install的jar依赖了很多东西，而jar文件里又没有pom文件，那就必须得用这个参数指定pom文件了，不然你install成功了，会有依赖它的时候，它依赖的东西啥都没有。</p>\n<p>再比如<code>packaging</code>参数，如果你install的只是一个pom的话，比如你install了<code>struts2-core</code>，它的父工程<code>struts2-parent</code>就是一个pom，<code>struts2-core</code>继承了父工程的依赖，你得install一下<code>struts2-parent</code>，尽管它只是个pom，这时候<code>packaging</code>就应该是pom，而不是jar了。</p>\n<p>唉，只能手动install真的难受，各种依赖，少什么我就得去公司内网下载回来install，整整一下午。。</p>\n<h2 id=\"更新，关于maven本地库\"><a href=\"#更新，关于maven本地库\" class=\"headerlink\" title=\"更新，关于maven本地库\"></a>更新，关于maven本地库</h2><p>由于依赖太复杂，我服了，所以在可以连通maven远程库的机器Aclone了一份代码，make install，一波搞下来整个项目需要的所有依赖，然后把那边的本地库tar了个包通过跳板机搞到我本地了。想着一波把所有jar包复制到我本地库，该合并合并，该替换替换。。。</p>\n<p>在机器A<code>make install</code>的时候不管我怎么设置<code>settings.xml</code>文件，它都去找maven中向仓库！！！一度要疯。。</p>\n<p>后来找了几个博客看了下，了解到<strong>所有的自定义pom都是继承自super pom的。也就是maven项目在需要下载metadata、pom和jar的时候会优先去中央仓库。</strong> super pom文件内有配置<code>repositories</code>为中央仓库地址。</p>\n<p>所以我们需要在项目的pom文件里添加<code>repositories</code>来覆盖super pom的配置，让maven直接去我们自己的服务器下载。</p>\n<p>一顿操作，所有的依赖终于都下载到机器A了。sftp搞到我本地机器。</p>\n<p><strong>但是，却怎么都导不进来！！！</strong></p>\n<pre><code class=\"text\">[WARNING]  The POM for com.xxx:xxx:jar:xxx is missing, no dependency information available...</code></pre>\n<p>所有的包都是上面这种报错，我本地库明明都有，怎么就不行呢。。</p>\n<p>原来当我们用maven来构建项目时，离线模式下，他会去我们的本地库找依赖的包，但是并不是有就会用，他会做一个<code>Verifying availability</code>，也就是校验下这些包是否可用。</p>\n<p><strong>Maven根据<code>xxx.repositories</code>、<code>xxx.lastUpdated</code>和<code>xxx.sha1</code>来校验的</strong></p>\n<ul>\n<li><code>***.repositories</code>，例如<code>_remote.repositories</code>文件会让maven优先从私服下载。</li>\n<li><code>***.lastUpdated</code>，当远程库根据我们pom文件的描述找不到对应的资源，或者因为网络原因导致下载失败或中断，都会生成一个lastUpdated文件。</li>\n<li><code>xxx.sha1</code>，和md5类似，生成的对应文件的加密摘要，sha1比md5长32位，更安全。</li>\n</ul>\n<p>一顿操作，删除本地库目录下的所有<code>repositories</code>和<code>lastUpdated</code>文件删除：</p>\n<pre><code class=\"shell\">kongzheng1993@Evil:~/workspace/java/ngcrmpf_bj$ find ./ -name *.repositories | xargs rm\nkongzheng1993@Evil:~/workspace/java/ngcrmpf_bj$ find ./ -name *.lastUpdated | xargs rm</code></pre>\n<p>成功了，皆大欢喜，之前看过maven实战，看来是啥也每记住啊～～<br>有时间还得看看！</p>\n"},{"title":"NLP","excerpt":"","comments":1,"date":"2020-06-28T16:30:52.000Z","_content":"\n\n在新公司待了半个月了，好久总结以下了，刚进公司前几天，感觉漂泊不定，刚总部上两天班，就给安排到客户现场，到客户现场还没熟悉环境，又让回公司了。不过后面一直在公司总部，感觉算是稳定下来了。\n\n最近在做的东西，需要用到百度AI相关的服务。我理解的需求就是用户录音，我们将录音文件转文字，填充到页面表格里。这里第一步问题不大，百度有现成的语音转文字接口，也就是语音格式和长度待确定。后面一大段文本，根据主题抽取相关文字，填充到对应的文本框，这里才是最难的。我们是金融相关的产品，查看百度提供出来的API，没有找到相关的。和百度的同学了解了一下，他们直接说没有现成的产品，要提需求之类的。。。\n\n\n唉，AI相关的东西啥也不懂，和人家聊真的很难的很。。还露切。。\n\n刚毕业的时候，总觉得要了解以下AI，但是感觉数学不行，没敢动手。。到现在依然是就认识几个名词。。\n\n今天就建这么个文章，以后了解到AI相关的知识，就总结在下面了。。\n\n<img src=\"statistical-machine-translation.png\">","source":"_posts/2020-06-29-kongzheng1993-NLP.md","raw":"---\ntitle: NLP\nexcerpt: ''\ntags: [AI]\ncategories: [AI]\ncomments: true\ndate: 2020-06-29 00:30:52\n---\n\n\n在新公司待了半个月了，好久总结以下了，刚进公司前几天，感觉漂泊不定，刚总部上两天班，就给安排到客户现场，到客户现场还没熟悉环境，又让回公司了。不过后面一直在公司总部，感觉算是稳定下来了。\n\n最近在做的东西，需要用到百度AI相关的服务。我理解的需求就是用户录音，我们将录音文件转文字，填充到页面表格里。这里第一步问题不大，百度有现成的语音转文字接口，也就是语音格式和长度待确定。后面一大段文本，根据主题抽取相关文字，填充到对应的文本框，这里才是最难的。我们是金融相关的产品，查看百度提供出来的API，没有找到相关的。和百度的同学了解了一下，他们直接说没有现成的产品，要提需求之类的。。。\n\n\n唉，AI相关的东西啥也不懂，和人家聊真的很难的很。。还露切。。\n\n刚毕业的时候，总觉得要了解以下AI，但是感觉数学不行，没敢动手。。到现在依然是就认识几个名词。。\n\n今天就建这么个文章，以后了解到AI相关的知识，就总结在下面了。。\n\n<img src=\"statistical-machine-translation.png\">","slug":"kongzheng1993-NLP","published":1,"updated":"2023-03-08T07:05:58.803Z","layout":"post","photos":[],"link":"","_id":"clg0k2akp004ht26fh6xq0lgb","content":"<p>在新公司待了半个月了，好久总结以下了，刚进公司前几天，感觉漂泊不定，刚总部上两天班，就给安排到客户现场，到客户现场还没熟悉环境，又让回公司了。不过后面一直在公司总部，感觉算是稳定下来了。</p>\n<p>最近在做的东西，需要用到百度AI相关的服务。我理解的需求就是用户录音，我们将录音文件转文字，填充到页面表格里。这里第一步问题不大，百度有现成的语音转文字接口，也就是语音格式和长度待确定。后面一大段文本，根据主题抽取相关文字，填充到对应的文本框，这里才是最难的。我们是金融相关的产品，查看百度提供出来的API，没有找到相关的。和百度的同学了解了一下，他们直接说没有现成的产品，要提需求之类的。。。</p>\n<p>唉，AI相关的东西啥也不懂，和人家聊真的很难的很。。还露切。。</p>\n<p>刚毕业的时候，总觉得要了解以下AI，但是感觉数学不行，没敢动手。。到现在依然是就认识几个名词。。</p>\n<p>今天就建这么个文章，以后了解到AI相关的知识，就总结在下面了。。</p>\n<img src=\"/2020/06/29/kongzheng1993-NLP/statistical-machine-translation.png\">","site":{"data":{}},"more":"<p>在新公司待了半个月了，好久总结以下了，刚进公司前几天，感觉漂泊不定，刚总部上两天班，就给安排到客户现场，到客户现场还没熟悉环境，又让回公司了。不过后面一直在公司总部，感觉算是稳定下来了。</p>\n<p>最近在做的东西，需要用到百度AI相关的服务。我理解的需求就是用户录音，我们将录音文件转文字，填充到页面表格里。这里第一步问题不大，百度有现成的语音转文字接口，也就是语音格式和长度待确定。后面一大段文本，根据主题抽取相关文字，填充到对应的文本框，这里才是最难的。我们是金融相关的产品，查看百度提供出来的API，没有找到相关的。和百度的同学了解了一下，他们直接说没有现成的产品，要提需求之类的。。。</p>\n<p>唉，AI相关的东西啥也不懂，和人家聊真的很难的很。。还露切。。</p>\n<p>刚毕业的时候，总觉得要了解以下AI，但是感觉数学不行，没敢动手。。到现在依然是就认识几个名词。。</p>\n<p>今天就建这么个文章，以后了解到AI相关的知识，就总结在下面了。。</p>\n<img src=\"/2020/06/29/kongzheng1993-NLP/statistical-machine-translation.png\">"},{"title":"分布式事务","excerpt":"","comments":1,"date":"2020-05-20T16:30:52.000Z","_content":"\n### 解决方案：\n1. **通过mq**： 当A成功后，发送消息到mq，B消费消息，即使失败了，也能通过mq重试，直到B也成功，最终数据一致。**这里要注意发送消息最好在本地事务提交之后进行。** 但是还有问题，如果本地事务成功了，消息发送失败了呢？不能保证本地事务和发送消息两个操作同时都成功，这种方式存在问题！\n2. **2PC--两阶段提交**： 也是通过mq发送消息给B，不过发送都是事务消息，Kafka和RocketMQ支持事务消息。先发送perpare消息，等待A本地事务执行后，根据本地事务执行情况发送commit或rollback。即使本地事务执行后，发送commit或rollback失败了，rocketmq在没收到下一步操作的情况下，会回溯事务是否成功，进而设置自己的perpare消息是否可消费。也存在问题，就是A成功的情况下，B必须要成功，但是B也会存在失败的情况，这里没办法进行处理。\n3. **AT--业务无侵入**： 引入TxManager（事务管理器）来管理多个本地事务。各个本地事务提交前通知TxManager，由TxManager根据各个本地事务的情况来发出commit/rollback指令。大概思路就是写一个切面，在@Transaction的方法前执行创建事务组，通过netty等通信框架传给TxManager，然后执行本地事务代码，重写数据库连接commit方法（通过自定义数据库连接），让本地事务在commit前等待，根据本地事务执行情况，提交commit或者rollback结果到TxManager。TxManager在接收到所有\b本地事务的结构后，计算出commit还是rollback，发送指令到各个服务。\n\n```java\n@Aspect\n@Component\npublic class TransactionGroupAspect implements Order {\n    @Around(\"@annotation(xxx.TransactionGroup)\")\n    public void invoke(ProceedingJoinPoint point) {\n        //1. 在TxManager创建事务组，返回事务组ID\n        String transactionGroupId = ...\n        //2. 执行本地事务\n        try {\n            //执行本地事务--@Transaction方法\n            point.proceed();\n            //提交执行成功结果，此时并没有提交，而是卡在我们重写的数据库连接的commit方法。\n            ...send commit message\n        } catch (Throwable throwable) {\n            //发送rollback消息\n            ...send rollback message\n        }\n        //记录本地事务的transactionGroupId，待唤醒提交线程的时候使用\n        transactionMap.put(transactionGroupId, 本地事务对象)\n    }\n}\n```\n\n```java\n@Override\npublic void commit() throws SQLException {\n    //单独起一个线程，让TransactionGroupAspect的逻辑可以继续往下执行。。。发送消息到TxManager\n    new Thread(new Runnable() {\n        @Override\n        public void run() {\n            try{\n                //本地事务提交前阻塞当前线程，等待TxManager发送指令来唤醒\n                condition.await();\n                //判断TxManager指令\n                if (command.equals(\"commit\")) {\n                    //调用commit()，提交本地事务。\n                    connection.commit();\n                } else {\n                    //回滚\n                    connection.rollback();\n                }\n            }\n        }\n    }).start();\n}\n```\n\n```java\n//接收TxManager指令\n...readFromChannel\n//从本地事务集合中取出之前创建的本地事务\nlocalTransaction = transactionMap.get(transactionGroupId);\n//给本地事务指定将要执行的指令\nlocalTransaction.setCommand(commandFromTxManager);\n//唤醒之前阻塞在commit()前的线程，根据TxManager指令来提交或者回滚\nlocalTransaction.getCondition.signal();\n\n```\n\n\n4. **TCC--业务有侵入**： try-confirm-cancel，也是2pc，两阶段提交的方案。try阶段，我们搞一个中间状态，比如扣款先冻结，积分搞个预增加，订单搞个未完成状态。confirm阶段，可以引入开源框架，ByteTCC、Himly、TCC-transaction等，用来感知各个事务的状态，当确认所有子事务都try成功了，就控制事务进入confirm阶段，这里要把之前的操作完成，比如完成扣款，积分增加，修改订单状态为完成。如果在try阶段有任何一个事务未能完成，比如余额不足，扣款失败导致扣款事务失败，tcc事务框架感知到后，会执行cancel阶段的操作。比如把余额恢复，积分恢复，订单修改为已取消状态。\n   - 先是服务调用链路依次执行 Try 逻辑。\n   - 如果都正常的话，TCC 分布式事务框架推进执行 Confirm 逻辑，完成整个事务。\n   - 如果某个服务的 Try 逻辑有问题，TCC 分布式事务框架感知到之后就会推进执行各个服务的 Cancel 逻辑，撤销之前执行的各种操作。\nconfirm和cancel操作如果失败TCC框架会根据活动日志，不断重试，直至成功。异步调用一般基于MQ的可靠消息达到最终一致性。\n5. **Saga--业务有侵入**： 和TCC相比，Saga没有“预留”动作，它的Ti就是直接提交到库。\n   1. 每个Saga由一系列sub-transaction Ti 组成\n   2. 每个Ti 都有对应的补偿动作Ci，补偿动作用于撤销Ti造成的结果\n   saga定义了两种恢复策略：\n   - **backward recovery**，向后恢复，补偿所有已完成的事务，如果任一子事务失败。即上面提到的第二种执行顺序，其中j是发生错误的sub-transaction，这种做法的效果是撤销掉之前所有成功的sub-transation，使得整个Saga的执行结果撤销。\n   - **forward recovery**，向前恢复，重试失败的事务，假设每个子事务最终都会成功。适用于必须要成功的场景，执行顺序是类似于这样的：T1, T2, ..., Tj(失败), Tj(重试),..., Tn，其中j是发生错误的sub-transaction。该情况下不需要Ci。\n\n    但是saga依然存在问题，比如向前恢复子事务永远不会成功，向后恢复补偿事务失败。最终还是要人工干预。\n6. **XA**：XA需要两阶段提交: prepare 和 commit. \n第一阶段为 准备（prepare）阶段。即所有的参与者准备执行事务并锁住需要的资源。参与者ready时，向transaction manager报告已准备就绪。 \n第二阶段为提交阶段（commit）。当transaction manager确认所有参与者都ready后，向所有参与者发送commit命令。\n因为XA 事务是基于两阶段提交协议的，所以需要有一个事务协调者（transaction manager）来保证所有的事务参与者都完成了准备工作(第一阶段)。如果事务协调者（transaction manager）收到所有参与者都准备好的消息，就会通知所有的事务都可以提交了（第二阶段）。MySQL 在这个XA事务中扮演的是参与者的角色，而不是事务协调者（transaction manager）。\n\n### Alibaba Seata\n\nSeata是一款开源的分布式事务解决方案，致力于提供高性能和简单易用的分布式事务服务。Seata为用户提供了AT、TCC和XA事务模式，为用户打造一站式的分布式事务解决方案。\n\n- 强一致性： 刚性事务   使用seata的AT模式\n- 弱一致性： 柔性事务   基于BASE理论的最终一致性，使用seata的saga模式\n\n\n术语：\n- TC 事务协调者： 维护全局和分支事务的状态，驱动全局事务提交或回滚。\n- TM 事务管理器： 定义全局事务的范围，开始全局事务、提交或回滚全局事务。\n- RM 资源管理器： 管理分支事务处理的结果，与TC交谈以注册分支事务和报告分支事务的状态，并驱动分支事务提交或回滚。这里一般就是我们执行分支事务的服务，即事务参与者。\n\n<img src=\"seata.png\">","source":"_posts/2020-05-21-kongzheng1993-分布式事务.md","raw":"---\ntitle: 分布式事务\nexcerpt: ''\ntags: [分布式]\ncategories: [分布式]\ncomments: true\ndate: 2020-05-21 00:30:52\n---\n\n### 解决方案：\n1. **通过mq**： 当A成功后，发送消息到mq，B消费消息，即使失败了，也能通过mq重试，直到B也成功，最终数据一致。**这里要注意发送消息最好在本地事务提交之后进行。** 但是还有问题，如果本地事务成功了，消息发送失败了呢？不能保证本地事务和发送消息两个操作同时都成功，这种方式存在问题！\n2. **2PC--两阶段提交**： 也是通过mq发送消息给B，不过发送都是事务消息，Kafka和RocketMQ支持事务消息。先发送perpare消息，等待A本地事务执行后，根据本地事务执行情况发送commit或rollback。即使本地事务执行后，发送commit或rollback失败了，rocketmq在没收到下一步操作的情况下，会回溯事务是否成功，进而设置自己的perpare消息是否可消费。也存在问题，就是A成功的情况下，B必须要成功，但是B也会存在失败的情况，这里没办法进行处理。\n3. **AT--业务无侵入**： 引入TxManager（事务管理器）来管理多个本地事务。各个本地事务提交前通知TxManager，由TxManager根据各个本地事务的情况来发出commit/rollback指令。大概思路就是写一个切面，在@Transaction的方法前执行创建事务组，通过netty等通信框架传给TxManager，然后执行本地事务代码，重写数据库连接commit方法（通过自定义数据库连接），让本地事务在commit前等待，根据本地事务执行情况，提交commit或者rollback结果到TxManager。TxManager在接收到所有\b本地事务的结构后，计算出commit还是rollback，发送指令到各个服务。\n\n```java\n@Aspect\n@Component\npublic class TransactionGroupAspect implements Order {\n    @Around(\"@annotation(xxx.TransactionGroup)\")\n    public void invoke(ProceedingJoinPoint point) {\n        //1. 在TxManager创建事务组，返回事务组ID\n        String transactionGroupId = ...\n        //2. 执行本地事务\n        try {\n            //执行本地事务--@Transaction方法\n            point.proceed();\n            //提交执行成功结果，此时并没有提交，而是卡在我们重写的数据库连接的commit方法。\n            ...send commit message\n        } catch (Throwable throwable) {\n            //发送rollback消息\n            ...send rollback message\n        }\n        //记录本地事务的transactionGroupId，待唤醒提交线程的时候使用\n        transactionMap.put(transactionGroupId, 本地事务对象)\n    }\n}\n```\n\n```java\n@Override\npublic void commit() throws SQLException {\n    //单独起一个线程，让TransactionGroupAspect的逻辑可以继续往下执行。。。发送消息到TxManager\n    new Thread(new Runnable() {\n        @Override\n        public void run() {\n            try{\n                //本地事务提交前阻塞当前线程，等待TxManager发送指令来唤醒\n                condition.await();\n                //判断TxManager指令\n                if (command.equals(\"commit\")) {\n                    //调用commit()，提交本地事务。\n                    connection.commit();\n                } else {\n                    //回滚\n                    connection.rollback();\n                }\n            }\n        }\n    }).start();\n}\n```\n\n```java\n//接收TxManager指令\n...readFromChannel\n//从本地事务集合中取出之前创建的本地事务\nlocalTransaction = transactionMap.get(transactionGroupId);\n//给本地事务指定将要执行的指令\nlocalTransaction.setCommand(commandFromTxManager);\n//唤醒之前阻塞在commit()前的线程，根据TxManager指令来提交或者回滚\nlocalTransaction.getCondition.signal();\n\n```\n\n\n4. **TCC--业务有侵入**： try-confirm-cancel，也是2pc，两阶段提交的方案。try阶段，我们搞一个中间状态，比如扣款先冻结，积分搞个预增加，订单搞个未完成状态。confirm阶段，可以引入开源框架，ByteTCC、Himly、TCC-transaction等，用来感知各个事务的状态，当确认所有子事务都try成功了，就控制事务进入confirm阶段，这里要把之前的操作完成，比如完成扣款，积分增加，修改订单状态为完成。如果在try阶段有任何一个事务未能完成，比如余额不足，扣款失败导致扣款事务失败，tcc事务框架感知到后，会执行cancel阶段的操作。比如把余额恢复，积分恢复，订单修改为已取消状态。\n   - 先是服务调用链路依次执行 Try 逻辑。\n   - 如果都正常的话，TCC 分布式事务框架推进执行 Confirm 逻辑，完成整个事务。\n   - 如果某个服务的 Try 逻辑有问题，TCC 分布式事务框架感知到之后就会推进执行各个服务的 Cancel 逻辑，撤销之前执行的各种操作。\nconfirm和cancel操作如果失败TCC框架会根据活动日志，不断重试，直至成功。异步调用一般基于MQ的可靠消息达到最终一致性。\n5. **Saga--业务有侵入**： 和TCC相比，Saga没有“预留”动作，它的Ti就是直接提交到库。\n   1. 每个Saga由一系列sub-transaction Ti 组成\n   2. 每个Ti 都有对应的补偿动作Ci，补偿动作用于撤销Ti造成的结果\n   saga定义了两种恢复策略：\n   - **backward recovery**，向后恢复，补偿所有已完成的事务，如果任一子事务失败。即上面提到的第二种执行顺序，其中j是发生错误的sub-transaction，这种做法的效果是撤销掉之前所有成功的sub-transation，使得整个Saga的执行结果撤销。\n   - **forward recovery**，向前恢复，重试失败的事务，假设每个子事务最终都会成功。适用于必须要成功的场景，执行顺序是类似于这样的：T1, T2, ..., Tj(失败), Tj(重试),..., Tn，其中j是发生错误的sub-transaction。该情况下不需要Ci。\n\n    但是saga依然存在问题，比如向前恢复子事务永远不会成功，向后恢复补偿事务失败。最终还是要人工干预。\n6. **XA**：XA需要两阶段提交: prepare 和 commit. \n第一阶段为 准备（prepare）阶段。即所有的参与者准备执行事务并锁住需要的资源。参与者ready时，向transaction manager报告已准备就绪。 \n第二阶段为提交阶段（commit）。当transaction manager确认所有参与者都ready后，向所有参与者发送commit命令。\n因为XA 事务是基于两阶段提交协议的，所以需要有一个事务协调者（transaction manager）来保证所有的事务参与者都完成了准备工作(第一阶段)。如果事务协调者（transaction manager）收到所有参与者都准备好的消息，就会通知所有的事务都可以提交了（第二阶段）。MySQL 在这个XA事务中扮演的是参与者的角色，而不是事务协调者（transaction manager）。\n\n### Alibaba Seata\n\nSeata是一款开源的分布式事务解决方案，致力于提供高性能和简单易用的分布式事务服务。Seata为用户提供了AT、TCC和XA事务模式，为用户打造一站式的分布式事务解决方案。\n\n- 强一致性： 刚性事务   使用seata的AT模式\n- 弱一致性： 柔性事务   基于BASE理论的最终一致性，使用seata的saga模式\n\n\n术语：\n- TC 事务协调者： 维护全局和分支事务的状态，驱动全局事务提交或回滚。\n- TM 事务管理器： 定义全局事务的范围，开始全局事务、提交或回滚全局事务。\n- RM 资源管理器： 管理分支事务处理的结果，与TC交谈以注册分支事务和报告分支事务的状态，并驱动分支事务提交或回滚。这里一般就是我们执行分支事务的服务，即事务参与者。\n\n<img src=\"seata.png\">","slug":"kongzheng1993-分布式事务","published":1,"updated":"2023-03-08T07:05:58.802Z","layout":"post","photos":[],"link":"","_id":"clg0k2akq004lt26fzv9i9r77","content":"<h3 id=\"解决方案：\"><a href=\"#解决方案：\" class=\"headerlink\" title=\"解决方案：\"></a>解决方案：</h3><ol>\n<li><strong>通过mq</strong>： 当A成功后，发送消息到mq，B消费消息，即使失败了，也能通过mq重试，直到B也成功，最终数据一致。<strong>这里要注意发送消息最好在本地事务提交之后进行。</strong> 但是还有问题，如果本地事务成功了，消息发送失败了呢？不能保证本地事务和发送消息两个操作同时都成功，这种方式存在问题！</li>\n<li><strong>2PC–两阶段提交</strong>： 也是通过mq发送消息给B，不过发送都是事务消息，Kafka和RocketMQ支持事务消息。先发送perpare消息，等待A本地事务执行后，根据本地事务执行情况发送commit或rollback。即使本地事务执行后，发送commit或rollback失败了，rocketmq在没收到下一步操作的情况下，会回溯事务是否成功，进而设置自己的perpare消息是否可消费。也存在问题，就是A成功的情况下，B必须要成功，但是B也会存在失败的情况，这里没办法进行处理。</li>\n<li><strong>AT–业务无侵入</strong>： 引入TxManager（事务管理器）来管理多个本地事务。各个本地事务提交前通知TxManager，由TxManager根据各个本地事务的情况来发出commit/rollback指令。大概思路就是写一个切面，在@Transaction的方法前执行创建事务组，通过netty等通信框架传给TxManager，然后执行本地事务代码，重写数据库连接commit方法（通过自定义数据库连接），让本地事务在commit前等待，根据本地事务执行情况，提交commit或者rollback结果到TxManager。TxManager在接收到所有\b本地事务的结构后，计算出commit还是rollback，发送指令到各个服务。</li>\n</ol>\n<pre><code class=\"java\">@Aspect\n@Component\npublic class TransactionGroupAspect implements Order {\n    @Around(&quot;@annotation(xxx.TransactionGroup)&quot;)\n    public void invoke(ProceedingJoinPoint point) {\n        //1. 在TxManager创建事务组，返回事务组ID\n        String transactionGroupId = ...\n        //2. 执行本地事务\n        try {\n            //执行本地事务--@Transaction方法\n            point.proceed();\n            //提交执行成功结果，此时并没有提交，而是卡在我们重写的数据库连接的commit方法。\n            ...send commit message\n        } catch (Throwable throwable) {\n            //发送rollback消息\n            ...send rollback message\n        }\n        //记录本地事务的transactionGroupId，待唤醒提交线程的时候使用\n        transactionMap.put(transactionGroupId, 本地事务对象)\n    }\n}</code></pre>\n<pre><code class=\"java\">@Override\npublic void commit() throws SQLException {\n    //单独起一个线程，让TransactionGroupAspect的逻辑可以继续往下执行。。。发送消息到TxManager\n    new Thread(new Runnable() {\n        @Override\n        public void run() {\n            try{\n                //本地事务提交前阻塞当前线程，等待TxManager发送指令来唤醒\n                condition.await();\n                //判断TxManager指令\n                if (command.equals(&quot;commit&quot;)) {\n                    //调用commit()，提交本地事务。\n                    connection.commit();\n                } else {\n                    //回滚\n                    connection.rollback();\n                }\n            }\n        }\n    }).start();\n}</code></pre>\n<pre><code class=\"java\">//接收TxManager指令\n...readFromChannel\n//从本地事务集合中取出之前创建的本地事务\nlocalTransaction = transactionMap.get(transactionGroupId);\n//给本地事务指定将要执行的指令\nlocalTransaction.setCommand(commandFromTxManager);\n//唤醒之前阻塞在commit()前的线程，根据TxManager指令来提交或者回滚\nlocalTransaction.getCondition.signal();\n</code></pre>\n<ol start=\"4\">\n<li><p><strong>TCC–业务有侵入</strong>： try-confirm-cancel，也是2pc，两阶段提交的方案。try阶段，我们搞一个中间状态，比如扣款先冻结，积分搞个预增加，订单搞个未完成状态。confirm阶段，可以引入开源框架，ByteTCC、Himly、TCC-transaction等，用来感知各个事务的状态，当确认所有子事务都try成功了，就控制事务进入confirm阶段，这里要把之前的操作完成，比如完成扣款，积分增加，修改订单状态为完成。如果在try阶段有任何一个事务未能完成，比如余额不足，扣款失败导致扣款事务失败，tcc事务框架感知到后，会执行cancel阶段的操作。比如把余额恢复，积分恢复，订单修改为已取消状态。</p>\n<ul>\n<li>先是服务调用链路依次执行 Try 逻辑。</li>\n<li>如果都正常的话，TCC 分布式事务框架推进执行 Confirm 逻辑，完成整个事务。</li>\n<li>如果某个服务的 Try 逻辑有问题，TCC 分布式事务框架感知到之后就会推进执行各个服务的 Cancel 逻辑，撤销之前执行的各种操作。<br>confirm和cancel操作如果失败TCC框架会根据活动日志，不断重试，直至成功。异步调用一般基于MQ的可靠消息达到最终一致性。</li>\n</ul>\n</li>\n<li><p><strong>Saga–业务有侵入</strong>： 和TCC相比，Saga没有“预留”动作，它的Ti就是直接提交到库。</p>\n<ol>\n<li>每个Saga由一系列sub-transaction Ti 组成</li>\n<li>每个Ti 都有对应的补偿动作Ci，补偿动作用于撤销Ti造成的结果<br>saga定义了两种恢复策略：</li>\n</ol>\n<ul>\n<li><p><strong>backward recovery</strong>，向后恢复，补偿所有已完成的事务，如果任一子事务失败。即上面提到的第二种执行顺序，其中j是发生错误的sub-transaction，这种做法的效果是撤销掉之前所有成功的sub-transation，使得整个Saga的执行结果撤销。</p>\n</li>\n<li><p><strong>forward recovery</strong>，向前恢复，重试失败的事务，假设每个子事务最终都会成功。适用于必须要成功的场景，执行顺序是类似于这样的：T1, T2, …, Tj(失败), Tj(重试),…, Tn，其中j是发生错误的sub-transaction。该情况下不需要Ci。</p>\n<p>但是saga依然存在问题，比如向前恢复子事务永远不会成功，向后恢复补偿事务失败。最终还是要人工干预。</p>\n</li>\n</ul>\n</li>\n<li><p><strong>XA</strong>：XA需要两阶段提交: prepare 和 commit.<br>第一阶段为 准备（prepare）阶段。即所有的参与者准备执行事务并锁住需要的资源。参与者ready时，向transaction manager报告已准备就绪。<br>第二阶段为提交阶段（commit）。当transaction manager确认所有参与者都ready后，向所有参与者发送commit命令。<br>因为XA 事务是基于两阶段提交协议的，所以需要有一个事务协调者（transaction manager）来保证所有的事务参与者都完成了准备工作(第一阶段)。如果事务协调者（transaction manager）收到所有参与者都准备好的消息，就会通知所有的事务都可以提交了（第二阶段）。MySQL 在这个XA事务中扮演的是参与者的角色，而不是事务协调者（transaction manager）。</p>\n</li>\n</ol>\n<h3 id=\"Alibaba-Seata\"><a href=\"#Alibaba-Seata\" class=\"headerlink\" title=\"Alibaba Seata\"></a>Alibaba Seata</h3><p>Seata是一款开源的分布式事务解决方案，致力于提供高性能和简单易用的分布式事务服务。Seata为用户提供了AT、TCC和XA事务模式，为用户打造一站式的分布式事务解决方案。</p>\n<ul>\n<li>强一致性： 刚性事务   使用seata的AT模式</li>\n<li>弱一致性： 柔性事务   基于BASE理论的最终一致性，使用seata的saga模式</li>\n</ul>\n<p>术语：</p>\n<ul>\n<li>TC 事务协调者： 维护全局和分支事务的状态，驱动全局事务提交或回滚。</li>\n<li>TM 事务管理器： 定义全局事务的范围，开始全局事务、提交或回滚全局事务。</li>\n<li>RM 资源管理器： 管理分支事务处理的结果，与TC交谈以注册分支事务和报告分支事务的状态，并驱动分支事务提交或回滚。这里一般就是我们执行分支事务的服务，即事务参与者。</li>\n</ul>\n<img src=\"/2020/05/21/kongzheng1993-分布式事务/seata.png\">","site":{"data":{}},"more":"<h3 id=\"解决方案：\"><a href=\"#解决方案：\" class=\"headerlink\" title=\"解决方案：\"></a>解决方案：</h3><ol>\n<li><strong>通过mq</strong>： 当A成功后，发送消息到mq，B消费消息，即使失败了，也能通过mq重试，直到B也成功，最终数据一致。<strong>这里要注意发送消息最好在本地事务提交之后进行。</strong> 但是还有问题，如果本地事务成功了，消息发送失败了呢？不能保证本地事务和发送消息两个操作同时都成功，这种方式存在问题！</li>\n<li><strong>2PC–两阶段提交</strong>： 也是通过mq发送消息给B，不过发送都是事务消息，Kafka和RocketMQ支持事务消息。先发送perpare消息，等待A本地事务执行后，根据本地事务执行情况发送commit或rollback。即使本地事务执行后，发送commit或rollback失败了，rocketmq在没收到下一步操作的情况下，会回溯事务是否成功，进而设置自己的perpare消息是否可消费。也存在问题，就是A成功的情况下，B必须要成功，但是B也会存在失败的情况，这里没办法进行处理。</li>\n<li><strong>AT–业务无侵入</strong>： 引入TxManager（事务管理器）来管理多个本地事务。各个本地事务提交前通知TxManager，由TxManager根据各个本地事务的情况来发出commit/rollback指令。大概思路就是写一个切面，在@Transaction的方法前执行创建事务组，通过netty等通信框架传给TxManager，然后执行本地事务代码，重写数据库连接commit方法（通过自定义数据库连接），让本地事务在commit前等待，根据本地事务执行情况，提交commit或者rollback结果到TxManager。TxManager在接收到所有\b本地事务的结构后，计算出commit还是rollback，发送指令到各个服务。</li>\n</ol>\n<pre><code class=\"java\">@Aspect\n@Component\npublic class TransactionGroupAspect implements Order {\n    @Around(&quot;@annotation(xxx.TransactionGroup)&quot;)\n    public void invoke(ProceedingJoinPoint point) {\n        //1. 在TxManager创建事务组，返回事务组ID\n        String transactionGroupId = ...\n        //2. 执行本地事务\n        try {\n            //执行本地事务--@Transaction方法\n            point.proceed();\n            //提交执行成功结果，此时并没有提交，而是卡在我们重写的数据库连接的commit方法。\n            ...send commit message\n        } catch (Throwable throwable) {\n            //发送rollback消息\n            ...send rollback message\n        }\n        //记录本地事务的transactionGroupId，待唤醒提交线程的时候使用\n        transactionMap.put(transactionGroupId, 本地事务对象)\n    }\n}</code></pre>\n<pre><code class=\"java\">@Override\npublic void commit() throws SQLException {\n    //单独起一个线程，让TransactionGroupAspect的逻辑可以继续往下执行。。。发送消息到TxManager\n    new Thread(new Runnable() {\n        @Override\n        public void run() {\n            try{\n                //本地事务提交前阻塞当前线程，等待TxManager发送指令来唤醒\n                condition.await();\n                //判断TxManager指令\n                if (command.equals(&quot;commit&quot;)) {\n                    //调用commit()，提交本地事务。\n                    connection.commit();\n                } else {\n                    //回滚\n                    connection.rollback();\n                }\n            }\n        }\n    }).start();\n}</code></pre>\n<pre><code class=\"java\">//接收TxManager指令\n...readFromChannel\n//从本地事务集合中取出之前创建的本地事务\nlocalTransaction = transactionMap.get(transactionGroupId);\n//给本地事务指定将要执行的指令\nlocalTransaction.setCommand(commandFromTxManager);\n//唤醒之前阻塞在commit()前的线程，根据TxManager指令来提交或者回滚\nlocalTransaction.getCondition.signal();\n</code></pre>\n<ol start=\"4\">\n<li><p><strong>TCC–业务有侵入</strong>： try-confirm-cancel，也是2pc，两阶段提交的方案。try阶段，我们搞一个中间状态，比如扣款先冻结，积分搞个预增加，订单搞个未完成状态。confirm阶段，可以引入开源框架，ByteTCC、Himly、TCC-transaction等，用来感知各个事务的状态，当确认所有子事务都try成功了，就控制事务进入confirm阶段，这里要把之前的操作完成，比如完成扣款，积分增加，修改订单状态为完成。如果在try阶段有任何一个事务未能完成，比如余额不足，扣款失败导致扣款事务失败，tcc事务框架感知到后，会执行cancel阶段的操作。比如把余额恢复，积分恢复，订单修改为已取消状态。</p>\n<ul>\n<li>先是服务调用链路依次执行 Try 逻辑。</li>\n<li>如果都正常的话，TCC 分布式事务框架推进执行 Confirm 逻辑，完成整个事务。</li>\n<li>如果某个服务的 Try 逻辑有问题，TCC 分布式事务框架感知到之后就会推进执行各个服务的 Cancel 逻辑，撤销之前执行的各种操作。<br>confirm和cancel操作如果失败TCC框架会根据活动日志，不断重试，直至成功。异步调用一般基于MQ的可靠消息达到最终一致性。</li>\n</ul>\n</li>\n<li><p><strong>Saga–业务有侵入</strong>： 和TCC相比，Saga没有“预留”动作，它的Ti就是直接提交到库。</p>\n<ol>\n<li>每个Saga由一系列sub-transaction Ti 组成</li>\n<li>每个Ti 都有对应的补偿动作Ci，补偿动作用于撤销Ti造成的结果<br>saga定义了两种恢复策略：</li>\n</ol>\n<ul>\n<li><p><strong>backward recovery</strong>，向后恢复，补偿所有已完成的事务，如果任一子事务失败。即上面提到的第二种执行顺序，其中j是发生错误的sub-transaction，这种做法的效果是撤销掉之前所有成功的sub-transation，使得整个Saga的执行结果撤销。</p>\n</li>\n<li><p><strong>forward recovery</strong>，向前恢复，重试失败的事务，假设每个子事务最终都会成功。适用于必须要成功的场景，执行顺序是类似于这样的：T1, T2, …, Tj(失败), Tj(重试),…, Tn，其中j是发生错误的sub-transaction。该情况下不需要Ci。</p>\n<p>但是saga依然存在问题，比如向前恢复子事务永远不会成功，向后恢复补偿事务失败。最终还是要人工干预。</p>\n</li>\n</ul>\n</li>\n<li><p><strong>XA</strong>：XA需要两阶段提交: prepare 和 commit.<br>第一阶段为 准备（prepare）阶段。即所有的参与者准备执行事务并锁住需要的资源。参与者ready时，向transaction manager报告已准备就绪。<br>第二阶段为提交阶段（commit）。当transaction manager确认所有参与者都ready后，向所有参与者发送commit命令。<br>因为XA 事务是基于两阶段提交协议的，所以需要有一个事务协调者（transaction manager）来保证所有的事务参与者都完成了准备工作(第一阶段)。如果事务协调者（transaction manager）收到所有参与者都准备好的消息，就会通知所有的事务都可以提交了（第二阶段）。MySQL 在这个XA事务中扮演的是参与者的角色，而不是事务协调者（transaction manager）。</p>\n</li>\n</ol>\n<h3 id=\"Alibaba-Seata\"><a href=\"#Alibaba-Seata\" class=\"headerlink\" title=\"Alibaba Seata\"></a>Alibaba Seata</h3><p>Seata是一款开源的分布式事务解决方案，致力于提供高性能和简单易用的分布式事务服务。Seata为用户提供了AT、TCC和XA事务模式，为用户打造一站式的分布式事务解决方案。</p>\n<ul>\n<li>强一致性： 刚性事务   使用seata的AT模式</li>\n<li>弱一致性： 柔性事务   基于BASE理论的最终一致性，使用seata的saga模式</li>\n</ul>\n<p>术语：</p>\n<ul>\n<li>TC 事务协调者： 维护全局和分支事务的状态，驱动全局事务提交或回滚。</li>\n<li>TM 事务管理器： 定义全局事务的范围，开始全局事务、提交或回滚全局事务。</li>\n<li>RM 资源管理器： 管理分支事务处理的结果，与TC交谈以注册分支事务和报告分支事务的状态，并驱动分支事务提交或回滚。这里一般就是我们执行分支事务的服务，即事务参与者。</li>\n</ul>\n<img src=\"/2020/05/21/kongzheng1993-分布式事务/seata.png\">"},{"title":"Java动态代理","excerpt":"","comments":1,"date":"2020-05-28T16:30:52.000Z","_content":"\n## 静态代理\n\n静态代理是我们直接定义在代码里的，也就是手动创建代理类，在调用原有类方法的前后加入逻辑，实现增强。但是这种方式违反了软件设计的开闭原则。\n\n**开闭原则（开放/封闭原则）**\n\n在面向对象编程领域中，开闭原则规定“软件中的对象（类，模块，函数等等）应该对于扩展是开放的，但是对于修改是封闭的”，这意味着一个实体是允许在不改变它的源代码的前提下变更它的行为。该特性在产品化的环境中是特别有价值的，在这种环境中，改变源代码需要代码审查，单元测试以及诸如此类的用以确保产品使用质量的过程。遵循这种原则的代码在扩展时并不发生改变，因此无需上述的过程。\n\n\n\n## 动态代理\n\n**定义：** 给目标对象提供一个代理对象，并由代理对象控制对目标对象对引用；\n**目的：**\n    \n1. 通过引入代理对象的方式来间接访问目标对象，防止直接访问目标对象给系统带来的不必要的复杂性。\n2. 通过代理对象对原有对业务增强。\n\n**动态代理中几个概念：**\n- 接口对象： 声明了真实对象和代理对象的公共接口\n- 真实对象： 代理对象所代表的真实对象，最终被引用的对象\n- 代理对象： 包含真实对象从而操作真实对象，相当于访问者与真实对象之间的中介\n\n\n### JDK动态代理\n\n- Proxy （java.lang.reflect.Proxy） 提供静态方法来创建动态代理类和实例，同时也是所有动态代理类的父类。通过静态方法`Proxy.newProxyInstance(真实对象.getClass().getClassLoader(), 真实对象.getClass().getInterfaces(), this)`，这里就声明了代理类要使用什么类加载器，继承什么接口，还有this（进行增强的InvocationHandler）。\n- InvocationHandler （java.lang.reflect.InvocationHandler） 接口， 它只有一个invoke方法，通过实现这个方法来增加自己的逻辑。我们通过重写invoke方法，做一些增强，然后`method.invoke()`,通过反射来调用真实对象的方法。\n\n\n```java\npublic class SimpleJDKDynamicProxyDemo {\n    static interface IService {\n        public void sayHello();\n    }\n\n    static class RealService implements IService {\n        @Override\n        public void sayHello() {\n            System.out.println(\"hello\");\n        }\n    }\n\n    static class SimpleInvocationHandler implements InvocationHandler {\n        private Object realObj;\n\n        public SimpleInvocationHandler(Object realObj) {\n            this.realObj = realObj;\n        }\n\n        @Override\n        public Object invoke(Object proxy, Method method,\n                             Object[] args) throws Throwable {\n            System.out.println(\"entering \" + method.getName());\n            Object result = method.invoke(realObj, args);\n            System.out.println(\"leaving \" + method.getName());\n            return result;\n        }\n    }\n\n    public static void main(String[] args) {\n        IService realService = new RealService();\n        IService proxyService = (IService) Proxy.newProxyInstance(\n                IService.class.getClassLoader(), new Class<?>[]{IService.class}, new SimpleInvocationHandler(realService));\n        proxyService.sayHello();\n    }\n}\n```\n\n在上面的例子中，IService和RealService是我们原有的。通过Proxy.newProxyInstance()来创建代理对象。\n\n```java\n  public static Object newProxyInstance(ClassLoader loader,Class<?>[] interfaces, InvocationHandler h)\n```\n\n**这里要注意的一点：**\n我们可以把获取到的对象强转为`Proxy.newProxyInstance()`参数中interfaces中的任意一个接口类型，却不能把它强转为某个类类型，比如RealService，即使它实际去代理的对象就是RealServcie实例。\n\nSimpleInvocationHandler实现了InvocationHandler，它的构造方法接收一个参数realObj表示被代理对象。invoke方法处理所有的接口调用。invoke方法有三个参数：\n\n- proxy表示代理对象本身。\n- method表示正在被调用的方法。\n- args表示方法的参数。\n\n在SimpleInvocationHandler的invoke实现中，我们调用了method的invoke方法，传递了实际对象realObj作为参数，达到了调用实际对象对应方法的目的，调用方法的前后，我们加入了自己的代码。\n\n**这里要注意的一点：**\n不要将代理对象传入invoke方法：`Object result = method.invoke(proxy, args);` 这将造成死循环！！因为proxy就是代理对象，调用它的对应方法又会调到SimpleInvocationInvocationHandler的invoke方法。\n\n**Proxy.newProxyInstance()都干了什么？**\n\n```java\nClass<?> proxyCls = Proxy.getProxyClass(IService.class.getClassLoader(), new Class<?>[] { IService.class });\nConstructor<?> ctor = proxyCls.getConstructor( new Class<?>[] { InvocationHandler.class });\nInvocationHandler handler = new SimpleInvocationHandler(realService);\nIService proxyService = (IService) ctor.newInstance(handler);\n```\n\n1. 通过`Proxy.getProxyClass()`创建代理类定义，类定义会被缓存；\n2. 通过代理类都构造方法，构造方法有一个InvocationHandler类型的参数；\n3. 创建InvocationHandler对象；\n4. 创建代理对象。\n\n这里`Proxy.getProxyClass()`方法需要两个参数，一个是ClassLoader，另一个是接口数组。它会动态生成一个类，类名以$Proxy开头，后面跟一个数字。\n\n通过下面的参数可以在编译的时候保存生成的代理类的代码。\n```shell script\njava -Dsun.misc.ProxyGenerator.saveGeneratedFiles=true shuo.laoma.dynamic.c86.SimpleJDKDynamicProxyDemo\n```\n\n```java\nfinal class $Proxy0 extends Proxy implements SimpleJDKDynamicProxyDemo.IService {\n    private static Method m1;\n    private static Method m3;\n    private static Method m2;\n    private static Method m0;\n\n    public $Proxy0(InvocationHandler paramInvocationHandler) {\n        super(paramInvocationHandler);\n    }\n\n    public final boolean equals(Object paramObject) {\n        return ((Boolean) this.h.invoke(this, m1,\n                new Object[]{paramObject})).booleanValue();\n    }\n\n    public final void sayHello() {\n        this.h.invoke(this, m3, null);\n    }\n\n    public final String toString() {\n        return (String) this.h.invoke(this, m2, null);\n    }\n\n    public final int hashCode() {\n        return ((Integer) this.h.invoke(this, m0, null)).intValue();\n    }\n\n    static {\n        m1 = Class.forName(\"java.lang.Object\").getMethod(\"equals\", new Class[]{Class.forName(\"java.lang.Object\")});\n        m3 = Class.forName(\"laoma.demo.proxy.SimpleJDKDynamicProxyDemo$IService\").getMethod(\"sayHello\", new Class[0]);\n        m2 = Class.forName(\"java.lang.Object\").getMethod(\"toString\", new Class[0]);\n        m0 = Class.forName(\"java.lang.Object\").getMethod(\"hashCode\", new Class[0]);\n    }\n}\n```\n\n$Proxy0是Proxy的子类，有一个构造方法，接受一个InvocationHandler类型的参数，这个构造方法会调用父类Proxy的构造方法，将InvocationHandler对象传入，保存在父类成员变量h中。实现了IService接口，对于每个方法，比如例子中的`sayHello`，它将调用InvocationHandler的invoke方法，对于Object中的方法--heshcode、equals等方法，同样转发给了InvocationHandler对象来处理。\n\n上面的分析可以看出，这个代理类与被代理的对象没有任何关系，与InvocationHandler的具体实现也没有关系，而主要与接口数组有关，给定这个接口数组，它动态创建每个接口的实现代码，实现的方式就是转发给InvocationHandler，与被代理对象的关系以及对它的调用由Invocationhandler实现管理。\n\n","source":"_posts/2020-05-29-kongzheng1993-Java动态代理.md","raw":"---\ntitle: Java动态代理\nexcerpt: ''\ntags: [java]\ncategories: [java]\ncomments: true\ndate: 2020-05-29 00:30:52\n---\n\n## 静态代理\n\n静态代理是我们直接定义在代码里的，也就是手动创建代理类，在调用原有类方法的前后加入逻辑，实现增强。但是这种方式违反了软件设计的开闭原则。\n\n**开闭原则（开放/封闭原则）**\n\n在面向对象编程领域中，开闭原则规定“软件中的对象（类，模块，函数等等）应该对于扩展是开放的，但是对于修改是封闭的”，这意味着一个实体是允许在不改变它的源代码的前提下变更它的行为。该特性在产品化的环境中是特别有价值的，在这种环境中，改变源代码需要代码审查，单元测试以及诸如此类的用以确保产品使用质量的过程。遵循这种原则的代码在扩展时并不发生改变，因此无需上述的过程。\n\n\n\n## 动态代理\n\n**定义：** 给目标对象提供一个代理对象，并由代理对象控制对目标对象对引用；\n**目的：**\n    \n1. 通过引入代理对象的方式来间接访问目标对象，防止直接访问目标对象给系统带来的不必要的复杂性。\n2. 通过代理对象对原有对业务增强。\n\n**动态代理中几个概念：**\n- 接口对象： 声明了真实对象和代理对象的公共接口\n- 真实对象： 代理对象所代表的真实对象，最终被引用的对象\n- 代理对象： 包含真实对象从而操作真实对象，相当于访问者与真实对象之间的中介\n\n\n### JDK动态代理\n\n- Proxy （java.lang.reflect.Proxy） 提供静态方法来创建动态代理类和实例，同时也是所有动态代理类的父类。通过静态方法`Proxy.newProxyInstance(真实对象.getClass().getClassLoader(), 真实对象.getClass().getInterfaces(), this)`，这里就声明了代理类要使用什么类加载器，继承什么接口，还有this（进行增强的InvocationHandler）。\n- InvocationHandler （java.lang.reflect.InvocationHandler） 接口， 它只有一个invoke方法，通过实现这个方法来增加自己的逻辑。我们通过重写invoke方法，做一些增强，然后`method.invoke()`,通过反射来调用真实对象的方法。\n\n\n```java\npublic class SimpleJDKDynamicProxyDemo {\n    static interface IService {\n        public void sayHello();\n    }\n\n    static class RealService implements IService {\n        @Override\n        public void sayHello() {\n            System.out.println(\"hello\");\n        }\n    }\n\n    static class SimpleInvocationHandler implements InvocationHandler {\n        private Object realObj;\n\n        public SimpleInvocationHandler(Object realObj) {\n            this.realObj = realObj;\n        }\n\n        @Override\n        public Object invoke(Object proxy, Method method,\n                             Object[] args) throws Throwable {\n            System.out.println(\"entering \" + method.getName());\n            Object result = method.invoke(realObj, args);\n            System.out.println(\"leaving \" + method.getName());\n            return result;\n        }\n    }\n\n    public static void main(String[] args) {\n        IService realService = new RealService();\n        IService proxyService = (IService) Proxy.newProxyInstance(\n                IService.class.getClassLoader(), new Class<?>[]{IService.class}, new SimpleInvocationHandler(realService));\n        proxyService.sayHello();\n    }\n}\n```\n\n在上面的例子中，IService和RealService是我们原有的。通过Proxy.newProxyInstance()来创建代理对象。\n\n```java\n  public static Object newProxyInstance(ClassLoader loader,Class<?>[] interfaces, InvocationHandler h)\n```\n\n**这里要注意的一点：**\n我们可以把获取到的对象强转为`Proxy.newProxyInstance()`参数中interfaces中的任意一个接口类型，却不能把它强转为某个类类型，比如RealService，即使它实际去代理的对象就是RealServcie实例。\n\nSimpleInvocationHandler实现了InvocationHandler，它的构造方法接收一个参数realObj表示被代理对象。invoke方法处理所有的接口调用。invoke方法有三个参数：\n\n- proxy表示代理对象本身。\n- method表示正在被调用的方法。\n- args表示方法的参数。\n\n在SimpleInvocationHandler的invoke实现中，我们调用了method的invoke方法，传递了实际对象realObj作为参数，达到了调用实际对象对应方法的目的，调用方法的前后，我们加入了自己的代码。\n\n**这里要注意的一点：**\n不要将代理对象传入invoke方法：`Object result = method.invoke(proxy, args);` 这将造成死循环！！因为proxy就是代理对象，调用它的对应方法又会调到SimpleInvocationInvocationHandler的invoke方法。\n\n**Proxy.newProxyInstance()都干了什么？**\n\n```java\nClass<?> proxyCls = Proxy.getProxyClass(IService.class.getClassLoader(), new Class<?>[] { IService.class });\nConstructor<?> ctor = proxyCls.getConstructor( new Class<?>[] { InvocationHandler.class });\nInvocationHandler handler = new SimpleInvocationHandler(realService);\nIService proxyService = (IService) ctor.newInstance(handler);\n```\n\n1. 通过`Proxy.getProxyClass()`创建代理类定义，类定义会被缓存；\n2. 通过代理类都构造方法，构造方法有一个InvocationHandler类型的参数；\n3. 创建InvocationHandler对象；\n4. 创建代理对象。\n\n这里`Proxy.getProxyClass()`方法需要两个参数，一个是ClassLoader，另一个是接口数组。它会动态生成一个类，类名以$Proxy开头，后面跟一个数字。\n\n通过下面的参数可以在编译的时候保存生成的代理类的代码。\n```shell script\njava -Dsun.misc.ProxyGenerator.saveGeneratedFiles=true shuo.laoma.dynamic.c86.SimpleJDKDynamicProxyDemo\n```\n\n```java\nfinal class $Proxy0 extends Proxy implements SimpleJDKDynamicProxyDemo.IService {\n    private static Method m1;\n    private static Method m3;\n    private static Method m2;\n    private static Method m0;\n\n    public $Proxy0(InvocationHandler paramInvocationHandler) {\n        super(paramInvocationHandler);\n    }\n\n    public final boolean equals(Object paramObject) {\n        return ((Boolean) this.h.invoke(this, m1,\n                new Object[]{paramObject})).booleanValue();\n    }\n\n    public final void sayHello() {\n        this.h.invoke(this, m3, null);\n    }\n\n    public final String toString() {\n        return (String) this.h.invoke(this, m2, null);\n    }\n\n    public final int hashCode() {\n        return ((Integer) this.h.invoke(this, m0, null)).intValue();\n    }\n\n    static {\n        m1 = Class.forName(\"java.lang.Object\").getMethod(\"equals\", new Class[]{Class.forName(\"java.lang.Object\")});\n        m3 = Class.forName(\"laoma.demo.proxy.SimpleJDKDynamicProxyDemo$IService\").getMethod(\"sayHello\", new Class[0]);\n        m2 = Class.forName(\"java.lang.Object\").getMethod(\"toString\", new Class[0]);\n        m0 = Class.forName(\"java.lang.Object\").getMethod(\"hashCode\", new Class[0]);\n    }\n}\n```\n\n$Proxy0是Proxy的子类，有一个构造方法，接受一个InvocationHandler类型的参数，这个构造方法会调用父类Proxy的构造方法，将InvocationHandler对象传入，保存在父类成员变量h中。实现了IService接口，对于每个方法，比如例子中的`sayHello`，它将调用InvocationHandler的invoke方法，对于Object中的方法--heshcode、equals等方法，同样转发给了InvocationHandler对象来处理。\n\n上面的分析可以看出，这个代理类与被代理的对象没有任何关系，与InvocationHandler的具体实现也没有关系，而主要与接口数组有关，给定这个接口数组，它动态创建每个接口的实现代码，实现的方式就是转发给InvocationHandler，与被代理对象的关系以及对它的调用由Invocationhandler实现管理。\n\n","slug":"kongzheng1993-Java动态代理","published":1,"updated":"2023-03-08T07:05:58.803Z","layout":"post","photos":[],"link":"","_id":"clg0k2akr004ot26f3nm38b9g","content":"<h2 id=\"静态代理\"><a href=\"#静态代理\" class=\"headerlink\" title=\"静态代理\"></a>静态代理</h2><p>静态代理是我们直接定义在代码里的，也就是手动创建代理类，在调用原有类方法的前后加入逻辑，实现增强。但是这种方式违反了软件设计的开闭原则。</p>\n<p><strong>开闭原则（开放/封闭原则）</strong></p>\n<p>在面向对象编程领域中，开闭原则规定“软件中的对象（类，模块，函数等等）应该对于扩展是开放的，但是对于修改是封闭的”，这意味着一个实体是允许在不改变它的源代码的前提下变更它的行为。该特性在产品化的环境中是特别有价值的，在这种环境中，改变源代码需要代码审查，单元测试以及诸如此类的用以确保产品使用质量的过程。遵循这种原则的代码在扩展时并不发生改变，因此无需上述的过程。</p>\n<h2 id=\"动态代理\"><a href=\"#动态代理\" class=\"headerlink\" title=\"动态代理\"></a>动态代理</h2><p><strong>定义：</strong> 给目标对象提供一个代理对象，并由代理对象控制对目标对象对引用；<br><strong>目的：</strong></p>\n<ol>\n<li>通过引入代理对象的方式来间接访问目标对象，防止直接访问目标对象给系统带来的不必要的复杂性。</li>\n<li>通过代理对象对原有对业务增强。</li>\n</ol>\n<p><strong>动态代理中几个概念：</strong></p>\n<ul>\n<li>接口对象： 声明了真实对象和代理对象的公共接口</li>\n<li>真实对象： 代理对象所代表的真实对象，最终被引用的对象</li>\n<li>代理对象： 包含真实对象从而操作真实对象，相当于访问者与真实对象之间的中介</li>\n</ul>\n<h3 id=\"JDK动态代理\"><a href=\"#JDK动态代理\" class=\"headerlink\" title=\"JDK动态代理\"></a>JDK动态代理</h3><ul>\n<li>Proxy （java.lang.reflect.Proxy） 提供静态方法来创建动态代理类和实例，同时也是所有动态代理类的父类。通过静态方法<code>Proxy.newProxyInstance(真实对象.getClass().getClassLoader(), 真实对象.getClass().getInterfaces(), this)</code>，这里就声明了代理类要使用什么类加载器，继承什么接口，还有this（进行增强的InvocationHandler）。</li>\n<li>InvocationHandler （java.lang.reflect.InvocationHandler） 接口， 它只有一个invoke方法，通过实现这个方法来增加自己的逻辑。我们通过重写invoke方法，做一些增强，然后<code>method.invoke()</code>,通过反射来调用真实对象的方法。</li>\n</ul>\n<pre><code class=\"java\">public class SimpleJDKDynamicProxyDemo {\n    static interface IService {\n        public void sayHello();\n    }\n\n    static class RealService implements IService {\n        @Override\n        public void sayHello() {\n            System.out.println(&quot;hello&quot;);\n        }\n    }\n\n    static class SimpleInvocationHandler implements InvocationHandler {\n        private Object realObj;\n\n        public SimpleInvocationHandler(Object realObj) {\n            this.realObj = realObj;\n        }\n\n        @Override\n        public Object invoke(Object proxy, Method method,\n                             Object[] args) throws Throwable {\n            System.out.println(&quot;entering &quot; + method.getName());\n            Object result = method.invoke(realObj, args);\n            System.out.println(&quot;leaving &quot; + method.getName());\n            return result;\n        }\n    }\n\n    public static void main(String[] args) {\n        IService realService = new RealService();\n        IService proxyService = (IService) Proxy.newProxyInstance(\n                IService.class.getClassLoader(), new Class&lt;?&gt;[]{IService.class}, new SimpleInvocationHandler(realService));\n        proxyService.sayHello();\n    }\n}</code></pre>\n<p>在上面的例子中，IService和RealService是我们原有的。通过Proxy.newProxyInstance()来创建代理对象。</p>\n<pre><code class=\"java\">  public static Object newProxyInstance(ClassLoader loader,Class&lt;?&gt;[] interfaces, InvocationHandler h)</code></pre>\n<p><strong>这里要注意的一点：</strong><br>我们可以把获取到的对象强转为<code>Proxy.newProxyInstance()</code>参数中interfaces中的任意一个接口类型，却不能把它强转为某个类类型，比如RealService，即使它实际去代理的对象就是RealServcie实例。</p>\n<p>SimpleInvocationHandler实现了InvocationHandler，它的构造方法接收一个参数realObj表示被代理对象。invoke方法处理所有的接口调用。invoke方法有三个参数：</p>\n<ul>\n<li>proxy表示代理对象本身。</li>\n<li>method表示正在被调用的方法。</li>\n<li>args表示方法的参数。</li>\n</ul>\n<p>在SimpleInvocationHandler的invoke实现中，我们调用了method的invoke方法，传递了实际对象realObj作为参数，达到了调用实际对象对应方法的目的，调用方法的前后，我们加入了自己的代码。</p>\n<p><strong>这里要注意的一点：</strong><br>不要将代理对象传入invoke方法：<code>Object result = method.invoke(proxy, args);</code> 这将造成死循环！！因为proxy就是代理对象，调用它的对应方法又会调到SimpleInvocationInvocationHandler的invoke方法。</p>\n<p><strong>Proxy.newProxyInstance()都干了什么？</strong></p>\n<pre><code class=\"java\">Class&lt;?&gt; proxyCls = Proxy.getProxyClass(IService.class.getClassLoader(), new Class&lt;?&gt;[] { IService.class });\nConstructor&lt;?&gt; ctor = proxyCls.getConstructor( new Class&lt;?&gt;[] { InvocationHandler.class });\nInvocationHandler handler = new SimpleInvocationHandler(realService);\nIService proxyService = (IService) ctor.newInstance(handler);</code></pre>\n<ol>\n<li>通过<code>Proxy.getProxyClass()</code>创建代理类定义，类定义会被缓存；</li>\n<li>通过代理类都构造方法，构造方法有一个InvocationHandler类型的参数；</li>\n<li>创建InvocationHandler对象；</li>\n<li>创建代理对象。</li>\n</ol>\n<p>这里<code>Proxy.getProxyClass()</code>方法需要两个参数，一个是ClassLoader，另一个是接口数组。它会动态生成一个类，类名以$Proxy开头，后面跟一个数字。</p>\n<p>通过下面的参数可以在编译的时候保存生成的代理类的代码。</p>\n<pre><code class=\"shell\">java -Dsun.misc.ProxyGenerator.saveGeneratedFiles=true shuo.laoma.dynamic.c86.SimpleJDKDynamicProxyDemo</code></pre>\n<pre><code class=\"java\">final class $Proxy0 extends Proxy implements SimpleJDKDynamicProxyDemo.IService {\n    private static Method m1;\n    private static Method m3;\n    private static Method m2;\n    private static Method m0;\n\n    public $Proxy0(InvocationHandler paramInvocationHandler) {\n        super(paramInvocationHandler);\n    }\n\n    public final boolean equals(Object paramObject) {\n        return ((Boolean) this.h.invoke(this, m1,\n                new Object[]{paramObject})).booleanValue();\n    }\n\n    public final void sayHello() {\n        this.h.invoke(this, m3, null);\n    }\n\n    public final String toString() {\n        return (String) this.h.invoke(this, m2, null);\n    }\n\n    public final int hashCode() {\n        return ((Integer) this.h.invoke(this, m0, null)).intValue();\n    }\n\n    static {\n        m1 = Class.forName(&quot;java.lang.Object&quot;).getMethod(&quot;equals&quot;, new Class[]{Class.forName(&quot;java.lang.Object&quot;)});\n        m3 = Class.forName(&quot;laoma.demo.proxy.SimpleJDKDynamicProxyDemo$IService&quot;).getMethod(&quot;sayHello&quot;, new Class[0]);\n        m2 = Class.forName(&quot;java.lang.Object&quot;).getMethod(&quot;toString&quot;, new Class[0]);\n        m0 = Class.forName(&quot;java.lang.Object&quot;).getMethod(&quot;hashCode&quot;, new Class[0]);\n    }\n}</code></pre>\n<p>$Proxy0是Proxy的子类，有一个构造方法，接受一个InvocationHandler类型的参数，这个构造方法会调用父类Proxy的构造方法，将InvocationHandler对象传入，保存在父类成员变量h中。实现了IService接口，对于每个方法，比如例子中的<code>sayHello</code>，它将调用InvocationHandler的invoke方法，对于Object中的方法–heshcode、equals等方法，同样转发给了InvocationHandler对象来处理。</p>\n<p>上面的分析可以看出，这个代理类与被代理的对象没有任何关系，与InvocationHandler的具体实现也没有关系，而主要与接口数组有关，给定这个接口数组，它动态创建每个接口的实现代码，实现的方式就是转发给InvocationHandler，与被代理对象的关系以及对它的调用由Invocationhandler实现管理。</p>\n","site":{"data":{}},"more":"<h2 id=\"静态代理\"><a href=\"#静态代理\" class=\"headerlink\" title=\"静态代理\"></a>静态代理</h2><p>静态代理是我们直接定义在代码里的，也就是手动创建代理类，在调用原有类方法的前后加入逻辑，实现增强。但是这种方式违反了软件设计的开闭原则。</p>\n<p><strong>开闭原则（开放/封闭原则）</strong></p>\n<p>在面向对象编程领域中，开闭原则规定“软件中的对象（类，模块，函数等等）应该对于扩展是开放的，但是对于修改是封闭的”，这意味着一个实体是允许在不改变它的源代码的前提下变更它的行为。该特性在产品化的环境中是特别有价值的，在这种环境中，改变源代码需要代码审查，单元测试以及诸如此类的用以确保产品使用质量的过程。遵循这种原则的代码在扩展时并不发生改变，因此无需上述的过程。</p>\n<h2 id=\"动态代理\"><a href=\"#动态代理\" class=\"headerlink\" title=\"动态代理\"></a>动态代理</h2><p><strong>定义：</strong> 给目标对象提供一个代理对象，并由代理对象控制对目标对象对引用；<br><strong>目的：</strong></p>\n<ol>\n<li>通过引入代理对象的方式来间接访问目标对象，防止直接访问目标对象给系统带来的不必要的复杂性。</li>\n<li>通过代理对象对原有对业务增强。</li>\n</ol>\n<p><strong>动态代理中几个概念：</strong></p>\n<ul>\n<li>接口对象： 声明了真实对象和代理对象的公共接口</li>\n<li>真实对象： 代理对象所代表的真实对象，最终被引用的对象</li>\n<li>代理对象： 包含真实对象从而操作真实对象，相当于访问者与真实对象之间的中介</li>\n</ul>\n<h3 id=\"JDK动态代理\"><a href=\"#JDK动态代理\" class=\"headerlink\" title=\"JDK动态代理\"></a>JDK动态代理</h3><ul>\n<li>Proxy （java.lang.reflect.Proxy） 提供静态方法来创建动态代理类和实例，同时也是所有动态代理类的父类。通过静态方法<code>Proxy.newProxyInstance(真实对象.getClass().getClassLoader(), 真实对象.getClass().getInterfaces(), this)</code>，这里就声明了代理类要使用什么类加载器，继承什么接口，还有this（进行增强的InvocationHandler）。</li>\n<li>InvocationHandler （java.lang.reflect.InvocationHandler） 接口， 它只有一个invoke方法，通过实现这个方法来增加自己的逻辑。我们通过重写invoke方法，做一些增强，然后<code>method.invoke()</code>,通过反射来调用真实对象的方法。</li>\n</ul>\n<pre><code class=\"java\">public class SimpleJDKDynamicProxyDemo {\n    static interface IService {\n        public void sayHello();\n    }\n\n    static class RealService implements IService {\n        @Override\n        public void sayHello() {\n            System.out.println(&quot;hello&quot;);\n        }\n    }\n\n    static class SimpleInvocationHandler implements InvocationHandler {\n        private Object realObj;\n\n        public SimpleInvocationHandler(Object realObj) {\n            this.realObj = realObj;\n        }\n\n        @Override\n        public Object invoke(Object proxy, Method method,\n                             Object[] args) throws Throwable {\n            System.out.println(&quot;entering &quot; + method.getName());\n            Object result = method.invoke(realObj, args);\n            System.out.println(&quot;leaving &quot; + method.getName());\n            return result;\n        }\n    }\n\n    public static void main(String[] args) {\n        IService realService = new RealService();\n        IService proxyService = (IService) Proxy.newProxyInstance(\n                IService.class.getClassLoader(), new Class&lt;?&gt;[]{IService.class}, new SimpleInvocationHandler(realService));\n        proxyService.sayHello();\n    }\n}</code></pre>\n<p>在上面的例子中，IService和RealService是我们原有的。通过Proxy.newProxyInstance()来创建代理对象。</p>\n<pre><code class=\"java\">  public static Object newProxyInstance(ClassLoader loader,Class&lt;?&gt;[] interfaces, InvocationHandler h)</code></pre>\n<p><strong>这里要注意的一点：</strong><br>我们可以把获取到的对象强转为<code>Proxy.newProxyInstance()</code>参数中interfaces中的任意一个接口类型，却不能把它强转为某个类类型，比如RealService，即使它实际去代理的对象就是RealServcie实例。</p>\n<p>SimpleInvocationHandler实现了InvocationHandler，它的构造方法接收一个参数realObj表示被代理对象。invoke方法处理所有的接口调用。invoke方法有三个参数：</p>\n<ul>\n<li>proxy表示代理对象本身。</li>\n<li>method表示正在被调用的方法。</li>\n<li>args表示方法的参数。</li>\n</ul>\n<p>在SimpleInvocationHandler的invoke实现中，我们调用了method的invoke方法，传递了实际对象realObj作为参数，达到了调用实际对象对应方法的目的，调用方法的前后，我们加入了自己的代码。</p>\n<p><strong>这里要注意的一点：</strong><br>不要将代理对象传入invoke方法：<code>Object result = method.invoke(proxy, args);</code> 这将造成死循环！！因为proxy就是代理对象，调用它的对应方法又会调到SimpleInvocationInvocationHandler的invoke方法。</p>\n<p><strong>Proxy.newProxyInstance()都干了什么？</strong></p>\n<pre><code class=\"java\">Class&lt;?&gt; proxyCls = Proxy.getProxyClass(IService.class.getClassLoader(), new Class&lt;?&gt;[] { IService.class });\nConstructor&lt;?&gt; ctor = proxyCls.getConstructor( new Class&lt;?&gt;[] { InvocationHandler.class });\nInvocationHandler handler = new SimpleInvocationHandler(realService);\nIService proxyService = (IService) ctor.newInstance(handler);</code></pre>\n<ol>\n<li>通过<code>Proxy.getProxyClass()</code>创建代理类定义，类定义会被缓存；</li>\n<li>通过代理类都构造方法，构造方法有一个InvocationHandler类型的参数；</li>\n<li>创建InvocationHandler对象；</li>\n<li>创建代理对象。</li>\n</ol>\n<p>这里<code>Proxy.getProxyClass()</code>方法需要两个参数，一个是ClassLoader，另一个是接口数组。它会动态生成一个类，类名以$Proxy开头，后面跟一个数字。</p>\n<p>通过下面的参数可以在编译的时候保存生成的代理类的代码。</p>\n<pre><code class=\"shell\">java -Dsun.misc.ProxyGenerator.saveGeneratedFiles=true shuo.laoma.dynamic.c86.SimpleJDKDynamicProxyDemo</code></pre>\n<pre><code class=\"java\">final class $Proxy0 extends Proxy implements SimpleJDKDynamicProxyDemo.IService {\n    private static Method m1;\n    private static Method m3;\n    private static Method m2;\n    private static Method m0;\n\n    public $Proxy0(InvocationHandler paramInvocationHandler) {\n        super(paramInvocationHandler);\n    }\n\n    public final boolean equals(Object paramObject) {\n        return ((Boolean) this.h.invoke(this, m1,\n                new Object[]{paramObject})).booleanValue();\n    }\n\n    public final void sayHello() {\n        this.h.invoke(this, m3, null);\n    }\n\n    public final String toString() {\n        return (String) this.h.invoke(this, m2, null);\n    }\n\n    public final int hashCode() {\n        return ((Integer) this.h.invoke(this, m0, null)).intValue();\n    }\n\n    static {\n        m1 = Class.forName(&quot;java.lang.Object&quot;).getMethod(&quot;equals&quot;, new Class[]{Class.forName(&quot;java.lang.Object&quot;)});\n        m3 = Class.forName(&quot;laoma.demo.proxy.SimpleJDKDynamicProxyDemo$IService&quot;).getMethod(&quot;sayHello&quot;, new Class[0]);\n        m2 = Class.forName(&quot;java.lang.Object&quot;).getMethod(&quot;toString&quot;, new Class[0]);\n        m0 = Class.forName(&quot;java.lang.Object&quot;).getMethod(&quot;hashCode&quot;, new Class[0]);\n    }\n}</code></pre>\n<p>$Proxy0是Proxy的子类，有一个构造方法，接受一个InvocationHandler类型的参数，这个构造方法会调用父类Proxy的构造方法，将InvocationHandler对象传入，保存在父类成员变量h中。实现了IService接口，对于每个方法，比如例子中的<code>sayHello</code>，它将调用InvocationHandler的invoke方法，对于Object中的方法–heshcode、equals等方法，同样转发给了InvocationHandler对象来处理。</p>\n<p>上面的分析可以看出，这个代理类与被代理的对象没有任何关系，与InvocationHandler的具体实现也没有关系，而主要与接口数组有关，给定这个接口数组，它动态创建每个接口的实现代码，实现的方式就是转发给InvocationHandler，与被代理对象的关系以及对它的调用由Invocationhandler实现管理。</p>\n"},{"title":"单播、多播（组播）、广播","excerpt":"","comments":1,"date":"2020-05-21T16:30:52.000Z","_content":"\n单播、多播和广播单播”（Unicast）、“多播”（Multicast）和“广播”（Broadcast）这三个术语都是用来描述网络节点之间通讯方式的术语。那么这些术语究竟是什么意思？区别何在？\n\n## 概念\n\n1. **单播：**  网络节点之间的通信就好像是人们之间的对话一样。如果一个人对另外一个人说话，那么用网络技术的术语来描述就是“单播”，此时信息的接收和传递只在两个节点之间进行。单播在网络中得到了广泛的应用，网络上绝大部分的数据都是以单播的形式传输的，只是一般网络用户不知道而已。例如，你在收发电子邮件、浏览网页时，必须与邮件服务器、Web服务器建立连接，此时使用的就是单播数据传输方式。但是通常使用“点对点通信”（Point to Point）代替“单播”，因为“单播”一般与“多播”和“广播”相对应使用。\n\n2. **多播：** “多播”也可以称为“组播”，在网络技术的应用并不是很多，网上视频会议、网上视频点播特别适合采用多播方式。因为如果采用单播方式，逐个节点传输，有多少个目标节点，就会有多少次传送过程，这种方式显然效率极低，是不可取的；如果采用不区分目标、全部发送的广播方式，虽然一次可以传送完数据，但是显然达不到区分特定数据接收对象的目的。采用多播方式，既可以实现一次传送所有目标节点的数据，也可以达到只对特定对象传送数据的目的。IP网络的多播一般通过`多播IP地址`来实现。**多播IP地址就是D类IP地址，即224.0.0.0至239.255.255.255之间的IP地址。** Windows 2000中的DHCP管理器支持多播IP地址的自动分配。\n\n3. **广播：** “广播”在网络中的应用较多，如客户机通过DHCP自动获得IP地址的过程就是通过广播来实现的。但是同单播和多播相比，**广播几乎占用了子网内网络的所有带宽。** 拿开会打一个比方吧，在会场上只能有一个人发言，想象一下如果所有的人同时都用麦克风发言，那会场上就会乱成一锅粥。集线器由于其工作原理决定了不可能过滤广播风暴，一般的交换机也没有这一功能，不过现在有的网络交换机（如全向的QS系列交换机）也有过滤广播风暴功能了，路由器本身就有隔离广播风暴的作用。广播风暴不能完全杜绝，但是只能在同一子网内传播，就好像喇叭的声音只能在同一会场内传播一样，因此在由几百台甚至上千台电脑构成的大中型局域网中，一般进行子网划分，就像将一个大厅用墙壁隔离成许多小厅一样，以达到隔离广播风暴的目的。**在IP网络中，广播地址用IP地址“255.255.255.255”来表示，这个IP地址代表同一子网内所有的IP地址。**\n\n\n## 优缺点：\n\n当前的网络中有三种通讯模式：单播、广播、组播，其中的**组播出现时间最晚但同时具备单播和广播的优点**，最具有发展前景。\n\n1． **单播：**\n主机之间一对一的通讯模式，网络中的交换机和路由器对数据只进行转发不进行复制。如果10个客户机需要相同的数据，则服务器需要逐一传送，重复10次相同的工作。但由于其能够针对每个客户的及时响应，所以现在的网页浏览全部都是采用单播模式，具体的说就是IP单播协议。网络中的路由器和交换机根据其目标地址选择传输路径，将IP单播数据传送到其指定的目的地。\n\n**单播的优点：**\n- 服务器及时响应客户机的请求\n- 服务器针对每个客户不通的请求发送不通的数据，容易实现个性化服务。\n\n**单播的缺点：**\n- 服务器针对每个客户机发送数据流，服务器流量＝客户机数量×客户机流量；在客户数量大、每个客户机流量大的流媒体应用中服务器不堪重负。\n- 现有的网络带宽是金字塔结构，城际省际主干带宽仅仅相当于其所有用户带宽之和的5％。如果全部使用单播协议，将造成网络主干不堪重负。现在的P2P应用就已经使主干经常阻塞。而将主干扩展20倍几乎是不可能。\n\n2． **广播：**\n主机之间一对所有的通讯模式，网络对其中每一台主机发出的信号都进行无条件复制并转发，所有主机都可以接收到所有信息（不管你是否需要），由于其不用路径选择，所以其网络成本可以很低廉。有线电视网就是典型的广播型网络，我们的电视机实际上是接受到所有频道的信号，但只将一个频道的信号还原成画面。在数据网络中也允许广播的存在，但其被限制在二层交换机的局域网范围内，禁止广播数据穿过路由器，防止广播数据影响大面积的主机。\n\n**广播的优点：**\n- 网络设备简单，维护简单，布网成本低廉\n- 由于服务器不用向每个客户机单独发送数据，所以服务器流量负载极低。\n\n**广播的缺点：**\n- 无法针对每个客户的要求和时间及时提供个性化服务。\n- 网络允许服务器提供数据的带宽有限，客户端的最大带宽＝服务总带宽。例如有线电视的客户端的线路支持100个频道（如果采用数字压缩技术，理论上可以提供500个频道），即使服务商有更大的财力配置更多的发送设备、改成光纤主干，也无法超过此极限。也就是说无法向众多客户提供更多样化、更加个性化的服务。\n- 广播禁止允许在Internet宽带网上传输。\n\n3． **组播：**\n主机之间一对一组的通讯模式，也就是**加入了同一个组**的主机可以接受到此组内的所有数据，网络中的交换机和路由器只向有需求者复制并转发其所需数据。主机可以向路由器请求加入或退出某个组，网络中的路由器和交换机有选择的复制并传输数据，即只将组内数据传输给那些加入组的主机。这样既能一次将数据传输给多个有需要（加入组）的主机，又能保证不影响其他不需要（未加入组）的主机的其他通讯。\n\n**组播的优点：**\n- 需要相同数据流的客户端加入相同的组共享一条数据流，节省了服务器的负载。具备广播所具备的优点。\n- 由于组播协议是根据接受者的需要对数据流进行复制转发，所以服务端的服务总带宽不受客户接入端带宽的限制。IP协议允许有2亿6千多万个组播，所以其提供的服务可以非常丰富。\n- 此协议和单播协议一样允许在Internet宽带网上传输。\n\n**组播的缺点：**\n- 与单播协议相比没有纠错机制，发生丢包错包后难以弥补，但可以通过一定的容错机制和QOS加以弥补。\n- 现行网络虽然都支持组播的传输，但在客户认证、QOS等方面还需要完善，这些缺点在理论上都有成熟的解决方案，只是需要逐步推广应用到现存网络当中。","source":"_posts/2020-05-22-kongzheng1993-Unicast_Multicast_Broadcast.md","raw":"---\ntitle: 单播、多播（组播）、广播\nexcerpt: ''\ntags: [maven]\ncategories: [maven]\ncomments: true\ndate: 2020-05-22 00:30:52\n---\n\n单播、多播和广播单播”（Unicast）、“多播”（Multicast）和“广播”（Broadcast）这三个术语都是用来描述网络节点之间通讯方式的术语。那么这些术语究竟是什么意思？区别何在？\n\n## 概念\n\n1. **单播：**  网络节点之间的通信就好像是人们之间的对话一样。如果一个人对另外一个人说话，那么用网络技术的术语来描述就是“单播”，此时信息的接收和传递只在两个节点之间进行。单播在网络中得到了广泛的应用，网络上绝大部分的数据都是以单播的形式传输的，只是一般网络用户不知道而已。例如，你在收发电子邮件、浏览网页时，必须与邮件服务器、Web服务器建立连接，此时使用的就是单播数据传输方式。但是通常使用“点对点通信”（Point to Point）代替“单播”，因为“单播”一般与“多播”和“广播”相对应使用。\n\n2. **多播：** “多播”也可以称为“组播”，在网络技术的应用并不是很多，网上视频会议、网上视频点播特别适合采用多播方式。因为如果采用单播方式，逐个节点传输，有多少个目标节点，就会有多少次传送过程，这种方式显然效率极低，是不可取的；如果采用不区分目标、全部发送的广播方式，虽然一次可以传送完数据，但是显然达不到区分特定数据接收对象的目的。采用多播方式，既可以实现一次传送所有目标节点的数据，也可以达到只对特定对象传送数据的目的。IP网络的多播一般通过`多播IP地址`来实现。**多播IP地址就是D类IP地址，即224.0.0.0至239.255.255.255之间的IP地址。** Windows 2000中的DHCP管理器支持多播IP地址的自动分配。\n\n3. **广播：** “广播”在网络中的应用较多，如客户机通过DHCP自动获得IP地址的过程就是通过广播来实现的。但是同单播和多播相比，**广播几乎占用了子网内网络的所有带宽。** 拿开会打一个比方吧，在会场上只能有一个人发言，想象一下如果所有的人同时都用麦克风发言，那会场上就会乱成一锅粥。集线器由于其工作原理决定了不可能过滤广播风暴，一般的交换机也没有这一功能，不过现在有的网络交换机（如全向的QS系列交换机）也有过滤广播风暴功能了，路由器本身就有隔离广播风暴的作用。广播风暴不能完全杜绝，但是只能在同一子网内传播，就好像喇叭的声音只能在同一会场内传播一样，因此在由几百台甚至上千台电脑构成的大中型局域网中，一般进行子网划分，就像将一个大厅用墙壁隔离成许多小厅一样，以达到隔离广播风暴的目的。**在IP网络中，广播地址用IP地址“255.255.255.255”来表示，这个IP地址代表同一子网内所有的IP地址。**\n\n\n## 优缺点：\n\n当前的网络中有三种通讯模式：单播、广播、组播，其中的**组播出现时间最晚但同时具备单播和广播的优点**，最具有发展前景。\n\n1． **单播：**\n主机之间一对一的通讯模式，网络中的交换机和路由器对数据只进行转发不进行复制。如果10个客户机需要相同的数据，则服务器需要逐一传送，重复10次相同的工作。但由于其能够针对每个客户的及时响应，所以现在的网页浏览全部都是采用单播模式，具体的说就是IP单播协议。网络中的路由器和交换机根据其目标地址选择传输路径，将IP单播数据传送到其指定的目的地。\n\n**单播的优点：**\n- 服务器及时响应客户机的请求\n- 服务器针对每个客户不通的请求发送不通的数据，容易实现个性化服务。\n\n**单播的缺点：**\n- 服务器针对每个客户机发送数据流，服务器流量＝客户机数量×客户机流量；在客户数量大、每个客户机流量大的流媒体应用中服务器不堪重负。\n- 现有的网络带宽是金字塔结构，城际省际主干带宽仅仅相当于其所有用户带宽之和的5％。如果全部使用单播协议，将造成网络主干不堪重负。现在的P2P应用就已经使主干经常阻塞。而将主干扩展20倍几乎是不可能。\n\n2． **广播：**\n主机之间一对所有的通讯模式，网络对其中每一台主机发出的信号都进行无条件复制并转发，所有主机都可以接收到所有信息（不管你是否需要），由于其不用路径选择，所以其网络成本可以很低廉。有线电视网就是典型的广播型网络，我们的电视机实际上是接受到所有频道的信号，但只将一个频道的信号还原成画面。在数据网络中也允许广播的存在，但其被限制在二层交换机的局域网范围内，禁止广播数据穿过路由器，防止广播数据影响大面积的主机。\n\n**广播的优点：**\n- 网络设备简单，维护简单，布网成本低廉\n- 由于服务器不用向每个客户机单独发送数据，所以服务器流量负载极低。\n\n**广播的缺点：**\n- 无法针对每个客户的要求和时间及时提供个性化服务。\n- 网络允许服务器提供数据的带宽有限，客户端的最大带宽＝服务总带宽。例如有线电视的客户端的线路支持100个频道（如果采用数字压缩技术，理论上可以提供500个频道），即使服务商有更大的财力配置更多的发送设备、改成光纤主干，也无法超过此极限。也就是说无法向众多客户提供更多样化、更加个性化的服务。\n- 广播禁止允许在Internet宽带网上传输。\n\n3． **组播：**\n主机之间一对一组的通讯模式，也就是**加入了同一个组**的主机可以接受到此组内的所有数据，网络中的交换机和路由器只向有需求者复制并转发其所需数据。主机可以向路由器请求加入或退出某个组，网络中的路由器和交换机有选择的复制并传输数据，即只将组内数据传输给那些加入组的主机。这样既能一次将数据传输给多个有需要（加入组）的主机，又能保证不影响其他不需要（未加入组）的主机的其他通讯。\n\n**组播的优点：**\n- 需要相同数据流的客户端加入相同的组共享一条数据流，节省了服务器的负载。具备广播所具备的优点。\n- 由于组播协议是根据接受者的需要对数据流进行复制转发，所以服务端的服务总带宽不受客户接入端带宽的限制。IP协议允许有2亿6千多万个组播，所以其提供的服务可以非常丰富。\n- 此协议和单播协议一样允许在Internet宽带网上传输。\n\n**组播的缺点：**\n- 与单播协议相比没有纠错机制，发生丢包错包后难以弥补，但可以通过一定的容错机制和QOS加以弥补。\n- 现行网络虽然都支持组播的传输，但在客户认证、QOS等方面还需要完善，这些缺点在理论上都有成熟的解决方案，只是需要逐步推广应用到现存网络当中。","slug":"kongzheng1993-Unicast_Multicast_Broadcast","published":1,"updated":"2023-03-08T07:05:58.803Z","layout":"post","photos":[],"link":"","_id":"clg0k2akr004rt26fh6yirhwd","content":"<p>单播、多播和广播单播”（Unicast）、“多播”（Multicast）和“广播”（Broadcast）这三个术语都是用来描述网络节点之间通讯方式的术语。那么这些术语究竟是什么意思？区别何在？</p>\n<h2 id=\"概念\"><a href=\"#概念\" class=\"headerlink\" title=\"概念\"></a>概念</h2><ol>\n<li><p><strong>单播：</strong>  网络节点之间的通信就好像是人们之间的对话一样。如果一个人对另外一个人说话，那么用网络技术的术语来描述就是“单播”，此时信息的接收和传递只在两个节点之间进行。单播在网络中得到了广泛的应用，网络上绝大部分的数据都是以单播的形式传输的，只是一般网络用户不知道而已。例如，你在收发电子邮件、浏览网页时，必须与邮件服务器、Web服务器建立连接，此时使用的就是单播数据传输方式。但是通常使用“点对点通信”（Point to Point）代替“单播”，因为“单播”一般与“多播”和“广播”相对应使用。</p>\n</li>\n<li><p><strong>多播：</strong> “多播”也可以称为“组播”，在网络技术的应用并不是很多，网上视频会议、网上视频点播特别适合采用多播方式。因为如果采用单播方式，逐个节点传输，有多少个目标节点，就会有多少次传送过程，这种方式显然效率极低，是不可取的；如果采用不区分目标、全部发送的广播方式，虽然一次可以传送完数据，但是显然达不到区分特定数据接收对象的目的。采用多播方式，既可以实现一次传送所有目标节点的数据，也可以达到只对特定对象传送数据的目的。IP网络的多播一般通过<code>多播IP地址</code>来实现。<strong>多播IP地址就是D类IP地址，即224.0.0.0至239.255.255.255之间的IP地址。</strong> Windows 2000中的DHCP管理器支持多播IP地址的自动分配。</p>\n</li>\n<li><p><strong>广播：</strong> “广播”在网络中的应用较多，如客户机通过DHCP自动获得IP地址的过程就是通过广播来实现的。但是同单播和多播相比，<strong>广播几乎占用了子网内网络的所有带宽。</strong> 拿开会打一个比方吧，在会场上只能有一个人发言，想象一下如果所有的人同时都用麦克风发言，那会场上就会乱成一锅粥。集线器由于其工作原理决定了不可能过滤广播风暴，一般的交换机也没有这一功能，不过现在有的网络交换机（如全向的QS系列交换机）也有过滤广播风暴功能了，路由器本身就有隔离广播风暴的作用。广播风暴不能完全杜绝，但是只能在同一子网内传播，就好像喇叭的声音只能在同一会场内传播一样，因此在由几百台甚至上千台电脑构成的大中型局域网中，一般进行子网划分，就像将一个大厅用墙壁隔离成许多小厅一样，以达到隔离广播风暴的目的。<strong>在IP网络中，广播地址用IP地址“255.255.255.255”来表示，这个IP地址代表同一子网内所有的IP地址。</strong></p>\n</li>\n</ol>\n<h2 id=\"优缺点：\"><a href=\"#优缺点：\" class=\"headerlink\" title=\"优缺点：\"></a>优缺点：</h2><p>当前的网络中有三种通讯模式：单播、广播、组播，其中的<strong>组播出现时间最晚但同时具备单播和广播的优点</strong>，最具有发展前景。</p>\n<p>1． <strong>单播：</strong><br>主机之间一对一的通讯模式，网络中的交换机和路由器对数据只进行转发不进行复制。如果10个客户机需要相同的数据，则服务器需要逐一传送，重复10次相同的工作。但由于其能够针对每个客户的及时响应，所以现在的网页浏览全部都是采用单播模式，具体的说就是IP单播协议。网络中的路由器和交换机根据其目标地址选择传输路径，将IP单播数据传送到其指定的目的地。</p>\n<p><strong>单播的优点：</strong></p>\n<ul>\n<li>服务器及时响应客户机的请求</li>\n<li>服务器针对每个客户不通的请求发送不通的数据，容易实现个性化服务。</li>\n</ul>\n<p><strong>单播的缺点：</strong></p>\n<ul>\n<li>服务器针对每个客户机发送数据流，服务器流量＝客户机数量×客户机流量；在客户数量大、每个客户机流量大的流媒体应用中服务器不堪重负。</li>\n<li>现有的网络带宽是金字塔结构，城际省际主干带宽仅仅相当于其所有用户带宽之和的5％。如果全部使用单播协议，将造成网络主干不堪重负。现在的P2P应用就已经使主干经常阻塞。而将主干扩展20倍几乎是不可能。</li>\n</ul>\n<p>2． <strong>广播：</strong><br>主机之间一对所有的通讯模式，网络对其中每一台主机发出的信号都进行无条件复制并转发，所有主机都可以接收到所有信息（不管你是否需要），由于其不用路径选择，所以其网络成本可以很低廉。有线电视网就是典型的广播型网络，我们的电视机实际上是接受到所有频道的信号，但只将一个频道的信号还原成画面。在数据网络中也允许广播的存在，但其被限制在二层交换机的局域网范围内，禁止广播数据穿过路由器，防止广播数据影响大面积的主机。</p>\n<p><strong>广播的优点：</strong></p>\n<ul>\n<li>网络设备简单，维护简单，布网成本低廉</li>\n<li>由于服务器不用向每个客户机单独发送数据，所以服务器流量负载极低。</li>\n</ul>\n<p><strong>广播的缺点：</strong></p>\n<ul>\n<li>无法针对每个客户的要求和时间及时提供个性化服务。</li>\n<li>网络允许服务器提供数据的带宽有限，客户端的最大带宽＝服务总带宽。例如有线电视的客户端的线路支持100个频道（如果采用数字压缩技术，理论上可以提供500个频道），即使服务商有更大的财力配置更多的发送设备、改成光纤主干，也无法超过此极限。也就是说无法向众多客户提供更多样化、更加个性化的服务。</li>\n<li>广播禁止允许在Internet宽带网上传输。</li>\n</ul>\n<p>3． <strong>组播：</strong><br>主机之间一对一组的通讯模式，也就是<strong>加入了同一个组</strong>的主机可以接受到此组内的所有数据，网络中的交换机和路由器只向有需求者复制并转发其所需数据。主机可以向路由器请求加入或退出某个组，网络中的路由器和交换机有选择的复制并传输数据，即只将组内数据传输给那些加入组的主机。这样既能一次将数据传输给多个有需要（加入组）的主机，又能保证不影响其他不需要（未加入组）的主机的其他通讯。</p>\n<p><strong>组播的优点：</strong></p>\n<ul>\n<li>需要相同数据流的客户端加入相同的组共享一条数据流，节省了服务器的负载。具备广播所具备的优点。</li>\n<li>由于组播协议是根据接受者的需要对数据流进行复制转发，所以服务端的服务总带宽不受客户接入端带宽的限制。IP协议允许有2亿6千多万个组播，所以其提供的服务可以非常丰富。</li>\n<li>此协议和单播协议一样允许在Internet宽带网上传输。</li>\n</ul>\n<p><strong>组播的缺点：</strong></p>\n<ul>\n<li>与单播协议相比没有纠错机制，发生丢包错包后难以弥补，但可以通过一定的容错机制和QOS加以弥补。</li>\n<li>现行网络虽然都支持组播的传输，但在客户认证、QOS等方面还需要完善，这些缺点在理论上都有成熟的解决方案，只是需要逐步推广应用到现存网络当中。</li>\n</ul>\n","site":{"data":{}},"more":"<p>单播、多播和广播单播”（Unicast）、“多播”（Multicast）和“广播”（Broadcast）这三个术语都是用来描述网络节点之间通讯方式的术语。那么这些术语究竟是什么意思？区别何在？</p>\n<h2 id=\"概念\"><a href=\"#概念\" class=\"headerlink\" title=\"概念\"></a>概念</h2><ol>\n<li><p><strong>单播：</strong>  网络节点之间的通信就好像是人们之间的对话一样。如果一个人对另外一个人说话，那么用网络技术的术语来描述就是“单播”，此时信息的接收和传递只在两个节点之间进行。单播在网络中得到了广泛的应用，网络上绝大部分的数据都是以单播的形式传输的，只是一般网络用户不知道而已。例如，你在收发电子邮件、浏览网页时，必须与邮件服务器、Web服务器建立连接，此时使用的就是单播数据传输方式。但是通常使用“点对点通信”（Point to Point）代替“单播”，因为“单播”一般与“多播”和“广播”相对应使用。</p>\n</li>\n<li><p><strong>多播：</strong> “多播”也可以称为“组播”，在网络技术的应用并不是很多，网上视频会议、网上视频点播特别适合采用多播方式。因为如果采用单播方式，逐个节点传输，有多少个目标节点，就会有多少次传送过程，这种方式显然效率极低，是不可取的；如果采用不区分目标、全部发送的广播方式，虽然一次可以传送完数据，但是显然达不到区分特定数据接收对象的目的。采用多播方式，既可以实现一次传送所有目标节点的数据，也可以达到只对特定对象传送数据的目的。IP网络的多播一般通过<code>多播IP地址</code>来实现。<strong>多播IP地址就是D类IP地址，即224.0.0.0至239.255.255.255之间的IP地址。</strong> Windows 2000中的DHCP管理器支持多播IP地址的自动分配。</p>\n</li>\n<li><p><strong>广播：</strong> “广播”在网络中的应用较多，如客户机通过DHCP自动获得IP地址的过程就是通过广播来实现的。但是同单播和多播相比，<strong>广播几乎占用了子网内网络的所有带宽。</strong> 拿开会打一个比方吧，在会场上只能有一个人发言，想象一下如果所有的人同时都用麦克风发言，那会场上就会乱成一锅粥。集线器由于其工作原理决定了不可能过滤广播风暴，一般的交换机也没有这一功能，不过现在有的网络交换机（如全向的QS系列交换机）也有过滤广播风暴功能了，路由器本身就有隔离广播风暴的作用。广播风暴不能完全杜绝，但是只能在同一子网内传播，就好像喇叭的声音只能在同一会场内传播一样，因此在由几百台甚至上千台电脑构成的大中型局域网中，一般进行子网划分，就像将一个大厅用墙壁隔离成许多小厅一样，以达到隔离广播风暴的目的。<strong>在IP网络中，广播地址用IP地址“255.255.255.255”来表示，这个IP地址代表同一子网内所有的IP地址。</strong></p>\n</li>\n</ol>\n<h2 id=\"优缺点：\"><a href=\"#优缺点：\" class=\"headerlink\" title=\"优缺点：\"></a>优缺点：</h2><p>当前的网络中有三种通讯模式：单播、广播、组播，其中的<strong>组播出现时间最晚但同时具备单播和广播的优点</strong>，最具有发展前景。</p>\n<p>1． <strong>单播：</strong><br>主机之间一对一的通讯模式，网络中的交换机和路由器对数据只进行转发不进行复制。如果10个客户机需要相同的数据，则服务器需要逐一传送，重复10次相同的工作。但由于其能够针对每个客户的及时响应，所以现在的网页浏览全部都是采用单播模式，具体的说就是IP单播协议。网络中的路由器和交换机根据其目标地址选择传输路径，将IP单播数据传送到其指定的目的地。</p>\n<p><strong>单播的优点：</strong></p>\n<ul>\n<li>服务器及时响应客户机的请求</li>\n<li>服务器针对每个客户不通的请求发送不通的数据，容易实现个性化服务。</li>\n</ul>\n<p><strong>单播的缺点：</strong></p>\n<ul>\n<li>服务器针对每个客户机发送数据流，服务器流量＝客户机数量×客户机流量；在客户数量大、每个客户机流量大的流媒体应用中服务器不堪重负。</li>\n<li>现有的网络带宽是金字塔结构，城际省际主干带宽仅仅相当于其所有用户带宽之和的5％。如果全部使用单播协议，将造成网络主干不堪重负。现在的P2P应用就已经使主干经常阻塞。而将主干扩展20倍几乎是不可能。</li>\n</ul>\n<p>2． <strong>广播：</strong><br>主机之间一对所有的通讯模式，网络对其中每一台主机发出的信号都进行无条件复制并转发，所有主机都可以接收到所有信息（不管你是否需要），由于其不用路径选择，所以其网络成本可以很低廉。有线电视网就是典型的广播型网络，我们的电视机实际上是接受到所有频道的信号，但只将一个频道的信号还原成画面。在数据网络中也允许广播的存在，但其被限制在二层交换机的局域网范围内，禁止广播数据穿过路由器，防止广播数据影响大面积的主机。</p>\n<p><strong>广播的优点：</strong></p>\n<ul>\n<li>网络设备简单，维护简单，布网成本低廉</li>\n<li>由于服务器不用向每个客户机单独发送数据，所以服务器流量负载极低。</li>\n</ul>\n<p><strong>广播的缺点：</strong></p>\n<ul>\n<li>无法针对每个客户的要求和时间及时提供个性化服务。</li>\n<li>网络允许服务器提供数据的带宽有限，客户端的最大带宽＝服务总带宽。例如有线电视的客户端的线路支持100个频道（如果采用数字压缩技术，理论上可以提供500个频道），即使服务商有更大的财力配置更多的发送设备、改成光纤主干，也无法超过此极限。也就是说无法向众多客户提供更多样化、更加个性化的服务。</li>\n<li>广播禁止允许在Internet宽带网上传输。</li>\n</ul>\n<p>3． <strong>组播：</strong><br>主机之间一对一组的通讯模式，也就是<strong>加入了同一个组</strong>的主机可以接受到此组内的所有数据，网络中的交换机和路由器只向有需求者复制并转发其所需数据。主机可以向路由器请求加入或退出某个组，网络中的路由器和交换机有选择的复制并传输数据，即只将组内数据传输给那些加入组的主机。这样既能一次将数据传输给多个有需要（加入组）的主机，又能保证不影响其他不需要（未加入组）的主机的其他通讯。</p>\n<p><strong>组播的优点：</strong></p>\n<ul>\n<li>需要相同数据流的客户端加入相同的组共享一条数据流，节省了服务器的负载。具备广播所具备的优点。</li>\n<li>由于组播协议是根据接受者的需要对数据流进行复制转发，所以服务端的服务总带宽不受客户接入端带宽的限制。IP协议允许有2亿6千多万个组播，所以其提供的服务可以非常丰富。</li>\n<li>此协议和单播协议一样允许在Internet宽带网上传输。</li>\n</ul>\n<p><strong>组播的缺点：</strong></p>\n<ul>\n<li>与单播协议相比没有纠错机制，发生丢包错包后难以弥补，但可以通过一定的容错机制和QOS加以弥补。</li>\n<li>现行网络虽然都支持组播的传输，但在客户认证、QOS等方面还需要完善，这些缺点在理论上都有成熟的解决方案，只是需要逐步推广应用到现存网络当中。</li>\n</ul>\n"},{"title":"Java RMI","excerpt":"","comments":1,"date":"2020-07-04T16:30:52.000Z","_content":"\n\n今天是周日，昨天是挺忙碌的一天，上午去了一趟姥姥家，一年多没去了，最然都在北京，却还是不能经常见面。和舅舅聊了聊最近的生活和工作，他一直鼓励我努力。下午去找潇哥玩了，也是很久不见了，半年是有了。去他家坐了坐，有了女朋友的潇哥确实是精致了一些，晚上吃了顿露天烧烤，聊了聊这半年怎么被社会毒打的。。\n\n今天坐在电脑前，不知道干点啥，b站首页停了半天不知道刷个什么视频。突然想起来之前面试又被问到java的RMI，今天来总结一下。\n\n\nRMI是Java官方的一个RPC协议，像dubbo也支持RMI。\n\n官方文档[Java RMI](https://docs.oracle.com/javase/tutorial/rmi/index.html)。\n\n- Registry 注册中心，负责注册服务。\n- Server 提供服务，实现接口。\n- Client 调用方，调用服务。\n\n\n官方文档中demo工程可以看。\n\nServer端需要实现接口，并将接口暴露到网络。\n\n```java\n    public static void main(String[] args) {\n        try {\n            String name = \"Compute\";\n            Compute engine = new ComputeEngine();\n            Compute stub =\n                    (Compute) UnicastRemoteObject.exportObject(engine, 0); // anonymous port\n            Registry registry = LocateRegistry.createRegistry(1099);\n            registry.rebind(name, stub);\n            System.out.println(\"ComputeEngine bound\");\n        } catch (Exception e) {\n            System.err.println(\"ComputeEngine exception:\");\n            e.printStackTrace();\n        }\n    }\n```\n\nClient端要获取Server端注册接口的注册中心，并从注册中心获取到接口，然后调用。\n\n```java\n    public static void main(String args[]) {\n        try {\n            String name = \"Compute\";\n            Registry registry = LocateRegistry.getRegistry(\"127.0.0.1\", 1099);\n            Compute comp = (Compute) registry.lookup(name);\n            Pi task = new Pi();\n            BigDecimal pi = comp.executeTask(task);\n            System.out.println(pi);\n        } catch (Exception e) {\n            System.err.println(\"ComputePi exception:\");\n            e.printStackTrace();\n        }\n    }\n```\n\n其实，RMI只是Java对RPC的一种实现而已。只不过，很多RPC都是网络协议发送方法、参数等实现远程调用;RMI是通过客户端的Stub对象作为远程接口进行远程方法的调用。\n\n    注：Stub:为屏蔽客户调用远程主机上的对象，必须提供某种方式来模拟本地对象,这种本地对象称为存根(stub),存根负责接收本地方法调用,并将它们委派给各自的具体实现对象。\n\nstub意思存根，在上面的程序中就是我们定义的接口--Compute，一开始我理解的不透彻是因为我一直以为这个接口是服务端设计的，客户端不应该有，而看到`Compute comp = (Compute) registry.lookup(name);`又很不解，客户端怎么知道的有Compute？所以这也是rmi这种rpc实现的不足之一。interface作为一种规定，需要服务端和客户端都了解到，二者再进行通信。客户端只需要知道这个规范（interface），真正的对象是客户端返回来的，也就是这个stub。当compute被调用时，在通过网络访问对应的方法，返回结果。\n\n<img src=\"rmi.png\">","source":"_posts/2020-07-05-kongzheng1993-Java-rmi.md","raw":"---\ntitle: Java RMI\nexcerpt: ''\ntags: [java]\ncategories: [java]\ncomments: true\ndate: 2020-07-05 00:30:52\n---\n\n\n今天是周日，昨天是挺忙碌的一天，上午去了一趟姥姥家，一年多没去了，最然都在北京，却还是不能经常见面。和舅舅聊了聊最近的生活和工作，他一直鼓励我努力。下午去找潇哥玩了，也是很久不见了，半年是有了。去他家坐了坐，有了女朋友的潇哥确实是精致了一些，晚上吃了顿露天烧烤，聊了聊这半年怎么被社会毒打的。。\n\n今天坐在电脑前，不知道干点啥，b站首页停了半天不知道刷个什么视频。突然想起来之前面试又被问到java的RMI，今天来总结一下。\n\n\nRMI是Java官方的一个RPC协议，像dubbo也支持RMI。\n\n官方文档[Java RMI](https://docs.oracle.com/javase/tutorial/rmi/index.html)。\n\n- Registry 注册中心，负责注册服务。\n- Server 提供服务，实现接口。\n- Client 调用方，调用服务。\n\n\n官方文档中demo工程可以看。\n\nServer端需要实现接口，并将接口暴露到网络。\n\n```java\n    public static void main(String[] args) {\n        try {\n            String name = \"Compute\";\n            Compute engine = new ComputeEngine();\n            Compute stub =\n                    (Compute) UnicastRemoteObject.exportObject(engine, 0); // anonymous port\n            Registry registry = LocateRegistry.createRegistry(1099);\n            registry.rebind(name, stub);\n            System.out.println(\"ComputeEngine bound\");\n        } catch (Exception e) {\n            System.err.println(\"ComputeEngine exception:\");\n            e.printStackTrace();\n        }\n    }\n```\n\nClient端要获取Server端注册接口的注册中心，并从注册中心获取到接口，然后调用。\n\n```java\n    public static void main(String args[]) {\n        try {\n            String name = \"Compute\";\n            Registry registry = LocateRegistry.getRegistry(\"127.0.0.1\", 1099);\n            Compute comp = (Compute) registry.lookup(name);\n            Pi task = new Pi();\n            BigDecimal pi = comp.executeTask(task);\n            System.out.println(pi);\n        } catch (Exception e) {\n            System.err.println(\"ComputePi exception:\");\n            e.printStackTrace();\n        }\n    }\n```\n\n其实，RMI只是Java对RPC的一种实现而已。只不过，很多RPC都是网络协议发送方法、参数等实现远程调用;RMI是通过客户端的Stub对象作为远程接口进行远程方法的调用。\n\n    注：Stub:为屏蔽客户调用远程主机上的对象，必须提供某种方式来模拟本地对象,这种本地对象称为存根(stub),存根负责接收本地方法调用,并将它们委派给各自的具体实现对象。\n\nstub意思存根，在上面的程序中就是我们定义的接口--Compute，一开始我理解的不透彻是因为我一直以为这个接口是服务端设计的，客户端不应该有，而看到`Compute comp = (Compute) registry.lookup(name);`又很不解，客户端怎么知道的有Compute？所以这也是rmi这种rpc实现的不足之一。interface作为一种规定，需要服务端和客户端都了解到，二者再进行通信。客户端只需要知道这个规范（interface），真正的对象是客户端返回来的，也就是这个stub。当compute被调用时，在通过网络访问对应的方法，返回结果。\n\n<img src=\"rmi.png\">","slug":"kongzheng1993-Java-rmi","published":1,"updated":"2023-03-08T07:05:58.805Z","layout":"post","photos":[],"link":"","_id":"clg0k2aks004ut26f8h7jl3tj","content":"<p>今天是周日，昨天是挺忙碌的一天，上午去了一趟姥姥家，一年多没去了，最然都在北京，却还是不能经常见面。和舅舅聊了聊最近的生活和工作，他一直鼓励我努力。下午去找潇哥玩了，也是很久不见了，半年是有了。去他家坐了坐，有了女朋友的潇哥确实是精致了一些，晚上吃了顿露天烧烤，聊了聊这半年怎么被社会毒打的。。</p>\n<p>今天坐在电脑前，不知道干点啥，b站首页停了半天不知道刷个什么视频。突然想起来之前面试又被问到java的RMI，今天来总结一下。</p>\n<p>RMI是Java官方的一个RPC协议，像dubbo也支持RMI。</p>\n<p>官方文档<a href=\"https://docs.oracle.com/javase/tutorial/rmi/index.html\" target=\"_blank\" rel=\"noopener\">Java RMI</a>。</p>\n<ul>\n<li>Registry 注册中心，负责注册服务。</li>\n<li>Server 提供服务，实现接口。</li>\n<li>Client 调用方，调用服务。</li>\n</ul>\n<p>官方文档中demo工程可以看。</p>\n<p>Server端需要实现接口，并将接口暴露到网络。</p>\n<pre><code class=\"java\">    public static void main(String[] args) {\n        try {\n            String name = &quot;Compute&quot;;\n            Compute engine = new ComputeEngine();\n            Compute stub =\n                    (Compute) UnicastRemoteObject.exportObject(engine, 0); // anonymous port\n            Registry registry = LocateRegistry.createRegistry(1099);\n            registry.rebind(name, stub);\n            System.out.println(&quot;ComputeEngine bound&quot;);\n        } catch (Exception e) {\n            System.err.println(&quot;ComputeEngine exception:&quot;);\n            e.printStackTrace();\n        }\n    }</code></pre>\n<p>Client端要获取Server端注册接口的注册中心，并从注册中心获取到接口，然后调用。</p>\n<pre><code class=\"java\">    public static void main(String args[]) {\n        try {\n            String name = &quot;Compute&quot;;\n            Registry registry = LocateRegistry.getRegistry(&quot;127.0.0.1&quot;, 1099);\n            Compute comp = (Compute) registry.lookup(name);\n            Pi task = new Pi();\n            BigDecimal pi = comp.executeTask(task);\n            System.out.println(pi);\n        } catch (Exception e) {\n            System.err.println(&quot;ComputePi exception:&quot;);\n            e.printStackTrace();\n        }\n    }</code></pre>\n<p>其实，RMI只是Java对RPC的一种实现而已。只不过，很多RPC都是网络协议发送方法、参数等实现远程调用;RMI是通过客户端的Stub对象作为远程接口进行远程方法的调用。</p>\n<pre><code>注：Stub:为屏蔽客户调用远程主机上的对象，必须提供某种方式来模拟本地对象,这种本地对象称为存根(stub),存根负责接收本地方法调用,并将它们委派给各自的具体实现对象。</code></pre><p>stub意思存根，在上面的程序中就是我们定义的接口–Compute，一开始我理解的不透彻是因为我一直以为这个接口是服务端设计的，客户端不应该有，而看到<code>Compute comp = (Compute) registry.lookup(name);</code>又很不解，客户端怎么知道的有Compute？所以这也是rmi这种rpc实现的不足之一。interface作为一种规定，需要服务端和客户端都了解到，二者再进行通信。客户端只需要知道这个规范（interface），真正的对象是客户端返回来的，也就是这个stub。当compute被调用时，在通过网络访问对应的方法，返回结果。</p>\n<img src=\"/2020/07/05/kongzheng1993-Java-rmi/rmi.png\">","site":{"data":{}},"more":"<p>今天是周日，昨天是挺忙碌的一天，上午去了一趟姥姥家，一年多没去了，最然都在北京，却还是不能经常见面。和舅舅聊了聊最近的生活和工作，他一直鼓励我努力。下午去找潇哥玩了，也是很久不见了，半年是有了。去他家坐了坐，有了女朋友的潇哥确实是精致了一些，晚上吃了顿露天烧烤，聊了聊这半年怎么被社会毒打的。。</p>\n<p>今天坐在电脑前，不知道干点啥，b站首页停了半天不知道刷个什么视频。突然想起来之前面试又被问到java的RMI，今天来总结一下。</p>\n<p>RMI是Java官方的一个RPC协议，像dubbo也支持RMI。</p>\n<p>官方文档<a href=\"https://docs.oracle.com/javase/tutorial/rmi/index.html\" target=\"_blank\" rel=\"noopener\">Java RMI</a>。</p>\n<ul>\n<li>Registry 注册中心，负责注册服务。</li>\n<li>Server 提供服务，实现接口。</li>\n<li>Client 调用方，调用服务。</li>\n</ul>\n<p>官方文档中demo工程可以看。</p>\n<p>Server端需要实现接口，并将接口暴露到网络。</p>\n<pre><code class=\"java\">    public static void main(String[] args) {\n        try {\n            String name = &quot;Compute&quot;;\n            Compute engine = new ComputeEngine();\n            Compute stub =\n                    (Compute) UnicastRemoteObject.exportObject(engine, 0); // anonymous port\n            Registry registry = LocateRegistry.createRegistry(1099);\n            registry.rebind(name, stub);\n            System.out.println(&quot;ComputeEngine bound&quot;);\n        } catch (Exception e) {\n            System.err.println(&quot;ComputeEngine exception:&quot;);\n            e.printStackTrace();\n        }\n    }</code></pre>\n<p>Client端要获取Server端注册接口的注册中心，并从注册中心获取到接口，然后调用。</p>\n<pre><code class=\"java\">    public static void main(String args[]) {\n        try {\n            String name = &quot;Compute&quot;;\n            Registry registry = LocateRegistry.getRegistry(&quot;127.0.0.1&quot;, 1099);\n            Compute comp = (Compute) registry.lookup(name);\n            Pi task = new Pi();\n            BigDecimal pi = comp.executeTask(task);\n            System.out.println(pi);\n        } catch (Exception e) {\n            System.err.println(&quot;ComputePi exception:&quot;);\n            e.printStackTrace();\n        }\n    }</code></pre>\n<p>其实，RMI只是Java对RPC的一种实现而已。只不过，很多RPC都是网络协议发送方法、参数等实现远程调用;RMI是通过客户端的Stub对象作为远程接口进行远程方法的调用。</p>\n<pre><code>注：Stub:为屏蔽客户调用远程主机上的对象，必须提供某种方式来模拟本地对象,这种本地对象称为存根(stub),存根负责接收本地方法调用,并将它们委派给各自的具体实现对象。</code></pre><p>stub意思存根，在上面的程序中就是我们定义的接口–Compute，一开始我理解的不透彻是因为我一直以为这个接口是服务端设计的，客户端不应该有，而看到<code>Compute comp = (Compute) registry.lookup(name);</code>又很不解，客户端怎么知道的有Compute？所以这也是rmi这种rpc实现的不足之一。interface作为一种规定，需要服务端和客户端都了解到，二者再进行通信。客户端只需要知道这个规范（interface），真正的对象是客户端返回来的，也就是这个stub。当compute被调用时，在通过网络访问对应的方法，返回结果。</p>\n<img src=\"/2020/07/05/kongzheng1993-Java-rmi/rmi.png\">"},{"title":"将博客搬至CSDN","excerpt":"","comments":1,"date":"2020-07-07T16:30:52.000Z","_content":"\n\n为了可以和更多的人交流学习，将博客搬至CSDN。","source":"_posts/2020-07-05-kongzheng1993-move-to-csdn.md","raw":"---\ntitle: 将博客搬至CSDN\nexcerpt: ''\ntags: [blog]\ncategories: [blog]\ncomments: true\ndate: 2020-07-08 00:30:52\n---\n\n\n为了可以和更多的人交流学习，将博客搬至CSDN。","slug":"kongzheng1993-move-to-csdn","published":1,"updated":"2023-03-08T07:05:58.805Z","layout":"post","photos":[],"link":"","_id":"clg0k2akw004wt26f62rqecp9","content":"<p>为了可以和更多的人交流学习，将博客搬至CSDN。</p>\n","site":{"data":{}},"more":"<p>为了可以和更多的人交流学习，将博客搬至CSDN。</p>\n"},{"title":"由一次github README.md引发的思考","excerpt":"","comments":1,"date":"2020-07-10T16:30:52.000Z","_content":"\n\n今天继续整理springcloud，到nacos那块了，然后写完文档，发现目录不好使？？？记得之前看很多大佬的github，README里有的目录点击也没反应。感觉也不能github的bug啊。。。\n\n## 用vscode打开试试？\n\n之前经常用vscode写blog，就是因为vscode自带markdown的预览，而且也有很多好用的markdown插件。打开试了一下，没问题，能正常跳转。。\n\n## 观察github点击目录标题后的变化\n\n比如我springcloud学习仓库。\n\n点击前浏览器地址栏为：`https://github.com/kongzheng1993/SpringCloudLearn`\n\n点击后：`https://github.com/kongzheng1993/SpringCloudLearn#Nacos注册中心&配置中心`\n\n感觉好像对啊。。\n\n反复看几遍！标题上有个 **&** ！！！\n\n再联系我们熟知的http url参数。。\n\n**&** 是分割参数的！！！\n\n删掉目录和标题中的 **&**\n\n没问题了，正常跳转！\n\n```text\n    + [spring-cloud-stream](#spring-cloud-stream)\n      - [springcloud-stream流程](#springcloud-stream流程)\n      - [使用方法](#使用方法)\n      - [集群重复消费问题](#-集群重复消费问题)\n      - [SpringCloud-stream消息持久化](#springcloud-stream消息持久化)\n    + [springcloud-Sleuth分布式请求链路跟踪](#springcloud-Sleuth分布式请求链路跟踪)\n    + [springcloud-alibaba](#springcloud-alibaba)\n      - [Nacos注册中心配置中心](#Nacos注册中心配置中心)\n```\n\n## 总结\n\n就是因为 **&** 符导致的！浏览器会以为你这里是参数分割。。\n\n别让我再看到有大佬的README.md有这个问题，有我就提PR [doge]\n\n","source":"_posts/2020-07-11-kongzheng1993-think-in-md-catalog.md","raw":"---\ntitle: 由一次github README.md引发的思考\nexcerpt: ''\ntags: [other]\ncategories: [other]\ncomments: true\ndate: 2020-07-11 00:30:52\n---\n\n\n今天继续整理springcloud，到nacos那块了，然后写完文档，发现目录不好使？？？记得之前看很多大佬的github，README里有的目录点击也没反应。感觉也不能github的bug啊。。。\n\n## 用vscode打开试试？\n\n之前经常用vscode写blog，就是因为vscode自带markdown的预览，而且也有很多好用的markdown插件。打开试了一下，没问题，能正常跳转。。\n\n## 观察github点击目录标题后的变化\n\n比如我springcloud学习仓库。\n\n点击前浏览器地址栏为：`https://github.com/kongzheng1993/SpringCloudLearn`\n\n点击后：`https://github.com/kongzheng1993/SpringCloudLearn#Nacos注册中心&配置中心`\n\n感觉好像对啊。。\n\n反复看几遍！标题上有个 **&** ！！！\n\n再联系我们熟知的http url参数。。\n\n**&** 是分割参数的！！！\n\n删掉目录和标题中的 **&**\n\n没问题了，正常跳转！\n\n```text\n    + [spring-cloud-stream](#spring-cloud-stream)\n      - [springcloud-stream流程](#springcloud-stream流程)\n      - [使用方法](#使用方法)\n      - [集群重复消费问题](#-集群重复消费问题)\n      - [SpringCloud-stream消息持久化](#springcloud-stream消息持久化)\n    + [springcloud-Sleuth分布式请求链路跟踪](#springcloud-Sleuth分布式请求链路跟踪)\n    + [springcloud-alibaba](#springcloud-alibaba)\n      - [Nacos注册中心配置中心](#Nacos注册中心配置中心)\n```\n\n## 总结\n\n就是因为 **&** 符导致的！浏览器会以为你这里是参数分割。。\n\n别让我再看到有大佬的README.md有这个问题，有我就提PR [doge]\n\n","slug":"kongzheng1993-think-in-md-catalog","published":1,"updated":"2023-03-08T07:05:58.806Z","layout":"post","photos":[],"link":"","_id":"clg0k2akx0050t26fv740cypa","content":"<p>今天继续整理springcloud，到nacos那块了，然后写完文档，发现目录不好使？？？记得之前看很多大佬的github，README里有的目录点击也没反应。感觉也不能github的bug啊。。。</p>\n<h2 id=\"用vscode打开试试？\"><a href=\"#用vscode打开试试？\" class=\"headerlink\" title=\"用vscode打开试试？\"></a>用vscode打开试试？</h2><p>之前经常用vscode写blog，就是因为vscode自带markdown的预览，而且也有很多好用的markdown插件。打开试了一下，没问题，能正常跳转。。</p>\n<h2 id=\"观察github点击目录标题后的变化\"><a href=\"#观察github点击目录标题后的变化\" class=\"headerlink\" title=\"观察github点击目录标题后的变化\"></a>观察github点击目录标题后的变化</h2><p>比如我springcloud学习仓库。</p>\n<p>点击前浏览器地址栏为：<code>https://github.com/kongzheng1993/SpringCloudLearn</code></p>\n<p>点击后：<code>https://github.com/kongzheng1993/SpringCloudLearn#Nacos注册中心&amp;配置中心</code></p>\n<p>感觉好像对啊。。</p>\n<p>反复看几遍！标题上有个 <strong>&amp;</strong> ！！！</p>\n<p>再联系我们熟知的http url参数。。</p>\n<p><strong>&amp;</strong> 是分割参数的！！！</p>\n<p>删掉目录和标题中的 <strong>&amp;</strong></p>\n<p>没问题了，正常跳转！</p>\n<pre><code class=\"text\">    + [spring-cloud-stream](#spring-cloud-stream)\n      - [springcloud-stream流程](#springcloud-stream流程)\n      - [使用方法](#使用方法)\n      - [集群重复消费问题](#-集群重复消费问题)\n      - [SpringCloud-stream消息持久化](#springcloud-stream消息持久化)\n    + [springcloud-Sleuth分布式请求链路跟踪](#springcloud-Sleuth分布式请求链路跟踪)\n    + [springcloud-alibaba](#springcloud-alibaba)\n      - [Nacos注册中心配置中心](#Nacos注册中心配置中心)</code></pre>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>就是因为 <strong>&amp;</strong> 符导致的！浏览器会以为你这里是参数分割。。</p>\n<p>别让我再看到有大佬的README.md有这个问题，有我就提PR [doge]</p>\n","site":{"data":{}},"more":"<p>今天继续整理springcloud，到nacos那块了，然后写完文档，发现目录不好使？？？记得之前看很多大佬的github，README里有的目录点击也没反应。感觉也不能github的bug啊。。。</p>\n<h2 id=\"用vscode打开试试？\"><a href=\"#用vscode打开试试？\" class=\"headerlink\" title=\"用vscode打开试试？\"></a>用vscode打开试试？</h2><p>之前经常用vscode写blog，就是因为vscode自带markdown的预览，而且也有很多好用的markdown插件。打开试了一下，没问题，能正常跳转。。</p>\n<h2 id=\"观察github点击目录标题后的变化\"><a href=\"#观察github点击目录标题后的变化\" class=\"headerlink\" title=\"观察github点击目录标题后的变化\"></a>观察github点击目录标题后的变化</h2><p>比如我springcloud学习仓库。</p>\n<p>点击前浏览器地址栏为：<code>https://github.com/kongzheng1993/SpringCloudLearn</code></p>\n<p>点击后：<code>https://github.com/kongzheng1993/SpringCloudLearn#Nacos注册中心&amp;配置中心</code></p>\n<p>感觉好像对啊。。</p>\n<p>反复看几遍！标题上有个 <strong>&amp;</strong> ！！！</p>\n<p>再联系我们熟知的http url参数。。</p>\n<p><strong>&amp;</strong> 是分割参数的！！！</p>\n<p>删掉目录和标题中的 <strong>&amp;</strong></p>\n<p>没问题了，正常跳转！</p>\n<pre><code class=\"text\">    + [spring-cloud-stream](#spring-cloud-stream)\n      - [springcloud-stream流程](#springcloud-stream流程)\n      - [使用方法](#使用方法)\n      - [集群重复消费问题](#-集群重复消费问题)\n      - [SpringCloud-stream消息持久化](#springcloud-stream消息持久化)\n    + [springcloud-Sleuth分布式请求链路跟踪](#springcloud-Sleuth分布式请求链路跟踪)\n    + [springcloud-alibaba](#springcloud-alibaba)\n      - [Nacos注册中心配置中心](#Nacos注册中心配置中心)</code></pre>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>就是因为 <strong>&amp;</strong> 符导致的！浏览器会以为你这里是参数分割。。</p>\n<p>别让我再看到有大佬的README.md有这个问题，有我就提PR [doge]</p>\n"},{"title":"Java调用外部程序","excerpt":"","comments":1,"date":"2020-08-03T16:30:52.000Z","_content":"\n最近在用ffmpeg做音频文件的转换，开发环境是win，本地使用没有毛病，直接`Runtime.getRuntime().exec(\"ffmpeg.exe ...\")`就可以了。但是今天到了测试阶段，应用部署到服务器上，直接就炸了。应用刚起来，调接口，正常，再调就不行了，等一会，又正常，然后又不行，再等一会，又可以了。。。反正就是很玄幻。。\n\n听同事说，起一个线程单独去调用ffmpeg是没问题的，但是我转念一想，我这个业务逻辑，就是需要接口是同步的，客户端要等待ffmpeg完成处理才行。。而且就算一次调用阻塞了，另一个请求过来，也是一个新的线程啊，怎么之前的线程会影响现在这个线程？\n\n怀疑是调起一个新进程导致本java线程阻塞，但是每次调用不都是一个新等线程么？？？\n\n直到看到csdn一篇[文章](https://blog.csdn.net/liuhailiuhai12/article/details/80320026)。\n\n文章说：Runtime对象调用exec方法后，JVM会启动一个子进程，该进程会与JVM进程建立三个管道连接，分别是标准输入、标准输出、标准错误。\n\n如果程序不断想标准输出和标准错误两个流写入数据，而JVM却没有读取的话，当缓冲区满了，就无法继续写入，导致外部进程阻塞，进而使我们的程序阻塞在`process.waitFor()`。\n\n文章作者也做了实验，在程序中，手动读出输出流里的数据，就能是缓冲区不会写满，进而不会导致我们上面说的问题。而且ffmpeg有一个参数`-loglevel quiet`可以禁止外部程序向JVM写入数据。\n\n所以我就在我执行的ffmpeg命令中加了这个参数，之前的问题就没有了，每次调用接口都能正常返回。。。\n\n可是我还是不清楚，我的程序里调用了`process.waitFor()`，第一个请求过来了，成功返回了，说明没有阻塞住，为什么第二个请求会不行呢？\n\n\n","source":"_posts/2020-07-26-kongzheng1993-java调用外部程序.md","raw":"---\ntitle: Java调用外部程序\nexcerpt: ''\ntags: [Java]\ncategories: [Java]\ncomments: true\ndate: 2020-08-04 00:30:52\n---\n\n最近在用ffmpeg做音频文件的转换，开发环境是win，本地使用没有毛病，直接`Runtime.getRuntime().exec(\"ffmpeg.exe ...\")`就可以了。但是今天到了测试阶段，应用部署到服务器上，直接就炸了。应用刚起来，调接口，正常，再调就不行了，等一会，又正常，然后又不行，再等一会，又可以了。。。反正就是很玄幻。。\n\n听同事说，起一个线程单独去调用ffmpeg是没问题的，但是我转念一想，我这个业务逻辑，就是需要接口是同步的，客户端要等待ffmpeg完成处理才行。。而且就算一次调用阻塞了，另一个请求过来，也是一个新的线程啊，怎么之前的线程会影响现在这个线程？\n\n怀疑是调起一个新进程导致本java线程阻塞，但是每次调用不都是一个新等线程么？？？\n\n直到看到csdn一篇[文章](https://blog.csdn.net/liuhailiuhai12/article/details/80320026)。\n\n文章说：Runtime对象调用exec方法后，JVM会启动一个子进程，该进程会与JVM进程建立三个管道连接，分别是标准输入、标准输出、标准错误。\n\n如果程序不断想标准输出和标准错误两个流写入数据，而JVM却没有读取的话，当缓冲区满了，就无法继续写入，导致外部进程阻塞，进而使我们的程序阻塞在`process.waitFor()`。\n\n文章作者也做了实验，在程序中，手动读出输出流里的数据，就能是缓冲区不会写满，进而不会导致我们上面说的问题。而且ffmpeg有一个参数`-loglevel quiet`可以禁止外部程序向JVM写入数据。\n\n所以我就在我执行的ffmpeg命令中加了这个参数，之前的问题就没有了，每次调用接口都能正常返回。。。\n\n可是我还是不清楚，我的程序里调用了`process.waitFor()`，第一个请求过来了，成功返回了，说明没有阻塞住，为什么第二个请求会不行呢？\n\n\n","slug":"kongzheng1993-java调用外部程序","published":1,"updated":"2023-03-08T07:05:58.807Z","layout":"post","photos":[],"link":"","_id":"clg0k2akx0052t26f9yztkweh","content":"<p>最近在用ffmpeg做音频文件的转换，开发环境是win，本地使用没有毛病，直接<code>Runtime.getRuntime().exec(&quot;ffmpeg.exe ...&quot;)</code>就可以了。但是今天到了测试阶段，应用部署到服务器上，直接就炸了。应用刚起来，调接口，正常，再调就不行了，等一会，又正常，然后又不行，再等一会，又可以了。。。反正就是很玄幻。。</p>\n<p>听同事说，起一个线程单独去调用ffmpeg是没问题的，但是我转念一想，我这个业务逻辑，就是需要接口是同步的，客户端要等待ffmpeg完成处理才行。。而且就算一次调用阻塞了，另一个请求过来，也是一个新的线程啊，怎么之前的线程会影响现在这个线程？</p>\n<p>怀疑是调起一个新进程导致本java线程阻塞，但是每次调用不都是一个新等线程么？？？</p>\n<p>直到看到csdn一篇<a href=\"https://blog.csdn.net/liuhailiuhai12/article/details/80320026\" target=\"_blank\" rel=\"noopener\">文章</a>。</p>\n<p>文章说：Runtime对象调用exec方法后，JVM会启动一个子进程，该进程会与JVM进程建立三个管道连接，分别是标准输入、标准输出、标准错误。</p>\n<p>如果程序不断想标准输出和标准错误两个流写入数据，而JVM却没有读取的话，当缓冲区满了，就无法继续写入，导致外部进程阻塞，进而使我们的程序阻塞在<code>process.waitFor()</code>。</p>\n<p>文章作者也做了实验，在程序中，手动读出输出流里的数据，就能是缓冲区不会写满，进而不会导致我们上面说的问题。而且ffmpeg有一个参数<code>-loglevel quiet</code>可以禁止外部程序向JVM写入数据。</p>\n<p>所以我就在我执行的ffmpeg命令中加了这个参数，之前的问题就没有了，每次调用接口都能正常返回。。。</p>\n<p>可是我还是不清楚，我的程序里调用了<code>process.waitFor()</code>，第一个请求过来了，成功返回了，说明没有阻塞住，为什么第二个请求会不行呢？</p>\n","site":{"data":{}},"more":"<p>最近在用ffmpeg做音频文件的转换，开发环境是win，本地使用没有毛病，直接<code>Runtime.getRuntime().exec(&quot;ffmpeg.exe ...&quot;)</code>就可以了。但是今天到了测试阶段，应用部署到服务器上，直接就炸了。应用刚起来，调接口，正常，再调就不行了，等一会，又正常，然后又不行，再等一会，又可以了。。。反正就是很玄幻。。</p>\n<p>听同事说，起一个线程单独去调用ffmpeg是没问题的，但是我转念一想，我这个业务逻辑，就是需要接口是同步的，客户端要等待ffmpeg完成处理才行。。而且就算一次调用阻塞了，另一个请求过来，也是一个新的线程啊，怎么之前的线程会影响现在这个线程？</p>\n<p>怀疑是调起一个新进程导致本java线程阻塞，但是每次调用不都是一个新等线程么？？？</p>\n<p>直到看到csdn一篇<a href=\"https://blog.csdn.net/liuhailiuhai12/article/details/80320026\" target=\"_blank\" rel=\"noopener\">文章</a>。</p>\n<p>文章说：Runtime对象调用exec方法后，JVM会启动一个子进程，该进程会与JVM进程建立三个管道连接，分别是标准输入、标准输出、标准错误。</p>\n<p>如果程序不断想标准输出和标准错误两个流写入数据，而JVM却没有读取的话，当缓冲区满了，就无法继续写入，导致外部进程阻塞，进而使我们的程序阻塞在<code>process.waitFor()</code>。</p>\n<p>文章作者也做了实验，在程序中，手动读出输出流里的数据，就能是缓冲区不会写满，进而不会导致我们上面说的问题。而且ffmpeg有一个参数<code>-loglevel quiet</code>可以禁止外部程序向JVM写入数据。</p>\n<p>所以我就在我执行的ffmpeg命令中加了这个参数，之前的问题就没有了，每次调用接口都能正常返回。。。</p>\n<p>可是我还是不清楚，我的程序里调用了<code>process.waitFor()</code>，第一个请求过来了，成功返回了，说明没有阻塞住，为什么第二个请求会不行呢？</p>\n"},{"title":"原生js实现双击复制后的思考","excerpt":"","comments":1,"date":"2020-10-20T16:30:52.000Z","_content":"\n\n昨天做了一个需求 --- 把一个系统所有页面的一个重要编号（a），增加双击复制的功能。\n\n查了一下资料，问了一个做前端的前同事，得到的结果都是： \n\n```js\n    $$.dblClick = function (value) {\n        const oInput = document.createElement('textarea')\n        oInput.value = value\n        oInput.select()\n        if (document.execCommand('copy')) {\n            Vue.prototype.$message({message: value + ' 已复制', type: 'success'})\n        }\n        oInput.remove()\n    }\n```\n\n然后就这么实现了，而且效果也可以。\n\n然后后面需求变动，因为有一个页面的表单里，这个编码（a）是个button，点击会弹出详情，所以要在这个button后面加一个复制的icon，点击的时候复制这个编码到剪贴板。\n\n前面的复制到剪贴板的代码，我抽取出来成为了公共方法，一共需要修改19个页面，共同使用。\n\n下面是增加到icon到代码：\n\n```html\n<el-tooltip class=\"item\" effect=\"dark\" content=\"点击复制\" placement=\"right\">\n    <i class=\"el-icon-document\" style=\"color: dodgerblue\" @click=\"$$UF.dblClick(scope.row.a)\"></i>\n</el-tooltip>\n```\n\n这里到icon在点击到时候，和其他页面调用同一个方法，传入a，并且也能正常传入a。\n\n但是诡异的事情发生了，点击icon并不能正常复制。前面所有的双击选中复制的都能正常复制。\n\n后面debug发现，`document.execCommand('copy')`返回`true`时，复制成功，返回`false`时，不支持或者当前场景不允许使用。而点击icon时，就会返回`false`。\n\n<img src=\"WechatIMG26.jpeg\">\n\n上图就可以看到，断点打在`if`，还没有执行execCommand，此时可以看到我debug之前添加的watch，exec方法返回的是`true`，但是执行了方法的前三行代码后，exec方法却要返回`false`了。\n\n网上查资料看到，`document.execCommand`方法，有人说是因为ajax异步，有回调函数，导致作用域变了，导致这里返回`false`。有人说，有一个userAction的变量，表示用户操作，如果当前动作是用户操作的，userAction为`true`，否则为`false`，而这个userAction会影响exec方法的执行，也就是因为操作剪贴板等操作，是安全级别比较高的操作，程序必须判断当前动作是否为用户的操作来保证安全。\n\n\n但是前面十几个双击复制，和这边的点解icon复制有什么不同呢，为什么结果不一样呢？\n\n我们仔细看下代码，这方法的意思很简单，就是new一个textarea，然后把我们要复制的内容赋值给这个textarea的value，然后选中这个textarea，然后执行copy命令。\n\n双击复制，和点击icon复制，都是把我们要保存的value传入这个方法，有什么不一样呢？？？\n\nmmp，js真是玄学。。\n\n经过几个同事的讨论，我认为比较靠谱的还是：\n\n当双击的时候，我们真的会选中我们双击的内容！！！而点击icon的时候，代码里select了，却不是人为的操作，导致程序认为这不是用户操作，导致userAction被置为`false`，进而导致exec方法返回`false`，复制失败。\n\n后面我把双击复制，修改为单击复制，exec也会返回`false`。\n\n而且，我修改为单击后，点击无法复制成功，双击却可以复制成功，应该就双击会选中的影响。\n\n大概可以证实上面的猜测。。\n\n希望有大佬能在评论区指点。。\n\n\n","source":"_posts/2020-10-21-kongzheng1993-原生js实现双击复制后的思考.md","raw":"---\ntitle: 原生js实现双击复制后的思考\nexcerpt: 'JavaScript'\ntags: [JavaScript]\ncategories: [JavaScript]\ncomments: true\ndate: 2020-10-21 00:30:52\n---\n\n\n昨天做了一个需求 --- 把一个系统所有页面的一个重要编号（a），增加双击复制的功能。\n\n查了一下资料，问了一个做前端的前同事，得到的结果都是： \n\n```js\n    $$.dblClick = function (value) {\n        const oInput = document.createElement('textarea')\n        oInput.value = value\n        oInput.select()\n        if (document.execCommand('copy')) {\n            Vue.prototype.$message({message: value + ' 已复制', type: 'success'})\n        }\n        oInput.remove()\n    }\n```\n\n然后就这么实现了，而且效果也可以。\n\n然后后面需求变动，因为有一个页面的表单里，这个编码（a）是个button，点击会弹出详情，所以要在这个button后面加一个复制的icon，点击的时候复制这个编码到剪贴板。\n\n前面的复制到剪贴板的代码，我抽取出来成为了公共方法，一共需要修改19个页面，共同使用。\n\n下面是增加到icon到代码：\n\n```html\n<el-tooltip class=\"item\" effect=\"dark\" content=\"点击复制\" placement=\"right\">\n    <i class=\"el-icon-document\" style=\"color: dodgerblue\" @click=\"$$UF.dblClick(scope.row.a)\"></i>\n</el-tooltip>\n```\n\n这里到icon在点击到时候，和其他页面调用同一个方法，传入a，并且也能正常传入a。\n\n但是诡异的事情发生了，点击icon并不能正常复制。前面所有的双击选中复制的都能正常复制。\n\n后面debug发现，`document.execCommand('copy')`返回`true`时，复制成功，返回`false`时，不支持或者当前场景不允许使用。而点击icon时，就会返回`false`。\n\n<img src=\"WechatIMG26.jpeg\">\n\n上图就可以看到，断点打在`if`，还没有执行execCommand，此时可以看到我debug之前添加的watch，exec方法返回的是`true`，但是执行了方法的前三行代码后，exec方法却要返回`false`了。\n\n网上查资料看到，`document.execCommand`方法，有人说是因为ajax异步，有回调函数，导致作用域变了，导致这里返回`false`。有人说，有一个userAction的变量，表示用户操作，如果当前动作是用户操作的，userAction为`true`，否则为`false`，而这个userAction会影响exec方法的执行，也就是因为操作剪贴板等操作，是安全级别比较高的操作，程序必须判断当前动作是否为用户的操作来保证安全。\n\n\n但是前面十几个双击复制，和这边的点解icon复制有什么不同呢，为什么结果不一样呢？\n\n我们仔细看下代码，这方法的意思很简单，就是new一个textarea，然后把我们要复制的内容赋值给这个textarea的value，然后选中这个textarea，然后执行copy命令。\n\n双击复制，和点击icon复制，都是把我们要保存的value传入这个方法，有什么不一样呢？？？\n\nmmp，js真是玄学。。\n\n经过几个同事的讨论，我认为比较靠谱的还是：\n\n当双击的时候，我们真的会选中我们双击的内容！！！而点击icon的时候，代码里select了，却不是人为的操作，导致程序认为这不是用户操作，导致userAction被置为`false`，进而导致exec方法返回`false`，复制失败。\n\n后面我把双击复制，修改为单击复制，exec也会返回`false`。\n\n而且，我修改为单击后，点击无法复制成功，双击却可以复制成功，应该就双击会选中的影响。\n\n大概可以证实上面的猜测。。\n\n希望有大佬能在评论区指点。。\n\n\n","slug":"kongzheng1993-原生js实现双击复制后的思考","published":1,"updated":"2023-03-08T07:05:58.807Z","layout":"post","photos":[],"link":"","_id":"clg0k2al10056t26fojh32hjb","content":"<p>昨天做了一个需求 — 把一个系统所有页面的一个重要编号（a），增加双击复制的功能。</p>\n<p>查了一下资料，问了一个做前端的前同事，得到的结果都是： </p>\n<pre><code class=\"js\">    $$.dblClick = function (value) {\n        const oInput = document.createElement(&#39;textarea&#39;)\n        oInput.value = value\n        oInput.select()\n        if (document.execCommand(&#39;copy&#39;)) {\n            Vue.prototype.$message({message: value + &#39; 已复制&#39;, type: &#39;success&#39;})\n        }\n        oInput.remove()\n    }</code></pre>\n<p>然后就这么实现了，而且效果也可以。</p>\n<p>然后后面需求变动，因为有一个页面的表单里，这个编码（a）是个button，点击会弹出详情，所以要在这个button后面加一个复制的icon，点击的时候复制这个编码到剪贴板。</p>\n<p>前面的复制到剪贴板的代码，我抽取出来成为了公共方法，一共需要修改19个页面，共同使用。</p>\n<p>下面是增加到icon到代码：</p>\n<pre><code class=\"html\">&lt;el-tooltip class=&quot;item&quot; effect=&quot;dark&quot; content=&quot;点击复制&quot; placement=&quot;right&quot;&gt;\n    &lt;i class=&quot;el-icon-document&quot; style=&quot;color: dodgerblue&quot; @click=&quot;$$UF.dblClick(scope.row.a)&quot;&gt;&lt;/i&gt;\n&lt;/el-tooltip&gt;</code></pre>\n<p>这里到icon在点击到时候，和其他页面调用同一个方法，传入a，并且也能正常传入a。</p>\n<p>但是诡异的事情发生了，点击icon并不能正常复制。前面所有的双击选中复制的都能正常复制。</p>\n<p>后面debug发现，<code>document.execCommand(&#39;copy&#39;)</code>返回<code>true</code>时，复制成功，返回<code>false</code>时，不支持或者当前场景不允许使用。而点击icon时，就会返回<code>false</code>。</p>\n<img src=\"/2020/10/21/kongzheng1993-原生js实现双击复制后的思考/WechatIMG26.jpeg\">\n\n<p>上图就可以看到，断点打在<code>if</code>，还没有执行execCommand，此时可以看到我debug之前添加的watch，exec方法返回的是<code>true</code>，但是执行了方法的前三行代码后，exec方法却要返回<code>false</code>了。</p>\n<p>网上查资料看到，<code>document.execCommand</code>方法，有人说是因为ajax异步，有回调函数，导致作用域变了，导致这里返回<code>false</code>。有人说，有一个userAction的变量，表示用户操作，如果当前动作是用户操作的，userAction为<code>true</code>，否则为<code>false</code>，而这个userAction会影响exec方法的执行，也就是因为操作剪贴板等操作，是安全级别比较高的操作，程序必须判断当前动作是否为用户的操作来保证安全。</p>\n<p>但是前面十几个双击复制，和这边的点解icon复制有什么不同呢，为什么结果不一样呢？</p>\n<p>我们仔细看下代码，这方法的意思很简单，就是new一个textarea，然后把我们要复制的内容赋值给这个textarea的value，然后选中这个textarea，然后执行copy命令。</p>\n<p>双击复制，和点击icon复制，都是把我们要保存的value传入这个方法，有什么不一样呢？？？</p>\n<p>mmp，js真是玄学。。</p>\n<p>经过几个同事的讨论，我认为比较靠谱的还是：</p>\n<p>当双击的时候，我们真的会选中我们双击的内容！！！而点击icon的时候，代码里select了，却不是人为的操作，导致程序认为这不是用户操作，导致userAction被置为<code>false</code>，进而导致exec方法返回<code>false</code>，复制失败。</p>\n<p>后面我把双击复制，修改为单击复制，exec也会返回<code>false</code>。</p>\n<p>而且，我修改为单击后，点击无法复制成功，双击却可以复制成功，应该就双击会选中的影响。</p>\n<p>大概可以证实上面的猜测。。</p>\n<p>希望有大佬能在评论区指点。。</p>\n","site":{"data":{}},"more":"<p>昨天做了一个需求 — 把一个系统所有页面的一个重要编号（a），增加双击复制的功能。</p>\n<p>查了一下资料，问了一个做前端的前同事，得到的结果都是： </p>\n<pre><code class=\"js\">    $$.dblClick = function (value) {\n        const oInput = document.createElement(&#39;textarea&#39;)\n        oInput.value = value\n        oInput.select()\n        if (document.execCommand(&#39;copy&#39;)) {\n            Vue.prototype.$message({message: value + &#39; 已复制&#39;, type: &#39;success&#39;})\n        }\n        oInput.remove()\n    }</code></pre>\n<p>然后就这么实现了，而且效果也可以。</p>\n<p>然后后面需求变动，因为有一个页面的表单里，这个编码（a）是个button，点击会弹出详情，所以要在这个button后面加一个复制的icon，点击的时候复制这个编码到剪贴板。</p>\n<p>前面的复制到剪贴板的代码，我抽取出来成为了公共方法，一共需要修改19个页面，共同使用。</p>\n<p>下面是增加到icon到代码：</p>\n<pre><code class=\"html\">&lt;el-tooltip class=&quot;item&quot; effect=&quot;dark&quot; content=&quot;点击复制&quot; placement=&quot;right&quot;&gt;\n    &lt;i class=&quot;el-icon-document&quot; style=&quot;color: dodgerblue&quot; @click=&quot;$$UF.dblClick(scope.row.a)&quot;&gt;&lt;/i&gt;\n&lt;/el-tooltip&gt;</code></pre>\n<p>这里到icon在点击到时候，和其他页面调用同一个方法，传入a，并且也能正常传入a。</p>\n<p>但是诡异的事情发生了，点击icon并不能正常复制。前面所有的双击选中复制的都能正常复制。</p>\n<p>后面debug发现，<code>document.execCommand(&#39;copy&#39;)</code>返回<code>true</code>时，复制成功，返回<code>false</code>时，不支持或者当前场景不允许使用。而点击icon时，就会返回<code>false</code>。</p>\n<img src=\"/2020/10/21/kongzheng1993-原生js实现双击复制后的思考/WechatIMG26.jpeg\">\n\n<p>上图就可以看到，断点打在<code>if</code>，还没有执行execCommand，此时可以看到我debug之前添加的watch，exec方法返回的是<code>true</code>，但是执行了方法的前三行代码后，exec方法却要返回<code>false</code>了。</p>\n<p>网上查资料看到，<code>document.execCommand</code>方法，有人说是因为ajax异步，有回调函数，导致作用域变了，导致这里返回<code>false</code>。有人说，有一个userAction的变量，表示用户操作，如果当前动作是用户操作的，userAction为<code>true</code>，否则为<code>false</code>，而这个userAction会影响exec方法的执行，也就是因为操作剪贴板等操作，是安全级别比较高的操作，程序必须判断当前动作是否为用户的操作来保证安全。</p>\n<p>但是前面十几个双击复制，和这边的点解icon复制有什么不同呢，为什么结果不一样呢？</p>\n<p>我们仔细看下代码，这方法的意思很简单，就是new一个textarea，然后把我们要复制的内容赋值给这个textarea的value，然后选中这个textarea，然后执行copy命令。</p>\n<p>双击复制，和点击icon复制，都是把我们要保存的value传入这个方法，有什么不一样呢？？？</p>\n<p>mmp，js真是玄学。。</p>\n<p>经过几个同事的讨论，我认为比较靠谱的还是：</p>\n<p>当双击的时候，我们真的会选中我们双击的内容！！！而点击icon的时候，代码里select了，却不是人为的操作，导致程序认为这不是用户操作，导致userAction被置为<code>false</code>，进而导致exec方法返回<code>false</code>，复制失败。</p>\n<p>后面我把双击复制，修改为单击复制，exec也会返回<code>false</code>。</p>\n<p>而且，我修改为单击后，点击无法复制成功，双击却可以复制成功，应该就双击会选中的影响。</p>\n<p>大概可以证实上面的猜测。。</p>\n<p>希望有大佬能在评论区指点。。</p>\n"},{"title":"Apollo分布式配置中心","excerpt":"","comments":1,"date":"2020-07-25T16:30:52.000Z","_content":"\n看到新公司技术架构中有apollo配置中心，之前就有听说过，但是没真正在项目中使用，所以今天就来总结下。\n\n## Apollo是什么\n\nApollo（阿波罗）是携程框架部门研发的分布式配置中心，能够集中化管理应用不同环境、不同集群的配置，配置修改后能够实时推送到应用端，并且具备规范的权限、流程治理等特性，适用于微服务配置管理场景。\n\n服务端基于Spring Boot和Spring Cloud开发，打包后可以直接运行，不需要额外安装Tomcat等应用容器。\n\nJava客户端不依赖任何框架，能够运行于所有Java运行时环境，同时对Spring/Spring Boot环境也有较好的支持。\n\n.Net客户端不依赖任何框架，能够运行于所有.Net运行时环境。\n\n### 特性\n\n- 统一管理不同环境、不同集群的配置\n  - Apollo提供了一个统一界面集中式管理不同环境（environment）、不同集群（cluster）、不同命名空间（namespace）的配置。\n  - 同一份代码部署在不同的集群，可以有不同的配置，比如zookeeper的地址等\n  - 通过命名空间（namespace）可以很方便地支持多个不同应用共享同一份配置，同时还允许应用对共享的配置进行覆盖\n- 配置修改实时生效（热发布）\n  - 用户在Apollo修改完配置并发布后，客户端能实时（1秒）接收到最新的配置，并通知到应用程序\n- 版本发布管理\n  - 所有的配置发布都有版本概念，从而可以方便地支持配置的回滚\n- 灰度发布\n  - 支持配置的灰度发布，比如点了发布后，只对部分应用实例生效，等观察一段时间没问题后再推给所有应用实例\n- 权限管理、发布审核、操作审计\n  - 应用和配置的管理都有完善的权限管理机制，对配置的管理还分为了编辑和发布两个环节，从而减少人为的错误。\n  - 所有的操作都有审计日志，可以方便地追踪问题\n- 客户端配置信息监控\n  - 可以在界面上方便地看到配置在被哪些实例使用\n- 提供Java和.Net原生客户端\n  - 提供了Java和.Net的原生客户端，方便应用集成\n  - 支持Spring Placeholder, Annotation和Spring Boot的ConfigurationProperties，方便应用使用（需要Spring 3.1.1+）\n  - 同时提供了Http接口，非Java和.Net应用也可以方便地使用\n- 提供开放平台API\n  - Apollo自身提供了比较完善的统一配置管理界面，支持多环境、多数据中心配置管理、权限、流程治理等特性。不过Apollo出于通用性考虑，不会对配置的修改做过多限制，只要符合基本的格式就能保存，不会针对不同的配置值进行针对性的校验，如数据库用户名、密码，Redis服务地址等\n  - 对于这类应用配置，Apollo支持应用方通过开放平台API在Apollo进行配置的修改和发布，并且具备完善的授权和权限控制\n- 部署简单\n  - 配置中心作为基础服务，可用性要求非常高，这就要求Apollo对外部依赖尽可能地少\n  - 目前唯一的外部依赖是MySQL，所以部署非常简单，只要安装好Java和MySQL就可以让Apollo跑起来\n  - Apollo还提供了打包脚本，一键就可以生成所有需要的安装包，并且支持自定义运行时参数\n\n### 运行时流程\n\n<img src=\"apollo-flow.png\">\n\n### 总体设计图\n\n<img src=\"overall-architecture.png\">\n\n\n- Config Service提供配置的读取、推送等功能，服务对象是Apollo客户端\n- Admin Service提供配置的修改、发布等功能，服务对象是Apollo Portal（管理界面）\n- Config Service和Admin Service都是多实例、无状态部署，所以需要将自己注册到Eureka中并保持心跳\n- 在Eureka之上架了一层Meta Server用于封装Eureka的服务发现接口\n- Client通过域名访问Meta Server获取Config Service服务列表（IP+Port），而后直接通过IP+Port访问服务，同时在Client侧会做load balance、错误重试\n- Portal通过域名访问Meta Server获取Admin Service服务列表（IP+Port），而后直接通过IP+Port访问服务，同时在Portal侧会做load balance、错误重试\n- 为了简化部署，实际上会把Config Service、Eureka和Meta Server三个逻辑角色部署在同一个JVM进程中\n\n\n\n\n\n### 客户端设计\n\n<img src=\"client-architecture.png\">\n\n上图简要描述了Apollo客户端的实现原理：\n\n- 客户端和服务端保持了一个长连接，从而能第一时间获得配置更新的推送。\n- 客户端还会定时从Apollo配置中心服务端拉取应用的最新配置。\n  - 这是一个fallback机制，为了防止推送机制失效导致配置不更新\n  - 客户端定时拉取会上报本地版本，所以一般情况下，对于定时拉取的操作，服务端都会返回304 - Not Modified\n  - 定时频率默认为每5分钟拉取一次，客户端也可以通过在运行时指定System Property: apollo.refreshInterval来覆盖，单位为分钟。\n- 客户端从Apollo配置中心服务端获取到应用的最新配置后，会保存在内存中\n- 客户端会把从服务端获取到的配置在本地文件系统缓存一份\n- 在遇到服务不可用，或网络不通的时候，依然能从本地恢复配置\n- 应用程序从Apollo客户端获取最新的配置、订阅配置更新通知\n\n\n#### 配置更新推送实现\n前面提到了Apollo客户端和服务端保持了一个长连接，从而能第一时间获得配置更新的推送。\n\n长连接实际上是通过Http Long Polling实现的，具体而言：\n\n- 客户端发起一个Http请求到服务端\n- 服务端会保持住这个连接60秒\n  - 如果在60秒内有客户端关心的配置变化，被保持住的客户端请求会立即返回，并告知客户端有配置变化的namespace信息，客户端会据此拉取对应namespace的最新配置\n  - 如果在60秒内没有客户端关心的配置变化，那么会返回Http状态码304给客户端\n- 客户端在收到服务端请求后会立即重新发起连接，回到第一步\n\n考虑到会有数万客户端向服务端发起长连，在服务端使用了`async servlet(Spring DeferredResult)`来服务Http Long Polling请求。\n\n","source":"_posts/2020-07-26-kongzheng1993-apollo.md","raw":"---\ntitle: Apollo分布式配置中心\nexcerpt: ''\ntags: [分布式]\ncategories: [分布式]\ncomments: true\ndate: 2020-07-26 00:30:52\n---\n\n看到新公司技术架构中有apollo配置中心，之前就有听说过，但是没真正在项目中使用，所以今天就来总结下。\n\n## Apollo是什么\n\nApollo（阿波罗）是携程框架部门研发的分布式配置中心，能够集中化管理应用不同环境、不同集群的配置，配置修改后能够实时推送到应用端，并且具备规范的权限、流程治理等特性，适用于微服务配置管理场景。\n\n服务端基于Spring Boot和Spring Cloud开发，打包后可以直接运行，不需要额外安装Tomcat等应用容器。\n\nJava客户端不依赖任何框架，能够运行于所有Java运行时环境，同时对Spring/Spring Boot环境也有较好的支持。\n\n.Net客户端不依赖任何框架，能够运行于所有.Net运行时环境。\n\n### 特性\n\n- 统一管理不同环境、不同集群的配置\n  - Apollo提供了一个统一界面集中式管理不同环境（environment）、不同集群（cluster）、不同命名空间（namespace）的配置。\n  - 同一份代码部署在不同的集群，可以有不同的配置，比如zookeeper的地址等\n  - 通过命名空间（namespace）可以很方便地支持多个不同应用共享同一份配置，同时还允许应用对共享的配置进行覆盖\n- 配置修改实时生效（热发布）\n  - 用户在Apollo修改完配置并发布后，客户端能实时（1秒）接收到最新的配置，并通知到应用程序\n- 版本发布管理\n  - 所有的配置发布都有版本概念，从而可以方便地支持配置的回滚\n- 灰度发布\n  - 支持配置的灰度发布，比如点了发布后，只对部分应用实例生效，等观察一段时间没问题后再推给所有应用实例\n- 权限管理、发布审核、操作审计\n  - 应用和配置的管理都有完善的权限管理机制，对配置的管理还分为了编辑和发布两个环节，从而减少人为的错误。\n  - 所有的操作都有审计日志，可以方便地追踪问题\n- 客户端配置信息监控\n  - 可以在界面上方便地看到配置在被哪些实例使用\n- 提供Java和.Net原生客户端\n  - 提供了Java和.Net的原生客户端，方便应用集成\n  - 支持Spring Placeholder, Annotation和Spring Boot的ConfigurationProperties，方便应用使用（需要Spring 3.1.1+）\n  - 同时提供了Http接口，非Java和.Net应用也可以方便地使用\n- 提供开放平台API\n  - Apollo自身提供了比较完善的统一配置管理界面，支持多环境、多数据中心配置管理、权限、流程治理等特性。不过Apollo出于通用性考虑，不会对配置的修改做过多限制，只要符合基本的格式就能保存，不会针对不同的配置值进行针对性的校验，如数据库用户名、密码，Redis服务地址等\n  - 对于这类应用配置，Apollo支持应用方通过开放平台API在Apollo进行配置的修改和发布，并且具备完善的授权和权限控制\n- 部署简单\n  - 配置中心作为基础服务，可用性要求非常高，这就要求Apollo对外部依赖尽可能地少\n  - 目前唯一的外部依赖是MySQL，所以部署非常简单，只要安装好Java和MySQL就可以让Apollo跑起来\n  - Apollo还提供了打包脚本，一键就可以生成所有需要的安装包，并且支持自定义运行时参数\n\n### 运行时流程\n\n<img src=\"apollo-flow.png\">\n\n### 总体设计图\n\n<img src=\"overall-architecture.png\">\n\n\n- Config Service提供配置的读取、推送等功能，服务对象是Apollo客户端\n- Admin Service提供配置的修改、发布等功能，服务对象是Apollo Portal（管理界面）\n- Config Service和Admin Service都是多实例、无状态部署，所以需要将自己注册到Eureka中并保持心跳\n- 在Eureka之上架了一层Meta Server用于封装Eureka的服务发现接口\n- Client通过域名访问Meta Server获取Config Service服务列表（IP+Port），而后直接通过IP+Port访问服务，同时在Client侧会做load balance、错误重试\n- Portal通过域名访问Meta Server获取Admin Service服务列表（IP+Port），而后直接通过IP+Port访问服务，同时在Portal侧会做load balance、错误重试\n- 为了简化部署，实际上会把Config Service、Eureka和Meta Server三个逻辑角色部署在同一个JVM进程中\n\n\n\n\n\n### 客户端设计\n\n<img src=\"client-architecture.png\">\n\n上图简要描述了Apollo客户端的实现原理：\n\n- 客户端和服务端保持了一个长连接，从而能第一时间获得配置更新的推送。\n- 客户端还会定时从Apollo配置中心服务端拉取应用的最新配置。\n  - 这是一个fallback机制，为了防止推送机制失效导致配置不更新\n  - 客户端定时拉取会上报本地版本，所以一般情况下，对于定时拉取的操作，服务端都会返回304 - Not Modified\n  - 定时频率默认为每5分钟拉取一次，客户端也可以通过在运行时指定System Property: apollo.refreshInterval来覆盖，单位为分钟。\n- 客户端从Apollo配置中心服务端获取到应用的最新配置后，会保存在内存中\n- 客户端会把从服务端获取到的配置在本地文件系统缓存一份\n- 在遇到服务不可用，或网络不通的时候，依然能从本地恢复配置\n- 应用程序从Apollo客户端获取最新的配置、订阅配置更新通知\n\n\n#### 配置更新推送实现\n前面提到了Apollo客户端和服务端保持了一个长连接，从而能第一时间获得配置更新的推送。\n\n长连接实际上是通过Http Long Polling实现的，具体而言：\n\n- 客户端发起一个Http请求到服务端\n- 服务端会保持住这个连接60秒\n  - 如果在60秒内有客户端关心的配置变化，被保持住的客户端请求会立即返回，并告知客户端有配置变化的namespace信息，客户端会据此拉取对应namespace的最新配置\n  - 如果在60秒内没有客户端关心的配置变化，那么会返回Http状态码304给客户端\n- 客户端在收到服务端请求后会立即重新发起连接，回到第一步\n\n考虑到会有数万客户端向服务端发起长连，在服务端使用了`async servlet(Spring DeferredResult)`来服务Http Long Polling请求。\n\n","slug":"kongzheng1993-apollo","published":1,"updated":"2023-03-08T07:05:58.806Z","layout":"post","photos":[],"link":"","_id":"clg0k2al40059t26fqif1l6ng","content":"<p>看到新公司技术架构中有apollo配置中心，之前就有听说过，但是没真正在项目中使用，所以今天就来总结下。</p>\n<h2 id=\"Apollo是什么\"><a href=\"#Apollo是什么\" class=\"headerlink\" title=\"Apollo是什么\"></a>Apollo是什么</h2><p>Apollo（阿波罗）是携程框架部门研发的分布式配置中心，能够集中化管理应用不同环境、不同集群的配置，配置修改后能够实时推送到应用端，并且具备规范的权限、流程治理等特性，适用于微服务配置管理场景。</p>\n<p>服务端基于Spring Boot和Spring Cloud开发，打包后可以直接运行，不需要额外安装Tomcat等应用容器。</p>\n<p>Java客户端不依赖任何框架，能够运行于所有Java运行时环境，同时对Spring/Spring Boot环境也有较好的支持。</p>\n<p>.Net客户端不依赖任何框架，能够运行于所有.Net运行时环境。</p>\n<h3 id=\"特性\"><a href=\"#特性\" class=\"headerlink\" title=\"特性\"></a>特性</h3><ul>\n<li>统一管理不同环境、不同集群的配置<ul>\n<li>Apollo提供了一个统一界面集中式管理不同环境（environment）、不同集群（cluster）、不同命名空间（namespace）的配置。</li>\n<li>同一份代码部署在不同的集群，可以有不同的配置，比如zookeeper的地址等</li>\n<li>通过命名空间（namespace）可以很方便地支持多个不同应用共享同一份配置，同时还允许应用对共享的配置进行覆盖</li>\n</ul>\n</li>\n<li>配置修改实时生效（热发布）<ul>\n<li>用户在Apollo修改完配置并发布后，客户端能实时（1秒）接收到最新的配置，并通知到应用程序</li>\n</ul>\n</li>\n<li>版本发布管理<ul>\n<li>所有的配置发布都有版本概念，从而可以方便地支持配置的回滚</li>\n</ul>\n</li>\n<li>灰度发布<ul>\n<li>支持配置的灰度发布，比如点了发布后，只对部分应用实例生效，等观察一段时间没问题后再推给所有应用实例</li>\n</ul>\n</li>\n<li>权限管理、发布审核、操作审计<ul>\n<li>应用和配置的管理都有完善的权限管理机制，对配置的管理还分为了编辑和发布两个环节，从而减少人为的错误。</li>\n<li>所有的操作都有审计日志，可以方便地追踪问题</li>\n</ul>\n</li>\n<li>客户端配置信息监控<ul>\n<li>可以在界面上方便地看到配置在被哪些实例使用</li>\n</ul>\n</li>\n<li>提供Java和.Net原生客户端<ul>\n<li>提供了Java和.Net的原生客户端，方便应用集成</li>\n<li>支持Spring Placeholder, Annotation和Spring Boot的ConfigurationProperties，方便应用使用（需要Spring 3.1.1+）</li>\n<li>同时提供了Http接口，非Java和.Net应用也可以方便地使用</li>\n</ul>\n</li>\n<li>提供开放平台API<ul>\n<li>Apollo自身提供了比较完善的统一配置管理界面，支持多环境、多数据中心配置管理、权限、流程治理等特性。不过Apollo出于通用性考虑，不会对配置的修改做过多限制，只要符合基本的格式就能保存，不会针对不同的配置值进行针对性的校验，如数据库用户名、密码，Redis服务地址等</li>\n<li>对于这类应用配置，Apollo支持应用方通过开放平台API在Apollo进行配置的修改和发布，并且具备完善的授权和权限控制</li>\n</ul>\n</li>\n<li>部署简单<ul>\n<li>配置中心作为基础服务，可用性要求非常高，这就要求Apollo对外部依赖尽可能地少</li>\n<li>目前唯一的外部依赖是MySQL，所以部署非常简单，只要安装好Java和MySQL就可以让Apollo跑起来</li>\n<li>Apollo还提供了打包脚本，一键就可以生成所有需要的安装包，并且支持自定义运行时参数</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"运行时流程\"><a href=\"#运行时流程\" class=\"headerlink\" title=\"运行时流程\"></a>运行时流程</h3><img src=\"/2020/07/26/kongzheng1993-apollo/apollo-flow.png\">\n\n<h3 id=\"总体设计图\"><a href=\"#总体设计图\" class=\"headerlink\" title=\"总体设计图\"></a>总体设计图</h3><img src=\"/2020/07/26/kongzheng1993-apollo/overall-architecture.png\">\n\n\n<ul>\n<li>Config Service提供配置的读取、推送等功能，服务对象是Apollo客户端</li>\n<li>Admin Service提供配置的修改、发布等功能，服务对象是Apollo Portal（管理界面）</li>\n<li>Config Service和Admin Service都是多实例、无状态部署，所以需要将自己注册到Eureka中并保持心跳</li>\n<li>在Eureka之上架了一层Meta Server用于封装Eureka的服务发现接口</li>\n<li>Client通过域名访问Meta Server获取Config Service服务列表（IP+Port），而后直接通过IP+Port访问服务，同时在Client侧会做load balance、错误重试</li>\n<li>Portal通过域名访问Meta Server获取Admin Service服务列表（IP+Port），而后直接通过IP+Port访问服务，同时在Portal侧会做load balance、错误重试</li>\n<li>为了简化部署，实际上会把Config Service、Eureka和Meta Server三个逻辑角色部署在同一个JVM进程中</li>\n</ul>\n<h3 id=\"客户端设计\"><a href=\"#客户端设计\" class=\"headerlink\" title=\"客户端设计\"></a>客户端设计</h3><img src=\"/2020/07/26/kongzheng1993-apollo/client-architecture.png\">\n\n<p>上图简要描述了Apollo客户端的实现原理：</p>\n<ul>\n<li>客户端和服务端保持了一个长连接，从而能第一时间获得配置更新的推送。</li>\n<li>客户端还会定时从Apollo配置中心服务端拉取应用的最新配置。<ul>\n<li>这是一个fallback机制，为了防止推送机制失效导致配置不更新</li>\n<li>客户端定时拉取会上报本地版本，所以一般情况下，对于定时拉取的操作，服务端都会返回304 - Not Modified</li>\n<li>定时频率默认为每5分钟拉取一次，客户端也可以通过在运行时指定System Property: apollo.refreshInterval来覆盖，单位为分钟。</li>\n</ul>\n</li>\n<li>客户端从Apollo配置中心服务端获取到应用的最新配置后，会保存在内存中</li>\n<li>客户端会把从服务端获取到的配置在本地文件系统缓存一份</li>\n<li>在遇到服务不可用，或网络不通的时候，依然能从本地恢复配置</li>\n<li>应用程序从Apollo客户端获取最新的配置、订阅配置更新通知</li>\n</ul>\n<h4 id=\"配置更新推送实现\"><a href=\"#配置更新推送实现\" class=\"headerlink\" title=\"配置更新推送实现\"></a>配置更新推送实现</h4><p>前面提到了Apollo客户端和服务端保持了一个长连接，从而能第一时间获得配置更新的推送。</p>\n<p>长连接实际上是通过Http Long Polling实现的，具体而言：</p>\n<ul>\n<li>客户端发起一个Http请求到服务端</li>\n<li>服务端会保持住这个连接60秒<ul>\n<li>如果在60秒内有客户端关心的配置变化，被保持住的客户端请求会立即返回，并告知客户端有配置变化的namespace信息，客户端会据此拉取对应namespace的最新配置</li>\n<li>如果在60秒内没有客户端关心的配置变化，那么会返回Http状态码304给客户端</li>\n</ul>\n</li>\n<li>客户端在收到服务端请求后会立即重新发起连接，回到第一步</li>\n</ul>\n<p>考虑到会有数万客户端向服务端发起长连，在服务端使用了<code>async servlet(Spring DeferredResult)</code>来服务Http Long Polling请求。</p>\n","site":{"data":{}},"more":"<p>看到新公司技术架构中有apollo配置中心，之前就有听说过，但是没真正在项目中使用，所以今天就来总结下。</p>\n<h2 id=\"Apollo是什么\"><a href=\"#Apollo是什么\" class=\"headerlink\" title=\"Apollo是什么\"></a>Apollo是什么</h2><p>Apollo（阿波罗）是携程框架部门研发的分布式配置中心，能够集中化管理应用不同环境、不同集群的配置，配置修改后能够实时推送到应用端，并且具备规范的权限、流程治理等特性，适用于微服务配置管理场景。</p>\n<p>服务端基于Spring Boot和Spring Cloud开发，打包后可以直接运行，不需要额外安装Tomcat等应用容器。</p>\n<p>Java客户端不依赖任何框架，能够运行于所有Java运行时环境，同时对Spring/Spring Boot环境也有较好的支持。</p>\n<p>.Net客户端不依赖任何框架，能够运行于所有.Net运行时环境。</p>\n<h3 id=\"特性\"><a href=\"#特性\" class=\"headerlink\" title=\"特性\"></a>特性</h3><ul>\n<li>统一管理不同环境、不同集群的配置<ul>\n<li>Apollo提供了一个统一界面集中式管理不同环境（environment）、不同集群（cluster）、不同命名空间（namespace）的配置。</li>\n<li>同一份代码部署在不同的集群，可以有不同的配置，比如zookeeper的地址等</li>\n<li>通过命名空间（namespace）可以很方便地支持多个不同应用共享同一份配置，同时还允许应用对共享的配置进行覆盖</li>\n</ul>\n</li>\n<li>配置修改实时生效（热发布）<ul>\n<li>用户在Apollo修改完配置并发布后，客户端能实时（1秒）接收到最新的配置，并通知到应用程序</li>\n</ul>\n</li>\n<li>版本发布管理<ul>\n<li>所有的配置发布都有版本概念，从而可以方便地支持配置的回滚</li>\n</ul>\n</li>\n<li>灰度发布<ul>\n<li>支持配置的灰度发布，比如点了发布后，只对部分应用实例生效，等观察一段时间没问题后再推给所有应用实例</li>\n</ul>\n</li>\n<li>权限管理、发布审核、操作审计<ul>\n<li>应用和配置的管理都有完善的权限管理机制，对配置的管理还分为了编辑和发布两个环节，从而减少人为的错误。</li>\n<li>所有的操作都有审计日志，可以方便地追踪问题</li>\n</ul>\n</li>\n<li>客户端配置信息监控<ul>\n<li>可以在界面上方便地看到配置在被哪些实例使用</li>\n</ul>\n</li>\n<li>提供Java和.Net原生客户端<ul>\n<li>提供了Java和.Net的原生客户端，方便应用集成</li>\n<li>支持Spring Placeholder, Annotation和Spring Boot的ConfigurationProperties，方便应用使用（需要Spring 3.1.1+）</li>\n<li>同时提供了Http接口，非Java和.Net应用也可以方便地使用</li>\n</ul>\n</li>\n<li>提供开放平台API<ul>\n<li>Apollo自身提供了比较完善的统一配置管理界面，支持多环境、多数据中心配置管理、权限、流程治理等特性。不过Apollo出于通用性考虑，不会对配置的修改做过多限制，只要符合基本的格式就能保存，不会针对不同的配置值进行针对性的校验，如数据库用户名、密码，Redis服务地址等</li>\n<li>对于这类应用配置，Apollo支持应用方通过开放平台API在Apollo进行配置的修改和发布，并且具备完善的授权和权限控制</li>\n</ul>\n</li>\n<li>部署简单<ul>\n<li>配置中心作为基础服务，可用性要求非常高，这就要求Apollo对外部依赖尽可能地少</li>\n<li>目前唯一的外部依赖是MySQL，所以部署非常简单，只要安装好Java和MySQL就可以让Apollo跑起来</li>\n<li>Apollo还提供了打包脚本，一键就可以生成所有需要的安装包，并且支持自定义运行时参数</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"运行时流程\"><a href=\"#运行时流程\" class=\"headerlink\" title=\"运行时流程\"></a>运行时流程</h3><img src=\"/2020/07/26/kongzheng1993-apollo/apollo-flow.png\">\n\n<h3 id=\"总体设计图\"><a href=\"#总体设计图\" class=\"headerlink\" title=\"总体设计图\"></a>总体设计图</h3><img src=\"/2020/07/26/kongzheng1993-apollo/overall-architecture.png\">\n\n\n<ul>\n<li>Config Service提供配置的读取、推送等功能，服务对象是Apollo客户端</li>\n<li>Admin Service提供配置的修改、发布等功能，服务对象是Apollo Portal（管理界面）</li>\n<li>Config Service和Admin Service都是多实例、无状态部署，所以需要将自己注册到Eureka中并保持心跳</li>\n<li>在Eureka之上架了一层Meta Server用于封装Eureka的服务发现接口</li>\n<li>Client通过域名访问Meta Server获取Config Service服务列表（IP+Port），而后直接通过IP+Port访问服务，同时在Client侧会做load balance、错误重试</li>\n<li>Portal通过域名访问Meta Server获取Admin Service服务列表（IP+Port），而后直接通过IP+Port访问服务，同时在Portal侧会做load balance、错误重试</li>\n<li>为了简化部署，实际上会把Config Service、Eureka和Meta Server三个逻辑角色部署在同一个JVM进程中</li>\n</ul>\n<h3 id=\"客户端设计\"><a href=\"#客户端设计\" class=\"headerlink\" title=\"客户端设计\"></a>客户端设计</h3><img src=\"/2020/07/26/kongzheng1993-apollo/client-architecture.png\">\n\n<p>上图简要描述了Apollo客户端的实现原理：</p>\n<ul>\n<li>客户端和服务端保持了一个长连接，从而能第一时间获得配置更新的推送。</li>\n<li>客户端还会定时从Apollo配置中心服务端拉取应用的最新配置。<ul>\n<li>这是一个fallback机制，为了防止推送机制失效导致配置不更新</li>\n<li>客户端定时拉取会上报本地版本，所以一般情况下，对于定时拉取的操作，服务端都会返回304 - Not Modified</li>\n<li>定时频率默认为每5分钟拉取一次，客户端也可以通过在运行时指定System Property: apollo.refreshInterval来覆盖，单位为分钟。</li>\n</ul>\n</li>\n<li>客户端从Apollo配置中心服务端获取到应用的最新配置后，会保存在内存中</li>\n<li>客户端会把从服务端获取到的配置在本地文件系统缓存一份</li>\n<li>在遇到服务不可用，或网络不通的时候，依然能从本地恢复配置</li>\n<li>应用程序从Apollo客户端获取最新的配置、订阅配置更新通知</li>\n</ul>\n<h4 id=\"配置更新推送实现\"><a href=\"#配置更新推送实现\" class=\"headerlink\" title=\"配置更新推送实现\"></a>配置更新推送实现</h4><p>前面提到了Apollo客户端和服务端保持了一个长连接，从而能第一时间获得配置更新的推送。</p>\n<p>长连接实际上是通过Http Long Polling实现的，具体而言：</p>\n<ul>\n<li>客户端发起一个Http请求到服务端</li>\n<li>服务端会保持住这个连接60秒<ul>\n<li>如果在60秒内有客户端关心的配置变化，被保持住的客户端请求会立即返回，并告知客户端有配置变化的namespace信息，客户端会据此拉取对应namespace的最新配置</li>\n<li>如果在60秒内没有客户端关心的配置变化，那么会返回Http状态码304给客户端</li>\n</ul>\n</li>\n<li>客户端在收到服务端请求后会立即重新发起连接，回到第一步</li>\n</ul>\n<p>考虑到会有数万客户端向服务端发起长连，在服务端使用了<code>async servlet(Spring DeferredResult)</code>来服务Http Long Polling请求。</p>\n"},{"title":"Vue.prototype","excerpt":"","comments":1,"date":"2020-10-18T16:30:52.000Z","_content":"\n\n今天要在页面上加入双击复制的功能，一共18个页面，都要加上这个功能，所以我想抽出来这个复制到剪贴板到方法，放到公共js里。\n\n```js\ndblClick: function (value) {\n    const oInput = document.createElement('textarea')\n    oInput.value = value\n    oInput.select()\n    document.execCommand('copy')\n    this.$message({message: '已复制', type: 'success'})\n}\n```\n\n但是当我抽取这个方法到公共js后，this会报错，因为这里到this已经不是之前页面到vue对象了，所以要修改成下面到样子：\n\n```js\n    $$.dblClick = function (value) {\n        const oInput = document.createElement('textarea')\n        oInput.value = value\n        oInput.select()\n        document.execCommand('copy')\n        Vue.prototype.$message({message: '已复制', type: 'success'})\n    }\n```\n\n使用Vue.prototype调用全局到`$message`方法。\n\n### Vue.prototype\n\n当我们要做一个很多组件都要用到到数据/工具，但是不想`污染全局作用域`。这时，可以通过在原型上定义它们，使它们在每个Vue的实例中可用。\n\n```js\nVue.prototype.$appName = 'My App'\n```\n\n这样并不是说增加了一个全局变量，而是给原型增加了一个属性，`给原型增加了属性，所有的vue实例都会拥有这个属性`。这里之所以变量名为`$appName`，是因为 `$` 是在 Vue 所有实例中都可用的 property 的一个简单约定。这样做会避免和已被定义的数据、方法、计算属性产生冲突。\n\n\n","source":"_posts/2020-10-19-kongzheng1993-Vue.prototype.md","raw":"---\ntitle: Vue.prototype\nexcerpt: 'vue'\ntags: [vue]\ncategories: [vue]\ncomments: true\ndate: 2020-10-19 00:30:52\n---\n\n\n今天要在页面上加入双击复制的功能，一共18个页面，都要加上这个功能，所以我想抽出来这个复制到剪贴板到方法，放到公共js里。\n\n```js\ndblClick: function (value) {\n    const oInput = document.createElement('textarea')\n    oInput.value = value\n    oInput.select()\n    document.execCommand('copy')\n    this.$message({message: '已复制', type: 'success'})\n}\n```\n\n但是当我抽取这个方法到公共js后，this会报错，因为这里到this已经不是之前页面到vue对象了，所以要修改成下面到样子：\n\n```js\n    $$.dblClick = function (value) {\n        const oInput = document.createElement('textarea')\n        oInput.value = value\n        oInput.select()\n        document.execCommand('copy')\n        Vue.prototype.$message({message: '已复制', type: 'success'})\n    }\n```\n\n使用Vue.prototype调用全局到`$message`方法。\n\n### Vue.prototype\n\n当我们要做一个很多组件都要用到到数据/工具，但是不想`污染全局作用域`。这时，可以通过在原型上定义它们，使它们在每个Vue的实例中可用。\n\n```js\nVue.prototype.$appName = 'My App'\n```\n\n这样并不是说增加了一个全局变量，而是给原型增加了一个属性，`给原型增加了属性，所有的vue实例都会拥有这个属性`。这里之所以变量名为`$appName`，是因为 `$` 是在 Vue 所有实例中都可用的 property 的一个简单约定。这样做会避免和已被定义的数据、方法、计算属性产生冲突。\n\n\n","slug":"kongzheng1993-Vue.prototype","published":1,"updated":"2023-03-08T07:05:58.807Z","layout":"post","photos":[],"link":"","_id":"clg0k2al5005et26fieo9h7sq","content":"<p>今天要在页面上加入双击复制的功能，一共18个页面，都要加上这个功能，所以我想抽出来这个复制到剪贴板到方法，放到公共js里。</p>\n<pre><code class=\"js\">dblClick: function (value) {\n    const oInput = document.createElement(&#39;textarea&#39;)\n    oInput.value = value\n    oInput.select()\n    document.execCommand(&#39;copy&#39;)\n    this.$message({message: &#39;已复制&#39;, type: &#39;success&#39;})\n}</code></pre>\n<p>但是当我抽取这个方法到公共js后，this会报错，因为这里到this已经不是之前页面到vue对象了，所以要修改成下面到样子：</p>\n<pre><code class=\"js\">    $$.dblClick = function (value) {\n        const oInput = document.createElement(&#39;textarea&#39;)\n        oInput.value = value\n        oInput.select()\n        document.execCommand(&#39;copy&#39;)\n        Vue.prototype.$message({message: &#39;已复制&#39;, type: &#39;success&#39;})\n    }</code></pre>\n<p>使用Vue.prototype调用全局到<code>$message</code>方法。</p>\n<h3 id=\"Vue-prototype\"><a href=\"#Vue-prototype\" class=\"headerlink\" title=\"Vue.prototype\"></a>Vue.prototype</h3><p>当我们要做一个很多组件都要用到到数据/工具，但是不想<code>污染全局作用域</code>。这时，可以通过在原型上定义它们，使它们在每个Vue的实例中可用。</p>\n<pre><code class=\"js\">Vue.prototype.$appName = &#39;My App&#39;</code></pre>\n<p>这样并不是说增加了一个全局变量，而是给原型增加了一个属性，<code>给原型增加了属性，所有的vue实例都会拥有这个属性</code>。这里之所以变量名为<code>$appName</code>，是因为 <code>$</code> 是在 Vue 所有实例中都可用的 property 的一个简单约定。这样做会避免和已被定义的数据、方法、计算属性产生冲突。</p>\n","site":{"data":{}},"more":"<p>今天要在页面上加入双击复制的功能，一共18个页面，都要加上这个功能，所以我想抽出来这个复制到剪贴板到方法，放到公共js里。</p>\n<pre><code class=\"js\">dblClick: function (value) {\n    const oInput = document.createElement(&#39;textarea&#39;)\n    oInput.value = value\n    oInput.select()\n    document.execCommand(&#39;copy&#39;)\n    this.$message({message: &#39;已复制&#39;, type: &#39;success&#39;})\n}</code></pre>\n<p>但是当我抽取这个方法到公共js后，this会报错，因为这里到this已经不是之前页面到vue对象了，所以要修改成下面到样子：</p>\n<pre><code class=\"js\">    $$.dblClick = function (value) {\n        const oInput = document.createElement(&#39;textarea&#39;)\n        oInput.value = value\n        oInput.select()\n        document.execCommand(&#39;copy&#39;)\n        Vue.prototype.$message({message: &#39;已复制&#39;, type: &#39;success&#39;})\n    }</code></pre>\n<p>使用Vue.prototype调用全局到<code>$message</code>方法。</p>\n<h3 id=\"Vue-prototype\"><a href=\"#Vue-prototype\" class=\"headerlink\" title=\"Vue.prototype\"></a>Vue.prototype</h3><p>当我们要做一个很多组件都要用到到数据/工具，但是不想<code>污染全局作用域</code>。这时，可以通过在原型上定义它们，使它们在每个Vue的实例中可用。</p>\n<pre><code class=\"js\">Vue.prototype.$appName = &#39;My App&#39;</code></pre>\n<p>这样并不是说增加了一个全局变量，而是给原型增加了一个属性，<code>给原型增加了属性，所有的vue实例都会拥有这个属性</code>。这里之所以变量名为<code>$appName</code>，是因为 <code>$</code> 是在 Vue 所有实例中都可用的 property 的一个简单约定。这样做会避免和已被定义的数据、方法、计算属性产生冲突。</p>\n"},{"title":"SpringBoot自定义starter","excerpt":"","comments":1,"date":"2020-10-22T16:30:52.000Z","_content":"\n## 什么是SpringBoot starter\n\nStarter可以理解为一个可拔插式的插件，提供一系列便利的依赖描述符，您可以获得所需的所有Spring和相关技术的一站式服务。应用程序只需要在maven中引入starter依赖，SpringBoot就能自动扫描到要加载的信息并启动相应的默认配置。用一句话描述，就是springboot的场景启动器。\n\n\n\n## 为什么starter可以热插拔\n\n一个Springboot应用都会有一个`@SpringBootApplication`注解。而`@SpringBootApplication`注解里其实包含三个注解:\n\n- @SpringBootConfiguration 与`@Configuration`作用相同，生命当前类是个配置类\n- @EnableAutoConfiguration `@EnableAutoConfiguration`是springboot实现自动化配置的核心注解，通过这个注解把spring应用所需的bean注入容器中。`@EnableAutoConfiguration`源码通过`@Import`注入了一个`ImportSelector`的实现类`AutoConfigurationImportSelector`,这个`ImportSelector`最终实现根据我们的配置，动态加载所需的bean.\n- @ComponentScan   扫描各种Component（service，controller，component，repository），默认扫描本类所在包和子包中都类，所以一般会把springboot启动类放在项目源码的根目录。\n\n\n\n```java\n@Target({ElementType.TYPE})\n@Retention(RetentionPolicy.RUNTIME)\n@Documented\n@Inherited\n@AutoConfigurationPackage\n@Import({EnableAutoConfigurationImportSelector.class})\npublic @interface EnableAutoConfiguration {\n    String ENABLED_OVERRIDE_PROPERTY = \"spring.boot.enableautoconfiguration\";\n\n    Class<?>[] exclude() default {};\n\n    String[] excludeName() default {};\n}\n```\n\n\n```java\n@Override\n//annotationMetadata 是＠import所用在的注解．这里指定是@EnableAutoConfiguration\npublic String[] selectImports(AnnotationMetadata annotationMetadata) {\n    if (!isEnabled(annotationMetadata)) {\n        return NO_IMPORTS;\n    }\n     //加载XXConfiguration的元数据信息（包含了某些类被生成bean条件），继续跟进这个方法调用，就会发现加载的是：spring-boot-autoconfigure　jar包里面META-INF的spring-autoconfigure-metadata.properties\n    AutoConfigurationMetadata autoConfigurationMetadata = AutoConfigurationMetadataLoader\n            .loadMetadata(this.beanClassLoader);\n　　    //获取注解里设置的属性，在＠SpringBootApplication设置的exclude,excludeＮame属性值，其实就是设置＠EnableAutoConfiguration的这两个属性值\n       AnnotationAttributes attributes = getAttributes(annotationMetadata);\n       //从spring-boot-autoconfigure　jar包里面META-INF/spring.factories加载配置类的名称，打开这个文件发现里面包含了springboot框架提供的所有配置类\n    List<String> configurations = getCandidateConfigurations(annotationMetadata,\n            attributes);\n     //去掉重复项\n    configurations = removeDuplicates(configurations);\n     //获取自己配置不需要生成bean的class\n    Set<String> exclusions = getExclusions(annotationMetadata, attributes);\n    //校验被exclude的类是否都是springboot自动化配置里的类，如果存在抛出异常\n    checkExcludedClasses(configurations, exclusions);\n   //删除被exclude掉的类\n    configurations.removeAll(exclusions);\n   //过滤刷选，满足OnClassCondition的类\n    configurations = filter(configurations, autoConfigurationMetadata);\n    fireAutoConfigurationImportEvents(configurations, exclusions);\n//返回需要注入的bean的类路径\n    return StringUtils.toStringArray(configurations);\n}\n```\n\n\nSpringBoot 在启动时会去依赖的 starter 包中寻找 /META-INF/spring.factories 文件，然后根据文件中配置的路径去扫描项目所依赖的 Jar 包，这类似于 Java 的 SPI 机制。\n\n\nJavaSPI 实际上是“基于接口的编程＋策略模式＋配置文件”组合实现的动态加载机制。\n\n\n## 步骤\n\n1. 新建工程\n\n一般starter的命名格式为：spring-boot-starter-hello\n\n2. 新建HelloProperties类，定义一个hello.msg参数（默认值World！）。\n\n```java\n@ConfigurationProperties(prefix = \"hello\")\npublic class HelloProperties {\n    /**\n     * 打招呼的内容，默认为“World!”\n     */\n    private String msg = \"World!\";\n \n    public String getMsg() {\n        return msg;\n    }\n \n    public void setMsg(String msg) {\n        this.msg = msg;\n    }\n}\n```\n\n3. 编写功能（HelloService）\n\n```java\n@Service\npublic class HelloService {\n    @Autowired\n    private HelloProperties helloProperties;\n \n    /**\n     * 打招呼方法\n     *\n     * @param name 人名，向谁打招呼使用\n     * @return\n     */\n    public String sayHello(String name) {\n        return \"Hello \" + name + \" \" + helloProperties.getMsg();\n    }\n```\n\n4. 编写自动配置类\n\n```java\n//定义为配置类\n@Configuration\n//在web工程条件下成立\n@ConditionalOnWebApplication\n//启用HelloProperties配置功能，并加入到IOC容器中\n@EnableConfigurationProperties({HelloProperties.class})\n//导入HelloService组件\n@Import(HelloService.class)\n//@ComponentScan\npublic class HelloAutoConfiguration {\n}\n```\n\n5. 在resources目录下新建META-INF目录，并在META-INF下新建spring.factories文件，写入：\n\n```properties\norg.springframework.boot.autoconfigure.EnableAutoConfiguration=\\\ncom.example.springbootstarterhello.HelloAutoConfiguration\n```\n\n6. 收尾工作\n\n    1. 删除自动生成的启动类SpringBootStarterHelloApplication。\n    2. 删除resources下的除META-INF目录之外的所有文件目录。\n    3. 删除spring-boot-starter-test依赖并且删除test目录。\n\n6. 到目前为止，spring-boot-starter-hello的自动配置功能已实现，并且正确使用了，但还有一点不够完美，如果你也按上面步骤实现了自己的spring-boot-starter-hello自动配置，在application.properties中配置hello.msg属性时，你会发现并没有提示你有关该配置的信息，但是如果你想配置tomcat端口时，输入server.port是有提示的。\n新建META-INF/spring-configuration-metadata.json文件，进行配置。\n\n```json\n{\n  \"hints\":[{\n    \"name\":\"hello.msg\",\n    \"values\":[{\n      \"value\":\"你好\",\n      \"description\":\"中文方式打招呼\"\n    },{\n      \"value\":\"Hi\",\n      \"description\":\"英文方式打招呼\"\n    }]\n  }],\n  \"groups\":[\n    {\n      \"sourceType\": \"com.seagetech.spring.boot.helloworld.HelloWorldProperties\",\n      \"name\": \"hello\",\n      \"type\": \"com.example.springbootstarterhello.HelloProperties\"\n    }],\n  \"properties\":[\n    {\n      \"sourceType\": \"com.example.springbootstarterhello.HelloProperties\",\n      \"name\": \"hello.msg\",\n      \"type\": \"java.lang.String\",\n      \"description\": \"打招呼的内容\",\n      \"defaultValue\": \"Worlds\"\n    }]\n}\n```\n\n\n7. 执行`mvn install`将spring-boot-starter-hello安装到本地\n\n\n至此，我们的starter就可以使用了。\n\n\n","source":"_posts/2020-10-23-kongzheng1993-SpringBoot自定义starter.md","raw":"---\ntitle: SpringBoot自定义starter\nexcerpt: 'SpringBoot'\ntags: [SpringBoot]\ncategories: [SpringBoot]\ncomments: true\ndate: 2020-10-23 00:30:52\n---\n\n## 什么是SpringBoot starter\n\nStarter可以理解为一个可拔插式的插件，提供一系列便利的依赖描述符，您可以获得所需的所有Spring和相关技术的一站式服务。应用程序只需要在maven中引入starter依赖，SpringBoot就能自动扫描到要加载的信息并启动相应的默认配置。用一句话描述，就是springboot的场景启动器。\n\n\n\n## 为什么starter可以热插拔\n\n一个Springboot应用都会有一个`@SpringBootApplication`注解。而`@SpringBootApplication`注解里其实包含三个注解:\n\n- @SpringBootConfiguration 与`@Configuration`作用相同，生命当前类是个配置类\n- @EnableAutoConfiguration `@EnableAutoConfiguration`是springboot实现自动化配置的核心注解，通过这个注解把spring应用所需的bean注入容器中。`@EnableAutoConfiguration`源码通过`@Import`注入了一个`ImportSelector`的实现类`AutoConfigurationImportSelector`,这个`ImportSelector`最终实现根据我们的配置，动态加载所需的bean.\n- @ComponentScan   扫描各种Component（service，controller，component，repository），默认扫描本类所在包和子包中都类，所以一般会把springboot启动类放在项目源码的根目录。\n\n\n\n```java\n@Target({ElementType.TYPE})\n@Retention(RetentionPolicy.RUNTIME)\n@Documented\n@Inherited\n@AutoConfigurationPackage\n@Import({EnableAutoConfigurationImportSelector.class})\npublic @interface EnableAutoConfiguration {\n    String ENABLED_OVERRIDE_PROPERTY = \"spring.boot.enableautoconfiguration\";\n\n    Class<?>[] exclude() default {};\n\n    String[] excludeName() default {};\n}\n```\n\n\n```java\n@Override\n//annotationMetadata 是＠import所用在的注解．这里指定是@EnableAutoConfiguration\npublic String[] selectImports(AnnotationMetadata annotationMetadata) {\n    if (!isEnabled(annotationMetadata)) {\n        return NO_IMPORTS;\n    }\n     //加载XXConfiguration的元数据信息（包含了某些类被生成bean条件），继续跟进这个方法调用，就会发现加载的是：spring-boot-autoconfigure　jar包里面META-INF的spring-autoconfigure-metadata.properties\n    AutoConfigurationMetadata autoConfigurationMetadata = AutoConfigurationMetadataLoader\n            .loadMetadata(this.beanClassLoader);\n　　    //获取注解里设置的属性，在＠SpringBootApplication设置的exclude,excludeＮame属性值，其实就是设置＠EnableAutoConfiguration的这两个属性值\n       AnnotationAttributes attributes = getAttributes(annotationMetadata);\n       //从spring-boot-autoconfigure　jar包里面META-INF/spring.factories加载配置类的名称，打开这个文件发现里面包含了springboot框架提供的所有配置类\n    List<String> configurations = getCandidateConfigurations(annotationMetadata,\n            attributes);\n     //去掉重复项\n    configurations = removeDuplicates(configurations);\n     //获取自己配置不需要生成bean的class\n    Set<String> exclusions = getExclusions(annotationMetadata, attributes);\n    //校验被exclude的类是否都是springboot自动化配置里的类，如果存在抛出异常\n    checkExcludedClasses(configurations, exclusions);\n   //删除被exclude掉的类\n    configurations.removeAll(exclusions);\n   //过滤刷选，满足OnClassCondition的类\n    configurations = filter(configurations, autoConfigurationMetadata);\n    fireAutoConfigurationImportEvents(configurations, exclusions);\n//返回需要注入的bean的类路径\n    return StringUtils.toStringArray(configurations);\n}\n```\n\n\nSpringBoot 在启动时会去依赖的 starter 包中寻找 /META-INF/spring.factories 文件，然后根据文件中配置的路径去扫描项目所依赖的 Jar 包，这类似于 Java 的 SPI 机制。\n\n\nJavaSPI 实际上是“基于接口的编程＋策略模式＋配置文件”组合实现的动态加载机制。\n\n\n## 步骤\n\n1. 新建工程\n\n一般starter的命名格式为：spring-boot-starter-hello\n\n2. 新建HelloProperties类，定义一个hello.msg参数（默认值World！）。\n\n```java\n@ConfigurationProperties(prefix = \"hello\")\npublic class HelloProperties {\n    /**\n     * 打招呼的内容，默认为“World!”\n     */\n    private String msg = \"World!\";\n \n    public String getMsg() {\n        return msg;\n    }\n \n    public void setMsg(String msg) {\n        this.msg = msg;\n    }\n}\n```\n\n3. 编写功能（HelloService）\n\n```java\n@Service\npublic class HelloService {\n    @Autowired\n    private HelloProperties helloProperties;\n \n    /**\n     * 打招呼方法\n     *\n     * @param name 人名，向谁打招呼使用\n     * @return\n     */\n    public String sayHello(String name) {\n        return \"Hello \" + name + \" \" + helloProperties.getMsg();\n    }\n```\n\n4. 编写自动配置类\n\n```java\n//定义为配置类\n@Configuration\n//在web工程条件下成立\n@ConditionalOnWebApplication\n//启用HelloProperties配置功能，并加入到IOC容器中\n@EnableConfigurationProperties({HelloProperties.class})\n//导入HelloService组件\n@Import(HelloService.class)\n//@ComponentScan\npublic class HelloAutoConfiguration {\n}\n```\n\n5. 在resources目录下新建META-INF目录，并在META-INF下新建spring.factories文件，写入：\n\n```properties\norg.springframework.boot.autoconfigure.EnableAutoConfiguration=\\\ncom.example.springbootstarterhello.HelloAutoConfiguration\n```\n\n6. 收尾工作\n\n    1. 删除自动生成的启动类SpringBootStarterHelloApplication。\n    2. 删除resources下的除META-INF目录之外的所有文件目录。\n    3. 删除spring-boot-starter-test依赖并且删除test目录。\n\n6. 到目前为止，spring-boot-starter-hello的自动配置功能已实现，并且正确使用了，但还有一点不够完美，如果你也按上面步骤实现了自己的spring-boot-starter-hello自动配置，在application.properties中配置hello.msg属性时，你会发现并没有提示你有关该配置的信息，但是如果你想配置tomcat端口时，输入server.port是有提示的。\n新建META-INF/spring-configuration-metadata.json文件，进行配置。\n\n```json\n{\n  \"hints\":[{\n    \"name\":\"hello.msg\",\n    \"values\":[{\n      \"value\":\"你好\",\n      \"description\":\"中文方式打招呼\"\n    },{\n      \"value\":\"Hi\",\n      \"description\":\"英文方式打招呼\"\n    }]\n  }],\n  \"groups\":[\n    {\n      \"sourceType\": \"com.seagetech.spring.boot.helloworld.HelloWorldProperties\",\n      \"name\": \"hello\",\n      \"type\": \"com.example.springbootstarterhello.HelloProperties\"\n    }],\n  \"properties\":[\n    {\n      \"sourceType\": \"com.example.springbootstarterhello.HelloProperties\",\n      \"name\": \"hello.msg\",\n      \"type\": \"java.lang.String\",\n      \"description\": \"打招呼的内容\",\n      \"defaultValue\": \"Worlds\"\n    }]\n}\n```\n\n\n7. 执行`mvn install`将spring-boot-starter-hello安装到本地\n\n\n至此，我们的starter就可以使用了。\n\n\n","slug":"kongzheng1993-SpringBoot自定义starter","published":1,"updated":"2023-03-08T07:05:58.808Z","layout":"post","photos":[],"link":"","_id":"clg0k2al7005gt26f20a807e6","content":"<h2 id=\"什么是SpringBoot-starter\"><a href=\"#什么是SpringBoot-starter\" class=\"headerlink\" title=\"什么是SpringBoot starter\"></a>什么是SpringBoot starter</h2><p>Starter可以理解为一个可拔插式的插件，提供一系列便利的依赖描述符，您可以获得所需的所有Spring和相关技术的一站式服务。应用程序只需要在maven中引入starter依赖，SpringBoot就能自动扫描到要加载的信息并启动相应的默认配置。用一句话描述，就是springboot的场景启动器。</p>\n<h2 id=\"为什么starter可以热插拔\"><a href=\"#为什么starter可以热插拔\" class=\"headerlink\" title=\"为什么starter可以热插拔\"></a>为什么starter可以热插拔</h2><p>一个Springboot应用都会有一个<code>@SpringBootApplication</code>注解。而<code>@SpringBootApplication</code>注解里其实包含三个注解:</p>\n<ul>\n<li>@SpringBootConfiguration 与<code>@Configuration</code>作用相同，生命当前类是个配置类</li>\n<li>@EnableAutoConfiguration <code>@EnableAutoConfiguration</code>是springboot实现自动化配置的核心注解，通过这个注解把spring应用所需的bean注入容器中。<code>@EnableAutoConfiguration</code>源码通过<code>@Import</code>注入了一个<code>ImportSelector</code>的实现类<code>AutoConfigurationImportSelector</code>,这个<code>ImportSelector</code>最终实现根据我们的配置，动态加载所需的bean.</li>\n<li>@ComponentScan   扫描各种Component（service，controller，component，repository），默认扫描本类所在包和子包中都类，所以一般会把springboot启动类放在项目源码的根目录。</li>\n</ul>\n<pre><code class=\"java\">@Target({ElementType.TYPE})\n@Retention(RetentionPolicy.RUNTIME)\n@Documented\n@Inherited\n@AutoConfigurationPackage\n@Import({EnableAutoConfigurationImportSelector.class})\npublic @interface EnableAutoConfiguration {\n    String ENABLED_OVERRIDE_PROPERTY = &quot;spring.boot.enableautoconfiguration&quot;;\n\n    Class&lt;?&gt;[] exclude() default {};\n\n    String[] excludeName() default {};\n}</code></pre>\n<pre><code class=\"java\">@Override\n//annotationMetadata 是＠import所用在的注解．这里指定是@EnableAutoConfiguration\npublic String[] selectImports(AnnotationMetadata annotationMetadata) {\n    if (!isEnabled(annotationMetadata)) {\n        return NO_IMPORTS;\n    }\n     //加载XXConfiguration的元数据信息（包含了某些类被生成bean条件），继续跟进这个方法调用，就会发现加载的是：spring-boot-autoconfigure　jar包里面META-INF的spring-autoconfigure-metadata.properties\n    AutoConfigurationMetadata autoConfigurationMetadata = AutoConfigurationMetadataLoader\n            .loadMetadata(this.beanClassLoader);\n　　    //获取注解里设置的属性，在＠SpringBootApplication设置的exclude,excludeＮame属性值，其实就是设置＠EnableAutoConfiguration的这两个属性值\n       AnnotationAttributes attributes = getAttributes(annotationMetadata);\n       //从spring-boot-autoconfigure　jar包里面META-INF/spring.factories加载配置类的名称，打开这个文件发现里面包含了springboot框架提供的所有配置类\n    List&lt;String&gt; configurations = getCandidateConfigurations(annotationMetadata,\n            attributes);\n     //去掉重复项\n    configurations = removeDuplicates(configurations);\n     //获取自己配置不需要生成bean的class\n    Set&lt;String&gt; exclusions = getExclusions(annotationMetadata, attributes);\n    //校验被exclude的类是否都是springboot自动化配置里的类，如果存在抛出异常\n    checkExcludedClasses(configurations, exclusions);\n   //删除被exclude掉的类\n    configurations.removeAll(exclusions);\n   //过滤刷选，满足OnClassCondition的类\n    configurations = filter(configurations, autoConfigurationMetadata);\n    fireAutoConfigurationImportEvents(configurations, exclusions);\n//返回需要注入的bean的类路径\n    return StringUtils.toStringArray(configurations);\n}</code></pre>\n<p>SpringBoot 在启动时会去依赖的 starter 包中寻找 /META-INF/spring.factories 文件，然后根据文件中配置的路径去扫描项目所依赖的 Jar 包，这类似于 Java 的 SPI 机制。</p>\n<p>JavaSPI 实际上是“基于接口的编程＋策略模式＋配置文件”组合实现的动态加载机制。</p>\n<h2 id=\"步骤\"><a href=\"#步骤\" class=\"headerlink\" title=\"步骤\"></a>步骤</h2><ol>\n<li>新建工程</li>\n</ol>\n<p>一般starter的命名格式为：spring-boot-starter-hello</p>\n<ol start=\"2\">\n<li>新建HelloProperties类，定义一个hello.msg参数（默认值World！）。</li>\n</ol>\n<pre><code class=\"java\">@ConfigurationProperties(prefix = &quot;hello&quot;)\npublic class HelloProperties {\n    /**\n     * 打招呼的内容，默认为“World!”\n     */\n    private String msg = &quot;World!&quot;;\n\n    public String getMsg() {\n        return msg;\n    }\n\n    public void setMsg(String msg) {\n        this.msg = msg;\n    }\n}</code></pre>\n<ol start=\"3\">\n<li>编写功能（HelloService）</li>\n</ol>\n<pre><code class=\"java\">@Service\npublic class HelloService {\n    @Autowired\n    private HelloProperties helloProperties;\n\n    /**\n     * 打招呼方法\n     *\n     * @param name 人名，向谁打招呼使用\n     * @return\n     */\n    public String sayHello(String name) {\n        return &quot;Hello &quot; + name + &quot; &quot; + helloProperties.getMsg();\n    }</code></pre>\n<ol start=\"4\">\n<li>编写自动配置类</li>\n</ol>\n<pre><code class=\"java\">//定义为配置类\n@Configuration\n//在web工程条件下成立\n@ConditionalOnWebApplication\n//启用HelloProperties配置功能，并加入到IOC容器中\n@EnableConfigurationProperties({HelloProperties.class})\n//导入HelloService组件\n@Import(HelloService.class)\n//@ComponentScan\npublic class HelloAutoConfiguration {\n}</code></pre>\n<ol start=\"5\">\n<li>在resources目录下新建META-INF目录，并在META-INF下新建spring.factories文件，写入：</li>\n</ol>\n<pre><code class=\"properties\">org.springframework.boot.autoconfigure.EnableAutoConfiguration=\\\ncom.example.springbootstarterhello.HelloAutoConfiguration</code></pre>\n<ol start=\"6\">\n<li><p>收尾工作</p>\n<ol>\n<li>删除自动生成的启动类SpringBootStarterHelloApplication。</li>\n<li>删除resources下的除META-INF目录之外的所有文件目录。</li>\n<li>删除spring-boot-starter-test依赖并且删除test目录。</li>\n</ol>\n</li>\n<li><p>到目前为止，spring-boot-starter-hello的自动配置功能已实现，并且正确使用了，但还有一点不够完美，如果你也按上面步骤实现了自己的spring-boot-starter-hello自动配置，在application.properties中配置hello.msg属性时，你会发现并没有提示你有关该配置的信息，但是如果你想配置tomcat端口时，输入server.port是有提示的。<br>新建META-INF/spring-configuration-metadata.json文件，进行配置。</p>\n</li>\n</ol>\n<pre><code class=\"json\">{\n  &quot;hints&quot;:[{\n    &quot;name&quot;:&quot;hello.msg&quot;,\n    &quot;values&quot;:[{\n      &quot;value&quot;:&quot;你好&quot;,\n      &quot;description&quot;:&quot;中文方式打招呼&quot;\n    },{\n      &quot;value&quot;:&quot;Hi&quot;,\n      &quot;description&quot;:&quot;英文方式打招呼&quot;\n    }]\n  }],\n  &quot;groups&quot;:[\n    {\n      &quot;sourceType&quot;: &quot;com.seagetech.spring.boot.helloworld.HelloWorldProperties&quot;,\n      &quot;name&quot;: &quot;hello&quot;,\n      &quot;type&quot;: &quot;com.example.springbootstarterhello.HelloProperties&quot;\n    }],\n  &quot;properties&quot;:[\n    {\n      &quot;sourceType&quot;: &quot;com.example.springbootstarterhello.HelloProperties&quot;,\n      &quot;name&quot;: &quot;hello.msg&quot;,\n      &quot;type&quot;: &quot;java.lang.String&quot;,\n      &quot;description&quot;: &quot;打招呼的内容&quot;,\n      &quot;defaultValue&quot;: &quot;Worlds&quot;\n    }]\n}</code></pre>\n<ol start=\"7\">\n<li>执行<code>mvn install</code>将spring-boot-starter-hello安装到本地</li>\n</ol>\n<p>至此，我们的starter就可以使用了。</p>\n","site":{"data":{}},"more":"<h2 id=\"什么是SpringBoot-starter\"><a href=\"#什么是SpringBoot-starter\" class=\"headerlink\" title=\"什么是SpringBoot starter\"></a>什么是SpringBoot starter</h2><p>Starter可以理解为一个可拔插式的插件，提供一系列便利的依赖描述符，您可以获得所需的所有Spring和相关技术的一站式服务。应用程序只需要在maven中引入starter依赖，SpringBoot就能自动扫描到要加载的信息并启动相应的默认配置。用一句话描述，就是springboot的场景启动器。</p>\n<h2 id=\"为什么starter可以热插拔\"><a href=\"#为什么starter可以热插拔\" class=\"headerlink\" title=\"为什么starter可以热插拔\"></a>为什么starter可以热插拔</h2><p>一个Springboot应用都会有一个<code>@SpringBootApplication</code>注解。而<code>@SpringBootApplication</code>注解里其实包含三个注解:</p>\n<ul>\n<li>@SpringBootConfiguration 与<code>@Configuration</code>作用相同，生命当前类是个配置类</li>\n<li>@EnableAutoConfiguration <code>@EnableAutoConfiguration</code>是springboot实现自动化配置的核心注解，通过这个注解把spring应用所需的bean注入容器中。<code>@EnableAutoConfiguration</code>源码通过<code>@Import</code>注入了一个<code>ImportSelector</code>的实现类<code>AutoConfigurationImportSelector</code>,这个<code>ImportSelector</code>最终实现根据我们的配置，动态加载所需的bean.</li>\n<li>@ComponentScan   扫描各种Component（service，controller，component，repository），默认扫描本类所在包和子包中都类，所以一般会把springboot启动类放在项目源码的根目录。</li>\n</ul>\n<pre><code class=\"java\">@Target({ElementType.TYPE})\n@Retention(RetentionPolicy.RUNTIME)\n@Documented\n@Inherited\n@AutoConfigurationPackage\n@Import({EnableAutoConfigurationImportSelector.class})\npublic @interface EnableAutoConfiguration {\n    String ENABLED_OVERRIDE_PROPERTY = &quot;spring.boot.enableautoconfiguration&quot;;\n\n    Class&lt;?&gt;[] exclude() default {};\n\n    String[] excludeName() default {};\n}</code></pre>\n<pre><code class=\"java\">@Override\n//annotationMetadata 是＠import所用在的注解．这里指定是@EnableAutoConfiguration\npublic String[] selectImports(AnnotationMetadata annotationMetadata) {\n    if (!isEnabled(annotationMetadata)) {\n        return NO_IMPORTS;\n    }\n     //加载XXConfiguration的元数据信息（包含了某些类被生成bean条件），继续跟进这个方法调用，就会发现加载的是：spring-boot-autoconfigure　jar包里面META-INF的spring-autoconfigure-metadata.properties\n    AutoConfigurationMetadata autoConfigurationMetadata = AutoConfigurationMetadataLoader\n            .loadMetadata(this.beanClassLoader);\n　　    //获取注解里设置的属性，在＠SpringBootApplication设置的exclude,excludeＮame属性值，其实就是设置＠EnableAutoConfiguration的这两个属性值\n       AnnotationAttributes attributes = getAttributes(annotationMetadata);\n       //从spring-boot-autoconfigure　jar包里面META-INF/spring.factories加载配置类的名称，打开这个文件发现里面包含了springboot框架提供的所有配置类\n    List&lt;String&gt; configurations = getCandidateConfigurations(annotationMetadata,\n            attributes);\n     //去掉重复项\n    configurations = removeDuplicates(configurations);\n     //获取自己配置不需要生成bean的class\n    Set&lt;String&gt; exclusions = getExclusions(annotationMetadata, attributes);\n    //校验被exclude的类是否都是springboot自动化配置里的类，如果存在抛出异常\n    checkExcludedClasses(configurations, exclusions);\n   //删除被exclude掉的类\n    configurations.removeAll(exclusions);\n   //过滤刷选，满足OnClassCondition的类\n    configurations = filter(configurations, autoConfigurationMetadata);\n    fireAutoConfigurationImportEvents(configurations, exclusions);\n//返回需要注入的bean的类路径\n    return StringUtils.toStringArray(configurations);\n}</code></pre>\n<p>SpringBoot 在启动时会去依赖的 starter 包中寻找 /META-INF/spring.factories 文件，然后根据文件中配置的路径去扫描项目所依赖的 Jar 包，这类似于 Java 的 SPI 机制。</p>\n<p>JavaSPI 实际上是“基于接口的编程＋策略模式＋配置文件”组合实现的动态加载机制。</p>\n<h2 id=\"步骤\"><a href=\"#步骤\" class=\"headerlink\" title=\"步骤\"></a>步骤</h2><ol>\n<li>新建工程</li>\n</ol>\n<p>一般starter的命名格式为：spring-boot-starter-hello</p>\n<ol start=\"2\">\n<li>新建HelloProperties类，定义一个hello.msg参数（默认值World！）。</li>\n</ol>\n<pre><code class=\"java\">@ConfigurationProperties(prefix = &quot;hello&quot;)\npublic class HelloProperties {\n    /**\n     * 打招呼的内容，默认为“World!”\n     */\n    private String msg = &quot;World!&quot;;\n\n    public String getMsg() {\n        return msg;\n    }\n\n    public void setMsg(String msg) {\n        this.msg = msg;\n    }\n}</code></pre>\n<ol start=\"3\">\n<li>编写功能（HelloService）</li>\n</ol>\n<pre><code class=\"java\">@Service\npublic class HelloService {\n    @Autowired\n    private HelloProperties helloProperties;\n\n    /**\n     * 打招呼方法\n     *\n     * @param name 人名，向谁打招呼使用\n     * @return\n     */\n    public String sayHello(String name) {\n        return &quot;Hello &quot; + name + &quot; &quot; + helloProperties.getMsg();\n    }</code></pre>\n<ol start=\"4\">\n<li>编写自动配置类</li>\n</ol>\n<pre><code class=\"java\">//定义为配置类\n@Configuration\n//在web工程条件下成立\n@ConditionalOnWebApplication\n//启用HelloProperties配置功能，并加入到IOC容器中\n@EnableConfigurationProperties({HelloProperties.class})\n//导入HelloService组件\n@Import(HelloService.class)\n//@ComponentScan\npublic class HelloAutoConfiguration {\n}</code></pre>\n<ol start=\"5\">\n<li>在resources目录下新建META-INF目录，并在META-INF下新建spring.factories文件，写入：</li>\n</ol>\n<pre><code class=\"properties\">org.springframework.boot.autoconfigure.EnableAutoConfiguration=\\\ncom.example.springbootstarterhello.HelloAutoConfiguration</code></pre>\n<ol start=\"6\">\n<li><p>收尾工作</p>\n<ol>\n<li>删除自动生成的启动类SpringBootStarterHelloApplication。</li>\n<li>删除resources下的除META-INF目录之外的所有文件目录。</li>\n<li>删除spring-boot-starter-test依赖并且删除test目录。</li>\n</ol>\n</li>\n<li><p>到目前为止，spring-boot-starter-hello的自动配置功能已实现，并且正确使用了，但还有一点不够完美，如果你也按上面步骤实现了自己的spring-boot-starter-hello自动配置，在application.properties中配置hello.msg属性时，你会发现并没有提示你有关该配置的信息，但是如果你想配置tomcat端口时，输入server.port是有提示的。<br>新建META-INF/spring-configuration-metadata.json文件，进行配置。</p>\n</li>\n</ol>\n<pre><code class=\"json\">{\n  &quot;hints&quot;:[{\n    &quot;name&quot;:&quot;hello.msg&quot;,\n    &quot;values&quot;:[{\n      &quot;value&quot;:&quot;你好&quot;,\n      &quot;description&quot;:&quot;中文方式打招呼&quot;\n    },{\n      &quot;value&quot;:&quot;Hi&quot;,\n      &quot;description&quot;:&quot;英文方式打招呼&quot;\n    }]\n  }],\n  &quot;groups&quot;:[\n    {\n      &quot;sourceType&quot;: &quot;com.seagetech.spring.boot.helloworld.HelloWorldProperties&quot;,\n      &quot;name&quot;: &quot;hello&quot;,\n      &quot;type&quot;: &quot;com.example.springbootstarterhello.HelloProperties&quot;\n    }],\n  &quot;properties&quot;:[\n    {\n      &quot;sourceType&quot;: &quot;com.example.springbootstarterhello.HelloProperties&quot;,\n      &quot;name&quot;: &quot;hello.msg&quot;,\n      &quot;type&quot;: &quot;java.lang.String&quot;,\n      &quot;description&quot;: &quot;打招呼的内容&quot;,\n      &quot;defaultValue&quot;: &quot;Worlds&quot;\n    }]\n}</code></pre>\n<ol start=\"7\">\n<li>执行<code>mvn install</code>将spring-boot-starter-hello安装到本地</li>\n</ol>\n<p>至此，我们的starter就可以使用了。</p>\n"},{"title":"你不知道StopWatch吗？","excerpt":"","comments":1,"date":"2020-11-11T02:30:52.000Z","_content":"\n昨天测试提了一个bug，页面数据导出excel太慢，ontest环境试了一下，导出4k条数据，竟然花了3min！我本地和test环境测试都没问题啊，一时间摸不着头脑。准备给代码关键步骤加日志，发到ontest测试。正准备`long start = System.currentTimeMillis();`，同事来了一句：你不知道StopWatch吗？\n\n\nSpring提供的计时器StopWatch对于秒、毫秒为单位方便计时的程序，尤其是单线程、顺序执行程序的时间特性的统计输出支持比较好。也就是说假如我们手里面有几个在顺序上前后执行的几个任务，而且我们比较关心几个任务分别执行的时间占用状况，希望能够形成一个不太复杂的日志输出，StopWatch提供了这样的功能。而且Spring的StopWatch基本上也就是仅仅为了这样的功能而实现。\n\n\n文章开头的场景，下面就是类似的实践。\n\n```java\nimport org.springframework.util.StopWatch;  \n  \npublic class StopWatchDemo {  \n  \n    /** \n     * @param args \n     * @throws InterruptedException \n     */  \n    public static void main(String[] args) throws InterruptedException {  \n        // TODO Auto-generated method stub  \n        StopWatch clock = new StopWatch();  \n        clock.start(\"TaskOneName\");  \n        Thread.sleep(1000 * 3);// 任务一模拟休眠3秒钟  \n        clock.stop();  \n        clock.start(\"TaskTwoName\");  \n        Thread.sleep(1000 * 10);// 任务一模拟休眠10秒钟  \n        clock.stop();  \n        clock.start(\"TaskThreeName\");  \n        Thread.sleep(1000 * 10);// 任务一模拟休眠10秒钟  \n        clock.stop();  \n  \n        System.out.println(clock.prettyPrint());  \n    }  \n  \n}\n```\n日志输出如下：\n\n```bash\nStopWatch '': running time (millis) = 22926\n-----------------------------------------\nms     %     Task name\n-----------------------------------------\n02990  013%  TaskOneName\n09968  043%  TaskTwoName\n09968  043%  TaskThreeName\n```\n\n### 原理：\n\n这个`StopWatch`的原理也很简单，`StopWatch`有个内部类`TaskInfo`，内部有两个属性，taskName和timeMillis。说是叫taskName，不过这里面并没有启动新的线程，只是新建一个TaskInfo对象，在StopWatch的一次启停之后，记录启停之间的时间差。\n\n","source":"_posts/2020-11-11-kongzheng1993-StopWatch.md","raw":"---\ntitle: 你不知道StopWatch吗？\nexcerpt: 'Spring'\ntags: [Spring]\ncategories: [Spring]\ncomments: true\ndate: 2020-11-11 10:30:52\n---\n\n昨天测试提了一个bug，页面数据导出excel太慢，ontest环境试了一下，导出4k条数据，竟然花了3min！我本地和test环境测试都没问题啊，一时间摸不着头脑。准备给代码关键步骤加日志，发到ontest测试。正准备`long start = System.currentTimeMillis();`，同事来了一句：你不知道StopWatch吗？\n\n\nSpring提供的计时器StopWatch对于秒、毫秒为单位方便计时的程序，尤其是单线程、顺序执行程序的时间特性的统计输出支持比较好。也就是说假如我们手里面有几个在顺序上前后执行的几个任务，而且我们比较关心几个任务分别执行的时间占用状况，希望能够形成一个不太复杂的日志输出，StopWatch提供了这样的功能。而且Spring的StopWatch基本上也就是仅仅为了这样的功能而实现。\n\n\n文章开头的场景，下面就是类似的实践。\n\n```java\nimport org.springframework.util.StopWatch;  \n  \npublic class StopWatchDemo {  \n  \n    /** \n     * @param args \n     * @throws InterruptedException \n     */  \n    public static void main(String[] args) throws InterruptedException {  \n        // TODO Auto-generated method stub  \n        StopWatch clock = new StopWatch();  \n        clock.start(\"TaskOneName\");  \n        Thread.sleep(1000 * 3);// 任务一模拟休眠3秒钟  \n        clock.stop();  \n        clock.start(\"TaskTwoName\");  \n        Thread.sleep(1000 * 10);// 任务一模拟休眠10秒钟  \n        clock.stop();  \n        clock.start(\"TaskThreeName\");  \n        Thread.sleep(1000 * 10);// 任务一模拟休眠10秒钟  \n        clock.stop();  \n  \n        System.out.println(clock.prettyPrint());  \n    }  \n  \n}\n```\n日志输出如下：\n\n```bash\nStopWatch '': running time (millis) = 22926\n-----------------------------------------\nms     %     Task name\n-----------------------------------------\n02990  013%  TaskOneName\n09968  043%  TaskTwoName\n09968  043%  TaskThreeName\n```\n\n### 原理：\n\n这个`StopWatch`的原理也很简单，`StopWatch`有个内部类`TaskInfo`，内部有两个属性，taskName和timeMillis。说是叫taskName，不过这里面并没有启动新的线程，只是新建一个TaskInfo对象，在StopWatch的一次启停之后，记录启停之间的时间差。\n\n","slug":"kongzheng1993-StopWatch","published":1,"updated":"2023-03-08T07:05:58.808Z","layout":"post","photos":[],"link":"","_id":"clg0k2ala005kt26fw65uyg2x","content":"<p>昨天测试提了一个bug，页面数据导出excel太慢，ontest环境试了一下，导出4k条数据，竟然花了3min！我本地和test环境测试都没问题啊，一时间摸不着头脑。准备给代码关键步骤加日志，发到ontest测试。正准备<code>long start = System.currentTimeMillis();</code>，同事来了一句：你不知道StopWatch吗？</p>\n<p>Spring提供的计时器StopWatch对于秒、毫秒为单位方便计时的程序，尤其是单线程、顺序执行程序的时间特性的统计输出支持比较好。也就是说假如我们手里面有几个在顺序上前后执行的几个任务，而且我们比较关心几个任务分别执行的时间占用状况，希望能够形成一个不太复杂的日志输出，StopWatch提供了这样的功能。而且Spring的StopWatch基本上也就是仅仅为了这样的功能而实现。</p>\n<p>文章开头的场景，下面就是类似的实践。</p>\n<pre><code class=\"java\">import org.springframework.util.StopWatch;  \n\npublic class StopWatchDemo {  \n\n    /** \n     * @param args \n     * @throws InterruptedException \n     */  \n    public static void main(String[] args) throws InterruptedException {  \n        // TODO Auto-generated method stub  \n        StopWatch clock = new StopWatch();  \n        clock.start(&quot;TaskOneName&quot;);  \n        Thread.sleep(1000 * 3);// 任务一模拟休眠3秒钟  \n        clock.stop();  \n        clock.start(&quot;TaskTwoName&quot;);  \n        Thread.sleep(1000 * 10);// 任务一模拟休眠10秒钟  \n        clock.stop();  \n        clock.start(&quot;TaskThreeName&quot;);  \n        Thread.sleep(1000 * 10);// 任务一模拟休眠10秒钟  \n        clock.stop();  \n\n        System.out.println(clock.prettyPrint());  \n    }  \n\n}</code></pre>\n<p>日志输出如下：</p>\n<pre><code class=\"bash\">StopWatch &#39;&#39;: running time (millis) = 22926\n-----------------------------------------\nms     %     Task name\n-----------------------------------------\n02990  013%  TaskOneName\n09968  043%  TaskTwoName\n09968  043%  TaskThreeName</code></pre>\n<h3 id=\"原理：\"><a href=\"#原理：\" class=\"headerlink\" title=\"原理：\"></a>原理：</h3><p>这个<code>StopWatch</code>的原理也很简单，<code>StopWatch</code>有个内部类<code>TaskInfo</code>，内部有两个属性，taskName和timeMillis。说是叫taskName，不过这里面并没有启动新的线程，只是新建一个TaskInfo对象，在StopWatch的一次启停之后，记录启停之间的时间差。</p>\n","site":{"data":{}},"more":"<p>昨天测试提了一个bug，页面数据导出excel太慢，ontest环境试了一下，导出4k条数据，竟然花了3min！我本地和test环境测试都没问题啊，一时间摸不着头脑。准备给代码关键步骤加日志，发到ontest测试。正准备<code>long start = System.currentTimeMillis();</code>，同事来了一句：你不知道StopWatch吗？</p>\n<p>Spring提供的计时器StopWatch对于秒、毫秒为单位方便计时的程序，尤其是单线程、顺序执行程序的时间特性的统计输出支持比较好。也就是说假如我们手里面有几个在顺序上前后执行的几个任务，而且我们比较关心几个任务分别执行的时间占用状况，希望能够形成一个不太复杂的日志输出，StopWatch提供了这样的功能。而且Spring的StopWatch基本上也就是仅仅为了这样的功能而实现。</p>\n<p>文章开头的场景，下面就是类似的实践。</p>\n<pre><code class=\"java\">import org.springframework.util.StopWatch;  \n\npublic class StopWatchDemo {  \n\n    /** \n     * @param args \n     * @throws InterruptedException \n     */  \n    public static void main(String[] args) throws InterruptedException {  \n        // TODO Auto-generated method stub  \n        StopWatch clock = new StopWatch();  \n        clock.start(&quot;TaskOneName&quot;);  \n        Thread.sleep(1000 * 3);// 任务一模拟休眠3秒钟  \n        clock.stop();  \n        clock.start(&quot;TaskTwoName&quot;);  \n        Thread.sleep(1000 * 10);// 任务一模拟休眠10秒钟  \n        clock.stop();  \n        clock.start(&quot;TaskThreeName&quot;);  \n        Thread.sleep(1000 * 10);// 任务一模拟休眠10秒钟  \n        clock.stop();  \n\n        System.out.println(clock.prettyPrint());  \n    }  \n\n}</code></pre>\n<p>日志输出如下：</p>\n<pre><code class=\"bash\">StopWatch &#39;&#39;: running time (millis) = 22926\n-----------------------------------------\nms     %     Task name\n-----------------------------------------\n02990  013%  TaskOneName\n09968  043%  TaskTwoName\n09968  043%  TaskThreeName</code></pre>\n<h3 id=\"原理：\"><a href=\"#原理：\" class=\"headerlink\" title=\"原理：\"></a>原理：</h3><p>这个<code>StopWatch</code>的原理也很简单，<code>StopWatch</code>有个内部类<code>TaskInfo</code>，内部有两个属性，taskName和timeMillis。说是叫taskName，不过这里面并没有启动新的线程，只是新建一个TaskInfo对象，在StopWatch的一次启停之后，记录启停之间的时间差。</p>\n"},{"title":"乐观锁实现方式","excerpt":"","comments":1,"date":"2020-11-10T16:30:52.000Z","_content":"\n\n### 概念\n\n- 乐观锁：乐观锁在操作数据时非常乐观，认为别人不会同时修改数据。因此乐观锁不会上锁，只是在执行更新的时候判断一下在此期间别人是否修改了数据：如果别人修改了数据则放弃操作，否则执行操作。\n- 悲观锁：悲观锁在操作数据时比较悲观，认为别人会同时修改数据。因此操作数据时直接把数据锁住，直到操作完成后才会释放锁；上锁期间其他人不能修改数据。\n\n    乐观锁和悲观锁是两种思想，它们的使用是非常广泛的，不局限于某种编程语言或数据库。\n\n### 什么场景使用什么锁？\n\n乐观锁适用于写比较少的情况下（多读场景），即冲突真的很少发生的时候，这样可以省去了锁的开销，加大了系统的整个吞吐量。但如果是多写的情况，一般会经常产生冲突，这就会导致上层应用会不断的进行retry，这样反倒是降低了性能，所以一般多写的场景下用悲观锁就比较合适。\n\n### 实现方式\n\n1. 悲观锁\n\nselect ... for update\n\n2. 乐观锁\n\n    1. 版本号机制\n    一般是在数据表中加上一个数据版本号version字段，表示数据被修改的次数，当数据被修改时，version值会加一。当线程A要更新数据值时，在读取数据的同时也会读取version值，在提交更新时，若刚才读取到的version值为当前数据库中的version值相等时才更新，否则重试更新操作，直到更新成功。\n\n    2. CAS\n    即compare and swap（比较与交换），是一种有名的无锁算法。无锁编程，即不使用锁的情况下实现多线程之间的变量同步，也就是在没有线程被阻塞的情况下实现变量的同步，所以也叫非阻塞同步（Non-blocking Synchronization）。CAS算法涉及到三个操作数\n    - 需要读写的内存值 V\n    - 进行比较的值 A\n    - 拟写入的新值 B\n    当且仅当 V 的值等于 A时，CAS通过原子方式用新值B来更新V的值，否则不会执行任何操作（比较和替换是一个原子操作）。一般情况下是一个自旋操作，即不断的重试。\n\n### 缺点\n\n1. 悲观锁\n\n2. 乐观锁\n\n    1. ABA 问题\n    如果一个变量V初次读取的时候是A值，并且在准备赋值的时候检查到它仍然是A值，那我们就能说明它的值没有被其他线程修改过了吗？很明显是不能的，因为在这段时间它的值可能被改为其他值，然后又改回A，那CAS操作就会误认为它从来没有被修改过。这个问题被称为CAS操作的 \"ABA\"问题。\n\n    2. 自旋CAS（也就是不成功就一直循环执行直到成功）如果长时间不成功，会给CPU带来非常大的执行开销。 如果JVM能支持处理器提供的pause指令那么效率会有一定的提升，pause指令有两个作用，第一它可以延迟流水线执行指令（de-pipeline）,使CPU不会消耗过多的执行资源，延迟的时间取决于具体实现的版本，在一些处理器上延迟时间是零。第二它可以避免在退出循环的时候因内存顺序冲突（memory order violation）而引起CPU流水线被清空（CPU pipeline flush），从而提高CPU的执行效率。\n\n    3. 只能保证一个共享变量的原子操作\n    CAS 只对单个共享变量有效，当操作涉及跨多个共享变量时 CAS 无效。但是从 JDK 1.5开始，提供了AtomicReference类来保证引用对象之间的原子性，你可以把多个变量放在一个对象里来进行 CAS 操作.所以我们可以使用锁或者利用AtomicReference类把多个共享变量合并成一个共享变量来操作。\n\n\n\n\n","source":"_posts/2020-11-11-kongzheng1993-乐观锁实现方式.md","raw":"---\ntitle: 乐观锁实现方式\nexcerpt: '算法'\ntags: [算法]\ncategories: [算法]\ncomments: true\ndate: 2020-11-11 00:30:52\n---\n\n\n### 概念\n\n- 乐观锁：乐观锁在操作数据时非常乐观，认为别人不会同时修改数据。因此乐观锁不会上锁，只是在执行更新的时候判断一下在此期间别人是否修改了数据：如果别人修改了数据则放弃操作，否则执行操作。\n- 悲观锁：悲观锁在操作数据时比较悲观，认为别人会同时修改数据。因此操作数据时直接把数据锁住，直到操作完成后才会释放锁；上锁期间其他人不能修改数据。\n\n    乐观锁和悲观锁是两种思想，它们的使用是非常广泛的，不局限于某种编程语言或数据库。\n\n### 什么场景使用什么锁？\n\n乐观锁适用于写比较少的情况下（多读场景），即冲突真的很少发生的时候，这样可以省去了锁的开销，加大了系统的整个吞吐量。但如果是多写的情况，一般会经常产生冲突，这就会导致上层应用会不断的进行retry，这样反倒是降低了性能，所以一般多写的场景下用悲观锁就比较合适。\n\n### 实现方式\n\n1. 悲观锁\n\nselect ... for update\n\n2. 乐观锁\n\n    1. 版本号机制\n    一般是在数据表中加上一个数据版本号version字段，表示数据被修改的次数，当数据被修改时，version值会加一。当线程A要更新数据值时，在读取数据的同时也会读取version值，在提交更新时，若刚才读取到的version值为当前数据库中的version值相等时才更新，否则重试更新操作，直到更新成功。\n\n    2. CAS\n    即compare and swap（比较与交换），是一种有名的无锁算法。无锁编程，即不使用锁的情况下实现多线程之间的变量同步，也就是在没有线程被阻塞的情况下实现变量的同步，所以也叫非阻塞同步（Non-blocking Synchronization）。CAS算法涉及到三个操作数\n    - 需要读写的内存值 V\n    - 进行比较的值 A\n    - 拟写入的新值 B\n    当且仅当 V 的值等于 A时，CAS通过原子方式用新值B来更新V的值，否则不会执行任何操作（比较和替换是一个原子操作）。一般情况下是一个自旋操作，即不断的重试。\n\n### 缺点\n\n1. 悲观锁\n\n2. 乐观锁\n\n    1. ABA 问题\n    如果一个变量V初次读取的时候是A值，并且在准备赋值的时候检查到它仍然是A值，那我们就能说明它的值没有被其他线程修改过了吗？很明显是不能的，因为在这段时间它的值可能被改为其他值，然后又改回A，那CAS操作就会误认为它从来没有被修改过。这个问题被称为CAS操作的 \"ABA\"问题。\n\n    2. 自旋CAS（也就是不成功就一直循环执行直到成功）如果长时间不成功，会给CPU带来非常大的执行开销。 如果JVM能支持处理器提供的pause指令那么效率会有一定的提升，pause指令有两个作用，第一它可以延迟流水线执行指令（de-pipeline）,使CPU不会消耗过多的执行资源，延迟的时间取决于具体实现的版本，在一些处理器上延迟时间是零。第二它可以避免在退出循环的时候因内存顺序冲突（memory order violation）而引起CPU流水线被清空（CPU pipeline flush），从而提高CPU的执行效率。\n\n    3. 只能保证一个共享变量的原子操作\n    CAS 只对单个共享变量有效，当操作涉及跨多个共享变量时 CAS 无效。但是从 JDK 1.5开始，提供了AtomicReference类来保证引用对象之间的原子性，你可以把多个变量放在一个对象里来进行 CAS 操作.所以我们可以使用锁或者利用AtomicReference类把多个共享变量合并成一个共享变量来操作。\n\n\n\n\n","slug":"kongzheng1993-乐观锁实现方式","published":1,"updated":"2023-03-08T07:05:58.808Z","layout":"post","photos":[],"link":"","_id":"clg0k2ald005mt26f5dc7tesq","content":"<h3 id=\"概念\"><a href=\"#概念\" class=\"headerlink\" title=\"概念\"></a>概念</h3><ul>\n<li><p>乐观锁：乐观锁在操作数据时非常乐观，认为别人不会同时修改数据。因此乐观锁不会上锁，只是在执行更新的时候判断一下在此期间别人是否修改了数据：如果别人修改了数据则放弃操作，否则执行操作。</p>\n</li>\n<li><p>悲观锁：悲观锁在操作数据时比较悲观，认为别人会同时修改数据。因此操作数据时直接把数据锁住，直到操作完成后才会释放锁；上锁期间其他人不能修改数据。</p>\n<p>  乐观锁和悲观锁是两种思想，它们的使用是非常广泛的，不局限于某种编程语言或数据库。</p>\n</li>\n</ul>\n<h3 id=\"什么场景使用什么锁？\"><a href=\"#什么场景使用什么锁？\" class=\"headerlink\" title=\"什么场景使用什么锁？\"></a>什么场景使用什么锁？</h3><p>乐观锁适用于写比较少的情况下（多读场景），即冲突真的很少发生的时候，这样可以省去了锁的开销，加大了系统的整个吞吐量。但如果是多写的情况，一般会经常产生冲突，这就会导致上层应用会不断的进行retry，这样反倒是降低了性能，所以一般多写的场景下用悲观锁就比较合适。</p>\n<h3 id=\"实现方式\"><a href=\"#实现方式\" class=\"headerlink\" title=\"实现方式\"></a>实现方式</h3><ol>\n<li>悲观锁</li>\n</ol>\n<p>select … for update</p>\n<ol start=\"2\">\n<li><p>乐观锁</p>\n<ol>\n<li><p>版本号机制<br>一般是在数据表中加上一个数据版本号version字段，表示数据被修改的次数，当数据被修改时，version值会加一。当线程A要更新数据值时，在读取数据的同时也会读取version值，在提交更新时，若刚才读取到的version值为当前数据库中的version值相等时才更新，否则重试更新操作，直到更新成功。</p>\n</li>\n<li><p>CAS<br>即compare and swap（比较与交换），是一种有名的无锁算法。无锁编程，即不使用锁的情况下实现多线程之间的变量同步，也就是在没有线程被阻塞的情况下实现变量的同步，所以也叫非阻塞同步（Non-blocking Synchronization）。CAS算法涉及到三个操作数</p>\n</li>\n</ol>\n<ul>\n<li>需要读写的内存值 V</li>\n<li>进行比较的值 A</li>\n<li>拟写入的新值 B<br>当且仅当 V 的值等于 A时，CAS通过原子方式用新值B来更新V的值，否则不会执行任何操作（比较和替换是一个原子操作）。一般情况下是一个自旋操作，即不断的重试。</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"缺点\"><a href=\"#缺点\" class=\"headerlink\" title=\"缺点\"></a>缺点</h3><ol>\n<li><p>悲观锁</p>\n</li>\n<li><p>乐观锁</p>\n<ol>\n<li><p>ABA 问题<br>如果一个变量V初次读取的时候是A值，并且在准备赋值的时候检查到它仍然是A值，那我们就能说明它的值没有被其他线程修改过了吗？很明显是不能的，因为在这段时间它的值可能被改为其他值，然后又改回A，那CAS操作就会误认为它从来没有被修改过。这个问题被称为CAS操作的 “ABA”问题。</p>\n</li>\n<li><p>自旋CAS（也就是不成功就一直循环执行直到成功）如果长时间不成功，会给CPU带来非常大的执行开销。 如果JVM能支持处理器提供的pause指令那么效率会有一定的提升，pause指令有两个作用，第一它可以延迟流水线执行指令（de-pipeline）,使CPU不会消耗过多的执行资源，延迟的时间取决于具体实现的版本，在一些处理器上延迟时间是零。第二它可以避免在退出循环的时候因内存顺序冲突（memory order violation）而引起CPU流水线被清空（CPU pipeline flush），从而提高CPU的执行效率。</p>\n</li>\n<li><p>只能保证一个共享变量的原子操作<br>CAS 只对单个共享变量有效，当操作涉及跨多个共享变量时 CAS 无效。但是从 JDK 1.5开始，提供了AtomicReference类来保证引用对象之间的原子性，你可以把多个变量放在一个对象里来进行 CAS 操作.所以我们可以使用锁或者利用AtomicReference类把多个共享变量合并成一个共享变量来操作。</p>\n</li>\n</ol>\n</li>\n</ol>\n","site":{"data":{}},"more":"<h3 id=\"概念\"><a href=\"#概念\" class=\"headerlink\" title=\"概念\"></a>概念</h3><ul>\n<li><p>乐观锁：乐观锁在操作数据时非常乐观，认为别人不会同时修改数据。因此乐观锁不会上锁，只是在执行更新的时候判断一下在此期间别人是否修改了数据：如果别人修改了数据则放弃操作，否则执行操作。</p>\n</li>\n<li><p>悲观锁：悲观锁在操作数据时比较悲观，认为别人会同时修改数据。因此操作数据时直接把数据锁住，直到操作完成后才会释放锁；上锁期间其他人不能修改数据。</p>\n<p>  乐观锁和悲观锁是两种思想，它们的使用是非常广泛的，不局限于某种编程语言或数据库。</p>\n</li>\n</ul>\n<h3 id=\"什么场景使用什么锁？\"><a href=\"#什么场景使用什么锁？\" class=\"headerlink\" title=\"什么场景使用什么锁？\"></a>什么场景使用什么锁？</h3><p>乐观锁适用于写比较少的情况下（多读场景），即冲突真的很少发生的时候，这样可以省去了锁的开销，加大了系统的整个吞吐量。但如果是多写的情况，一般会经常产生冲突，这就会导致上层应用会不断的进行retry，这样反倒是降低了性能，所以一般多写的场景下用悲观锁就比较合适。</p>\n<h3 id=\"实现方式\"><a href=\"#实现方式\" class=\"headerlink\" title=\"实现方式\"></a>实现方式</h3><ol>\n<li>悲观锁</li>\n</ol>\n<p>select … for update</p>\n<ol start=\"2\">\n<li><p>乐观锁</p>\n<ol>\n<li><p>版本号机制<br>一般是在数据表中加上一个数据版本号version字段，表示数据被修改的次数，当数据被修改时，version值会加一。当线程A要更新数据值时，在读取数据的同时也会读取version值，在提交更新时，若刚才读取到的version值为当前数据库中的version值相等时才更新，否则重试更新操作，直到更新成功。</p>\n</li>\n<li><p>CAS<br>即compare and swap（比较与交换），是一种有名的无锁算法。无锁编程，即不使用锁的情况下实现多线程之间的变量同步，也就是在没有线程被阻塞的情况下实现变量的同步，所以也叫非阻塞同步（Non-blocking Synchronization）。CAS算法涉及到三个操作数</p>\n</li>\n</ol>\n<ul>\n<li>需要读写的内存值 V</li>\n<li>进行比较的值 A</li>\n<li>拟写入的新值 B<br>当且仅当 V 的值等于 A时，CAS通过原子方式用新值B来更新V的值，否则不会执行任何操作（比较和替换是一个原子操作）。一般情况下是一个自旋操作，即不断的重试。</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"缺点\"><a href=\"#缺点\" class=\"headerlink\" title=\"缺点\"></a>缺点</h3><ol>\n<li><p>悲观锁</p>\n</li>\n<li><p>乐观锁</p>\n<ol>\n<li><p>ABA 问题<br>如果一个变量V初次读取的时候是A值，并且在准备赋值的时候检查到它仍然是A值，那我们就能说明它的值没有被其他线程修改过了吗？很明显是不能的，因为在这段时间它的值可能被改为其他值，然后又改回A，那CAS操作就会误认为它从来没有被修改过。这个问题被称为CAS操作的 “ABA”问题。</p>\n</li>\n<li><p>自旋CAS（也就是不成功就一直循环执行直到成功）如果长时间不成功，会给CPU带来非常大的执行开销。 如果JVM能支持处理器提供的pause指令那么效率会有一定的提升，pause指令有两个作用，第一它可以延迟流水线执行指令（de-pipeline）,使CPU不会消耗过多的执行资源，延迟的时间取决于具体实现的版本，在一些处理器上延迟时间是零。第二它可以避免在退出循环的时候因内存顺序冲突（memory order violation）而引起CPU流水线被清空（CPU pipeline flush），从而提高CPU的执行效率。</p>\n</li>\n<li><p>只能保证一个共享变量的原子操作<br>CAS 只对单个共享变量有效，当操作涉及跨多个共享变量时 CAS 无效。但是从 JDK 1.5开始，提供了AtomicReference类来保证引用对象之间的原子性，你可以把多个变量放在一个对象里来进行 CAS 操作.所以我们可以使用锁或者利用AtomicReference类把多个共享变量合并成一个共享变量来操作。</p>\n</li>\n</ol>\n</li>\n</ol>\n"},{"title":"iframe重复加载的问题","excerpt":"","comments":1,"date":"2020-12-18T11:30:52.000Z","_content":"\n最近需要开发一个可复用的dialog，用iframe实现，但是发现一个问题，当我打开显示这个dialog时，iframe引入的页面加载，没有问题。但是关闭这个iframe时，又重新加载了这个页面。从浏览器开发者工具可以看到两次请求这个页面，而且通过断点也能看到两次都进入了vue的creted、mount等生命周期函数。\n\n```html\n    <el-dialog title=\"iframe测试\" :visible.sync=\"visiable\" lock-scroll=\"false\" @close=\"visiable = false\"\n               width=\"80%\">\n        <iframe id=\"iframeId\" :src=\"'/XXX?YYY=' + yyy + '&ZZZ=' + zzz + '&r='+ Math.random()\"\n                style=\"width: 100% \" frameborder=\"0\" onload=\"this.height=400\"></iframe>\n    </el-dialog>\n```\n\n经过查询资料，当iframe的src属性被修改时，则会导致iframe再次被加载。上面的例子中，虽然YYY变量没有变动，但是当我关闭iframe的时候，再次检测src属性的时候，会执行`Math.random()`，每次都不同，所以会重新加载iframe。\n\n### 如何修复\n\nsrc属性的值用变量，不需要显示dialog的时候，将变量赋值`null`，只要src为`null`，iframe就不会加载，因为就算加载，也是请求到`null`。。。当我们需要用iframe的时候再给src赋值，关闭的时候，在修改会`null`。这样，iframe就只加载一次了～","source":"_posts/2020-12-18-kongzheng1993-iframe重复加载的问题.md","raw":"---\ntitle: iframe重复加载的问题\nexcerpt: 'Web'\ntags: [Web]\ncategories: [Web]\ncomments: true\ndate: 2020-12-18 19:30:52\n---\n\n最近需要开发一个可复用的dialog，用iframe实现，但是发现一个问题，当我打开显示这个dialog时，iframe引入的页面加载，没有问题。但是关闭这个iframe时，又重新加载了这个页面。从浏览器开发者工具可以看到两次请求这个页面，而且通过断点也能看到两次都进入了vue的creted、mount等生命周期函数。\n\n```html\n    <el-dialog title=\"iframe测试\" :visible.sync=\"visiable\" lock-scroll=\"false\" @close=\"visiable = false\"\n               width=\"80%\">\n        <iframe id=\"iframeId\" :src=\"'/XXX?YYY=' + yyy + '&ZZZ=' + zzz + '&r='+ Math.random()\"\n                style=\"width: 100% \" frameborder=\"0\" onload=\"this.height=400\"></iframe>\n    </el-dialog>\n```\n\n经过查询资料，当iframe的src属性被修改时，则会导致iframe再次被加载。上面的例子中，虽然YYY变量没有变动，但是当我关闭iframe的时候，再次检测src属性的时候，会执行`Math.random()`，每次都不同，所以会重新加载iframe。\n\n### 如何修复\n\nsrc属性的值用变量，不需要显示dialog的时候，将变量赋值`null`，只要src为`null`，iframe就不会加载，因为就算加载，也是请求到`null`。。。当我们需要用iframe的时候再给src赋值，关闭的时候，在修改会`null`。这样，iframe就只加载一次了～","slug":"kongzheng1993-iframe重复加载的问题","published":1,"updated":"2023-03-08T07:05:58.808Z","layout":"post","photos":[],"link":"","_id":"clg0k2alf005pt26fd823ftxy","content":"<p>最近需要开发一个可复用的dialog，用iframe实现，但是发现一个问题，当我打开显示这个dialog时，iframe引入的页面加载，没有问题。但是关闭这个iframe时，又重新加载了这个页面。从浏览器开发者工具可以看到两次请求这个页面，而且通过断点也能看到两次都进入了vue的creted、mount等生命周期函数。</p>\n<pre><code class=\"html\">    &lt;el-dialog title=&quot;iframe测试&quot; :visible.sync=&quot;visiable&quot; lock-scroll=&quot;false&quot; @close=&quot;visiable = false&quot;\n               width=&quot;80%&quot;&gt;\n        &lt;iframe id=&quot;iframeId&quot; :src=&quot;&#39;/XXX?YYY=&#39; + yyy + &#39;&amp;ZZZ=&#39; + zzz + &#39;&amp;r=&#39;+ Math.random()&quot;\n                style=&quot;width: 100% &quot; frameborder=&quot;0&quot; onload=&quot;this.height=400&quot;&gt;&lt;/iframe&gt;\n    &lt;/el-dialog&gt;</code></pre>\n<p>经过查询资料，当iframe的src属性被修改时，则会导致iframe再次被加载。上面的例子中，虽然YYY变量没有变动，但是当我关闭iframe的时候，再次检测src属性的时候，会执行<code>Math.random()</code>，每次都不同，所以会重新加载iframe。</p>\n<h3 id=\"如何修复\"><a href=\"#如何修复\" class=\"headerlink\" title=\"如何修复\"></a>如何修复</h3><p>src属性的值用变量，不需要显示dialog的时候，将变量赋值<code>null</code>，只要src为<code>null</code>，iframe就不会加载，因为就算加载，也是请求到<code>null</code>。。。当我们需要用iframe的时候再给src赋值，关闭的时候，在修改会<code>null</code>。这样，iframe就只加载一次了～</p>\n","site":{"data":{}},"more":"<p>最近需要开发一个可复用的dialog，用iframe实现，但是发现一个问题，当我打开显示这个dialog时，iframe引入的页面加载，没有问题。但是关闭这个iframe时，又重新加载了这个页面。从浏览器开发者工具可以看到两次请求这个页面，而且通过断点也能看到两次都进入了vue的creted、mount等生命周期函数。</p>\n<pre><code class=\"html\">    &lt;el-dialog title=&quot;iframe测试&quot; :visible.sync=&quot;visiable&quot; lock-scroll=&quot;false&quot; @close=&quot;visiable = false&quot;\n               width=&quot;80%&quot;&gt;\n        &lt;iframe id=&quot;iframeId&quot; :src=&quot;&#39;/XXX?YYY=&#39; + yyy + &#39;&amp;ZZZ=&#39; + zzz + &#39;&amp;r=&#39;+ Math.random()&quot;\n                style=&quot;width: 100% &quot; frameborder=&quot;0&quot; onload=&quot;this.height=400&quot;&gt;&lt;/iframe&gt;\n    &lt;/el-dialog&gt;</code></pre>\n<p>经过查询资料，当iframe的src属性被修改时，则会导致iframe再次被加载。上面的例子中，虽然YYY变量没有变动，但是当我关闭iframe的时候，再次检测src属性的时候，会执行<code>Math.random()</code>，每次都不同，所以会重新加载iframe。</p>\n<h3 id=\"如何修复\"><a href=\"#如何修复\" class=\"headerlink\" title=\"如何修复\"></a>如何修复</h3><p>src属性的值用变量，不需要显示dialog的时候，将变量赋值<code>null</code>，只要src为<code>null</code>，iframe就不会加载，因为就算加载，也是请求到<code>null</code>。。。当我们需要用iframe的时候再给src赋值，关闭的时候，在修改会<code>null</code>。这样，iframe就只加载一次了～</p>\n"},{"title":"JDK自带的脚本引擎javax.script.ScriptEngine","excerpt":"","comments":1,"date":"2020-12-29T02:30:52.000Z","_content":"\n最近在做一个需求，因为时免测的功能，所以要做一个开关，如果出现问题，不能影响之前的业务。像这种开关，我之前的办法就是在配置中心搞一个变量，如果有问题就修改开关变量的值。\n\n这次这个“开关“是一个同事来做的，他的方法是使用javax.script包下的脚本引擎，在配置中心搞一个javascript函数，将后台的java对象传入，执行js函数，得出结果。根据结果来决定后面代码的执行。\n\n这个方法就很灵活了，可以传入参数来计算，也就是不仅可以开关，还能调整逻辑。在不重启服务的情况下，也能及时调整业务逻辑。\n\n我都不知道jdk还有这个包呢。。。\n\n原来从java6开始，jdk就开始支持脚本语言。\n\n### 使用Java Script的方法\n\n1. 创建一个ScriptEngineManager对象\n2. 从管理器对象中获取ScriptEngine对象\n3. 使用脚本引擎的eval()方法来执行脚本\n\n```java\n\nScriptEngineManager manager = new ScriptEngineManager();\nScriptEngine engine = manager.getEngineByName(\"js\");\nString script = \"print('hello world')\";\ntry {\n    engine.eval(script);\n} catch (Exception e) {\n    e.printStackTrace();\n}\n```\n\n### 传递变量\n\nScriptEngine对象的put方法，可以传入参数。\n\n```java\nengine.put(\"a\", 3);\nengine.put(\"b\", 4);\n\nObject result = engine.eval(\"function add(a,b) {return a+b} add(a,b)\");\nSystem.out.println(\"result=\" + result);\n\n```\n\n","source":"_posts/2020-12-29-kongzheng1993-javax.script.md","raw":"---\ntitle: JDK自带的脚本引擎javax.script.ScriptEngine\nexcerpt: 'JDK'\ntags: [JDK]\ncategories: [JDK]\ncomments: true\ndate: 2020-12-29 10:30:52\n---\n\n最近在做一个需求，因为时免测的功能，所以要做一个开关，如果出现问题，不能影响之前的业务。像这种开关，我之前的办法就是在配置中心搞一个变量，如果有问题就修改开关变量的值。\n\n这次这个“开关“是一个同事来做的，他的方法是使用javax.script包下的脚本引擎，在配置中心搞一个javascript函数，将后台的java对象传入，执行js函数，得出结果。根据结果来决定后面代码的执行。\n\n这个方法就很灵活了，可以传入参数来计算，也就是不仅可以开关，还能调整逻辑。在不重启服务的情况下，也能及时调整业务逻辑。\n\n我都不知道jdk还有这个包呢。。。\n\n原来从java6开始，jdk就开始支持脚本语言。\n\n### 使用Java Script的方法\n\n1. 创建一个ScriptEngineManager对象\n2. 从管理器对象中获取ScriptEngine对象\n3. 使用脚本引擎的eval()方法来执行脚本\n\n```java\n\nScriptEngineManager manager = new ScriptEngineManager();\nScriptEngine engine = manager.getEngineByName(\"js\");\nString script = \"print('hello world')\";\ntry {\n    engine.eval(script);\n} catch (Exception e) {\n    e.printStackTrace();\n}\n```\n\n### 传递变量\n\nScriptEngine对象的put方法，可以传入参数。\n\n```java\nengine.put(\"a\", 3);\nengine.put(\"b\", 4);\n\nObject result = engine.eval(\"function add(a,b) {return a+b} add(a,b)\");\nSystem.out.println(\"result=\" + result);\n\n```\n\n","slug":"kongzheng1993-javax.script","published":1,"updated":"2023-03-08T07:05:58.808Z","layout":"post","photos":[],"link":"","_id":"clg0k2alg005tt26f1hin0ad0","content":"<p>最近在做一个需求，因为时免测的功能，所以要做一个开关，如果出现问题，不能影响之前的业务。像这种开关，我之前的办法就是在配置中心搞一个变量，如果有问题就修改开关变量的值。</p>\n<p>这次这个“开关“是一个同事来做的，他的方法是使用javax.script包下的脚本引擎，在配置中心搞一个javascript函数，将后台的java对象传入，执行js函数，得出结果。根据结果来决定后面代码的执行。</p>\n<p>这个方法就很灵活了，可以传入参数来计算，也就是不仅可以开关，还能调整逻辑。在不重启服务的情况下，也能及时调整业务逻辑。</p>\n<p>我都不知道jdk还有这个包呢。。。</p>\n<p>原来从java6开始，jdk就开始支持脚本语言。</p>\n<h3 id=\"使用Java-Script的方法\"><a href=\"#使用Java-Script的方法\" class=\"headerlink\" title=\"使用Java Script的方法\"></a>使用Java Script的方法</h3><ol>\n<li>创建一个ScriptEngineManager对象</li>\n<li>从管理器对象中获取ScriptEngine对象</li>\n<li>使用脚本引擎的eval()方法来执行脚本</li>\n</ol>\n<pre><code class=\"java\">\nScriptEngineManager manager = new ScriptEngineManager();\nScriptEngine engine = manager.getEngineByName(&quot;js&quot;);\nString script = &quot;print(&#39;hello world&#39;)&quot;;\ntry {\n    engine.eval(script);\n} catch (Exception e) {\n    e.printStackTrace();\n}</code></pre>\n<h3 id=\"传递变量\"><a href=\"#传递变量\" class=\"headerlink\" title=\"传递变量\"></a>传递变量</h3><p>ScriptEngine对象的put方法，可以传入参数。</p>\n<pre><code class=\"java\">engine.put(&quot;a&quot;, 3);\nengine.put(&quot;b&quot;, 4);\n\nObject result = engine.eval(&quot;function add(a,b) {return a+b} add(a,b)&quot;);\nSystem.out.println(&quot;result=&quot; + result);\n</code></pre>\n","site":{"data":{}},"more":"<p>最近在做一个需求，因为时免测的功能，所以要做一个开关，如果出现问题，不能影响之前的业务。像这种开关，我之前的办法就是在配置中心搞一个变量，如果有问题就修改开关变量的值。</p>\n<p>这次这个“开关“是一个同事来做的，他的方法是使用javax.script包下的脚本引擎，在配置中心搞一个javascript函数，将后台的java对象传入，执行js函数，得出结果。根据结果来决定后面代码的执行。</p>\n<p>这个方法就很灵活了，可以传入参数来计算，也就是不仅可以开关，还能调整逻辑。在不重启服务的情况下，也能及时调整业务逻辑。</p>\n<p>我都不知道jdk还有这个包呢。。。</p>\n<p>原来从java6开始，jdk就开始支持脚本语言。</p>\n<h3 id=\"使用Java-Script的方法\"><a href=\"#使用Java-Script的方法\" class=\"headerlink\" title=\"使用Java Script的方法\"></a>使用Java Script的方法</h3><ol>\n<li>创建一个ScriptEngineManager对象</li>\n<li>从管理器对象中获取ScriptEngine对象</li>\n<li>使用脚本引擎的eval()方法来执行脚本</li>\n</ol>\n<pre><code class=\"java\">\nScriptEngineManager manager = new ScriptEngineManager();\nScriptEngine engine = manager.getEngineByName(&quot;js&quot;);\nString script = &quot;print(&#39;hello world&#39;)&quot;;\ntry {\n    engine.eval(script);\n} catch (Exception e) {\n    e.printStackTrace();\n}</code></pre>\n<h3 id=\"传递变量\"><a href=\"#传递变量\" class=\"headerlink\" title=\"传递变量\"></a>传递变量</h3><p>ScriptEngine对象的put方法，可以传入参数。</p>\n<pre><code class=\"java\">engine.put(&quot;a&quot;, 3);\nengine.put(&quot;b&quot;, 4);\n\nObject result = engine.eval(&quot;function add(a,b) {return a+b} add(a,b)&quot;);\nSystem.out.println(&quot;result=&quot; + result);\n</code></pre>\n"},{"title":"避免浏览器缓存的技巧","excerpt":"","comments":1,"date":"2020-12-18T02:30:52.000Z","_content":"\n今天在做一个需求，需要做一个可复用的页面，最后准备用iframe来做。三下五除二，一个页面做完了。没什么难度，就是接受一个参数，跳转过来后调用接口，然后展示数据。\n照常在created方法里接收参数，然后调用接口，将返回数据赋值给data相关变量。\n\n自测的时候，发现页面只加载一次，每次都是第一次加载时的数据。\n\n静下心来思考，created只运行一次，页面也会缓存，所以才导致数据都是一样的。\n\n翻翻项目里其他的页面跳转，发现跳转页面的url后面都加了一个时间戳。学着加上，发现确实可以每次都重新加载了。\n\n难道这是什么默认的规范吗？url后如果有timestamp参数，浏览器会比对之前的时间戳，如果不一致就重新加载？\n\n尝试将参数名timestamp修改为t，依然可以每次重新加载。说明不是浏览器在检查请求url的参数列表。\n\n将url中的时间戳参数修改为`t=Math.random()`，依然可以每次都重新加载。\n\n<strong>恍然大悟，其实是浏览器每次请求的url都不一样了，每次都认为是要请求一个新的资源，所以每次都去请求！</strong>\n\n前端的知识点太匮乏了，需要多学习啊～","source":"_posts/2020-12-18-kongzheng1993-避免浏览器缓存的技巧.md","raw":"---\ntitle: 避免浏览器缓存的技巧\nexcerpt: 'Web'\ntags: [Web]\ncategories: [Web]\ncomments: true\ndate: 2020-12-18 10:30:52\n---\n\n今天在做一个需求，需要做一个可复用的页面，最后准备用iframe来做。三下五除二，一个页面做完了。没什么难度，就是接受一个参数，跳转过来后调用接口，然后展示数据。\n照常在created方法里接收参数，然后调用接口，将返回数据赋值给data相关变量。\n\n自测的时候，发现页面只加载一次，每次都是第一次加载时的数据。\n\n静下心来思考，created只运行一次，页面也会缓存，所以才导致数据都是一样的。\n\n翻翻项目里其他的页面跳转，发现跳转页面的url后面都加了一个时间戳。学着加上，发现确实可以每次都重新加载了。\n\n难道这是什么默认的规范吗？url后如果有timestamp参数，浏览器会比对之前的时间戳，如果不一致就重新加载？\n\n尝试将参数名timestamp修改为t，依然可以每次重新加载。说明不是浏览器在检查请求url的参数列表。\n\n将url中的时间戳参数修改为`t=Math.random()`，依然可以每次都重新加载。\n\n<strong>恍然大悟，其实是浏览器每次请求的url都不一样了，每次都认为是要请求一个新的资源，所以每次都去请求！</strong>\n\n前端的知识点太匮乏了，需要多学习啊～","slug":"kongzheng1993-避免浏览器缓存的技巧","published":1,"updated":"2023-03-08T07:05:58.808Z","layout":"post","photos":[],"link":"","_id":"clg0k2ali005xt26fumef1my1","content":"<p>今天在做一个需求，需要做一个可复用的页面，最后准备用iframe来做。三下五除二，一个页面做完了。没什么难度，就是接受一个参数，跳转过来后调用接口，然后展示数据。<br>照常在created方法里接收参数，然后调用接口，将返回数据赋值给data相关变量。</p>\n<p>自测的时候，发现页面只加载一次，每次都是第一次加载时的数据。</p>\n<p>静下心来思考，created只运行一次，页面也会缓存，所以才导致数据都是一样的。</p>\n<p>翻翻项目里其他的页面跳转，发现跳转页面的url后面都加了一个时间戳。学着加上，发现确实可以每次都重新加载了。</p>\n<p>难道这是什么默认的规范吗？url后如果有timestamp参数，浏览器会比对之前的时间戳，如果不一致就重新加载？</p>\n<p>尝试将参数名timestamp修改为t，依然可以每次重新加载。说明不是浏览器在检查请求url的参数列表。</p>\n<p>将url中的时间戳参数修改为<code>t=Math.random()</code>，依然可以每次都重新加载。</p>\n<p><strong>恍然大悟，其实是浏览器每次请求的url都不一样了，每次都认为是要请求一个新的资源，所以每次都去请求！</strong></p>\n<p>前端的知识点太匮乏了，需要多学习啊～</p>\n","site":{"data":{}},"more":"<p>今天在做一个需求，需要做一个可复用的页面，最后准备用iframe来做。三下五除二，一个页面做完了。没什么难度，就是接受一个参数，跳转过来后调用接口，然后展示数据。<br>照常在created方法里接收参数，然后调用接口，将返回数据赋值给data相关变量。</p>\n<p>自测的时候，发现页面只加载一次，每次都是第一次加载时的数据。</p>\n<p>静下心来思考，created只运行一次，页面也会缓存，所以才导致数据都是一样的。</p>\n<p>翻翻项目里其他的页面跳转，发现跳转页面的url后面都加了一个时间戳。学着加上，发现确实可以每次都重新加载了。</p>\n<p>难道这是什么默认的规范吗？url后如果有timestamp参数，浏览器会比对之前的时间戳，如果不一致就重新加载？</p>\n<p>尝试将参数名timestamp修改为t，依然可以每次重新加载。说明不是浏览器在检查请求url的参数列表。</p>\n<p>将url中的时间戳参数修改为<code>t=Math.random()</code>，依然可以每次都重新加载。</p>\n<p><strong>恍然大悟，其实是浏览器每次请求的url都不一样了，每次都认为是要请求一个新的资源，所以每次都去请求！</strong></p>\n<p>前端的知识点太匮乏了，需要多学习啊～</p>\n"},{"title":"PageHelper","excerpt":"","comments":1,"date":"2020-12-29T02:30:52.000Z","_content":"\n## 问题\n\n最近遇到了两次PageHelper分页失效的问题，第一次没记住，幸好当时跟同事讲了这个问题，第二次遇到问了他一下，才想起来。其实就是之前有分页查询，后面修改的时候在`PageHelper.startPage(pageRequest.getPageIndex(), pageRequest.getPageSize());`和执行sql之间，加入了其他的数据库查询操作。导致我们前面设置的分页信息，在第一次查询是使用并清空了，第二次真正想使用的时候就没有了。<strong>这就要求我们在真正想使用分页的查询前，设置分页信息，中间不能有其他的数据库操作。</strong>\n\n## 原理\n\n其实PageHelper的原理也简单，就是PageHelper有一个ThreadLocal对象`protected static final ThreadLocal<Page> LOCAL_PAGE = new ThreadLocal();`，每个请求过来的时候，我们手动去增加当前线程的分页信息，然后PageHelper的拦截器会拦截mybatis的query方法，在查询前count一下，然后将分页信息追加到我们到插叙sql中，返回分页数据，然后remove掉threadlocal里的分页信息。\n\n## 使用方法\n\n1. 引入分页插件\n\n```xml\n<dependency>\n    <groupId>com.github.pagehelper</groupId>\n    <artifactId>pagehelper</artifactId>\n    <version>最新版本</version>\n</dependency>\n```\n\n2. 配置拦截器插件\n\n    两种方式\n\n    - 在 MyBatis 配置 xml 中配置拦截器插件\n\n        ```xml\n        <!-- \n            plugins在配置文件中的位置必须符合要求，否则会报错，顺序如下:\n            properties?, settings?, \n            typeAliases?, typeHandlers?, \n            objectFactory?,objectWrapperFactory?, \n            plugins?, \n            environments?, databaseIdProvider?, mappers?\n        -->\n        <plugins>\n            <!-- com.github.pagehelper为PageHelper类所在包名 -->\n            <plugin interceptor=\"com.github.pagehelper.PageInterceptor\">\n                <!-- 使用下面的方式配置参数，后面会有所有的参数介绍 -->\n                <property name=\"param1\" value=\"value1\"/>\n            </plugin>\n        </plugins>\n        ```\n    - 在 Spring 配置文件中配置拦截器插件\n\n        ```xml\n        <bean id=\"sqlSessionFactory\" class=\"org.mybatis.spring.SqlSessionFactoryBean\">\n        <!-- 注意其他配置 -->\n        <property name=\"plugins\">\n            <array>\n            <bean class=\"com.github.pagehelper.PageInterceptor\">\n                <property name=\"properties\">\n                <!--使用下面的方式配置参数，一行配置一个 -->\n                <value>\n                    params=value1\n                </value>\n                </property>\n            </bean>\n            </array>\n        </property>\n        </bean>\n        ```\n\n3. 在业务代码中使用\n\n```java\n//第一种，RowBounds方式的调用\nList<User> list = sqlSession.selectList(\"x.y.selectIf\", null, new RowBounds(0, 10));\n\n//第二种，Mapper接口方式的调用，推荐这种使用方式。\nPageHelper.startPage(1, 10);\nList<User> list = userMapper.selectIf(1);\n\n//第三种，Mapper接口方式的调用，推荐这种使用方式。\nPageHelper.offsetPage(1, 10);\nList<User> list = userMapper.selectIf(1);\n\n//第四种，参数方法调用\n//存在以下 Mapper 接口方法，你不需要在 xml 处理后两个参数\npublic interface CountryMapper {\n    List<User> selectByPageNumSize(\n            @Param(\"user\") User user,\n            @Param(\"pageNum\") int pageNum, \n            @Param(\"pageSize\") int pageSize);\n}\n//配置supportMethodsArguments=true\n//在代码中直接调用：\nList<User> list = userMapper.selectByPageNumSize(user, 1, 10);\n\n//第五种，参数对象\n//如果 pageNum 和 pageSize 存在于 User 对象中，只要参数有值，也会被分页\n//有如下 User 对象\npublic class User {\n    //其他fields\n    //下面两个参数名和 params 配置的名字一致\n    private Integer pageNum;\n    private Integer pageSize;\n}\n//存在以下 Mapper 接口方法，你不需要在 xml 处理后两个参数\npublic interface CountryMapper {\n    List<User> selectByPageNumSize(User user);\n}\n//当 user 中的 pageNum!= null && pageSize!= null 时，会自动分页\nList<User> list = userMapper.selectByPageNumSize(user);\n\n//第六种，ISelect 接口方式\n//jdk6,7用法，创建接口\nPage<User> page = PageHelper.startPage(1, 10).doSelectPage(new ISelect() {\n    @Override\n    public void doSelect() {\n        userMapper.selectGroupBy();\n    }\n});\n//jdk8 lambda用法\nPage<User> page = PageHelper.startPage(1, 10).doSelectPage(()-> userMapper.selectGroupBy());\n\n//也可以直接返回PageInfo，注意doSelectPageInfo方法和doSelectPage\npageInfo = PageHelper.startPage(1, 10).doSelectPageInfo(new ISelect() {\n    @Override\n    public void doSelect() {\n        userMapper.selectGroupBy();\n    }\n});\n//对应的lambda用法\npageInfo = PageHelper.startPage(1, 10).doSelectPageInfo(() -> userMapper.selectGroupBy());\n\n//count查询，返回一个查询语句的count数\nlong total = PageHelper.count(new ISelect() {\n    @Override\n    public void doSelect() {\n        userMapper.selectLike(user);\n    }\n});\n//lambda\ntotal = PageHelper.count(()->userMapper.selectLike(user));\n```","source":"_posts/2021-01-04-kongzheng1993-PageHelper.md","raw":"---\ntitle: PageHelper\nexcerpt: '分页'\ntags: [分页]\ncategories: [分页]\ncomments: true\ndate: 2020-12-29 10:30:52\n---\n\n## 问题\n\n最近遇到了两次PageHelper分页失效的问题，第一次没记住，幸好当时跟同事讲了这个问题，第二次遇到问了他一下，才想起来。其实就是之前有分页查询，后面修改的时候在`PageHelper.startPage(pageRequest.getPageIndex(), pageRequest.getPageSize());`和执行sql之间，加入了其他的数据库查询操作。导致我们前面设置的分页信息，在第一次查询是使用并清空了，第二次真正想使用的时候就没有了。<strong>这就要求我们在真正想使用分页的查询前，设置分页信息，中间不能有其他的数据库操作。</strong>\n\n## 原理\n\n其实PageHelper的原理也简单，就是PageHelper有一个ThreadLocal对象`protected static final ThreadLocal<Page> LOCAL_PAGE = new ThreadLocal();`，每个请求过来的时候，我们手动去增加当前线程的分页信息，然后PageHelper的拦截器会拦截mybatis的query方法，在查询前count一下，然后将分页信息追加到我们到插叙sql中，返回分页数据，然后remove掉threadlocal里的分页信息。\n\n## 使用方法\n\n1. 引入分页插件\n\n```xml\n<dependency>\n    <groupId>com.github.pagehelper</groupId>\n    <artifactId>pagehelper</artifactId>\n    <version>最新版本</version>\n</dependency>\n```\n\n2. 配置拦截器插件\n\n    两种方式\n\n    - 在 MyBatis 配置 xml 中配置拦截器插件\n\n        ```xml\n        <!-- \n            plugins在配置文件中的位置必须符合要求，否则会报错，顺序如下:\n            properties?, settings?, \n            typeAliases?, typeHandlers?, \n            objectFactory?,objectWrapperFactory?, \n            plugins?, \n            environments?, databaseIdProvider?, mappers?\n        -->\n        <plugins>\n            <!-- com.github.pagehelper为PageHelper类所在包名 -->\n            <plugin interceptor=\"com.github.pagehelper.PageInterceptor\">\n                <!-- 使用下面的方式配置参数，后面会有所有的参数介绍 -->\n                <property name=\"param1\" value=\"value1\"/>\n            </plugin>\n        </plugins>\n        ```\n    - 在 Spring 配置文件中配置拦截器插件\n\n        ```xml\n        <bean id=\"sqlSessionFactory\" class=\"org.mybatis.spring.SqlSessionFactoryBean\">\n        <!-- 注意其他配置 -->\n        <property name=\"plugins\">\n            <array>\n            <bean class=\"com.github.pagehelper.PageInterceptor\">\n                <property name=\"properties\">\n                <!--使用下面的方式配置参数，一行配置一个 -->\n                <value>\n                    params=value1\n                </value>\n                </property>\n            </bean>\n            </array>\n        </property>\n        </bean>\n        ```\n\n3. 在业务代码中使用\n\n```java\n//第一种，RowBounds方式的调用\nList<User> list = sqlSession.selectList(\"x.y.selectIf\", null, new RowBounds(0, 10));\n\n//第二种，Mapper接口方式的调用，推荐这种使用方式。\nPageHelper.startPage(1, 10);\nList<User> list = userMapper.selectIf(1);\n\n//第三种，Mapper接口方式的调用，推荐这种使用方式。\nPageHelper.offsetPage(1, 10);\nList<User> list = userMapper.selectIf(1);\n\n//第四种，参数方法调用\n//存在以下 Mapper 接口方法，你不需要在 xml 处理后两个参数\npublic interface CountryMapper {\n    List<User> selectByPageNumSize(\n            @Param(\"user\") User user,\n            @Param(\"pageNum\") int pageNum, \n            @Param(\"pageSize\") int pageSize);\n}\n//配置supportMethodsArguments=true\n//在代码中直接调用：\nList<User> list = userMapper.selectByPageNumSize(user, 1, 10);\n\n//第五种，参数对象\n//如果 pageNum 和 pageSize 存在于 User 对象中，只要参数有值，也会被分页\n//有如下 User 对象\npublic class User {\n    //其他fields\n    //下面两个参数名和 params 配置的名字一致\n    private Integer pageNum;\n    private Integer pageSize;\n}\n//存在以下 Mapper 接口方法，你不需要在 xml 处理后两个参数\npublic interface CountryMapper {\n    List<User> selectByPageNumSize(User user);\n}\n//当 user 中的 pageNum!= null && pageSize!= null 时，会自动分页\nList<User> list = userMapper.selectByPageNumSize(user);\n\n//第六种，ISelect 接口方式\n//jdk6,7用法，创建接口\nPage<User> page = PageHelper.startPage(1, 10).doSelectPage(new ISelect() {\n    @Override\n    public void doSelect() {\n        userMapper.selectGroupBy();\n    }\n});\n//jdk8 lambda用法\nPage<User> page = PageHelper.startPage(1, 10).doSelectPage(()-> userMapper.selectGroupBy());\n\n//也可以直接返回PageInfo，注意doSelectPageInfo方法和doSelectPage\npageInfo = PageHelper.startPage(1, 10).doSelectPageInfo(new ISelect() {\n    @Override\n    public void doSelect() {\n        userMapper.selectGroupBy();\n    }\n});\n//对应的lambda用法\npageInfo = PageHelper.startPage(1, 10).doSelectPageInfo(() -> userMapper.selectGroupBy());\n\n//count查询，返回一个查询语句的count数\nlong total = PageHelper.count(new ISelect() {\n    @Override\n    public void doSelect() {\n        userMapper.selectLike(user);\n    }\n});\n//lambda\ntotal = PageHelper.count(()->userMapper.selectLike(user));\n```","slug":"kongzheng1993-PageHelper","published":1,"updated":"2023-03-08T07:05:58.808Z","layout":"post","photos":[],"link":"","_id":"clg0k2alo0060t26f301wqmii","content":"<h2 id=\"问题\"><a href=\"#问题\" class=\"headerlink\" title=\"问题\"></a>问题</h2><p>最近遇到了两次PageHelper分页失效的问题，第一次没记住，幸好当时跟同事讲了这个问题，第二次遇到问了他一下，才想起来。其实就是之前有分页查询，后面修改的时候在<code>PageHelper.startPage(pageRequest.getPageIndex(), pageRequest.getPageSize());</code>和执行sql之间，加入了其他的数据库查询操作。导致我们前面设置的分页信息，在第一次查询是使用并清空了，第二次真正想使用的时候就没有了。<strong>这就要求我们在真正想使用分页的查询前，设置分页信息，中间不能有其他的数据库操作。</strong></p>\n<h2 id=\"原理\"><a href=\"#原理\" class=\"headerlink\" title=\"原理\"></a>原理</h2><p>其实PageHelper的原理也简单，就是PageHelper有一个ThreadLocal对象<code>protected static final ThreadLocal&lt;Page&gt; LOCAL_PAGE = new ThreadLocal();</code>，每个请求过来的时候，我们手动去增加当前线程的分页信息，然后PageHelper的拦截器会拦截mybatis的query方法，在查询前count一下，然后将分页信息追加到我们到插叙sql中，返回分页数据，然后remove掉threadlocal里的分页信息。</p>\n<h2 id=\"使用方法\"><a href=\"#使用方法\" class=\"headerlink\" title=\"使用方法\"></a>使用方法</h2><ol>\n<li>引入分页插件</li>\n</ol>\n<pre><code class=\"xml\">&lt;dependency&gt;\n    &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt;\n    &lt;artifactId&gt;pagehelper&lt;/artifactId&gt;\n    &lt;version&gt;最新版本&lt;/version&gt;\n&lt;/dependency&gt;</code></pre>\n<ol start=\"2\">\n<li><p>配置拦截器插件</p>\n<p> 两种方式</p>\n<ul>\n<li><p>在 MyBatis 配置 xml 中配置拦截器插件</p>\n<pre><code class=\"xml\">  &lt;!-- \n      plugins在配置文件中的位置必须符合要求，否则会报错，顺序如下:\n      properties?, settings?, \n      typeAliases?, typeHandlers?, \n      objectFactory?,objectWrapperFactory?, \n      plugins?, \n      environments?, databaseIdProvider?, mappers?\n  --&gt;\n  &lt;plugins&gt;\n      &lt;!-- com.github.pagehelper为PageHelper类所在包名 --&gt;\n      &lt;plugin interceptor=&quot;com.github.pagehelper.PageInterceptor&quot;&gt;\n          &lt;!-- 使用下面的方式配置参数，后面会有所有的参数介绍 --&gt;\n          &lt;property name=&quot;param1&quot; value=&quot;value1&quot;/&gt;\n      &lt;/plugin&gt;\n  &lt;/plugins&gt;</code></pre>\n</li>\n<li><p>在 Spring 配置文件中配置拦截器插件</p>\n<pre><code class=\"xml\">  &lt;bean id=&quot;sqlSessionFactory&quot; class=&quot;org.mybatis.spring.SqlSessionFactoryBean&quot;&gt;\n  &lt;!-- 注意其他配置 --&gt;\n  &lt;property name=&quot;plugins&quot;&gt;\n      &lt;array&gt;\n      &lt;bean class=&quot;com.github.pagehelper.PageInterceptor&quot;&gt;\n          &lt;property name=&quot;properties&quot;&gt;\n          &lt;!--使用下面的方式配置参数，一行配置一个 --&gt;\n          &lt;value&gt;\n              params=value1\n          &lt;/value&gt;\n          &lt;/property&gt;\n      &lt;/bean&gt;\n      &lt;/array&gt;\n  &lt;/property&gt;\n  &lt;/bean&gt;</code></pre>\n</li>\n</ul>\n</li>\n<li><p>在业务代码中使用</p>\n</li>\n</ol>\n<pre><code class=\"java\">//第一种，RowBounds方式的调用\nList&lt;User&gt; list = sqlSession.selectList(&quot;x.y.selectIf&quot;, null, new RowBounds(0, 10));\n\n//第二种，Mapper接口方式的调用，推荐这种使用方式。\nPageHelper.startPage(1, 10);\nList&lt;User&gt; list = userMapper.selectIf(1);\n\n//第三种，Mapper接口方式的调用，推荐这种使用方式。\nPageHelper.offsetPage(1, 10);\nList&lt;User&gt; list = userMapper.selectIf(1);\n\n//第四种，参数方法调用\n//存在以下 Mapper 接口方法，你不需要在 xml 处理后两个参数\npublic interface CountryMapper {\n    List&lt;User&gt; selectByPageNumSize(\n            @Param(&quot;user&quot;) User user,\n            @Param(&quot;pageNum&quot;) int pageNum, \n            @Param(&quot;pageSize&quot;) int pageSize);\n}\n//配置supportMethodsArguments=true\n//在代码中直接调用：\nList&lt;User&gt; list = userMapper.selectByPageNumSize(user, 1, 10);\n\n//第五种，参数对象\n//如果 pageNum 和 pageSize 存在于 User 对象中，只要参数有值，也会被分页\n//有如下 User 对象\npublic class User {\n    //其他fields\n    //下面两个参数名和 params 配置的名字一致\n    private Integer pageNum;\n    private Integer pageSize;\n}\n//存在以下 Mapper 接口方法，你不需要在 xml 处理后两个参数\npublic interface CountryMapper {\n    List&lt;User&gt; selectByPageNumSize(User user);\n}\n//当 user 中的 pageNum!= null &amp;&amp; pageSize!= null 时，会自动分页\nList&lt;User&gt; list = userMapper.selectByPageNumSize(user);\n\n//第六种，ISelect 接口方式\n//jdk6,7用法，创建接口\nPage&lt;User&gt; page = PageHelper.startPage(1, 10).doSelectPage(new ISelect() {\n    @Override\n    public void doSelect() {\n        userMapper.selectGroupBy();\n    }\n});\n//jdk8 lambda用法\nPage&lt;User&gt; page = PageHelper.startPage(1, 10).doSelectPage(()-&gt; userMapper.selectGroupBy());\n\n//也可以直接返回PageInfo，注意doSelectPageInfo方法和doSelectPage\npageInfo = PageHelper.startPage(1, 10).doSelectPageInfo(new ISelect() {\n    @Override\n    public void doSelect() {\n        userMapper.selectGroupBy();\n    }\n});\n//对应的lambda用法\npageInfo = PageHelper.startPage(1, 10).doSelectPageInfo(() -&gt; userMapper.selectGroupBy());\n\n//count查询，返回一个查询语句的count数\nlong total = PageHelper.count(new ISelect() {\n    @Override\n    public void doSelect() {\n        userMapper.selectLike(user);\n    }\n});\n//lambda\ntotal = PageHelper.count(()-&gt;userMapper.selectLike(user));</code></pre>\n","site":{"data":{}},"more":"<h2 id=\"问题\"><a href=\"#问题\" class=\"headerlink\" title=\"问题\"></a>问题</h2><p>最近遇到了两次PageHelper分页失效的问题，第一次没记住，幸好当时跟同事讲了这个问题，第二次遇到问了他一下，才想起来。其实就是之前有分页查询，后面修改的时候在<code>PageHelper.startPage(pageRequest.getPageIndex(), pageRequest.getPageSize());</code>和执行sql之间，加入了其他的数据库查询操作。导致我们前面设置的分页信息，在第一次查询是使用并清空了，第二次真正想使用的时候就没有了。<strong>这就要求我们在真正想使用分页的查询前，设置分页信息，中间不能有其他的数据库操作。</strong></p>\n<h2 id=\"原理\"><a href=\"#原理\" class=\"headerlink\" title=\"原理\"></a>原理</h2><p>其实PageHelper的原理也简单，就是PageHelper有一个ThreadLocal对象<code>protected static final ThreadLocal&lt;Page&gt; LOCAL_PAGE = new ThreadLocal();</code>，每个请求过来的时候，我们手动去增加当前线程的分页信息，然后PageHelper的拦截器会拦截mybatis的query方法，在查询前count一下，然后将分页信息追加到我们到插叙sql中，返回分页数据，然后remove掉threadlocal里的分页信息。</p>\n<h2 id=\"使用方法\"><a href=\"#使用方法\" class=\"headerlink\" title=\"使用方法\"></a>使用方法</h2><ol>\n<li>引入分页插件</li>\n</ol>\n<pre><code class=\"xml\">&lt;dependency&gt;\n    &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt;\n    &lt;artifactId&gt;pagehelper&lt;/artifactId&gt;\n    &lt;version&gt;最新版本&lt;/version&gt;\n&lt;/dependency&gt;</code></pre>\n<ol start=\"2\">\n<li><p>配置拦截器插件</p>\n<p> 两种方式</p>\n<ul>\n<li><p>在 MyBatis 配置 xml 中配置拦截器插件</p>\n<pre><code class=\"xml\">  &lt;!-- \n      plugins在配置文件中的位置必须符合要求，否则会报错，顺序如下:\n      properties?, settings?, \n      typeAliases?, typeHandlers?, \n      objectFactory?,objectWrapperFactory?, \n      plugins?, \n      environments?, databaseIdProvider?, mappers?\n  --&gt;\n  &lt;plugins&gt;\n      &lt;!-- com.github.pagehelper为PageHelper类所在包名 --&gt;\n      &lt;plugin interceptor=&quot;com.github.pagehelper.PageInterceptor&quot;&gt;\n          &lt;!-- 使用下面的方式配置参数，后面会有所有的参数介绍 --&gt;\n          &lt;property name=&quot;param1&quot; value=&quot;value1&quot;/&gt;\n      &lt;/plugin&gt;\n  &lt;/plugins&gt;</code></pre>\n</li>\n<li><p>在 Spring 配置文件中配置拦截器插件</p>\n<pre><code class=\"xml\">  &lt;bean id=&quot;sqlSessionFactory&quot; class=&quot;org.mybatis.spring.SqlSessionFactoryBean&quot;&gt;\n  &lt;!-- 注意其他配置 --&gt;\n  &lt;property name=&quot;plugins&quot;&gt;\n      &lt;array&gt;\n      &lt;bean class=&quot;com.github.pagehelper.PageInterceptor&quot;&gt;\n          &lt;property name=&quot;properties&quot;&gt;\n          &lt;!--使用下面的方式配置参数，一行配置一个 --&gt;\n          &lt;value&gt;\n              params=value1\n          &lt;/value&gt;\n          &lt;/property&gt;\n      &lt;/bean&gt;\n      &lt;/array&gt;\n  &lt;/property&gt;\n  &lt;/bean&gt;</code></pre>\n</li>\n</ul>\n</li>\n<li><p>在业务代码中使用</p>\n</li>\n</ol>\n<pre><code class=\"java\">//第一种，RowBounds方式的调用\nList&lt;User&gt; list = sqlSession.selectList(&quot;x.y.selectIf&quot;, null, new RowBounds(0, 10));\n\n//第二种，Mapper接口方式的调用，推荐这种使用方式。\nPageHelper.startPage(1, 10);\nList&lt;User&gt; list = userMapper.selectIf(1);\n\n//第三种，Mapper接口方式的调用，推荐这种使用方式。\nPageHelper.offsetPage(1, 10);\nList&lt;User&gt; list = userMapper.selectIf(1);\n\n//第四种，参数方法调用\n//存在以下 Mapper 接口方法，你不需要在 xml 处理后两个参数\npublic interface CountryMapper {\n    List&lt;User&gt; selectByPageNumSize(\n            @Param(&quot;user&quot;) User user,\n            @Param(&quot;pageNum&quot;) int pageNum, \n            @Param(&quot;pageSize&quot;) int pageSize);\n}\n//配置supportMethodsArguments=true\n//在代码中直接调用：\nList&lt;User&gt; list = userMapper.selectByPageNumSize(user, 1, 10);\n\n//第五种，参数对象\n//如果 pageNum 和 pageSize 存在于 User 对象中，只要参数有值，也会被分页\n//有如下 User 对象\npublic class User {\n    //其他fields\n    //下面两个参数名和 params 配置的名字一致\n    private Integer pageNum;\n    private Integer pageSize;\n}\n//存在以下 Mapper 接口方法，你不需要在 xml 处理后两个参数\npublic interface CountryMapper {\n    List&lt;User&gt; selectByPageNumSize(User user);\n}\n//当 user 中的 pageNum!= null &amp;&amp; pageSize!= null 时，会自动分页\nList&lt;User&gt; list = userMapper.selectByPageNumSize(user);\n\n//第六种，ISelect 接口方式\n//jdk6,7用法，创建接口\nPage&lt;User&gt; page = PageHelper.startPage(1, 10).doSelectPage(new ISelect() {\n    @Override\n    public void doSelect() {\n        userMapper.selectGroupBy();\n    }\n});\n//jdk8 lambda用法\nPage&lt;User&gt; page = PageHelper.startPage(1, 10).doSelectPage(()-&gt; userMapper.selectGroupBy());\n\n//也可以直接返回PageInfo，注意doSelectPageInfo方法和doSelectPage\npageInfo = PageHelper.startPage(1, 10).doSelectPageInfo(new ISelect() {\n    @Override\n    public void doSelect() {\n        userMapper.selectGroupBy();\n    }\n});\n//对应的lambda用法\npageInfo = PageHelper.startPage(1, 10).doSelectPageInfo(() -&gt; userMapper.selectGroupBy());\n\n//count查询，返回一个查询语句的count数\nlong total = PageHelper.count(new ISelect() {\n    @Override\n    public void doSelect() {\n        userMapper.selectLike(user);\n    }\n});\n//lambda\ntotal = PageHelper.count(()-&gt;userMapper.selectLike(user));</code></pre>\n"},{"title":"包装类存在的意义是什么？","excerpt":"","comments":1,"date":"2021-01-07T02:30:52.000Z","_content":"\nJava中有八大基本数据类型：\n\n- byte：8位，最大存储数据量是255，存放的数据范围是-128~127之间。\n\n- short：16位，最大数据存储量是65536，数据范围是-32768~32767之间。\n\n- int：32位，最大数据存储容量是2的32次方减1，数据范围是负的2的31次方到正的2的31次方减1。\n\n- long：64位，最大数据存储容量是2的64次方减1，数据范围为负的2的63次方到正的2的63次方减1。\n\n- float：32位，数据范围在3.4e-45~1.4e38，直接赋值时必须在数字后加上f或F。\n\n- double：64位，数据范围在4.9e-324~1.8e308，赋值时可以加d或D也可以不加。\n\n- boolean：只有true和false两个取值。\n\n- char：16位，存储Unicode码，用单引号赋值。\n\n可是既然存在了基本数据类型，为什么还要设计对应的包装类型呢？\n\n<strong>什么？你说他是乱设计的？他可不是乱设计的，训练有素，有备而来！</strong>\n\n1. 丰富基本类型的操作\n    \n    Java是面向对象的编程，有了包装类型可以使基本数据类型有了对象的性质，丰富了其操作。\n2. 可以添加进集合中\n    \n    在集合容器（如List，Map）中不能添加基本数据类型，只能添加引用类型的数据，使用包装类型后可以添加进集合\n3. 框架开发中结果准确\n    \n    基本数据类型有初始值，如int默认为0，boolean默认为false。如在spring框架开发中，查询数据库的id结果若为null，传递给bean时int类型就会默认为0。id为null说明数据不存在，而id为0说明有数据，两者意义不同。使用Integer包装类型结果就会对应为null。\n","source":"_posts/2021-01-07-kongzheng1993-包装类型存在的意义.md","raw":"---\ntitle: 包装类存在的意义是什么？\nexcerpt: 'Java'\ntags: [Java]\ncategories: [Java]\ncomments: true\ndate: 2021-01-07 10:30:52\n---\n\nJava中有八大基本数据类型：\n\n- byte：8位，最大存储数据量是255，存放的数据范围是-128~127之间。\n\n- short：16位，最大数据存储量是65536，数据范围是-32768~32767之间。\n\n- int：32位，最大数据存储容量是2的32次方减1，数据范围是负的2的31次方到正的2的31次方减1。\n\n- long：64位，最大数据存储容量是2的64次方减1，数据范围为负的2的63次方到正的2的63次方减1。\n\n- float：32位，数据范围在3.4e-45~1.4e38，直接赋值时必须在数字后加上f或F。\n\n- double：64位，数据范围在4.9e-324~1.8e308，赋值时可以加d或D也可以不加。\n\n- boolean：只有true和false两个取值。\n\n- char：16位，存储Unicode码，用单引号赋值。\n\n可是既然存在了基本数据类型，为什么还要设计对应的包装类型呢？\n\n<strong>什么？你说他是乱设计的？他可不是乱设计的，训练有素，有备而来！</strong>\n\n1. 丰富基本类型的操作\n    \n    Java是面向对象的编程，有了包装类型可以使基本数据类型有了对象的性质，丰富了其操作。\n2. 可以添加进集合中\n    \n    在集合容器（如List，Map）中不能添加基本数据类型，只能添加引用类型的数据，使用包装类型后可以添加进集合\n3. 框架开发中结果准确\n    \n    基本数据类型有初始值，如int默认为0，boolean默认为false。如在spring框架开发中，查询数据库的id结果若为null，传递给bean时int类型就会默认为0。id为null说明数据不存在，而id为0说明有数据，两者意义不同。使用Integer包装类型结果就会对应为null。\n","slug":"kongzheng1993-包装类型存在的意义","published":1,"updated":"2023-03-08T07:05:58.808Z","layout":"post","photos":[],"link":"","_id":"clg0k2alo0063t26fz5c18acl","content":"<p>Java中有八大基本数据类型：</p>\n<ul>\n<li><p>byte：8位，最大存储数据量是255，存放的数据范围是-128~127之间。</p>\n</li>\n<li><p>short：16位，最大数据存储量是65536，数据范围是-32768~32767之间。</p>\n</li>\n<li><p>int：32位，最大数据存储容量是2的32次方减1，数据范围是负的2的31次方到正的2的31次方减1。</p>\n</li>\n<li><p>long：64位，最大数据存储容量是2的64次方减1，数据范围为负的2的63次方到正的2的63次方减1。</p>\n</li>\n<li><p>float：32位，数据范围在3.4e-45~1.4e38，直接赋值时必须在数字后加上f或F。</p>\n</li>\n<li><p>double：64位，数据范围在4.9e-324~1.8e308，赋值时可以加d或D也可以不加。</p>\n</li>\n<li><p>boolean：只有true和false两个取值。</p>\n</li>\n<li><p>char：16位，存储Unicode码，用单引号赋值。</p>\n</li>\n</ul>\n<p>可是既然存在了基本数据类型，为什么还要设计对应的包装类型呢？</p>\n<p><strong>什么？你说他是乱设计的？他可不是乱设计的，训练有素，有备而来！</strong></p>\n<ol>\n<li><p>丰富基本类型的操作</p>\n<p> Java是面向对象的编程，有了包装类型可以使基本数据类型有了对象的性质，丰富了其操作。</p>\n</li>\n<li><p>可以添加进集合中</p>\n<p> 在集合容器（如List，Map）中不能添加基本数据类型，只能添加引用类型的数据，使用包装类型后可以添加进集合</p>\n</li>\n<li><p>框架开发中结果准确</p>\n<p> 基本数据类型有初始值，如int默认为0，boolean默认为false。如在spring框架开发中，查询数据库的id结果若为null，传递给bean时int类型就会默认为0。id为null说明数据不存在，而id为0说明有数据，两者意义不同。使用Integer包装类型结果就会对应为null。</p>\n</li>\n</ol>\n","site":{"data":{}},"more":"<p>Java中有八大基本数据类型：</p>\n<ul>\n<li><p>byte：8位，最大存储数据量是255，存放的数据范围是-128~127之间。</p>\n</li>\n<li><p>short：16位，最大数据存储量是65536，数据范围是-32768~32767之间。</p>\n</li>\n<li><p>int：32位，最大数据存储容量是2的32次方减1，数据范围是负的2的31次方到正的2的31次方减1。</p>\n</li>\n<li><p>long：64位，最大数据存储容量是2的64次方减1，数据范围为负的2的63次方到正的2的63次方减1。</p>\n</li>\n<li><p>float：32位，数据范围在3.4e-45~1.4e38，直接赋值时必须在数字后加上f或F。</p>\n</li>\n<li><p>double：64位，数据范围在4.9e-324~1.8e308，赋值时可以加d或D也可以不加。</p>\n</li>\n<li><p>boolean：只有true和false两个取值。</p>\n</li>\n<li><p>char：16位，存储Unicode码，用单引号赋值。</p>\n</li>\n</ul>\n<p>可是既然存在了基本数据类型，为什么还要设计对应的包装类型呢？</p>\n<p><strong>什么？你说他是乱设计的？他可不是乱设计的，训练有素，有备而来！</strong></p>\n<ol>\n<li><p>丰富基本类型的操作</p>\n<p> Java是面向对象的编程，有了包装类型可以使基本数据类型有了对象的性质，丰富了其操作。</p>\n</li>\n<li><p>可以添加进集合中</p>\n<p> 在集合容器（如List，Map）中不能添加基本数据类型，只能添加引用类型的数据，使用包装类型后可以添加进集合</p>\n</li>\n<li><p>框架开发中结果准确</p>\n<p> 基本数据类型有初始值，如int默认为0，boolean默认为false。如在spring框架开发中，查询数据库的id结果若为null，传递给bean时int类型就会默认为0。id为null说明数据不存在，而id为0说明有数据，两者意义不同。使用Integer包装类型结果就会对应为null。</p>\n</li>\n</ol>\n"},{"title":"Vue学习笔记","excerpt":"","comments":1,"date":"2021-02-05T11:30:52.000Z","_content":"\n\n\n","source":"_posts/2021-02-05-kongzheng1993-Vue学习笔记.md","raw":"---\ntitle: Vue学习笔记\nexcerpt: 'Java'\ntags: [Java]\ncategories: [Java]\ncomments: true\ndate: 2021-02-05 19:30:52\n---\n\n\n\n","slug":"kongzheng1993-Vue学习笔记","published":1,"updated":"2023-03-08T07:05:58.809Z","layout":"post","photos":[],"link":"","_id":"clg0k2alp0067t26fgp718a9d","content":"","site":{"data":{}},"more":""},{"title":"Java8 Lambda","excerpt":"","comments":1,"date":"2021-01-21T02:30:52.000Z","_content":"\n## 四大内置核心函数式接口\n\n1. Consumer<T>： 消费型接口\n\n```java\n\nvoid accept(T t);\n\n```\n\n2. Supplier<T>： 供给型接口\n\n```java\n\nT get();\n\n```\n\n3. Function<T, R>：函数型接口\n\n```java\n\nR apply(T t);\n\n```\n\n4. Predicate<T>： 断言型接口\n\n```java\n\nboolean test(T t);\n\n```\n\n\n## 方法引用\n\n如果Lambda体中的内容已经有方法实现了，可以使用方法引用\n\n### 语法格式\n\n1. 对象::实例方法名\n2. 类::静态方法名\n3. 类::实例方法名\n\n## Stream\n\n流（Stream）： 是数据通道，用于操作数据源（这里指的是集合、数组等）所生成的元素序列。\n\n- Stream不会存储元素\n- Stream不会改变源对象，而是生成一个持有结果的新Stream\n- Stream操作是延迟执行的。这意味着他们会等到需要结果的时候再执行\n\n### Stream的操作步骤\n\n1. 创建Stream\n2. 中间操作\n3. 终止操作，产生结果。\n\n```java\n\n//1. 从集合Colllection提供的stream()或parallelStream()创建流\nList<String> list = new ArrayList<>();\nStream<String> stream1 = list.stream();\n//2. 通过数组Arrays的静态方法stream()获取数组流\nString[] str = new String[10];\nStream<String> stream2 = Arrays.stream(str);\n//3. 通过Stream类中的静态方法of()\nStream<String> stream3 = Stream.of(\"1\", \"2\", \"3\");\n//4. 创建无限流\n//迭代\nStream<Integer> stream4 = Stream.iterate(0, (x) -> x + 2);\nstream4.limit(10).forEach(System.out::println);\n//生成\nStream.generate(() -> Math.random()).limit(5).forEach(System.out::println);\n\n```\n\n\n","source":"_posts/2021-01-21-kongzheng1993-Java8Lambda.md","raw":"---\ntitle: Java8 Lambda\nexcerpt: 'Java'\ntags: [Java]\ncategories: [Java]\ncomments: true\ndate: 2021-01-21 10:30:52\n---\n\n## 四大内置核心函数式接口\n\n1. Consumer<T>： 消费型接口\n\n```java\n\nvoid accept(T t);\n\n```\n\n2. Supplier<T>： 供给型接口\n\n```java\n\nT get();\n\n```\n\n3. Function<T, R>：函数型接口\n\n```java\n\nR apply(T t);\n\n```\n\n4. Predicate<T>： 断言型接口\n\n```java\n\nboolean test(T t);\n\n```\n\n\n## 方法引用\n\n如果Lambda体中的内容已经有方法实现了，可以使用方法引用\n\n### 语法格式\n\n1. 对象::实例方法名\n2. 类::静态方法名\n3. 类::实例方法名\n\n## Stream\n\n流（Stream）： 是数据通道，用于操作数据源（这里指的是集合、数组等）所生成的元素序列。\n\n- Stream不会存储元素\n- Stream不会改变源对象，而是生成一个持有结果的新Stream\n- Stream操作是延迟执行的。这意味着他们会等到需要结果的时候再执行\n\n### Stream的操作步骤\n\n1. 创建Stream\n2. 中间操作\n3. 终止操作，产生结果。\n\n```java\n\n//1. 从集合Colllection提供的stream()或parallelStream()创建流\nList<String> list = new ArrayList<>();\nStream<String> stream1 = list.stream();\n//2. 通过数组Arrays的静态方法stream()获取数组流\nString[] str = new String[10];\nStream<String> stream2 = Arrays.stream(str);\n//3. 通过Stream类中的静态方法of()\nStream<String> stream3 = Stream.of(\"1\", \"2\", \"3\");\n//4. 创建无限流\n//迭代\nStream<Integer> stream4 = Stream.iterate(0, (x) -> x + 2);\nstream4.limit(10).forEach(System.out::println);\n//生成\nStream.generate(() -> Math.random()).limit(5).forEach(System.out::println);\n\n```\n\n\n","slug":"kongzheng1993-Java8Lambda","published":1,"updated":"2023-03-08T07:05:58.808Z","layout":"post","photos":[],"link":"","_id":"clg0k2als0069t26f4qf1nwab","content":"<h2 id=\"四大内置核心函数式接口\"><a href=\"#四大内置核心函数式接口\" class=\"headerlink\" title=\"四大内置核心函数式接口\"></a>四大内置核心函数式接口</h2><ol>\n<li>Consumer<t>： 消费型接口</t></li>\n</ol>\n<pre><code class=\"java\">\nvoid accept(T t);\n</code></pre>\n<ol start=\"2\">\n<li>Supplier<t>： 供给型接口</t></li>\n</ol>\n<pre><code class=\"java\">\nT get();\n</code></pre>\n<ol start=\"3\">\n<li>Function&lt;T, R&gt;：函数型接口</li>\n</ol>\n<pre><code class=\"java\">\nR apply(T t);\n</code></pre>\n<ol start=\"4\">\n<li>Predicate<t>： 断言型接口</t></li>\n</ol>\n<pre><code class=\"java\">\nboolean test(T t);\n</code></pre>\n<h2 id=\"方法引用\"><a href=\"#方法引用\" class=\"headerlink\" title=\"方法引用\"></a>方法引用</h2><p>如果Lambda体中的内容已经有方法实现了，可以使用方法引用</p>\n<h3 id=\"语法格式\"><a href=\"#语法格式\" class=\"headerlink\" title=\"语法格式\"></a>语法格式</h3><ol>\n<li>对象::实例方法名</li>\n<li>类::静态方法名</li>\n<li>类::实例方法名</li>\n</ol>\n<h2 id=\"Stream\"><a href=\"#Stream\" class=\"headerlink\" title=\"Stream\"></a>Stream</h2><p>流（Stream）： 是数据通道，用于操作数据源（这里指的是集合、数组等）所生成的元素序列。</p>\n<ul>\n<li>Stream不会存储元素</li>\n<li>Stream不会改变源对象，而是生成一个持有结果的新Stream</li>\n<li>Stream操作是延迟执行的。这意味着他们会等到需要结果的时候再执行</li>\n</ul>\n<h3 id=\"Stream的操作步骤\"><a href=\"#Stream的操作步骤\" class=\"headerlink\" title=\"Stream的操作步骤\"></a>Stream的操作步骤</h3><ol>\n<li>创建Stream</li>\n<li>中间操作</li>\n<li>终止操作，产生结果。</li>\n</ol>\n<pre><code class=\"java\">\n//1. 从集合Colllection提供的stream()或parallelStream()创建流\nList&lt;String&gt; list = new ArrayList&lt;&gt;();\nStream&lt;String&gt; stream1 = list.stream();\n//2. 通过数组Arrays的静态方法stream()获取数组流\nString[] str = new String[10];\nStream&lt;String&gt; stream2 = Arrays.stream(str);\n//3. 通过Stream类中的静态方法of()\nStream&lt;String&gt; stream3 = Stream.of(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;);\n//4. 创建无限流\n//迭代\nStream&lt;Integer&gt; stream4 = Stream.iterate(0, (x) -&gt; x + 2);\nstream4.limit(10).forEach(System.out::println);\n//生成\nStream.generate(() -&gt; Math.random()).limit(5).forEach(System.out::println);\n</code></pre>\n","site":{"data":{}},"more":"<h2 id=\"四大内置核心函数式接口\"><a href=\"#四大内置核心函数式接口\" class=\"headerlink\" title=\"四大内置核心函数式接口\"></a>四大内置核心函数式接口</h2><ol>\n<li>Consumer<t>： 消费型接口</t></li>\n</ol>\n<pre><code class=\"java\">\nvoid accept(T t);\n</code></pre>\n<ol start=\"2\">\n<li>Supplier<t>： 供给型接口</t></li>\n</ol>\n<pre><code class=\"java\">\nT get();\n</code></pre>\n<ol start=\"3\">\n<li>Function&lt;T, R&gt;：函数型接口</li>\n</ol>\n<pre><code class=\"java\">\nR apply(T t);\n</code></pre>\n<ol start=\"4\">\n<li>Predicate<t>： 断言型接口</t></li>\n</ol>\n<pre><code class=\"java\">\nboolean test(T t);\n</code></pre>\n<h2 id=\"方法引用\"><a href=\"#方法引用\" class=\"headerlink\" title=\"方法引用\"></a>方法引用</h2><p>如果Lambda体中的内容已经有方法实现了，可以使用方法引用</p>\n<h3 id=\"语法格式\"><a href=\"#语法格式\" class=\"headerlink\" title=\"语法格式\"></a>语法格式</h3><ol>\n<li>对象::实例方法名</li>\n<li>类::静态方法名</li>\n<li>类::实例方法名</li>\n</ol>\n<h2 id=\"Stream\"><a href=\"#Stream\" class=\"headerlink\" title=\"Stream\"></a>Stream</h2><p>流（Stream）： 是数据通道，用于操作数据源（这里指的是集合、数组等）所生成的元素序列。</p>\n<ul>\n<li>Stream不会存储元素</li>\n<li>Stream不会改变源对象，而是生成一个持有结果的新Stream</li>\n<li>Stream操作是延迟执行的。这意味着他们会等到需要结果的时候再执行</li>\n</ul>\n<h3 id=\"Stream的操作步骤\"><a href=\"#Stream的操作步骤\" class=\"headerlink\" title=\"Stream的操作步骤\"></a>Stream的操作步骤</h3><ol>\n<li>创建Stream</li>\n<li>中间操作</li>\n<li>终止操作，产生结果。</li>\n</ol>\n<pre><code class=\"java\">\n//1. 从集合Colllection提供的stream()或parallelStream()创建流\nList&lt;String&gt; list = new ArrayList&lt;&gt;();\nStream&lt;String&gt; stream1 = list.stream();\n//2. 通过数组Arrays的静态方法stream()获取数组流\nString[] str = new String[10];\nStream&lt;String&gt; stream2 = Arrays.stream(str);\n//3. 通过Stream类中的静态方法of()\nStream&lt;String&gt; stream3 = Stream.of(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;);\n//4. 创建无限流\n//迭代\nStream&lt;Integer&gt; stream4 = Stream.iterate(0, (x) -&gt; x + 2);\nstream4.limit(10).forEach(System.out::println);\n//生成\nStream.generate(() -&gt; Math.random()).limit(5).forEach(System.out::println);\n</code></pre>\n"},{"title":"Vue父子组件之间传递参数","excerpt":"","comments":1,"date":"2021-02-02T11:30:52.000Z","_content":"\n今天要把一个页面的dialog提出来，做成一个vue组件（component），共多个页面复用。\n之前我知道如何向封装的组件中传递参数：\n\n```html\n\n  <intention-editor ref=\"intentionEditor\" :bill-code=\"billCode\" :edit-visible=\"editVisible\" :is-db-edit=\"isDbEdit\" @cancelEditor=\"cancelEditorFn\"></intention-editor>\n\n```\n\n可是`intention-editor`中的dialog关闭的时候，要将和`:visible.sync`绑定的变量修改为false，这时候组件内的变量已经修改为false，上层页面的对应变量，也就是上面的`editVisible`却没有跟着变成false。之前有用过Vue的Bus实现过组件的通信，但是在这里用感觉太重了，后来问了同事，找到了下面的办法----`$emit`。\n\n1、父组件可以使用`props`把数据传给子组件。\n2、子组件可以使用`$emit`触发父组件的自定义事件。\n\n```js\n\nvm.$emit( event, arg ) //触发当前实例上的事件\n\nvm.$on( event, fn );//监听event事件后运行 fn；\n\n```\n\n例如：子组件：\n```html\n<template>\n  <div class=\"train-city\">\n    <h3>父组件传给子组件的toCity:{{sendData}}</h3> \n    <br/><button @click='select(`大连`)'>点击此处将‘大连’发射给父组件</button>\n  </div>\n</template>\n<script>\n  export default {\n    name:'trainCity',\n    props:['sendData'], // 用来接收父组件传给子组件的数据\n    methods:{\n      select(val) {\n        let data = {\n          cityname: val\n        };\n        this.$emit('showCityName',data);//select事件触发后，自动触发showCityName事件\n      }\n    }\n  }\n</script>\n```\n父组件：\n```html\n<template>\n    <div>\n        <div>父组件的toCity{{toCity}}</div>\n        <train-city @showCityName=\"updateCity\" :sendData=\"toCity\"></train-city>\n    </div>\n<template>\n<script>\n  import TrainCity from \"./train-city\";\n  export default {\n    name:'index',\n    components: {TrainCity},\n    data () {\n      return {\n        toCity:\"北京\"\n      }\n    },\n    methods:{\n      updateCity(data){//触发子组件城市选择-选择城市的事件\n        this.toCity = data.cityname;//改变了父组件的值\n        console.log('toCity:'+this.toCity)\n      }\n    }\n  }\n</script>\n```\n","source":"_posts/2021-02-02-kongzheng1993-Vue父子组件之间传递参数.md","raw":"---\ntitle: Vue父子组件之间传递参数\nexcerpt: 'Java'\ntags: [Java]\ncategories: [Java]\ncomments: true\ndate: 2021-02-02 19:30:52\n---\n\n今天要把一个页面的dialog提出来，做成一个vue组件（component），共多个页面复用。\n之前我知道如何向封装的组件中传递参数：\n\n```html\n\n  <intention-editor ref=\"intentionEditor\" :bill-code=\"billCode\" :edit-visible=\"editVisible\" :is-db-edit=\"isDbEdit\" @cancelEditor=\"cancelEditorFn\"></intention-editor>\n\n```\n\n可是`intention-editor`中的dialog关闭的时候，要将和`:visible.sync`绑定的变量修改为false，这时候组件内的变量已经修改为false，上层页面的对应变量，也就是上面的`editVisible`却没有跟着变成false。之前有用过Vue的Bus实现过组件的通信，但是在这里用感觉太重了，后来问了同事，找到了下面的办法----`$emit`。\n\n1、父组件可以使用`props`把数据传给子组件。\n2、子组件可以使用`$emit`触发父组件的自定义事件。\n\n```js\n\nvm.$emit( event, arg ) //触发当前实例上的事件\n\nvm.$on( event, fn );//监听event事件后运行 fn；\n\n```\n\n例如：子组件：\n```html\n<template>\n  <div class=\"train-city\">\n    <h3>父组件传给子组件的toCity:{{sendData}}</h3> \n    <br/><button @click='select(`大连`)'>点击此处将‘大连’发射给父组件</button>\n  </div>\n</template>\n<script>\n  export default {\n    name:'trainCity',\n    props:['sendData'], // 用来接收父组件传给子组件的数据\n    methods:{\n      select(val) {\n        let data = {\n          cityname: val\n        };\n        this.$emit('showCityName',data);//select事件触发后，自动触发showCityName事件\n      }\n    }\n  }\n</script>\n```\n父组件：\n```html\n<template>\n    <div>\n        <div>父组件的toCity{{toCity}}</div>\n        <train-city @showCityName=\"updateCity\" :sendData=\"toCity\"></train-city>\n    </div>\n<template>\n<script>\n  import TrainCity from \"./train-city\";\n  export default {\n    name:'index',\n    components: {TrainCity},\n    data () {\n      return {\n        toCity:\"北京\"\n      }\n    },\n    methods:{\n      updateCity(data){//触发子组件城市选择-选择城市的事件\n        this.toCity = data.cityname;//改变了父组件的值\n        console.log('toCity:'+this.toCity)\n      }\n    }\n  }\n</script>\n```\n","slug":"kongzheng1993-Vue父子组件之间传递参数","published":1,"updated":"2023-03-08T07:05:58.808Z","layout":"post","photos":[],"link":"","_id":"clg0k2alw006dt26fq65wxvyt","content":"<p>今天要把一个页面的dialog提出来，做成一个vue组件（component），共多个页面复用。<br>之前我知道如何向封装的组件中传递参数：</p>\n<pre><code class=\"html\">\n  &lt;intention-editor ref=&quot;intentionEditor&quot; :bill-code=&quot;billCode&quot; :edit-visible=&quot;editVisible&quot; :is-db-edit=&quot;isDbEdit&quot; @cancelEditor=&quot;cancelEditorFn&quot;&gt;&lt;/intention-editor&gt;\n</code></pre>\n<p>可是<code>intention-editor</code>中的dialog关闭的时候，要将和<code>:visible.sync</code>绑定的变量修改为false，这时候组件内的变量已经修改为false，上层页面的对应变量，也就是上面的<code>editVisible</code>却没有跟着变成false。之前有用过Vue的Bus实现过组件的通信，但是在这里用感觉太重了，后来问了同事，找到了下面的办法—-<code>$emit</code>。</p>\n<p>1、父组件可以使用<code>props</code>把数据传给子组件。<br>2、子组件可以使用<code>$emit</code>触发父组件的自定义事件。</p>\n<pre><code class=\"js\">\nvm.$emit( event, arg ) //触发当前实例上的事件\n\nvm.$on( event, fn );//监听event事件后运行 fn；\n</code></pre>\n<p>例如：子组件：</p>\n<pre><code class=\"html\">&lt;template&gt;\n  &lt;div class=&quot;train-city&quot;&gt;\n    &lt;h3&gt;父组件传给子组件的toCity:{{sendData}}&lt;/h3&gt; \n    &lt;br/&gt;&lt;button @click=&#39;select(`大连`)&#39;&gt;点击此处将‘大连’发射给父组件&lt;/button&gt;\n  &lt;/div&gt;\n&lt;/template&gt;\n&lt;script&gt;\n  export default {\n    name:&#39;trainCity&#39;,\n    props:[&#39;sendData&#39;], // 用来接收父组件传给子组件的数据\n    methods:{\n      select(val) {\n        let data = {\n          cityname: val\n        };\n        this.$emit(&#39;showCityName&#39;,data);//select事件触发后，自动触发showCityName事件\n      }\n    }\n  }\n&lt;/script&gt;</code></pre>\n<p>父组件：</p>\n<pre><code class=\"html\">&lt;template&gt;\n    &lt;div&gt;\n        &lt;div&gt;父组件的toCity{{toCity}}&lt;/div&gt;\n        &lt;train-city @showCityName=&quot;updateCity&quot; :sendData=&quot;toCity&quot;&gt;&lt;/train-city&gt;\n    &lt;/div&gt;\n&lt;template&gt;\n&lt;script&gt;\n  import TrainCity from &quot;./train-city&quot;;\n  export default {\n    name:&#39;index&#39;,\n    components: {TrainCity},\n    data () {\n      return {\n        toCity:&quot;北京&quot;\n      }\n    },\n    methods:{\n      updateCity(data){//触发子组件城市选择-选择城市的事件\n        this.toCity = data.cityname;//改变了父组件的值\n        console.log(&#39;toCity:&#39;+this.toCity)\n      }\n    }\n  }\n&lt;/script&gt;</code></pre>\n","site":{"data":{}},"more":"<p>今天要把一个页面的dialog提出来，做成一个vue组件（component），共多个页面复用。<br>之前我知道如何向封装的组件中传递参数：</p>\n<pre><code class=\"html\">\n  &lt;intention-editor ref=&quot;intentionEditor&quot; :bill-code=&quot;billCode&quot; :edit-visible=&quot;editVisible&quot; :is-db-edit=&quot;isDbEdit&quot; @cancelEditor=&quot;cancelEditorFn&quot;&gt;&lt;/intention-editor&gt;\n</code></pre>\n<p>可是<code>intention-editor</code>中的dialog关闭的时候，要将和<code>:visible.sync</code>绑定的变量修改为false，这时候组件内的变量已经修改为false，上层页面的对应变量，也就是上面的<code>editVisible</code>却没有跟着变成false。之前有用过Vue的Bus实现过组件的通信，但是在这里用感觉太重了，后来问了同事，找到了下面的办法—-<code>$emit</code>。</p>\n<p>1、父组件可以使用<code>props</code>把数据传给子组件。<br>2、子组件可以使用<code>$emit</code>触发父组件的自定义事件。</p>\n<pre><code class=\"js\">\nvm.$emit( event, arg ) //触发当前实例上的事件\n\nvm.$on( event, fn );//监听event事件后运行 fn；\n</code></pre>\n<p>例如：子组件：</p>\n<pre><code class=\"html\">&lt;template&gt;\n  &lt;div class=&quot;train-city&quot;&gt;\n    &lt;h3&gt;父组件传给子组件的toCity:{{sendData}}&lt;/h3&gt; \n    &lt;br/&gt;&lt;button @click=&#39;select(`大连`)&#39;&gt;点击此处将‘大连’发射给父组件&lt;/button&gt;\n  &lt;/div&gt;\n&lt;/template&gt;\n&lt;script&gt;\n  export default {\n    name:&#39;trainCity&#39;,\n    props:[&#39;sendData&#39;], // 用来接收父组件传给子组件的数据\n    methods:{\n      select(val) {\n        let data = {\n          cityname: val\n        };\n        this.$emit(&#39;showCityName&#39;,data);//select事件触发后，自动触发showCityName事件\n      }\n    }\n  }\n&lt;/script&gt;</code></pre>\n<p>父组件：</p>\n<pre><code class=\"html\">&lt;template&gt;\n    &lt;div&gt;\n        &lt;div&gt;父组件的toCity{{toCity}}&lt;/div&gt;\n        &lt;train-city @showCityName=&quot;updateCity&quot; :sendData=&quot;toCity&quot;&gt;&lt;/train-city&gt;\n    &lt;/div&gt;\n&lt;template&gt;\n&lt;script&gt;\n  import TrainCity from &quot;./train-city&quot;;\n  export default {\n    name:&#39;index&#39;,\n    components: {TrainCity},\n    data () {\n      return {\n        toCity:&quot;北京&quot;\n      }\n    },\n    methods:{\n      updateCity(data){//触发子组件城市选择-选择城市的事件\n        this.toCity = data.cityname;//改变了父组件的值\n        console.log(&#39;toCity:&#39;+this.toCity)\n      }\n    }\n  }\n&lt;/script&gt;</code></pre>\n"},{"title":"Win10下的wls中git状态不对的问题","excerpt":"","comments":1,"date":"2021-03-26T11:30:52.000Z","_content":"\n最近买了个thinkpad的扩展坞，换回了windows，用习惯了mac下的shell，好像有点回不去win的cmd了，不过问题不大，毕竟win自带linux子系统，以前用win的时候也是必备的，现在配合上巨硬出品的Terminal，香的很！\n\n但是最近遇到一个问题，我在win环境下的git，显示`working tree clean`，但是在wls的ubuntu下却是几乎所有的文件，还以为wls下git有什么bug，差点就卸载了。\n\n查看下差别：\n\n```shell\n\nkongzheng1993@LAPTOP-KCIF5AIF:/mnt/c/evilRat/workspace/lixiang/workspace/myProject$ git diff\ndiff --git a/.gitignore b/.gitignore\nindex 6b9542c0..96fc7230 100644\n--- a/.gitignore\n+++ b/.gitignore\n@@ -1,30 +1,30 @@\n-/target/\n-!.mvn/wrapper/maven-wrapper.jar\n-\n-### STS ###\n-.apt_generated\n-.classpath\n-.factorypath\n-.project\n-.settings\n-.springBeans\n-.sts4-cache\n-\n-### IntelliJ IDEA ###\n-.idea\n-*.iws\n-*.iml\n-*.ipr\n-api/target\n-service/target\n-model/target\n-pipeline/target\n-### NetBeans ###\n-/nbproject/private/\n-/build/\n-/nbbuild/\n-/dist/\n-/nbdist/\n-/.nb-gradle/\n-/.DS_store\n-/api/src/main/resources/static/.DS_Store\n+/target/^M\n+!.mvn/wrapper/maven-wrapper.jar^M\n+^M\n+### STS ###^M\n+.apt_generated^M\n+.classpath^M\n+.factorypath^M\n+.project^M\n+.settings^M\n+.springBeans^M\n+.sts4-cache^M\n+^M\n+### IntelliJ IDEA ###^M\n+.idea^M\n+*.iws^M\n+*.iml^M\n+*.ipr^M\n+api/target^M\n+service/target^M\n+model/target^M\n+pipeline/target^M\n+### NetBeans ###^M\n+/nbproject/private/^M\n+/build/^M\n+/nbbuild/^M\n+/dist/^M\n+/nbdist/^M\n+/.nb-gradle/^M\n+/.DS_store^M\n+/api/src/main/resources/static/.DS_Store^M\n\n\n```\n\n所有的文件都是删掉后又新增，而且后面又`^M`， 看到这里其实就已经明白了。就是简简单单的win和linux、unix下的换行符不同。\n\n- windows下：CRLF（表示句尾使用回车换行两个字符，即windows下的\"\\r\\n\"换行）\n- unix下：LF（表示句尾，只使用换行）\n- mac下：CR（表示只使用回车）\n\n而Git处理换行的配置是`core.autocrlf`，可以是设置为true、false、inout\n\n执行`git config --global core.autocrlf true`后，git仓库中所有的文件都会将crlf变成lf，也就不再不同了","source":"_posts/2021-02-05-kongzheng1993-Win10下的wls中git状态不对的问题.md","raw":"---\ntitle: Win10下的wls中git状态不对的问题\nexcerpt: 'Windows Linux'\ntags: [Windows, Linux]\ncategories: [OS]\ncomments: true\ndate: 2021-03-26 19:30:52\n---\n\n最近买了个thinkpad的扩展坞，换回了windows，用习惯了mac下的shell，好像有点回不去win的cmd了，不过问题不大，毕竟win自带linux子系统，以前用win的时候也是必备的，现在配合上巨硬出品的Terminal，香的很！\n\n但是最近遇到一个问题，我在win环境下的git，显示`working tree clean`，但是在wls的ubuntu下却是几乎所有的文件，还以为wls下git有什么bug，差点就卸载了。\n\n查看下差别：\n\n```shell\n\nkongzheng1993@LAPTOP-KCIF5AIF:/mnt/c/evilRat/workspace/lixiang/workspace/myProject$ git diff\ndiff --git a/.gitignore b/.gitignore\nindex 6b9542c0..96fc7230 100644\n--- a/.gitignore\n+++ b/.gitignore\n@@ -1,30 +1,30 @@\n-/target/\n-!.mvn/wrapper/maven-wrapper.jar\n-\n-### STS ###\n-.apt_generated\n-.classpath\n-.factorypath\n-.project\n-.settings\n-.springBeans\n-.sts4-cache\n-\n-### IntelliJ IDEA ###\n-.idea\n-*.iws\n-*.iml\n-*.ipr\n-api/target\n-service/target\n-model/target\n-pipeline/target\n-### NetBeans ###\n-/nbproject/private/\n-/build/\n-/nbbuild/\n-/dist/\n-/nbdist/\n-/.nb-gradle/\n-/.DS_store\n-/api/src/main/resources/static/.DS_Store\n+/target/^M\n+!.mvn/wrapper/maven-wrapper.jar^M\n+^M\n+### STS ###^M\n+.apt_generated^M\n+.classpath^M\n+.factorypath^M\n+.project^M\n+.settings^M\n+.springBeans^M\n+.sts4-cache^M\n+^M\n+### IntelliJ IDEA ###^M\n+.idea^M\n+*.iws^M\n+*.iml^M\n+*.ipr^M\n+api/target^M\n+service/target^M\n+model/target^M\n+pipeline/target^M\n+### NetBeans ###^M\n+/nbproject/private/^M\n+/build/^M\n+/nbbuild/^M\n+/dist/^M\n+/nbdist/^M\n+/.nb-gradle/^M\n+/.DS_store^M\n+/api/src/main/resources/static/.DS_Store^M\n\n\n```\n\n所有的文件都是删掉后又新增，而且后面又`^M`， 看到这里其实就已经明白了。就是简简单单的win和linux、unix下的换行符不同。\n\n- windows下：CRLF（表示句尾使用回车换行两个字符，即windows下的\"\\r\\n\"换行）\n- unix下：LF（表示句尾，只使用换行）\n- mac下：CR（表示只使用回车）\n\n而Git处理换行的配置是`core.autocrlf`，可以是设置为true、false、inout\n\n执行`git config --global core.autocrlf true`后，git仓库中所有的文件都会将crlf变成lf，也就不再不同了","slug":"kongzheng1993-Win10下的wls中git状态不对的问题","published":1,"updated":"2023-03-08T07:05:58.809Z","layout":"post","photos":[],"link":"","_id":"clg0k2alw006gt26f29jlsiz0","content":"<p>最近买了个thinkpad的扩展坞，换回了windows，用习惯了mac下的shell，好像有点回不去win的cmd了，不过问题不大，毕竟win自带linux子系统，以前用win的时候也是必备的，现在配合上巨硬出品的Terminal，香的很！</p>\n<p>但是最近遇到一个问题，我在win环境下的git，显示<code>working tree clean</code>，但是在wls的ubuntu下却是几乎所有的文件，还以为wls下git有什么bug，差点就卸载了。</p>\n<p>查看下差别：</p>\n<pre><code class=\"shell\">\nkongzheng1993@LAPTOP-KCIF5AIF:/mnt/c/evilRat/workspace/lixiang/workspace/myProject$ git diff\ndiff --git a/.gitignore b/.gitignore\nindex 6b9542c0..96fc7230 100644\n--- a/.gitignore\n+++ b/.gitignore\n@@ -1,30 +1,30 @@\n-/target/\n-!.mvn/wrapper/maven-wrapper.jar\n-\n-### STS ###\n-.apt_generated\n-.classpath\n-.factorypath\n-.project\n-.settings\n-.springBeans\n-.sts4-cache\n-\n-### IntelliJ IDEA ###\n-.idea\n-*.iws\n-*.iml\n-*.ipr\n-api/target\n-service/target\n-model/target\n-pipeline/target\n-### NetBeans ###\n-/nbproject/private/\n-/build/\n-/nbbuild/\n-/dist/\n-/nbdist/\n-/.nb-gradle/\n-/.DS_store\n-/api/src/main/resources/static/.DS_Store\n+/target/^M\n+!.mvn/wrapper/maven-wrapper.jar^M\n+^M\n+### STS ###^M\n+.apt_generated^M\n+.classpath^M\n+.factorypath^M\n+.project^M\n+.settings^M\n+.springBeans^M\n+.sts4-cache^M\n+^M\n+### IntelliJ IDEA ###^M\n+.idea^M\n+*.iws^M\n+*.iml^M\n+*.ipr^M\n+api/target^M\n+service/target^M\n+model/target^M\n+pipeline/target^M\n+### NetBeans ###^M\n+/nbproject/private/^M\n+/build/^M\n+/nbbuild/^M\n+/dist/^M\n+/nbdist/^M\n+/.nb-gradle/^M\n+/.DS_store^M\n+/api/src/main/resources/static/.DS_Store^M\n\n</code></pre>\n<p>所有的文件都是删掉后又新增，而且后面又<code>^M</code>， 看到这里其实就已经明白了。就是简简单单的win和linux、unix下的换行符不同。</p>\n<ul>\n<li>windows下：CRLF（表示句尾使用回车换行两个字符，即windows下的”\\r\\n”换行）</li>\n<li>unix下：LF（表示句尾，只使用换行）</li>\n<li>mac下：CR（表示只使用回车）</li>\n</ul>\n<p>而Git处理换行的配置是<code>core.autocrlf</code>，可以是设置为true、false、inout</p>\n<p>执行<code>git config --global core.autocrlf true</code>后，git仓库中所有的文件都会将crlf变成lf，也就不再不同了</p>\n","site":{"data":{}},"more":"<p>最近买了个thinkpad的扩展坞，换回了windows，用习惯了mac下的shell，好像有点回不去win的cmd了，不过问题不大，毕竟win自带linux子系统，以前用win的时候也是必备的，现在配合上巨硬出品的Terminal，香的很！</p>\n<p>但是最近遇到一个问题，我在win环境下的git，显示<code>working tree clean</code>，但是在wls的ubuntu下却是几乎所有的文件，还以为wls下git有什么bug，差点就卸载了。</p>\n<p>查看下差别：</p>\n<pre><code class=\"shell\">\nkongzheng1993@LAPTOP-KCIF5AIF:/mnt/c/evilRat/workspace/lixiang/workspace/myProject$ git diff\ndiff --git a/.gitignore b/.gitignore\nindex 6b9542c0..96fc7230 100644\n--- a/.gitignore\n+++ b/.gitignore\n@@ -1,30 +1,30 @@\n-/target/\n-!.mvn/wrapper/maven-wrapper.jar\n-\n-### STS ###\n-.apt_generated\n-.classpath\n-.factorypath\n-.project\n-.settings\n-.springBeans\n-.sts4-cache\n-\n-### IntelliJ IDEA ###\n-.idea\n-*.iws\n-*.iml\n-*.ipr\n-api/target\n-service/target\n-model/target\n-pipeline/target\n-### NetBeans ###\n-/nbproject/private/\n-/build/\n-/nbbuild/\n-/dist/\n-/nbdist/\n-/.nb-gradle/\n-/.DS_store\n-/api/src/main/resources/static/.DS_Store\n+/target/^M\n+!.mvn/wrapper/maven-wrapper.jar^M\n+^M\n+### STS ###^M\n+.apt_generated^M\n+.classpath^M\n+.factorypath^M\n+.project^M\n+.settings^M\n+.springBeans^M\n+.sts4-cache^M\n+^M\n+### IntelliJ IDEA ###^M\n+.idea^M\n+*.iws^M\n+*.iml^M\n+*.ipr^M\n+api/target^M\n+service/target^M\n+model/target^M\n+pipeline/target^M\n+### NetBeans ###^M\n+/nbproject/private/^M\n+/build/^M\n+/nbbuild/^M\n+/dist/^M\n+/nbdist/^M\n+/.nb-gradle/^M\n+/.DS_store^M\n+/api/src/main/resources/static/.DS_Store^M\n\n</code></pre>\n<p>所有的文件都是删掉后又新增，而且后面又<code>^M</code>， 看到这里其实就已经明白了。就是简简单单的win和linux、unix下的换行符不同。</p>\n<ul>\n<li>windows下：CRLF（表示句尾使用回车换行两个字符，即windows下的”\\r\\n”换行）</li>\n<li>unix下：LF（表示句尾，只使用换行）</li>\n<li>mac下：CR（表示只使用回车）</li>\n</ul>\n<p>而Git处理换行的配置是<code>core.autocrlf</code>，可以是设置为true、false、inout</p>\n<p>执行<code>git config --global core.autocrlf true</code>后，git仓库中所有的文件都会将crlf变成lf，也就不再不同了</p>\n"},{"title":"FeignClient遇到的小问题","excerpt":"","comments":1,"date":"2021-03-15T11:30:52.000Z","_content":"\n\n之前做了一个通过配置实现页面截图并发送到飞书群卡片的工具，可以配置截图页面url、宽高、超时时间等参数，通过cron定时发送或者@飞书机器人触发。并且自己也配置好了两个在用的业务，已经在用几个月了。前两天其他组的同事有业务场景要用到我们这个工具，配置上之后，竟然没有反应，我查了下日志---空指针，我第一反应是配置的表单我没有校验，导致后面取配置属性的时候NPE了。\n\n开始看代码，看到后面并没有会造成空指针的地方，报错信息也只是打印到Feign调用的那行代码，检查调用Feign接口的参数，并没有问题啊。在feign关键源码处打断点：\n\n```java\n\n    public Object invoke(Object[] argv) throws Throwable {\n        RequestTemplate template = this.buildTemplateFromArgs.create(argv);\n        Retryer retryer = this.retryer.clone();\n\n        while(true) {\n            try {\n                return this.executeAndDecode(template);\n            } catch (RetryableException var5) {\n                retryer.continueOrPropagate(var5);\n                if (this.logLevel != Level.NONE) {\n                    this.logger.logRetry(this.metadata.configKey(), this.logLevel);\n                }\n            }\n        }\n    }\n\n```\n\n一顿操作后，发现根本就没到这。\n\n那肯定是接口调用前，盯着FeignClient看了半天，发现有个参数是int类型的，而我调用时，传递过来的是Integer，这地方肯定是强转时拆箱炸了。。\n\n\n把FeignClient接口的参数类型修改为Integer后，测试通过。\n\n","source":"_posts/2021-03-15-kongzheng1993-FeignClient遇到的小问题.md","raw":"---\ntitle: FeignClient遇到的小问题\nexcerpt: 'Java'\ntags: [Java]\ncategories: [Java]\ncomments: true\ndate: 2021-03-15 19:30:52\n---\n\n\n之前做了一个通过配置实现页面截图并发送到飞书群卡片的工具，可以配置截图页面url、宽高、超时时间等参数，通过cron定时发送或者@飞书机器人触发。并且自己也配置好了两个在用的业务，已经在用几个月了。前两天其他组的同事有业务场景要用到我们这个工具，配置上之后，竟然没有反应，我查了下日志---空指针，我第一反应是配置的表单我没有校验，导致后面取配置属性的时候NPE了。\n\n开始看代码，看到后面并没有会造成空指针的地方，报错信息也只是打印到Feign调用的那行代码，检查调用Feign接口的参数，并没有问题啊。在feign关键源码处打断点：\n\n```java\n\n    public Object invoke(Object[] argv) throws Throwable {\n        RequestTemplate template = this.buildTemplateFromArgs.create(argv);\n        Retryer retryer = this.retryer.clone();\n\n        while(true) {\n            try {\n                return this.executeAndDecode(template);\n            } catch (RetryableException var5) {\n                retryer.continueOrPropagate(var5);\n                if (this.logLevel != Level.NONE) {\n                    this.logger.logRetry(this.metadata.configKey(), this.logLevel);\n                }\n            }\n        }\n    }\n\n```\n\n一顿操作后，发现根本就没到这。\n\n那肯定是接口调用前，盯着FeignClient看了半天，发现有个参数是int类型的，而我调用时，传递过来的是Integer，这地方肯定是强转时拆箱炸了。。\n\n\n把FeignClient接口的参数类型修改为Integer后，测试通过。\n\n","slug":"kongzheng1993-FeignClient遇到的小问题","published":1,"updated":"2023-03-08T07:05:58.809Z","layout":"post","photos":[],"link":"","_id":"clg0k2alx006lt26fm6snn2z9","content":"<p>之前做了一个通过配置实现页面截图并发送到飞书群卡片的工具，可以配置截图页面url、宽高、超时时间等参数，通过cron定时发送或者@飞书机器人触发。并且自己也配置好了两个在用的业务，已经在用几个月了。前两天其他组的同事有业务场景要用到我们这个工具，配置上之后，竟然没有反应，我查了下日志—空指针，我第一反应是配置的表单我没有校验，导致后面取配置属性的时候NPE了。</p>\n<p>开始看代码，看到后面并没有会造成空指针的地方，报错信息也只是打印到Feign调用的那行代码，检查调用Feign接口的参数，并没有问题啊。在feign关键源码处打断点：</p>\n<pre><code class=\"java\">\n    public Object invoke(Object[] argv) throws Throwable {\n        RequestTemplate template = this.buildTemplateFromArgs.create(argv);\n        Retryer retryer = this.retryer.clone();\n\n        while(true) {\n            try {\n                return this.executeAndDecode(template);\n            } catch (RetryableException var5) {\n                retryer.continueOrPropagate(var5);\n                if (this.logLevel != Level.NONE) {\n                    this.logger.logRetry(this.metadata.configKey(), this.logLevel);\n                }\n            }\n        }\n    }\n</code></pre>\n<p>一顿操作后，发现根本就没到这。</p>\n<p>那肯定是接口调用前，盯着FeignClient看了半天，发现有个参数是int类型的，而我调用时，传递过来的是Integer，这地方肯定是强转时拆箱炸了。。</p>\n<p>把FeignClient接口的参数类型修改为Integer后，测试通过。</p>\n","site":{"data":{}},"more":"<p>之前做了一个通过配置实现页面截图并发送到飞书群卡片的工具，可以配置截图页面url、宽高、超时时间等参数，通过cron定时发送或者@飞书机器人触发。并且自己也配置好了两个在用的业务，已经在用几个月了。前两天其他组的同事有业务场景要用到我们这个工具，配置上之后，竟然没有反应，我查了下日志—空指针，我第一反应是配置的表单我没有校验，导致后面取配置属性的时候NPE了。</p>\n<p>开始看代码，看到后面并没有会造成空指针的地方，报错信息也只是打印到Feign调用的那行代码，检查调用Feign接口的参数，并没有问题啊。在feign关键源码处打断点：</p>\n<pre><code class=\"java\">\n    public Object invoke(Object[] argv) throws Throwable {\n        RequestTemplate template = this.buildTemplateFromArgs.create(argv);\n        Retryer retryer = this.retryer.clone();\n\n        while(true) {\n            try {\n                return this.executeAndDecode(template);\n            } catch (RetryableException var5) {\n                retryer.continueOrPropagate(var5);\n                if (this.logLevel != Level.NONE) {\n                    this.logger.logRetry(this.metadata.configKey(), this.logLevel);\n                }\n            }\n        }\n    }\n</code></pre>\n<p>一顿操作后，发现根本就没到这。</p>\n<p>那肯定是接口调用前，盯着FeignClient看了半天，发现有个参数是int类型的，而我调用时，传递过来的是Integer，这地方肯定是强转时拆箱炸了。。</p>\n<p>把FeignClient接口的参数类型修改为Integer后，测试通过。</p>\n"},{"title":"Java Remote Debug","excerpt":"","comments":1,"date":"2021-03-27T11:30:52.000Z","_content":"\n记得刚毕业后刚上班的时候，写过一段时间的C++，用过GDB来调试程序，其实Java也有相应的远程调试的工具----JDB\n\n## 增加JVM配置开启远程调试\n\n启动参数中增加：\n\n```\n-Xdebug -Xrunjdwp:transport=dt_socket,server=y,address=5000,suspend=n,onthrow=java.io.IOExpection,launch=/sbin/echo\n```\n\n-Xdebug 启动调试\n-Xrunjdwp 加载JVM的JPDA参考实现库\n\n\n- transport指定了调试数据的传送方式：dt_socket是指用Socket模式，dt_shmem是指用共享内存方式，其中dt_shmem只适用于Windows平台。\n- server参数是指是否支持在server模式的VM中\n- onthrow是指定，当产生该类型的Exception时，JVM就会中断下来，进行调试\n- launch是指当JVM被中断下来时，执行的可执行程序\n- suspend指定是否在调试客户端建立起来后，再执行JVM\n- onuncaught是指明出现uncaught exception后，是否中断JVM的执行\n- address指指定连接地址，当transport为dt_socket时，address就是我们远程连接过去的端口号\n\n## 如何进行调试\n\n1. JDK自带了JDB：\n\n```console\njdb -connect com.sun.jdi.SocketAttach:port=5000,hostname=192.168.100.100\n```\n\n上面的命令就是通过socket连接到`192.168.100.100:5000`进行远程调试，连接后就可以通过jdb的命令来进行断点，调试了。\n\n\n2. 使用IDEA远程调试\n\n\n使用我们的ide工具，以IDEA为例，配置一个Remote JVM Debug的Run/Debug Configurations就好了，像下面一样\n\n<img src=\"idea_remote_debug.png\">\n\n接下来就是像本地调试一样，直接在源码上断点，就好了！所以，用工具吧，人类！","source":"_posts/2021-03-27-kongzheng1993-JavaRemoteDebug.md","raw":"---\ntitle: Java Remote Debug\nexcerpt: 'Java'\ntags: [Java]\ncategories: [Java]\ncomments: true\ndate: 2021-03-27 19:30:52\n---\n\n记得刚毕业后刚上班的时候，写过一段时间的C++，用过GDB来调试程序，其实Java也有相应的远程调试的工具----JDB\n\n## 增加JVM配置开启远程调试\n\n启动参数中增加：\n\n```\n-Xdebug -Xrunjdwp:transport=dt_socket,server=y,address=5000,suspend=n,onthrow=java.io.IOExpection,launch=/sbin/echo\n```\n\n-Xdebug 启动调试\n-Xrunjdwp 加载JVM的JPDA参考实现库\n\n\n- transport指定了调试数据的传送方式：dt_socket是指用Socket模式，dt_shmem是指用共享内存方式，其中dt_shmem只适用于Windows平台。\n- server参数是指是否支持在server模式的VM中\n- onthrow是指定，当产生该类型的Exception时，JVM就会中断下来，进行调试\n- launch是指当JVM被中断下来时，执行的可执行程序\n- suspend指定是否在调试客户端建立起来后，再执行JVM\n- onuncaught是指明出现uncaught exception后，是否中断JVM的执行\n- address指指定连接地址，当transport为dt_socket时，address就是我们远程连接过去的端口号\n\n## 如何进行调试\n\n1. JDK自带了JDB：\n\n```console\njdb -connect com.sun.jdi.SocketAttach:port=5000,hostname=192.168.100.100\n```\n\n上面的命令就是通过socket连接到`192.168.100.100:5000`进行远程调试，连接后就可以通过jdb的命令来进行断点，调试了。\n\n\n2. 使用IDEA远程调试\n\n\n使用我们的ide工具，以IDEA为例，配置一个Remote JVM Debug的Run/Debug Configurations就好了，像下面一样\n\n<img src=\"idea_remote_debug.png\">\n\n接下来就是像本地调试一样，直接在源码上断点，就好了！所以，用工具吧，人类！","slug":"kongzheng1993-JavaRemoteDebug","published":1,"updated":"2023-03-08T07:05:58.809Z","layout":"post","photos":[],"link":"","_id":"clg0k2alx006nt26flq1ztkt2","content":"<p>记得刚毕业后刚上班的时候，写过一段时间的C++，用过GDB来调试程序，其实Java也有相应的远程调试的工具—-JDB</p>\n<h2 id=\"增加JVM配置开启远程调试\"><a href=\"#增加JVM配置开启远程调试\" class=\"headerlink\" title=\"增加JVM配置开启远程调试\"></a>增加JVM配置开启远程调试</h2><p>启动参数中增加：</p>\n<pre><code>-Xdebug -Xrunjdwp:transport=dt_socket,server=y,address=5000,suspend=n,onthrow=java.io.IOExpection,launch=/sbin/echo</code></pre><p>-Xdebug 启动调试<br>-Xrunjdwp 加载JVM的JPDA参考实现库</p>\n<ul>\n<li>transport指定了调试数据的传送方式：dt_socket是指用Socket模式，dt_shmem是指用共享内存方式，其中dt_shmem只适用于Windows平台。</li>\n<li>server参数是指是否支持在server模式的VM中</li>\n<li>onthrow是指定，当产生该类型的Exception时，JVM就会中断下来，进行调试</li>\n<li>launch是指当JVM被中断下来时，执行的可执行程序</li>\n<li>suspend指定是否在调试客户端建立起来后，再执行JVM</li>\n<li>onuncaught是指明出现uncaught exception后，是否中断JVM的执行</li>\n<li>address指指定连接地址，当transport为dt_socket时，address就是我们远程连接过去的端口号</li>\n</ul>\n<h2 id=\"如何进行调试\"><a href=\"#如何进行调试\" class=\"headerlink\" title=\"如何进行调试\"></a>如何进行调试</h2><ol>\n<li>JDK自带了JDB：</li>\n</ol>\n<pre><code class=\"console\">jdb -connect com.sun.jdi.SocketAttach:port=5000,hostname=192.168.100.100</code></pre>\n<p>上面的命令就是通过socket连接到<code>192.168.100.100:5000</code>进行远程调试，连接后就可以通过jdb的命令来进行断点，调试了。</p>\n<ol start=\"2\">\n<li>使用IDEA远程调试</li>\n</ol>\n<p>使用我们的ide工具，以IDEA为例，配置一个Remote JVM Debug的Run/Debug Configurations就好了，像下面一样</p>\n<img src=\"/2021/03/27/kongzheng1993-JavaRemoteDebug/idea_remote_debug.png\">\n\n<p>接下来就是像本地调试一样，直接在源码上断点，就好了！所以，用工具吧，人类！</p>\n","site":{"data":{}},"more":"<p>记得刚毕业后刚上班的时候，写过一段时间的C++，用过GDB来调试程序，其实Java也有相应的远程调试的工具—-JDB</p>\n<h2 id=\"增加JVM配置开启远程调试\"><a href=\"#增加JVM配置开启远程调试\" class=\"headerlink\" title=\"增加JVM配置开启远程调试\"></a>增加JVM配置开启远程调试</h2><p>启动参数中增加：</p>\n<pre><code>-Xdebug -Xrunjdwp:transport=dt_socket,server=y,address=5000,suspend=n,onthrow=java.io.IOExpection,launch=/sbin/echo</code></pre><p>-Xdebug 启动调试<br>-Xrunjdwp 加载JVM的JPDA参考实现库</p>\n<ul>\n<li>transport指定了调试数据的传送方式：dt_socket是指用Socket模式，dt_shmem是指用共享内存方式，其中dt_shmem只适用于Windows平台。</li>\n<li>server参数是指是否支持在server模式的VM中</li>\n<li>onthrow是指定，当产生该类型的Exception时，JVM就会中断下来，进行调试</li>\n<li>launch是指当JVM被中断下来时，执行的可执行程序</li>\n<li>suspend指定是否在调试客户端建立起来后，再执行JVM</li>\n<li>onuncaught是指明出现uncaught exception后，是否中断JVM的执行</li>\n<li>address指指定连接地址，当transport为dt_socket时，address就是我们远程连接过去的端口号</li>\n</ul>\n<h2 id=\"如何进行调试\"><a href=\"#如何进行调试\" class=\"headerlink\" title=\"如何进行调试\"></a>如何进行调试</h2><ol>\n<li>JDK自带了JDB：</li>\n</ol>\n<pre><code class=\"console\">jdb -connect com.sun.jdi.SocketAttach:port=5000,hostname=192.168.100.100</code></pre>\n<p>上面的命令就是通过socket连接到<code>192.168.100.100:5000</code>进行远程调试，连接后就可以通过jdb的命令来进行断点，调试了。</p>\n<ol start=\"2\">\n<li>使用IDEA远程调试</li>\n</ol>\n<p>使用我们的ide工具，以IDEA为例，配置一个Remote JVM Debug的Run/Debug Configurations就好了，像下面一样</p>\n<img src=\"/2021/03/27/kongzheng1993-JavaRemoteDebug/idea_remote_debug.png\">\n\n<p>接下来就是像本地调试一样，直接在源码上断点，就好了！所以，用工具吧，人类！</p>\n"},{"title":"java.lang.Class#getResource浅析","excerpt":"","comments":1,"date":"2021-04-29T11:30:52.000Z","_content":"\n最近工程重构，原来单module的maven项目拆分出来api、web、model等多个module，之前我们有一个生成pdf的类`PdfGenerator`，需要获取字体文件：\n\n```java\nprivate static String fontPath = PdfGenerator.class.getResource(\"/\") + \"static/pdf/XXXXX.TTF\";\n```\n\n但是因为项目结构的调整，启动类再`app`模块下，其他的模块都被`app`模块依赖，`PdfGenerator`这个类和对应的字体文件都被挪到了`common`模块下，而上面的`getResoutce(\"/\")` 则会返回classpath，也就是app的`target/classes`目录，显然就找不到`common`模块`resource`目录（当然，编译后应该在`target/classes/static/pdf/`中）下的字体文件了。\n\n### 思考\n\n多module的maven工程，app依赖其他module，这些依赖都是其他module package的jar包，现在要取到字体文件，就需要去common的jar包中取。当然，我们如果再IDE中debug，结果是不对的：\n\n<img src=\"IDE.png\"/>\n\n因为这时的getResource会去所谓的target目录下找，而我们springboot项目通过`java -jar`启动，并不会解压这些jar包，也就不会存在这些所谓的目录。\n\n`java.lang.Class#getResource`做了什么？\n\n```java\n    public java.net.URL getResource(String name) {\n        name = resolveName(name);\n        ClassLoader cl = getClassLoader0();\n        if (cl==null) {\n            // A system class.\n            return ClassLoader.getSystemResource(name);\n        }\n        return cl.getResource(name);\n    }\n```\n\n通过源码可以看到，先处理name，如果是`/`开头，说名要从根目录查找，就去掉第一位，如果不以`/`开头，就获取当前类的路径，然后拼接在name之前，也就是从当前类所在目录查找。然后获取`ClassLoader`，之后调用`ClassLoade`r的`getResource`方法，我们有时候会看到`xxx.class.getClassLoader().getResource()`，就是手动直接调用`ClassLoader`的`getResource`方法。\n\n### 解决\n\n尝试`java -jar`启动，使用IDEA remote debug查看。`PdfGenerator.class.getResource(\"/\")`结果如下：\n\n```\njar:file:/my-workspace/project-name/app/target/app.jar!/BOOT-INF/classes!/\n```\n\n也就是获取到了`jar`包里面的目录。\n\n但是我们要取的是jar包里的jar包里的文件，也就是app里的common里的文件。\n\n`PdfGenerator.class.getResource(\"/static/pdf/font.TTF\")` 结果如下：\n\n```\njar:file:/my-workspace/project-name/app/target/app.jar!/BOOT-INF/lib/common.jar!/static/pdf/font.TTF\n```\n\n`PdfGenerator.class.getResource(\"/static\")` 结果如下：\n\n```\njar:file:/my-workspace/project-name/app/target/app.jar!/BOOT-INF/lib/common.jar!/static\n```\n\n对比可以发现，`PdfGenerator.class.getResource(\"/\")` 还是返回app.jar里的classpath，而`PdfGenerator.class.getResource(\"/static\")`就会找到app.jar的`/BOOT-INF/lib/`下的`common.jar`里的`static`目录，也就是我们传入`/status`，resoveName方法会删除开头的`/`，然后开始从app的classpath开始查找，一直找到`/BOOT-INF/lib/`下的`common.jar`里有一个`static`的资源（目录也算资源），于是返回。\n\n这样我们的问题就解决了。\n\n这里其实后面还遇到一个问题，既然`PdfGenerator.class.getResource(\"/static/pdf/font.TTF\")` 可以直接拿到资源，我还为什么`PdfGenerator.class.getResource(\"/static\") + \"pdf/font.TTF\"`？\n\n这里还有一个坑，就是URL的`getPath()`方法，而且URL还重写了`toString()`\n\n```\ngetPath():\nfile:/my-workspace/project-name/app/target/app.jar!/BOOT-INF/lib/common.jar!/static/pdf/font.TTF\n\ntoString():\njar:file:/my-workspace/project-name/app/target/app.jar!/BOOT-INF/lib/common.jar!/static/pdf/font.TTF\n```\n\n少了一个`jar:`，使用`toString()`可以得到的字符串才能用于iText指定字体文件。","source":"_posts/2021-04-29-kongzheng1993-getResource.md","raw":"---\ntitle: java.lang.Class#getResource浅析\nexcerpt: 'JDK'\ntags: [JDK]\ncategories: [JDK]\ncomments: true\ndate: 2021-04-29 19:30:52\n---\n\n最近工程重构，原来单module的maven项目拆分出来api、web、model等多个module，之前我们有一个生成pdf的类`PdfGenerator`，需要获取字体文件：\n\n```java\nprivate static String fontPath = PdfGenerator.class.getResource(\"/\") + \"static/pdf/XXXXX.TTF\";\n```\n\n但是因为项目结构的调整，启动类再`app`模块下，其他的模块都被`app`模块依赖，`PdfGenerator`这个类和对应的字体文件都被挪到了`common`模块下，而上面的`getResoutce(\"/\")` 则会返回classpath，也就是app的`target/classes`目录，显然就找不到`common`模块`resource`目录（当然，编译后应该在`target/classes/static/pdf/`中）下的字体文件了。\n\n### 思考\n\n多module的maven工程，app依赖其他module，这些依赖都是其他module package的jar包，现在要取到字体文件，就需要去common的jar包中取。当然，我们如果再IDE中debug，结果是不对的：\n\n<img src=\"IDE.png\"/>\n\n因为这时的getResource会去所谓的target目录下找，而我们springboot项目通过`java -jar`启动，并不会解压这些jar包，也就不会存在这些所谓的目录。\n\n`java.lang.Class#getResource`做了什么？\n\n```java\n    public java.net.URL getResource(String name) {\n        name = resolveName(name);\n        ClassLoader cl = getClassLoader0();\n        if (cl==null) {\n            // A system class.\n            return ClassLoader.getSystemResource(name);\n        }\n        return cl.getResource(name);\n    }\n```\n\n通过源码可以看到，先处理name，如果是`/`开头，说名要从根目录查找，就去掉第一位，如果不以`/`开头，就获取当前类的路径，然后拼接在name之前，也就是从当前类所在目录查找。然后获取`ClassLoader`，之后调用`ClassLoade`r的`getResource`方法，我们有时候会看到`xxx.class.getClassLoader().getResource()`，就是手动直接调用`ClassLoader`的`getResource`方法。\n\n### 解决\n\n尝试`java -jar`启动，使用IDEA remote debug查看。`PdfGenerator.class.getResource(\"/\")`结果如下：\n\n```\njar:file:/my-workspace/project-name/app/target/app.jar!/BOOT-INF/classes!/\n```\n\n也就是获取到了`jar`包里面的目录。\n\n但是我们要取的是jar包里的jar包里的文件，也就是app里的common里的文件。\n\n`PdfGenerator.class.getResource(\"/static/pdf/font.TTF\")` 结果如下：\n\n```\njar:file:/my-workspace/project-name/app/target/app.jar!/BOOT-INF/lib/common.jar!/static/pdf/font.TTF\n```\n\n`PdfGenerator.class.getResource(\"/static\")` 结果如下：\n\n```\njar:file:/my-workspace/project-name/app/target/app.jar!/BOOT-INF/lib/common.jar!/static\n```\n\n对比可以发现，`PdfGenerator.class.getResource(\"/\")` 还是返回app.jar里的classpath，而`PdfGenerator.class.getResource(\"/static\")`就会找到app.jar的`/BOOT-INF/lib/`下的`common.jar`里的`static`目录，也就是我们传入`/status`，resoveName方法会删除开头的`/`，然后开始从app的classpath开始查找，一直找到`/BOOT-INF/lib/`下的`common.jar`里有一个`static`的资源（目录也算资源），于是返回。\n\n这样我们的问题就解决了。\n\n这里其实后面还遇到一个问题，既然`PdfGenerator.class.getResource(\"/static/pdf/font.TTF\")` 可以直接拿到资源，我还为什么`PdfGenerator.class.getResource(\"/static\") + \"pdf/font.TTF\"`？\n\n这里还有一个坑，就是URL的`getPath()`方法，而且URL还重写了`toString()`\n\n```\ngetPath():\nfile:/my-workspace/project-name/app/target/app.jar!/BOOT-INF/lib/common.jar!/static/pdf/font.TTF\n\ntoString():\njar:file:/my-workspace/project-name/app/target/app.jar!/BOOT-INF/lib/common.jar!/static/pdf/font.TTF\n```\n\n少了一个`jar:`，使用`toString()`可以得到的字符串才能用于iText指定字体文件。","slug":"kongzheng1993-getResource","published":1,"updated":"2023-03-08T07:05:58.809Z","layout":"post","photos":[],"link":"","_id":"clg0k2aly006rt26fys80sagk","content":"<p>最近工程重构，原来单module的maven项目拆分出来api、web、model等多个module，之前我们有一个生成pdf的类<code>PdfGenerator</code>，需要获取字体文件：</p>\n<pre><code class=\"java\">private static String fontPath = PdfGenerator.class.getResource(&quot;/&quot;) + &quot;static/pdf/XXXXX.TTF&quot;;</code></pre>\n<p>但是因为项目结构的调整，启动类再<code>app</code>模块下，其他的模块都被<code>app</code>模块依赖，<code>PdfGenerator</code>这个类和对应的字体文件都被挪到了<code>common</code>模块下，而上面的<code>getResoutce(&quot;/&quot;)</code> 则会返回classpath，也就是app的<code>target/classes</code>目录，显然就找不到<code>common</code>模块<code>resource</code>目录（当然，编译后应该在<code>target/classes/static/pdf/</code>中）下的字体文件了。</p>\n<h3 id=\"思考\"><a href=\"#思考\" class=\"headerlink\" title=\"思考\"></a>思考</h3><p>多module的maven工程，app依赖其他module，这些依赖都是其他module package的jar包，现在要取到字体文件，就需要去common的jar包中取。当然，我们如果再IDE中debug，结果是不对的：</p>\n<img src=\"/2021/04/29/kongzheng1993-getResource/IDE.png\">\n\n<p>因为这时的getResource会去所谓的target目录下找，而我们springboot项目通过<code>java -jar</code>启动，并不会解压这些jar包，也就不会存在这些所谓的目录。</p>\n<p><code>java.lang.Class#getResource</code>做了什么？</p>\n<pre><code class=\"java\">    public java.net.URL getResource(String name) {\n        name = resolveName(name);\n        ClassLoader cl = getClassLoader0();\n        if (cl==null) {\n            // A system class.\n            return ClassLoader.getSystemResource(name);\n        }\n        return cl.getResource(name);\n    }</code></pre>\n<p>通过源码可以看到，先处理name，如果是<code>/</code>开头，说名要从根目录查找，就去掉第一位，如果不以<code>/</code>开头，就获取当前类的路径，然后拼接在name之前，也就是从当前类所在目录查找。然后获取<code>ClassLoader</code>，之后调用<code>ClassLoade</code>r的<code>getResource</code>方法，我们有时候会看到<code>xxx.class.getClassLoader().getResource()</code>，就是手动直接调用<code>ClassLoader</code>的<code>getResource</code>方法。</p>\n<h3 id=\"解决\"><a href=\"#解决\" class=\"headerlink\" title=\"解决\"></a>解决</h3><p>尝试<code>java -jar</code>启动，使用IDEA remote debug查看。<code>PdfGenerator.class.getResource(&quot;/&quot;)</code>结果如下：</p>\n<pre><code>jar:file:/my-workspace/project-name/app/target/app.jar!/BOOT-INF/classes!/</code></pre><p>也就是获取到了<code>jar</code>包里面的目录。</p>\n<p>但是我们要取的是jar包里的jar包里的文件，也就是app里的common里的文件。</p>\n<p><code>PdfGenerator.class.getResource(&quot;/static/pdf/font.TTF&quot;)</code> 结果如下：</p>\n<pre><code>jar:file:/my-workspace/project-name/app/target/app.jar!/BOOT-INF/lib/common.jar!/static/pdf/font.TTF</code></pre><p><code>PdfGenerator.class.getResource(&quot;/static&quot;)</code> 结果如下：</p>\n<pre><code>jar:file:/my-workspace/project-name/app/target/app.jar!/BOOT-INF/lib/common.jar!/static</code></pre><p>对比可以发现，<code>PdfGenerator.class.getResource(&quot;/&quot;)</code> 还是返回app.jar里的classpath，而<code>PdfGenerator.class.getResource(&quot;/static&quot;)</code>就会找到app.jar的<code>/BOOT-INF/lib/</code>下的<code>common.jar</code>里的<code>static</code>目录，也就是我们传入<code>/status</code>，resoveName方法会删除开头的<code>/</code>，然后开始从app的classpath开始查找，一直找到<code>/BOOT-INF/lib/</code>下的<code>common.jar</code>里有一个<code>static</code>的资源（目录也算资源），于是返回。</p>\n<p>这样我们的问题就解决了。</p>\n<p>这里其实后面还遇到一个问题，既然<code>PdfGenerator.class.getResource(&quot;/static/pdf/font.TTF&quot;)</code> 可以直接拿到资源，我还为什么<code>PdfGenerator.class.getResource(&quot;/static&quot;) + &quot;pdf/font.TTF&quot;</code>？</p>\n<p>这里还有一个坑，就是URL的<code>getPath()</code>方法，而且URL还重写了<code>toString()</code></p>\n<pre><code>getPath():\nfile:/my-workspace/project-name/app/target/app.jar!/BOOT-INF/lib/common.jar!/static/pdf/font.TTF\n\ntoString():\njar:file:/my-workspace/project-name/app/target/app.jar!/BOOT-INF/lib/common.jar!/static/pdf/font.TTF</code></pre><p>少了一个<code>jar:</code>，使用<code>toString()</code>可以得到的字符串才能用于iText指定字体文件。</p>\n","site":{"data":{}},"more":"<p>最近工程重构，原来单module的maven项目拆分出来api、web、model等多个module，之前我们有一个生成pdf的类<code>PdfGenerator</code>，需要获取字体文件：</p>\n<pre><code class=\"java\">private static String fontPath = PdfGenerator.class.getResource(&quot;/&quot;) + &quot;static/pdf/XXXXX.TTF&quot;;</code></pre>\n<p>但是因为项目结构的调整，启动类再<code>app</code>模块下，其他的模块都被<code>app</code>模块依赖，<code>PdfGenerator</code>这个类和对应的字体文件都被挪到了<code>common</code>模块下，而上面的<code>getResoutce(&quot;/&quot;)</code> 则会返回classpath，也就是app的<code>target/classes</code>目录，显然就找不到<code>common</code>模块<code>resource</code>目录（当然，编译后应该在<code>target/classes/static/pdf/</code>中）下的字体文件了。</p>\n<h3 id=\"思考\"><a href=\"#思考\" class=\"headerlink\" title=\"思考\"></a>思考</h3><p>多module的maven工程，app依赖其他module，这些依赖都是其他module package的jar包，现在要取到字体文件，就需要去common的jar包中取。当然，我们如果再IDE中debug，结果是不对的：</p>\n<img src=\"/2021/04/29/kongzheng1993-getResource/IDE.png\">\n\n<p>因为这时的getResource会去所谓的target目录下找，而我们springboot项目通过<code>java -jar</code>启动，并不会解压这些jar包，也就不会存在这些所谓的目录。</p>\n<p><code>java.lang.Class#getResource</code>做了什么？</p>\n<pre><code class=\"java\">    public java.net.URL getResource(String name) {\n        name = resolveName(name);\n        ClassLoader cl = getClassLoader0();\n        if (cl==null) {\n            // A system class.\n            return ClassLoader.getSystemResource(name);\n        }\n        return cl.getResource(name);\n    }</code></pre>\n<p>通过源码可以看到，先处理name，如果是<code>/</code>开头，说名要从根目录查找，就去掉第一位，如果不以<code>/</code>开头，就获取当前类的路径，然后拼接在name之前，也就是从当前类所在目录查找。然后获取<code>ClassLoader</code>，之后调用<code>ClassLoade</code>r的<code>getResource</code>方法，我们有时候会看到<code>xxx.class.getClassLoader().getResource()</code>，就是手动直接调用<code>ClassLoader</code>的<code>getResource</code>方法。</p>\n<h3 id=\"解决\"><a href=\"#解决\" class=\"headerlink\" title=\"解决\"></a>解决</h3><p>尝试<code>java -jar</code>启动，使用IDEA remote debug查看。<code>PdfGenerator.class.getResource(&quot;/&quot;)</code>结果如下：</p>\n<pre><code>jar:file:/my-workspace/project-name/app/target/app.jar!/BOOT-INF/classes!/</code></pre><p>也就是获取到了<code>jar</code>包里面的目录。</p>\n<p>但是我们要取的是jar包里的jar包里的文件，也就是app里的common里的文件。</p>\n<p><code>PdfGenerator.class.getResource(&quot;/static/pdf/font.TTF&quot;)</code> 结果如下：</p>\n<pre><code>jar:file:/my-workspace/project-name/app/target/app.jar!/BOOT-INF/lib/common.jar!/static/pdf/font.TTF</code></pre><p><code>PdfGenerator.class.getResource(&quot;/static&quot;)</code> 结果如下：</p>\n<pre><code>jar:file:/my-workspace/project-name/app/target/app.jar!/BOOT-INF/lib/common.jar!/static</code></pre><p>对比可以发现，<code>PdfGenerator.class.getResource(&quot;/&quot;)</code> 还是返回app.jar里的classpath，而<code>PdfGenerator.class.getResource(&quot;/static&quot;)</code>就会找到app.jar的<code>/BOOT-INF/lib/</code>下的<code>common.jar</code>里的<code>static</code>目录，也就是我们传入<code>/status</code>，resoveName方法会删除开头的<code>/</code>，然后开始从app的classpath开始查找，一直找到<code>/BOOT-INF/lib/</code>下的<code>common.jar</code>里有一个<code>static</code>的资源（目录也算资源），于是返回。</p>\n<p>这样我们的问题就解决了。</p>\n<p>这里其实后面还遇到一个问题，既然<code>PdfGenerator.class.getResource(&quot;/static/pdf/font.TTF&quot;)</code> 可以直接拿到资源，我还为什么<code>PdfGenerator.class.getResource(&quot;/static&quot;) + &quot;pdf/font.TTF&quot;</code>？</p>\n<p>这里还有一个坑，就是URL的<code>getPath()</code>方法，而且URL还重写了<code>toString()</code></p>\n<pre><code>getPath():\nfile:/my-workspace/project-name/app/target/app.jar!/BOOT-INF/lib/common.jar!/static/pdf/font.TTF\n\ntoString():\njar:file:/my-workspace/project-name/app/target/app.jar!/BOOT-INF/lib/common.jar!/static/pdf/font.TTF</code></pre><p>少了一个<code>jar:</code>，使用<code>toString()</code>可以得到的字符串才能用于iText指定字体文件。</p>\n"},{"title":"最近的一些感悟","excerpt":"","comments":1,"date":"2021-06-06T05:30:10.000Z","_content":"\n### 发生什么事了\n\n最近很忙，手忙脚乱，顾得了东就顾不了西，感觉身体被掏空，但是产出却很少。\n\n周五--2021年6月4日，炸了。准确说应该是6月3号晚上。\n\n那天晚上，我们要上线一个项目，有很多SQL脚本需要提交，这个项目主要的东西是我负责做的，所以我主动去提交sql申请。我们的数据库管理平台提交sql的时候，要求要把对同一个表的操作合并到一条sql，也就是这个表，你既要增加字段，又要修改字段，还要新建索引，需要合并成`alter table xxx add column xxx, modify column xxx, add index xxx;`，这时候，我一个粗心，把主表的唯一索引加到了子表中……\n\n很多人可能说，没事的，子表的数据本来就是重复的，你根本就加不上。神奇的是，我加上了。因为我们的数据库管理平台，在修改一个大表的时候，会创建临时表，然后根据原有的ddl和新增的ddl，创建一个最终符合要求的表（也就是加上唯一索引后的表），最后将临时表的数据insert回来。有了唯一索引，重复的数据肯定是回不了啊……但是我们并不知道这里面有这个逻辑。最后业务功能收到影响，我们找了一个多小时，才发现数据少了，咨询dba才知道公司的数据库管理平台有这个逻辑。后面就是近一个小时的恢复数据。晚上12点，系统恢复正常。\n\n**我很抱歉，因为一个粗心大意，让两个同事陪我熬到这么晚，如果没有这个事情，上线可以很顺利的。**\n\n第二天6月4日，组长就数据库管理平台的这个情况，写了一篇文章，解释了数据库平台ddl执行的逻辑。我知道这么做是对的，很多人都不知道提交ddl后是这么执行的，让大家都了解这个逻辑，对很多人都有帮助，以后一旦有人也出现这样的问题，第一时间就能去找临时表恢复数据。\n\n文章分享出来后，领导很生气：“这种事儿，为啥能误操作，都想啥呢？还能不能干！”。每一个字，每一个标点符号，都让我无地自容。我也想问自己，当时在想什么！\n\n### 关于这件事情的思考\n\n晚上八点，我修复了前一天上线后业务人员提出的一些小问题，回家。\n\n回家路上，静下来思考这件事情。是我的错，是因为我的粗心。不止一次的想，如果我当时仔细检查一下，如果不出这个差错，一切该多么美好！\n\n我不禁对自己产生了怀疑，我到底适不适合做程序员，我怎么会这么粗心！\n\n我不禁对自己的职业产生了怀疑，压力好大，每一秒钟都要绷紧神经，谨慎敲出每一行代码，小心自己每一个操作。\n\n我不禁对人生产生了怀疑，我的人生，每个工作日都要忙到深夜回家，周末也要抽出一天来工作，这到底有没有意义！\n\n带着各种想法，回到了家。打开一听可乐，拨通了儿时最好的朋友的电话，我想找个人聊聊，必须找个人聊聊，不然真的会疯掉！\n\n我把事情的来龙去脉和最近的压力，一股脑全都抛出来。他安慰我说，我也算是因为一个错误，了解到了一个很多人都不知道的问题，这样也算是帮很多人趟出了一个坑。他说不至于怀疑自己、怀疑人生。他跟我讲他最近的生活，前段时间孩子总发烧，隔三岔五去医院，很多次，他照顾孩子一晚上，一大早照常上班，该是他的工作，也不会因为家里有事而变少。他也怀疑过自己是不是入错行了，但是仔细想想，现在自己干的工作，就是自己最擅长的事情！要相信自己！\n\n他还跟我说了一个想法，说以前每次遇到一个问题，感觉自己完蛋了，这辈子都完了，但是过一段时间，发现这件事又算什么，甚至自己都想不起来是什么事情了。我回想一下，上次有这种感觉，好像是高二上课被老师抓到玩手机了……\n\n**人生没有过不去的坎，除非你一蹶不振了！**\n\n出问题了怎么办？积极一点吧！积极承担自己的责任，积极总结，积极改正，然后积极的继续奋斗！\n\n最后，我很庆幸，我有这么一个好朋友，也幸好我打给他，如果是一个不够强大的人，或许只会和我一起抱怨……\n\n---\n\n也不知道为什么要写下来，感觉很矫情，就当是个总结吧。不管今后如何，我一定积极一点，认真生活，做一个成熟的人！","source":"_posts/2021-06-06-kongzheng1993-最近的一些感悟.md","raw":"---\ntitle: 最近的一些感悟\nexcerpt: '杂谈'\ntags: [杂谈]\ncategories: [杂谈]\ncomments: true\ndate: 2021-06-06 13:30:10\n---\n\n### 发生什么事了\n\n最近很忙，手忙脚乱，顾得了东就顾不了西，感觉身体被掏空，但是产出却很少。\n\n周五--2021年6月4日，炸了。准确说应该是6月3号晚上。\n\n那天晚上，我们要上线一个项目，有很多SQL脚本需要提交，这个项目主要的东西是我负责做的，所以我主动去提交sql申请。我们的数据库管理平台提交sql的时候，要求要把对同一个表的操作合并到一条sql，也就是这个表，你既要增加字段，又要修改字段，还要新建索引，需要合并成`alter table xxx add column xxx, modify column xxx, add index xxx;`，这时候，我一个粗心，把主表的唯一索引加到了子表中……\n\n很多人可能说，没事的，子表的数据本来就是重复的，你根本就加不上。神奇的是，我加上了。因为我们的数据库管理平台，在修改一个大表的时候，会创建临时表，然后根据原有的ddl和新增的ddl，创建一个最终符合要求的表（也就是加上唯一索引后的表），最后将临时表的数据insert回来。有了唯一索引，重复的数据肯定是回不了啊……但是我们并不知道这里面有这个逻辑。最后业务功能收到影响，我们找了一个多小时，才发现数据少了，咨询dba才知道公司的数据库管理平台有这个逻辑。后面就是近一个小时的恢复数据。晚上12点，系统恢复正常。\n\n**我很抱歉，因为一个粗心大意，让两个同事陪我熬到这么晚，如果没有这个事情，上线可以很顺利的。**\n\n第二天6月4日，组长就数据库管理平台的这个情况，写了一篇文章，解释了数据库平台ddl执行的逻辑。我知道这么做是对的，很多人都不知道提交ddl后是这么执行的，让大家都了解这个逻辑，对很多人都有帮助，以后一旦有人也出现这样的问题，第一时间就能去找临时表恢复数据。\n\n文章分享出来后，领导很生气：“这种事儿，为啥能误操作，都想啥呢？还能不能干！”。每一个字，每一个标点符号，都让我无地自容。我也想问自己，当时在想什么！\n\n### 关于这件事情的思考\n\n晚上八点，我修复了前一天上线后业务人员提出的一些小问题，回家。\n\n回家路上，静下来思考这件事情。是我的错，是因为我的粗心。不止一次的想，如果我当时仔细检查一下，如果不出这个差错，一切该多么美好！\n\n我不禁对自己产生了怀疑，我到底适不适合做程序员，我怎么会这么粗心！\n\n我不禁对自己的职业产生了怀疑，压力好大，每一秒钟都要绷紧神经，谨慎敲出每一行代码，小心自己每一个操作。\n\n我不禁对人生产生了怀疑，我的人生，每个工作日都要忙到深夜回家，周末也要抽出一天来工作，这到底有没有意义！\n\n带着各种想法，回到了家。打开一听可乐，拨通了儿时最好的朋友的电话，我想找个人聊聊，必须找个人聊聊，不然真的会疯掉！\n\n我把事情的来龙去脉和最近的压力，一股脑全都抛出来。他安慰我说，我也算是因为一个错误，了解到了一个很多人都不知道的问题，这样也算是帮很多人趟出了一个坑。他说不至于怀疑自己、怀疑人生。他跟我讲他最近的生活，前段时间孩子总发烧，隔三岔五去医院，很多次，他照顾孩子一晚上，一大早照常上班，该是他的工作，也不会因为家里有事而变少。他也怀疑过自己是不是入错行了，但是仔细想想，现在自己干的工作，就是自己最擅长的事情！要相信自己！\n\n他还跟我说了一个想法，说以前每次遇到一个问题，感觉自己完蛋了，这辈子都完了，但是过一段时间，发现这件事又算什么，甚至自己都想不起来是什么事情了。我回想一下，上次有这种感觉，好像是高二上课被老师抓到玩手机了……\n\n**人生没有过不去的坎，除非你一蹶不振了！**\n\n出问题了怎么办？积极一点吧！积极承担自己的责任，积极总结，积极改正，然后积极的继续奋斗！\n\n最后，我很庆幸，我有这么一个好朋友，也幸好我打给他，如果是一个不够强大的人，或许只会和我一起抱怨……\n\n---\n\n也不知道为什么要写下来，感觉很矫情，就当是个总结吧。不管今后如何，我一定积极一点，认真生活，做一个成熟的人！","slug":"kongzheng1993-最近的一些感悟","published":1,"updated":"2023-03-08T07:05:58.810Z","layout":"post","photos":[],"link":"","_id":"clg0k2aly006tt26f6wx9xa44","content":"<h3 id=\"发生什么事了\"><a href=\"#发生什么事了\" class=\"headerlink\" title=\"发生什么事了\"></a>发生什么事了</h3><p>最近很忙，手忙脚乱，顾得了东就顾不了西，感觉身体被掏空，但是产出却很少。</p>\n<p>周五–2021年6月4日，炸了。准确说应该是6月3号晚上。</p>\n<p>那天晚上，我们要上线一个项目，有很多SQL脚本需要提交，这个项目主要的东西是我负责做的，所以我主动去提交sql申请。我们的数据库管理平台提交sql的时候，要求要把对同一个表的操作合并到一条sql，也就是这个表，你既要增加字段，又要修改字段，还要新建索引，需要合并成<code>alter table xxx add column xxx, modify column xxx, add index xxx;</code>，这时候，我一个粗心，把主表的唯一索引加到了子表中……</p>\n<p>很多人可能说，没事的，子表的数据本来就是重复的，你根本就加不上。神奇的是，我加上了。因为我们的数据库管理平台，在修改一个大表的时候，会创建临时表，然后根据原有的ddl和新增的ddl，创建一个最终符合要求的表（也就是加上唯一索引后的表），最后将临时表的数据insert回来。有了唯一索引，重复的数据肯定是回不了啊……但是我们并不知道这里面有这个逻辑。最后业务功能收到影响，我们找了一个多小时，才发现数据少了，咨询dba才知道公司的数据库管理平台有这个逻辑。后面就是近一个小时的恢复数据。晚上12点，系统恢复正常。</p>\n<p><strong>我很抱歉，因为一个粗心大意，让两个同事陪我熬到这么晚，如果没有这个事情，上线可以很顺利的。</strong></p>\n<p>第二天6月4日，组长就数据库管理平台的这个情况，写了一篇文章，解释了数据库平台ddl执行的逻辑。我知道这么做是对的，很多人都不知道提交ddl后是这么执行的，让大家都了解这个逻辑，对很多人都有帮助，以后一旦有人也出现这样的问题，第一时间就能去找临时表恢复数据。</p>\n<p>文章分享出来后，领导很生气：“这种事儿，为啥能误操作，都想啥呢？还能不能干！”。每一个字，每一个标点符号，都让我无地自容。我也想问自己，当时在想什么！</p>\n<h3 id=\"关于这件事情的思考\"><a href=\"#关于这件事情的思考\" class=\"headerlink\" title=\"关于这件事情的思考\"></a>关于这件事情的思考</h3><p>晚上八点，我修复了前一天上线后业务人员提出的一些小问题，回家。</p>\n<p>回家路上，静下来思考这件事情。是我的错，是因为我的粗心。不止一次的想，如果我当时仔细检查一下，如果不出这个差错，一切该多么美好！</p>\n<p>我不禁对自己产生了怀疑，我到底适不适合做程序员，我怎么会这么粗心！</p>\n<p>我不禁对自己的职业产生了怀疑，压力好大，每一秒钟都要绷紧神经，谨慎敲出每一行代码，小心自己每一个操作。</p>\n<p>我不禁对人生产生了怀疑，我的人生，每个工作日都要忙到深夜回家，周末也要抽出一天来工作，这到底有没有意义！</p>\n<p>带着各种想法，回到了家。打开一听可乐，拨通了儿时最好的朋友的电话，我想找个人聊聊，必须找个人聊聊，不然真的会疯掉！</p>\n<p>我把事情的来龙去脉和最近的压力，一股脑全都抛出来。他安慰我说，我也算是因为一个错误，了解到了一个很多人都不知道的问题，这样也算是帮很多人趟出了一个坑。他说不至于怀疑自己、怀疑人生。他跟我讲他最近的生活，前段时间孩子总发烧，隔三岔五去医院，很多次，他照顾孩子一晚上，一大早照常上班，该是他的工作，也不会因为家里有事而变少。他也怀疑过自己是不是入错行了，但是仔细想想，现在自己干的工作，就是自己最擅长的事情！要相信自己！</p>\n<p>他还跟我说了一个想法，说以前每次遇到一个问题，感觉自己完蛋了，这辈子都完了，但是过一段时间，发现这件事又算什么，甚至自己都想不起来是什么事情了。我回想一下，上次有这种感觉，好像是高二上课被老师抓到玩手机了……</p>\n<p><strong>人生没有过不去的坎，除非你一蹶不振了！</strong></p>\n<p>出问题了怎么办？积极一点吧！积极承担自己的责任，积极总结，积极改正，然后积极的继续奋斗！</p>\n<p>最后，我很庆幸，我有这么一个好朋友，也幸好我打给他，如果是一个不够强大的人，或许只会和我一起抱怨……</p>\n<hr>\n<p>也不知道为什么要写下来，感觉很矫情，就当是个总结吧。不管今后如何，我一定积极一点，认真生活，做一个成熟的人！</p>\n","site":{"data":{}},"more":"<h3 id=\"发生什么事了\"><a href=\"#发生什么事了\" class=\"headerlink\" title=\"发生什么事了\"></a>发生什么事了</h3><p>最近很忙，手忙脚乱，顾得了东就顾不了西，感觉身体被掏空，但是产出却很少。</p>\n<p>周五–2021年6月4日，炸了。准确说应该是6月3号晚上。</p>\n<p>那天晚上，我们要上线一个项目，有很多SQL脚本需要提交，这个项目主要的东西是我负责做的，所以我主动去提交sql申请。我们的数据库管理平台提交sql的时候，要求要把对同一个表的操作合并到一条sql，也就是这个表，你既要增加字段，又要修改字段，还要新建索引，需要合并成<code>alter table xxx add column xxx, modify column xxx, add index xxx;</code>，这时候，我一个粗心，把主表的唯一索引加到了子表中……</p>\n<p>很多人可能说，没事的，子表的数据本来就是重复的，你根本就加不上。神奇的是，我加上了。因为我们的数据库管理平台，在修改一个大表的时候，会创建临时表，然后根据原有的ddl和新增的ddl，创建一个最终符合要求的表（也就是加上唯一索引后的表），最后将临时表的数据insert回来。有了唯一索引，重复的数据肯定是回不了啊……但是我们并不知道这里面有这个逻辑。最后业务功能收到影响，我们找了一个多小时，才发现数据少了，咨询dba才知道公司的数据库管理平台有这个逻辑。后面就是近一个小时的恢复数据。晚上12点，系统恢复正常。</p>\n<p><strong>我很抱歉，因为一个粗心大意，让两个同事陪我熬到这么晚，如果没有这个事情，上线可以很顺利的。</strong></p>\n<p>第二天6月4日，组长就数据库管理平台的这个情况，写了一篇文章，解释了数据库平台ddl执行的逻辑。我知道这么做是对的，很多人都不知道提交ddl后是这么执行的，让大家都了解这个逻辑，对很多人都有帮助，以后一旦有人也出现这样的问题，第一时间就能去找临时表恢复数据。</p>\n<p>文章分享出来后，领导很生气：“这种事儿，为啥能误操作，都想啥呢？还能不能干！”。每一个字，每一个标点符号，都让我无地自容。我也想问自己，当时在想什么！</p>\n<h3 id=\"关于这件事情的思考\"><a href=\"#关于这件事情的思考\" class=\"headerlink\" title=\"关于这件事情的思考\"></a>关于这件事情的思考</h3><p>晚上八点，我修复了前一天上线后业务人员提出的一些小问题，回家。</p>\n<p>回家路上，静下来思考这件事情。是我的错，是因为我的粗心。不止一次的想，如果我当时仔细检查一下，如果不出这个差错，一切该多么美好！</p>\n<p>我不禁对自己产生了怀疑，我到底适不适合做程序员，我怎么会这么粗心！</p>\n<p>我不禁对自己的职业产生了怀疑，压力好大，每一秒钟都要绷紧神经，谨慎敲出每一行代码，小心自己每一个操作。</p>\n<p>我不禁对人生产生了怀疑，我的人生，每个工作日都要忙到深夜回家，周末也要抽出一天来工作，这到底有没有意义！</p>\n<p>带着各种想法，回到了家。打开一听可乐，拨通了儿时最好的朋友的电话，我想找个人聊聊，必须找个人聊聊，不然真的会疯掉！</p>\n<p>我把事情的来龙去脉和最近的压力，一股脑全都抛出来。他安慰我说，我也算是因为一个错误，了解到了一个很多人都不知道的问题，这样也算是帮很多人趟出了一个坑。他说不至于怀疑自己、怀疑人生。他跟我讲他最近的生活，前段时间孩子总发烧，隔三岔五去医院，很多次，他照顾孩子一晚上，一大早照常上班，该是他的工作，也不会因为家里有事而变少。他也怀疑过自己是不是入错行了，但是仔细想想，现在自己干的工作，就是自己最擅长的事情！要相信自己！</p>\n<p>他还跟我说了一个想法，说以前每次遇到一个问题，感觉自己完蛋了，这辈子都完了，但是过一段时间，发现这件事又算什么，甚至自己都想不起来是什么事情了。我回想一下，上次有这种感觉，好像是高二上课被老师抓到玩手机了……</p>\n<p><strong>人生没有过不去的坎，除非你一蹶不振了！</strong></p>\n<p>出问题了怎么办？积极一点吧！积极承担自己的责任，积极总结，积极改正，然后积极的继续奋斗！</p>\n<p>最后，我很庆幸，我有这么一个好朋友，也幸好我打给他，如果是一个不够强大的人，或许只会和我一起抱怨……</p>\n<hr>\n<p>也不知道为什么要写下来，感觉很矫情，就当是个总结吧。不管今后如何，我一定积极一点，认真生活，做一个成熟的人！</p>\n"},{"title":"JVM调优","excerpt":"","comments":1,"date":"2021-07-04T05:30:10.000Z","_content":"\n\n## 为什么\n\n1. 为什么要jvm调优？ 因为要尽量减少GC的次数\n2. 为什么要减少GC？ 因为GC时会发成STW，造成所有的java代码停止运行，native代码可以运行，但是不能与JVM进行交互。\n3. 为什么GC要STW，不能一起运行吗？因为程序运行会导致内存中数据的状态变化，比如根据可达性算法通过GC Root查找没有被引用的对象，开始gc的时候一个对象还不是垃圾，但是如果我们的程序依然在运行，线程结束后，栈被清空，一些堆内的对象失去了引用，就变成垃圾了，这时候如果gc线程再回去找垃圾，算法会很低效，因为数据的状态一直会变，不如直接stw，一把将所有的垃圾回收完，再恢复运行。\n\n## 知识点\n\n### 1. JVM\n\nJVM被分为三个主要的子系统：类加载器子系统、运行时数据区和执行引擎 。主要研究的是运行时数据区，也就是JVM内存结构，特别注意其中Java 堆和方法区是**线程共享**的。其他都是**线程私有**的，而jvm调优主要就是调整这里面的堆\n\n<img src='JVM.png'>\n\n<img src='stack.png'>\n\nJava 堆并不是单纯的一整块区域，**实际上java堆是根据对象存活时间的不同**，Java 堆还被分为年轻代、老年代两个区域，年轻代还被进一步划分为 Eden 区、From Survivor 0、To Survivor 1 区。并且默认的虚拟机配置比例是Eden：from ：to = 8:1:1 。简单来说就是：\n\n**Java堆 = 老年代 + 新生代**\n\n新生代 = Eden + S0 + S1\n\n默认Eden:from:to = 8:1:1\n\n`-Xms` 堆容量初始大小（堆包括新生代和老年代）。 例如：-Xms 20M\n`-Xmx` 堆总共（最大）大小。 例如：-Xmx 30M\n**注意：建议将 -Xms 和 -Xmx 设为相同值，避免每次垃圾回收完成后JVM重新分配内存！**\n`-Xmn` 新生代容量大小。例如：-Xmn 10M\n`-XX` SurvivorRatio` 设置参数Eden、form和to的比例 【比例参数Eden、form和to默认是8:1:1】例如：-XX： SurvivorRatio=8 代表比例8:1:1\n\n虽然没有直接设置老年代的参数，但是可以设置堆空间大小和新生代空间大小两个参数来间接控制：\n**老年代空间大小 = 堆空间大小 - 年轻代大空间大小**\n\n当我们的 Java 堆内有足够的空间去完成实例分配时，并且堆也无法扩展，将会抛出我们常见的**OutOfMemoryError** 异常，也就是我们常说的**OOM** 异常\n\n### 2. JVM新生代8:1:1的原因\n\n统计学测算出当内存使用超过98%以上时，内存就应该被minor gc时回收一次。但是实际应用中，我们不能较真的只给 他们留下2%，换句话说当内存使用达到98%时才GC 就有点晚了，应该是多一些预留10%内存空间，这预留下来的空间我们称为S区（有两个s区s1和s0），S区是用来存储新生代GC后存活下来的对象，而我们知道新生代GC算法使用的是复制回收算法。\n\n所以我们实际GC发生是在，新生代内存使用达到90%时开始进行，复制存活的对象到S1区，要知道GC结束后在S1区活下来的对象，在下一次GC的范围是，eden区和S1，把这两部分存活的对象放入S0区，如此反复，下一次GC范围是eden区和S0区，一句话每次GC范围是eden区+一个S区。（比例是，eden：s1:s0=80%:10%:10%=8:1:1）这里的eden区（80%） 和其中的一个  S区（10%） 合起来共占据90%，GC就是清理的他们，始终保持着其中一个S区是空留的，保证GC的时候复制存活的对象有个存储的地方。\n\n**这样的好处是什么？**\n\n高效！！！GC 算法总体就是三种：1 复制 2 标记 3标记整理，垃圾回收算法将这几种选择起来相互组合。毫无疑问，只存在少量存活的对象，只需复制少量存活的对象，远远比标记和标记整理高效多。\n\n**如何判断对象存活可用？**\n\n可达性分析法来判断:通过一系列称为`GCRoot`对象做起点，从这些节点向下搜索，搜索所走过的路径称为引用链，如果一个对象在引用链上，就说是可达的，这种对象就是需要存活下来的。\n\n**作为GC Roots的对象包括下面几种：**\n\n1. 当前虚拟机栈中局部变量表中的引用的对象\n\n2. 当前本地方法栈中局部变量表中的引用的对象\n\n3. 方法区中类静态属性引用的对象\n\n4. 方法区中的常量引用的对象\n\n**设置Survivor区是为了减少送到老年代的对象**\n\n","source":"_posts/2021-07-04-kongzheng1993-JVM调优.md","raw":"---\ntitle: JVM调优\nexcerpt: 'JVM'\ntags: [JVM]\ncategories: [JVM]\ncomments: true\ndate: 2021-07-04 13:30:10\n---\n\n\n## 为什么\n\n1. 为什么要jvm调优？ 因为要尽量减少GC的次数\n2. 为什么要减少GC？ 因为GC时会发成STW，造成所有的java代码停止运行，native代码可以运行，但是不能与JVM进行交互。\n3. 为什么GC要STW，不能一起运行吗？因为程序运行会导致内存中数据的状态变化，比如根据可达性算法通过GC Root查找没有被引用的对象，开始gc的时候一个对象还不是垃圾，但是如果我们的程序依然在运行，线程结束后，栈被清空，一些堆内的对象失去了引用，就变成垃圾了，这时候如果gc线程再回去找垃圾，算法会很低效，因为数据的状态一直会变，不如直接stw，一把将所有的垃圾回收完，再恢复运行。\n\n## 知识点\n\n### 1. JVM\n\nJVM被分为三个主要的子系统：类加载器子系统、运行时数据区和执行引擎 。主要研究的是运行时数据区，也就是JVM内存结构，特别注意其中Java 堆和方法区是**线程共享**的。其他都是**线程私有**的，而jvm调优主要就是调整这里面的堆\n\n<img src='JVM.png'>\n\n<img src='stack.png'>\n\nJava 堆并不是单纯的一整块区域，**实际上java堆是根据对象存活时间的不同**，Java 堆还被分为年轻代、老年代两个区域，年轻代还被进一步划分为 Eden 区、From Survivor 0、To Survivor 1 区。并且默认的虚拟机配置比例是Eden：from ：to = 8:1:1 。简单来说就是：\n\n**Java堆 = 老年代 + 新生代**\n\n新生代 = Eden + S0 + S1\n\n默认Eden:from:to = 8:1:1\n\n`-Xms` 堆容量初始大小（堆包括新生代和老年代）。 例如：-Xms 20M\n`-Xmx` 堆总共（最大）大小。 例如：-Xmx 30M\n**注意：建议将 -Xms 和 -Xmx 设为相同值，避免每次垃圾回收完成后JVM重新分配内存！**\n`-Xmn` 新生代容量大小。例如：-Xmn 10M\n`-XX` SurvivorRatio` 设置参数Eden、form和to的比例 【比例参数Eden、form和to默认是8:1:1】例如：-XX： SurvivorRatio=8 代表比例8:1:1\n\n虽然没有直接设置老年代的参数，但是可以设置堆空间大小和新生代空间大小两个参数来间接控制：\n**老年代空间大小 = 堆空间大小 - 年轻代大空间大小**\n\n当我们的 Java 堆内有足够的空间去完成实例分配时，并且堆也无法扩展，将会抛出我们常见的**OutOfMemoryError** 异常，也就是我们常说的**OOM** 异常\n\n### 2. JVM新生代8:1:1的原因\n\n统计学测算出当内存使用超过98%以上时，内存就应该被minor gc时回收一次。但是实际应用中，我们不能较真的只给 他们留下2%，换句话说当内存使用达到98%时才GC 就有点晚了，应该是多一些预留10%内存空间，这预留下来的空间我们称为S区（有两个s区s1和s0），S区是用来存储新生代GC后存活下来的对象，而我们知道新生代GC算法使用的是复制回收算法。\n\n所以我们实际GC发生是在，新生代内存使用达到90%时开始进行，复制存活的对象到S1区，要知道GC结束后在S1区活下来的对象，在下一次GC的范围是，eden区和S1，把这两部分存活的对象放入S0区，如此反复，下一次GC范围是eden区和S0区，一句话每次GC范围是eden区+一个S区。（比例是，eden：s1:s0=80%:10%:10%=8:1:1）这里的eden区（80%） 和其中的一个  S区（10%） 合起来共占据90%，GC就是清理的他们，始终保持着其中一个S区是空留的，保证GC的时候复制存活的对象有个存储的地方。\n\n**这样的好处是什么？**\n\n高效！！！GC 算法总体就是三种：1 复制 2 标记 3标记整理，垃圾回收算法将这几种选择起来相互组合。毫无疑问，只存在少量存活的对象，只需复制少量存活的对象，远远比标记和标记整理高效多。\n\n**如何判断对象存活可用？**\n\n可达性分析法来判断:通过一系列称为`GCRoot`对象做起点，从这些节点向下搜索，搜索所走过的路径称为引用链，如果一个对象在引用链上，就说是可达的，这种对象就是需要存活下来的。\n\n**作为GC Roots的对象包括下面几种：**\n\n1. 当前虚拟机栈中局部变量表中的引用的对象\n\n2. 当前本地方法栈中局部变量表中的引用的对象\n\n3. 方法区中类静态属性引用的对象\n\n4. 方法区中的常量引用的对象\n\n**设置Survivor区是为了减少送到老年代的对象**\n\n","slug":"kongzheng1993-JVM调优","published":1,"updated":"2023-03-08T07:05:58.812Z","layout":"post","photos":[],"link":"","_id":"clg0k2alz006wt26fd80oidjh","content":"<h2 id=\"为什么\"><a href=\"#为什么\" class=\"headerlink\" title=\"为什么\"></a>为什么</h2><ol>\n<li>为什么要jvm调优？ 因为要尽量减少GC的次数</li>\n<li>为什么要减少GC？ 因为GC时会发成STW，造成所有的java代码停止运行，native代码可以运行，但是不能与JVM进行交互。</li>\n<li>为什么GC要STW，不能一起运行吗？因为程序运行会导致内存中数据的状态变化，比如根据可达性算法通过GC Root查找没有被引用的对象，开始gc的时候一个对象还不是垃圾，但是如果我们的程序依然在运行，线程结束后，栈被清空，一些堆内的对象失去了引用，就变成垃圾了，这时候如果gc线程再回去找垃圾，算法会很低效，因为数据的状态一直会变，不如直接stw，一把将所有的垃圾回收完，再恢复运行。</li>\n</ol>\n<h2 id=\"知识点\"><a href=\"#知识点\" class=\"headerlink\" title=\"知识点\"></a>知识点</h2><h3 id=\"1-JVM\"><a href=\"#1-JVM\" class=\"headerlink\" title=\"1. JVM\"></a>1. JVM</h3><p>JVM被分为三个主要的子系统：类加载器子系统、运行时数据区和执行引擎 。主要研究的是运行时数据区，也就是JVM内存结构，特别注意其中Java 堆和方法区是<strong>线程共享</strong>的。其他都是<strong>线程私有</strong>的，而jvm调优主要就是调整这里面的堆</p>\n<img src=\"/2021/07/04/kongzheng1993-JVM调优/JVM.png\">\n\n<img src=\"/2021/07/04/kongzheng1993-JVM调优/stack.png\">\n\n<p>Java 堆并不是单纯的一整块区域，<strong>实际上java堆是根据对象存活时间的不同</strong>，Java 堆还被分为年轻代、老年代两个区域，年轻代还被进一步划分为 Eden 区、From Survivor 0、To Survivor 1 区。并且默认的虚拟机配置比例是Eden：from ：to = 8:1:1 。简单来说就是：</p>\n<p><strong>Java堆 = 老年代 + 新生代</strong></p>\n<p>新生代 = Eden + S0 + S1</p>\n<p>默认Eden:from:to = 8:1:1</p>\n<p><code>-Xms</code> 堆容量初始大小（堆包括新生代和老年代）。 例如：-Xms 20M<br><code>-Xmx</code> 堆总共（最大）大小。 例如：-Xmx 30M<br><strong>注意：建议将 -Xms 和 -Xmx 设为相同值，避免每次垃圾回收完成后JVM重新分配内存！</strong><br><code>-Xmn</code> 新生代容量大小。例如：-Xmn 10M<br><code>-XX</code> SurvivorRatio` 设置参数Eden、form和to的比例 【比例参数Eden、form和to默认是8:1:1】例如：-XX： SurvivorRatio=8 代表比例8:1:1</p>\n<p>虽然没有直接设置老年代的参数，但是可以设置堆空间大小和新生代空间大小两个参数来间接控制：<br><strong>老年代空间大小 = 堆空间大小 - 年轻代大空间大小</strong></p>\n<p>当我们的 Java 堆内有足够的空间去完成实例分配时，并且堆也无法扩展，将会抛出我们常见的<strong>OutOfMemoryError</strong> 异常，也就是我们常说的<strong>OOM</strong> 异常</p>\n<h3 id=\"2-JVM新生代8-1-1的原因\"><a href=\"#2-JVM新生代8-1-1的原因\" class=\"headerlink\" title=\"2. JVM新生代8:1:1的原因\"></a>2. JVM新生代8:1:1的原因</h3><p>统计学测算出当内存使用超过98%以上时，内存就应该被minor gc时回收一次。但是实际应用中，我们不能较真的只给 他们留下2%，换句话说当内存使用达到98%时才GC 就有点晚了，应该是多一些预留10%内存空间，这预留下来的空间我们称为S区（有两个s区s1和s0），S区是用来存储新生代GC后存活下来的对象，而我们知道新生代GC算法使用的是复制回收算法。</p>\n<p>所以我们实际GC发生是在，新生代内存使用达到90%时开始进行，复制存活的对象到S1区，要知道GC结束后在S1区活下来的对象，在下一次GC的范围是，eden区和S1，把这两部分存活的对象放入S0区，如此反复，下一次GC范围是eden区和S0区，一句话每次GC范围是eden区+一个S区。（比例是，eden：s1:s0=80%:10%:10%=8:1:1）这里的eden区（80%） 和其中的一个  S区（10%） 合起来共占据90%，GC就是清理的他们，始终保持着其中一个S区是空留的，保证GC的时候复制存活的对象有个存储的地方。</p>\n<p><strong>这样的好处是什么？</strong></p>\n<p>高效！！！GC 算法总体就是三种：1 复制 2 标记 3标记整理，垃圾回收算法将这几种选择起来相互组合。毫无疑问，只存在少量存活的对象，只需复制少量存活的对象，远远比标记和标记整理高效多。</p>\n<p><strong>如何判断对象存活可用？</strong></p>\n<p>可达性分析法来判断:通过一系列称为<code>GCRoot</code>对象做起点，从这些节点向下搜索，搜索所走过的路径称为引用链，如果一个对象在引用链上，就说是可达的，这种对象就是需要存活下来的。</p>\n<p><strong>作为GC Roots的对象包括下面几种：</strong></p>\n<ol>\n<li><p>当前虚拟机栈中局部变量表中的引用的对象</p>\n</li>\n<li><p>当前本地方法栈中局部变量表中的引用的对象</p>\n</li>\n<li><p>方法区中类静态属性引用的对象</p>\n</li>\n<li><p>方法区中的常量引用的对象</p>\n</li>\n</ol>\n<p><strong>设置Survivor区是为了减少送到老年代的对象</strong></p>\n","site":{"data":{}},"more":"<h2 id=\"为什么\"><a href=\"#为什么\" class=\"headerlink\" title=\"为什么\"></a>为什么</h2><ol>\n<li>为什么要jvm调优？ 因为要尽量减少GC的次数</li>\n<li>为什么要减少GC？ 因为GC时会发成STW，造成所有的java代码停止运行，native代码可以运行，但是不能与JVM进行交互。</li>\n<li>为什么GC要STW，不能一起运行吗？因为程序运行会导致内存中数据的状态变化，比如根据可达性算法通过GC Root查找没有被引用的对象，开始gc的时候一个对象还不是垃圾，但是如果我们的程序依然在运行，线程结束后，栈被清空，一些堆内的对象失去了引用，就变成垃圾了，这时候如果gc线程再回去找垃圾，算法会很低效，因为数据的状态一直会变，不如直接stw，一把将所有的垃圾回收完，再恢复运行。</li>\n</ol>\n<h2 id=\"知识点\"><a href=\"#知识点\" class=\"headerlink\" title=\"知识点\"></a>知识点</h2><h3 id=\"1-JVM\"><a href=\"#1-JVM\" class=\"headerlink\" title=\"1. JVM\"></a>1. JVM</h3><p>JVM被分为三个主要的子系统：类加载器子系统、运行时数据区和执行引擎 。主要研究的是运行时数据区，也就是JVM内存结构，特别注意其中Java 堆和方法区是<strong>线程共享</strong>的。其他都是<strong>线程私有</strong>的，而jvm调优主要就是调整这里面的堆</p>\n<img src=\"/2021/07/04/kongzheng1993-JVM调优/JVM.png\">\n\n<img src=\"/2021/07/04/kongzheng1993-JVM调优/stack.png\">\n\n<p>Java 堆并不是单纯的一整块区域，<strong>实际上java堆是根据对象存活时间的不同</strong>，Java 堆还被分为年轻代、老年代两个区域，年轻代还被进一步划分为 Eden 区、From Survivor 0、To Survivor 1 区。并且默认的虚拟机配置比例是Eden：from ：to = 8:1:1 。简单来说就是：</p>\n<p><strong>Java堆 = 老年代 + 新生代</strong></p>\n<p>新生代 = Eden + S0 + S1</p>\n<p>默认Eden:from:to = 8:1:1</p>\n<p><code>-Xms</code> 堆容量初始大小（堆包括新生代和老年代）。 例如：-Xms 20M<br><code>-Xmx</code> 堆总共（最大）大小。 例如：-Xmx 30M<br><strong>注意：建议将 -Xms 和 -Xmx 设为相同值，避免每次垃圾回收完成后JVM重新分配内存！</strong><br><code>-Xmn</code> 新生代容量大小。例如：-Xmn 10M<br><code>-XX</code> SurvivorRatio` 设置参数Eden、form和to的比例 【比例参数Eden、form和to默认是8:1:1】例如：-XX： SurvivorRatio=8 代表比例8:1:1</p>\n<p>虽然没有直接设置老年代的参数，但是可以设置堆空间大小和新生代空间大小两个参数来间接控制：<br><strong>老年代空间大小 = 堆空间大小 - 年轻代大空间大小</strong></p>\n<p>当我们的 Java 堆内有足够的空间去完成实例分配时，并且堆也无法扩展，将会抛出我们常见的<strong>OutOfMemoryError</strong> 异常，也就是我们常说的<strong>OOM</strong> 异常</p>\n<h3 id=\"2-JVM新生代8-1-1的原因\"><a href=\"#2-JVM新生代8-1-1的原因\" class=\"headerlink\" title=\"2. JVM新生代8:1:1的原因\"></a>2. JVM新生代8:1:1的原因</h3><p>统计学测算出当内存使用超过98%以上时，内存就应该被minor gc时回收一次。但是实际应用中，我们不能较真的只给 他们留下2%，换句话说当内存使用达到98%时才GC 就有点晚了，应该是多一些预留10%内存空间，这预留下来的空间我们称为S区（有两个s区s1和s0），S区是用来存储新生代GC后存活下来的对象，而我们知道新生代GC算法使用的是复制回收算法。</p>\n<p>所以我们实际GC发生是在，新生代内存使用达到90%时开始进行，复制存活的对象到S1区，要知道GC结束后在S1区活下来的对象，在下一次GC的范围是，eden区和S1，把这两部分存活的对象放入S0区，如此反复，下一次GC范围是eden区和S0区，一句话每次GC范围是eden区+一个S区。（比例是，eden：s1:s0=80%:10%:10%=8:1:1）这里的eden区（80%） 和其中的一个  S区（10%） 合起来共占据90%，GC就是清理的他们，始终保持着其中一个S区是空留的，保证GC的时候复制存活的对象有个存储的地方。</p>\n<p><strong>这样的好处是什么？</strong></p>\n<p>高效！！！GC 算法总体就是三种：1 复制 2 标记 3标记整理，垃圾回收算法将这几种选择起来相互组合。毫无疑问，只存在少量存活的对象，只需复制少量存活的对象，远远比标记和标记整理高效多。</p>\n<p><strong>如何判断对象存活可用？</strong></p>\n<p>可达性分析法来判断:通过一系列称为<code>GCRoot</code>对象做起点，从这些节点向下搜索，搜索所走过的路径称为引用链，如果一个对象在引用链上，就说是可达的，这种对象就是需要存活下来的。</p>\n<p><strong>作为GC Roots的对象包括下面几种：</strong></p>\n<ol>\n<li><p>当前虚拟机栈中局部变量表中的引用的对象</p>\n</li>\n<li><p>当前本地方法栈中局部变量表中的引用的对象</p>\n</li>\n<li><p>方法区中类静态属性引用的对象</p>\n</li>\n<li><p>方法区中的常量引用的对象</p>\n</li>\n</ol>\n<p><strong>设置Survivor区是为了减少送到老年代的对象</strong></p>\n"},{"title":"MySQL联表查询表字符集不一致索引失效问题","excerpt":"","comments":1,"date":"2021-07-27T08:30:10.000Z","_content":"\n### 背景\n\n新建的表字符集用的是utf8mb4，而之前的两张主表的字符集设置的是utf8，查询进行表关联，导致索引失效。\n\n### 表结构\n\n```mysql\n-- 表1utf8字符集，并建立code和name列索引\nCREATE TABLE `t1` (\n`id` int(11) NOT NULL AUTO_INCREMENT,\n`name` varchar(20) DEFAULT NULL,\n`code` varchar(50) DEFAULT NULL,\nPRIMARY KEY (`id`),\nKEY `idx_code` (`code`),\nKEY `idx_name` (`name`)\n) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8;\n\n-- 表2 utf8mb4字符集，并建立code和name列索引\nCREATE TABLE `t2` (\n`id` int(11) NOT NULL AUTO_INCREMENT,\n`name` varchar(20) DEFAULT NULL,\n`code` varchar(50) DEFAULT NULL,\nPRIMARY KEY (`id`),\nKEY `idx_code` (`code`),\nKEY `idx_name` (`name`)\n) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8mb4;\n\nINSERT INTO `t1` (`name`,`code`) VALUES ('zzz','00006'),('xxx','00002'),('aaa','000003'),('sss','000004'),('ddd','000005');\n\nINSERT INTO `t2` (`name`,`code`) VALUES ('zzz','00001'),('xxx','00002'),('aaa','000003'),('sss','000004'),('ddd','000005');\n```\n\n### 慢SQL\n\n```mysql\ndesc select * from t1 left join t2 on t1.code = t2.code where t2.name = 'ddd';\n```\n\n### 查看执行计划\n\n```mysql\nEXPLAIN EXTENDED select * from t2 left join t1 on t1.code = t2.code where t2.name = 'ddd';\nSHOW WARNINGS;\n-- 结果\n/* select#1 */ select `demo`.`t2`.`id` AS `id`,`demo`.`t2`.`name` AS `name`,`demo`.`t2`.`code` AS `code`,`demo`.`t1`.`id` AS `id`,`demo`.`t1`.`name` AS `name`,`demo`.`t1`.`code` AS `code` from `demo`.`t2` left join `demo`.`t1` on((convert(`demo`.`t1`.`code` using utf8mb4) = `demo`.`t2`.`code`)) where (`demo`.`t2`.`name` = 'ddd')\n```\n\n存在一个convert的过程\n\n### 查看告警信息\n\n```mysql\nshow warnings;\n```\n\n`show warnings;`可以显示上一条sql的告警信息。\n\n**字符集转换遵循由小到大的原则，因为utf8mb4是utf8的超集，所以这里把utf8转换成utf8mb4。而实际上t1表中的索引是utf8格式的，所以会导致t1表全表扫描。**\n\n","source":"_posts/2021-07-25-kongzheng1993-mysql联表查询字符集不一致不走索引.md","raw":"---\ntitle: MySQL联表查询表字符集不一致索引失效问题\nexcerpt: 'MySQL'\ntags: [MySQL]\ncategories: [MySQL]\ncomments: true\ndate: 2021-07-27 16:30:10\n---\n\n### 背景\n\n新建的表字符集用的是utf8mb4，而之前的两张主表的字符集设置的是utf8，查询进行表关联，导致索引失效。\n\n### 表结构\n\n```mysql\n-- 表1utf8字符集，并建立code和name列索引\nCREATE TABLE `t1` (\n`id` int(11) NOT NULL AUTO_INCREMENT,\n`name` varchar(20) DEFAULT NULL,\n`code` varchar(50) DEFAULT NULL,\nPRIMARY KEY (`id`),\nKEY `idx_code` (`code`),\nKEY `idx_name` (`name`)\n) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8;\n\n-- 表2 utf8mb4字符集，并建立code和name列索引\nCREATE TABLE `t2` (\n`id` int(11) NOT NULL AUTO_INCREMENT,\n`name` varchar(20) DEFAULT NULL,\n`code` varchar(50) DEFAULT NULL,\nPRIMARY KEY (`id`),\nKEY `idx_code` (`code`),\nKEY `idx_name` (`name`)\n) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8mb4;\n\nINSERT INTO `t1` (`name`,`code`) VALUES ('zzz','00006'),('xxx','00002'),('aaa','000003'),('sss','000004'),('ddd','000005');\n\nINSERT INTO `t2` (`name`,`code`) VALUES ('zzz','00001'),('xxx','00002'),('aaa','000003'),('sss','000004'),('ddd','000005');\n```\n\n### 慢SQL\n\n```mysql\ndesc select * from t1 left join t2 on t1.code = t2.code where t2.name = 'ddd';\n```\n\n### 查看执行计划\n\n```mysql\nEXPLAIN EXTENDED select * from t2 left join t1 on t1.code = t2.code where t2.name = 'ddd';\nSHOW WARNINGS;\n-- 结果\n/* select#1 */ select `demo`.`t2`.`id` AS `id`,`demo`.`t2`.`name` AS `name`,`demo`.`t2`.`code` AS `code`,`demo`.`t1`.`id` AS `id`,`demo`.`t1`.`name` AS `name`,`demo`.`t1`.`code` AS `code` from `demo`.`t2` left join `demo`.`t1` on((convert(`demo`.`t1`.`code` using utf8mb4) = `demo`.`t2`.`code`)) where (`demo`.`t2`.`name` = 'ddd')\n```\n\n存在一个convert的过程\n\n### 查看告警信息\n\n```mysql\nshow warnings;\n```\n\n`show warnings;`可以显示上一条sql的告警信息。\n\n**字符集转换遵循由小到大的原则，因为utf8mb4是utf8的超集，所以这里把utf8转换成utf8mb4。而实际上t1表中的索引是utf8格式的，所以会导致t1表全表扫描。**\n\n","slug":"kongzheng1993-mysql联表查询字符集不一致不走索引","published":1,"updated":"2023-03-08T07:05:58.815Z","layout":"post","photos":[],"link":"","_id":"clg0k2alz0070t26foj5n91h9","content":"<h3 id=\"背景\"><a href=\"#背景\" class=\"headerlink\" title=\"背景\"></a>背景</h3><p>新建的表字符集用的是utf8mb4，而之前的两张主表的字符集设置的是utf8，查询进行表关联，导致索引失效。</p>\n<h3 id=\"表结构\"><a href=\"#表结构\" class=\"headerlink\" title=\"表结构\"></a>表结构</h3><pre><code class=\"mysql\">-- 表1utf8字符集，并建立code和name列索引\nCREATE TABLE `t1` (\n`id` int(11) NOT NULL AUTO_INCREMENT,\n`name` varchar(20) DEFAULT NULL,\n`code` varchar(50) DEFAULT NULL,\nPRIMARY KEY (`id`),\nKEY `idx_code` (`code`),\nKEY `idx_name` (`name`)\n) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8;\n\n-- 表2 utf8mb4字符集，并建立code和name列索引\nCREATE TABLE `t2` (\n`id` int(11) NOT NULL AUTO_INCREMENT,\n`name` varchar(20) DEFAULT NULL,\n`code` varchar(50) DEFAULT NULL,\nPRIMARY KEY (`id`),\nKEY `idx_code` (`code`),\nKEY `idx_name` (`name`)\n) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8mb4;\n\nINSERT INTO `t1` (`name`,`code`) VALUES (&#39;zzz&#39;,&#39;00006&#39;),(&#39;xxx&#39;,&#39;00002&#39;),(&#39;aaa&#39;,&#39;000003&#39;),(&#39;sss&#39;,&#39;000004&#39;),(&#39;ddd&#39;,&#39;000005&#39;);\n\nINSERT INTO `t2` (`name`,`code`) VALUES (&#39;zzz&#39;,&#39;00001&#39;),(&#39;xxx&#39;,&#39;00002&#39;),(&#39;aaa&#39;,&#39;000003&#39;),(&#39;sss&#39;,&#39;000004&#39;),(&#39;ddd&#39;,&#39;000005&#39;);</code></pre>\n<h3 id=\"慢SQL\"><a href=\"#慢SQL\" class=\"headerlink\" title=\"慢SQL\"></a>慢SQL</h3><pre><code class=\"mysql\">desc select * from t1 left join t2 on t1.code = t2.code where t2.name = &#39;ddd&#39;;</code></pre>\n<h3 id=\"查看执行计划\"><a href=\"#查看执行计划\" class=\"headerlink\" title=\"查看执行计划\"></a>查看执行计划</h3><pre><code class=\"mysql\">EXPLAIN EXTENDED select * from t2 left join t1 on t1.code = t2.code where t2.name = &#39;ddd&#39;;\nSHOW WARNINGS;\n-- 结果\n/* select#1 */ select `demo`.`t2`.`id` AS `id`,`demo`.`t2`.`name` AS `name`,`demo`.`t2`.`code` AS `code`,`demo`.`t1`.`id` AS `id`,`demo`.`t1`.`name` AS `name`,`demo`.`t1`.`code` AS `code` from `demo`.`t2` left join `demo`.`t1` on((convert(`demo`.`t1`.`code` using utf8mb4) = `demo`.`t2`.`code`)) where (`demo`.`t2`.`name` = &#39;ddd&#39;)</code></pre>\n<p>存在一个convert的过程</p>\n<h3 id=\"查看告警信息\"><a href=\"#查看告警信息\" class=\"headerlink\" title=\"查看告警信息\"></a>查看告警信息</h3><pre><code class=\"mysql\">show warnings;</code></pre>\n<p><code>show warnings;</code>可以显示上一条sql的告警信息。</p>\n<p><strong>字符集转换遵循由小到大的原则，因为utf8mb4是utf8的超集，所以这里把utf8转换成utf8mb4。而实际上t1表中的索引是utf8格式的，所以会导致t1表全表扫描。</strong></p>\n","site":{"data":{}},"more":"<h3 id=\"背景\"><a href=\"#背景\" class=\"headerlink\" title=\"背景\"></a>背景</h3><p>新建的表字符集用的是utf8mb4，而之前的两张主表的字符集设置的是utf8，查询进行表关联，导致索引失效。</p>\n<h3 id=\"表结构\"><a href=\"#表结构\" class=\"headerlink\" title=\"表结构\"></a>表结构</h3><pre><code class=\"mysql\">-- 表1utf8字符集，并建立code和name列索引\nCREATE TABLE `t1` (\n`id` int(11) NOT NULL AUTO_INCREMENT,\n`name` varchar(20) DEFAULT NULL,\n`code` varchar(50) DEFAULT NULL,\nPRIMARY KEY (`id`),\nKEY `idx_code` (`code`),\nKEY `idx_name` (`name`)\n) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8;\n\n-- 表2 utf8mb4字符集，并建立code和name列索引\nCREATE TABLE `t2` (\n`id` int(11) NOT NULL AUTO_INCREMENT,\n`name` varchar(20) DEFAULT NULL,\n`code` varchar(50) DEFAULT NULL,\nPRIMARY KEY (`id`),\nKEY `idx_code` (`code`),\nKEY `idx_name` (`name`)\n) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8mb4;\n\nINSERT INTO `t1` (`name`,`code`) VALUES (&#39;zzz&#39;,&#39;00006&#39;),(&#39;xxx&#39;,&#39;00002&#39;),(&#39;aaa&#39;,&#39;000003&#39;),(&#39;sss&#39;,&#39;000004&#39;),(&#39;ddd&#39;,&#39;000005&#39;);\n\nINSERT INTO `t2` (`name`,`code`) VALUES (&#39;zzz&#39;,&#39;00001&#39;),(&#39;xxx&#39;,&#39;00002&#39;),(&#39;aaa&#39;,&#39;000003&#39;),(&#39;sss&#39;,&#39;000004&#39;),(&#39;ddd&#39;,&#39;000005&#39;);</code></pre>\n<h3 id=\"慢SQL\"><a href=\"#慢SQL\" class=\"headerlink\" title=\"慢SQL\"></a>慢SQL</h3><pre><code class=\"mysql\">desc select * from t1 left join t2 on t1.code = t2.code where t2.name = &#39;ddd&#39;;</code></pre>\n<h3 id=\"查看执行计划\"><a href=\"#查看执行计划\" class=\"headerlink\" title=\"查看执行计划\"></a>查看执行计划</h3><pre><code class=\"mysql\">EXPLAIN EXTENDED select * from t2 left join t1 on t1.code = t2.code where t2.name = &#39;ddd&#39;;\nSHOW WARNINGS;\n-- 结果\n/* select#1 */ select `demo`.`t2`.`id` AS `id`,`demo`.`t2`.`name` AS `name`,`demo`.`t2`.`code` AS `code`,`demo`.`t1`.`id` AS `id`,`demo`.`t1`.`name` AS `name`,`demo`.`t1`.`code` AS `code` from `demo`.`t2` left join `demo`.`t1` on((convert(`demo`.`t1`.`code` using utf8mb4) = `demo`.`t2`.`code`)) where (`demo`.`t2`.`name` = &#39;ddd&#39;)</code></pre>\n<p>存在一个convert的过程</p>\n<h3 id=\"查看告警信息\"><a href=\"#查看告警信息\" class=\"headerlink\" title=\"查看告警信息\"></a>查看告警信息</h3><pre><code class=\"mysql\">show warnings;</code></pre>\n<p><code>show warnings;</code>可以显示上一条sql的告警信息。</p>\n<p><strong>字符集转换遵循由小到大的原则，因为utf8mb4是utf8的超集，所以这里把utf8转换成utf8mb4。而实际上t1表中的索引是utf8格式的，所以会导致t1表全表扫描。</strong></p>\n"},{"title":"关于编译","excerpt":"","comments":1,"date":"2021-07-25T08:30:10.000Z","_content":"\n## 关于编译\n\n在Java技术下谈论“编译期”而没有上下文语境的话，是一个非常含糊的表述，因为它可能是指一个前端编译器把*.java文件转变成.class文件的过程；也可能是指Java虚拟机的即时编译器（常称JIT编译器，Just In Time Compiler）运行期把字节码转变成本地机器吗的过程；还可能是指使用静态的提前编译器（常称AOT编译器，Ahead Of Time Compiler）直接把程序编译成与目标机器指令集相关的二进制代码的过程。\n\n常见的上面三类编译器：\n\n- 前端编译器：JDK的javac、Eclipse JDT中的增量式编译器（ECJ）\n- 即时编译器：HotSpot虚拟机的C1、C2编译器，Graal编译器\n- 提前编译器：JDK的Jaotc、GUN Compiler for the Java（GCJ）、Excelsior JET\n\n","source":"_posts/2021-07-25-kongzheng1993-关于编译.md","raw":"---\ntitle: 关于编译\nexcerpt: 'Java'\ntags: [Java]\ncategories: [Java]\ncomments: true\ndate: 2021-07-25 16:30:10\n---\n\n## 关于编译\n\n在Java技术下谈论“编译期”而没有上下文语境的话，是一个非常含糊的表述，因为它可能是指一个前端编译器把*.java文件转变成.class文件的过程；也可能是指Java虚拟机的即时编译器（常称JIT编译器，Just In Time Compiler）运行期把字节码转变成本地机器吗的过程；还可能是指使用静态的提前编译器（常称AOT编译器，Ahead Of Time Compiler）直接把程序编译成与目标机器指令集相关的二进制代码的过程。\n\n常见的上面三类编译器：\n\n- 前端编译器：JDK的javac、Eclipse JDT中的增量式编译器（ECJ）\n- 即时编译器：HotSpot虚拟机的C1、C2编译器，Graal编译器\n- 提前编译器：JDK的Jaotc、GUN Compiler for the Java（GCJ）、Excelsior JET\n\n","slug":"kongzheng1993-关于编译","published":1,"updated":"2023-03-08T07:05:58.815Z","layout":"post","photos":[],"link":"","_id":"clg0k2am00074t26fz68b8ogr","content":"<h2 id=\"关于编译\"><a href=\"#关于编译\" class=\"headerlink\" title=\"关于编译\"></a>关于编译</h2><p>在Java技术下谈论“编译期”而没有上下文语境的话，是一个非常含糊的表述，因为它可能是指一个前端编译器把*.java文件转变成.class文件的过程；也可能是指Java虚拟机的即时编译器（常称JIT编译器，Just In Time Compiler）运行期把字节码转变成本地机器吗的过程；还可能是指使用静态的提前编译器（常称AOT编译器，Ahead Of Time Compiler）直接把程序编译成与目标机器指令集相关的二进制代码的过程。</p>\n<p>常见的上面三类编译器：</p>\n<ul>\n<li>前端编译器：JDK的javac、Eclipse JDT中的增量式编译器（ECJ）</li>\n<li>即时编译器：HotSpot虚拟机的C1、C2编译器，Graal编译器</li>\n<li>提前编译器：JDK的Jaotc、GUN Compiler for the Java（GCJ）、Excelsior JET</li>\n</ul>\n","site":{"data":{}},"more":"<h2 id=\"关于编译\"><a href=\"#关于编译\" class=\"headerlink\" title=\"关于编译\"></a>关于编译</h2><p>在Java技术下谈论“编译期”而没有上下文语境的话，是一个非常含糊的表述，因为它可能是指一个前端编译器把*.java文件转变成.class文件的过程；也可能是指Java虚拟机的即时编译器（常称JIT编译器，Just In Time Compiler）运行期把字节码转变成本地机器吗的过程；还可能是指使用静态的提前编译器（常称AOT编译器，Ahead Of Time Compiler）直接把程序编译成与目标机器指令集相关的二进制代码的过程。</p>\n<p>常见的上面三类编译器：</p>\n<ul>\n<li>前端编译器：JDK的javac、Eclipse JDT中的增量式编译器（ECJ）</li>\n<li>即时编译器：HotSpot虚拟机的C1、C2编译器，Graal编译器</li>\n<li>提前编译器：JDK的Jaotc、GUN Compiler for the Java（GCJ）、Excelsior JET</li>\n</ul>\n"},{"title":"feign上传文件","excerpt":"","comments":1,"date":"2021-07-15T05:30:10.000Z","_content":"\n今天要给app提供一个上传文件的接口，这块我们再pc端的服务上已经有了这样一个接口，所以提供给app的接口，要在给app提供能力的服务上通过feign调用pc端服务的上传接口来实现，这样可以保证pc端和移动端一致，后期也好维护。\n\n说着就在app服务增加了一个feignClient\n```java\n    /**\n     * 图片上传 feignClient\n     *\n     * @param\n     * @return\n     */\n    @ApiOperation(\"文件流方式上传\")\n    @PostMapping(value = \"/file-upload\")\n    @ApiImplicitParams({\n            @ApiImplicitParam(name = \"prefix\",value = \"文件前缀（例如：工单号）\",required = true),\n            @ApiImplicitParam(name = \"filename\",value = \"文件名称（上传文件名称,包含后缀名，如123456.jpg）\",required = true)\n    })\n    @ResponseBody\n    Response<UploadResult> uploadFile(\n            @RequestParam(\"file\") MultipartFile upfile,\n            @RequestParam(value = \"prefix\") String prefix,\n            @RequestParam(value = \"filename\") String filename\n    ) ;\n```\n\n然后一个api接口：\n\n```java\n    /**\n     * 图片上传 api\n     *\n     * @param\n     * @return\n     */\n    @ApiOperation(\"文件流方式上传\")\n    @PostMapping(value = \"/file-upload\")\n    @ApiImplicitParams({\n            @ApiImplicitParam(name = \"prefix\",value = \"文件前缀（例如：工单号）\",required = true),\n            @ApiImplicitParam(name = \"filename\",value = \"文件名称（上传文件名称,包含后缀名，如123456.jpg）\",required = true)\n    })\n    @ResponseBody\n    Response<UploadResult> uploadFile(\n            @RequestParam(\"file\") MultipartFile upfile,\n            @RequestParam(value = \"prefix\") String prefix,\n            @RequestParam(value = \"filename\") String filename\n    ) {\n        return datumFeign.uploadFile(upfile, prefix, filename);\n    }\n```\n\n然后就开心的自测，感觉应该没啥问题。\n\n没想到收到PC端服务返回的`org.springframework.web.multipart.MultipartException: Current request is not a multipart request`，很奇怪，我的feignClient传了MultipartFile了，而且打断点看了的。\n\n后来查了一些资料，发现FeignClient是不支持MultipartFile的，需要使用openfeign的feign-form来实现。\n\n增加依赖：\n\n```xml\n<dependency>\n    <groupId>io.github.openfeign.form</groupId>\n    <artifactId>feign-form</artifactId>\n    <version>3.0.1</version>\n</dependency>\n<dependency>\n    <groupId>io.github.openfeign.form</groupId>\n    <artifactId>feign-form-spring</artifactId>\n    <version>3.0.1</version>\n</dependency>\n```\n\nfeignClient的PostMapping注解增加属性：`consumes = MediaType.MULTIPART_FORM_DATA_VALUE`\n\n```java\n/**\n     * 图片上传\n     *\n     * @param\n     * @return\n     */\n    @ApiOperation(\"文件流方式上传\")\n    @PostMapping(value = \"/file-upload\", consumes = MediaType.MULTIPART_FORM_DATA_VALUE)\n    @ApiImplicitParams({\n            @ApiImplicitParam(name = \"prefix\",value = \"文件前缀（例如：工单号）\",required = true),\n            @ApiImplicitParam(name = \"filename\",value = \"文件名称（上传文件名称,包含后缀名，如123456.jpg）\",required = true)\n    })\n    @ResponseBody\n    Response<UploadResult> uploadFile(\n            @RequestParam(\"file\") MultipartFile upfile,\n            @RequestParam(value = \"prefix\") String prefix,\n            @RequestParam(value = \"filename\") String filename\n    ) ;\n```\n\n这时候在测试一下接口，返回`org.springframework.web.multipart.support.MissingServletRequestPartException: Required request part 'file' is not present`\n\n也就是说，第一次都不是个multipart request，现在是少是个multipart request了，只是没有file这个request part。\n\n翻看了《Spring实战》的“处理multipart形式的数据”章节，`multipart/form-data`不是普通的表单，而是每个输入域都是一个part，接收这写part需要使用`@RequestPart`注解。\n\n于是将feignClient中的`@RequestParam`修改为`@RequestPart`\n\n```java\n/**\n     * 图片上传 api\n     *\n     * @param\n     * @return\n     */\n    @ApiOperation(\"文件流方式上传\")\n    @PostMapping(value = \"/file-upload\", consumes = MediaType.MULTIPART_FORM_DATA_VALUE)\n    @ApiImplicitParams({\n            @ApiImplicitParam(name = \"prefix\",value = \"文件前缀（例如：工单号）\",required = true),\n            @ApiImplicitParam(name = \"filename\",value = \"文件名称（上传文件名称,包含后缀名，如123456.jpg）\",required = true)\n    })\n    @ResponseBody\n    Response<UploadResult> uploadFile(\n            @RequestPart(\"file\") MultipartFile upfile,\n            @RequestParam(value = \"prefix\") String prefix,\n            @RequestParam(value = \"filename\") String filename\n    ) ;\n```\n\n至此，上传文件成功！\n\n\n2022年5月注：\n最近给下游服务提供了一个上传文件的接口，除了上传文件还需要带一些参数，本来随手就写出了一个@RequestPart的参数、一个@RequestBody的对象参数，存在问题。因为MultipartFile本来就是一个form表单的一部分，占用的是http的body，而@RequestBody则是要用一个json来占用http的body，二者是有冲突的，body只能是二者之一。既然文件必须在body，那么其他参数就只能在Url中携带了，所以这里要用@RequestParam，在url中传参数","source":"_posts/2021-07-15-kongzheng1993-feign上传文件.md","raw":"---\ntitle: feign上传文件\nexcerpt: 'feign'\ntags: [SpringCloud]\ncategories: [SpringCloud]\ncomments: true\ndate: 2021-07-15 13:30:10\n---\n\n今天要给app提供一个上传文件的接口，这块我们再pc端的服务上已经有了这样一个接口，所以提供给app的接口，要在给app提供能力的服务上通过feign调用pc端服务的上传接口来实现，这样可以保证pc端和移动端一致，后期也好维护。\n\n说着就在app服务增加了一个feignClient\n```java\n    /**\n     * 图片上传 feignClient\n     *\n     * @param\n     * @return\n     */\n    @ApiOperation(\"文件流方式上传\")\n    @PostMapping(value = \"/file-upload\")\n    @ApiImplicitParams({\n            @ApiImplicitParam(name = \"prefix\",value = \"文件前缀（例如：工单号）\",required = true),\n            @ApiImplicitParam(name = \"filename\",value = \"文件名称（上传文件名称,包含后缀名，如123456.jpg）\",required = true)\n    })\n    @ResponseBody\n    Response<UploadResult> uploadFile(\n            @RequestParam(\"file\") MultipartFile upfile,\n            @RequestParam(value = \"prefix\") String prefix,\n            @RequestParam(value = \"filename\") String filename\n    ) ;\n```\n\n然后一个api接口：\n\n```java\n    /**\n     * 图片上传 api\n     *\n     * @param\n     * @return\n     */\n    @ApiOperation(\"文件流方式上传\")\n    @PostMapping(value = \"/file-upload\")\n    @ApiImplicitParams({\n            @ApiImplicitParam(name = \"prefix\",value = \"文件前缀（例如：工单号）\",required = true),\n            @ApiImplicitParam(name = \"filename\",value = \"文件名称（上传文件名称,包含后缀名，如123456.jpg）\",required = true)\n    })\n    @ResponseBody\n    Response<UploadResult> uploadFile(\n            @RequestParam(\"file\") MultipartFile upfile,\n            @RequestParam(value = \"prefix\") String prefix,\n            @RequestParam(value = \"filename\") String filename\n    ) {\n        return datumFeign.uploadFile(upfile, prefix, filename);\n    }\n```\n\n然后就开心的自测，感觉应该没啥问题。\n\n没想到收到PC端服务返回的`org.springframework.web.multipart.MultipartException: Current request is not a multipart request`，很奇怪，我的feignClient传了MultipartFile了，而且打断点看了的。\n\n后来查了一些资料，发现FeignClient是不支持MultipartFile的，需要使用openfeign的feign-form来实现。\n\n增加依赖：\n\n```xml\n<dependency>\n    <groupId>io.github.openfeign.form</groupId>\n    <artifactId>feign-form</artifactId>\n    <version>3.0.1</version>\n</dependency>\n<dependency>\n    <groupId>io.github.openfeign.form</groupId>\n    <artifactId>feign-form-spring</artifactId>\n    <version>3.0.1</version>\n</dependency>\n```\n\nfeignClient的PostMapping注解增加属性：`consumes = MediaType.MULTIPART_FORM_DATA_VALUE`\n\n```java\n/**\n     * 图片上传\n     *\n     * @param\n     * @return\n     */\n    @ApiOperation(\"文件流方式上传\")\n    @PostMapping(value = \"/file-upload\", consumes = MediaType.MULTIPART_FORM_DATA_VALUE)\n    @ApiImplicitParams({\n            @ApiImplicitParam(name = \"prefix\",value = \"文件前缀（例如：工单号）\",required = true),\n            @ApiImplicitParam(name = \"filename\",value = \"文件名称（上传文件名称,包含后缀名，如123456.jpg）\",required = true)\n    })\n    @ResponseBody\n    Response<UploadResult> uploadFile(\n            @RequestParam(\"file\") MultipartFile upfile,\n            @RequestParam(value = \"prefix\") String prefix,\n            @RequestParam(value = \"filename\") String filename\n    ) ;\n```\n\n这时候在测试一下接口，返回`org.springframework.web.multipart.support.MissingServletRequestPartException: Required request part 'file' is not present`\n\n也就是说，第一次都不是个multipart request，现在是少是个multipart request了，只是没有file这个request part。\n\n翻看了《Spring实战》的“处理multipart形式的数据”章节，`multipart/form-data`不是普通的表单，而是每个输入域都是一个part，接收这写part需要使用`@RequestPart`注解。\n\n于是将feignClient中的`@RequestParam`修改为`@RequestPart`\n\n```java\n/**\n     * 图片上传 api\n     *\n     * @param\n     * @return\n     */\n    @ApiOperation(\"文件流方式上传\")\n    @PostMapping(value = \"/file-upload\", consumes = MediaType.MULTIPART_FORM_DATA_VALUE)\n    @ApiImplicitParams({\n            @ApiImplicitParam(name = \"prefix\",value = \"文件前缀（例如：工单号）\",required = true),\n            @ApiImplicitParam(name = \"filename\",value = \"文件名称（上传文件名称,包含后缀名，如123456.jpg）\",required = true)\n    })\n    @ResponseBody\n    Response<UploadResult> uploadFile(\n            @RequestPart(\"file\") MultipartFile upfile,\n            @RequestParam(value = \"prefix\") String prefix,\n            @RequestParam(value = \"filename\") String filename\n    ) ;\n```\n\n至此，上传文件成功！\n\n\n2022年5月注：\n最近给下游服务提供了一个上传文件的接口，除了上传文件还需要带一些参数，本来随手就写出了一个@RequestPart的参数、一个@RequestBody的对象参数，存在问题。因为MultipartFile本来就是一个form表单的一部分，占用的是http的body，而@RequestBody则是要用一个json来占用http的body，二者是有冲突的，body只能是二者之一。既然文件必须在body，那么其他参数就只能在Url中携带了，所以这里要用@RequestParam，在url中传参数","slug":"kongzheng1993-feign上传文件","published":1,"updated":"2023-03-08T07:05:58.814Z","layout":"post","photos":[],"link":"","_id":"clg0k2am00078t26fplvndi5t","content":"<p>今天要给app提供一个上传文件的接口，这块我们再pc端的服务上已经有了这样一个接口，所以提供给app的接口，要在给app提供能力的服务上通过feign调用pc端服务的上传接口来实现，这样可以保证pc端和移动端一致，后期也好维护。</p>\n<p>说着就在app服务增加了一个feignClient</p>\n<pre><code class=\"java\">    /**\n     * 图片上传 feignClient\n     *\n     * @param\n     * @return\n     */\n    @ApiOperation(&quot;文件流方式上传&quot;)\n    @PostMapping(value = &quot;/file-upload&quot;)\n    @ApiImplicitParams({\n            @ApiImplicitParam(name = &quot;prefix&quot;,value = &quot;文件前缀（例如：工单号）&quot;,required = true),\n            @ApiImplicitParam(name = &quot;filename&quot;,value = &quot;文件名称（上传文件名称,包含后缀名，如123456.jpg）&quot;,required = true)\n    })\n    @ResponseBody\n    Response&lt;UploadResult&gt; uploadFile(\n            @RequestParam(&quot;file&quot;) MultipartFile upfile,\n            @RequestParam(value = &quot;prefix&quot;) String prefix,\n            @RequestParam(value = &quot;filename&quot;) String filename\n    ) ;</code></pre>\n<p>然后一个api接口：</p>\n<pre><code class=\"java\">    /**\n     * 图片上传 api\n     *\n     * @param\n     * @return\n     */\n    @ApiOperation(&quot;文件流方式上传&quot;)\n    @PostMapping(value = &quot;/file-upload&quot;)\n    @ApiImplicitParams({\n            @ApiImplicitParam(name = &quot;prefix&quot;,value = &quot;文件前缀（例如：工单号）&quot;,required = true),\n            @ApiImplicitParam(name = &quot;filename&quot;,value = &quot;文件名称（上传文件名称,包含后缀名，如123456.jpg）&quot;,required = true)\n    })\n    @ResponseBody\n    Response&lt;UploadResult&gt; uploadFile(\n            @RequestParam(&quot;file&quot;) MultipartFile upfile,\n            @RequestParam(value = &quot;prefix&quot;) String prefix,\n            @RequestParam(value = &quot;filename&quot;) String filename\n    ) {\n        return datumFeign.uploadFile(upfile, prefix, filename);\n    }</code></pre>\n<p>然后就开心的自测，感觉应该没啥问题。</p>\n<p>没想到收到PC端服务返回的<code>org.springframework.web.multipart.MultipartException: Current request is not a multipart request</code>，很奇怪，我的feignClient传了MultipartFile了，而且打断点看了的。</p>\n<p>后来查了一些资料，发现FeignClient是不支持MultipartFile的，需要使用openfeign的feign-form来实现。</p>\n<p>增加依赖：</p>\n<pre><code class=\"xml\">&lt;dependency&gt;\n    &lt;groupId&gt;io.github.openfeign.form&lt;/groupId&gt;\n    &lt;artifactId&gt;feign-form&lt;/artifactId&gt;\n    &lt;version&gt;3.0.1&lt;/version&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;io.github.openfeign.form&lt;/groupId&gt;\n    &lt;artifactId&gt;feign-form-spring&lt;/artifactId&gt;\n    &lt;version&gt;3.0.1&lt;/version&gt;\n&lt;/dependency&gt;</code></pre>\n<p>feignClient的PostMapping注解增加属性：<code>consumes = MediaType.MULTIPART_FORM_DATA_VALUE</code></p>\n<pre><code class=\"java\">/**\n     * 图片上传\n     *\n     * @param\n     * @return\n     */\n    @ApiOperation(&quot;文件流方式上传&quot;)\n    @PostMapping(value = &quot;/file-upload&quot;, consumes = MediaType.MULTIPART_FORM_DATA_VALUE)\n    @ApiImplicitParams({\n            @ApiImplicitParam(name = &quot;prefix&quot;,value = &quot;文件前缀（例如：工单号）&quot;,required = true),\n            @ApiImplicitParam(name = &quot;filename&quot;,value = &quot;文件名称（上传文件名称,包含后缀名，如123456.jpg）&quot;,required = true)\n    })\n    @ResponseBody\n    Response&lt;UploadResult&gt; uploadFile(\n            @RequestParam(&quot;file&quot;) MultipartFile upfile,\n            @RequestParam(value = &quot;prefix&quot;) String prefix,\n            @RequestParam(value = &quot;filename&quot;) String filename\n    ) ;</code></pre>\n<p>这时候在测试一下接口，返回<code>org.springframework.web.multipart.support.MissingServletRequestPartException: Required request part &#39;file&#39; is not present</code></p>\n<p>也就是说，第一次都不是个multipart request，现在是少是个multipart request了，只是没有file这个request part。</p>\n<p>翻看了《Spring实战》的“处理multipart形式的数据”章节，<code>multipart/form-data</code>不是普通的表单，而是每个输入域都是一个part，接收这写part需要使用<code>@RequestPart</code>注解。</p>\n<p>于是将feignClient中的<code>@RequestParam</code>修改为<code>@RequestPart</code></p>\n<pre><code class=\"java\">/**\n     * 图片上传 api\n     *\n     * @param\n     * @return\n     */\n    @ApiOperation(&quot;文件流方式上传&quot;)\n    @PostMapping(value = &quot;/file-upload&quot;, consumes = MediaType.MULTIPART_FORM_DATA_VALUE)\n    @ApiImplicitParams({\n            @ApiImplicitParam(name = &quot;prefix&quot;,value = &quot;文件前缀（例如：工单号）&quot;,required = true),\n            @ApiImplicitParam(name = &quot;filename&quot;,value = &quot;文件名称（上传文件名称,包含后缀名，如123456.jpg）&quot;,required = true)\n    })\n    @ResponseBody\n    Response&lt;UploadResult&gt; uploadFile(\n            @RequestPart(&quot;file&quot;) MultipartFile upfile,\n            @RequestParam(value = &quot;prefix&quot;) String prefix,\n            @RequestParam(value = &quot;filename&quot;) String filename\n    ) ;</code></pre>\n<p>至此，上传文件成功！</p>\n<p>2022年5月注：<br>最近给下游服务提供了一个上传文件的接口，除了上传文件还需要带一些参数，本来随手就写出了一个@RequestPart的参数、一个@RequestBody的对象参数，存在问题。因为MultipartFile本来就是一个form表单的一部分，占用的是http的body，而@RequestBody则是要用一个json来占用http的body，二者是有冲突的，body只能是二者之一。既然文件必须在body，那么其他参数就只能在Url中携带了，所以这里要用@RequestParam，在url中传参数</p>\n","site":{"data":{}},"more":"<p>今天要给app提供一个上传文件的接口，这块我们再pc端的服务上已经有了这样一个接口，所以提供给app的接口，要在给app提供能力的服务上通过feign调用pc端服务的上传接口来实现，这样可以保证pc端和移动端一致，后期也好维护。</p>\n<p>说着就在app服务增加了一个feignClient</p>\n<pre><code class=\"java\">    /**\n     * 图片上传 feignClient\n     *\n     * @param\n     * @return\n     */\n    @ApiOperation(&quot;文件流方式上传&quot;)\n    @PostMapping(value = &quot;/file-upload&quot;)\n    @ApiImplicitParams({\n            @ApiImplicitParam(name = &quot;prefix&quot;,value = &quot;文件前缀（例如：工单号）&quot;,required = true),\n            @ApiImplicitParam(name = &quot;filename&quot;,value = &quot;文件名称（上传文件名称,包含后缀名，如123456.jpg）&quot;,required = true)\n    })\n    @ResponseBody\n    Response&lt;UploadResult&gt; uploadFile(\n            @RequestParam(&quot;file&quot;) MultipartFile upfile,\n            @RequestParam(value = &quot;prefix&quot;) String prefix,\n            @RequestParam(value = &quot;filename&quot;) String filename\n    ) ;</code></pre>\n<p>然后一个api接口：</p>\n<pre><code class=\"java\">    /**\n     * 图片上传 api\n     *\n     * @param\n     * @return\n     */\n    @ApiOperation(&quot;文件流方式上传&quot;)\n    @PostMapping(value = &quot;/file-upload&quot;)\n    @ApiImplicitParams({\n            @ApiImplicitParam(name = &quot;prefix&quot;,value = &quot;文件前缀（例如：工单号）&quot;,required = true),\n            @ApiImplicitParam(name = &quot;filename&quot;,value = &quot;文件名称（上传文件名称,包含后缀名，如123456.jpg）&quot;,required = true)\n    })\n    @ResponseBody\n    Response&lt;UploadResult&gt; uploadFile(\n            @RequestParam(&quot;file&quot;) MultipartFile upfile,\n            @RequestParam(value = &quot;prefix&quot;) String prefix,\n            @RequestParam(value = &quot;filename&quot;) String filename\n    ) {\n        return datumFeign.uploadFile(upfile, prefix, filename);\n    }</code></pre>\n<p>然后就开心的自测，感觉应该没啥问题。</p>\n<p>没想到收到PC端服务返回的<code>org.springframework.web.multipart.MultipartException: Current request is not a multipart request</code>，很奇怪，我的feignClient传了MultipartFile了，而且打断点看了的。</p>\n<p>后来查了一些资料，发现FeignClient是不支持MultipartFile的，需要使用openfeign的feign-form来实现。</p>\n<p>增加依赖：</p>\n<pre><code class=\"xml\">&lt;dependency&gt;\n    &lt;groupId&gt;io.github.openfeign.form&lt;/groupId&gt;\n    &lt;artifactId&gt;feign-form&lt;/artifactId&gt;\n    &lt;version&gt;3.0.1&lt;/version&gt;\n&lt;/dependency&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;io.github.openfeign.form&lt;/groupId&gt;\n    &lt;artifactId&gt;feign-form-spring&lt;/artifactId&gt;\n    &lt;version&gt;3.0.1&lt;/version&gt;\n&lt;/dependency&gt;</code></pre>\n<p>feignClient的PostMapping注解增加属性：<code>consumes = MediaType.MULTIPART_FORM_DATA_VALUE</code></p>\n<pre><code class=\"java\">/**\n     * 图片上传\n     *\n     * @param\n     * @return\n     */\n    @ApiOperation(&quot;文件流方式上传&quot;)\n    @PostMapping(value = &quot;/file-upload&quot;, consumes = MediaType.MULTIPART_FORM_DATA_VALUE)\n    @ApiImplicitParams({\n            @ApiImplicitParam(name = &quot;prefix&quot;,value = &quot;文件前缀（例如：工单号）&quot;,required = true),\n            @ApiImplicitParam(name = &quot;filename&quot;,value = &quot;文件名称（上传文件名称,包含后缀名，如123456.jpg）&quot;,required = true)\n    })\n    @ResponseBody\n    Response&lt;UploadResult&gt; uploadFile(\n            @RequestParam(&quot;file&quot;) MultipartFile upfile,\n            @RequestParam(value = &quot;prefix&quot;) String prefix,\n            @RequestParam(value = &quot;filename&quot;) String filename\n    ) ;</code></pre>\n<p>这时候在测试一下接口，返回<code>org.springframework.web.multipart.support.MissingServletRequestPartException: Required request part &#39;file&#39; is not present</code></p>\n<p>也就是说，第一次都不是个multipart request，现在是少是个multipart request了，只是没有file这个request part。</p>\n<p>翻看了《Spring实战》的“处理multipart形式的数据”章节，<code>multipart/form-data</code>不是普通的表单，而是每个输入域都是一个part，接收这写part需要使用<code>@RequestPart</code>注解。</p>\n<p>于是将feignClient中的<code>@RequestParam</code>修改为<code>@RequestPart</code></p>\n<pre><code class=\"java\">/**\n     * 图片上传 api\n     *\n     * @param\n     * @return\n     */\n    @ApiOperation(&quot;文件流方式上传&quot;)\n    @PostMapping(value = &quot;/file-upload&quot;, consumes = MediaType.MULTIPART_FORM_DATA_VALUE)\n    @ApiImplicitParams({\n            @ApiImplicitParam(name = &quot;prefix&quot;,value = &quot;文件前缀（例如：工单号）&quot;,required = true),\n            @ApiImplicitParam(name = &quot;filename&quot;,value = &quot;文件名称（上传文件名称,包含后缀名，如123456.jpg）&quot;,required = true)\n    })\n    @ResponseBody\n    Response&lt;UploadResult&gt; uploadFile(\n            @RequestPart(&quot;file&quot;) MultipartFile upfile,\n            @RequestParam(value = &quot;prefix&quot;) String prefix,\n            @RequestParam(value = &quot;filename&quot;) String filename\n    ) ;</code></pre>\n<p>至此，上传文件成功！</p>\n<p>2022年5月注：<br>最近给下游服务提供了一个上传文件的接口，除了上传文件还需要带一些参数，本来随手就写出了一个@RequestPart的参数、一个@RequestBody的对象参数，存在问题。因为MultipartFile本来就是一个form表单的一部分，占用的是http的body，而@RequestBody则是要用一个json来占用http的body，二者是有冲突的，body只能是二者之一。既然文件必须在body，那么其他参数就只能在Url中携带了，所以这里要用@RequestParam，在url中传参数</p>\n"},{"title":"Java异常和错误","excerpt":"","comments":1,"date":"2021-11-03T08:30:10.000Z","_content":"\n\ncopy from [http://doc.okbase.net/foxty/archive/120046.html](http://doc.okbase.net/foxty/archive/120046.html)\n\n\n# Java的异常体系\n- Throwable: Java中所有异常和错误类的父类。只有这个类的实例（或者子类的实例）可以被虚拟机抛出或者被java的throw关键字抛出。同样，只有其或其子类可以出现在catch子句里面。\n- Error: Throwable的子类，表示严重的问题发生了，而且这种错误是不可恢复的。\n- Exception: Throwable的子类，应用程序应该要捕获其或其子类（RuntimeException例外），称为checked exception。比如：IOException, NoSuchMethodException…\n- RuntimeException: Exception的子类，运行时异常，程序可以不捕获，称为unchecked exception。比如：NullPointException.\n\n\n## 应该catch什么\n\n其实只要是Throwable和其子类都是可以throw和catch的，那么如果在需要统一处理异常的地方，我们应该catch (Throwable th) 还是 catch (Exception)呢？\n\n这两种处理的区别在于，catch throwable会把Error和其他继承Throwable的类捕捉到。而catch Exception只会捕捉Exception极其子类，捕捉的范围更小。先不考虑有其他的类继承了Throwable的情况下（附录A），第一种catch相当于比第二种catch多捕捉了把Error和其子类。\n\n那么究竟Error是否需要捕捉呢？**JDK中Error类的的注释（如下）里提到过，Error是一种严重的问题，应用程序不应该捕捉它。**\n\n    An Error is a subclass of Throwable that indicates serious problems that a reasonable application should not try to catch. Most such errors are abnormal conditions. The ThreadDeath error, though a “normal” condition, is also a subclass of Error because most applications should not try to catch it.\n\n    A method is not required to declare in its throws clause any subclasses of Error that might be thrown during the execution of the method but not caught, since these errors are abnormal conditions that should never occur.\n\nJava Lanuage Spec 7 中也提到：Error继承自Throwable而不是继承自Exception，是为了方便程序可以使用 “catch (Exception)“来捕捉异常而不会把Error也捕捉在内，因为Exception发生后可以进行一些恢复工作的，但是Error发生后一般是不可恢复的。\n\n    The class Error is a separate subclass ofThrowable, distinct from Exception in the class hierarchy, to allow programs to use the idiom “} catch (Exception e) { \" (§11.2.3) to catch all exceptions from which recovery may be possible without catching errors from which recovery is typically not possible.\n\n已经不难看出，Java本身设计思路就是希望大家catch Exception就足够了，如果有Error发生，catch了也不会有什么作用（附录B）。\n\n## 引申，如何设计异常体系？\n\n如何设计异常体系要根据你的项目的情况，类库框架，应用程序的异常设计方式都会有一些区别。下面简单谈谈个人对异常设计的一些看法\n\n### 类库/框架\n\n继承RuntimeException扩展一个新的异常作为整个类库的异常基类。这个异常应该可以满足大部分类库对异常的要求。\n在实现中，在任何需要捕捉checked exception的地方都会把异常统一转化成这个新的异常。\n对于有特殊需求，需要自定义异常的，就通过继承这个基类来实现自定义异常。\n不对异常记录log（交给上层来处理）\n案例\nfastjson\n\nspring\n自定义异常比较多，不过都是继承自org.springframework.core.NestedRuntimeException，而这个异常也是继承自RuntimeException。\n\n### 应用程序\n\n设计上和框架异常类似，只是在捕捉checked exception的时候需要log\n如果需要根据异常进行不同的处理，建议给自定义异常增加一个ERROR_CODE字段，这样无论在服务器还是客户端都可以根据不同的ERROR_CODE进行对应的处理。但是出现这种情况的时候，应该需要考虑一下设计思路了，一般来讲根据异常来决定业务流程不是一个好的设计方案。\n\n# 附录A：是否应该直接继承Throwable来扩展新的异常？\n个人认为异常都应该继承自Exception或者RuntimeException，而且Java本身对Exception和Error的规划就很清晰了，Java自己类库中没有异常是直接继承自Throwable的。\n\n# 附录B：Error可以catch吗？ 可以catch了后做些其他处理吗？\nError是可以catch的，而且也可以向常规Exception一样被处理，而且就算不捕捉的话也只是导致当前线程挂掉，其他线程还是可以正常运行，如果有需要的话捕捉Error之后也可以做些其他处理。但是Error是一种系统内部的错误，这种错误不像Exception一样是可能是程序和业务上的错误是可以恢复的。\n\n假设进行网络连接操作的时候，IOException 发生了，可能是网络中断，我可以再尝试几次。\n\n假设OutOfMemoryError发生了，就算被捕捉了，可以有什么手段让程序正常运行下去吗？\n假设ExceptionInInitializerError发生了，类无法被正常初始化，这个是可以通过捕捉来恢复的吗？","source":"_posts/2021-10-08-kongzheng1993-Java异常和错误.md","raw":"---\ntitle: Java异常和错误\nexcerpt: 'Java'\ntags: [Java]\ncategories: [Java]\ncomments: true\ndate: 2021-11-03 16:30:10\n---\n\n\ncopy from [http://doc.okbase.net/foxty/archive/120046.html](http://doc.okbase.net/foxty/archive/120046.html)\n\n\n# Java的异常体系\n- Throwable: Java中所有异常和错误类的父类。只有这个类的实例（或者子类的实例）可以被虚拟机抛出或者被java的throw关键字抛出。同样，只有其或其子类可以出现在catch子句里面。\n- Error: Throwable的子类，表示严重的问题发生了，而且这种错误是不可恢复的。\n- Exception: Throwable的子类，应用程序应该要捕获其或其子类（RuntimeException例外），称为checked exception。比如：IOException, NoSuchMethodException…\n- RuntimeException: Exception的子类，运行时异常，程序可以不捕获，称为unchecked exception。比如：NullPointException.\n\n\n## 应该catch什么\n\n其实只要是Throwable和其子类都是可以throw和catch的，那么如果在需要统一处理异常的地方，我们应该catch (Throwable th) 还是 catch (Exception)呢？\n\n这两种处理的区别在于，catch throwable会把Error和其他继承Throwable的类捕捉到。而catch Exception只会捕捉Exception极其子类，捕捉的范围更小。先不考虑有其他的类继承了Throwable的情况下（附录A），第一种catch相当于比第二种catch多捕捉了把Error和其子类。\n\n那么究竟Error是否需要捕捉呢？**JDK中Error类的的注释（如下）里提到过，Error是一种严重的问题，应用程序不应该捕捉它。**\n\n    An Error is a subclass of Throwable that indicates serious problems that a reasonable application should not try to catch. Most such errors are abnormal conditions. The ThreadDeath error, though a “normal” condition, is also a subclass of Error because most applications should not try to catch it.\n\n    A method is not required to declare in its throws clause any subclasses of Error that might be thrown during the execution of the method but not caught, since these errors are abnormal conditions that should never occur.\n\nJava Lanuage Spec 7 中也提到：Error继承自Throwable而不是继承自Exception，是为了方便程序可以使用 “catch (Exception)“来捕捉异常而不会把Error也捕捉在内，因为Exception发生后可以进行一些恢复工作的，但是Error发生后一般是不可恢复的。\n\n    The class Error is a separate subclass ofThrowable, distinct from Exception in the class hierarchy, to allow programs to use the idiom “} catch (Exception e) { \" (§11.2.3) to catch all exceptions from which recovery may be possible without catching errors from which recovery is typically not possible.\n\n已经不难看出，Java本身设计思路就是希望大家catch Exception就足够了，如果有Error发生，catch了也不会有什么作用（附录B）。\n\n## 引申，如何设计异常体系？\n\n如何设计异常体系要根据你的项目的情况，类库框架，应用程序的异常设计方式都会有一些区别。下面简单谈谈个人对异常设计的一些看法\n\n### 类库/框架\n\n继承RuntimeException扩展一个新的异常作为整个类库的异常基类。这个异常应该可以满足大部分类库对异常的要求。\n在实现中，在任何需要捕捉checked exception的地方都会把异常统一转化成这个新的异常。\n对于有特殊需求，需要自定义异常的，就通过继承这个基类来实现自定义异常。\n不对异常记录log（交给上层来处理）\n案例\nfastjson\n\nspring\n自定义异常比较多，不过都是继承自org.springframework.core.NestedRuntimeException，而这个异常也是继承自RuntimeException。\n\n### 应用程序\n\n设计上和框架异常类似，只是在捕捉checked exception的时候需要log\n如果需要根据异常进行不同的处理，建议给自定义异常增加一个ERROR_CODE字段，这样无论在服务器还是客户端都可以根据不同的ERROR_CODE进行对应的处理。但是出现这种情况的时候，应该需要考虑一下设计思路了，一般来讲根据异常来决定业务流程不是一个好的设计方案。\n\n# 附录A：是否应该直接继承Throwable来扩展新的异常？\n个人认为异常都应该继承自Exception或者RuntimeException，而且Java本身对Exception和Error的规划就很清晰了，Java自己类库中没有异常是直接继承自Throwable的。\n\n# 附录B：Error可以catch吗？ 可以catch了后做些其他处理吗？\nError是可以catch的，而且也可以向常规Exception一样被处理，而且就算不捕捉的话也只是导致当前线程挂掉，其他线程还是可以正常运行，如果有需要的话捕捉Error之后也可以做些其他处理。但是Error是一种系统内部的错误，这种错误不像Exception一样是可能是程序和业务上的错误是可以恢复的。\n\n假设进行网络连接操作的时候，IOException 发生了，可能是网络中断，我可以再尝试几次。\n\n假设OutOfMemoryError发生了，就算被捕捉了，可以有什么手段让程序正常运行下去吗？\n假设ExceptionInInitializerError发生了，类无法被正常初始化，这个是可以通过捕捉来恢复的吗？","slug":"kongzheng1993-Java异常和错误","published":1,"updated":"2023-03-08T07:05:58.815Z","layout":"post","photos":[],"link":"","_id":"clg0k2am0007bt26fza8oop1z","content":"<p>copy from <a href=\"http://doc.okbase.net/foxty/archive/120046.html\" target=\"_blank\" rel=\"noopener\">http://doc.okbase.net/foxty/archive/120046.html</a></p>\n<h1 id=\"Java的异常体系\"><a href=\"#Java的异常体系\" class=\"headerlink\" title=\"Java的异常体系\"></a>Java的异常体系</h1><ul>\n<li>Throwable: Java中所有异常和错误类的父类。只有这个类的实例（或者子类的实例）可以被虚拟机抛出或者被java的throw关键字抛出。同样，只有其或其子类可以出现在catch子句里面。</li>\n<li>Error: Throwable的子类，表示严重的问题发生了，而且这种错误是不可恢复的。</li>\n<li>Exception: Throwable的子类，应用程序应该要捕获其或其子类（RuntimeException例外），称为checked exception。比如：IOException, NoSuchMethodException…</li>\n<li>RuntimeException: Exception的子类，运行时异常，程序可以不捕获，称为unchecked exception。比如：NullPointException.</li>\n</ul>\n<h2 id=\"应该catch什么\"><a href=\"#应该catch什么\" class=\"headerlink\" title=\"应该catch什么\"></a>应该catch什么</h2><p>其实只要是Throwable和其子类都是可以throw和catch的，那么如果在需要统一处理异常的地方，我们应该catch (Throwable th) 还是 catch (Exception)呢？</p>\n<p>这两种处理的区别在于，catch throwable会把Error和其他继承Throwable的类捕捉到。而catch Exception只会捕捉Exception极其子类，捕捉的范围更小。先不考虑有其他的类继承了Throwable的情况下（附录A），第一种catch相当于比第二种catch多捕捉了把Error和其子类。</p>\n<p>那么究竟Error是否需要捕捉呢？<strong>JDK中Error类的的注释（如下）里提到过，Error是一种严重的问题，应用程序不应该捕捉它。</strong></p>\n<pre><code>An Error is a subclass of Throwable that indicates serious problems that a reasonable application should not try to catch. Most such errors are abnormal conditions. The ThreadDeath error, though a “normal” condition, is also a subclass of Error because most applications should not try to catch it.\n\nA method is not required to declare in its throws clause any subclasses of Error that might be thrown during the execution of the method but not caught, since these errors are abnormal conditions that should never occur.</code></pre><p>Java Lanuage Spec 7 中也提到：Error继承自Throwable而不是继承自Exception，是为了方便程序可以使用 “catch (Exception)“来捕捉异常而不会把Error也捕捉在内，因为Exception发生后可以进行一些恢复工作的，但是Error发生后一般是不可恢复的。</p>\n<pre><code>The class Error is a separate subclass ofThrowable, distinct from Exception in the class hierarchy, to allow programs to use the idiom “} catch (Exception e) { &quot; (§11.2.3) to catch all exceptions from which recovery may be possible without catching errors from which recovery is typically not possible.</code></pre><p>已经不难看出，Java本身设计思路就是希望大家catch Exception就足够了，如果有Error发生，catch了也不会有什么作用（附录B）。</p>\n<h2 id=\"引申，如何设计异常体系？\"><a href=\"#引申，如何设计异常体系？\" class=\"headerlink\" title=\"引申，如何设计异常体系？\"></a>引申，如何设计异常体系？</h2><p>如何设计异常体系要根据你的项目的情况，类库框架，应用程序的异常设计方式都会有一些区别。下面简单谈谈个人对异常设计的一些看法</p>\n<h3 id=\"类库-框架\"><a href=\"#类库-框架\" class=\"headerlink\" title=\"类库/框架\"></a>类库/框架</h3><p>继承RuntimeException扩展一个新的异常作为整个类库的异常基类。这个异常应该可以满足大部分类库对异常的要求。<br>在实现中，在任何需要捕捉checked exception的地方都会把异常统一转化成这个新的异常。<br>对于有特殊需求，需要自定义异常的，就通过继承这个基类来实现自定义异常。<br>不对异常记录log（交给上层来处理）<br>案例<br>fastjson</p>\n<p>spring<br>自定义异常比较多，不过都是继承自org.springframework.core.NestedRuntimeException，而这个异常也是继承自RuntimeException。</p>\n<h3 id=\"应用程序\"><a href=\"#应用程序\" class=\"headerlink\" title=\"应用程序\"></a>应用程序</h3><p>设计上和框架异常类似，只是在捕捉checked exception的时候需要log<br>如果需要根据异常进行不同的处理，建议给自定义异常增加一个ERROR_CODE字段，这样无论在服务器还是客户端都可以根据不同的ERROR_CODE进行对应的处理。但是出现这种情况的时候，应该需要考虑一下设计思路了，一般来讲根据异常来决定业务流程不是一个好的设计方案。</p>\n<h1 id=\"附录A：是否应该直接继承Throwable来扩展新的异常？\"><a href=\"#附录A：是否应该直接继承Throwable来扩展新的异常？\" class=\"headerlink\" title=\"附录A：是否应该直接继承Throwable来扩展新的异常？\"></a>附录A：是否应该直接继承Throwable来扩展新的异常？</h1><p>个人认为异常都应该继承自Exception或者RuntimeException，而且Java本身对Exception和Error的规划就很清晰了，Java自己类库中没有异常是直接继承自Throwable的。</p>\n<h1 id=\"附录B：Error可以catch吗？-可以catch了后做些其他处理吗？\"><a href=\"#附录B：Error可以catch吗？-可以catch了后做些其他处理吗？\" class=\"headerlink\" title=\"附录B：Error可以catch吗？ 可以catch了后做些其他处理吗？\"></a>附录B：Error可以catch吗？ 可以catch了后做些其他处理吗？</h1><p>Error是可以catch的，而且也可以向常规Exception一样被处理，而且就算不捕捉的话也只是导致当前线程挂掉，其他线程还是可以正常运行，如果有需要的话捕捉Error之后也可以做些其他处理。但是Error是一种系统内部的错误，这种错误不像Exception一样是可能是程序和业务上的错误是可以恢复的。</p>\n<p>假设进行网络连接操作的时候，IOException 发生了，可能是网络中断，我可以再尝试几次。</p>\n<p>假设OutOfMemoryError发生了，就算被捕捉了，可以有什么手段让程序正常运行下去吗？<br>假设ExceptionInInitializerError发生了，类无法被正常初始化，这个是可以通过捕捉来恢复的吗？</p>\n","site":{"data":{}},"more":"<p>copy from <a href=\"http://doc.okbase.net/foxty/archive/120046.html\" target=\"_blank\" rel=\"noopener\">http://doc.okbase.net/foxty/archive/120046.html</a></p>\n<h1 id=\"Java的异常体系\"><a href=\"#Java的异常体系\" class=\"headerlink\" title=\"Java的异常体系\"></a>Java的异常体系</h1><ul>\n<li>Throwable: Java中所有异常和错误类的父类。只有这个类的实例（或者子类的实例）可以被虚拟机抛出或者被java的throw关键字抛出。同样，只有其或其子类可以出现在catch子句里面。</li>\n<li>Error: Throwable的子类，表示严重的问题发生了，而且这种错误是不可恢复的。</li>\n<li>Exception: Throwable的子类，应用程序应该要捕获其或其子类（RuntimeException例外），称为checked exception。比如：IOException, NoSuchMethodException…</li>\n<li>RuntimeException: Exception的子类，运行时异常，程序可以不捕获，称为unchecked exception。比如：NullPointException.</li>\n</ul>\n<h2 id=\"应该catch什么\"><a href=\"#应该catch什么\" class=\"headerlink\" title=\"应该catch什么\"></a>应该catch什么</h2><p>其实只要是Throwable和其子类都是可以throw和catch的，那么如果在需要统一处理异常的地方，我们应该catch (Throwable th) 还是 catch (Exception)呢？</p>\n<p>这两种处理的区别在于，catch throwable会把Error和其他继承Throwable的类捕捉到。而catch Exception只会捕捉Exception极其子类，捕捉的范围更小。先不考虑有其他的类继承了Throwable的情况下（附录A），第一种catch相当于比第二种catch多捕捉了把Error和其子类。</p>\n<p>那么究竟Error是否需要捕捉呢？<strong>JDK中Error类的的注释（如下）里提到过，Error是一种严重的问题，应用程序不应该捕捉它。</strong></p>\n<pre><code>An Error is a subclass of Throwable that indicates serious problems that a reasonable application should not try to catch. Most such errors are abnormal conditions. The ThreadDeath error, though a “normal” condition, is also a subclass of Error because most applications should not try to catch it.\n\nA method is not required to declare in its throws clause any subclasses of Error that might be thrown during the execution of the method but not caught, since these errors are abnormal conditions that should never occur.</code></pre><p>Java Lanuage Spec 7 中也提到：Error继承自Throwable而不是继承自Exception，是为了方便程序可以使用 “catch (Exception)“来捕捉异常而不会把Error也捕捉在内，因为Exception发生后可以进行一些恢复工作的，但是Error发生后一般是不可恢复的。</p>\n<pre><code>The class Error is a separate subclass ofThrowable, distinct from Exception in the class hierarchy, to allow programs to use the idiom “} catch (Exception e) { &quot; (§11.2.3) to catch all exceptions from which recovery may be possible without catching errors from which recovery is typically not possible.</code></pre><p>已经不难看出，Java本身设计思路就是希望大家catch Exception就足够了，如果有Error发生，catch了也不会有什么作用（附录B）。</p>\n<h2 id=\"引申，如何设计异常体系？\"><a href=\"#引申，如何设计异常体系？\" class=\"headerlink\" title=\"引申，如何设计异常体系？\"></a>引申，如何设计异常体系？</h2><p>如何设计异常体系要根据你的项目的情况，类库框架，应用程序的异常设计方式都会有一些区别。下面简单谈谈个人对异常设计的一些看法</p>\n<h3 id=\"类库-框架\"><a href=\"#类库-框架\" class=\"headerlink\" title=\"类库/框架\"></a>类库/框架</h3><p>继承RuntimeException扩展一个新的异常作为整个类库的异常基类。这个异常应该可以满足大部分类库对异常的要求。<br>在实现中，在任何需要捕捉checked exception的地方都会把异常统一转化成这个新的异常。<br>对于有特殊需求，需要自定义异常的，就通过继承这个基类来实现自定义异常。<br>不对异常记录log（交给上层来处理）<br>案例<br>fastjson</p>\n<p>spring<br>自定义异常比较多，不过都是继承自org.springframework.core.NestedRuntimeException，而这个异常也是继承自RuntimeException。</p>\n<h3 id=\"应用程序\"><a href=\"#应用程序\" class=\"headerlink\" title=\"应用程序\"></a>应用程序</h3><p>设计上和框架异常类似，只是在捕捉checked exception的时候需要log<br>如果需要根据异常进行不同的处理，建议给自定义异常增加一个ERROR_CODE字段，这样无论在服务器还是客户端都可以根据不同的ERROR_CODE进行对应的处理。但是出现这种情况的时候，应该需要考虑一下设计思路了，一般来讲根据异常来决定业务流程不是一个好的设计方案。</p>\n<h1 id=\"附录A：是否应该直接继承Throwable来扩展新的异常？\"><a href=\"#附录A：是否应该直接继承Throwable来扩展新的异常？\" class=\"headerlink\" title=\"附录A：是否应该直接继承Throwable来扩展新的异常？\"></a>附录A：是否应该直接继承Throwable来扩展新的异常？</h1><p>个人认为异常都应该继承自Exception或者RuntimeException，而且Java本身对Exception和Error的规划就很清晰了，Java自己类库中没有异常是直接继承自Throwable的。</p>\n<h1 id=\"附录B：Error可以catch吗？-可以catch了后做些其他处理吗？\"><a href=\"#附录B：Error可以catch吗？-可以catch了后做些其他处理吗？\" class=\"headerlink\" title=\"附录B：Error可以catch吗？ 可以catch了后做些其他处理吗？\"></a>附录B：Error可以catch吗？ 可以catch了后做些其他处理吗？</h1><p>Error是可以catch的，而且也可以向常规Exception一样被处理，而且就算不捕捉的话也只是导致当前线程挂掉，其他线程还是可以正常运行，如果有需要的话捕捉Error之后也可以做些其他处理。但是Error是一种系统内部的错误，这种错误不像Exception一样是可能是程序和业务上的错误是可以恢复的。</p>\n<p>假设进行网络连接操作的时候，IOException 发生了，可能是网络中断，我可以再尝试几次。</p>\n<p>假设OutOfMemoryError发生了，就算被捕捉了，可以有什么手段让程序正常运行下去吗？<br>假设ExceptionInInitializerError发生了，类无法被正常初始化，这个是可以通过捕捉来恢复的吗？</p>\n"},{"title":"Spring启动过程源码跟踪！","excerpt":"","comments":1,"date":"2021-10-08T16:30:52.000Z","_content":"\n\n    跟踪Spring源码org.springframework.context.support.ClassPathXmlApplicationContextTests#testSingleConfigLocation记录Spring容器启动过程，整个过程全部在ClassPathXmlApplicationContext的构造方法中\n## 1. 根据传入的xml配置文件创建ApplicationContext\n测试用例中传入的配置文件为/org/springframework/context/support/simpleContext.xml。org.springframework.context.support.AbstractRefreshableConfigApplicationContext#setConfigLocations方法中会有配置文件的判空和文件路径格式的调整，以方便后面读取文件。\n## 2. 容器初始化 refresh()\n### 1. prepareRefresh()\n容器刷新前的准备，设置上下文状态，获取属性，验证必要的属性等\n### 2. obtainFreshBeanFactory()\n获取新的beanFactory，销毁原有beanFactory、为每个bean生成BeanDefinition等\nBeanFactory，顾名思义Bean工厂，用于实例化和保存对象。\nFactoryBean，是一个Bean，用于实例化创建过程比较复杂的对象。使用工厂方法模式，由一个特定的工厂来生产特定的java类的实例化对象。\nObjectFactory，是某个特定的工厂，用于在项目启动时，延迟实例化对象，解决循环依赖的问题。\n```java\npublic interface FactoryBean<T> { \n    //返回的对象实例 \n    T getObject() throws Exception; \n    //Bean的类型 \n    Class<?> getObjectType(); \n    //true是单例，false是非单例 在Spring5.0中此方法利用了JDK1.8的新特性变成了default方法，返回true \n    boolean isSingleton(); \n}\n```\n\nFactoryBean的好处：正常情况下，Spring在实例化对象的时候，都是由BeanFactory从上下文获取BeanDefinition信息，然后通过反射，调用java类的构造方法进行实例化，而通过FactoryBean的形式，相当于将实例化的功能交给了这个类对应的FactoryBean来实现，可以更加灵活的去做一些解析、判断和逻辑处理。\nSpring中由两种Bean，一种是普通的Bean，另一种是实现了FactoryBean的工厂Bean。如果共BeanFactory中getBean的时候，获取到的Bean是工厂Bean，会自动调用这个工厂Bean的getObject方法返回真实的实例化对象。如果就是要获取工厂Bean对象，需要在getBean的时候加上前缀'&'。\nObjectFactory只有一个方法getObject()，可以借助Scope接口来自定义scope控制对象的创建时机。\n执行过程：\n  - 创建DefaultListableBeanFactory\n  - 载入beanDefinition\n    - 获取spring相关的xml文件，并转换为Document对象\n    - 解析Document，判断node是否属于beans(http://www.springframework.org/schema/beans)这个命名空间（Namespace）。针对默认命名空间(beans）和非默认空间，有不同的处理。\n        - 处理默认命名空间相关node:import、alias、bean、beans4种node。\n        - 处理非默认命名空间相关node，如：<context:annotation-config/>、<context:component-scan base-package=\"xx\"/>、<mongo:mongo-client/>\n    - 注册beanDefinition\n### 3. prepareBeanFactory(beanFactory)\n配置标准的beanFactory，设置ClassLoader，设置SpEL表达式解析器，添加忽略注入的接口，添加bean，添加bean后置处理器等\n执行过程：\n  - 设置类加载器\n  - 设置EL表达式解析器（Bean初始化完成后填充属性时会用到）\n  - 利用BeanPostProcessor的特性给各种Aware接口的实现类注入ApplicationContext中对应的属性\n  - 设置各种Aware接口的实现类为忽略自动配置ignoreDependencyInterface\n  - 设置自动装配的类registerResolvableDependency（BeanFactory、ResourceLoader、ApplicationEventPublisher、ApplicationContext）\n  - 如果BeanFactory中存在loadTimeWeaver的bean，那么需要添加动态织入功能\n  - 注册各种可用组件（environment、systemProperties、systemEnvironment）\n### 4. postProcessBeanFactory(beanFactory)\n模板方法，此时，所有的beanDefinition已经加载，但是还没有实例化。允许在子类中对beanFactory进行扩展处理。比如添加ware相关接口自动装配设置，添加后置处理器等，是子类扩展prepareBeanFactory(beanFactory)的方法\n### 5. invokeBeanFactoryPostProcessors(beanFactory)\n实例化并调用所有注册的beanFactory后置处理器（实现接口BeanFactoryPostProcessor的bean，在beanFactory标准初始化之后执行）。例如: PropertyPlaceholderConfigurer(处理占位符)。BeanFactoryPostProcessor 接口是 Spring 初始化 BeanFactory 时对外暴露的扩展点，Spring IoC 容器允许 BeanFactoryPostProcessor 在容器实例化任何 bean 之前读取 bean 的定义，并可以修改它。\nBeanDefinitionRegistryPostProcessor 继承自 BeanFactoryPostProcessor，比 BeanFactoryPostProcessor 具有更高的优先级，主要用来在常规的 BeanFactoryPostProcessor 检测开始之前注册其他 bean 定义。特别是，你可以通过 BeanDefinitionRegistryPostProcessor 来注册一些常规的 BeanFactoryPostProcessor，因为此时所有常规的 BeanFactoryPostProcessor 都还没开始被处理。\n执行过程：\n  - 拿到当前应用上下文的beanFactoryPostProcessors\n  - 实例化并调用所有已注册的BeanFactoryPostProcessor\n  - \n### 6. registerBeanPostProcessors(beanFactory)\n实例化和注册beanFactory中扩展了BeanPostProcessor的bean\n例如：\n AutowiredAnnotationBeanPostProcessor(处理被@Autowired注解修饰的bean并注入)\n RequiredAnnotationBeanPostProcessor(处理被@Required注解修饰的方法)\n CommonAnnotationBeanPostProcessor(处理@PreDestroy、@PostConstruct、@Resource等多个注解的作用)等。\n### 7. initMessageSource()\n初始化国际化工具类MessageSource。MessageSource定义的Bean名字必须是 messageSource，如果找不到就会默认注册DelegatingMessageSource 作为messageSource的Bean。\n### 8. initApplicationEventMulticaster()\n初始化事件广播器。先判断有没有applicationEventMulticaster的bean，有的话就使用，没有的话就new一个SimpleApplicationEventMulticaster\n### 9. onRefresh()\n模板方法，在容器刷新的时候可以自定义逻辑，不同的Spring容器做不同的事情。\n### 10. registerListeners()\n注册监听器，如果有earlyEventsToProcess广播earlyEvent\n### 11. finishBeanFactoryInitialization(beanFactory)\n实例化所有剩余的（非懒加载）单例\n比如invokeBeanFactoryPostProcessors方法中根据各种注解解析出来的类，在这个时候都会被初始化。实例化的过程各种BeanPostProcessor开始起作用。\n### 12. finishRefresh()\nrefresh做完之后需要做的其他事情。\n  - 清除上下文资源缓存（如扫描中的ASM元数据）\n  - 初始化上下文的生命周期处理器\n  - 刷新Spring容器中实现了Lifecycle接口的bean并执行start()方法\n  - 发布ContextRefreshedEvent事件告知对应的ApplicationListener进行响应的操作\n","source":"_posts/2021-10-08-kongzheng1993-Spring启动过程代码跟踪.md","raw":"---\ntitle: Spring启动过程源码跟踪！\nexcerpt: ''\ntags: [Spring]\ncategories: [Spring]\ncomments: true\ndate: 2021-10-09 00:30:52\n---\n\n\n    跟踪Spring源码org.springframework.context.support.ClassPathXmlApplicationContextTests#testSingleConfigLocation记录Spring容器启动过程，整个过程全部在ClassPathXmlApplicationContext的构造方法中\n## 1. 根据传入的xml配置文件创建ApplicationContext\n测试用例中传入的配置文件为/org/springframework/context/support/simpleContext.xml。org.springframework.context.support.AbstractRefreshableConfigApplicationContext#setConfigLocations方法中会有配置文件的判空和文件路径格式的调整，以方便后面读取文件。\n## 2. 容器初始化 refresh()\n### 1. prepareRefresh()\n容器刷新前的准备，设置上下文状态，获取属性，验证必要的属性等\n### 2. obtainFreshBeanFactory()\n获取新的beanFactory，销毁原有beanFactory、为每个bean生成BeanDefinition等\nBeanFactory，顾名思义Bean工厂，用于实例化和保存对象。\nFactoryBean，是一个Bean，用于实例化创建过程比较复杂的对象。使用工厂方法模式，由一个特定的工厂来生产特定的java类的实例化对象。\nObjectFactory，是某个特定的工厂，用于在项目启动时，延迟实例化对象，解决循环依赖的问题。\n```java\npublic interface FactoryBean<T> { \n    //返回的对象实例 \n    T getObject() throws Exception; \n    //Bean的类型 \n    Class<?> getObjectType(); \n    //true是单例，false是非单例 在Spring5.0中此方法利用了JDK1.8的新特性变成了default方法，返回true \n    boolean isSingleton(); \n}\n```\n\nFactoryBean的好处：正常情况下，Spring在实例化对象的时候，都是由BeanFactory从上下文获取BeanDefinition信息，然后通过反射，调用java类的构造方法进行实例化，而通过FactoryBean的形式，相当于将实例化的功能交给了这个类对应的FactoryBean来实现，可以更加灵活的去做一些解析、判断和逻辑处理。\nSpring中由两种Bean，一种是普通的Bean，另一种是实现了FactoryBean的工厂Bean。如果共BeanFactory中getBean的时候，获取到的Bean是工厂Bean，会自动调用这个工厂Bean的getObject方法返回真实的实例化对象。如果就是要获取工厂Bean对象，需要在getBean的时候加上前缀'&'。\nObjectFactory只有一个方法getObject()，可以借助Scope接口来自定义scope控制对象的创建时机。\n执行过程：\n  - 创建DefaultListableBeanFactory\n  - 载入beanDefinition\n    - 获取spring相关的xml文件，并转换为Document对象\n    - 解析Document，判断node是否属于beans(http://www.springframework.org/schema/beans)这个命名空间（Namespace）。针对默认命名空间(beans）和非默认空间，有不同的处理。\n        - 处理默认命名空间相关node:import、alias、bean、beans4种node。\n        - 处理非默认命名空间相关node，如：<context:annotation-config/>、<context:component-scan base-package=\"xx\"/>、<mongo:mongo-client/>\n    - 注册beanDefinition\n### 3. prepareBeanFactory(beanFactory)\n配置标准的beanFactory，设置ClassLoader，设置SpEL表达式解析器，添加忽略注入的接口，添加bean，添加bean后置处理器等\n执行过程：\n  - 设置类加载器\n  - 设置EL表达式解析器（Bean初始化完成后填充属性时会用到）\n  - 利用BeanPostProcessor的特性给各种Aware接口的实现类注入ApplicationContext中对应的属性\n  - 设置各种Aware接口的实现类为忽略自动配置ignoreDependencyInterface\n  - 设置自动装配的类registerResolvableDependency（BeanFactory、ResourceLoader、ApplicationEventPublisher、ApplicationContext）\n  - 如果BeanFactory中存在loadTimeWeaver的bean，那么需要添加动态织入功能\n  - 注册各种可用组件（environment、systemProperties、systemEnvironment）\n### 4. postProcessBeanFactory(beanFactory)\n模板方法，此时，所有的beanDefinition已经加载，但是还没有实例化。允许在子类中对beanFactory进行扩展处理。比如添加ware相关接口自动装配设置，添加后置处理器等，是子类扩展prepareBeanFactory(beanFactory)的方法\n### 5. invokeBeanFactoryPostProcessors(beanFactory)\n实例化并调用所有注册的beanFactory后置处理器（实现接口BeanFactoryPostProcessor的bean，在beanFactory标准初始化之后执行）。例如: PropertyPlaceholderConfigurer(处理占位符)。BeanFactoryPostProcessor 接口是 Spring 初始化 BeanFactory 时对外暴露的扩展点，Spring IoC 容器允许 BeanFactoryPostProcessor 在容器实例化任何 bean 之前读取 bean 的定义，并可以修改它。\nBeanDefinitionRegistryPostProcessor 继承自 BeanFactoryPostProcessor，比 BeanFactoryPostProcessor 具有更高的优先级，主要用来在常规的 BeanFactoryPostProcessor 检测开始之前注册其他 bean 定义。特别是，你可以通过 BeanDefinitionRegistryPostProcessor 来注册一些常规的 BeanFactoryPostProcessor，因为此时所有常规的 BeanFactoryPostProcessor 都还没开始被处理。\n执行过程：\n  - 拿到当前应用上下文的beanFactoryPostProcessors\n  - 实例化并调用所有已注册的BeanFactoryPostProcessor\n  - \n### 6. registerBeanPostProcessors(beanFactory)\n实例化和注册beanFactory中扩展了BeanPostProcessor的bean\n例如：\n AutowiredAnnotationBeanPostProcessor(处理被@Autowired注解修饰的bean并注入)\n RequiredAnnotationBeanPostProcessor(处理被@Required注解修饰的方法)\n CommonAnnotationBeanPostProcessor(处理@PreDestroy、@PostConstruct、@Resource等多个注解的作用)等。\n### 7. initMessageSource()\n初始化国际化工具类MessageSource。MessageSource定义的Bean名字必须是 messageSource，如果找不到就会默认注册DelegatingMessageSource 作为messageSource的Bean。\n### 8. initApplicationEventMulticaster()\n初始化事件广播器。先判断有没有applicationEventMulticaster的bean，有的话就使用，没有的话就new一个SimpleApplicationEventMulticaster\n### 9. onRefresh()\n模板方法，在容器刷新的时候可以自定义逻辑，不同的Spring容器做不同的事情。\n### 10. registerListeners()\n注册监听器，如果有earlyEventsToProcess广播earlyEvent\n### 11. finishBeanFactoryInitialization(beanFactory)\n实例化所有剩余的（非懒加载）单例\n比如invokeBeanFactoryPostProcessors方法中根据各种注解解析出来的类，在这个时候都会被初始化。实例化的过程各种BeanPostProcessor开始起作用。\n### 12. finishRefresh()\nrefresh做完之后需要做的其他事情。\n  - 清除上下文资源缓存（如扫描中的ASM元数据）\n  - 初始化上下文的生命周期处理器\n  - 刷新Spring容器中实现了Lifecycle接口的bean并执行start()方法\n  - 发布ContextRefreshedEvent事件告知对应的ApplicationListener进行响应的操作\n","slug":"kongzheng1993-Spring启动过程代码跟踪","published":1,"updated":"2023-03-08T07:05:58.815Z","layout":"post","photos":[],"link":"","_id":"clg0k2am1007et26fa5p3ag88","content":"<pre><code>跟踪Spring源码org.springframework.context.support.ClassPathXmlApplicationContextTests#testSingleConfigLocation记录Spring容器启动过程，整个过程全部在ClassPathXmlApplicationContext的构造方法中</code></pre><h2 id=\"1-根据传入的xml配置文件创建ApplicationContext\"><a href=\"#1-根据传入的xml配置文件创建ApplicationContext\" class=\"headerlink\" title=\"1. 根据传入的xml配置文件创建ApplicationContext\"></a>1. 根据传入的xml配置文件创建ApplicationContext</h2><p>测试用例中传入的配置文件为/org/springframework/context/support/simpleContext.xml。org.springframework.context.support.AbstractRefreshableConfigApplicationContext#setConfigLocations方法中会有配置文件的判空和文件路径格式的调整，以方便后面读取文件。</p>\n<h2 id=\"2-容器初始化-refresh\"><a href=\"#2-容器初始化-refresh\" class=\"headerlink\" title=\"2. 容器初始化 refresh()\"></a>2. 容器初始化 refresh()</h2><h3 id=\"1-prepareRefresh\"><a href=\"#1-prepareRefresh\" class=\"headerlink\" title=\"1. prepareRefresh()\"></a>1. prepareRefresh()</h3><p>容器刷新前的准备，设置上下文状态，获取属性，验证必要的属性等</p>\n<h3 id=\"2-obtainFreshBeanFactory\"><a href=\"#2-obtainFreshBeanFactory\" class=\"headerlink\" title=\"2. obtainFreshBeanFactory()\"></a>2. obtainFreshBeanFactory()</h3><p>获取新的beanFactory，销毁原有beanFactory、为每个bean生成BeanDefinition等<br>BeanFactory，顾名思义Bean工厂，用于实例化和保存对象。<br>FactoryBean，是一个Bean，用于实例化创建过程比较复杂的对象。使用工厂方法模式，由一个特定的工厂来生产特定的java类的实例化对象。<br>ObjectFactory，是某个特定的工厂，用于在项目启动时，延迟实例化对象，解决循环依赖的问题。</p>\n<pre><code class=\"java\">public interface FactoryBean&lt;T&gt; { \n    //返回的对象实例 \n    T getObject() throws Exception; \n    //Bean的类型 \n    Class&lt;?&gt; getObjectType(); \n    //true是单例，false是非单例 在Spring5.0中此方法利用了JDK1.8的新特性变成了default方法，返回true \n    boolean isSingleton(); \n}</code></pre>\n<p>FactoryBean的好处：正常情况下，Spring在实例化对象的时候，都是由BeanFactory从上下文获取BeanDefinition信息，然后通过反射，调用java类的构造方法进行实例化，而通过FactoryBean的形式，相当于将实例化的功能交给了这个类对应的FactoryBean来实现，可以更加灵活的去做一些解析、判断和逻辑处理。<br>Spring中由两种Bean，一种是普通的Bean，另一种是实现了FactoryBean的工厂Bean。如果共BeanFactory中getBean的时候，获取到的Bean是工厂Bean，会自动调用这个工厂Bean的getObject方法返回真实的实例化对象。如果就是要获取工厂Bean对象，需要在getBean的时候加上前缀’&amp;’。<br>ObjectFactory只有一个方法getObject()，可以借助Scope接口来自定义scope控制对象的创建时机。<br>执行过程：</p>\n<ul>\n<li>创建DefaultListableBeanFactory</li>\n<li>载入beanDefinition<ul>\n<li>获取spring相关的xml文件，并转换为Document对象</li>\n<li>解析Document，判断node是否属于beans(<a href=\"http://www.springframework.org/schema/beans)这个命名空间（Namespace）。针对默认命名空间\" target=\"_blank\" rel=\"noopener\">http://www.springframework.org/schema/beans)这个命名空间（Namespace）。针对默认命名空间</a>(beans）和非默认空间，有不同的处理。<ul>\n<li>处理默认命名空间相关node:import、alias、bean、beans4种node。</li>\n<li>处理非默认命名空间相关node，如：<a href=\"context:annotation-config/\" target=\"_blank\" rel=\"noopener\">context:annotation-config/</a>、&lt;context:component-scan base-package=”xx”/&gt;、<a href=\"mongo:mongo-client/\" target=\"_blank\" rel=\"noopener\">mongo:mongo-client/</a></li>\n</ul>\n</li>\n<li>注册beanDefinition<h3 id=\"3-prepareBeanFactory-beanFactory\"><a href=\"#3-prepareBeanFactory-beanFactory\" class=\"headerlink\" title=\"3. prepareBeanFactory(beanFactory)\"></a>3. prepareBeanFactory(beanFactory)</h3>配置标准的beanFactory，设置ClassLoader，设置SpEL表达式解析器，添加忽略注入的接口，添加bean，添加bean后置处理器等<br>执行过程：</li>\n</ul>\n</li>\n<li>设置类加载器</li>\n<li>设置EL表达式解析器（Bean初始化完成后填充属性时会用到）</li>\n<li>利用BeanPostProcessor的特性给各种Aware接口的实现类注入ApplicationContext中对应的属性</li>\n<li>设置各种Aware接口的实现类为忽略自动配置ignoreDependencyInterface</li>\n<li>设置自动装配的类registerResolvableDependency（BeanFactory、ResourceLoader、ApplicationEventPublisher、ApplicationContext）</li>\n<li>如果BeanFactory中存在loadTimeWeaver的bean，那么需要添加动态织入功能</li>\n<li>注册各种可用组件（environment、systemProperties、systemEnvironment）<h3 id=\"4-postProcessBeanFactory-beanFactory\"><a href=\"#4-postProcessBeanFactory-beanFactory\" class=\"headerlink\" title=\"4. postProcessBeanFactory(beanFactory)\"></a>4. postProcessBeanFactory(beanFactory)</h3>模板方法，此时，所有的beanDefinition已经加载，但是还没有实例化。允许在子类中对beanFactory进行扩展处理。比如添加ware相关接口自动装配设置，添加后置处理器等，是子类扩展prepareBeanFactory(beanFactory)的方法<h3 id=\"5-invokeBeanFactoryPostProcessors-beanFactory\"><a href=\"#5-invokeBeanFactoryPostProcessors-beanFactory\" class=\"headerlink\" title=\"5. invokeBeanFactoryPostProcessors(beanFactory)\"></a>5. invokeBeanFactoryPostProcessors(beanFactory)</h3>实例化并调用所有注册的beanFactory后置处理器（实现接口BeanFactoryPostProcessor的bean，在beanFactory标准初始化之后执行）。例如: PropertyPlaceholderConfigurer(处理占位符)。BeanFactoryPostProcessor 接口是 Spring 初始化 BeanFactory 时对外暴露的扩展点，Spring IoC 容器允许 BeanFactoryPostProcessor 在容器实例化任何 bean 之前读取 bean 的定义，并可以修改它。<br>BeanDefinitionRegistryPostProcessor 继承自 BeanFactoryPostProcessor，比 BeanFactoryPostProcessor 具有更高的优先级，主要用来在常规的 BeanFactoryPostProcessor 检测开始之前注册其他 bean 定义。特别是，你可以通过 BeanDefinitionRegistryPostProcessor 来注册一些常规的 BeanFactoryPostProcessor，因为此时所有常规的 BeanFactoryPostProcessor 都还没开始被处理。<br>执行过程：</li>\n<li>拿到当前应用上下文的beanFactoryPostProcessors</li>\n<li>实例化并调用所有已注册的BeanFactoryPostProcessor</li>\n<li><h3 id=\"6-registerBeanPostProcessors-beanFactory\"><a href=\"#6-registerBeanPostProcessors-beanFactory\" class=\"headerlink\" title=\"6. registerBeanPostProcessors(beanFactory)\"></a>6. registerBeanPostProcessors(beanFactory)</h3>实例化和注册beanFactory中扩展了BeanPostProcessor的bean<br>例如：<br>AutowiredAnnotationBeanPostProcessor(处理被@Autowired注解修饰的bean并注入)<br>RequiredAnnotationBeanPostProcessor(处理被@Required注解修饰的方法)<br>CommonAnnotationBeanPostProcessor(处理@PreDestroy、@PostConstruct、@Resource等多个注解的作用)等。<h3 id=\"7-initMessageSource\"><a href=\"#7-initMessageSource\" class=\"headerlink\" title=\"7. initMessageSource()\"></a>7. initMessageSource()</h3>初始化国际化工具类MessageSource。MessageSource定义的Bean名字必须是 messageSource，如果找不到就会默认注册DelegatingMessageSource 作为messageSource的Bean。<h3 id=\"8-initApplicationEventMulticaster\"><a href=\"#8-initApplicationEventMulticaster\" class=\"headerlink\" title=\"8. initApplicationEventMulticaster()\"></a>8. initApplicationEventMulticaster()</h3>初始化事件广播器。先判断有没有applicationEventMulticaster的bean，有的话就使用，没有的话就new一个SimpleApplicationEventMulticaster<h3 id=\"9-onRefresh\"><a href=\"#9-onRefresh\" class=\"headerlink\" title=\"9. onRefresh()\"></a>9. onRefresh()</h3>模板方法，在容器刷新的时候可以自定义逻辑，不同的Spring容器做不同的事情。<h3 id=\"10-registerListeners\"><a href=\"#10-registerListeners\" class=\"headerlink\" title=\"10. registerListeners()\"></a>10. registerListeners()</h3>注册监听器，如果有earlyEventsToProcess广播earlyEvent<h3 id=\"11-finishBeanFactoryInitialization-beanFactory\"><a href=\"#11-finishBeanFactoryInitialization-beanFactory\" class=\"headerlink\" title=\"11. finishBeanFactoryInitialization(beanFactory)\"></a>11. finishBeanFactoryInitialization(beanFactory)</h3>实例化所有剩余的（非懒加载）单例<br>比如invokeBeanFactoryPostProcessors方法中根据各种注解解析出来的类，在这个时候都会被初始化。实例化的过程各种BeanPostProcessor开始起作用。<h3 id=\"12-finishRefresh\"><a href=\"#12-finishRefresh\" class=\"headerlink\" title=\"12. finishRefresh()\"></a>12. finishRefresh()</h3>refresh做完之后需要做的其他事情。</li>\n<li>清除上下文资源缓存（如扫描中的ASM元数据）</li>\n<li>初始化上下文的生命周期处理器</li>\n<li>刷新Spring容器中实现了Lifecycle接口的bean并执行start()方法</li>\n<li>发布ContextRefreshedEvent事件告知对应的ApplicationListener进行响应的操作</li>\n</ul>\n","site":{"data":{}},"more":"<pre><code>跟踪Spring源码org.springframework.context.support.ClassPathXmlApplicationContextTests#testSingleConfigLocation记录Spring容器启动过程，整个过程全部在ClassPathXmlApplicationContext的构造方法中</code></pre><h2 id=\"1-根据传入的xml配置文件创建ApplicationContext\"><a href=\"#1-根据传入的xml配置文件创建ApplicationContext\" class=\"headerlink\" title=\"1. 根据传入的xml配置文件创建ApplicationContext\"></a>1. 根据传入的xml配置文件创建ApplicationContext</h2><p>测试用例中传入的配置文件为/org/springframework/context/support/simpleContext.xml。org.springframework.context.support.AbstractRefreshableConfigApplicationContext#setConfigLocations方法中会有配置文件的判空和文件路径格式的调整，以方便后面读取文件。</p>\n<h2 id=\"2-容器初始化-refresh\"><a href=\"#2-容器初始化-refresh\" class=\"headerlink\" title=\"2. 容器初始化 refresh()\"></a>2. 容器初始化 refresh()</h2><h3 id=\"1-prepareRefresh\"><a href=\"#1-prepareRefresh\" class=\"headerlink\" title=\"1. prepareRefresh()\"></a>1. prepareRefresh()</h3><p>容器刷新前的准备，设置上下文状态，获取属性，验证必要的属性等</p>\n<h3 id=\"2-obtainFreshBeanFactory\"><a href=\"#2-obtainFreshBeanFactory\" class=\"headerlink\" title=\"2. obtainFreshBeanFactory()\"></a>2. obtainFreshBeanFactory()</h3><p>获取新的beanFactory，销毁原有beanFactory、为每个bean生成BeanDefinition等<br>BeanFactory，顾名思义Bean工厂，用于实例化和保存对象。<br>FactoryBean，是一个Bean，用于实例化创建过程比较复杂的对象。使用工厂方法模式，由一个特定的工厂来生产特定的java类的实例化对象。<br>ObjectFactory，是某个特定的工厂，用于在项目启动时，延迟实例化对象，解决循环依赖的问题。</p>\n<pre><code class=\"java\">public interface FactoryBean&lt;T&gt; { \n    //返回的对象实例 \n    T getObject() throws Exception; \n    //Bean的类型 \n    Class&lt;?&gt; getObjectType(); \n    //true是单例，false是非单例 在Spring5.0中此方法利用了JDK1.8的新特性变成了default方法，返回true \n    boolean isSingleton(); \n}</code></pre>\n<p>FactoryBean的好处：正常情况下，Spring在实例化对象的时候，都是由BeanFactory从上下文获取BeanDefinition信息，然后通过反射，调用java类的构造方法进行实例化，而通过FactoryBean的形式，相当于将实例化的功能交给了这个类对应的FactoryBean来实现，可以更加灵活的去做一些解析、判断和逻辑处理。<br>Spring中由两种Bean，一种是普通的Bean，另一种是实现了FactoryBean的工厂Bean。如果共BeanFactory中getBean的时候，获取到的Bean是工厂Bean，会自动调用这个工厂Bean的getObject方法返回真实的实例化对象。如果就是要获取工厂Bean对象，需要在getBean的时候加上前缀’&amp;’。<br>ObjectFactory只有一个方法getObject()，可以借助Scope接口来自定义scope控制对象的创建时机。<br>执行过程：</p>\n<ul>\n<li>创建DefaultListableBeanFactory</li>\n<li>载入beanDefinition<ul>\n<li>获取spring相关的xml文件，并转换为Document对象</li>\n<li>解析Document，判断node是否属于beans(<a href=\"http://www.springframework.org/schema/beans)这个命名空间（Namespace）。针对默认命名空间\" target=\"_blank\" rel=\"noopener\">http://www.springframework.org/schema/beans)这个命名空间（Namespace）。针对默认命名空间</a>(beans）和非默认空间，有不同的处理。<ul>\n<li>处理默认命名空间相关node:import、alias、bean、beans4种node。</li>\n<li>处理非默认命名空间相关node，如：<a href=\"context:annotation-config/\" target=\"_blank\" rel=\"noopener\">context:annotation-config/</a>、&lt;context:component-scan base-package=”xx”/&gt;、<a href=\"mongo:mongo-client/\" target=\"_blank\" rel=\"noopener\">mongo:mongo-client/</a></li>\n</ul>\n</li>\n<li>注册beanDefinition<h3 id=\"3-prepareBeanFactory-beanFactory\"><a href=\"#3-prepareBeanFactory-beanFactory\" class=\"headerlink\" title=\"3. prepareBeanFactory(beanFactory)\"></a>3. prepareBeanFactory(beanFactory)</h3>配置标准的beanFactory，设置ClassLoader，设置SpEL表达式解析器，添加忽略注入的接口，添加bean，添加bean后置处理器等<br>执行过程：</li>\n</ul>\n</li>\n<li>设置类加载器</li>\n<li>设置EL表达式解析器（Bean初始化完成后填充属性时会用到）</li>\n<li>利用BeanPostProcessor的特性给各种Aware接口的实现类注入ApplicationContext中对应的属性</li>\n<li>设置各种Aware接口的实现类为忽略自动配置ignoreDependencyInterface</li>\n<li>设置自动装配的类registerResolvableDependency（BeanFactory、ResourceLoader、ApplicationEventPublisher、ApplicationContext）</li>\n<li>如果BeanFactory中存在loadTimeWeaver的bean，那么需要添加动态织入功能</li>\n<li>注册各种可用组件（environment、systemProperties、systemEnvironment）<h3 id=\"4-postProcessBeanFactory-beanFactory\"><a href=\"#4-postProcessBeanFactory-beanFactory\" class=\"headerlink\" title=\"4. postProcessBeanFactory(beanFactory)\"></a>4. postProcessBeanFactory(beanFactory)</h3>模板方法，此时，所有的beanDefinition已经加载，但是还没有实例化。允许在子类中对beanFactory进行扩展处理。比如添加ware相关接口自动装配设置，添加后置处理器等，是子类扩展prepareBeanFactory(beanFactory)的方法<h3 id=\"5-invokeBeanFactoryPostProcessors-beanFactory\"><a href=\"#5-invokeBeanFactoryPostProcessors-beanFactory\" class=\"headerlink\" title=\"5. invokeBeanFactoryPostProcessors(beanFactory)\"></a>5. invokeBeanFactoryPostProcessors(beanFactory)</h3>实例化并调用所有注册的beanFactory后置处理器（实现接口BeanFactoryPostProcessor的bean，在beanFactory标准初始化之后执行）。例如: PropertyPlaceholderConfigurer(处理占位符)。BeanFactoryPostProcessor 接口是 Spring 初始化 BeanFactory 时对外暴露的扩展点，Spring IoC 容器允许 BeanFactoryPostProcessor 在容器实例化任何 bean 之前读取 bean 的定义，并可以修改它。<br>BeanDefinitionRegistryPostProcessor 继承自 BeanFactoryPostProcessor，比 BeanFactoryPostProcessor 具有更高的优先级，主要用来在常规的 BeanFactoryPostProcessor 检测开始之前注册其他 bean 定义。特别是，你可以通过 BeanDefinitionRegistryPostProcessor 来注册一些常规的 BeanFactoryPostProcessor，因为此时所有常规的 BeanFactoryPostProcessor 都还没开始被处理。<br>执行过程：</li>\n<li>拿到当前应用上下文的beanFactoryPostProcessors</li>\n<li>实例化并调用所有已注册的BeanFactoryPostProcessor</li>\n<li><h3 id=\"6-registerBeanPostProcessors-beanFactory\"><a href=\"#6-registerBeanPostProcessors-beanFactory\" class=\"headerlink\" title=\"6. registerBeanPostProcessors(beanFactory)\"></a>6. registerBeanPostProcessors(beanFactory)</h3>实例化和注册beanFactory中扩展了BeanPostProcessor的bean<br>例如：<br>AutowiredAnnotationBeanPostProcessor(处理被@Autowired注解修饰的bean并注入)<br>RequiredAnnotationBeanPostProcessor(处理被@Required注解修饰的方法)<br>CommonAnnotationBeanPostProcessor(处理@PreDestroy、@PostConstruct、@Resource等多个注解的作用)等。<h3 id=\"7-initMessageSource\"><a href=\"#7-initMessageSource\" class=\"headerlink\" title=\"7. initMessageSource()\"></a>7. initMessageSource()</h3>初始化国际化工具类MessageSource。MessageSource定义的Bean名字必须是 messageSource，如果找不到就会默认注册DelegatingMessageSource 作为messageSource的Bean。<h3 id=\"8-initApplicationEventMulticaster\"><a href=\"#8-initApplicationEventMulticaster\" class=\"headerlink\" title=\"8. initApplicationEventMulticaster()\"></a>8. initApplicationEventMulticaster()</h3>初始化事件广播器。先判断有没有applicationEventMulticaster的bean，有的话就使用，没有的话就new一个SimpleApplicationEventMulticaster<h3 id=\"9-onRefresh\"><a href=\"#9-onRefresh\" class=\"headerlink\" title=\"9. onRefresh()\"></a>9. onRefresh()</h3>模板方法，在容器刷新的时候可以自定义逻辑，不同的Spring容器做不同的事情。<h3 id=\"10-registerListeners\"><a href=\"#10-registerListeners\" class=\"headerlink\" title=\"10. registerListeners()\"></a>10. registerListeners()</h3>注册监听器，如果有earlyEventsToProcess广播earlyEvent<h3 id=\"11-finishBeanFactoryInitialization-beanFactory\"><a href=\"#11-finishBeanFactoryInitialization-beanFactory\" class=\"headerlink\" title=\"11. finishBeanFactoryInitialization(beanFactory)\"></a>11. finishBeanFactoryInitialization(beanFactory)</h3>实例化所有剩余的（非懒加载）单例<br>比如invokeBeanFactoryPostProcessors方法中根据各种注解解析出来的类，在这个时候都会被初始化。实例化的过程各种BeanPostProcessor开始起作用。<h3 id=\"12-finishRefresh\"><a href=\"#12-finishRefresh\" class=\"headerlink\" title=\"12. finishRefresh()\"></a>12. finishRefresh()</h3>refresh做完之后需要做的其他事情。</li>\n<li>清除上下文资源缓存（如扫描中的ASM元数据）</li>\n<li>初始化上下文的生命周期处理器</li>\n<li>刷新Spring容器中实现了Lifecycle接口的bean并执行start()方法</li>\n<li>发布ContextRefreshedEvent事件告知对应的ApplicationListener进行响应的操作</li>\n</ul>\n"},{"title":"Feign请求Request header is too large","excerpt":"","comments":1,"date":"2021-10-08T16:30:52.000Z","_content":"\n","source":"_posts/2021-11-03-kongzheng1993-Feign_Request_Header_is_too_large.md","raw":"---\ntitle: Feign请求Request header is too large\nexcerpt: ''\ntags: [Spring Cloud]\ncategories: [Spring Cloud]\ncomments: true\ndate: 2021-10-09 00:30:52\n---\n\n","slug":"kongzheng1993-Feign_Request_Header_is_too_large","published":1,"updated":"2023-03-08T07:05:58.815Z","layout":"post","photos":[],"link":"","_id":"clg0k2am1007it26ffjby2ibe","content":"","site":{"data":{}},"more":""},{"title":"Spring是如何解决循环依赖的？","excerpt":"","comments":1,"date":"2021-10-08T08:30:10.000Z","_content":"\n## 什么是循环依赖\n\n循环依赖分为三种，自身依赖于自身、互相循环依赖、多组循环依赖。但无论循环依赖的数量有多少，循环依赖的本质是一样的。就是你的完整创建依赖于我，而我的完整创建也依赖于你，但我们互相没法解耦，最终导致依赖创建失败。所以 Spring 提供了除了构造函数注入和原型注入外的，setter循环依赖注入解决方案。\n\n```java\n\npublic class ABTest {\n\n    public static void main(String[] args) {\n        new ClazzA();\n    }\n\n}\n\nclass ClazzA {\n\n    private ClazzB b = new ClazzB();\n\n}\n\nclass ClazzB {\n\n    private ClazzA a = new ClazzA();\n\n}\n\n```\n\n这段代码就是循环依赖最初的模样，你中有我，我中有你，运行就报错`java.lang.StackOverflowError`。\n\n#### 解决办法\n\n```java\n\npublic class CircleTest {\n\n    private final static Map<String, Object> singletonObjects = new ConcurrentHashMap<>(256);\n\n    public static void main(String[] args) throws Exception {\n        System.out.println(getBean(B.class).getA());\n        System.out.println(getBean(A.class).getB());\n    }\n\n    private static <T> T getBean(Class<T> beanClass) throws Exception {\n        String beanName = beanClass.getSimpleName().toLowerCase();\n        if (singletonObjects.containsKey(beanName)) {\n            return (T) singletonObjects.get(beanName);\n        }\n        // 实例化对象入缓存\n        Object obj = beanClass.newInstance();\n        singletonObjects.put(beanName, obj);\n        // 属性填充补全对象\n        Field[] fields = obj.getClass().getDeclaredFields();\n        for (Field field : fields) {\n            field.setAccessible(true);\n            Class<?> fieldClass = field.getType();\n            String fieldBeanName = fieldClass.getSimpleName().toLowerCase();\n            field.set(obj, singletonObjects.containsKey(fieldBeanName) ? singletonObjects.get(fieldBeanName) : getBean(fieldClass));\n            field.setAccessible(false);\n        }\n        return (T) obj;\n    }\n\n}\n\nclass A {\n\n    private B b;\n\n    // ...get/set\n}\n\nclass B {\n    private A a;\n\n\t// ...get/set\n}\n```\n\n这里的解决方案就是将半成品对象，存放在缓存`singletonObjects`中，当B依赖A的时候能先使用半成品A来完成B的创建。\n\n## Spring的三级缓存\n\n```java\n\n/**\n * Return the (raw) singleton object registered under the given name.\n * <p>Checks already instantiated singletons and also allows for an early\n * reference to a currently created singleton (resolving a circular reference).\n * @param beanName the name of the bean to look for\n * @param allowEarlyReference whether early references should be created or not\n * @return the registered singleton object, or {@code null} if none found\n */\n@Nullable\nprotected Object getSingleton(String beanName, boolean allowEarlyReference) {\n\t// Quick check for existing instance without full singleton lock\n\tObject singletonObject = this.singletonObjects.get(beanName);\n\tif (singletonObject == null && isSingletonCurrentlyInCreation(beanName)) {\n\t\tsingletonObject = this.earlySingletonObjects.get(beanName);\n\t\tif (singletonObject == null && allowEarlyReference) {\n\t\t\tsynchronized (this.singletonObjects) {\n\t\t\t\t// Consistent creation of early reference within full singleton lock\n\t\t\t\tsingletonObject = this.singletonObjects.get(beanName);\n\t\t\t\tif (singletonObject == null) {\n\t\t\t\t\tsingletonObject = this.earlySingletonObjects.get(beanName);\n\t\t\t\t\tif (singletonObject == null) {\n\t\t\t\t\t\tObjectFactory<?> singletonFactory = this.singletonFactories.get(beanName);\n\t\t\t\t\t\tif (singletonFactory != null) {\n\t\t\t\t\t\t\tsingletonObject = singletonFactory.getObject();\n\t\t\t\t\t\t\tthis.earlySingletonObjects.put(beanName, singletonObject);\n\t\t\t\t\t\t\tthis.singletonFactories.remove(beanName);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn singletonObject;\n}\n\n```\n\n- `singletonObjects.get(beanName)`，从`singletonObjects`获取实例，`singletonObjects`是成品bean\n- `isSingletonCurrentlyInCreation`，判断beanName，`isSingletonCurrentlyInCreation` 对应的bean是否正在创建中\n- `allowEarlyReference`，从`earlySingletonObjects`中获取提前曝光未成品的bean\n- `singletonFactory.getObject()`，提前曝光bean实例，主要用于解决AOP循环依赖\n\n### 只有一级缓存为什么不行？\n\n一级缓存是存放bean的半成品。但是如果创建A的时候需要B，创建B的时候需要A，而A却还没有创建完成，会出现死循环。\n\n### 二级缓存能解决问题吗？\n\n一级缓存存放bean的成品，二级缓存存放bean的半成品。A在创建半成品对象后存放到缓存中，接下来补充A对象中依赖的B的属性。B继续创建，创建的半成品同样存放到缓存中，在补充对象的A属性的时候，可以从半成品缓存中获取A的半成品，那么现在B就是一个完成的对象了，而接下来递归操作后，A也是一个完整的对象了。\n\n### 三级缓存解决了什么问题？\n\n一级缓存是成品，二级缓存是半成品，三级缓存是工厂对象。二级缓存已经可以解决Spring的依赖了。三级缓存是为了解决Spring AOP的特性，AOP本身就是对方法的增强，是`ObjectFactory<?>`类型的lambda表达式，而Spring的原则又不希望将此类类型的Bean前置创建，所以要放到三级缓存中处理。其实整体处理过程类似，唯独是B在填充属性A时，先查询成品缓存、在查询半成品缓存，最后再看看有没有单例工程类在三级缓存中。最终获取到以后调用getObject方法返回代理引用或者原始引用。\n\n","source":"_posts/2021-10-08-kongzheng1993-Spring是如何解决循环依赖的（三级缓存）.md","raw":"---\ntitle: Spring是如何解决循环依赖的？\nexcerpt: 'Spring'\ntags: [Spring]\ncategories: [Spring]\ncomments: true\ndate: 2021-10-08 16:30:10\n---\n\n## 什么是循环依赖\n\n循环依赖分为三种，自身依赖于自身、互相循环依赖、多组循环依赖。但无论循环依赖的数量有多少，循环依赖的本质是一样的。就是你的完整创建依赖于我，而我的完整创建也依赖于你，但我们互相没法解耦，最终导致依赖创建失败。所以 Spring 提供了除了构造函数注入和原型注入外的，setter循环依赖注入解决方案。\n\n```java\n\npublic class ABTest {\n\n    public static void main(String[] args) {\n        new ClazzA();\n    }\n\n}\n\nclass ClazzA {\n\n    private ClazzB b = new ClazzB();\n\n}\n\nclass ClazzB {\n\n    private ClazzA a = new ClazzA();\n\n}\n\n```\n\n这段代码就是循环依赖最初的模样，你中有我，我中有你，运行就报错`java.lang.StackOverflowError`。\n\n#### 解决办法\n\n```java\n\npublic class CircleTest {\n\n    private final static Map<String, Object> singletonObjects = new ConcurrentHashMap<>(256);\n\n    public static void main(String[] args) throws Exception {\n        System.out.println(getBean(B.class).getA());\n        System.out.println(getBean(A.class).getB());\n    }\n\n    private static <T> T getBean(Class<T> beanClass) throws Exception {\n        String beanName = beanClass.getSimpleName().toLowerCase();\n        if (singletonObjects.containsKey(beanName)) {\n            return (T) singletonObjects.get(beanName);\n        }\n        // 实例化对象入缓存\n        Object obj = beanClass.newInstance();\n        singletonObjects.put(beanName, obj);\n        // 属性填充补全对象\n        Field[] fields = obj.getClass().getDeclaredFields();\n        for (Field field : fields) {\n            field.setAccessible(true);\n            Class<?> fieldClass = field.getType();\n            String fieldBeanName = fieldClass.getSimpleName().toLowerCase();\n            field.set(obj, singletonObjects.containsKey(fieldBeanName) ? singletonObjects.get(fieldBeanName) : getBean(fieldClass));\n            field.setAccessible(false);\n        }\n        return (T) obj;\n    }\n\n}\n\nclass A {\n\n    private B b;\n\n    // ...get/set\n}\n\nclass B {\n    private A a;\n\n\t// ...get/set\n}\n```\n\n这里的解决方案就是将半成品对象，存放在缓存`singletonObjects`中，当B依赖A的时候能先使用半成品A来完成B的创建。\n\n## Spring的三级缓存\n\n```java\n\n/**\n * Return the (raw) singleton object registered under the given name.\n * <p>Checks already instantiated singletons and also allows for an early\n * reference to a currently created singleton (resolving a circular reference).\n * @param beanName the name of the bean to look for\n * @param allowEarlyReference whether early references should be created or not\n * @return the registered singleton object, or {@code null} if none found\n */\n@Nullable\nprotected Object getSingleton(String beanName, boolean allowEarlyReference) {\n\t// Quick check for existing instance without full singleton lock\n\tObject singletonObject = this.singletonObjects.get(beanName);\n\tif (singletonObject == null && isSingletonCurrentlyInCreation(beanName)) {\n\t\tsingletonObject = this.earlySingletonObjects.get(beanName);\n\t\tif (singletonObject == null && allowEarlyReference) {\n\t\t\tsynchronized (this.singletonObjects) {\n\t\t\t\t// Consistent creation of early reference within full singleton lock\n\t\t\t\tsingletonObject = this.singletonObjects.get(beanName);\n\t\t\t\tif (singletonObject == null) {\n\t\t\t\t\tsingletonObject = this.earlySingletonObjects.get(beanName);\n\t\t\t\t\tif (singletonObject == null) {\n\t\t\t\t\t\tObjectFactory<?> singletonFactory = this.singletonFactories.get(beanName);\n\t\t\t\t\t\tif (singletonFactory != null) {\n\t\t\t\t\t\t\tsingletonObject = singletonFactory.getObject();\n\t\t\t\t\t\t\tthis.earlySingletonObjects.put(beanName, singletonObject);\n\t\t\t\t\t\t\tthis.singletonFactories.remove(beanName);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn singletonObject;\n}\n\n```\n\n- `singletonObjects.get(beanName)`，从`singletonObjects`获取实例，`singletonObjects`是成品bean\n- `isSingletonCurrentlyInCreation`，判断beanName，`isSingletonCurrentlyInCreation` 对应的bean是否正在创建中\n- `allowEarlyReference`，从`earlySingletonObjects`中获取提前曝光未成品的bean\n- `singletonFactory.getObject()`，提前曝光bean实例，主要用于解决AOP循环依赖\n\n### 只有一级缓存为什么不行？\n\n一级缓存是存放bean的半成品。但是如果创建A的时候需要B，创建B的时候需要A，而A却还没有创建完成，会出现死循环。\n\n### 二级缓存能解决问题吗？\n\n一级缓存存放bean的成品，二级缓存存放bean的半成品。A在创建半成品对象后存放到缓存中，接下来补充A对象中依赖的B的属性。B继续创建，创建的半成品同样存放到缓存中，在补充对象的A属性的时候，可以从半成品缓存中获取A的半成品，那么现在B就是一个完成的对象了，而接下来递归操作后，A也是一个完整的对象了。\n\n### 三级缓存解决了什么问题？\n\n一级缓存是成品，二级缓存是半成品，三级缓存是工厂对象。二级缓存已经可以解决Spring的依赖了。三级缓存是为了解决Spring AOP的特性，AOP本身就是对方法的增强，是`ObjectFactory<?>`类型的lambda表达式，而Spring的原则又不希望将此类类型的Bean前置创建，所以要放到三级缓存中处理。其实整体处理过程类似，唯独是B在填充属性A时，先查询成品缓存、在查询半成品缓存，最后再看看有没有单例工程类在三级缓存中。最终获取到以后调用getObject方法返回代理引用或者原始引用。\n\n","slug":"kongzheng1993-Spring是如何解决循环依赖的（三级缓存）","published":1,"updated":"2023-03-08T07:05:58.815Z","layout":"post","photos":[],"link":"","_id":"clg0k2am2007mt26fv3uqirp1","content":"<h2 id=\"什么是循环依赖\"><a href=\"#什么是循环依赖\" class=\"headerlink\" title=\"什么是循环依赖\"></a>什么是循环依赖</h2><p>循环依赖分为三种，自身依赖于自身、互相循环依赖、多组循环依赖。但无论循环依赖的数量有多少，循环依赖的本质是一样的。就是你的完整创建依赖于我，而我的完整创建也依赖于你，但我们互相没法解耦，最终导致依赖创建失败。所以 Spring 提供了除了构造函数注入和原型注入外的，setter循环依赖注入解决方案。</p>\n<pre><code class=\"java\">\npublic class ABTest {\n\n    public static void main(String[] args) {\n        new ClazzA();\n    }\n\n}\n\nclass ClazzA {\n\n    private ClazzB b = new ClazzB();\n\n}\n\nclass ClazzB {\n\n    private ClazzA a = new ClazzA();\n\n}\n</code></pre>\n<p>这段代码就是循环依赖最初的模样，你中有我，我中有你，运行就报错<code>java.lang.StackOverflowError</code>。</p>\n<h4 id=\"解决办法\"><a href=\"#解决办法\" class=\"headerlink\" title=\"解决办法\"></a>解决办法</h4><pre><code class=\"java\">\npublic class CircleTest {\n\n    private final static Map&lt;String, Object&gt; singletonObjects = new ConcurrentHashMap&lt;&gt;(256);\n\n    public static void main(String[] args) throws Exception {\n        System.out.println(getBean(B.class).getA());\n        System.out.println(getBean(A.class).getB());\n    }\n\n    private static &lt;T&gt; T getBean(Class&lt;T&gt; beanClass) throws Exception {\n        String beanName = beanClass.getSimpleName().toLowerCase();\n        if (singletonObjects.containsKey(beanName)) {\n            return (T) singletonObjects.get(beanName);\n        }\n        // 实例化对象入缓存\n        Object obj = beanClass.newInstance();\n        singletonObjects.put(beanName, obj);\n        // 属性填充补全对象\n        Field[] fields = obj.getClass().getDeclaredFields();\n        for (Field field : fields) {\n            field.setAccessible(true);\n            Class&lt;?&gt; fieldClass = field.getType();\n            String fieldBeanName = fieldClass.getSimpleName().toLowerCase();\n            field.set(obj, singletonObjects.containsKey(fieldBeanName) ? singletonObjects.get(fieldBeanName) : getBean(fieldClass));\n            field.setAccessible(false);\n        }\n        return (T) obj;\n    }\n\n}\n\nclass A {\n\n    private B b;\n\n    // ...get/set\n}\n\nclass B {\n    private A a;\n\n    // ...get/set\n}</code></pre>\n<p>这里的解决方案就是将半成品对象，存放在缓存<code>singletonObjects</code>中，当B依赖A的时候能先使用半成品A来完成B的创建。</p>\n<h2 id=\"Spring的三级缓存\"><a href=\"#Spring的三级缓存\" class=\"headerlink\" title=\"Spring的三级缓存\"></a>Spring的三级缓存</h2><pre><code class=\"java\">\n/**\n * Return the (raw) singleton object registered under the given name.\n * &lt;p&gt;Checks already instantiated singletons and also allows for an early\n * reference to a currently created singleton (resolving a circular reference).\n * @param beanName the name of the bean to look for\n * @param allowEarlyReference whether early references should be created or not\n * @return the registered singleton object, or {@code null} if none found\n */\n@Nullable\nprotected Object getSingleton(String beanName, boolean allowEarlyReference) {\n    // Quick check for existing instance without full singleton lock\n    Object singletonObject = this.singletonObjects.get(beanName);\n    if (singletonObject == null &amp;&amp; isSingletonCurrentlyInCreation(beanName)) {\n        singletonObject = this.earlySingletonObjects.get(beanName);\n        if (singletonObject == null &amp;&amp; allowEarlyReference) {\n            synchronized (this.singletonObjects) {\n                // Consistent creation of early reference within full singleton lock\n                singletonObject = this.singletonObjects.get(beanName);\n                if (singletonObject == null) {\n                    singletonObject = this.earlySingletonObjects.get(beanName);\n                    if (singletonObject == null) {\n                        ObjectFactory&lt;?&gt; singletonFactory = this.singletonFactories.get(beanName);\n                        if (singletonFactory != null) {\n                            singletonObject = singletonFactory.getObject();\n                            this.earlySingletonObjects.put(beanName, singletonObject);\n                            this.singletonFactories.remove(beanName);\n                        }\n                    }\n                }\n            }\n        }\n    }\n    return singletonObject;\n}\n</code></pre>\n<ul>\n<li><code>singletonObjects.get(beanName)</code>，从<code>singletonObjects</code>获取实例，<code>singletonObjects</code>是成品bean</li>\n<li><code>isSingletonCurrentlyInCreation</code>，判断beanName，<code>isSingletonCurrentlyInCreation</code> 对应的bean是否正在创建中</li>\n<li><code>allowEarlyReference</code>，从<code>earlySingletonObjects</code>中获取提前曝光未成品的bean</li>\n<li><code>singletonFactory.getObject()</code>，提前曝光bean实例，主要用于解决AOP循环依赖</li>\n</ul>\n<h3 id=\"只有一级缓存为什么不行？\"><a href=\"#只有一级缓存为什么不行？\" class=\"headerlink\" title=\"只有一级缓存为什么不行？\"></a>只有一级缓存为什么不行？</h3><p>一级缓存是存放bean的半成品。但是如果创建A的时候需要B，创建B的时候需要A，而A却还没有创建完成，会出现死循环。</p>\n<h3 id=\"二级缓存能解决问题吗？\"><a href=\"#二级缓存能解决问题吗？\" class=\"headerlink\" title=\"二级缓存能解决问题吗？\"></a>二级缓存能解决问题吗？</h3><p>一级缓存存放bean的成品，二级缓存存放bean的半成品。A在创建半成品对象后存放到缓存中，接下来补充A对象中依赖的B的属性。B继续创建，创建的半成品同样存放到缓存中，在补充对象的A属性的时候，可以从半成品缓存中获取A的半成品，那么现在B就是一个完成的对象了，而接下来递归操作后，A也是一个完整的对象了。</p>\n<h3 id=\"三级缓存解决了什么问题？\"><a href=\"#三级缓存解决了什么问题？\" class=\"headerlink\" title=\"三级缓存解决了什么问题？\"></a>三级缓存解决了什么问题？</h3><p>一级缓存是成品，二级缓存是半成品，三级缓存是工厂对象。二级缓存已经可以解决Spring的依赖了。三级缓存是为了解决Spring AOP的特性，AOP本身就是对方法的增强，是<code>ObjectFactory&lt;?&gt;</code>类型的lambda表达式，而Spring的原则又不希望将此类类型的Bean前置创建，所以要放到三级缓存中处理。其实整体处理过程类似，唯独是B在填充属性A时，先查询成品缓存、在查询半成品缓存，最后再看看有没有单例工程类在三级缓存中。最终获取到以后调用getObject方法返回代理引用或者原始引用。</p>\n","site":{"data":{}},"more":"<h2 id=\"什么是循环依赖\"><a href=\"#什么是循环依赖\" class=\"headerlink\" title=\"什么是循环依赖\"></a>什么是循环依赖</h2><p>循环依赖分为三种，自身依赖于自身、互相循环依赖、多组循环依赖。但无论循环依赖的数量有多少，循环依赖的本质是一样的。就是你的完整创建依赖于我，而我的完整创建也依赖于你，但我们互相没法解耦，最终导致依赖创建失败。所以 Spring 提供了除了构造函数注入和原型注入外的，setter循环依赖注入解决方案。</p>\n<pre><code class=\"java\">\npublic class ABTest {\n\n    public static void main(String[] args) {\n        new ClazzA();\n    }\n\n}\n\nclass ClazzA {\n\n    private ClazzB b = new ClazzB();\n\n}\n\nclass ClazzB {\n\n    private ClazzA a = new ClazzA();\n\n}\n</code></pre>\n<p>这段代码就是循环依赖最初的模样，你中有我，我中有你，运行就报错<code>java.lang.StackOverflowError</code>。</p>\n<h4 id=\"解决办法\"><a href=\"#解决办法\" class=\"headerlink\" title=\"解决办法\"></a>解决办法</h4><pre><code class=\"java\">\npublic class CircleTest {\n\n    private final static Map&lt;String, Object&gt; singletonObjects = new ConcurrentHashMap&lt;&gt;(256);\n\n    public static void main(String[] args) throws Exception {\n        System.out.println(getBean(B.class).getA());\n        System.out.println(getBean(A.class).getB());\n    }\n\n    private static &lt;T&gt; T getBean(Class&lt;T&gt; beanClass) throws Exception {\n        String beanName = beanClass.getSimpleName().toLowerCase();\n        if (singletonObjects.containsKey(beanName)) {\n            return (T) singletonObjects.get(beanName);\n        }\n        // 实例化对象入缓存\n        Object obj = beanClass.newInstance();\n        singletonObjects.put(beanName, obj);\n        // 属性填充补全对象\n        Field[] fields = obj.getClass().getDeclaredFields();\n        for (Field field : fields) {\n            field.setAccessible(true);\n            Class&lt;?&gt; fieldClass = field.getType();\n            String fieldBeanName = fieldClass.getSimpleName().toLowerCase();\n            field.set(obj, singletonObjects.containsKey(fieldBeanName) ? singletonObjects.get(fieldBeanName) : getBean(fieldClass));\n            field.setAccessible(false);\n        }\n        return (T) obj;\n    }\n\n}\n\nclass A {\n\n    private B b;\n\n    // ...get/set\n}\n\nclass B {\n    private A a;\n\n    // ...get/set\n}</code></pre>\n<p>这里的解决方案就是将半成品对象，存放在缓存<code>singletonObjects</code>中，当B依赖A的时候能先使用半成品A来完成B的创建。</p>\n<h2 id=\"Spring的三级缓存\"><a href=\"#Spring的三级缓存\" class=\"headerlink\" title=\"Spring的三级缓存\"></a>Spring的三级缓存</h2><pre><code class=\"java\">\n/**\n * Return the (raw) singleton object registered under the given name.\n * &lt;p&gt;Checks already instantiated singletons and also allows for an early\n * reference to a currently created singleton (resolving a circular reference).\n * @param beanName the name of the bean to look for\n * @param allowEarlyReference whether early references should be created or not\n * @return the registered singleton object, or {@code null} if none found\n */\n@Nullable\nprotected Object getSingleton(String beanName, boolean allowEarlyReference) {\n    // Quick check for existing instance without full singleton lock\n    Object singletonObject = this.singletonObjects.get(beanName);\n    if (singletonObject == null &amp;&amp; isSingletonCurrentlyInCreation(beanName)) {\n        singletonObject = this.earlySingletonObjects.get(beanName);\n        if (singletonObject == null &amp;&amp; allowEarlyReference) {\n            synchronized (this.singletonObjects) {\n                // Consistent creation of early reference within full singleton lock\n                singletonObject = this.singletonObjects.get(beanName);\n                if (singletonObject == null) {\n                    singletonObject = this.earlySingletonObjects.get(beanName);\n                    if (singletonObject == null) {\n                        ObjectFactory&lt;?&gt; singletonFactory = this.singletonFactories.get(beanName);\n                        if (singletonFactory != null) {\n                            singletonObject = singletonFactory.getObject();\n                            this.earlySingletonObjects.put(beanName, singletonObject);\n                            this.singletonFactories.remove(beanName);\n                        }\n                    }\n                }\n            }\n        }\n    }\n    return singletonObject;\n}\n</code></pre>\n<ul>\n<li><code>singletonObjects.get(beanName)</code>，从<code>singletonObjects</code>获取实例，<code>singletonObjects</code>是成品bean</li>\n<li><code>isSingletonCurrentlyInCreation</code>，判断beanName，<code>isSingletonCurrentlyInCreation</code> 对应的bean是否正在创建中</li>\n<li><code>allowEarlyReference</code>，从<code>earlySingletonObjects</code>中获取提前曝光未成品的bean</li>\n<li><code>singletonFactory.getObject()</code>，提前曝光bean实例，主要用于解决AOP循环依赖</li>\n</ul>\n<h3 id=\"只有一级缓存为什么不行？\"><a href=\"#只有一级缓存为什么不行？\" class=\"headerlink\" title=\"只有一级缓存为什么不行？\"></a>只有一级缓存为什么不行？</h3><p>一级缓存是存放bean的半成品。但是如果创建A的时候需要B，创建B的时候需要A，而A却还没有创建完成，会出现死循环。</p>\n<h3 id=\"二级缓存能解决问题吗？\"><a href=\"#二级缓存能解决问题吗？\" class=\"headerlink\" title=\"二级缓存能解决问题吗？\"></a>二级缓存能解决问题吗？</h3><p>一级缓存存放bean的成品，二级缓存存放bean的半成品。A在创建半成品对象后存放到缓存中，接下来补充A对象中依赖的B的属性。B继续创建，创建的半成品同样存放到缓存中，在补充对象的A属性的时候，可以从半成品缓存中获取A的半成品，那么现在B就是一个完成的对象了，而接下来递归操作后，A也是一个完整的对象了。</p>\n<h3 id=\"三级缓存解决了什么问题？\"><a href=\"#三级缓存解决了什么问题？\" class=\"headerlink\" title=\"三级缓存解决了什么问题？\"></a>三级缓存解决了什么问题？</h3><p>一级缓存是成品，二级缓存是半成品，三级缓存是工厂对象。二级缓存已经可以解决Spring的依赖了。三级缓存是为了解决Spring AOP的特性，AOP本身就是对方法的增强，是<code>ObjectFactory&lt;?&gt;</code>类型的lambda表达式，而Spring的原则又不希望将此类类型的Bean前置创建，所以要放到三级缓存中处理。其实整体处理过程类似，唯独是B在填充属性A时，先查询成品缓存、在查询半成品缓存，最后再看看有没有单例工程类在三级缓存中。最终获取到以后调用getObject方法返回代理引用或者原始引用。</p>\n"},{"title":"记一次频繁FullGC问题解决","excerpt":"","comments":1,"date":"2021-11-26T08:30:10.000Z","_content":"\n\n今天由于一个同事出差和上海一个病例同坐了一列高铁，我们又开始了全员核酸和流调，不过还好，有了上次的经验，公司安排的很明白，效率比上次高了很多，核酸开始比上次晚，却比上次早结束，十点多就解禁了。\n\n下午五点多，告警群突然一阵急促的告警，显示mq超时，然后是一堆业务接口超时，最后服务都自动重启了。好在探活机制重启了服务，业务影响比较小。\n\n看了一眼大禹（我们的监控平台），Full GC频繁，并且每次GC仅仅释放少量内存，而且停顿时间最长已经到了2-3s，非常恐怖。我们看了一下超时的mq消息，是埋点相关的。我由埋点数据比较大，而且不知为何这里埋点用的是同步消息，联想到可能是用户操作产生的埋点信息产生大量的大对象，直接进入了老年代，而且因为超时的同步消息，这些对象都有引用不能回收，导致老年代被占满，大禹的探活接口超时，重启了服务。\n\n当然以上都是我根据自己的认知的猜测，也没能继续追溯，因为服务重启，pod已经销毁，没能dump当时的内存来分析。\n\n吃完晚饭，做完核酸，组长回来了，于是请大佬帮忙分析一下。大佬只一个`jmap -histo:live ${pid} | grep ${我们的业务标识}`。也就是看看现在存活的业务对象，然后一眼发现权限对象存在超多示例，实例数冠绝全场。然后让我们打开项目，看了下权限相关的代码，发现TMD权限根本就没存在redis……每次客户端来鉴权，都会查数据库，然后生成一个崭新的权限数据对象……\n\nSpring Session是通过来管理session的，将session保存再redis，而Spring Session的是重写了HttpServletRequest的getSession方法。由于Spring Session没有引用进来，导致这块并没能调用`SessionRepositoryRequestWrapper`的getSession方法，我们有多个实例，只要相邻的两次请求没能落到同一个实例上，也就是每一个请求过来，getSession都无法根据id找到session，也就每次都会鉴权然后build一个新的session……所以随着时间的推移，堆中的session相关的对象越来越多……\n\n修复后Full GC次数明显减少，并且保持在一个合理的值。","source":"_posts/2021-11-26-kongzheng1993-记一次频繁FullGC解决.md","raw":"---\ntitle: 记一次频繁FullGC问题解决\nexcerpt: 'Spring'\ntags: [Spring]\ncategories: [Spring]\ncomments: true\ndate: 2021-11-26 16:30:10\n---\n\n\n今天由于一个同事出差和上海一个病例同坐了一列高铁，我们又开始了全员核酸和流调，不过还好，有了上次的经验，公司安排的很明白，效率比上次高了很多，核酸开始比上次晚，却比上次早结束，十点多就解禁了。\n\n下午五点多，告警群突然一阵急促的告警，显示mq超时，然后是一堆业务接口超时，最后服务都自动重启了。好在探活机制重启了服务，业务影响比较小。\n\n看了一眼大禹（我们的监控平台），Full GC频繁，并且每次GC仅仅释放少量内存，而且停顿时间最长已经到了2-3s，非常恐怖。我们看了一下超时的mq消息，是埋点相关的。我由埋点数据比较大，而且不知为何这里埋点用的是同步消息，联想到可能是用户操作产生的埋点信息产生大量的大对象，直接进入了老年代，而且因为超时的同步消息，这些对象都有引用不能回收，导致老年代被占满，大禹的探活接口超时，重启了服务。\n\n当然以上都是我根据自己的认知的猜测，也没能继续追溯，因为服务重启，pod已经销毁，没能dump当时的内存来分析。\n\n吃完晚饭，做完核酸，组长回来了，于是请大佬帮忙分析一下。大佬只一个`jmap -histo:live ${pid} | grep ${我们的业务标识}`。也就是看看现在存活的业务对象，然后一眼发现权限对象存在超多示例，实例数冠绝全场。然后让我们打开项目，看了下权限相关的代码，发现TMD权限根本就没存在redis……每次客户端来鉴权，都会查数据库，然后生成一个崭新的权限数据对象……\n\nSpring Session是通过来管理session的，将session保存再redis，而Spring Session的是重写了HttpServletRequest的getSession方法。由于Spring Session没有引用进来，导致这块并没能调用`SessionRepositoryRequestWrapper`的getSession方法，我们有多个实例，只要相邻的两次请求没能落到同一个实例上，也就是每一个请求过来，getSession都无法根据id找到session，也就每次都会鉴权然后build一个新的session……所以随着时间的推移，堆中的session相关的对象越来越多……\n\n修复后Full GC次数明显减少，并且保持在一个合理的值。","slug":"kongzheng1993-记一次频繁FullGC解决","published":1,"updated":"2023-03-08T07:05:58.815Z","layout":"post","photos":[],"link":"","_id":"clg0k2am2007ot26fyzcfe5ry","content":"<p>今天由于一个同事出差和上海一个病例同坐了一列高铁，我们又开始了全员核酸和流调，不过还好，有了上次的经验，公司安排的很明白，效率比上次高了很多，核酸开始比上次晚，却比上次早结束，十点多就解禁了。</p>\n<p>下午五点多，告警群突然一阵急促的告警，显示mq超时，然后是一堆业务接口超时，最后服务都自动重启了。好在探活机制重启了服务，业务影响比较小。</p>\n<p>看了一眼大禹（我们的监控平台），Full GC频繁，并且每次GC仅仅释放少量内存，而且停顿时间最长已经到了2-3s，非常恐怖。我们看了一下超时的mq消息，是埋点相关的。我由埋点数据比较大，而且不知为何这里埋点用的是同步消息，联想到可能是用户操作产生的埋点信息产生大量的大对象，直接进入了老年代，而且因为超时的同步消息，这些对象都有引用不能回收，导致老年代被占满，大禹的探活接口超时，重启了服务。</p>\n<p>当然以上都是我根据自己的认知的猜测，也没能继续追溯，因为服务重启，pod已经销毁，没能dump当时的内存来分析。</p>\n<p>吃完晚饭，做完核酸，组长回来了，于是请大佬帮忙分析一下。大佬只一个<code>jmap -histo:live ${pid} | grep ${我们的业务标识}</code>。也就是看看现在存活的业务对象，然后一眼发现权限对象存在超多示例，实例数冠绝全场。然后让我们打开项目，看了下权限相关的代码，发现TMD权限根本就没存在redis……每次客户端来鉴权，都会查数据库，然后生成一个崭新的权限数据对象……</p>\n<p>Spring Session是通过来管理session的，将session保存再redis，而Spring Session的是重写了HttpServletRequest的getSession方法。由于Spring Session没有引用进来，导致这块并没能调用<code>SessionRepositoryRequestWrapper</code>的getSession方法，我们有多个实例，只要相邻的两次请求没能落到同一个实例上，也就是每一个请求过来，getSession都无法根据id找到session，也就每次都会鉴权然后build一个新的session……所以随着时间的推移，堆中的session相关的对象越来越多……</p>\n<p>修复后Full GC次数明显减少，并且保持在一个合理的值。</p>\n","site":{"data":{}},"more":"<p>今天由于一个同事出差和上海一个病例同坐了一列高铁，我们又开始了全员核酸和流调，不过还好，有了上次的经验，公司安排的很明白，效率比上次高了很多，核酸开始比上次晚，却比上次早结束，十点多就解禁了。</p>\n<p>下午五点多，告警群突然一阵急促的告警，显示mq超时，然后是一堆业务接口超时，最后服务都自动重启了。好在探活机制重启了服务，业务影响比较小。</p>\n<p>看了一眼大禹（我们的监控平台），Full GC频繁，并且每次GC仅仅释放少量内存，而且停顿时间最长已经到了2-3s，非常恐怖。我们看了一下超时的mq消息，是埋点相关的。我由埋点数据比较大，而且不知为何这里埋点用的是同步消息，联想到可能是用户操作产生的埋点信息产生大量的大对象，直接进入了老年代，而且因为超时的同步消息，这些对象都有引用不能回收，导致老年代被占满，大禹的探活接口超时，重启了服务。</p>\n<p>当然以上都是我根据自己的认知的猜测，也没能继续追溯，因为服务重启，pod已经销毁，没能dump当时的内存来分析。</p>\n<p>吃完晚饭，做完核酸，组长回来了，于是请大佬帮忙分析一下。大佬只一个<code>jmap -histo:live ${pid} | grep ${我们的业务标识}</code>。也就是看看现在存活的业务对象，然后一眼发现权限对象存在超多示例，实例数冠绝全场。然后让我们打开项目，看了下权限相关的代码，发现TMD权限根本就没存在redis……每次客户端来鉴权，都会查数据库，然后生成一个崭新的权限数据对象……</p>\n<p>Spring Session是通过来管理session的，将session保存再redis，而Spring Session的是重写了HttpServletRequest的getSession方法。由于Spring Session没有引用进来，导致这块并没能调用<code>SessionRepositoryRequestWrapper</code>的getSession方法，我们有多个实例，只要相邻的两次请求没能落到同一个实例上，也就是每一个请求过来，getSession都无法根据id找到session，也就每次都会鉴权然后build一个新的session……所以随着时间的推移，堆中的session相关的对象越来越多……</p>\n<p>修复后Full GC次数明显减少，并且保持在一个合理的值。</p>\n"},{"title":"BigDecimal用法","excerpt":"","comments":1,"date":"2021-11-26T08:30:10.000Z","_content":"\nhttps://www.cnblogs.com/ljk-shm-0208/p/13821161.html\n\n\n\nhttps://www.liaoxuefeng.com/wiki/1252599548343744/1279768011997217","source":"_posts/2021-11-29-kongzheng1993-BigDecimal.md","raw":"---\ntitle: BigDecimal用法\nexcerpt: 'Java'\ntags: [Java]\ncategories: [Java]\ncomments: true\ndate: 2021-11-26 16:30:10\n---\n\nhttps://www.cnblogs.com/ljk-shm-0208/p/13821161.html\n\n\n\nhttps://www.liaoxuefeng.com/wiki/1252599548343744/1279768011997217","slug":"kongzheng1993-BigDecimal","published":1,"updated":"2023-03-08T07:05:58.815Z","layout":"post","photos":[],"link":"","_id":"clg0k2am3007rt26fa515kbuo","content":"<p><a href=\"https://www.cnblogs.com/ljk-shm-0208/p/13821161.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/ljk-shm-0208/p/13821161.html</a></p>\n<p><a href=\"https://www.liaoxuefeng.com/wiki/1252599548343744/1279768011997217\" target=\"_blank\" rel=\"noopener\">https://www.liaoxuefeng.com/wiki/1252599548343744/1279768011997217</a></p>\n","site":{"data":{}},"more":"<p><a href=\"https://www.cnblogs.com/ljk-shm-0208/p/13821161.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/ljk-shm-0208/p/13821161.html</a></p>\n<p><a href=\"https://www.liaoxuefeng.com/wiki/1252599548343744/1279768011997217\" target=\"_blank\" rel=\"noopener\">https://www.liaoxuefeng.com/wiki/1252599548343744/1279768011997217</a></p>\n"},{"title":"hs_err_pid_pdi.log分析","excerpt":"","comments":1,"date":"2021-11-29T08:30:10.000Z","_content":"\n\n<img src=\"飞书20211129-112140.png\">\n\n<img src=\"飞书20211129-112155.png\">\n\n\n\nhttps://bugs.java.com/bugdatabase/view_bug.do?bug_id=8004124","source":"_posts/2021-11-29-kongzheng1993-hs_err_pid_pid_log.md","raw":"---\ntitle: hs_err_pid_pdi.log分析\nexcerpt: 'Spring'\ntags: [Spring]\ncategories: [Spring]\ncomments: true\ndate: 2021-11-29 16:30:10\n---\n\n\n<img src=\"飞书20211129-112140.png\">\n\n<img src=\"飞书20211129-112155.png\">\n\n\n\nhttps://bugs.java.com/bugdatabase/view_bug.do?bug_id=8004124","slug":"kongzheng1993-hs_err_pid_pid_log","published":1,"updated":"2023-03-08T07:05:58.815Z","layout":"post","photos":[],"link":"","_id":"clg0k2am3007ut26f3d1n3ng1","content":"<img src=\"/2021/11/29/kongzheng1993-hs_err_pid_pid_log/飞书20211129-112140.png\">\n\n<img src=\"/2021/11/29/kongzheng1993-hs_err_pid_pid_log/飞书20211129-112155.png\">\n\n\n\n<p><a href=\"https://bugs.java.com/bugdatabase/view_bug.do?bug_id=8004124\" target=\"_blank\" rel=\"noopener\">https://bugs.java.com/bugdatabase/view_bug.do?bug_id=8004124</a></p>\n","site":{"data":{}},"more":"<img src=\"/2021/11/29/kongzheng1993-hs_err_pid_pid_log/飞书20211129-112140.png\">\n\n<img src=\"/2021/11/29/kongzheng1993-hs_err_pid_pid_log/飞书20211129-112155.png\">\n\n\n\n<p><a href=\"https://bugs.java.com/bugdatabase/view_bug.do?bug_id=8004124\" target=\"_blank\" rel=\"noopener\">https://bugs.java.com/bugdatabase/view_bug.do?bug_id=8004124</a></p>\n"},{"title":"Spring Session","excerpt":"","comments":1,"date":"2021-11-26T08:30:10.000Z","_content":"\nhttps://zhuanlan.zhihu.com/p/85543763\n\nhttps://zhuanlan.zhihu.com/p/246344640\n\n\n\n","source":"_posts/2021-11-29-kongzheng1993-spring_session.md","raw":"---\ntitle: Spring Session\nexcerpt: 'Spring'\ntags: [Spring]\ncategories: [Spring]\ncomments: true\ndate: 2021-11-26 16:30:10\n---\n\nhttps://zhuanlan.zhihu.com/p/85543763\n\nhttps://zhuanlan.zhihu.com/p/246344640\n\n\n\n","slug":"kongzheng1993-spring_session","published":1,"updated":"2023-03-08T07:05:58.819Z","layout":"post","photos":[],"link":"","_id":"clg0k2am3007xt26f3jwg1hed","content":"<p><a href=\"https://zhuanlan.zhihu.com/p/85543763\" target=\"_blank\" rel=\"noopener\">https://zhuanlan.zhihu.com/p/85543763</a></p>\n<p><a href=\"https://zhuanlan.zhihu.com/p/246344640\" target=\"_blank\" rel=\"noopener\">https://zhuanlan.zhihu.com/p/246344640</a></p>\n","site":{"data":{}},"more":"<p><a href=\"https://zhuanlan.zhihu.com/p/85543763\" target=\"_blank\" rel=\"noopener\">https://zhuanlan.zhihu.com/p/85543763</a></p>\n<p><a href=\"https://zhuanlan.zhihu.com/p/246344640\" target=\"_blank\" rel=\"noopener\">https://zhuanlan.zhihu.com/p/246344640</a></p>\n"},{"title":"maven-resource-plugin","excerpt":"","comments":1,"date":"2021-11-26T08:30:10.000Z","_content":"\n每次上线后，总会用户过来问，怎么没有生效，新功能不好使等问题。大概率都是因为浏览器缓存造成的。这些静态文件一般都在maven项目的resource目录下。\n\n浏览器的缓存是通过url来的。如果url变了，浏览器就会认为要请求的不是一个资源，就会重新发起请求获取资源。\n\n所以如果我们在修改静态文件后，统一给这些文件修改名称，到时候浏览器就会重新获取拿到新文件了。\n\nspring resource支持给资源名增加后缀：\n1. 资源名-md5方式：此时会将请求增加后缀（-资源名的md5）\n```ini\nspring.resources.chain.strategy.content.enabled=true\nspring.resources.chain.strategy.content.paths=/**\n ```\n2. 资源名-版本号：会在请求后增加后缀（-版本号）\n```ini\nspring.resources.chain.strategy.fixed.enabled=true\nspring.resources.chain.strategy.fixed.paths=/**\nspring.resources.chain.strategy.fixed.version=v1.0.0\n```\n\n第一种方法不需要每次修改配置，每次都是崭新的md5，但是需要记住老的md5，以便判断是否加载了最新的资源。第二种需要每次修改版本号，好处是，一眼就能看出是否是新版本的资源。\n\n第二种方式我们可以使用`@project.version@`变量直接使用maven项目的版本号，这样就不需要再来bootstrap配置文件修改resource的版本号了。\n\n因为在Spring MVC中，资源的查找、处理使用的是责任链设计模式（Filter Chain）。\n\n<img src=\"20161012101735543.png\"/>\n\n而springboot的相关配置就是spring.resources.chain。\n\n\n以上配置之后，所有的resource的请求都会加后缀，浏览器会重新获取静态资源，解决了发版后静态资源缓存的问题。但是这样会影响一些二进制文件，比如我们导入功能的excel模版文件，tff字体，pdf模版等等。因为maven-resources-plugin在打包resources时，会对文件进行统一编码，导致二进制文件损坏。\n\n下面的配置就可以排除一些文件，以免被重新编码导致不可用。\n\n```yml\n\n<build>\n    <plugins>\n        <plugin>\n            <groupId>org.apache.maven.plugins</groupId>\n            <artifactId>maven-resources-plugin</artifactId>\n            <version>3.1.0</version>\n            <configuration>\n                <encoding>UTF-8</encoding>\n                <nonFilteredFileExtensions>\n                    <nonFilteredFileExtension>xlsx</nonFilteredFileExtension>\n                    <nonFilteredFileExtension>xls</nonFilteredFileExtension>\n                    <nonFilteredFileExtension>svg</nonFilteredFileExtension>\n                    <nonFilteredFileExtension>tff</nonFilteredFileExtension>\n                    <nonFilteredFileExtension>pdf</nonFilteredFileExtension>\n                    <nonFilteredFileExtension>wsf</nonFilteredFileExtension>\n                    <nonFilteredFileExtension>jpg</nonFilteredFileExtension>\n                    <nonFilteredFileExtension>jpeg</nonFilteredFileExtension>\n                    <nonFilteredFileExtension>gif</nonFilteredFileExtension>\n                    <nonFilteredFileExtension>bmp</nonFilteredFileExtension>\n                    <nonFilteredFileExtension>png</nonFilteredFileExtension>\n                </nonFilteredFileExtensions>\n            </configuration>\n        </plugin>\n    </plugins>\n    <resources>\n        <resource>\n            <directory>src/main/resources</directory>\n            <filtering>true</filtering>\n        </resource>\n    </resources>\n</build>\n\n```\n\n[Maven官网资料]https://maven.apache.org/plugins/maven-resources-plugin/examples/include-exclude.html","source":"_posts/2021-11-29-kongzheng1993-maven_resource_plugin.md","raw":"---\ntitle: maven-resource-plugin\nexcerpt: 'Maven'\ntags: [Maven]\ncategories: [Maven]\ncomments: true\ndate: 2021-11-26 16:30:10\n---\n\n每次上线后，总会用户过来问，怎么没有生效，新功能不好使等问题。大概率都是因为浏览器缓存造成的。这些静态文件一般都在maven项目的resource目录下。\n\n浏览器的缓存是通过url来的。如果url变了，浏览器就会认为要请求的不是一个资源，就会重新发起请求获取资源。\n\n所以如果我们在修改静态文件后，统一给这些文件修改名称，到时候浏览器就会重新获取拿到新文件了。\n\nspring resource支持给资源名增加后缀：\n1. 资源名-md5方式：此时会将请求增加后缀（-资源名的md5）\n```ini\nspring.resources.chain.strategy.content.enabled=true\nspring.resources.chain.strategy.content.paths=/**\n ```\n2. 资源名-版本号：会在请求后增加后缀（-版本号）\n```ini\nspring.resources.chain.strategy.fixed.enabled=true\nspring.resources.chain.strategy.fixed.paths=/**\nspring.resources.chain.strategy.fixed.version=v1.0.0\n```\n\n第一种方法不需要每次修改配置，每次都是崭新的md5，但是需要记住老的md5，以便判断是否加载了最新的资源。第二种需要每次修改版本号，好处是，一眼就能看出是否是新版本的资源。\n\n第二种方式我们可以使用`@project.version@`变量直接使用maven项目的版本号，这样就不需要再来bootstrap配置文件修改resource的版本号了。\n\n因为在Spring MVC中，资源的查找、处理使用的是责任链设计模式（Filter Chain）。\n\n<img src=\"20161012101735543.png\"/>\n\n而springboot的相关配置就是spring.resources.chain。\n\n\n以上配置之后，所有的resource的请求都会加后缀，浏览器会重新获取静态资源，解决了发版后静态资源缓存的问题。但是这样会影响一些二进制文件，比如我们导入功能的excel模版文件，tff字体，pdf模版等等。因为maven-resources-plugin在打包resources时，会对文件进行统一编码，导致二进制文件损坏。\n\n下面的配置就可以排除一些文件，以免被重新编码导致不可用。\n\n```yml\n\n<build>\n    <plugins>\n        <plugin>\n            <groupId>org.apache.maven.plugins</groupId>\n            <artifactId>maven-resources-plugin</artifactId>\n            <version>3.1.0</version>\n            <configuration>\n                <encoding>UTF-8</encoding>\n                <nonFilteredFileExtensions>\n                    <nonFilteredFileExtension>xlsx</nonFilteredFileExtension>\n                    <nonFilteredFileExtension>xls</nonFilteredFileExtension>\n                    <nonFilteredFileExtension>svg</nonFilteredFileExtension>\n                    <nonFilteredFileExtension>tff</nonFilteredFileExtension>\n                    <nonFilteredFileExtension>pdf</nonFilteredFileExtension>\n                    <nonFilteredFileExtension>wsf</nonFilteredFileExtension>\n                    <nonFilteredFileExtension>jpg</nonFilteredFileExtension>\n                    <nonFilteredFileExtension>jpeg</nonFilteredFileExtension>\n                    <nonFilteredFileExtension>gif</nonFilteredFileExtension>\n                    <nonFilteredFileExtension>bmp</nonFilteredFileExtension>\n                    <nonFilteredFileExtension>png</nonFilteredFileExtension>\n                </nonFilteredFileExtensions>\n            </configuration>\n        </plugin>\n    </plugins>\n    <resources>\n        <resource>\n            <directory>src/main/resources</directory>\n            <filtering>true</filtering>\n        </resource>\n    </resources>\n</build>\n\n```\n\n[Maven官网资料]https://maven.apache.org/plugins/maven-resources-plugin/examples/include-exclude.html","slug":"kongzheng1993-maven_resource_plugin","published":1,"updated":"2023-03-08T07:05:58.818Z","layout":"post","photos":[],"link":"","_id":"clg0k2am4007zt26f300uvrkj","content":"<p>每次上线后，总会用户过来问，怎么没有生效，新功能不好使等问题。大概率都是因为浏览器缓存造成的。这些静态文件一般都在maven项目的resource目录下。</p>\n<p>浏览器的缓存是通过url来的。如果url变了，浏览器就会认为要请求的不是一个资源，就会重新发起请求获取资源。</p>\n<p>所以如果我们在修改静态文件后，统一给这些文件修改名称，到时候浏览器就会重新获取拿到新文件了。</p>\n<p>spring resource支持给资源名增加后缀：</p>\n<ol>\n<li>资源名-md5方式：此时会将请求增加后缀（-资源名的md5）<pre><code class=\"ini\">spring.resources.chain.strategy.content.enabled=true\nspring.resources.chain.strategy.content.paths=/**</code></pre>\n</li>\n<li>资源名-版本号：会在请求后增加后缀（-版本号）<pre><code class=\"ini\">spring.resources.chain.strategy.fixed.enabled=true\nspring.resources.chain.strategy.fixed.paths=/**\nspring.resources.chain.strategy.fixed.version=v1.0.0</code></pre>\n</li>\n</ol>\n<p>第一种方法不需要每次修改配置，每次都是崭新的md5，但是需要记住老的md5，以便判断是否加载了最新的资源。第二种需要每次修改版本号，好处是，一眼就能看出是否是新版本的资源。</p>\n<p>第二种方式我们可以使用<code>@project.version@</code>变量直接使用maven项目的版本号，这样就不需要再来bootstrap配置文件修改resource的版本号了。</p>\n<p>因为在Spring MVC中，资源的查找、处理使用的是责任链设计模式（Filter Chain）。</p>\n<img src=\"/2021/11/26/kongzheng1993-maven_resource_plugin/20161012101735543.png\">\n\n<p>而springboot的相关配置就是spring.resources.chain。</p>\n<p>以上配置之后，所有的resource的请求都会加后缀，浏览器会重新获取静态资源，解决了发版后静态资源缓存的问题。但是这样会影响一些二进制文件，比如我们导入功能的excel模版文件，tff字体，pdf模版等等。因为maven-resources-plugin在打包resources时，会对文件进行统一编码，导致二进制文件损坏。</p>\n<p>下面的配置就可以排除一些文件，以免被重新编码导致不可用。</p>\n<pre><code class=\"yml\">\n&lt;build&gt;\n    &lt;plugins&gt;\n        &lt;plugin&gt;\n            &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;\n            &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt;\n            &lt;version&gt;3.1.0&lt;/version&gt;\n            &lt;configuration&gt;\n                &lt;encoding&gt;UTF-8&lt;/encoding&gt;\n                &lt;nonFilteredFileExtensions&gt;\n                    &lt;nonFilteredFileExtension&gt;xlsx&lt;/nonFilteredFileExtension&gt;\n                    &lt;nonFilteredFileExtension&gt;xls&lt;/nonFilteredFileExtension&gt;\n                    &lt;nonFilteredFileExtension&gt;svg&lt;/nonFilteredFileExtension&gt;\n                    &lt;nonFilteredFileExtension&gt;tff&lt;/nonFilteredFileExtension&gt;\n                    &lt;nonFilteredFileExtension&gt;pdf&lt;/nonFilteredFileExtension&gt;\n                    &lt;nonFilteredFileExtension&gt;wsf&lt;/nonFilteredFileExtension&gt;\n                    &lt;nonFilteredFileExtension&gt;jpg&lt;/nonFilteredFileExtension&gt;\n                    &lt;nonFilteredFileExtension&gt;jpeg&lt;/nonFilteredFileExtension&gt;\n                    &lt;nonFilteredFileExtension&gt;gif&lt;/nonFilteredFileExtension&gt;\n                    &lt;nonFilteredFileExtension&gt;bmp&lt;/nonFilteredFileExtension&gt;\n                    &lt;nonFilteredFileExtension&gt;png&lt;/nonFilteredFileExtension&gt;\n                &lt;/nonFilteredFileExtensions&gt;\n            &lt;/configuration&gt;\n        &lt;/plugin&gt;\n    &lt;/plugins&gt;\n    &lt;resources&gt;\n        &lt;resource&gt;\n            &lt;directory&gt;src/main/resources&lt;/directory&gt;\n            &lt;filtering&gt;true&lt;/filtering&gt;\n        &lt;/resource&gt;\n    &lt;/resources&gt;\n&lt;/build&gt;\n</code></pre>\n<p>[Maven官网资料]<a href=\"https://maven.apache.org/plugins/maven-resources-plugin/examples/include-exclude.html\" target=\"_blank\" rel=\"noopener\">https://maven.apache.org/plugins/maven-resources-plugin/examples/include-exclude.html</a></p>\n","site":{"data":{}},"more":"<p>每次上线后，总会用户过来问，怎么没有生效，新功能不好使等问题。大概率都是因为浏览器缓存造成的。这些静态文件一般都在maven项目的resource目录下。</p>\n<p>浏览器的缓存是通过url来的。如果url变了，浏览器就会认为要请求的不是一个资源，就会重新发起请求获取资源。</p>\n<p>所以如果我们在修改静态文件后，统一给这些文件修改名称，到时候浏览器就会重新获取拿到新文件了。</p>\n<p>spring resource支持给资源名增加后缀：</p>\n<ol>\n<li>资源名-md5方式：此时会将请求增加后缀（-资源名的md5）<pre><code class=\"ini\">spring.resources.chain.strategy.content.enabled=true\nspring.resources.chain.strategy.content.paths=/**</code></pre>\n</li>\n<li>资源名-版本号：会在请求后增加后缀（-版本号）<pre><code class=\"ini\">spring.resources.chain.strategy.fixed.enabled=true\nspring.resources.chain.strategy.fixed.paths=/**\nspring.resources.chain.strategy.fixed.version=v1.0.0</code></pre>\n</li>\n</ol>\n<p>第一种方法不需要每次修改配置，每次都是崭新的md5，但是需要记住老的md5，以便判断是否加载了最新的资源。第二种需要每次修改版本号，好处是，一眼就能看出是否是新版本的资源。</p>\n<p>第二种方式我们可以使用<code>@project.version@</code>变量直接使用maven项目的版本号，这样就不需要再来bootstrap配置文件修改resource的版本号了。</p>\n<p>因为在Spring MVC中，资源的查找、处理使用的是责任链设计模式（Filter Chain）。</p>\n<img src=\"/2021/11/26/kongzheng1993-maven_resource_plugin/20161012101735543.png\">\n\n<p>而springboot的相关配置就是spring.resources.chain。</p>\n<p>以上配置之后，所有的resource的请求都会加后缀，浏览器会重新获取静态资源，解决了发版后静态资源缓存的问题。但是这样会影响一些二进制文件，比如我们导入功能的excel模版文件，tff字体，pdf模版等等。因为maven-resources-plugin在打包resources时，会对文件进行统一编码，导致二进制文件损坏。</p>\n<p>下面的配置就可以排除一些文件，以免被重新编码导致不可用。</p>\n<pre><code class=\"yml\">\n&lt;build&gt;\n    &lt;plugins&gt;\n        &lt;plugin&gt;\n            &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;\n            &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt;\n            &lt;version&gt;3.1.0&lt;/version&gt;\n            &lt;configuration&gt;\n                &lt;encoding&gt;UTF-8&lt;/encoding&gt;\n                &lt;nonFilteredFileExtensions&gt;\n                    &lt;nonFilteredFileExtension&gt;xlsx&lt;/nonFilteredFileExtension&gt;\n                    &lt;nonFilteredFileExtension&gt;xls&lt;/nonFilteredFileExtension&gt;\n                    &lt;nonFilteredFileExtension&gt;svg&lt;/nonFilteredFileExtension&gt;\n                    &lt;nonFilteredFileExtension&gt;tff&lt;/nonFilteredFileExtension&gt;\n                    &lt;nonFilteredFileExtension&gt;pdf&lt;/nonFilteredFileExtension&gt;\n                    &lt;nonFilteredFileExtension&gt;wsf&lt;/nonFilteredFileExtension&gt;\n                    &lt;nonFilteredFileExtension&gt;jpg&lt;/nonFilteredFileExtension&gt;\n                    &lt;nonFilteredFileExtension&gt;jpeg&lt;/nonFilteredFileExtension&gt;\n                    &lt;nonFilteredFileExtension&gt;gif&lt;/nonFilteredFileExtension&gt;\n                    &lt;nonFilteredFileExtension&gt;bmp&lt;/nonFilteredFileExtension&gt;\n                    &lt;nonFilteredFileExtension&gt;png&lt;/nonFilteredFileExtension&gt;\n                &lt;/nonFilteredFileExtensions&gt;\n            &lt;/configuration&gt;\n        &lt;/plugin&gt;\n    &lt;/plugins&gt;\n    &lt;resources&gt;\n        &lt;resource&gt;\n            &lt;directory&gt;src/main/resources&lt;/directory&gt;\n            &lt;filtering&gt;true&lt;/filtering&gt;\n        &lt;/resource&gt;\n    &lt;/resources&gt;\n&lt;/build&gt;\n</code></pre>\n<p>[Maven官网资料]<a href=\"https://maven.apache.org/plugins/maven-resources-plugin/examples/include-exclude.html\" target=\"_blank\" rel=\"noopener\">https://maven.apache.org/plugins/maven-resources-plugin/examples/include-exclude.html</a></p>\n"},{"title":"MySQL性能优化","excerpt":"","comments":1,"date":"2022-01-09T10:30:52.000Z","_content":"\n# MySQL性能优化\n\n## 硬件和操作系统层面的优化\n\n硬件层面影响MySQL运行的因素主要有：CPU、可用内存大小、磁盘读写速度、网络带宽\n\n操作系统层面影响因素主要有：应用文件句柄数、操作系统的网络配置\n\n这部分的优化一般是由运维工程师去完成。在硬件基础资源的优化中，我们重点应该关注的层面是服务本身所承载的体量，然后提出合理的指标要求，避免出现资源浪费的现象。\n\n## 架构设计层面的优化\n\nMySQL是一个磁盘IO访问非常频繁的关系型数据库，在高并发和高性能的场景中，mysql会承受巨大的并发压力，优化的思路如下：\n\n1. 搭建MySQL主从集群，避免单点故障。\n2. 读写分离设计，可以避免读写冲突导致的性能问题；引入分库分表机制，通过分库，降低单个服务器节点的IO压力，通过分表可以降低单表数据量，从而提升SQL查询效率。\n3. 对于热点数据，可以引入Redis、MongoDB等分布式数据库，可以很好的缓解MySQL的压力，同时还能提升数据的检索性能。\n\n## MySQL程序配置优化\n\n对于MySQL程序本身的优化，一般可以通过MySQL配置文件（my.cnf）来进行。比如说MySQL5.7版本默认的最大连接数是151个，binlog日志默认不开启，Bufferpool缓存池默认大小等都可以通过my.cnf来配置。配置的重点在于：作用域分为会话级别和全局范围、是否支持热加载。全局参数的设定对于已经存在的会话是无法生效的，会话参数的设定随着会话的销毁而失效，全局的统一配置建议配置在默认配置文件中，否则重启服务会导致配置失效。\n\n## SQL执行优化\n\nSQL优化可以分为三个步骤：\n\n1. 慢SQL的定位和排查。通过慢查询日志和慢查询日志分析工具得到有问题的SQL列表。\n2. 执行计划分析。针对慢SQL使用explain来查看当前SQL的执行计划，可以重点关注type、key、rows、filtered等字段从去定位该SQL执行慢的根本原因，再去有的放矢的进行优化。\n3. 使用show profile（MySQL提供的用于查看SQL语句执行中查看SQL语句资源消耗情况的工具）。默认情况下show profile是关闭的。打开之后会保存最近15次的运行结果。针对运行慢的SQL通过此工具进行详细分析可以得到SQL执行过程中所有资源的开销情况，比如IO、CPU、内存等。\n\n## 常见SQL优化的规则\n\n1. SQL的查询一定要基于索引来进行数据扫描\n2. 避免索引列上使用函数或者运算符\n3. where子句中like %进行放置在右侧，最左原则\n4. 使用索引扫描，联合索引中的列从左往右，命中越多越好\n5. 尽可能使用SQL语句中用到的索引完成排序\n6. 查询有效的列信息即可，少用*代替\n7. 永远用小的结果集驱动大结果集","source":"_posts/2022-01-09-kongzheng1993-MySQL性能优化.md","raw":"---\ntitle: MySQL性能优化\nexcerpt: 'mysql'\ntags: [mysql]\ncategories: [mysql]\ncomments: true\ndate: 2022-01-09 18:30:52\n---\n\n# MySQL性能优化\n\n## 硬件和操作系统层面的优化\n\n硬件层面影响MySQL运行的因素主要有：CPU、可用内存大小、磁盘读写速度、网络带宽\n\n操作系统层面影响因素主要有：应用文件句柄数、操作系统的网络配置\n\n这部分的优化一般是由运维工程师去完成。在硬件基础资源的优化中，我们重点应该关注的层面是服务本身所承载的体量，然后提出合理的指标要求，避免出现资源浪费的现象。\n\n## 架构设计层面的优化\n\nMySQL是一个磁盘IO访问非常频繁的关系型数据库，在高并发和高性能的场景中，mysql会承受巨大的并发压力，优化的思路如下：\n\n1. 搭建MySQL主从集群，避免单点故障。\n2. 读写分离设计，可以避免读写冲突导致的性能问题；引入分库分表机制，通过分库，降低单个服务器节点的IO压力，通过分表可以降低单表数据量，从而提升SQL查询效率。\n3. 对于热点数据，可以引入Redis、MongoDB等分布式数据库，可以很好的缓解MySQL的压力，同时还能提升数据的检索性能。\n\n## MySQL程序配置优化\n\n对于MySQL程序本身的优化，一般可以通过MySQL配置文件（my.cnf）来进行。比如说MySQL5.7版本默认的最大连接数是151个，binlog日志默认不开启，Bufferpool缓存池默认大小等都可以通过my.cnf来配置。配置的重点在于：作用域分为会话级别和全局范围、是否支持热加载。全局参数的设定对于已经存在的会话是无法生效的，会话参数的设定随着会话的销毁而失效，全局的统一配置建议配置在默认配置文件中，否则重启服务会导致配置失效。\n\n## SQL执行优化\n\nSQL优化可以分为三个步骤：\n\n1. 慢SQL的定位和排查。通过慢查询日志和慢查询日志分析工具得到有问题的SQL列表。\n2. 执行计划分析。针对慢SQL使用explain来查看当前SQL的执行计划，可以重点关注type、key、rows、filtered等字段从去定位该SQL执行慢的根本原因，再去有的放矢的进行优化。\n3. 使用show profile（MySQL提供的用于查看SQL语句执行中查看SQL语句资源消耗情况的工具）。默认情况下show profile是关闭的。打开之后会保存最近15次的运行结果。针对运行慢的SQL通过此工具进行详细分析可以得到SQL执行过程中所有资源的开销情况，比如IO、CPU、内存等。\n\n## 常见SQL优化的规则\n\n1. SQL的查询一定要基于索引来进行数据扫描\n2. 避免索引列上使用函数或者运算符\n3. where子句中like %进行放置在右侧，最左原则\n4. 使用索引扫描，联合索引中的列从左往右，命中越多越好\n5. 尽可能使用SQL语句中用到的索引完成排序\n6. 查询有效的列信息即可，少用*代替\n7. 永远用小的结果集驱动大结果集","slug":"kongzheng1993-MySQL性能优化","published":1,"updated":"2023-03-08T07:05:58.820Z","layout":"post","photos":[],"link":"","_id":"clg0k2am80082t26ff06z2d7a","content":"<h1 id=\"MySQL性能优化\"><a href=\"#MySQL性能优化\" class=\"headerlink\" title=\"MySQL性能优化\"></a>MySQL性能优化</h1><h2 id=\"硬件和操作系统层面的优化\"><a href=\"#硬件和操作系统层面的优化\" class=\"headerlink\" title=\"硬件和操作系统层面的优化\"></a>硬件和操作系统层面的优化</h2><p>硬件层面影响MySQL运行的因素主要有：CPU、可用内存大小、磁盘读写速度、网络带宽</p>\n<p>操作系统层面影响因素主要有：应用文件句柄数、操作系统的网络配置</p>\n<p>这部分的优化一般是由运维工程师去完成。在硬件基础资源的优化中，我们重点应该关注的层面是服务本身所承载的体量，然后提出合理的指标要求，避免出现资源浪费的现象。</p>\n<h2 id=\"架构设计层面的优化\"><a href=\"#架构设计层面的优化\" class=\"headerlink\" title=\"架构设计层面的优化\"></a>架构设计层面的优化</h2><p>MySQL是一个磁盘IO访问非常频繁的关系型数据库，在高并发和高性能的场景中，mysql会承受巨大的并发压力，优化的思路如下：</p>\n<ol>\n<li>搭建MySQL主从集群，避免单点故障。</li>\n<li>读写分离设计，可以避免读写冲突导致的性能问题；引入分库分表机制，通过分库，降低单个服务器节点的IO压力，通过分表可以降低单表数据量，从而提升SQL查询效率。</li>\n<li>对于热点数据，可以引入Redis、MongoDB等分布式数据库，可以很好的缓解MySQL的压力，同时还能提升数据的检索性能。</li>\n</ol>\n<h2 id=\"MySQL程序配置优化\"><a href=\"#MySQL程序配置优化\" class=\"headerlink\" title=\"MySQL程序配置优化\"></a>MySQL程序配置优化</h2><p>对于MySQL程序本身的优化，一般可以通过MySQL配置文件（my.cnf）来进行。比如说MySQL5.7版本默认的最大连接数是151个，binlog日志默认不开启，Bufferpool缓存池默认大小等都可以通过my.cnf来配置。配置的重点在于：作用域分为会话级别和全局范围、是否支持热加载。全局参数的设定对于已经存在的会话是无法生效的，会话参数的设定随着会话的销毁而失效，全局的统一配置建议配置在默认配置文件中，否则重启服务会导致配置失效。</p>\n<h2 id=\"SQL执行优化\"><a href=\"#SQL执行优化\" class=\"headerlink\" title=\"SQL执行优化\"></a>SQL执行优化</h2><p>SQL优化可以分为三个步骤：</p>\n<ol>\n<li>慢SQL的定位和排查。通过慢查询日志和慢查询日志分析工具得到有问题的SQL列表。</li>\n<li>执行计划分析。针对慢SQL使用explain来查看当前SQL的执行计划，可以重点关注type、key、rows、filtered等字段从去定位该SQL执行慢的根本原因，再去有的放矢的进行优化。</li>\n<li>使用show profile（MySQL提供的用于查看SQL语句执行中查看SQL语句资源消耗情况的工具）。默认情况下show profile是关闭的。打开之后会保存最近15次的运行结果。针对运行慢的SQL通过此工具进行详细分析可以得到SQL执行过程中所有资源的开销情况，比如IO、CPU、内存等。</li>\n</ol>\n<h2 id=\"常见SQL优化的规则\"><a href=\"#常见SQL优化的规则\" class=\"headerlink\" title=\"常见SQL优化的规则\"></a>常见SQL优化的规则</h2><ol>\n<li>SQL的查询一定要基于索引来进行数据扫描</li>\n<li>避免索引列上使用函数或者运算符</li>\n<li>where子句中like %进行放置在右侧，最左原则</li>\n<li>使用索引扫描，联合索引中的列从左往右，命中越多越好</li>\n<li>尽可能使用SQL语句中用到的索引完成排序</li>\n<li>查询有效的列信息即可，少用*代替</li>\n<li>永远用小的结果集驱动大结果集</li>\n</ol>\n","site":{"data":{}},"more":"<h1 id=\"MySQL性能优化\"><a href=\"#MySQL性能优化\" class=\"headerlink\" title=\"MySQL性能优化\"></a>MySQL性能优化</h1><h2 id=\"硬件和操作系统层面的优化\"><a href=\"#硬件和操作系统层面的优化\" class=\"headerlink\" title=\"硬件和操作系统层面的优化\"></a>硬件和操作系统层面的优化</h2><p>硬件层面影响MySQL运行的因素主要有：CPU、可用内存大小、磁盘读写速度、网络带宽</p>\n<p>操作系统层面影响因素主要有：应用文件句柄数、操作系统的网络配置</p>\n<p>这部分的优化一般是由运维工程师去完成。在硬件基础资源的优化中，我们重点应该关注的层面是服务本身所承载的体量，然后提出合理的指标要求，避免出现资源浪费的现象。</p>\n<h2 id=\"架构设计层面的优化\"><a href=\"#架构设计层面的优化\" class=\"headerlink\" title=\"架构设计层面的优化\"></a>架构设计层面的优化</h2><p>MySQL是一个磁盘IO访问非常频繁的关系型数据库，在高并发和高性能的场景中，mysql会承受巨大的并发压力，优化的思路如下：</p>\n<ol>\n<li>搭建MySQL主从集群，避免单点故障。</li>\n<li>读写分离设计，可以避免读写冲突导致的性能问题；引入分库分表机制，通过分库，降低单个服务器节点的IO压力，通过分表可以降低单表数据量，从而提升SQL查询效率。</li>\n<li>对于热点数据，可以引入Redis、MongoDB等分布式数据库，可以很好的缓解MySQL的压力，同时还能提升数据的检索性能。</li>\n</ol>\n<h2 id=\"MySQL程序配置优化\"><a href=\"#MySQL程序配置优化\" class=\"headerlink\" title=\"MySQL程序配置优化\"></a>MySQL程序配置优化</h2><p>对于MySQL程序本身的优化，一般可以通过MySQL配置文件（my.cnf）来进行。比如说MySQL5.7版本默认的最大连接数是151个，binlog日志默认不开启，Bufferpool缓存池默认大小等都可以通过my.cnf来配置。配置的重点在于：作用域分为会话级别和全局范围、是否支持热加载。全局参数的设定对于已经存在的会话是无法生效的，会话参数的设定随着会话的销毁而失效，全局的统一配置建议配置在默认配置文件中，否则重启服务会导致配置失效。</p>\n<h2 id=\"SQL执行优化\"><a href=\"#SQL执行优化\" class=\"headerlink\" title=\"SQL执行优化\"></a>SQL执行优化</h2><p>SQL优化可以分为三个步骤：</p>\n<ol>\n<li>慢SQL的定位和排查。通过慢查询日志和慢查询日志分析工具得到有问题的SQL列表。</li>\n<li>执行计划分析。针对慢SQL使用explain来查看当前SQL的执行计划，可以重点关注type、key、rows、filtered等字段从去定位该SQL执行慢的根本原因，再去有的放矢的进行优化。</li>\n<li>使用show profile（MySQL提供的用于查看SQL语句执行中查看SQL语句资源消耗情况的工具）。默认情况下show profile是关闭的。打开之后会保存最近15次的运行结果。针对运行慢的SQL通过此工具进行详细分析可以得到SQL执行过程中所有资源的开销情况，比如IO、CPU、内存等。</li>\n</ol>\n<h2 id=\"常见SQL优化的规则\"><a href=\"#常见SQL优化的规则\" class=\"headerlink\" title=\"常见SQL优化的规则\"></a>常见SQL优化的规则</h2><ol>\n<li>SQL的查询一定要基于索引来进行数据扫描</li>\n<li>避免索引列上使用函数或者运算符</li>\n<li>where子句中like %进行放置在右侧，最左原则</li>\n<li>使用索引扫描，联合索引中的列从左往右，命中越多越好</li>\n<li>尽可能使用SQL语句中用到的索引完成排序</li>\n<li>查询有效的列信息即可，少用*代替</li>\n<li>永远用小的结果集驱动大结果集</li>\n</ol>\n"},{"title":"MySQL位运算实现权限控制","excerpt":"","comments":1,"date":"2021-11-26T08:30:10.000Z","_content":"\nhttps://sq.sf.163.com/blog/article/195969597830971392\n\n\n\n","source":"_posts/2021-11-29-kongzheng1993-mysql_bitMap.md","raw":"---\ntitle: MySQL位运算实现权限控制\nexcerpt: 'Spring'\ntags: [Spring]\ncategories: [Spring]\ncomments: true\ndate: 2021-11-26 16:30:10\n---\n\nhttps://sq.sf.163.com/blog/article/195969597830971392\n\n\n\n","slug":"kongzheng1993-mysql_bitMap","published":1,"updated":"2023-03-08T07:05:58.819Z","layout":"post","photos":[],"link":"","_id":"clg0k2amd0085t26fotwp1uru","content":"<p><a href=\"https://sq.sf.163.com/blog/article/195969597830971392\" target=\"_blank\" rel=\"noopener\">https://sq.sf.163.com/blog/article/195969597830971392</a></p>\n","site":{"data":{}},"more":"<p><a href=\"https://sq.sf.163.com/blog/article/195969597830971392\" target=\"_blank\" rel=\"noopener\">https://sq.sf.163.com/blog/article/195969597830971392</a></p>\n"},{"title":"使用jsoup遇到的问题","excerpt":"","comments":1,"date":"2022-01-14T10:30:52.000Z","_content":"\n最近做了一个通过jsoup来处理html，实现页面table可以根据用户的配置来展示哪些列。\n\nhttps://jsoup.org/apidocs/org/jsoup/select/Selector.html\n\n```java\n    public Elements children() {\n        return new Elements(childElementsList());\n    }\n```","source":"_posts/2022-01-09-kongzheng1993-jsoup遇到的问题.md","raw":"---\ntitle: 使用jsoup遇到的问题\nexcerpt: 'Web'\ntags: [Web]\ncategories: [Web]\ncomments: true\ndate: 2022-01-14 18:30:52\n---\n\n最近做了一个通过jsoup来处理html，实现页面table可以根据用户的配置来展示哪些列。\n\nhttps://jsoup.org/apidocs/org/jsoup/select/Selector.html\n\n```java\n    public Elements children() {\n        return new Elements(childElementsList());\n    }\n```","slug":"kongzheng1993-jsoup遇到的问题","published":1,"updated":"2023-03-08T07:05:58.820Z","layout":"post","photos":[],"link":"","_id":"clg0k2amf0089t26fsbac5mw4","content":"<p>最近做了一个通过jsoup来处理html，实现页面table可以根据用户的配置来展示哪些列。</p>\n<p><a href=\"https://jsoup.org/apidocs/org/jsoup/select/Selector.html\" target=\"_blank\" rel=\"noopener\">https://jsoup.org/apidocs/org/jsoup/select/Selector.html</a></p>\n<pre><code class=\"java\">    public Elements children() {\n        return new Elements(childElementsList());\n    }</code></pre>\n","site":{"data":{}},"more":"<p>最近做了一个通过jsoup来处理html，实现页面table可以根据用户的配置来展示哪些列。</p>\n<p><a href=\"https://jsoup.org/apidocs/org/jsoup/select/Selector.html\" target=\"_blank\" rel=\"noopener\">https://jsoup.org/apidocs/org/jsoup/select/Selector.html</a></p>\n<pre><code class=\"java\">    public Elements children() {\n        return new Elements(childElementsList());\n    }</code></pre>\n"},{"title":"MySQL MVCC","excerpt":"","comments":1,"date":"2022-01-09T10:30:52.000Z","_content":"\n# MySQL的MVCC、事务隔离和锁\n\n原子性（atomicity，或称不可分割性）、一致性（consistency）、隔离性（isolation，又称独立性）、持久性（durability）\n\n## MVCC\n\nMVCC，全称`Multi-Version Concurrency Control`，即多版本并发控制。MVCC是一种并发控制的方法，一般在数据库管理系统中，实现对数据库的并发访问，在编程语言中实现事务内存。\n\n记为一致性非锁定读，MySQL基于自己的***回滚机制**为并发场景的**读操作**做的一个优化。回滚机制也就是undo log，\n\n`MVCC`的基本思路是对数据库的任何修改都不会直接覆盖之前的数据，而是产生一个新版副本与老版本共存，以此达到读取时可以**完全不加锁**的目的。在这句话中，“版本”是个关键词，你不妨将版本理解为数据库中每一行记录都存在两个看不见的字段：`CREATE_VERSION`和 `DELETE_VERSION`，这两个字段记录的值都是`事务ID`，`事务ID`是一个全局严格递增的数值，然后根据以下规则写入数据。\n\n- 插入数据时：CREATE_VERSION 记录插入数据的事务 ID，DELETE_VERSION 为空。\n- 删除数据时：DELETE_VERSION 记录删除数据的事务 ID，CREATE_VERSION 为空。\n- 修改数据时：将修改数据视为“删除旧数据，插入新数据”的组合，即先将原有数据复制一份，原有数据的 DELETE_VERSION 记录修改数据的事务 ID，CREATE_VERSION 为空。复制出来的新数据的 CREATE_VERSION 记录修改数据的事务 ID，DELETE_VERSION 为空。\n\n此时，如有另外一个事务要读取这些发生了变化的数据，将根据`隔离级别`来决定到底应该读取哪个版本的数据。\n\n- 隔离级别是可重复读：总是读取 CREATE_VERSION 小于或等于当前事务 ID 的记录，在这个前提下，如果数据仍有多个版本，则取最新（事务 ID 最大）的。\n- 隔离级别是读已提交：总是取最新的版本即可，即最近被 Commit 的那个版本的数据记录。\n\n另外两个隔离级别都没有必要用到 MVCC，因为读未提交直接修改原始数据即可，其他事务查看数据的时候立刻可以看到，根本无须版本字段。可串行化本来的语义就是要阻塞其他事务的读取操作，而 MVCC 是做读取时无锁优化的，自然就不会放到一起用。\n\nMVCC 是只针对“读+写”场景的优化，如果是两个事务同时修改数据，即“写+写”的情况，那就没有多少优化的空间了，此时加锁几乎是唯一可行的解决方案，稍微有点讨论余地的是加锁的策略是“乐观加锁”（Optimistic Locking）还是“悲观加锁”（Pessimistic Locking）。前面笔者介绍的加锁都属于悲观加锁策略，即认为如果不先做加锁再访问数据，就肯定会出现问题。相对地，乐观加锁策略认为事务之间数据存在竞争是偶然情况，没有竞争才是普遍情况，这样就不应该在一开始就加锁，而是应当在出现竞争时再找补救措施。这种思路被称为“乐观并发控制”（Optimistic Concurrency Control，OCC），囿于篇幅与主题的原因，就不再展开了，不过笔者提醒一句，没有必要迷信什么乐观锁要比悲观锁更快的说法，这纯粹看竞争的剧烈程度，如果竞争剧烈的话，乐观锁反而更慢。\n\n## 隔离级别\n\nMySQL有四种隔离级别，由低到高分别是：\n\n- read uncommited 读取未提交数据\n- read commited 读取已提交数据\n- repeatable read 可重复读\n- serializable 串行化\n\nMySQL的默认隔离级别是repeatable read。\n\n### 举例描述MVCC和隔离级别的关系\n\n举例： A、B线程为写线程，C线程为读线程\nrepeatable read级别下：\nA、C同时向一条数据发起了写和读的操作，C发起线程后（已开启事务了）sleep，A开始修改数据，在可重复读的隔离界别下，要先生成一版快照，修改之前的快照，也就是undo log，以便回滚，A线程修改完成后提交了，这时候存在2个版本，A线程结束。然后B线程来了，也是一个写线程，又产生了一个快照，对这条数据进行了写操作，commit后，B线程结束，这时候一共有3个版本，A线程之前到版本，A线程之后、B线程之前到版本，B线程之后到版本。这时候C线程sleep结束，C线程读到的是第一个版本的数据。\n\nread commited:\n同样是上面的例子，AC线程同时开启事务发起操作，C线程sleep，A线程写，A线程提交后，B线程过来修改完提交，C线程这个时候过来读，C线程读到的是最新的版本，也就是B提交的版本。\n\n总结：repeatable read读取的是自己线程开始时的版本，read commited读取的是最新的版本。\n\nread uncommited，还没有提交的数据就能读到，就没有必要使用版本管理了，直接就能读到其他线程修改的数据，直接操作一份数据就可以了。不需要MVCC。serializable，这个隔离级别下，所有的操作（读+写）都是加锁的，也就是所有线程顺序执行，并不会出现并发问题。\n\nread commited能读到其他事物提交的数据，事物之间没有隔离，违背了食物的隔离性（ACID的I）。\nrepeatable read其他线程再怎么修改，C读取到的都是最初自己开启事务时的版本，也就做到了事务的隔离性。\n\n\n### 不能隔离级别下存在的问题\n\nread uncommited：会造成**脏读**、**幻读**和**不可重复读**，其他线程还没提交，你就能读到，这读到的数据时一种临时状态的数据，或者说是脏数据，我们称之为**脏读**。总结：脏读是在read uncommited事务隔离级别下的读取到其他线程未提交到数据。\n\nread commited：会造成**幻读**和**不可重复读**。不可重复读可以理解为读取同一条数据，两次读取到的内容不一样。幻读可以理解为同一条sql的执行两次的到的数据量不一样。\n\nrepeatable read：会造成**幻读**，next key lock\n\nserializable：可以解决以上所有问题。他存在的问题就是慢……\n\n\n## 锁\n\nInnoDB存储引擎实现了如下两种标准的行级锁：\n\n- 共享锁（S Lock），允许事务读一行数据。\n\n- 排他锁（X Lock），允许事务删除或更新一行数据。\n\n如果一个事务T1已经获得了行r的共享锁，那么另外的事务T2可以立即获得行r的共享锁，因为读取并没有改变行r的数据，称这种情况为锁兼容（Lock Compatible）。但若有其他的事务T3想获得行r的排他锁，则其必须等待事务T1、T2释放行r上的共享锁——这种情况称为锁不兼容\n\n\nInnoDB存储引擎有3种行锁的算法，其分别是：\n\n- Record Lock：单个行记录上的锁\n\n- Gap Lock：间隙锁，锁定一个范围，但不包含记录本身\n\n- Next-Key Lock∶Gap Lock+Record Lock，锁定一个范围，并且锁定记录本身\n\nRecord Lock总是会去锁住索引记录，如果InnoDB存储引擎表在建立的时候没有设置任何一个索引，那么这时InnoDB存储引擎会使用隐式的主键来进行锁定。\n\nNext-Key Lock是结合了Gap Lock和Record Lock的一种锁定算法，在Next-Key Lock算法下，InnoDB对于行的查询都是采用这种锁定算法。","source":"_posts/2022-02-20-kongzheng1993-MySQL_MVCC.md","raw":"---\ntitle: MySQL MVCC\nexcerpt: 'mysql'\ntags: [mysql]\ncategories: [mysql]\ncomments: true\ndate: 2022-01-09 18:30:52\n---\n\n# MySQL的MVCC、事务隔离和锁\n\n原子性（atomicity，或称不可分割性）、一致性（consistency）、隔离性（isolation，又称独立性）、持久性（durability）\n\n## MVCC\n\nMVCC，全称`Multi-Version Concurrency Control`，即多版本并发控制。MVCC是一种并发控制的方法，一般在数据库管理系统中，实现对数据库的并发访问，在编程语言中实现事务内存。\n\n记为一致性非锁定读，MySQL基于自己的***回滚机制**为并发场景的**读操作**做的一个优化。回滚机制也就是undo log，\n\n`MVCC`的基本思路是对数据库的任何修改都不会直接覆盖之前的数据，而是产生一个新版副本与老版本共存，以此达到读取时可以**完全不加锁**的目的。在这句话中，“版本”是个关键词，你不妨将版本理解为数据库中每一行记录都存在两个看不见的字段：`CREATE_VERSION`和 `DELETE_VERSION`，这两个字段记录的值都是`事务ID`，`事务ID`是一个全局严格递增的数值，然后根据以下规则写入数据。\n\n- 插入数据时：CREATE_VERSION 记录插入数据的事务 ID，DELETE_VERSION 为空。\n- 删除数据时：DELETE_VERSION 记录删除数据的事务 ID，CREATE_VERSION 为空。\n- 修改数据时：将修改数据视为“删除旧数据，插入新数据”的组合，即先将原有数据复制一份，原有数据的 DELETE_VERSION 记录修改数据的事务 ID，CREATE_VERSION 为空。复制出来的新数据的 CREATE_VERSION 记录修改数据的事务 ID，DELETE_VERSION 为空。\n\n此时，如有另外一个事务要读取这些发生了变化的数据，将根据`隔离级别`来决定到底应该读取哪个版本的数据。\n\n- 隔离级别是可重复读：总是读取 CREATE_VERSION 小于或等于当前事务 ID 的记录，在这个前提下，如果数据仍有多个版本，则取最新（事务 ID 最大）的。\n- 隔离级别是读已提交：总是取最新的版本即可，即最近被 Commit 的那个版本的数据记录。\n\n另外两个隔离级别都没有必要用到 MVCC，因为读未提交直接修改原始数据即可，其他事务查看数据的时候立刻可以看到，根本无须版本字段。可串行化本来的语义就是要阻塞其他事务的读取操作，而 MVCC 是做读取时无锁优化的，自然就不会放到一起用。\n\nMVCC 是只针对“读+写”场景的优化，如果是两个事务同时修改数据，即“写+写”的情况，那就没有多少优化的空间了，此时加锁几乎是唯一可行的解决方案，稍微有点讨论余地的是加锁的策略是“乐观加锁”（Optimistic Locking）还是“悲观加锁”（Pessimistic Locking）。前面笔者介绍的加锁都属于悲观加锁策略，即认为如果不先做加锁再访问数据，就肯定会出现问题。相对地，乐观加锁策略认为事务之间数据存在竞争是偶然情况，没有竞争才是普遍情况，这样就不应该在一开始就加锁，而是应当在出现竞争时再找补救措施。这种思路被称为“乐观并发控制”（Optimistic Concurrency Control，OCC），囿于篇幅与主题的原因，就不再展开了，不过笔者提醒一句，没有必要迷信什么乐观锁要比悲观锁更快的说法，这纯粹看竞争的剧烈程度，如果竞争剧烈的话，乐观锁反而更慢。\n\n## 隔离级别\n\nMySQL有四种隔离级别，由低到高分别是：\n\n- read uncommited 读取未提交数据\n- read commited 读取已提交数据\n- repeatable read 可重复读\n- serializable 串行化\n\nMySQL的默认隔离级别是repeatable read。\n\n### 举例描述MVCC和隔离级别的关系\n\n举例： A、B线程为写线程，C线程为读线程\nrepeatable read级别下：\nA、C同时向一条数据发起了写和读的操作，C发起线程后（已开启事务了）sleep，A开始修改数据，在可重复读的隔离界别下，要先生成一版快照，修改之前的快照，也就是undo log，以便回滚，A线程修改完成后提交了，这时候存在2个版本，A线程结束。然后B线程来了，也是一个写线程，又产生了一个快照，对这条数据进行了写操作，commit后，B线程结束，这时候一共有3个版本，A线程之前到版本，A线程之后、B线程之前到版本，B线程之后到版本。这时候C线程sleep结束，C线程读到的是第一个版本的数据。\n\nread commited:\n同样是上面的例子，AC线程同时开启事务发起操作，C线程sleep，A线程写，A线程提交后，B线程过来修改完提交，C线程这个时候过来读，C线程读到的是最新的版本，也就是B提交的版本。\n\n总结：repeatable read读取的是自己线程开始时的版本，read commited读取的是最新的版本。\n\nread uncommited，还没有提交的数据就能读到，就没有必要使用版本管理了，直接就能读到其他线程修改的数据，直接操作一份数据就可以了。不需要MVCC。serializable，这个隔离级别下，所有的操作（读+写）都是加锁的，也就是所有线程顺序执行，并不会出现并发问题。\n\nread commited能读到其他事物提交的数据，事物之间没有隔离，违背了食物的隔离性（ACID的I）。\nrepeatable read其他线程再怎么修改，C读取到的都是最初自己开启事务时的版本，也就做到了事务的隔离性。\n\n\n### 不能隔离级别下存在的问题\n\nread uncommited：会造成**脏读**、**幻读**和**不可重复读**，其他线程还没提交，你就能读到，这读到的数据时一种临时状态的数据，或者说是脏数据，我们称之为**脏读**。总结：脏读是在read uncommited事务隔离级别下的读取到其他线程未提交到数据。\n\nread commited：会造成**幻读**和**不可重复读**。不可重复读可以理解为读取同一条数据，两次读取到的内容不一样。幻读可以理解为同一条sql的执行两次的到的数据量不一样。\n\nrepeatable read：会造成**幻读**，next key lock\n\nserializable：可以解决以上所有问题。他存在的问题就是慢……\n\n\n## 锁\n\nInnoDB存储引擎实现了如下两种标准的行级锁：\n\n- 共享锁（S Lock），允许事务读一行数据。\n\n- 排他锁（X Lock），允许事务删除或更新一行数据。\n\n如果一个事务T1已经获得了行r的共享锁，那么另外的事务T2可以立即获得行r的共享锁，因为读取并没有改变行r的数据，称这种情况为锁兼容（Lock Compatible）。但若有其他的事务T3想获得行r的排他锁，则其必须等待事务T1、T2释放行r上的共享锁——这种情况称为锁不兼容\n\n\nInnoDB存储引擎有3种行锁的算法，其分别是：\n\n- Record Lock：单个行记录上的锁\n\n- Gap Lock：间隙锁，锁定一个范围，但不包含记录本身\n\n- Next-Key Lock∶Gap Lock+Record Lock，锁定一个范围，并且锁定记录本身\n\nRecord Lock总是会去锁住索引记录，如果InnoDB存储引擎表在建立的时候没有设置任何一个索引，那么这时InnoDB存储引擎会使用隐式的主键来进行锁定。\n\nNext-Key Lock是结合了Gap Lock和Record Lock的一种锁定算法，在Next-Key Lock算法下，InnoDB对于行的查询都是采用这种锁定算法。","slug":"kongzheng1993-MySQL_MVCC","published":1,"updated":"2023-03-08T07:05:58.820Z","layout":"post","photos":[],"link":"","_id":"clg0k2amg008ct26fipfg07e6","content":"<h1 id=\"MySQL的MVCC、事务隔离和锁\"><a href=\"#MySQL的MVCC、事务隔离和锁\" class=\"headerlink\" title=\"MySQL的MVCC、事务隔离和锁\"></a>MySQL的MVCC、事务隔离和锁</h1><p>原子性（atomicity，或称不可分割性）、一致性（consistency）、隔离性（isolation，又称独立性）、持久性（durability）</p>\n<h2 id=\"MVCC\"><a href=\"#MVCC\" class=\"headerlink\" title=\"MVCC\"></a>MVCC</h2><p>MVCC，全称<code>Multi-Version Concurrency Control</code>，即多版本并发控制。MVCC是一种并发控制的方法，一般在数据库管理系统中，实现对数据库的并发访问，在编程语言中实现事务内存。</p>\n<p>记为一致性非锁定读，MySQL基于自己的<strong>*回滚机制</strong>为并发场景的<strong>读操作</strong>做的一个优化。回滚机制也就是undo log，</p>\n<p><code>MVCC</code>的基本思路是对数据库的任何修改都不会直接覆盖之前的数据，而是产生一个新版副本与老版本共存，以此达到读取时可以<strong>完全不加锁</strong>的目的。在这句话中，“版本”是个关键词，你不妨将版本理解为数据库中每一行记录都存在两个看不见的字段：<code>CREATE_VERSION</code>和 <code>DELETE_VERSION</code>，这两个字段记录的值都是<code>事务ID</code>，<code>事务ID</code>是一个全局严格递增的数值，然后根据以下规则写入数据。</p>\n<ul>\n<li>插入数据时：CREATE_VERSION 记录插入数据的事务 ID，DELETE_VERSION 为空。</li>\n<li>删除数据时：DELETE_VERSION 记录删除数据的事务 ID，CREATE_VERSION 为空。</li>\n<li>修改数据时：将修改数据视为“删除旧数据，插入新数据”的组合，即先将原有数据复制一份，原有数据的 DELETE_VERSION 记录修改数据的事务 ID，CREATE_VERSION 为空。复制出来的新数据的 CREATE_VERSION 记录修改数据的事务 ID，DELETE_VERSION 为空。</li>\n</ul>\n<p>此时，如有另外一个事务要读取这些发生了变化的数据，将根据<code>隔离级别</code>来决定到底应该读取哪个版本的数据。</p>\n<ul>\n<li>隔离级别是可重复读：总是读取 CREATE_VERSION 小于或等于当前事务 ID 的记录，在这个前提下，如果数据仍有多个版本，则取最新（事务 ID 最大）的。</li>\n<li>隔离级别是读已提交：总是取最新的版本即可，即最近被 Commit 的那个版本的数据记录。</li>\n</ul>\n<p>另外两个隔离级别都没有必要用到 MVCC，因为读未提交直接修改原始数据即可，其他事务查看数据的时候立刻可以看到，根本无须版本字段。可串行化本来的语义就是要阻塞其他事务的读取操作，而 MVCC 是做读取时无锁优化的，自然就不会放到一起用。</p>\n<p>MVCC 是只针对“读+写”场景的优化，如果是两个事务同时修改数据，即“写+写”的情况，那就没有多少优化的空间了，此时加锁几乎是唯一可行的解决方案，稍微有点讨论余地的是加锁的策略是“乐观加锁”（Optimistic Locking）还是“悲观加锁”（Pessimistic Locking）。前面笔者介绍的加锁都属于悲观加锁策略，即认为如果不先做加锁再访问数据，就肯定会出现问题。相对地，乐观加锁策略认为事务之间数据存在竞争是偶然情况，没有竞争才是普遍情况，这样就不应该在一开始就加锁，而是应当在出现竞争时再找补救措施。这种思路被称为“乐观并发控制”（Optimistic Concurrency Control，OCC），囿于篇幅与主题的原因，就不再展开了，不过笔者提醒一句，没有必要迷信什么乐观锁要比悲观锁更快的说法，这纯粹看竞争的剧烈程度，如果竞争剧烈的话，乐观锁反而更慢。</p>\n<h2 id=\"隔离级别\"><a href=\"#隔离级别\" class=\"headerlink\" title=\"隔离级别\"></a>隔离级别</h2><p>MySQL有四种隔离级别，由低到高分别是：</p>\n<ul>\n<li>read uncommited 读取未提交数据</li>\n<li>read commited 读取已提交数据</li>\n<li>repeatable read 可重复读</li>\n<li>serializable 串行化</li>\n</ul>\n<p>MySQL的默认隔离级别是repeatable read。</p>\n<h3 id=\"举例描述MVCC和隔离级别的关系\"><a href=\"#举例描述MVCC和隔离级别的关系\" class=\"headerlink\" title=\"举例描述MVCC和隔离级别的关系\"></a>举例描述MVCC和隔离级别的关系</h3><p>举例： A、B线程为写线程，C线程为读线程<br>repeatable read级别下：<br>A、C同时向一条数据发起了写和读的操作，C发起线程后（已开启事务了）sleep，A开始修改数据，在可重复读的隔离界别下，要先生成一版快照，修改之前的快照，也就是undo log，以便回滚，A线程修改完成后提交了，这时候存在2个版本，A线程结束。然后B线程来了，也是一个写线程，又产生了一个快照，对这条数据进行了写操作，commit后，B线程结束，这时候一共有3个版本，A线程之前到版本，A线程之后、B线程之前到版本，B线程之后到版本。这时候C线程sleep结束，C线程读到的是第一个版本的数据。</p>\n<p>read commited:<br>同样是上面的例子，AC线程同时开启事务发起操作，C线程sleep，A线程写，A线程提交后，B线程过来修改完提交，C线程这个时候过来读，C线程读到的是最新的版本，也就是B提交的版本。</p>\n<p>总结：repeatable read读取的是自己线程开始时的版本，read commited读取的是最新的版本。</p>\n<p>read uncommited，还没有提交的数据就能读到，就没有必要使用版本管理了，直接就能读到其他线程修改的数据，直接操作一份数据就可以了。不需要MVCC。serializable，这个隔离级别下，所有的操作（读+写）都是加锁的，也就是所有线程顺序执行，并不会出现并发问题。</p>\n<p>read commited能读到其他事物提交的数据，事物之间没有隔离，违背了食物的隔离性（ACID的I）。<br>repeatable read其他线程再怎么修改，C读取到的都是最初自己开启事务时的版本，也就做到了事务的隔离性。</p>\n<h3 id=\"不能隔离级别下存在的问题\"><a href=\"#不能隔离级别下存在的问题\" class=\"headerlink\" title=\"不能隔离级别下存在的问题\"></a>不能隔离级别下存在的问题</h3><p>read uncommited：会造成<strong>脏读</strong>、<strong>幻读</strong>和<strong>不可重复读</strong>，其他线程还没提交，你就能读到，这读到的数据时一种临时状态的数据，或者说是脏数据，我们称之为<strong>脏读</strong>。总结：脏读是在read uncommited事务隔离级别下的读取到其他线程未提交到数据。</p>\n<p>read commited：会造成<strong>幻读</strong>和<strong>不可重复读</strong>。不可重复读可以理解为读取同一条数据，两次读取到的内容不一样。幻读可以理解为同一条sql的执行两次的到的数据量不一样。</p>\n<p>repeatable read：会造成<strong>幻读</strong>，next key lock</p>\n<p>serializable：可以解决以上所有问题。他存在的问题就是慢……</p>\n<h2 id=\"锁\"><a href=\"#锁\" class=\"headerlink\" title=\"锁\"></a>锁</h2><p>InnoDB存储引擎实现了如下两种标准的行级锁：</p>\n<ul>\n<li><p>共享锁（S Lock），允许事务读一行数据。</p>\n</li>\n<li><p>排他锁（X Lock），允许事务删除或更新一行数据。</p>\n</li>\n</ul>\n<p>如果一个事务T1已经获得了行r的共享锁，那么另外的事务T2可以立即获得行r的共享锁，因为读取并没有改变行r的数据，称这种情况为锁兼容（Lock Compatible）。但若有其他的事务T3想获得行r的排他锁，则其必须等待事务T1、T2释放行r上的共享锁——这种情况称为锁不兼容</p>\n<p>InnoDB存储引擎有3种行锁的算法，其分别是：</p>\n<ul>\n<li><p>Record Lock：单个行记录上的锁</p>\n</li>\n<li><p>Gap Lock：间隙锁，锁定一个范围，但不包含记录本身</p>\n</li>\n<li><p>Next-Key Lock∶Gap Lock+Record Lock，锁定一个范围，并且锁定记录本身</p>\n</li>\n</ul>\n<p>Record Lock总是会去锁住索引记录，如果InnoDB存储引擎表在建立的时候没有设置任何一个索引，那么这时InnoDB存储引擎会使用隐式的主键来进行锁定。</p>\n<p>Next-Key Lock是结合了Gap Lock和Record Lock的一种锁定算法，在Next-Key Lock算法下，InnoDB对于行的查询都是采用这种锁定算法。</p>\n","site":{"data":{}},"more":"<h1 id=\"MySQL的MVCC、事务隔离和锁\"><a href=\"#MySQL的MVCC、事务隔离和锁\" class=\"headerlink\" title=\"MySQL的MVCC、事务隔离和锁\"></a>MySQL的MVCC、事务隔离和锁</h1><p>原子性（atomicity，或称不可分割性）、一致性（consistency）、隔离性（isolation，又称独立性）、持久性（durability）</p>\n<h2 id=\"MVCC\"><a href=\"#MVCC\" class=\"headerlink\" title=\"MVCC\"></a>MVCC</h2><p>MVCC，全称<code>Multi-Version Concurrency Control</code>，即多版本并发控制。MVCC是一种并发控制的方法，一般在数据库管理系统中，实现对数据库的并发访问，在编程语言中实现事务内存。</p>\n<p>记为一致性非锁定读，MySQL基于自己的<strong>*回滚机制</strong>为并发场景的<strong>读操作</strong>做的一个优化。回滚机制也就是undo log，</p>\n<p><code>MVCC</code>的基本思路是对数据库的任何修改都不会直接覆盖之前的数据，而是产生一个新版副本与老版本共存，以此达到读取时可以<strong>完全不加锁</strong>的目的。在这句话中，“版本”是个关键词，你不妨将版本理解为数据库中每一行记录都存在两个看不见的字段：<code>CREATE_VERSION</code>和 <code>DELETE_VERSION</code>，这两个字段记录的值都是<code>事务ID</code>，<code>事务ID</code>是一个全局严格递增的数值，然后根据以下规则写入数据。</p>\n<ul>\n<li>插入数据时：CREATE_VERSION 记录插入数据的事务 ID，DELETE_VERSION 为空。</li>\n<li>删除数据时：DELETE_VERSION 记录删除数据的事务 ID，CREATE_VERSION 为空。</li>\n<li>修改数据时：将修改数据视为“删除旧数据，插入新数据”的组合，即先将原有数据复制一份，原有数据的 DELETE_VERSION 记录修改数据的事务 ID，CREATE_VERSION 为空。复制出来的新数据的 CREATE_VERSION 记录修改数据的事务 ID，DELETE_VERSION 为空。</li>\n</ul>\n<p>此时，如有另外一个事务要读取这些发生了变化的数据，将根据<code>隔离级别</code>来决定到底应该读取哪个版本的数据。</p>\n<ul>\n<li>隔离级别是可重复读：总是读取 CREATE_VERSION 小于或等于当前事务 ID 的记录，在这个前提下，如果数据仍有多个版本，则取最新（事务 ID 最大）的。</li>\n<li>隔离级别是读已提交：总是取最新的版本即可，即最近被 Commit 的那个版本的数据记录。</li>\n</ul>\n<p>另外两个隔离级别都没有必要用到 MVCC，因为读未提交直接修改原始数据即可，其他事务查看数据的时候立刻可以看到，根本无须版本字段。可串行化本来的语义就是要阻塞其他事务的读取操作，而 MVCC 是做读取时无锁优化的，自然就不会放到一起用。</p>\n<p>MVCC 是只针对“读+写”场景的优化，如果是两个事务同时修改数据，即“写+写”的情况，那就没有多少优化的空间了，此时加锁几乎是唯一可行的解决方案，稍微有点讨论余地的是加锁的策略是“乐观加锁”（Optimistic Locking）还是“悲观加锁”（Pessimistic Locking）。前面笔者介绍的加锁都属于悲观加锁策略，即认为如果不先做加锁再访问数据，就肯定会出现问题。相对地，乐观加锁策略认为事务之间数据存在竞争是偶然情况，没有竞争才是普遍情况，这样就不应该在一开始就加锁，而是应当在出现竞争时再找补救措施。这种思路被称为“乐观并发控制”（Optimistic Concurrency Control，OCC），囿于篇幅与主题的原因，就不再展开了，不过笔者提醒一句，没有必要迷信什么乐观锁要比悲观锁更快的说法，这纯粹看竞争的剧烈程度，如果竞争剧烈的话，乐观锁反而更慢。</p>\n<h2 id=\"隔离级别\"><a href=\"#隔离级别\" class=\"headerlink\" title=\"隔离级别\"></a>隔离级别</h2><p>MySQL有四种隔离级别，由低到高分别是：</p>\n<ul>\n<li>read uncommited 读取未提交数据</li>\n<li>read commited 读取已提交数据</li>\n<li>repeatable read 可重复读</li>\n<li>serializable 串行化</li>\n</ul>\n<p>MySQL的默认隔离级别是repeatable read。</p>\n<h3 id=\"举例描述MVCC和隔离级别的关系\"><a href=\"#举例描述MVCC和隔离级别的关系\" class=\"headerlink\" title=\"举例描述MVCC和隔离级别的关系\"></a>举例描述MVCC和隔离级别的关系</h3><p>举例： A、B线程为写线程，C线程为读线程<br>repeatable read级别下：<br>A、C同时向一条数据发起了写和读的操作，C发起线程后（已开启事务了）sleep，A开始修改数据，在可重复读的隔离界别下，要先生成一版快照，修改之前的快照，也就是undo log，以便回滚，A线程修改完成后提交了，这时候存在2个版本，A线程结束。然后B线程来了，也是一个写线程，又产生了一个快照，对这条数据进行了写操作，commit后，B线程结束，这时候一共有3个版本，A线程之前到版本，A线程之后、B线程之前到版本，B线程之后到版本。这时候C线程sleep结束，C线程读到的是第一个版本的数据。</p>\n<p>read commited:<br>同样是上面的例子，AC线程同时开启事务发起操作，C线程sleep，A线程写，A线程提交后，B线程过来修改完提交，C线程这个时候过来读，C线程读到的是最新的版本，也就是B提交的版本。</p>\n<p>总结：repeatable read读取的是自己线程开始时的版本，read commited读取的是最新的版本。</p>\n<p>read uncommited，还没有提交的数据就能读到，就没有必要使用版本管理了，直接就能读到其他线程修改的数据，直接操作一份数据就可以了。不需要MVCC。serializable，这个隔离级别下，所有的操作（读+写）都是加锁的，也就是所有线程顺序执行，并不会出现并发问题。</p>\n<p>read commited能读到其他事物提交的数据，事物之间没有隔离，违背了食物的隔离性（ACID的I）。<br>repeatable read其他线程再怎么修改，C读取到的都是最初自己开启事务时的版本，也就做到了事务的隔离性。</p>\n<h3 id=\"不能隔离级别下存在的问题\"><a href=\"#不能隔离级别下存在的问题\" class=\"headerlink\" title=\"不能隔离级别下存在的问题\"></a>不能隔离级别下存在的问题</h3><p>read uncommited：会造成<strong>脏读</strong>、<strong>幻读</strong>和<strong>不可重复读</strong>，其他线程还没提交，你就能读到，这读到的数据时一种临时状态的数据，或者说是脏数据，我们称之为<strong>脏读</strong>。总结：脏读是在read uncommited事务隔离级别下的读取到其他线程未提交到数据。</p>\n<p>read commited：会造成<strong>幻读</strong>和<strong>不可重复读</strong>。不可重复读可以理解为读取同一条数据，两次读取到的内容不一样。幻读可以理解为同一条sql的执行两次的到的数据量不一样。</p>\n<p>repeatable read：会造成<strong>幻读</strong>，next key lock</p>\n<p>serializable：可以解决以上所有问题。他存在的问题就是慢……</p>\n<h2 id=\"锁\"><a href=\"#锁\" class=\"headerlink\" title=\"锁\"></a>锁</h2><p>InnoDB存储引擎实现了如下两种标准的行级锁：</p>\n<ul>\n<li><p>共享锁（S Lock），允许事务读一行数据。</p>\n</li>\n<li><p>排他锁（X Lock），允许事务删除或更新一行数据。</p>\n</li>\n</ul>\n<p>如果一个事务T1已经获得了行r的共享锁，那么另外的事务T2可以立即获得行r的共享锁，因为读取并没有改变行r的数据，称这种情况为锁兼容（Lock Compatible）。但若有其他的事务T3想获得行r的排他锁，则其必须等待事务T1、T2释放行r上的共享锁——这种情况称为锁不兼容</p>\n<p>InnoDB存储引擎有3种行锁的算法，其分别是：</p>\n<ul>\n<li><p>Record Lock：单个行记录上的锁</p>\n</li>\n<li><p>Gap Lock：间隙锁，锁定一个范围，但不包含记录本身</p>\n</li>\n<li><p>Next-Key Lock∶Gap Lock+Record Lock，锁定一个范围，并且锁定记录本身</p>\n</li>\n</ul>\n<p>Record Lock总是会去锁住索引记录，如果InnoDB存储引擎表在建立的时候没有设置任何一个索引，那么这时InnoDB存储引擎会使用隐式的主键来进行锁定。</p>\n<p>Next-Key Lock是结合了Gap Lock和Record Lock的一种锁定算法，在Next-Key Lock算法下，InnoDB对于行的查询都是采用这种锁定算法。</p>\n"},{"title":"DevTools的bug","excerpt":"","comments":1,"date":"2022-03-02T10:30:52.000Z","_content":"\nhttps://www.bilibili.com/video/BV1cZ4y1C717?spm_id_from=333.999.0.0\n\nDevTools有一个类加载器，叫做Restart ClassLoader，负责加载我们src中自己写的类，但是依赖的jar包中的类，它不会加载，而是由Application ClassLoader加载。","source":"_posts/2022-03-02-kongzheng1993-DevTools.md","raw":"---\ntitle: DevTools的bug\nexcerpt: 'java'\ntags: [java]\ncategories: [java]\ncomments: true\ndate: 2022-03-02 18:30:52\n---\n\nhttps://www.bilibili.com/video/BV1cZ4y1C717?spm_id_from=333.999.0.0\n\nDevTools有一个类加载器，叫做Restart ClassLoader，负责加载我们src中自己写的类，但是依赖的jar包中的类，它不会加载，而是由Application ClassLoader加载。","slug":"kongzheng1993-DevTools","published":1,"updated":"2023-03-08T07:05:58.820Z","layout":"post","photos":[],"link":"","_id":"clg0k2amg008gt26f40jhfyif","content":"<p><a href=\"https://www.bilibili.com/video/BV1cZ4y1C717?spm_id_from=333.999.0.0\" target=\"_blank\" rel=\"noopener\">https://www.bilibili.com/video/BV1cZ4y1C717?spm_id_from=333.999.0.0</a></p>\n<p>DevTools有一个类加载器，叫做Restart ClassLoader，负责加载我们src中自己写的类，但是依赖的jar包中的类，它不会加载，而是由Application ClassLoader加载。</p>\n","site":{"data":{}},"more":"<p><a href=\"https://www.bilibili.com/video/BV1cZ4y1C717?spm_id_from=333.999.0.0\" target=\"_blank\" rel=\"noopener\">https://www.bilibili.com/video/BV1cZ4y1C717?spm_id_from=333.999.0.0</a></p>\n<p>DevTools有一个类加载器，叫做Restart ClassLoader，负责加载我们src中自己写的类，但是依赖的jar包中的类，它不会加载，而是由Application ClassLoader加载。</p>\n"},{"title":"包装类“==”的问题","excerpt":"","comments":1,"date":"2022-03-09T10:30:52.000Z","_content":"\n这个知识点或许是我忘了。。\n\n最近重构了一个工程，把里面两个model合成了一个，但是没有注意被我删除的model-A中的一个type属性是int类型的，而我保留下来的另一个model-B中这个属性是Integer的。所有业务代码中使用的model-A被我全部替换为model-B后，有一个type和Integer类型枚举“==”的地方出问题了，之前相等的地方case现在返回不相等了。当然第一时刻想到的就是对象之间“==”比较的是内存地址/内存的引用，bulabula，比较的话肯定不一致。\n\n修改为equals后解决问题。\n\n我想聊的并不是引用类型和基本类型之间的关系。而是下面的问题：\n\n<img src=\"Integer.png\"/>\n\n这个图中，一个Integer的a，不等于另一个new Interger(1)，但是却等于另一个Integer.valueOf(1)，也等于一个int的1。\n\n这就是因为Integer中有一个缓存IntegerCache，为了让-128到127自动装箱后的对象有相同的语意。\n\n```java\n    /**\n     * Cache to support the object identity semantics of autoboxing for values between\n     * -128 and 127 (inclusive) as required by JLS.\n     *\n     * The cache is initialized on first usage.  The size of the cache\n     * may be controlled by the {@code -XX:AutoBoxCacheMax=<size>} option.\n     * During VM initialization, java.lang.Integer.IntegerCache.high property\n     * may be set and saved in the private system properties in the\n     * sun.misc.VM class.\n     */\n\n    private static class IntegerCache {\n        static final int low = -128;\n        static final int high;\n        static final Integer cache[];\n\n        static {\n            // high value may be configured by property\n            int h = 127;\n            String integerCacheHighPropValue =\n                sun.misc.VM.getSavedProperty(\"java.lang.Integer.IntegerCache.high\");\n            if (integerCacheHighPropValue != null) {\n                try {\n                    int i = parseInt(integerCacheHighPropValue);\n                    i = Math.max(i, 127);\n                    // Maximum array size is Integer.MAX_VALUE\n                    h = Math.min(i, Integer.MAX_VALUE - (-low) -1);\n                } catch( NumberFormatException nfe) {\n                    // If the property cannot be parsed into an int, ignore it.\n                }\n            }\n            high = h;\n\n            cache = new Integer[(high - low) + 1];\n            int j = low;\n            for(int k = 0; k < cache.length; k++)\n                cache[k] = new Integer(j++);\n\n            // range [-128, 127] must be interned (JLS7 5.1.7)\n            assert IntegerCache.high >= 127;\n        }\n```\n\n下面是Integer#valueOf方法。当使用valueOf获取一个Integer对象时，如果值在缓存区间中，就直接使用缓存中的对象，所以上门说的a就等于Integer.valueOf(1)了，Long相同，也是维护了-128到127的缓存\n\n```java\n\n    /**\n     * Returns an {@code Integer} instance representing the specified\n     * {@code int} value.  If a new {@code Integer} instance is not\n     * required, this method should generally be used in preference to\n     * the constructor {@link #Integer(int)}, as this method is likely\n     * to yield significantly better space and time performance by\n     * caching frequently requested values.\n     *\n     * This method will always cache values in the range -128 to 127,\n     * inclusive, and may cache other values outside of this range.\n     *\n     * @param  i an {@code int} value.\n     * @return an {@code Integer} instance representing {@code i}.\n     * @since  1.5\n     */\n    public static Integer valueOf(int i) {\n        if (i >= IntegerCache.low && i <= IntegerCache.high)\n            return IntegerCache.cache[i + (-IntegerCache.low)];\n        return new Integer(i);\n    }\n\n```","source":"_posts/2022-03-09-kongzheng1993-包装类==的问题.md","raw":"---\ntitle: 包装类“==”的问题\nexcerpt: 'JDK'\ntags: [JDK]\ncategories: [JDK]\ncomments: true\ndate: 2022-03-09 18:30:52\n---\n\n这个知识点或许是我忘了。。\n\n最近重构了一个工程，把里面两个model合成了一个，但是没有注意被我删除的model-A中的一个type属性是int类型的，而我保留下来的另一个model-B中这个属性是Integer的。所有业务代码中使用的model-A被我全部替换为model-B后，有一个type和Integer类型枚举“==”的地方出问题了，之前相等的地方case现在返回不相等了。当然第一时刻想到的就是对象之间“==”比较的是内存地址/内存的引用，bulabula，比较的话肯定不一致。\n\n修改为equals后解决问题。\n\n我想聊的并不是引用类型和基本类型之间的关系。而是下面的问题：\n\n<img src=\"Integer.png\"/>\n\n这个图中，一个Integer的a，不等于另一个new Interger(1)，但是却等于另一个Integer.valueOf(1)，也等于一个int的1。\n\n这就是因为Integer中有一个缓存IntegerCache，为了让-128到127自动装箱后的对象有相同的语意。\n\n```java\n    /**\n     * Cache to support the object identity semantics of autoboxing for values between\n     * -128 and 127 (inclusive) as required by JLS.\n     *\n     * The cache is initialized on first usage.  The size of the cache\n     * may be controlled by the {@code -XX:AutoBoxCacheMax=<size>} option.\n     * During VM initialization, java.lang.Integer.IntegerCache.high property\n     * may be set and saved in the private system properties in the\n     * sun.misc.VM class.\n     */\n\n    private static class IntegerCache {\n        static final int low = -128;\n        static final int high;\n        static final Integer cache[];\n\n        static {\n            // high value may be configured by property\n            int h = 127;\n            String integerCacheHighPropValue =\n                sun.misc.VM.getSavedProperty(\"java.lang.Integer.IntegerCache.high\");\n            if (integerCacheHighPropValue != null) {\n                try {\n                    int i = parseInt(integerCacheHighPropValue);\n                    i = Math.max(i, 127);\n                    // Maximum array size is Integer.MAX_VALUE\n                    h = Math.min(i, Integer.MAX_VALUE - (-low) -1);\n                } catch( NumberFormatException nfe) {\n                    // If the property cannot be parsed into an int, ignore it.\n                }\n            }\n            high = h;\n\n            cache = new Integer[(high - low) + 1];\n            int j = low;\n            for(int k = 0; k < cache.length; k++)\n                cache[k] = new Integer(j++);\n\n            // range [-128, 127] must be interned (JLS7 5.1.7)\n            assert IntegerCache.high >= 127;\n        }\n```\n\n下面是Integer#valueOf方法。当使用valueOf获取一个Integer对象时，如果值在缓存区间中，就直接使用缓存中的对象，所以上门说的a就等于Integer.valueOf(1)了，Long相同，也是维护了-128到127的缓存\n\n```java\n\n    /**\n     * Returns an {@code Integer} instance representing the specified\n     * {@code int} value.  If a new {@code Integer} instance is not\n     * required, this method should generally be used in preference to\n     * the constructor {@link #Integer(int)}, as this method is likely\n     * to yield significantly better space and time performance by\n     * caching frequently requested values.\n     *\n     * This method will always cache values in the range -128 to 127,\n     * inclusive, and may cache other values outside of this range.\n     *\n     * @param  i an {@code int} value.\n     * @return an {@code Integer} instance representing {@code i}.\n     * @since  1.5\n     */\n    public static Integer valueOf(int i) {\n        if (i >= IntegerCache.low && i <= IntegerCache.high)\n            return IntegerCache.cache[i + (-IntegerCache.low)];\n        return new Integer(i);\n    }\n\n```","slug":"kongzheng1993-包装类==的问题","published":1,"updated":"2023-03-08T07:05:58.823Z","layout":"post","photos":[],"link":"","_id":"clg0k2amk008jt26fn0lsekaz","content":"<p>这个知识点或许是我忘了。。</p>\n<p>最近重构了一个工程，把里面两个model合成了一个，但是没有注意被我删除的model-A中的一个type属性是int类型的，而我保留下来的另一个model-B中这个属性是Integer的。所有业务代码中使用的model-A被我全部替换为model-B后，有一个type和Integer类型枚举“==”的地方出问题了，之前相等的地方case现在返回不相等了。当然第一时刻想到的就是对象之间“==”比较的是内存地址/内存的引用，bulabula，比较的话肯定不一致。</p>\n<p>修改为equals后解决问题。</p>\n<p>我想聊的并不是引用类型和基本类型之间的关系。而是下面的问题：</p>\n<img src=\"/2022/03/09/kongzheng1993-包装类==的问题/Integer.png\">\n\n<p>这个图中，一个Integer的a，不等于另一个new Interger(1)，但是却等于另一个Integer.valueOf(1)，也等于一个int的1。</p>\n<p>这就是因为Integer中有一个缓存IntegerCache，为了让-128到127自动装箱后的对象有相同的语意。</p>\n<pre><code class=\"java\">    /**\n     * Cache to support the object identity semantics of autoboxing for values between\n     * -128 and 127 (inclusive) as required by JLS.\n     *\n     * The cache is initialized on first usage.  The size of the cache\n     * may be controlled by the {@code -XX:AutoBoxCacheMax=&lt;size&gt;} option.\n     * During VM initialization, java.lang.Integer.IntegerCache.high property\n     * may be set and saved in the private system properties in the\n     * sun.misc.VM class.\n     */\n\n    private static class IntegerCache {\n        static final int low = -128;\n        static final int high;\n        static final Integer cache[];\n\n        static {\n            // high value may be configured by property\n            int h = 127;\n            String integerCacheHighPropValue =\n                sun.misc.VM.getSavedProperty(&quot;java.lang.Integer.IntegerCache.high&quot;);\n            if (integerCacheHighPropValue != null) {\n                try {\n                    int i = parseInt(integerCacheHighPropValue);\n                    i = Math.max(i, 127);\n                    // Maximum array size is Integer.MAX_VALUE\n                    h = Math.min(i, Integer.MAX_VALUE - (-low) -1);\n                } catch( NumberFormatException nfe) {\n                    // If the property cannot be parsed into an int, ignore it.\n                }\n            }\n            high = h;\n\n            cache = new Integer[(high - low) + 1];\n            int j = low;\n            for(int k = 0; k &lt; cache.length; k++)\n                cache[k] = new Integer(j++);\n\n            // range [-128, 127] must be interned (JLS7 5.1.7)\n            assert IntegerCache.high &gt;= 127;\n        }</code></pre>\n<p>下面是Integer#valueOf方法。当使用valueOf获取一个Integer对象时，如果值在缓存区间中，就直接使用缓存中的对象，所以上门说的a就等于Integer.valueOf(1)了，Long相同，也是维护了-128到127的缓存</p>\n<pre><code class=\"java\">\n    /**\n     * Returns an {@code Integer} instance representing the specified\n     * {@code int} value.  If a new {@code Integer} instance is not\n     * required, this method should generally be used in preference to\n     * the constructor {@link #Integer(int)}, as this method is likely\n     * to yield significantly better space and time performance by\n     * caching frequently requested values.\n     *\n     * This method will always cache values in the range -128 to 127,\n     * inclusive, and may cache other values outside of this range.\n     *\n     * @param  i an {@code int} value.\n     * @return an {@code Integer} instance representing {@code i}.\n     * @since  1.5\n     */\n    public static Integer valueOf(int i) {\n        if (i &gt;= IntegerCache.low &amp;&amp; i &lt;= IntegerCache.high)\n            return IntegerCache.cache[i + (-IntegerCache.low)];\n        return new Integer(i);\n    }\n</code></pre>\n","site":{"data":{}},"more":"<p>这个知识点或许是我忘了。。</p>\n<p>最近重构了一个工程，把里面两个model合成了一个，但是没有注意被我删除的model-A中的一个type属性是int类型的，而我保留下来的另一个model-B中这个属性是Integer的。所有业务代码中使用的model-A被我全部替换为model-B后，有一个type和Integer类型枚举“==”的地方出问题了，之前相等的地方case现在返回不相等了。当然第一时刻想到的就是对象之间“==”比较的是内存地址/内存的引用，bulabula，比较的话肯定不一致。</p>\n<p>修改为equals后解决问题。</p>\n<p>我想聊的并不是引用类型和基本类型之间的关系。而是下面的问题：</p>\n<img src=\"/2022/03/09/kongzheng1993-包装类==的问题/Integer.png\">\n\n<p>这个图中，一个Integer的a，不等于另一个new Interger(1)，但是却等于另一个Integer.valueOf(1)，也等于一个int的1。</p>\n<p>这就是因为Integer中有一个缓存IntegerCache，为了让-128到127自动装箱后的对象有相同的语意。</p>\n<pre><code class=\"java\">    /**\n     * Cache to support the object identity semantics of autoboxing for values between\n     * -128 and 127 (inclusive) as required by JLS.\n     *\n     * The cache is initialized on first usage.  The size of the cache\n     * may be controlled by the {@code -XX:AutoBoxCacheMax=&lt;size&gt;} option.\n     * During VM initialization, java.lang.Integer.IntegerCache.high property\n     * may be set and saved in the private system properties in the\n     * sun.misc.VM class.\n     */\n\n    private static class IntegerCache {\n        static final int low = -128;\n        static final int high;\n        static final Integer cache[];\n\n        static {\n            // high value may be configured by property\n            int h = 127;\n            String integerCacheHighPropValue =\n                sun.misc.VM.getSavedProperty(&quot;java.lang.Integer.IntegerCache.high&quot;);\n            if (integerCacheHighPropValue != null) {\n                try {\n                    int i = parseInt(integerCacheHighPropValue);\n                    i = Math.max(i, 127);\n                    // Maximum array size is Integer.MAX_VALUE\n                    h = Math.min(i, Integer.MAX_VALUE - (-low) -1);\n                } catch( NumberFormatException nfe) {\n                    // If the property cannot be parsed into an int, ignore it.\n                }\n            }\n            high = h;\n\n            cache = new Integer[(high - low) + 1];\n            int j = low;\n            for(int k = 0; k &lt; cache.length; k++)\n                cache[k] = new Integer(j++);\n\n            // range [-128, 127] must be interned (JLS7 5.1.7)\n            assert IntegerCache.high &gt;= 127;\n        }</code></pre>\n<p>下面是Integer#valueOf方法。当使用valueOf获取一个Integer对象时，如果值在缓存区间中，就直接使用缓存中的对象，所以上门说的a就等于Integer.valueOf(1)了，Long相同，也是维护了-128到127的缓存</p>\n<pre><code class=\"java\">\n    /**\n     * Returns an {@code Integer} instance representing the specified\n     * {@code int} value.  If a new {@code Integer} instance is not\n     * required, this method should generally be used in preference to\n     * the constructor {@link #Integer(int)}, as this method is likely\n     * to yield significantly better space and time performance by\n     * caching frequently requested values.\n     *\n     * This method will always cache values in the range -128 to 127,\n     * inclusive, and may cache other values outside of this range.\n     *\n     * @param  i an {@code int} value.\n     * @return an {@code Integer} instance representing {@code i}.\n     * @since  1.5\n     */\n    public static Integer valueOf(int i) {\n        if (i &gt;= IntegerCache.low &amp;&amp; i &lt;= IntegerCache.high)\n            return IntegerCache.cache[i + (-IntegerCache.low)];\n        return new Integer(i);\n    }\n</code></pre>\n"},{"title":"spring.provides是什么？","excerpt":"","comments":1,"date":"2022-05-06T10:30:52.000Z","_content":"\n今天看代码发现很多springboot的starter的META-INF/目录下都有一个spring.provides文件，本来想找spring.factories的。查了很多资料，原来是spring的大佬都用STS开发，STS会用到这个文件，这个文件也是他们为了STS创建的，为了创建索引。\n\n[spring-boot issues](https://github.com/spring-projects/spring-boot/issues/1926)","source":"_posts/2022-05-06-kongzheng1993-spring_provides.md","raw":"---\ntitle: spring.provides是什么？\nexcerpt: 'Spring'\ntags: [SpringBoot]\ncategories: [SpringBoot]\ncomments: true\ndate: 2022-05-06 18:30:52\n---\n\n今天看代码发现很多springboot的starter的META-INF/目录下都有一个spring.provides文件，本来想找spring.factories的。查了很多资料，原来是spring的大佬都用STS开发，STS会用到这个文件，这个文件也是他们为了STS创建的，为了创建索引。\n\n[spring-boot issues](https://github.com/spring-projects/spring-boot/issues/1926)","slug":"kongzheng1993-spring_provides","published":1,"updated":"2023-03-08T07:05:58.832Z","layout":"post","photos":[],"link":"","_id":"clg0k2amp008ot26f2zjr6ibs","content":"<p>今天看代码发现很多springboot的starter的META-INF/目录下都有一个spring.provides文件，本来想找spring.factories的。查了很多资料，原来是spring的大佬都用STS开发，STS会用到这个文件，这个文件也是他们为了STS创建的，为了创建索引。</p>\n<p><a href=\"https://github.com/spring-projects/spring-boot/issues/1926\" target=\"_blank\" rel=\"noopener\">spring-boot issues</a></p>\n","site":{"data":{}},"more":"<p>今天看代码发现很多springboot的starter的META-INF/目录下都有一个spring.provides文件，本来想找spring.factories的。查了很多资料，原来是spring的大佬都用STS开发，STS会用到这个文件，这个文件也是他们为了STS创建的，为了创建索引。</p>\n<p><a href=\"https://github.com/spring-projects/spring-boot/issues/1926\" target=\"_blank\" rel=\"noopener\">spring-boot issues</a></p>\n"},{"title":"什么！JVM连报错都优化了？","excerpt":"","comments":1,"date":"2022-04-15T10:30:52.000Z","_content":"\n\n今天查一个生产问题，发现很奇怪的NPE，没有打印堆栈信息，幸好几天前也发生过类似的问题，找到了堆栈信息，修复了问题。\n\n今天查了一些资料，JVM竟然有一个Fast Throw的机制。为了避免同类异常频繁抛出，造成性能下降。\n\n相关JDK源码如下：\n\n```java\n// If this throw happens frequently, an uncommon trap might cause\n  // a performance pothole.  If there is a local exception handler,\n  // and if this particular bytecode appears to be deoptimizing often,\n  // let us handle the throw inline, with a preconstructed instance.\n  // Note:   If the deopt count has blown up, the uncommon trap\n  // runtime is going to flush this nmethod, not matter what.\n  if (treat_throw_as_hot\n      && (!StackTraceInThrowable || OmitStackTraceInFastThrow)) {\n    // If the throw is local, we use a pre-existing instance and\n    // punt on the backtrace.  This would lead to a missing backtrace\n    // (a repeat of 4292742) if the backtrace object is ever asked\n    // for its backtrace.\n    // Fixing this remaining case of 4292742 requires some flavor of\n    // escape analysis.  Leave that for the future.\n    ciInstance* ex_obj = NULL;\n    switch (reason) {\n    case Deoptimization::Reason_null_check:\n      ex_obj = env()->NullPointerException_instance();\n      break;\n    case Deoptimization::Reason_div0_check:\n      ex_obj = env()->ArithmeticException_instance();\n      break;\n    case Deoptimization::Reason_range_check:\n      ex_obj = env()->ArrayIndexOutOfBoundsException_instance();\n      break;\n    case Deoptimization::Reason_class_check:\n      if (java_bc() == Bytecodes::_aastore) {\n        ex_obj = env()->ArrayStoreException_instance();\n      } else {\n        ex_obj = env()->ClassCastException_instance();\n      }\n      break;\n    default:\n      break;\n    }\n}\n```\n\n从上面的代码可以看出，满足以下四种情况，异常会被预定义的无堆栈异常替换：\n\n- tread_throw_as_hot，也就是hot exception，被抛出很多次的异常类型\n    - 同样的异常抛出太多\n    - 同样的异常抛出次数不为0，以及方法拥有local-exception-handler，那么将被标记为hot\n- !StackTraceInThrowable || OmitStackTraceInFastThrow, 由于这两个参数值默认都是true，所以默认整体条件满足。\n- 异常是设定内的五种异常\n    - NullPointerException\n    - ArithmeticException\n    - ArrayIndexOutOfBoundsException\n    - ArrayStoreException\n    - ClassCastException\n- 补充：只能是implict exception。stackoverflow上的一个回答说这里的异常要是implict exception, 也就是说代码里面直接throw new NullPointerException() 这种异常是不会被替换的。亲测符合预期。\n\n### 关闭Fast Throw\n\n启动增加-XX:-OmitStackTraceInFastThrow这个参数就可以关闭JIT后特定异常fast throw\n\n### 复现\n\n```java\npublic class Test{\n    public static void main(String... args) {\n        String a = null;\n        for (int i = 0; i< 700000; i++) {\n            try {\n                // System.out.println(1111);\n                a.toString();\n            } catch (Exception e) {\n                // System.out.println(2222);\n                e.printStackTrace();\n            }\n        }\n    }\n}\n```\n\n编译后执行：\n\n```shell\njava Test\n```\n\n结果：\n\n<img src='noParam.png'/>\n\n\n关闭fast throw执行：\n\n```shell\njava -XX:-OmitStackTraceInFastThrow Test\n```\n\n结果：\n<img src='param.png'>","source":"_posts/2022-04-15-kongzheng1993-FastThrow.md","raw":"---\ntitle: 什么！JVM连报错都优化了？\nexcerpt: 'fast throw'\ntags: [JVM]\ncategories: [JVM]\ncomments: true\ndate: 2022-04-15 18:30:52\n---\n\n\n今天查一个生产问题，发现很奇怪的NPE，没有打印堆栈信息，幸好几天前也发生过类似的问题，找到了堆栈信息，修复了问题。\n\n今天查了一些资料，JVM竟然有一个Fast Throw的机制。为了避免同类异常频繁抛出，造成性能下降。\n\n相关JDK源码如下：\n\n```java\n// If this throw happens frequently, an uncommon trap might cause\n  // a performance pothole.  If there is a local exception handler,\n  // and if this particular bytecode appears to be deoptimizing often,\n  // let us handle the throw inline, with a preconstructed instance.\n  // Note:   If the deopt count has blown up, the uncommon trap\n  // runtime is going to flush this nmethod, not matter what.\n  if (treat_throw_as_hot\n      && (!StackTraceInThrowable || OmitStackTraceInFastThrow)) {\n    // If the throw is local, we use a pre-existing instance and\n    // punt on the backtrace.  This would lead to a missing backtrace\n    // (a repeat of 4292742) if the backtrace object is ever asked\n    // for its backtrace.\n    // Fixing this remaining case of 4292742 requires some flavor of\n    // escape analysis.  Leave that for the future.\n    ciInstance* ex_obj = NULL;\n    switch (reason) {\n    case Deoptimization::Reason_null_check:\n      ex_obj = env()->NullPointerException_instance();\n      break;\n    case Deoptimization::Reason_div0_check:\n      ex_obj = env()->ArithmeticException_instance();\n      break;\n    case Deoptimization::Reason_range_check:\n      ex_obj = env()->ArrayIndexOutOfBoundsException_instance();\n      break;\n    case Deoptimization::Reason_class_check:\n      if (java_bc() == Bytecodes::_aastore) {\n        ex_obj = env()->ArrayStoreException_instance();\n      } else {\n        ex_obj = env()->ClassCastException_instance();\n      }\n      break;\n    default:\n      break;\n    }\n}\n```\n\n从上面的代码可以看出，满足以下四种情况，异常会被预定义的无堆栈异常替换：\n\n- tread_throw_as_hot，也就是hot exception，被抛出很多次的异常类型\n    - 同样的异常抛出太多\n    - 同样的异常抛出次数不为0，以及方法拥有local-exception-handler，那么将被标记为hot\n- !StackTraceInThrowable || OmitStackTraceInFastThrow, 由于这两个参数值默认都是true，所以默认整体条件满足。\n- 异常是设定内的五种异常\n    - NullPointerException\n    - ArithmeticException\n    - ArrayIndexOutOfBoundsException\n    - ArrayStoreException\n    - ClassCastException\n- 补充：只能是implict exception。stackoverflow上的一个回答说这里的异常要是implict exception, 也就是说代码里面直接throw new NullPointerException() 这种异常是不会被替换的。亲测符合预期。\n\n### 关闭Fast Throw\n\n启动增加-XX:-OmitStackTraceInFastThrow这个参数就可以关闭JIT后特定异常fast throw\n\n### 复现\n\n```java\npublic class Test{\n    public static void main(String... args) {\n        String a = null;\n        for (int i = 0; i< 700000; i++) {\n            try {\n                // System.out.println(1111);\n                a.toString();\n            } catch (Exception e) {\n                // System.out.println(2222);\n                e.printStackTrace();\n            }\n        }\n    }\n}\n```\n\n编译后执行：\n\n```shell\njava Test\n```\n\n结果：\n\n<img src='noParam.png'/>\n\n\n关闭fast throw执行：\n\n```shell\njava -XX:-OmitStackTraceInFastThrow Test\n```\n\n结果：\n<img src='param.png'>","slug":"kongzheng1993-FastThrow","published":1,"updated":"2023-03-08T07:05:58.829Z","layout":"post","photos":[],"link":"","_id":"clg0k2amq008rt26f7vnybqjh","content":"<p>今天查一个生产问题，发现很奇怪的NPE，没有打印堆栈信息，幸好几天前也发生过类似的问题，找到了堆栈信息，修复了问题。</p>\n<p>今天查了一些资料，JVM竟然有一个Fast Throw的机制。为了避免同类异常频繁抛出，造成性能下降。</p>\n<p>相关JDK源码如下：</p>\n<pre><code class=\"java\">// If this throw happens frequently, an uncommon trap might cause\n  // a performance pothole.  If there is a local exception handler,\n  // and if this particular bytecode appears to be deoptimizing often,\n  // let us handle the throw inline, with a preconstructed instance.\n  // Note:   If the deopt count has blown up, the uncommon trap\n  // runtime is going to flush this nmethod, not matter what.\n  if (treat_throw_as_hot\n      &amp;&amp; (!StackTraceInThrowable || OmitStackTraceInFastThrow)) {\n    // If the throw is local, we use a pre-existing instance and\n    // punt on the backtrace.  This would lead to a missing backtrace\n    // (a repeat of 4292742) if the backtrace object is ever asked\n    // for its backtrace.\n    // Fixing this remaining case of 4292742 requires some flavor of\n    // escape analysis.  Leave that for the future.\n    ciInstance* ex_obj = NULL;\n    switch (reason) {\n    case Deoptimization::Reason_null_check:\n      ex_obj = env()-&gt;NullPointerException_instance();\n      break;\n    case Deoptimization::Reason_div0_check:\n      ex_obj = env()-&gt;ArithmeticException_instance();\n      break;\n    case Deoptimization::Reason_range_check:\n      ex_obj = env()-&gt;ArrayIndexOutOfBoundsException_instance();\n      break;\n    case Deoptimization::Reason_class_check:\n      if (java_bc() == Bytecodes::_aastore) {\n        ex_obj = env()-&gt;ArrayStoreException_instance();\n      } else {\n        ex_obj = env()-&gt;ClassCastException_instance();\n      }\n      break;\n    default:\n      break;\n    }\n}</code></pre>\n<p>从上面的代码可以看出，满足以下四种情况，异常会被预定义的无堆栈异常替换：</p>\n<ul>\n<li>tread_throw_as_hot，也就是hot exception，被抛出很多次的异常类型<ul>\n<li>同样的异常抛出太多</li>\n<li>同样的异常抛出次数不为0，以及方法拥有local-exception-handler，那么将被标记为hot</li>\n</ul>\n</li>\n<li>!StackTraceInThrowable || OmitStackTraceInFastThrow, 由于这两个参数值默认都是true，所以默认整体条件满足。</li>\n<li>异常是设定内的五种异常<ul>\n<li>NullPointerException</li>\n<li>ArithmeticException</li>\n<li>ArrayIndexOutOfBoundsException</li>\n<li>ArrayStoreException</li>\n<li>ClassCastException</li>\n</ul>\n</li>\n<li>补充：只能是implict exception。stackoverflow上的一个回答说这里的异常要是implict exception, 也就是说代码里面直接throw new NullPointerException() 这种异常是不会被替换的。亲测符合预期。</li>\n</ul>\n<h3 id=\"关闭Fast-Throw\"><a href=\"#关闭Fast-Throw\" class=\"headerlink\" title=\"关闭Fast Throw\"></a>关闭Fast Throw</h3><p>启动增加-XX:-OmitStackTraceInFastThrow这个参数就可以关闭JIT后特定异常fast throw</p>\n<h3 id=\"复现\"><a href=\"#复现\" class=\"headerlink\" title=\"复现\"></a>复现</h3><pre><code class=\"java\">public class Test{\n    public static void main(String... args) {\n        String a = null;\n        for (int i = 0; i&lt; 700000; i++) {\n            try {\n                // System.out.println(1111);\n                a.toString();\n            } catch (Exception e) {\n                // System.out.println(2222);\n                e.printStackTrace();\n            }\n        }\n    }\n}</code></pre>\n<p>编译后执行：</p>\n<pre><code class=\"shell\">java Test</code></pre>\n<p>结果：</p>\n<img src=\"/2022/04/15/kongzheng1993-FastThrow/noParam.png\">\n\n\n<p>关闭fast throw执行：</p>\n<pre><code class=\"shell\">java -XX:-OmitStackTraceInFastThrow Test</code></pre>\n<p>结果：<br><img src=\"/2022/04/15/kongzheng1993-FastThrow/param.png\"></p>\n","site":{"data":{}},"more":"<p>今天查一个生产问题，发现很奇怪的NPE，没有打印堆栈信息，幸好几天前也发生过类似的问题，找到了堆栈信息，修复了问题。</p>\n<p>今天查了一些资料，JVM竟然有一个Fast Throw的机制。为了避免同类异常频繁抛出，造成性能下降。</p>\n<p>相关JDK源码如下：</p>\n<pre><code class=\"java\">// If this throw happens frequently, an uncommon trap might cause\n  // a performance pothole.  If there is a local exception handler,\n  // and if this particular bytecode appears to be deoptimizing often,\n  // let us handle the throw inline, with a preconstructed instance.\n  // Note:   If the deopt count has blown up, the uncommon trap\n  // runtime is going to flush this nmethod, not matter what.\n  if (treat_throw_as_hot\n      &amp;&amp; (!StackTraceInThrowable || OmitStackTraceInFastThrow)) {\n    // If the throw is local, we use a pre-existing instance and\n    // punt on the backtrace.  This would lead to a missing backtrace\n    // (a repeat of 4292742) if the backtrace object is ever asked\n    // for its backtrace.\n    // Fixing this remaining case of 4292742 requires some flavor of\n    // escape analysis.  Leave that for the future.\n    ciInstance* ex_obj = NULL;\n    switch (reason) {\n    case Deoptimization::Reason_null_check:\n      ex_obj = env()-&gt;NullPointerException_instance();\n      break;\n    case Deoptimization::Reason_div0_check:\n      ex_obj = env()-&gt;ArithmeticException_instance();\n      break;\n    case Deoptimization::Reason_range_check:\n      ex_obj = env()-&gt;ArrayIndexOutOfBoundsException_instance();\n      break;\n    case Deoptimization::Reason_class_check:\n      if (java_bc() == Bytecodes::_aastore) {\n        ex_obj = env()-&gt;ArrayStoreException_instance();\n      } else {\n        ex_obj = env()-&gt;ClassCastException_instance();\n      }\n      break;\n    default:\n      break;\n    }\n}</code></pre>\n<p>从上面的代码可以看出，满足以下四种情况，异常会被预定义的无堆栈异常替换：</p>\n<ul>\n<li>tread_throw_as_hot，也就是hot exception，被抛出很多次的异常类型<ul>\n<li>同样的异常抛出太多</li>\n<li>同样的异常抛出次数不为0，以及方法拥有local-exception-handler，那么将被标记为hot</li>\n</ul>\n</li>\n<li>!StackTraceInThrowable || OmitStackTraceInFastThrow, 由于这两个参数值默认都是true，所以默认整体条件满足。</li>\n<li>异常是设定内的五种异常<ul>\n<li>NullPointerException</li>\n<li>ArithmeticException</li>\n<li>ArrayIndexOutOfBoundsException</li>\n<li>ArrayStoreException</li>\n<li>ClassCastException</li>\n</ul>\n</li>\n<li>补充：只能是implict exception。stackoverflow上的一个回答说这里的异常要是implict exception, 也就是说代码里面直接throw new NullPointerException() 这种异常是不会被替换的。亲测符合预期。</li>\n</ul>\n<h3 id=\"关闭Fast-Throw\"><a href=\"#关闭Fast-Throw\" class=\"headerlink\" title=\"关闭Fast Throw\"></a>关闭Fast Throw</h3><p>启动增加-XX:-OmitStackTraceInFastThrow这个参数就可以关闭JIT后特定异常fast throw</p>\n<h3 id=\"复现\"><a href=\"#复现\" class=\"headerlink\" title=\"复现\"></a>复现</h3><pre><code class=\"java\">public class Test{\n    public static void main(String... args) {\n        String a = null;\n        for (int i = 0; i&lt; 700000; i++) {\n            try {\n                // System.out.println(1111);\n                a.toString();\n            } catch (Exception e) {\n                // System.out.println(2222);\n                e.printStackTrace();\n            }\n        }\n    }\n}</code></pre>\n<p>编译后执行：</p>\n<pre><code class=\"shell\">java Test</code></pre>\n<p>结果：</p>\n<img src=\"/2022/04/15/kongzheng1993-FastThrow/noParam.png\">\n\n\n<p>关闭fast throw执行：</p>\n<pre><code class=\"shell\">java -XX:-OmitStackTraceInFastThrow Test</code></pre>\n<p>结果：<br><img src=\"/2022/04/15/kongzheng1993-FastThrow/param.png\"></p>\n"},{"title":"volatile","excerpt":"","comments":1,"date":"2022-06-12T10:30:52.000Z","_content":"\n**volatile是轻量级的synchronized，它在多处理器开发中保证了共享变量的“可见性”。** --《Java并发编程的艺术》\n\nvolatile比synchronized的使用和执行成本更低，因为它不会引起线程上下文的切换和调度。\n\n## volatile是如何保证可见性的？\n\n在X86处理器下通过工具获取JIT编译器生成的汇编语言指令来查看对volatile进行写操作时，会多出一行汇编代码，Lock前缀。而Lock前缀的指令在多核处理器下会引发两件事情：\n- 将当前处理器缓存行的数据写回到系统内存\n- 这个写回内存的操作会使在其他CPU里缓存了该内存地址的数据无效。\n\nCPU在使用数据时，会先将数据读取到自己的缓存中（L1、L2等），然后再进行运算，但是操作完之后不一定什么时候再写回到内存。如果对声明了volatile的变量进行写操作，JVM就会向处理器发送一条Lock前缀的指令，将这个变量所在的缓存行数据写回到系统内存中。多处理器的环境下为了保证各个处理器缓存一致，就会实现缓存一致性协议，这个协议就是每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是不是过期了，当处理器发现自己缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置为无效状态。","source":"_posts/2022-06-12-kongzheng1993-volatile.md","raw":"---\ntitle: volatile\nexcerpt: '并发'\ntags: [并发]\ncategories: [并发]\ncomments: true\ndate: 2022-06-12 18:30:52\n---\n\n**volatile是轻量级的synchronized，它在多处理器开发中保证了共享变量的“可见性”。** --《Java并发编程的艺术》\n\nvolatile比synchronized的使用和执行成本更低，因为它不会引起线程上下文的切换和调度。\n\n## volatile是如何保证可见性的？\n\n在X86处理器下通过工具获取JIT编译器生成的汇编语言指令来查看对volatile进行写操作时，会多出一行汇编代码，Lock前缀。而Lock前缀的指令在多核处理器下会引发两件事情：\n- 将当前处理器缓存行的数据写回到系统内存\n- 这个写回内存的操作会使在其他CPU里缓存了该内存地址的数据无效。\n\nCPU在使用数据时，会先将数据读取到自己的缓存中（L1、L2等），然后再进行运算，但是操作完之后不一定什么时候再写回到内存。如果对声明了volatile的变量进行写操作，JVM就会向处理器发送一条Lock前缀的指令，将这个变量所在的缓存行数据写回到系统内存中。多处理器的环境下为了保证各个处理器缓存一致，就会实现缓存一致性协议，这个协议就是每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是不是过期了，当处理器发现自己缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置为无效状态。","slug":"kongzheng1993-volatile","published":1,"updated":"2023-03-08T07:05:58.832Z","layout":"post","photos":[],"link":"","_id":"clg0k2amq008wt26f55zujceo","content":"<p><strong>volatile是轻量级的synchronized，它在多处理器开发中保证了共享变量的“可见性”。</strong> –《Java并发编程的艺术》</p>\n<p>volatile比synchronized的使用和执行成本更低，因为它不会引起线程上下文的切换和调度。</p>\n<h2 id=\"volatile是如何保证可见性的？\"><a href=\"#volatile是如何保证可见性的？\" class=\"headerlink\" title=\"volatile是如何保证可见性的？\"></a>volatile是如何保证可见性的？</h2><p>在X86处理器下通过工具获取JIT编译器生成的汇编语言指令来查看对volatile进行写操作时，会多出一行汇编代码，Lock前缀。而Lock前缀的指令在多核处理器下会引发两件事情：</p>\n<ul>\n<li>将当前处理器缓存行的数据写回到系统内存</li>\n<li>这个写回内存的操作会使在其他CPU里缓存了该内存地址的数据无效。</li>\n</ul>\n<p>CPU在使用数据时，会先将数据读取到自己的缓存中（L1、L2等），然后再进行运算，但是操作完之后不一定什么时候再写回到内存。如果对声明了volatile的变量进行写操作，JVM就会向处理器发送一条Lock前缀的指令，将这个变量所在的缓存行数据写回到系统内存中。多处理器的环境下为了保证各个处理器缓存一致，就会实现缓存一致性协议，这个协议就是每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是不是过期了，当处理器发现自己缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置为无效状态。</p>\n","site":{"data":{}},"more":"<p><strong>volatile是轻量级的synchronized，它在多处理器开发中保证了共享变量的“可见性”。</strong> –《Java并发编程的艺术》</p>\n<p>volatile比synchronized的使用和执行成本更低，因为它不会引起线程上下文的切换和调度。</p>\n<h2 id=\"volatile是如何保证可见性的？\"><a href=\"#volatile是如何保证可见性的？\" class=\"headerlink\" title=\"volatile是如何保证可见性的？\"></a>volatile是如何保证可见性的？</h2><p>在X86处理器下通过工具获取JIT编译器生成的汇编语言指令来查看对volatile进行写操作时，会多出一行汇编代码，Lock前缀。而Lock前缀的指令在多核处理器下会引发两件事情：</p>\n<ul>\n<li>将当前处理器缓存行的数据写回到系统内存</li>\n<li>这个写回内存的操作会使在其他CPU里缓存了该内存地址的数据无效。</li>\n</ul>\n<p>CPU在使用数据时，会先将数据读取到自己的缓存中（L1、L2等），然后再进行运算，但是操作完之后不一定什么时候再写回到内存。如果对声明了volatile的变量进行写操作，JVM就会向处理器发送一条Lock前缀的指令，将这个变量所在的缓存行数据写回到系统内存中。多处理器的环境下为了保证各个处理器缓存一致，就会实现缓存一致性协议，这个协议就是每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是不是过期了，当处理器发现自己缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置为无效状态。</p>\n"},{"title":"主键自增的原理","excerpt":"","comments":1,"date":"2022-06-22T10:30:52.000Z","_content":"\n我们平常使用关系行数据库，总会创建一个与业务无关的主键列ID，并且这个id是自增的。记得刚工作前两年，还在用oracle数据库，oracle的自增要靠创建一个从1开始，步长为1的序列，每次要插入数据前，先通过这个序列获取id。\n\n后来开始用MySQL了，每次建表上来就是一个`id int not null primary key auto_increment`，知道这样我们insert数据的时候id为空或者0，就可以出发id自增。说实话一直也没仔细去了解这其中的原理，今天就好好盘一下。\n\n## 怎么实现自增\n\nmysql中有两个设置：自增值`auto_increment_offset`和漂移值`auto_increment_increment`（也就是步长）\n\n```shell\nmysql> show variables like 'auto_increment%';\n+--------------------------+-------+\n| Variable_name            | Value |\n+--------------------------+-------+\n| auto_increment_increment | 1     |\n| auto_increment_offset    | 1     |\n+--------------------------+-------+\n2 rows in set (0.01 sec)\n```\n\n自增的算法：从auto_increment_offset开始，以auto_increment_increment为步长，持续增加。如果插入的id为x，当前的自增值为y：\n- 如果x < y，那么这个表的自增值不变，如果x表里不存在，可以插入成功，如果存在报主键重复。\n- 如果x>=y，那么需要把当前自增值修改为x\n\n```\nmysql> create table t_test(id int not null primary key auto_increment, a varchar(20) default null );\nQuery OK, 0 rows affected (0.04 sec)\n\nmysql> insert into t_test(a) values ('test');\nQuery OK, 1 row affected (0.02 sec)\n\nmysql> select * from t_test;\n+----+------+\n| id | a    |\n+----+------+\n|  1 | test |\n+----+------+\n1 row in set (0.01 sec)\n\nmysql> insert into t_test values (3, 'test3');\nQuery OK, 1 row affected (0.03 sec)\n\nmysql> select * From t_test;\n+----+-------+\n| id | a     |\n+----+-------+\n|  1 | test  |\n|  3 | test3 |\n+----+-------+\n2 rows in set (0.00 sec)\n\nmysql> insert into t_test(a) values ('test4');\nQuery OK, 1 row affected (0.02 sec)\n\nmysql> select * From t_test;\n+----+-------+\n| id | a     |\n+----+-------+\n|  1 | test  |\n|  3 | test3 |\n|  4 | test4 |\n+----+-------+\n3 rows in set (0.00 sec)\n```\n\n## 怎么记住自增值\n\n1. MyISAM引擎的自增值保存在数据文件中\n2. InnoDB引擎的自增值，在5.7及之前的版本，自增值保存在内存里，没有持久化，每次重启后，第一次打开表的时候，都会去找max(id)，然后将max(id)+步长作为这个表当前的自增值。8.0版本以后，将自增值的变更记录在了redo log中，重启的时候依靠redo log恢复重启前的值。\n\n## 自增锁\n\n自增id锁并不是一个事务锁，而是每次申请完就马上释放，以便其他事务再申请\nMySQL5.0版本时，自增锁的范围是语句级别的，也就是一个语句申请了一个表的自增锁，这个锁会在语句执行结束后释放。\nMySQL5.1.22版本引入了一个新策略，新增参数innodb_autoinc_lock_mode，默认为1。\n    - 0表示采用5.0时的策略，语句结束后释放锁；\n    - 1表示普通insert语句，自增锁在申请之后马上释放，不用等到语句结束，而insert...select这样的批量插入数据的语句，自增锁还是要在语句结束之后才能释放。\n    - 2表示所有申请自增主键的动作都是申请后就释放锁\n\n2虽然提高了并发，但又可能造成数据不一致的问题。如果binlog_format=statement的话，两个session交替插入数据，binlog只能先记录其中一个session的日志，由于binlog记录的是statement，也就是sql，到时候根据binlog恢复数据，或者主从同步的话，id就不一致了。如果有这种情况，就应该innodb_autoinc_lock_mode设置为0或1，让批量插入的数据的语句执行完之后再释放锁。或者innodb_autoinc_lock_mode=2 && binlog_format=row，binlog不记录sql，而是记录数据修改的日志，也就不存在id不一致的问题了。\n\n\n## 主键用完了会发生什么？\n\n自增值不会再增加，再插入数据会报主键重复\n\n\nhttps://www.jb51.net/article/221895.htm","source":"_posts/2022-06-22-kongzheng1993-主键自增.md","raw":"---\ntitle: 主键自增的原理\nexcerpt: '数据库'\ntags: [数据库]\ncategories: [数据库]\ncomments: true\ndate: 2022-06-22 18:30:52\n---\n\n我们平常使用关系行数据库，总会创建一个与业务无关的主键列ID，并且这个id是自增的。记得刚工作前两年，还在用oracle数据库，oracle的自增要靠创建一个从1开始，步长为1的序列，每次要插入数据前，先通过这个序列获取id。\n\n后来开始用MySQL了，每次建表上来就是一个`id int not null primary key auto_increment`，知道这样我们insert数据的时候id为空或者0，就可以出发id自增。说实话一直也没仔细去了解这其中的原理，今天就好好盘一下。\n\n## 怎么实现自增\n\nmysql中有两个设置：自增值`auto_increment_offset`和漂移值`auto_increment_increment`（也就是步长）\n\n```shell\nmysql> show variables like 'auto_increment%';\n+--------------------------+-------+\n| Variable_name            | Value |\n+--------------------------+-------+\n| auto_increment_increment | 1     |\n| auto_increment_offset    | 1     |\n+--------------------------+-------+\n2 rows in set (0.01 sec)\n```\n\n自增的算法：从auto_increment_offset开始，以auto_increment_increment为步长，持续增加。如果插入的id为x，当前的自增值为y：\n- 如果x < y，那么这个表的自增值不变，如果x表里不存在，可以插入成功，如果存在报主键重复。\n- 如果x>=y，那么需要把当前自增值修改为x\n\n```\nmysql> create table t_test(id int not null primary key auto_increment, a varchar(20) default null );\nQuery OK, 0 rows affected (0.04 sec)\n\nmysql> insert into t_test(a) values ('test');\nQuery OK, 1 row affected (0.02 sec)\n\nmysql> select * from t_test;\n+----+------+\n| id | a    |\n+----+------+\n|  1 | test |\n+----+------+\n1 row in set (0.01 sec)\n\nmysql> insert into t_test values (3, 'test3');\nQuery OK, 1 row affected (0.03 sec)\n\nmysql> select * From t_test;\n+----+-------+\n| id | a     |\n+----+-------+\n|  1 | test  |\n|  3 | test3 |\n+----+-------+\n2 rows in set (0.00 sec)\n\nmysql> insert into t_test(a) values ('test4');\nQuery OK, 1 row affected (0.02 sec)\n\nmysql> select * From t_test;\n+----+-------+\n| id | a     |\n+----+-------+\n|  1 | test  |\n|  3 | test3 |\n|  4 | test4 |\n+----+-------+\n3 rows in set (0.00 sec)\n```\n\n## 怎么记住自增值\n\n1. MyISAM引擎的自增值保存在数据文件中\n2. InnoDB引擎的自增值，在5.7及之前的版本，自增值保存在内存里，没有持久化，每次重启后，第一次打开表的时候，都会去找max(id)，然后将max(id)+步长作为这个表当前的自增值。8.0版本以后，将自增值的变更记录在了redo log中，重启的时候依靠redo log恢复重启前的值。\n\n## 自增锁\n\n自增id锁并不是一个事务锁，而是每次申请完就马上释放，以便其他事务再申请\nMySQL5.0版本时，自增锁的范围是语句级别的，也就是一个语句申请了一个表的自增锁，这个锁会在语句执行结束后释放。\nMySQL5.1.22版本引入了一个新策略，新增参数innodb_autoinc_lock_mode，默认为1。\n    - 0表示采用5.0时的策略，语句结束后释放锁；\n    - 1表示普通insert语句，自增锁在申请之后马上释放，不用等到语句结束，而insert...select这样的批量插入数据的语句，自增锁还是要在语句结束之后才能释放。\n    - 2表示所有申请自增主键的动作都是申请后就释放锁\n\n2虽然提高了并发，但又可能造成数据不一致的问题。如果binlog_format=statement的话，两个session交替插入数据，binlog只能先记录其中一个session的日志，由于binlog记录的是statement，也就是sql，到时候根据binlog恢复数据，或者主从同步的话，id就不一致了。如果有这种情况，就应该innodb_autoinc_lock_mode设置为0或1，让批量插入的数据的语句执行完之后再释放锁。或者innodb_autoinc_lock_mode=2 && binlog_format=row，binlog不记录sql，而是记录数据修改的日志，也就不存在id不一致的问题了。\n\n\n## 主键用完了会发生什么？\n\n自增值不会再增加，再插入数据会报主键重复\n\n\nhttps://www.jb51.net/article/221895.htm","slug":"kongzheng1993-主键自增","published":1,"updated":"2023-03-08T07:05:58.833Z","layout":"post","photos":[],"link":"","_id":"clg0k2amr008zt26feqgiett2","content":"<p>我们平常使用关系行数据库，总会创建一个与业务无关的主键列ID，并且这个id是自增的。记得刚工作前两年，还在用oracle数据库，oracle的自增要靠创建一个从1开始，步长为1的序列，每次要插入数据前，先通过这个序列获取id。</p>\n<p>后来开始用MySQL了，每次建表上来就是一个<code>id int not null primary key auto_increment</code>，知道这样我们insert数据的时候id为空或者0，就可以出发id自增。说实话一直也没仔细去了解这其中的原理，今天就好好盘一下。</p>\n<h2 id=\"怎么实现自增\"><a href=\"#怎么实现自增\" class=\"headerlink\" title=\"怎么实现自增\"></a>怎么实现自增</h2><p>mysql中有两个设置：自增值<code>auto_increment_offset</code>和漂移值<code>auto_increment_increment</code>（也就是步长）</p>\n<pre><code class=\"shell\">mysql&gt; show variables like &#39;auto_increment%&#39;;\n+--------------------------+-------+\n| Variable_name            | Value |\n+--------------------------+-------+\n| auto_increment_increment | 1     |\n| auto_increment_offset    | 1     |\n+--------------------------+-------+\n2 rows in set (0.01 sec)</code></pre>\n<p>自增的算法：从auto_increment_offset开始，以auto_increment_increment为步长，持续增加。如果插入的id为x，当前的自增值为y：</p>\n<ul>\n<li>如果x &lt; y，那么这个表的自增值不变，如果x表里不存在，可以插入成功，如果存在报主键重复。</li>\n<li>如果x&gt;=y，那么需要把当前自增值修改为x</li>\n</ul>\n<pre><code>mysql&gt; create table t_test(id int not null primary key auto_increment, a varchar(20) default null );\nQuery OK, 0 rows affected (0.04 sec)\n\nmysql&gt; insert into t_test(a) values (&#39;test&#39;);\nQuery OK, 1 row affected (0.02 sec)\n\nmysql&gt; select * from t_test;\n+----+------+\n| id | a    |\n+----+------+\n|  1 | test |\n+----+------+\n1 row in set (0.01 sec)\n\nmysql&gt; insert into t_test values (3, &#39;test3&#39;);\nQuery OK, 1 row affected (0.03 sec)\n\nmysql&gt; select * From t_test;\n+----+-------+\n| id | a     |\n+----+-------+\n|  1 | test  |\n|  3 | test3 |\n+----+-------+\n2 rows in set (0.00 sec)\n\nmysql&gt; insert into t_test(a) values (&#39;test4&#39;);\nQuery OK, 1 row affected (0.02 sec)\n\nmysql&gt; select * From t_test;\n+----+-------+\n| id | a     |\n+----+-------+\n|  1 | test  |\n|  3 | test3 |\n|  4 | test4 |\n+----+-------+\n3 rows in set (0.00 sec)</code></pre><h2 id=\"怎么记住自增值\"><a href=\"#怎么记住自增值\" class=\"headerlink\" title=\"怎么记住自增值\"></a>怎么记住自增值</h2><ol>\n<li>MyISAM引擎的自增值保存在数据文件中</li>\n<li>InnoDB引擎的自增值，在5.7及之前的版本，自增值保存在内存里，没有持久化，每次重启后，第一次打开表的时候，都会去找max(id)，然后将max(id)+步长作为这个表当前的自增值。8.0版本以后，将自增值的变更记录在了redo log中，重启的时候依靠redo log恢复重启前的值。</li>\n</ol>\n<h2 id=\"自增锁\"><a href=\"#自增锁\" class=\"headerlink\" title=\"自增锁\"></a>自增锁</h2><p>自增id锁并不是一个事务锁，而是每次申请完就马上释放，以便其他事务再申请<br>MySQL5.0版本时，自增锁的范围是语句级别的，也就是一个语句申请了一个表的自增锁，这个锁会在语句执行结束后释放。<br>MySQL5.1.22版本引入了一个新策略，新增参数innodb_autoinc_lock_mode，默认为1。<br>    - 0表示采用5.0时的策略，语句结束后释放锁；<br>    - 1表示普通insert语句，自增锁在申请之后马上释放，不用等到语句结束，而insert…select这样的批量插入数据的语句，自增锁还是要在语句结束之后才能释放。<br>    - 2表示所有申请自增主键的动作都是申请后就释放锁</p>\n<p>2虽然提高了并发，但又可能造成数据不一致的问题。如果binlog_format=statement的话，两个session交替插入数据，binlog只能先记录其中一个session的日志，由于binlog记录的是statement，也就是sql，到时候根据binlog恢复数据，或者主从同步的话，id就不一致了。如果有这种情况，就应该innodb_autoinc_lock_mode设置为0或1，让批量插入的数据的语句执行完之后再释放锁。或者innodb_autoinc_lock_mode=2 &amp;&amp; binlog_format=row，binlog不记录sql，而是记录数据修改的日志，也就不存在id不一致的问题了。</p>\n<h2 id=\"主键用完了会发生什么？\"><a href=\"#主键用完了会发生什么？\" class=\"headerlink\" title=\"主键用完了会发生什么？\"></a>主键用完了会发生什么？</h2><p>自增值不会再增加，再插入数据会报主键重复</p>\n<p><a href=\"https://www.jb51.net/article/221895.htm\" target=\"_blank\" rel=\"noopener\">https://www.jb51.net/article/221895.htm</a></p>\n","site":{"data":{}},"more":"<p>我们平常使用关系行数据库，总会创建一个与业务无关的主键列ID，并且这个id是自增的。记得刚工作前两年，还在用oracle数据库，oracle的自增要靠创建一个从1开始，步长为1的序列，每次要插入数据前，先通过这个序列获取id。</p>\n<p>后来开始用MySQL了，每次建表上来就是一个<code>id int not null primary key auto_increment</code>，知道这样我们insert数据的时候id为空或者0，就可以出发id自增。说实话一直也没仔细去了解这其中的原理，今天就好好盘一下。</p>\n<h2 id=\"怎么实现自增\"><a href=\"#怎么实现自增\" class=\"headerlink\" title=\"怎么实现自增\"></a>怎么实现自增</h2><p>mysql中有两个设置：自增值<code>auto_increment_offset</code>和漂移值<code>auto_increment_increment</code>（也就是步长）</p>\n<pre><code class=\"shell\">mysql&gt; show variables like &#39;auto_increment%&#39;;\n+--------------------------+-------+\n| Variable_name            | Value |\n+--------------------------+-------+\n| auto_increment_increment | 1     |\n| auto_increment_offset    | 1     |\n+--------------------------+-------+\n2 rows in set (0.01 sec)</code></pre>\n<p>自增的算法：从auto_increment_offset开始，以auto_increment_increment为步长，持续增加。如果插入的id为x，当前的自增值为y：</p>\n<ul>\n<li>如果x &lt; y，那么这个表的自增值不变，如果x表里不存在，可以插入成功，如果存在报主键重复。</li>\n<li>如果x&gt;=y，那么需要把当前自增值修改为x</li>\n</ul>\n<pre><code>mysql&gt; create table t_test(id int not null primary key auto_increment, a varchar(20) default null );\nQuery OK, 0 rows affected (0.04 sec)\n\nmysql&gt; insert into t_test(a) values (&#39;test&#39;);\nQuery OK, 1 row affected (0.02 sec)\n\nmysql&gt; select * from t_test;\n+----+------+\n| id | a    |\n+----+------+\n|  1 | test |\n+----+------+\n1 row in set (0.01 sec)\n\nmysql&gt; insert into t_test values (3, &#39;test3&#39;);\nQuery OK, 1 row affected (0.03 sec)\n\nmysql&gt; select * From t_test;\n+----+-------+\n| id | a     |\n+----+-------+\n|  1 | test  |\n|  3 | test3 |\n+----+-------+\n2 rows in set (0.00 sec)\n\nmysql&gt; insert into t_test(a) values (&#39;test4&#39;);\nQuery OK, 1 row affected (0.02 sec)\n\nmysql&gt; select * From t_test;\n+----+-------+\n| id | a     |\n+----+-------+\n|  1 | test  |\n|  3 | test3 |\n|  4 | test4 |\n+----+-------+\n3 rows in set (0.00 sec)</code></pre><h2 id=\"怎么记住自增值\"><a href=\"#怎么记住自增值\" class=\"headerlink\" title=\"怎么记住自增值\"></a>怎么记住自增值</h2><ol>\n<li>MyISAM引擎的自增值保存在数据文件中</li>\n<li>InnoDB引擎的自增值，在5.7及之前的版本，自增值保存在内存里，没有持久化，每次重启后，第一次打开表的时候，都会去找max(id)，然后将max(id)+步长作为这个表当前的自增值。8.0版本以后，将自增值的变更记录在了redo log中，重启的时候依靠redo log恢复重启前的值。</li>\n</ol>\n<h2 id=\"自增锁\"><a href=\"#自增锁\" class=\"headerlink\" title=\"自增锁\"></a>自增锁</h2><p>自增id锁并不是一个事务锁，而是每次申请完就马上释放，以便其他事务再申请<br>MySQL5.0版本时，自增锁的范围是语句级别的，也就是一个语句申请了一个表的自增锁，这个锁会在语句执行结束后释放。<br>MySQL5.1.22版本引入了一个新策略，新增参数innodb_autoinc_lock_mode，默认为1。<br>    - 0表示采用5.0时的策略，语句结束后释放锁；<br>    - 1表示普通insert语句，自增锁在申请之后马上释放，不用等到语句结束，而insert…select这样的批量插入数据的语句，自增锁还是要在语句结束之后才能释放。<br>    - 2表示所有申请自增主键的动作都是申请后就释放锁</p>\n<p>2虽然提高了并发，但又可能造成数据不一致的问题。如果binlog_format=statement的话，两个session交替插入数据，binlog只能先记录其中一个session的日志，由于binlog记录的是statement，也就是sql，到时候根据binlog恢复数据，或者主从同步的话，id就不一致了。如果有这种情况，就应该innodb_autoinc_lock_mode设置为0或1，让批量插入的数据的语句执行完之后再释放锁。或者innodb_autoinc_lock_mode=2 &amp;&amp; binlog_format=row，binlog不记录sql，而是记录数据修改的日志，也就不存在id不一致的问题了。</p>\n<h2 id=\"主键用完了会发生什么？\"><a href=\"#主键用完了会发生什么？\" class=\"headerlink\" title=\"主键用完了会发生什么？\"></a>主键用完了会发生什么？</h2><p>自增值不会再增加，再插入数据会报主键重复</p>\n<p><a href=\"https://www.jb51.net/article/221895.htm\" target=\"_blank\" rel=\"noopener\">https://www.jb51.net/article/221895.htm</a></p>\n"},{"title":"package-info.java是什么","excerpt":"","comments":1,"date":"2022-07-12T10:30:52.000Z","_content":"\n\n今天翻阅公司大佬写的项目，发现有个package-info.java的文件，里面啥都没有，就是一个```package xxx.xxx```。查了一些资料，了解到这个package-info的作用：\n\n- 为标注在包上的Annotation提供便利；\n- 声明友好类和包常量\n- 提供包的整体注释\n\nhttps://www.pudn.com/news/628f83e0bf399b7f351ebf3f.html","source":"_posts/2022-07-12-kongzheng1993-package-info.md","raw":"---\ntitle: package-info.java是什么\nexcerpt: 'Java'\ntags: [Java]\ncategories: [Java]\ncomments: true\ndate: 2022-07-12 18:30:52\n---\n\n\n今天翻阅公司大佬写的项目，发现有个package-info.java的文件，里面啥都没有，就是一个```package xxx.xxx```。查了一些资料，了解到这个package-info的作用：\n\n- 为标注在包上的Annotation提供便利；\n- 声明友好类和包常量\n- 提供包的整体注释\n\nhttps://www.pudn.com/news/628f83e0bf399b7f351ebf3f.html","slug":"kongzheng1993-package-info","published":1,"updated":"2023-03-08T07:05:58.833Z","layout":"post","photos":[],"link":"","_id":"clg0k2amr0092t26f1ufvokun","content":"<p>今天翻阅公司大佬写的项目，发现有个package-info.java的文件，里面啥都没有，就是一个<code>package xxx.xxx</code>。查了一些资料，了解到这个package-info的作用：</p>\n<ul>\n<li>为标注在包上的Annotation提供便利；</li>\n<li>声明友好类和包常量</li>\n<li>提供包的整体注释</li>\n</ul>\n<p><a href=\"https://www.pudn.com/news/628f83e0bf399b7f351ebf3f.html\" target=\"_blank\" rel=\"noopener\">https://www.pudn.com/news/628f83e0bf399b7f351ebf3f.html</a></p>\n","site":{"data":{}},"more":"<p>今天翻阅公司大佬写的项目，发现有个package-info.java的文件，里面啥都没有，就是一个<code>package xxx.xxx</code>。查了一些资料，了解到这个package-info的作用：</p>\n<ul>\n<li>为标注在包上的Annotation提供便利；</li>\n<li>声明友好类和包常量</li>\n<li>提供包的整体注释</li>\n</ul>\n<p><a href=\"https://www.pudn.com/news/628f83e0bf399b7f351ebf3f.html\" target=\"_blank\" rel=\"noopener\">https://www.pudn.com/news/628f83e0bf399b7f351ebf3f.html</a></p>\n"},{"title":"NoSuchMethodError","excerpt":"","comments":1,"date":"2022-07-14T10:30:52.000Z","_content":"\nNoSuchMethodError是一个运行时错误，在编译时一般不会出现。如果编译成功，就说明方法本身是存在的，方法所在的类也是存在的，而且可以正常的引用到。\n\n如果编译没有报错，说明方法存在，但是运行时还是会报NoSuchMethodError，说明存在相同权限定名的类，而其中一个没有对应的方法。\n\n比如有两个类：A和B，A中有一个方法test()，而B中没有方法test()。编译的时候使用的是A#test方法，编译通过。而运行时，使用的时B#test，而B类中没有test方法，所以就会报NoSuchMethodError。\n\n解决办法就是排除其中一个依赖的jar，或者干脆不用这个方法了。这种问题比较难复现，全看jvm类加载的顺序（？？？不确定）\n","source":"_posts/2022-07-14-kongzheng1993-NoSuchMethodError.md","raw":"---\ntitle: NoSuchMethodError\nexcerpt: 'Java'\ntags: [Java]\ncategories: [Java]\ncomments: true\ndate: 2022-07-14 18:30:52\n---\n\nNoSuchMethodError是一个运行时错误，在编译时一般不会出现。如果编译成功，就说明方法本身是存在的，方法所在的类也是存在的，而且可以正常的引用到。\n\n如果编译没有报错，说明方法存在，但是运行时还是会报NoSuchMethodError，说明存在相同权限定名的类，而其中一个没有对应的方法。\n\n比如有两个类：A和B，A中有一个方法test()，而B中没有方法test()。编译的时候使用的是A#test方法，编译通过。而运行时，使用的时B#test，而B类中没有test方法，所以就会报NoSuchMethodError。\n\n解决办法就是排除其中一个依赖的jar，或者干脆不用这个方法了。这种问题比较难复现，全看jvm类加载的顺序（？？？不确定）\n","slug":"kongzheng1993-NoSuchMethodError","published":1,"updated":"2023-03-08T07:05:58.833Z","layout":"post","photos":[],"link":"","_id":"clg0k2ams0095t26f3zaj3yqb","content":"<p>NoSuchMethodError是一个运行时错误，在编译时一般不会出现。如果编译成功，就说明方法本身是存在的，方法所在的类也是存在的，而且可以正常的引用到。</p>\n<p>如果编译没有报错，说明方法存在，但是运行时还是会报NoSuchMethodError，说明存在相同权限定名的类，而其中一个没有对应的方法。</p>\n<p>比如有两个类：A和B，A中有一个方法test()，而B中没有方法test()。编译的时候使用的是A#test方法，编译通过。而运行时，使用的时B#test，而B类中没有test方法，所以就会报NoSuchMethodError。</p>\n<p>解决办法就是排除其中一个依赖的jar，或者干脆不用这个方法了。这种问题比较难复现，全看jvm类加载的顺序（？？？不确定）</p>\n","site":{"data":{}},"more":"<p>NoSuchMethodError是一个运行时错误，在编译时一般不会出现。如果编译成功，就说明方法本身是存在的，方法所在的类也是存在的，而且可以正常的引用到。</p>\n<p>如果编译没有报错，说明方法存在，但是运行时还是会报NoSuchMethodError，说明存在相同权限定名的类，而其中一个没有对应的方法。</p>\n<p>比如有两个类：A和B，A中有一个方法test()，而B中没有方法test()。编译的时候使用的是A#test方法，编译通过。而运行时，使用的时B#test，而B类中没有test方法，所以就会报NoSuchMethodError。</p>\n<p>解决办法就是排除其中一个依赖的jar，或者干脆不用这个方法了。这种问题比较难复现，全看jvm类加载的顺序（？？？不确定）</p>\n"},{"title":"MySQL中的锁","excerpt":"","comments":1,"date":"2022-07-02T10:30:52.000Z","_content":"\n\nhttps://cdn.modb.pro/db/69911","source":"_posts/2022-07-02-kongzheng1993-MySQL中的锁.md","raw":"---\ntitle: MySQL中的锁\nexcerpt: '数据库'\ntags: [数据库]\ncategories: [数据库]\ncomments: true\ndate: 2022-07-02 18:30:52\n---\n\n\nhttps://cdn.modb.pro/db/69911","slug":"kongzheng1993-MySQL中的锁","published":1,"updated":"2023-03-08T07:05:58.833Z","layout":"post","photos":[],"link":"","_id":"clg0k2amt0098t26f5ujmwi8f","content":"<p><a href=\"https://cdn.modb.pro/db/69911\" target=\"_blank\" rel=\"noopener\">https://cdn.modb.pro/db/69911</a></p>\n","site":{"data":{}},"more":"<p><a href=\"https://cdn.modb.pro/db/69911\" target=\"_blank\" rel=\"noopener\">https://cdn.modb.pro/db/69911</a></p>\n"},{"title":"为什么需要JMM","excerpt":"","comments":1,"date":"2022-09-27T10:30:52.000Z","_content":"\nhttps://blog.csdn.net/fuzhongmin05/article/details/105148133/","source":"_posts/2022-09-25-kongzheng1993-为什么需要JMM.md","raw":"---\ntitle: 为什么需要JMM\nexcerpt: 'JMM'\ntags: [Java]\ncategories: [Java]\ncomments: true\ndate: 2022-09-27 18:30:52\n---\n\nhttps://blog.csdn.net/fuzhongmin05/article/details/105148133/","slug":"kongzheng1993-为什么需要JMM","published":1,"updated":"2023-03-08T07:05:58.834Z","layout":"post","photos":[],"link":"","_id":"clg0k2amt009ct26flwfrnvwi","content":"<p><a href=\"https://blog.csdn.net/fuzhongmin05/article/details/105148133/\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/fuzhongmin05/article/details/105148133/</a></p>\n","site":{"data":{}},"more":"<p><a href=\"https://blog.csdn.net/fuzhongmin05/article/details/105148133/\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/fuzhongmin05/article/details/105148133/</a></p>\n"},{"title":"Spring Cloud Feign继承特性","excerpt":"","comments":1,"date":"2022-11-19T02:30:52.000Z","_content":"\n由于FeignClient的编写和其对应的服务提供方Controller及其相似，很多情况我们都是找服务提供方要过来Controller改造一下，其实我们可以利用其继承特性来减少代码的复制操作。\n\n以下一个demo来演示一下：\n\n## 1. 制定可复用的dto和接口定义\n创建一个工程user-service-api，里面包含同时可复用于服务端和客户端的接口和dto。\n<img src=\"1.png\">\n\n```java\npackage com.evil.user.dto;\n\n\npublic class UserDto {\n\n    private String userName;\n\n    private Integer age;\n\n    public String getUserName() {\n        return userName;\n    }\n\n    public void setUserName(String userName) {\n        this.userName = userName;\n    }\n\n    public Integer getAge() {\n        return age;\n    }\n\n    public void setAge(Integer age) {\n        this.age = age;\n    }\n}\n\n```\n\n```java\npackage com.evil.user.service;\n\nimport com.evil.user.dto.UserDto;\nimport org.springframework.web.bind.annotation.PathVariable;\nimport org.springframework.web.bind.annotation.RequestMapping;\n\n@RequestMapping(\"/user\")\npublic interface UserService {\n\n    @RequestMapping(\"get/{id}\")\n    UserDto getById(@PathVariable(\"id\") Integer id);\n\n}\n\n```\n定义好了dto和接口，打包user-service-api给服务提供者和消费者公用。\n\n## 2. 服务提供者使用\n\n服务提供者引入依赖\n```xml\n    <dependency>\n      <groupId>com.evil</groupId>\n      <artifactId>user-service-api</artifactId>\n      <version>1.0.0</version>\n    </dependency>\n```\n\ncontroller直接实现一把\n\n```java\n\npackage com.evil.user.controller;\n\nimport com.evil.user.dto.UserDto;\nimport com.evil.user.service.UserService;\nimport org.springframework.web.bind.annotation.RestController;\n\n@RestController\npublic class UserController implements UserService {\n\n    public UserDto getById(Integer integer) {\n        UserDto userDto = new UserDto();\n        userDto.setUserName(\"小明\");\n        userDto.setAge(28);\n        return userDto;\n    }\n}\n\n```\n\n启动后测试。\n\n<img src=\"2.png\">\n\n## 3. 服务消费方使用\n\n一样的，服务消费者引入依赖，另外还要引入feign的依赖\n\n```xml\n    <dependency>\n      <groupId>com.evil</groupId>\n      <artifactId>user-service-api</artifactId>\n      <version>1.0.0</version>\n    </dependency>\n    <dependency>\n      <groupId>org.springframework.cloud</groupId>\n      <artifactId>spring-cloud-starter-feign</artifactId>\n      <version>1.4.7.RELEASE</version>\n    </dependency>\n```\n\nFienClient直接继承api包里的UserService\n\n```java\npackage com.evil.feign;\n\nimport com.evil.user.dto.UserDto;\nimport com.evil.user.service.UserService;\nimport org.springframework.cloud.netflix.feign.FeignClient;\n\n@FeignClient\npublic interface UserFeign extends UserService {\n\n}\n```\n\n## 总结：\n\n同一个接口定义，服务提供者实现UserService，增加@RestController注解即可；服务消费者只需要继承UserService，增加@FeignClient，即可完成对服务提供者的调用。\n","source":"_posts/2022-11-19-kongzheng1993-feign继承特性.md","raw":"---\ntitle: Spring Cloud Feign继承特性\nexcerpt: 'feign'\ntags: [feign]\ncategories: [feign]\ncomments: true\ndate: 2022-11-19 10:30:52\n---\n\n由于FeignClient的编写和其对应的服务提供方Controller及其相似，很多情况我们都是找服务提供方要过来Controller改造一下，其实我们可以利用其继承特性来减少代码的复制操作。\n\n以下一个demo来演示一下：\n\n## 1. 制定可复用的dto和接口定义\n创建一个工程user-service-api，里面包含同时可复用于服务端和客户端的接口和dto。\n<img src=\"1.png\">\n\n```java\npackage com.evil.user.dto;\n\n\npublic class UserDto {\n\n    private String userName;\n\n    private Integer age;\n\n    public String getUserName() {\n        return userName;\n    }\n\n    public void setUserName(String userName) {\n        this.userName = userName;\n    }\n\n    public Integer getAge() {\n        return age;\n    }\n\n    public void setAge(Integer age) {\n        this.age = age;\n    }\n}\n\n```\n\n```java\npackage com.evil.user.service;\n\nimport com.evil.user.dto.UserDto;\nimport org.springframework.web.bind.annotation.PathVariable;\nimport org.springframework.web.bind.annotation.RequestMapping;\n\n@RequestMapping(\"/user\")\npublic interface UserService {\n\n    @RequestMapping(\"get/{id}\")\n    UserDto getById(@PathVariable(\"id\") Integer id);\n\n}\n\n```\n定义好了dto和接口，打包user-service-api给服务提供者和消费者公用。\n\n## 2. 服务提供者使用\n\n服务提供者引入依赖\n```xml\n    <dependency>\n      <groupId>com.evil</groupId>\n      <artifactId>user-service-api</artifactId>\n      <version>1.0.0</version>\n    </dependency>\n```\n\ncontroller直接实现一把\n\n```java\n\npackage com.evil.user.controller;\n\nimport com.evil.user.dto.UserDto;\nimport com.evil.user.service.UserService;\nimport org.springframework.web.bind.annotation.RestController;\n\n@RestController\npublic class UserController implements UserService {\n\n    public UserDto getById(Integer integer) {\n        UserDto userDto = new UserDto();\n        userDto.setUserName(\"小明\");\n        userDto.setAge(28);\n        return userDto;\n    }\n}\n\n```\n\n启动后测试。\n\n<img src=\"2.png\">\n\n## 3. 服务消费方使用\n\n一样的，服务消费者引入依赖，另外还要引入feign的依赖\n\n```xml\n    <dependency>\n      <groupId>com.evil</groupId>\n      <artifactId>user-service-api</artifactId>\n      <version>1.0.0</version>\n    </dependency>\n    <dependency>\n      <groupId>org.springframework.cloud</groupId>\n      <artifactId>spring-cloud-starter-feign</artifactId>\n      <version>1.4.7.RELEASE</version>\n    </dependency>\n```\n\nFienClient直接继承api包里的UserService\n\n```java\npackage com.evil.feign;\n\nimport com.evil.user.dto.UserDto;\nimport com.evil.user.service.UserService;\nimport org.springframework.cloud.netflix.feign.FeignClient;\n\n@FeignClient\npublic interface UserFeign extends UserService {\n\n}\n```\n\n## 总结：\n\n同一个接口定义，服务提供者实现UserService，增加@RestController注解即可；服务消费者只需要继承UserService，增加@FeignClient，即可完成对服务提供者的调用。\n","slug":"kongzheng1993-feign继承特性","published":1,"updated":"2023-03-08T07:05:58.834Z","layout":"post","photos":[],"link":"","_id":"clg0k2amx009ft26fh3xbnosw","content":"<p>由于FeignClient的编写和其对应的服务提供方Controller及其相似，很多情况我们都是找服务提供方要过来Controller改造一下，其实我们可以利用其继承特性来减少代码的复制操作。</p>\n<p>以下一个demo来演示一下：</p>\n<h2 id=\"1-制定可复用的dto和接口定义\"><a href=\"#1-制定可复用的dto和接口定义\" class=\"headerlink\" title=\"1. 制定可复用的dto和接口定义\"></a>1. 制定可复用的dto和接口定义</h2><p>创建一个工程user-service-api，里面包含同时可复用于服务端和客户端的接口和dto。<br><img src=\"/2022/11/19/kongzheng1993-feign继承特性/1.png\"></p>\n<pre><code class=\"java\">package com.evil.user.dto;\n\n\npublic class UserDto {\n\n    private String userName;\n\n    private Integer age;\n\n    public String getUserName() {\n        return userName;\n    }\n\n    public void setUserName(String userName) {\n        this.userName = userName;\n    }\n\n    public Integer getAge() {\n        return age;\n    }\n\n    public void setAge(Integer age) {\n        this.age = age;\n    }\n}\n</code></pre>\n<pre><code class=\"java\">package com.evil.user.service;\n\nimport com.evil.user.dto.UserDto;\nimport org.springframework.web.bind.annotation.PathVariable;\nimport org.springframework.web.bind.annotation.RequestMapping;\n\n@RequestMapping(&quot;/user&quot;)\npublic interface UserService {\n\n    @RequestMapping(&quot;get/{id}&quot;)\n    UserDto getById(@PathVariable(&quot;id&quot;) Integer id);\n\n}\n</code></pre>\n<p>定义好了dto和接口，打包user-service-api给服务提供者和消费者公用。</p>\n<h2 id=\"2-服务提供者使用\"><a href=\"#2-服务提供者使用\" class=\"headerlink\" title=\"2. 服务提供者使用\"></a>2. 服务提供者使用</h2><p>服务提供者引入依赖</p>\n<pre><code class=\"xml\">    &lt;dependency&gt;\n      &lt;groupId&gt;com.evil&lt;/groupId&gt;\n      &lt;artifactId&gt;user-service-api&lt;/artifactId&gt;\n      &lt;version&gt;1.0.0&lt;/version&gt;\n    &lt;/dependency&gt;</code></pre>\n<p>controller直接实现一把</p>\n<pre><code class=\"java\">\npackage com.evil.user.controller;\n\nimport com.evil.user.dto.UserDto;\nimport com.evil.user.service.UserService;\nimport org.springframework.web.bind.annotation.RestController;\n\n@RestController\npublic class UserController implements UserService {\n\n    public UserDto getById(Integer integer) {\n        UserDto userDto = new UserDto();\n        userDto.setUserName(&quot;小明&quot;);\n        userDto.setAge(28);\n        return userDto;\n    }\n}\n</code></pre>\n<p>启动后测试。</p>\n<img src=\"/2022/11/19/kongzheng1993-feign继承特性/2.png\">\n\n<h2 id=\"3-服务消费方使用\"><a href=\"#3-服务消费方使用\" class=\"headerlink\" title=\"3. 服务消费方使用\"></a>3. 服务消费方使用</h2><p>一样的，服务消费者引入依赖，另外还要引入feign的依赖</p>\n<pre><code class=\"xml\">    &lt;dependency&gt;\n      &lt;groupId&gt;com.evil&lt;/groupId&gt;\n      &lt;artifactId&gt;user-service-api&lt;/artifactId&gt;\n      &lt;version&gt;1.0.0&lt;/version&gt;\n    &lt;/dependency&gt;\n    &lt;dependency&gt;\n      &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\n      &lt;artifactId&gt;spring-cloud-starter-feign&lt;/artifactId&gt;\n      &lt;version&gt;1.4.7.RELEASE&lt;/version&gt;\n    &lt;/dependency&gt;</code></pre>\n<p>FienClient直接继承api包里的UserService</p>\n<pre><code class=\"java\">package com.evil.feign;\n\nimport com.evil.user.dto.UserDto;\nimport com.evil.user.service.UserService;\nimport org.springframework.cloud.netflix.feign.FeignClient;\n\n@FeignClient\npublic interface UserFeign extends UserService {\n\n}</code></pre>\n<h2 id=\"总结：\"><a href=\"#总结：\" class=\"headerlink\" title=\"总结：\"></a>总结：</h2><p>同一个接口定义，服务提供者实现UserService，增加@RestController注解即可；服务消费者只需要继承UserService，增加@FeignClient，即可完成对服务提供者的调用。</p>\n","site":{"data":{}},"more":"<p>由于FeignClient的编写和其对应的服务提供方Controller及其相似，很多情况我们都是找服务提供方要过来Controller改造一下，其实我们可以利用其继承特性来减少代码的复制操作。</p>\n<p>以下一个demo来演示一下：</p>\n<h2 id=\"1-制定可复用的dto和接口定义\"><a href=\"#1-制定可复用的dto和接口定义\" class=\"headerlink\" title=\"1. 制定可复用的dto和接口定义\"></a>1. 制定可复用的dto和接口定义</h2><p>创建一个工程user-service-api，里面包含同时可复用于服务端和客户端的接口和dto。<br><img src=\"/2022/11/19/kongzheng1993-feign继承特性/1.png\"></p>\n<pre><code class=\"java\">package com.evil.user.dto;\n\n\npublic class UserDto {\n\n    private String userName;\n\n    private Integer age;\n\n    public String getUserName() {\n        return userName;\n    }\n\n    public void setUserName(String userName) {\n        this.userName = userName;\n    }\n\n    public Integer getAge() {\n        return age;\n    }\n\n    public void setAge(Integer age) {\n        this.age = age;\n    }\n}\n</code></pre>\n<pre><code class=\"java\">package com.evil.user.service;\n\nimport com.evil.user.dto.UserDto;\nimport org.springframework.web.bind.annotation.PathVariable;\nimport org.springframework.web.bind.annotation.RequestMapping;\n\n@RequestMapping(&quot;/user&quot;)\npublic interface UserService {\n\n    @RequestMapping(&quot;get/{id}&quot;)\n    UserDto getById(@PathVariable(&quot;id&quot;) Integer id);\n\n}\n</code></pre>\n<p>定义好了dto和接口，打包user-service-api给服务提供者和消费者公用。</p>\n<h2 id=\"2-服务提供者使用\"><a href=\"#2-服务提供者使用\" class=\"headerlink\" title=\"2. 服务提供者使用\"></a>2. 服务提供者使用</h2><p>服务提供者引入依赖</p>\n<pre><code class=\"xml\">    &lt;dependency&gt;\n      &lt;groupId&gt;com.evil&lt;/groupId&gt;\n      &lt;artifactId&gt;user-service-api&lt;/artifactId&gt;\n      &lt;version&gt;1.0.0&lt;/version&gt;\n    &lt;/dependency&gt;</code></pre>\n<p>controller直接实现一把</p>\n<pre><code class=\"java\">\npackage com.evil.user.controller;\n\nimport com.evil.user.dto.UserDto;\nimport com.evil.user.service.UserService;\nimport org.springframework.web.bind.annotation.RestController;\n\n@RestController\npublic class UserController implements UserService {\n\n    public UserDto getById(Integer integer) {\n        UserDto userDto = new UserDto();\n        userDto.setUserName(&quot;小明&quot;);\n        userDto.setAge(28);\n        return userDto;\n    }\n}\n</code></pre>\n<p>启动后测试。</p>\n<img src=\"/2022/11/19/kongzheng1993-feign继承特性/2.png\">\n\n<h2 id=\"3-服务消费方使用\"><a href=\"#3-服务消费方使用\" class=\"headerlink\" title=\"3. 服务消费方使用\"></a>3. 服务消费方使用</h2><p>一样的，服务消费者引入依赖，另外还要引入feign的依赖</p>\n<pre><code class=\"xml\">    &lt;dependency&gt;\n      &lt;groupId&gt;com.evil&lt;/groupId&gt;\n      &lt;artifactId&gt;user-service-api&lt;/artifactId&gt;\n      &lt;version&gt;1.0.0&lt;/version&gt;\n    &lt;/dependency&gt;\n    &lt;dependency&gt;\n      &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\n      &lt;artifactId&gt;spring-cloud-starter-feign&lt;/artifactId&gt;\n      &lt;version&gt;1.4.7.RELEASE&lt;/version&gt;\n    &lt;/dependency&gt;</code></pre>\n<p>FienClient直接继承api包里的UserService</p>\n<pre><code class=\"java\">package com.evil.feign;\n\nimport com.evil.user.dto.UserDto;\nimport com.evil.user.service.UserService;\nimport org.springframework.cloud.netflix.feign.FeignClient;\n\n@FeignClient\npublic interface UserFeign extends UserService {\n\n}</code></pre>\n<h2 id=\"总结：\"><a href=\"#总结：\" class=\"headerlink\" title=\"总结：\"></a>总结：</h2><p>同一个接口定义，服务提供者实现UserService，增加@RestController注解即可；服务消费者只需要继承UserService，增加@FeignClient，即可完成对服务提供者的调用。</p>\n"},{"title":"Kafka常见问题总结","excerpt":"","comments":1,"date":"2023-02-20T02:30:52.000Z","_content":"\n\n# 1.顺序问题\n\n有些消息的消费是有顺序的，比如先创建订单，才能修改订单。\n\n## 1. 如何保证消息的顺序性\n\nkafka的topic是无序的，但是一个topic包含多个partition，每个partition内部是有序的，只要保证生产者写消息时，按照一定的规则写到同一个partition，不同的消费者读不同的partition的消息，就能保证生产和消费消息的顺序。比如同一个商户编号的消息写到同一个partition中，topic中创建了4个partition，然后部署4个消费者节点，构成消费者组，一个partition对应一个消费者节点，从理论上说，这套方案是能够保证消息顺序的。\n\n## 2. 顺序消息失败了怎么办？\n\nabcd四个顺序消息，如果a失败了，影响了bcd的消费怎么办？\n加入重试，每个消息如果失败了，重试三到五次？可以解决大部分情况，但极端情况下，也可能会有问题。\n\n\n\n\n\nhttps://mp.weixin.qq.com/s/YPkE3Tsu3RVbhfVZCBt1pQ","source":"_posts/2023-02-20-kongzheng1993-kafka.md","raw":"---\ntitle: Kafka常见问题总结\nexcerpt: 'Kafka'\ntags: [Kafka]\ncategories: [Kafka]\ncomments: true\ndate: 2023-02-20 10:30:52\n---\n\n\n# 1.顺序问题\n\n有些消息的消费是有顺序的，比如先创建订单，才能修改订单。\n\n## 1. 如何保证消息的顺序性\n\nkafka的topic是无序的，但是一个topic包含多个partition，每个partition内部是有序的，只要保证生产者写消息时，按照一定的规则写到同一个partition，不同的消费者读不同的partition的消息，就能保证生产和消费消息的顺序。比如同一个商户编号的消息写到同一个partition中，topic中创建了4个partition，然后部署4个消费者节点，构成消费者组，一个partition对应一个消费者节点，从理论上说，这套方案是能够保证消息顺序的。\n\n## 2. 顺序消息失败了怎么办？\n\nabcd四个顺序消息，如果a失败了，影响了bcd的消费怎么办？\n加入重试，每个消息如果失败了，重试三到五次？可以解决大部分情况，但极端情况下，也可能会有问题。\n\n\n\n\n\nhttps://mp.weixin.qq.com/s/YPkE3Tsu3RVbhfVZCBt1pQ","slug":"kongzheng1993-kafka","published":1,"updated":"2023-03-08T07:05:58.835Z","layout":"post","photos":[],"link":"","_id":"clg0k2amz009jt26fcaqshlxj","content":"<h1 id=\"1-顺序问题\"><a href=\"#1-顺序问题\" class=\"headerlink\" title=\"1.顺序问题\"></a>1.顺序问题</h1><p>有些消息的消费是有顺序的，比如先创建订单，才能修改订单。</p>\n<h2 id=\"1-如何保证消息的顺序性\"><a href=\"#1-如何保证消息的顺序性\" class=\"headerlink\" title=\"1. 如何保证消息的顺序性\"></a>1. 如何保证消息的顺序性</h2><p>kafka的topic是无序的，但是一个topic包含多个partition，每个partition内部是有序的，只要保证生产者写消息时，按照一定的规则写到同一个partition，不同的消费者读不同的partition的消息，就能保证生产和消费消息的顺序。比如同一个商户编号的消息写到同一个partition中，topic中创建了4个partition，然后部署4个消费者节点，构成消费者组，一个partition对应一个消费者节点，从理论上说，这套方案是能够保证消息顺序的。</p>\n<h2 id=\"2-顺序消息失败了怎么办？\"><a href=\"#2-顺序消息失败了怎么办？\" class=\"headerlink\" title=\"2. 顺序消息失败了怎么办？\"></a>2. 顺序消息失败了怎么办？</h2><p>abcd四个顺序消息，如果a失败了，影响了bcd的消费怎么办？<br>加入重试，每个消息如果失败了，重试三到五次？可以解决大部分情况，但极端情况下，也可能会有问题。</p>\n<p><a href=\"https://mp.weixin.qq.com/s/YPkE3Tsu3RVbhfVZCBt1pQ\" target=\"_blank\" rel=\"noopener\">https://mp.weixin.qq.com/s/YPkE3Tsu3RVbhfVZCBt1pQ</a></p>\n","site":{"data":{}},"more":"<h1 id=\"1-顺序问题\"><a href=\"#1-顺序问题\" class=\"headerlink\" title=\"1.顺序问题\"></a>1.顺序问题</h1><p>有些消息的消费是有顺序的，比如先创建订单，才能修改订单。</p>\n<h2 id=\"1-如何保证消息的顺序性\"><a href=\"#1-如何保证消息的顺序性\" class=\"headerlink\" title=\"1. 如何保证消息的顺序性\"></a>1. 如何保证消息的顺序性</h2><p>kafka的topic是无序的，但是一个topic包含多个partition，每个partition内部是有序的，只要保证生产者写消息时，按照一定的规则写到同一个partition，不同的消费者读不同的partition的消息，就能保证生产和消费消息的顺序。比如同一个商户编号的消息写到同一个partition中，topic中创建了4个partition，然后部署4个消费者节点，构成消费者组，一个partition对应一个消费者节点，从理论上说，这套方案是能够保证消息顺序的。</p>\n<h2 id=\"2-顺序消息失败了怎么办？\"><a href=\"#2-顺序消息失败了怎么办？\" class=\"headerlink\" title=\"2. 顺序消息失败了怎么办？\"></a>2. 顺序消息失败了怎么办？</h2><p>abcd四个顺序消息，如果a失败了，影响了bcd的消费怎么办？<br>加入重试，每个消息如果失败了，重试三到五次？可以解决大部分情况，但极端情况下，也可能会有问题。</p>\n<p><a href=\"https://mp.weixin.qq.com/s/YPkE3Tsu3RVbhfVZCBt1pQ\" target=\"_blank\" rel=\"noopener\">https://mp.weixin.qq.com/s/YPkE3Tsu3RVbhfVZCBt1pQ</a></p>\n"},{"title":"双检锁","excerpt":"","comments":1,"date":"2022-09-27T10:30:52.000Z","_content":"\n双重检查锁定模式（也被称为\"双重检查加锁优化\"，\"锁暗示\"（Lock hint）) 是一种软件设计模式用来减少并发系统中竞争和同步的开销。双重检查锁定模式首先验证锁定条件(第一次检查)，只有通过锁定条件验证才真正的进行加锁逻辑并再次验证条件(第二次检查)。\n\n该模式在某些语言在某些硬件平台的实现可能是不安全的。有的时候，这一模式被看做是反模式。\n它通常用于减少加锁开销，尤其是为多线程环境中的单例模式实现“惰性初始化”。惰性初始化的意思是直到第一次访问时才初始化它的值。\n\n### Java双检锁实现单单例模式\n\n```java\npublic class Singleton {\n        private volatile static Singleton instance;\n    \n    private Singleton() {\n        \n    }\n    \n    public static Singleton getInstance() {\n        if (instance == null) {\n            synchronized (Singleton.class) {\n                if (instance == null) {\n                    instance = new Singleton();\n                }\n            }\n        }\n        return instance;\n    }\n}\n\n```\n\n1. 为什么双重检验\n\n如果多个线程同时到达第一个判断，此时isntance为null，多个线程通过这个判断，synchronized还可以加锁，同一时间只有一个线程可以执行同步代码块，同步代码块内再次判断，可以保证只有第一个执行同步代码块的线程会创建出实例。第一个检查的意义在于，实例化后，没必要每个线程都走同步代码块，这样会阻塞。\n\n2. 为什么需要volatile\n\n`instance = new Instance();`这行代码执行过程分为3个步骤：\n- 在堆中开辟空间分配地址\n- 根据类加载器初始化顺序进行初始化\n- 将内存地址保存到栈中的变量\n\nJava模型允许无序写入，可以会出现执行顺序为1-3-2，恰好此时其他线程在第一次if处判断，不是空，直接返回了。后面拿着null去执行肯定会出错。\n\n而使用volatile，会在对instance操作时增加Lock前缀，相当于一个内存屏障，防止指令重排序，就不会出现1-3-2的情况。\n","source":"_posts/2022-09-25-kongzheng1993-双检锁.md","raw":"---\ntitle: 双检锁\nexcerpt: 'Java'\ntags: [Java]\ncategories: [Java]\ncomments: true\ndate: 2022-09-27 18:30:52\n---\n\n双重检查锁定模式（也被称为\"双重检查加锁优化\"，\"锁暗示\"（Lock hint）) 是一种软件设计模式用来减少并发系统中竞争和同步的开销。双重检查锁定模式首先验证锁定条件(第一次检查)，只有通过锁定条件验证才真正的进行加锁逻辑并再次验证条件(第二次检查)。\n\n该模式在某些语言在某些硬件平台的实现可能是不安全的。有的时候，这一模式被看做是反模式。\n它通常用于减少加锁开销，尤其是为多线程环境中的单例模式实现“惰性初始化”。惰性初始化的意思是直到第一次访问时才初始化它的值。\n\n### Java双检锁实现单单例模式\n\n```java\npublic class Singleton {\n        private volatile static Singleton instance;\n    \n    private Singleton() {\n        \n    }\n    \n    public static Singleton getInstance() {\n        if (instance == null) {\n            synchronized (Singleton.class) {\n                if (instance == null) {\n                    instance = new Singleton();\n                }\n            }\n        }\n        return instance;\n    }\n}\n\n```\n\n1. 为什么双重检验\n\n如果多个线程同时到达第一个判断，此时isntance为null，多个线程通过这个判断，synchronized还可以加锁，同一时间只有一个线程可以执行同步代码块，同步代码块内再次判断，可以保证只有第一个执行同步代码块的线程会创建出实例。第一个检查的意义在于，实例化后，没必要每个线程都走同步代码块，这样会阻塞。\n\n2. 为什么需要volatile\n\n`instance = new Instance();`这行代码执行过程分为3个步骤：\n- 在堆中开辟空间分配地址\n- 根据类加载器初始化顺序进行初始化\n- 将内存地址保存到栈中的变量\n\nJava模型允许无序写入，可以会出现执行顺序为1-3-2，恰好此时其他线程在第一次if处判断，不是空，直接返回了。后面拿着null去执行肯定会出错。\n\n而使用volatile，会在对instance操作时增加Lock前缀，相当于一个内存屏障，防止指令重排序，就不会出现1-3-2的情况。\n","slug":"kongzheng1993-双检锁","published":1,"updated":"2023-03-08T07:05:58.834Z","layout":"post","photos":[],"link":"","_id":"clg0k2an0009nt26fgy2atepz","content":"<p>双重检查锁定模式（也被称为”双重检查加锁优化”，”锁暗示”（Lock hint）) 是一种软件设计模式用来减少并发系统中竞争和同步的开销。双重检查锁定模式首先验证锁定条件(第一次检查)，只有通过锁定条件验证才真正的进行加锁逻辑并再次验证条件(第二次检查)。</p>\n<p>该模式在某些语言在某些硬件平台的实现可能是不安全的。有的时候，这一模式被看做是反模式。<br>它通常用于减少加锁开销，尤其是为多线程环境中的单例模式实现“惰性初始化”。惰性初始化的意思是直到第一次访问时才初始化它的值。</p>\n<h3 id=\"Java双检锁实现单单例模式\"><a href=\"#Java双检锁实现单单例模式\" class=\"headerlink\" title=\"Java双检锁实现单单例模式\"></a>Java双检锁实现单单例模式</h3><pre><code class=\"java\">public class Singleton {\n        private volatile static Singleton instance;\n\n    private Singleton() {\n\n    }\n\n    public static Singleton getInstance() {\n        if (instance == null) {\n            synchronized (Singleton.class) {\n                if (instance == null) {\n                    instance = new Singleton();\n                }\n            }\n        }\n        return instance;\n    }\n}\n</code></pre>\n<ol>\n<li>为什么双重检验</li>\n</ol>\n<p>如果多个线程同时到达第一个判断，此时isntance为null，多个线程通过这个判断，synchronized还可以加锁，同一时间只有一个线程可以执行同步代码块，同步代码块内再次判断，可以保证只有第一个执行同步代码块的线程会创建出实例。第一个检查的意义在于，实例化后，没必要每个线程都走同步代码块，这样会阻塞。</p>\n<ol start=\"2\">\n<li>为什么需要volatile</li>\n</ol>\n<p><code>instance = new Instance();</code>这行代码执行过程分为3个步骤：</p>\n<ul>\n<li>在堆中开辟空间分配地址</li>\n<li>根据类加载器初始化顺序进行初始化</li>\n<li>将内存地址保存到栈中的变量</li>\n</ul>\n<p>Java模型允许无序写入，可以会出现执行顺序为1-3-2，恰好此时其他线程在第一次if处判断，不是空，直接返回了。后面拿着null去执行肯定会出错。</p>\n<p>而使用volatile，会在对instance操作时增加Lock前缀，相当于一个内存屏障，防止指令重排序，就不会出现1-3-2的情况。</p>\n","site":{"data":{}},"more":"<p>双重检查锁定模式（也被称为”双重检查加锁优化”，”锁暗示”（Lock hint）) 是一种软件设计模式用来减少并发系统中竞争和同步的开销。双重检查锁定模式首先验证锁定条件(第一次检查)，只有通过锁定条件验证才真正的进行加锁逻辑并再次验证条件(第二次检查)。</p>\n<p>该模式在某些语言在某些硬件平台的实现可能是不安全的。有的时候，这一模式被看做是反模式。<br>它通常用于减少加锁开销，尤其是为多线程环境中的单例模式实现“惰性初始化”。惰性初始化的意思是直到第一次访问时才初始化它的值。</p>\n<h3 id=\"Java双检锁实现单单例模式\"><a href=\"#Java双检锁实现单单例模式\" class=\"headerlink\" title=\"Java双检锁实现单单例模式\"></a>Java双检锁实现单单例模式</h3><pre><code class=\"java\">public class Singleton {\n        private volatile static Singleton instance;\n\n    private Singleton() {\n\n    }\n\n    public static Singleton getInstance() {\n        if (instance == null) {\n            synchronized (Singleton.class) {\n                if (instance == null) {\n                    instance = new Singleton();\n                }\n            }\n        }\n        return instance;\n    }\n}\n</code></pre>\n<ol>\n<li>为什么双重检验</li>\n</ol>\n<p>如果多个线程同时到达第一个判断，此时isntance为null，多个线程通过这个判断，synchronized还可以加锁，同一时间只有一个线程可以执行同步代码块，同步代码块内再次判断，可以保证只有第一个执行同步代码块的线程会创建出实例。第一个检查的意义在于，实例化后，没必要每个线程都走同步代码块，这样会阻塞。</p>\n<ol start=\"2\">\n<li>为什么需要volatile</li>\n</ol>\n<p><code>instance = new Instance();</code>这行代码执行过程分为3个步骤：</p>\n<ul>\n<li>在堆中开辟空间分配地址</li>\n<li>根据类加载器初始化顺序进行初始化</li>\n<li>将内存地址保存到栈中的变量</li>\n</ul>\n<p>Java模型允许无序写入，可以会出现执行顺序为1-3-2，恰好此时其他线程在第一次if处判断，不是空，直接返回了。后面拿着null去执行肯定会出错。</p>\n<p>而使用volatile，会在对instance操作时增加Lock前缀，相当于一个内存屏障，防止指令重排序，就不会出现1-3-2的情况。</p>\n"},{"title":"Ribbon重试机制的意义之一：弥补EurekaAP最终一致性","excerpt":"","comments":1,"date":"2023-01-30T02:30:52.000Z","_content":"\n# 背景\n\n随着公司业务量增加，服务qps随之增加。上线发布过程中偶尔报出：“Error creating bean with name 'xxxx': Singleton bean creation not allowed while singletons of this factory are in destruction...”。\n\n# 原因\n\n## 发布过程分析\n\n渐进发布过程：会先销毁一部分pod，然后用新镜像启动相同数量的pod，待新pod启动完成，再销毁剩下的pod，启动剩余的pod。应该是发布过程中，有请求去访问了已经开始销毁的pod（connection refuse等），或者服务没有处理完请求就开始销毁（Error creating bean...）。\n\n## Eureka\n\n在这个过程中，eureka剔除服务实例的时机是连续3次心跳失败，在这期间eureka的保护模式会依然提供已销毁节点的ip。这是Eureka实现的服务治理机制强调了CAP原理中的AP，即可用性与可靠性，它与ZooKeeper这类强调CP的服务治理框架最大的区别就是，Eureka为了实现更高的服务可用性，牺牲了一定的一致性，在极端情况下它宁愿接受故障实例也不要丢掉它认为“健康”的实例。\n\n### 自我保护机制\n\nEureka服务端为了防止Eureka客户端本身是可以正常访问的，但是由于网路通信故障等原因，造成Eureka服务端失去于客户端的连接，从而形成的不可用。因为网络通信是可能恢复的，但是Eureka客户端只会在启动时才去服务端注册。如果因为网络的原因而剔除了客户端，将造成客户端无法再注册到服务端。极端情况下，Eureka还有自我保护机制。\n\n如何选择关闭还是开启自我保护机制？\nEureka服务端默认情况下是会开启自我保护机制的。但我们在不同环境应该选择是否开启保护机制。\n- 一般情况下，我们会选择在 开发环境下关闭自我保护机制，而在生产环境下启动自我保护机制。\n- 开发环境下，我们我们启动的服务数量较少而且会经常修改重启。如果开启自我保护机制，很容易触发Eureka客户端心跳占比低于85%的情况。使得Eureka不会剔除我们的服务，从而在我们访问的时候，会访问到可能已经失效的服务，导致请求失败，影响我们的开发。\n\n在生产环境下，我们启动的服务多且不会反复启动修改。环境也相对稳定，影响服务正常运行的人为情况较少。适合开启自我保护机制，让Eureka进行管理。\n\n## Ribbon重试机制\n\n由于Spring Cloud Eureka在可用性与一致性上的取舍，不论是由于触发了保护机制还是服务剔除的延迟，引起服务调用到故障实例等时候，我们还是希望能够增强对这类问题的容错。所以在服务调用时通常会加入一些重试机制。ribbon的MaxAutoRetries和MaxAutoRetriesNextServer配置可以实现：当访问到故障请求到时候，他会再尝试访问一次当前实例（次数由MaxAutoRetries配置），如果不行，就换一个实例进行访问，如果还是不行，再换一次（更换次数由MaxAutoRetriesNextServer配置），如果依然不行，返回失败信息。\n\n# 思考\n\nRibbon的重试机制可以弥补Eureka的C的缺失，通过重试达到最终一致。但是在复杂的分布式系统中，由于调用链过长可能会产生调用风暴，给正常的服务实例带来巨大的压力。所以还需要配合熔断来保护健康的实例。而且重试的情况需要确认，比如读超时（read timeout）最好是不要重试，即使接口都幂等，也会无端增加系统的压力。\n\n","source":"_posts/2023-02-16-kongzheng1993-eureka_ribbon.md","raw":"---\ntitle: Ribbon重试机制的意义之一：弥补EurekaAP最终一致性\nexcerpt: 'netty'\ntags: [netty]\ncategories: [netty]\ncomments: true\ndate: 2023-01-30 10:30:52\n---\n\n# 背景\n\n随着公司业务量增加，服务qps随之增加。上线发布过程中偶尔报出：“Error creating bean with name 'xxxx': Singleton bean creation not allowed while singletons of this factory are in destruction...”。\n\n# 原因\n\n## 发布过程分析\n\n渐进发布过程：会先销毁一部分pod，然后用新镜像启动相同数量的pod，待新pod启动完成，再销毁剩下的pod，启动剩余的pod。应该是发布过程中，有请求去访问了已经开始销毁的pod（connection refuse等），或者服务没有处理完请求就开始销毁（Error creating bean...）。\n\n## Eureka\n\n在这个过程中，eureka剔除服务实例的时机是连续3次心跳失败，在这期间eureka的保护模式会依然提供已销毁节点的ip。这是Eureka实现的服务治理机制强调了CAP原理中的AP，即可用性与可靠性，它与ZooKeeper这类强调CP的服务治理框架最大的区别就是，Eureka为了实现更高的服务可用性，牺牲了一定的一致性，在极端情况下它宁愿接受故障实例也不要丢掉它认为“健康”的实例。\n\n### 自我保护机制\n\nEureka服务端为了防止Eureka客户端本身是可以正常访问的，但是由于网路通信故障等原因，造成Eureka服务端失去于客户端的连接，从而形成的不可用。因为网络通信是可能恢复的，但是Eureka客户端只会在启动时才去服务端注册。如果因为网络的原因而剔除了客户端，将造成客户端无法再注册到服务端。极端情况下，Eureka还有自我保护机制。\n\n如何选择关闭还是开启自我保护机制？\nEureka服务端默认情况下是会开启自我保护机制的。但我们在不同环境应该选择是否开启保护机制。\n- 一般情况下，我们会选择在 开发环境下关闭自我保护机制，而在生产环境下启动自我保护机制。\n- 开发环境下，我们我们启动的服务数量较少而且会经常修改重启。如果开启自我保护机制，很容易触发Eureka客户端心跳占比低于85%的情况。使得Eureka不会剔除我们的服务，从而在我们访问的时候，会访问到可能已经失效的服务，导致请求失败，影响我们的开发。\n\n在生产环境下，我们启动的服务多且不会反复启动修改。环境也相对稳定，影响服务正常运行的人为情况较少。适合开启自我保护机制，让Eureka进行管理。\n\n## Ribbon重试机制\n\n由于Spring Cloud Eureka在可用性与一致性上的取舍，不论是由于触发了保护机制还是服务剔除的延迟，引起服务调用到故障实例等时候，我们还是希望能够增强对这类问题的容错。所以在服务调用时通常会加入一些重试机制。ribbon的MaxAutoRetries和MaxAutoRetriesNextServer配置可以实现：当访问到故障请求到时候，他会再尝试访问一次当前实例（次数由MaxAutoRetries配置），如果不行，就换一个实例进行访问，如果还是不行，再换一次（更换次数由MaxAutoRetriesNextServer配置），如果依然不行，返回失败信息。\n\n# 思考\n\nRibbon的重试机制可以弥补Eureka的C的缺失，通过重试达到最终一致。但是在复杂的分布式系统中，由于调用链过长可能会产生调用风暴，给正常的服务实例带来巨大的压力。所以还需要配合熔断来保护健康的实例。而且重试的情况需要确认，比如读超时（read timeout）最好是不要重试，即使接口都幂等，也会无端增加系统的压力。\n\n","slug":"kongzheng1993-eureka_ribbon","published":1,"updated":"2023-03-08T07:05:58.835Z","layout":"post","photos":[],"link":"","_id":"clg0k2an0009rt26fuizbv8go","content":"<h1 id=\"背景\"><a href=\"#背景\" class=\"headerlink\" title=\"背景\"></a>背景</h1><p>随着公司业务量增加，服务qps随之增加。上线发布过程中偶尔报出：“Error creating bean with name ‘xxxx’: Singleton bean creation not allowed while singletons of this factory are in destruction…”。</p>\n<h1 id=\"原因\"><a href=\"#原因\" class=\"headerlink\" title=\"原因\"></a>原因</h1><h2 id=\"发布过程分析\"><a href=\"#发布过程分析\" class=\"headerlink\" title=\"发布过程分析\"></a>发布过程分析</h2><p>渐进发布过程：会先销毁一部分pod，然后用新镜像启动相同数量的pod，待新pod启动完成，再销毁剩下的pod，启动剩余的pod。应该是发布过程中，有请求去访问了已经开始销毁的pod（connection refuse等），或者服务没有处理完请求就开始销毁（Error creating bean…）。</p>\n<h2 id=\"Eureka\"><a href=\"#Eureka\" class=\"headerlink\" title=\"Eureka\"></a>Eureka</h2><p>在这个过程中，eureka剔除服务实例的时机是连续3次心跳失败，在这期间eureka的保护模式会依然提供已销毁节点的ip。这是Eureka实现的服务治理机制强调了CAP原理中的AP，即可用性与可靠性，它与ZooKeeper这类强调CP的服务治理框架最大的区别就是，Eureka为了实现更高的服务可用性，牺牲了一定的一致性，在极端情况下它宁愿接受故障实例也不要丢掉它认为“健康”的实例。</p>\n<h3 id=\"自我保护机制\"><a href=\"#自我保护机制\" class=\"headerlink\" title=\"自我保护机制\"></a>自我保护机制</h3><p>Eureka服务端为了防止Eureka客户端本身是可以正常访问的，但是由于网路通信故障等原因，造成Eureka服务端失去于客户端的连接，从而形成的不可用。因为网络通信是可能恢复的，但是Eureka客户端只会在启动时才去服务端注册。如果因为网络的原因而剔除了客户端，将造成客户端无法再注册到服务端。极端情况下，Eureka还有自我保护机制。</p>\n<p>如何选择关闭还是开启自我保护机制？<br>Eureka服务端默认情况下是会开启自我保护机制的。但我们在不同环境应该选择是否开启保护机制。</p>\n<ul>\n<li>一般情况下，我们会选择在 开发环境下关闭自我保护机制，而在生产环境下启动自我保护机制。</li>\n<li>开发环境下，我们我们启动的服务数量较少而且会经常修改重启。如果开启自我保护机制，很容易触发Eureka客户端心跳占比低于85%的情况。使得Eureka不会剔除我们的服务，从而在我们访问的时候，会访问到可能已经失效的服务，导致请求失败，影响我们的开发。</li>\n</ul>\n<p>在生产环境下，我们启动的服务多且不会反复启动修改。环境也相对稳定，影响服务正常运行的人为情况较少。适合开启自我保护机制，让Eureka进行管理。</p>\n<h2 id=\"Ribbon重试机制\"><a href=\"#Ribbon重试机制\" class=\"headerlink\" title=\"Ribbon重试机制\"></a>Ribbon重试机制</h2><p>由于Spring Cloud Eureka在可用性与一致性上的取舍，不论是由于触发了保护机制还是服务剔除的延迟，引起服务调用到故障实例等时候，我们还是希望能够增强对这类问题的容错。所以在服务调用时通常会加入一些重试机制。ribbon的MaxAutoRetries和MaxAutoRetriesNextServer配置可以实现：当访问到故障请求到时候，他会再尝试访问一次当前实例（次数由MaxAutoRetries配置），如果不行，就换一个实例进行访问，如果还是不行，再换一次（更换次数由MaxAutoRetriesNextServer配置），如果依然不行，返回失败信息。</p>\n<h1 id=\"思考\"><a href=\"#思考\" class=\"headerlink\" title=\"思考\"></a>思考</h1><p>Ribbon的重试机制可以弥补Eureka的C的缺失，通过重试达到最终一致。但是在复杂的分布式系统中，由于调用链过长可能会产生调用风暴，给正常的服务实例带来巨大的压力。所以还需要配合熔断来保护健康的实例。而且重试的情况需要确认，比如读超时（read timeout）最好是不要重试，即使接口都幂等，也会无端增加系统的压力。</p>\n","site":{"data":{}},"more":"<h1 id=\"背景\"><a href=\"#背景\" class=\"headerlink\" title=\"背景\"></a>背景</h1><p>随着公司业务量增加，服务qps随之增加。上线发布过程中偶尔报出：“Error creating bean with name ‘xxxx’: Singleton bean creation not allowed while singletons of this factory are in destruction…”。</p>\n<h1 id=\"原因\"><a href=\"#原因\" class=\"headerlink\" title=\"原因\"></a>原因</h1><h2 id=\"发布过程分析\"><a href=\"#发布过程分析\" class=\"headerlink\" title=\"发布过程分析\"></a>发布过程分析</h2><p>渐进发布过程：会先销毁一部分pod，然后用新镜像启动相同数量的pod，待新pod启动完成，再销毁剩下的pod，启动剩余的pod。应该是发布过程中，有请求去访问了已经开始销毁的pod（connection refuse等），或者服务没有处理完请求就开始销毁（Error creating bean…）。</p>\n<h2 id=\"Eureka\"><a href=\"#Eureka\" class=\"headerlink\" title=\"Eureka\"></a>Eureka</h2><p>在这个过程中，eureka剔除服务实例的时机是连续3次心跳失败，在这期间eureka的保护模式会依然提供已销毁节点的ip。这是Eureka实现的服务治理机制强调了CAP原理中的AP，即可用性与可靠性，它与ZooKeeper这类强调CP的服务治理框架最大的区别就是，Eureka为了实现更高的服务可用性，牺牲了一定的一致性，在极端情况下它宁愿接受故障实例也不要丢掉它认为“健康”的实例。</p>\n<h3 id=\"自我保护机制\"><a href=\"#自我保护机制\" class=\"headerlink\" title=\"自我保护机制\"></a>自我保护机制</h3><p>Eureka服务端为了防止Eureka客户端本身是可以正常访问的，但是由于网路通信故障等原因，造成Eureka服务端失去于客户端的连接，从而形成的不可用。因为网络通信是可能恢复的，但是Eureka客户端只会在启动时才去服务端注册。如果因为网络的原因而剔除了客户端，将造成客户端无法再注册到服务端。极端情况下，Eureka还有自我保护机制。</p>\n<p>如何选择关闭还是开启自我保护机制？<br>Eureka服务端默认情况下是会开启自我保护机制的。但我们在不同环境应该选择是否开启保护机制。</p>\n<ul>\n<li>一般情况下，我们会选择在 开发环境下关闭自我保护机制，而在生产环境下启动自我保护机制。</li>\n<li>开发环境下，我们我们启动的服务数量较少而且会经常修改重启。如果开启自我保护机制，很容易触发Eureka客户端心跳占比低于85%的情况。使得Eureka不会剔除我们的服务，从而在我们访问的时候，会访问到可能已经失效的服务，导致请求失败，影响我们的开发。</li>\n</ul>\n<p>在生产环境下，我们启动的服务多且不会反复启动修改。环境也相对稳定，影响服务正常运行的人为情况较少。适合开启自我保护机制，让Eureka进行管理。</p>\n<h2 id=\"Ribbon重试机制\"><a href=\"#Ribbon重试机制\" class=\"headerlink\" title=\"Ribbon重试机制\"></a>Ribbon重试机制</h2><p>由于Spring Cloud Eureka在可用性与一致性上的取舍，不论是由于触发了保护机制还是服务剔除的延迟，引起服务调用到故障实例等时候，我们还是希望能够增强对这类问题的容错。所以在服务调用时通常会加入一些重试机制。ribbon的MaxAutoRetries和MaxAutoRetriesNextServer配置可以实现：当访问到故障请求到时候，他会再尝试访问一次当前实例（次数由MaxAutoRetries配置），如果不行，就换一个实例进行访问，如果还是不行，再换一次（更换次数由MaxAutoRetriesNextServer配置），如果依然不行，返回失败信息。</p>\n<h1 id=\"思考\"><a href=\"#思考\" class=\"headerlink\" title=\"思考\"></a>思考</h1><p>Ribbon的重试机制可以弥补Eureka的C的缺失，通过重试达到最终一致。但是在复杂的分布式系统中，由于调用链过长可能会产生调用风暴，给正常的服务实例带来巨大的压力。所以还需要配合熔断来保护健康的实例。而且重试的情况需要确认，比如读超时（read timeout）最好是不要重试，即使接口都幂等，也会无端增加系统的压力。</p>\n"},{"title":"Controller VS Endpoint","excerpt":"","comments":1,"date":"2023-02-20T02:30:52.000Z","_content":"\n","source":"_posts/2023-03-07-kongzheng1993-think-in-springmvc-and-acutator.md","raw":"---\ntitle: Controller VS Endpoint\nexcerpt: 'SpringMVC and Actuator'\ntags: [SpringMVC, Actuator]\ncategories: [SpringMVC, Actuator]\ncomments: true\ndate: 2023-02-20 10:30:52\n---\n\n","slug":"kongzheng1993-think-in-springmvc-and-acutator","published":1,"updated":"2023-03-23T02:51:23.198Z","layout":"post","photos":[],"link":"","_id":"clg0k2an1009tt26fgep1l2vf","content":"","site":{"data":{}},"more":""},{"layout":"post","title":"Resume","date":"2022-07-12T16:00:00.000Z","excerpt":"","top":999,"comments":1,"_content":"\n## 联系方式\n\n- 手机/微信：15810692477\n- Email：kongzheng1993@hotmail.com\n- QQ：767141624\n\n---\n\n## 个人信息\n\n- 孔征/男/1992\n- 本科/菏泽学院/计算机与信息工程系\n- 毕业时间：2016年7月\n- 技术博客：[https://evilRat.github.io](https://evilRat.github.io)\n- Github: [https://github.com/evilRat](https://github.com/evilRat)\n- 微信公众号：evilRat\n\n---\n\n## 近况简介\n\n在理想汽车负责销服计划和交付质量两条业务线，系统相关人员包括开发3人、测试2人、产品1人、业务1人。\n\n研发过程为敏捷迭代：\n\n- 使用飞书（项目、IM、文档、视频会议、OKR、日历）工具进行协作和项目管理\n- 使用Git进行代码版本控制\n- 使用Gerrit（CR）、Jenkins（BV）、Sonar（SV）保证代码质量\n- 使用Jenkins、K8s、Docker、Git实现全流程的CI/CD。\n\n作为系统负责人，参与需求研发的全流程，包括需求评审、产品评审、排期、技术方案设计、任务分配、功能开发、测试用例评审和bug修复。关注相关服务的健康状态，适时进行重构、优化。保障上线操作无误，至今0回滚，系统常年可用性在99.99%以上。\n\n此外，作为研发部核心骨干参与发布会等重大项目。\n\n## 工作经验\n\n### 理想汽车  （2020年9月至今）\n\n企业系统部，负责交付、物流和质量相关系统研发工作。\n\n### 亚信科技 （2018年10月-2020年6月）\n\n北京移动客服项目、中移在线北京分公司统一接口平台、移动营业厅一体机等项目开发。作为组内主力开发，组内5人，解决开发过程中的难点、重点问题，保证需求按时高质量交付。\n\n### 软通动力 （2016年8月-2018年10月）\n\n中国移动在线服务公司北京10086&12580呼叫中心开发运维工作，包括呼叫中心流程开发、数据库开发和接口开发。\n\n---\n\n## 项目经验\n\n### 销服计划（2023年6月至今）\n负责从0到1建设销服计划业务线，包含PSI产供销计划、分车系统和销服驾驶舱三个系统。\n- PSI产供销计划平台\n    1. 生产量、订单量、销售量、上线量等数据卷积预测\n    2. 周维度、月维度的历史实际值查看\n    3. 分价格段的市占率计算\n    4. PSI滚动看板：DOS、要货需求等数据计算和查看\n- 分车系统：现货模式下，为了保证健康的DOS，实现中央到省区、VDC，省区到门店的铺货与运输，以及门店主动挑车、释放的功能。\n- 销服驾驶舱：为公司高层提供的战略级看板，目前主要是上线量和市占率数据的多维度、多形式的展示。\n\n### 理想汽车L7发布会项目（2022年10月--2023年2月）\n\n理想汽车新车发布会是公司级重点项目，是对企业系统的一次大流量考验，是理想汽车的“双11”。本人在项目中参与了服务核心链路梳理，交易系统Code Review和重构，服务扩容、限流、降级功能梳理，应急预案设计，作战手册制定，发布会排练以及最终发布会保障。发布会过程中负责服务的监控和水位播报，按照作战手册完成发布会中的服务降级、限流等操作，监控网关异常流量，配合安全团队封禁恶意IP。最终0失误完成发布会保障工作，呈现了一场完美的发布会，2月8日当晚理想发布会很“苹果”冲上微博热搜。\n\n### 交付准备系统（2021年5月至今）\n\n交付准备管理系统（PC&APP），车辆清洗、PDI、整备、终检、OTA升级和质量登记等功能，主要是交付中心PDI团队人员和管理者使用。车辆交付周期内节点事件触发系统自动生成响应的工单，PDI人员可以通过PC或者APP操作相关工单或手动创建/取消工单，管理者可以通过系统查看数据、管理团队。\n- 作为系统负责人，参与需求评审、产品评审、排期、任务分配、功能开发、测试用例评审和bug修复工作\n- 服务监控、告警跟进处理、代码重构、需求自驱等\n- 负责理想家APP交付准备系统研发项目。系统上线后，交付中心的pdi时间由原来的半小时以上，降低到13分钟。**本人也因此在2021年Q4得到绩效E（超出预期）**\n- 打通售后服务系统，质损创建维修工单耗时缩短80%\n- 从0建设自动&手动OTA能力，通过较强的抽象能力，为公司节省4HC，推送覆盖70%交付车辆，极大提高了交付效率\n\n### 整车物流系统（2020年9月至今）\n\n车辆下产线到交付交接完成期间的车辆运输和仓储相关的业务系统，事件驱动，实现车辆的自动/手动释放，出入库单、运输单、提交车计划和司机板车的管理，以及车辆运输的质量管理和供应商绩效的管理，系统包括PC端管理系统、APP（车辆维护、远程交付、特殊运输）和车辆交接微信小程序。参与新功能开发和旧有功能的维护和优化。\n\n- 车辆维护APP后台的开发和上线，其中对于生成车辆维护工单的逻辑优化，使工单生成的业务节点更准确，避免了重复生成维护工单，APP的使用提高人效50%\n- 车辆交接小程序中提车计划的重构，规范了板车司机、门卫、仓管和运管的操作，闭环了车辆生产完成到交付完成之间每一次运输的提车和交车流程\n- 理想汽车远程交付功能开发（PC端+APP端），支持配送车辆到客户指定地点进行交接，简化业务流程，提升用户体验。获得了**2022年中国汽车物流行业创新奖**\n\n### 整车交付系统（2020年9月--2021年6月）\n\n用户主要是交付专家和中央管理人员，主要功能包括交付单管理、交付任务管理等。本人的工作是在添加新功能的同时维护已有功能，通过技术手段提高交付人员的效率，降低交付成本。负责开发了交付违约管理、交付pipeline等功能。交付违约管理功能，在客户无法在预约时间提车时，交付专家可以手动或者订单取消、挂起等事件自动触发进入违约流程，创建违约工单群，并将产品专家、零售店长、交付专家、交付店长等订单相关人员拉入群聊，在飞书机器人的引导下，完成发送提醒短信给用户等跟进手段，提高了人效、降低了沟通成本，**客户违约率降低30%**。\n\n### 中移在线北京统一接口平台（2018年10月--2020年6月）\n\n此项目为中国移动在线公司北京分公司统一接口平台。此系统为中间层，为中移在线北京分公司10086IVR、营业厅一体机、app、微信、门户网站等渠道提供接入转接服务。各渠道过来的请求，由接口平台转接到能力提供方，再将能力响应信息返回给调用方。大部分接口要做一些数据格式的转换和数据内容的映射，以适应各个渠道的调用。此系统为分布式架构（nginx、tomcat、redis、mysql、zookeeper、dubbo），使用spring作为ioc容器，使用jersey提供RESTful接口。在页面可以进行接入接口、转接接口、接口映射、接口编排、接入参数、转接参数、参数映射、接入渠道、渠道权限等的配置。接收请求后，程序会通过调用url获取到通过redis/mysql获取到此接口的相关配置，并根据获取到的参数配置进行参数校验、参数处理、参数映射，调用转接接口获取响应后处理并返回给调用方。根据需求完成各类接口的开发、测试、联调、发布。负责实现了项目的动态数据源和redis集群搭建与集成。\n- “移娃”项目中，引入redis实现了用户和“移娃”的会话上下文记录10min，利用redis速度和过期时间的天然优势，完美实现了功能\n- 优化了接口平台字段名大写蛇形（XXX_YYY）转驼峰（xxxYYY）算法，**500ms优化到20ms**，极大提高了接口RT。[**查看详情**](https://evilRat.github.io/2020/03/25/kongzheng1993-%E4%B8%80%E6%AC%A1%E8%80%81%E4%BB%A3%E7%A0%81%E4%BC%98%E5%8C%96/)\n\n---\n\n## 专业技能\n\n### 编程语言\n\n- Java: &#x2B50;&#x2B50;&#x2B50;\n- SQL: &#x2B50;&#x2B50;&#x2B50;\n- JavaScript: &#x2B50;&#x2B50;\n- HTML: &#x2B50;&#x2B50;\n- CSS: &#x2B50;&#x2B50;\n- Python: &#x2B50;\n- Shell: &#x2B50;\n\n### 工具\n\n- Maven: &#x2B50;&#x2B50;&#x2B50;\n- Git: &#x2B50;&#x2B50;&#x2B50;\n- SVN: &#x2B50;&#x2B50;&#x2B50;\n- Element UI: &#x2B50;&#x2B50;&#x2B50;\n\n### 框架\n\n- Spring: &#x2B50;&#x2B50;&#x2B50;\n- Spring Cloud: &#x2B50;&#x2B50;\n- MyBatis: &#x2B50;&#x2B50;&#x2B50;\n- Vue: &#x2B50;&#x2B50;\n- JUnit: &#x2B50;\n\n### 中间件\n\n- MySQL: &#x2B50;&#x2B50;\n- Oracle: &#x2B50;&#x2B50;\n- RocketMQ: &#x2B50;\n- Zookeeper: &#x2B50;\n- Redis: &#x2B50;&#x2B50;\n\n### 其他\n\n- Docker：&#x2B50;\n- K8s：&#x2B50;\n- Jenkins：&#x2B50;\n- Flink：&#x2B50;\n\n---\n\n## 开源作品\n\n- ftp文件下载工具 [github:downloadFiles](https://github.com/evilRat/downloadFiles)\n\n- testIVR配置文件生成工具 [github:GuiGenerateTestIVRConfig](https://github.com/evilRat/GuiGenerateTestIVRConfig)\n\n- 使用node.js+zookeeper+redis实现服务发现 [github:evil-service-discovery](https://github.com/evilRat/evil-service-discovery)\n\n- springboot+quartz+mysql定时任务集群 [github:EvilTask](https://github.com/evilRat/Eviltask)\n\n**更多请查看我的[GitHub](https://github.com/evilRat)**\n\n## 自我评价\n\n有较好的职业素养，对工作积极负责，有创新意识和团队合作精神。热爱技术、热爱编码、热爱学习，喜欢阅读技术书刊、源码，学习能力较强，能快速将学习内容转化为生产力。态度乐观，有较好的沟通能力，为人热情，可以在工作中统合综效，实现共赢。\n\n---\n\n## 致谢\n\n感谢您花时间阅读我的简历，期待能有机会和您共事。\n","source":"_posts/2016-05-21-kongzheng1993-resume.md","raw":"---\nlayout: post\ntitle: \"Resume\"\ndate: 2022-07-13\nexcerpt: \"resume 简历\"\ntags: [resume,简历]\ncategories: [resume]\ntop: 999\ncomments: true\n---\n\n## 联系方式\n\n- 手机/微信：15810692477\n- Email：kongzheng1993@hotmail.com\n- QQ：767141624\n\n---\n\n## 个人信息\n\n- 孔征/男/1992\n- 本科/菏泽学院/计算机与信息工程系\n- 毕业时间：2016年7月\n- 技术博客：[https://evilRat.github.io](https://evilRat.github.io)\n- Github: [https://github.com/evilRat](https://github.com/evilRat)\n- 微信公众号：evilRat\n\n---\n\n## 近况简介\n\n在理想汽车负责销服计划和交付质量两条业务线，系统相关人员包括开发3人、测试2人、产品1人、业务1人。\n\n研发过程为敏捷迭代：\n\n- 使用飞书（项目、IM、文档、视频会议、OKR、日历）工具进行协作和项目管理\n- 使用Git进行代码版本控制\n- 使用Gerrit（CR）、Jenkins（BV）、Sonar（SV）保证代码质量\n- 使用Jenkins、K8s、Docker、Git实现全流程的CI/CD。\n\n作为系统负责人，参与需求研发的全流程，包括需求评审、产品评审、排期、技术方案设计、任务分配、功能开发、测试用例评审和bug修复。关注相关服务的健康状态，适时进行重构、优化。保障上线操作无误，至今0回滚，系统常年可用性在99.99%以上。\n\n此外，作为研发部核心骨干参与发布会等重大项目。\n\n## 工作经验\n\n### 理想汽车  （2020年9月至今）\n\n企业系统部，负责交付、物流和质量相关系统研发工作。\n\n### 亚信科技 （2018年10月-2020年6月）\n\n北京移动客服项目、中移在线北京分公司统一接口平台、移动营业厅一体机等项目开发。作为组内主力开发，组内5人，解决开发过程中的难点、重点问题，保证需求按时高质量交付。\n\n### 软通动力 （2016年8月-2018年10月）\n\n中国移动在线服务公司北京10086&12580呼叫中心开发运维工作，包括呼叫中心流程开发、数据库开发和接口开发。\n\n---\n\n## 项目经验\n\n### 销服计划（2023年6月至今）\n负责从0到1建设销服计划业务线，包含PSI产供销计划、分车系统和销服驾驶舱三个系统。\n- PSI产供销计划平台\n    1. 生产量、订单量、销售量、上线量等数据卷积预测\n    2. 周维度、月维度的历史实际值查看\n    3. 分价格段的市占率计算\n    4. PSI滚动看板：DOS、要货需求等数据计算和查看\n- 分车系统：现货模式下，为了保证健康的DOS，实现中央到省区、VDC，省区到门店的铺货与运输，以及门店主动挑车、释放的功能。\n- 销服驾驶舱：为公司高层提供的战略级看板，目前主要是上线量和市占率数据的多维度、多形式的展示。\n\n### 理想汽车L7发布会项目（2022年10月--2023年2月）\n\n理想汽车新车发布会是公司级重点项目，是对企业系统的一次大流量考验，是理想汽车的“双11”。本人在项目中参与了服务核心链路梳理，交易系统Code Review和重构，服务扩容、限流、降级功能梳理，应急预案设计，作战手册制定，发布会排练以及最终发布会保障。发布会过程中负责服务的监控和水位播报，按照作战手册完成发布会中的服务降级、限流等操作，监控网关异常流量，配合安全团队封禁恶意IP。最终0失误完成发布会保障工作，呈现了一场完美的发布会，2月8日当晚理想发布会很“苹果”冲上微博热搜。\n\n### 交付准备系统（2021年5月至今）\n\n交付准备管理系统（PC&APP），车辆清洗、PDI、整备、终检、OTA升级和质量登记等功能，主要是交付中心PDI团队人员和管理者使用。车辆交付周期内节点事件触发系统自动生成响应的工单，PDI人员可以通过PC或者APP操作相关工单或手动创建/取消工单，管理者可以通过系统查看数据、管理团队。\n- 作为系统负责人，参与需求评审、产品评审、排期、任务分配、功能开发、测试用例评审和bug修复工作\n- 服务监控、告警跟进处理、代码重构、需求自驱等\n- 负责理想家APP交付准备系统研发项目。系统上线后，交付中心的pdi时间由原来的半小时以上，降低到13分钟。**本人也因此在2021年Q4得到绩效E（超出预期）**\n- 打通售后服务系统，质损创建维修工单耗时缩短80%\n- 从0建设自动&手动OTA能力，通过较强的抽象能力，为公司节省4HC，推送覆盖70%交付车辆，极大提高了交付效率\n\n### 整车物流系统（2020年9月至今）\n\n车辆下产线到交付交接完成期间的车辆运输和仓储相关的业务系统，事件驱动，实现车辆的自动/手动释放，出入库单、运输单、提交车计划和司机板车的管理，以及车辆运输的质量管理和供应商绩效的管理，系统包括PC端管理系统、APP（车辆维护、远程交付、特殊运输）和车辆交接微信小程序。参与新功能开发和旧有功能的维护和优化。\n\n- 车辆维护APP后台的开发和上线，其中对于生成车辆维护工单的逻辑优化，使工单生成的业务节点更准确，避免了重复生成维护工单，APP的使用提高人效50%\n- 车辆交接小程序中提车计划的重构，规范了板车司机、门卫、仓管和运管的操作，闭环了车辆生产完成到交付完成之间每一次运输的提车和交车流程\n- 理想汽车远程交付功能开发（PC端+APP端），支持配送车辆到客户指定地点进行交接，简化业务流程，提升用户体验。获得了**2022年中国汽车物流行业创新奖**\n\n### 整车交付系统（2020年9月--2021年6月）\n\n用户主要是交付专家和中央管理人员，主要功能包括交付单管理、交付任务管理等。本人的工作是在添加新功能的同时维护已有功能，通过技术手段提高交付人员的效率，降低交付成本。负责开发了交付违约管理、交付pipeline等功能。交付违约管理功能，在客户无法在预约时间提车时，交付专家可以手动或者订单取消、挂起等事件自动触发进入违约流程，创建违约工单群，并将产品专家、零售店长、交付专家、交付店长等订单相关人员拉入群聊，在飞书机器人的引导下，完成发送提醒短信给用户等跟进手段，提高了人效、降低了沟通成本，**客户违约率降低30%**。\n\n### 中移在线北京统一接口平台（2018年10月--2020年6月）\n\n此项目为中国移动在线公司北京分公司统一接口平台。此系统为中间层，为中移在线北京分公司10086IVR、营业厅一体机、app、微信、门户网站等渠道提供接入转接服务。各渠道过来的请求，由接口平台转接到能力提供方，再将能力响应信息返回给调用方。大部分接口要做一些数据格式的转换和数据内容的映射，以适应各个渠道的调用。此系统为分布式架构（nginx、tomcat、redis、mysql、zookeeper、dubbo），使用spring作为ioc容器，使用jersey提供RESTful接口。在页面可以进行接入接口、转接接口、接口映射、接口编排、接入参数、转接参数、参数映射、接入渠道、渠道权限等的配置。接收请求后，程序会通过调用url获取到通过redis/mysql获取到此接口的相关配置，并根据获取到的参数配置进行参数校验、参数处理、参数映射，调用转接接口获取响应后处理并返回给调用方。根据需求完成各类接口的开发、测试、联调、发布。负责实现了项目的动态数据源和redis集群搭建与集成。\n- “移娃”项目中，引入redis实现了用户和“移娃”的会话上下文记录10min，利用redis速度和过期时间的天然优势，完美实现了功能\n- 优化了接口平台字段名大写蛇形（XXX_YYY）转驼峰（xxxYYY）算法，**500ms优化到20ms**，极大提高了接口RT。[**查看详情**](https://evilRat.github.io/2020/03/25/kongzheng1993-%E4%B8%80%E6%AC%A1%E8%80%81%E4%BB%A3%E7%A0%81%E4%BC%98%E5%8C%96/)\n\n---\n\n## 专业技能\n\n### 编程语言\n\n- Java: &#x2B50;&#x2B50;&#x2B50;\n- SQL: &#x2B50;&#x2B50;&#x2B50;\n- JavaScript: &#x2B50;&#x2B50;\n- HTML: &#x2B50;&#x2B50;\n- CSS: &#x2B50;&#x2B50;\n- Python: &#x2B50;\n- Shell: &#x2B50;\n\n### 工具\n\n- Maven: &#x2B50;&#x2B50;&#x2B50;\n- Git: &#x2B50;&#x2B50;&#x2B50;\n- SVN: &#x2B50;&#x2B50;&#x2B50;\n- Element UI: &#x2B50;&#x2B50;&#x2B50;\n\n### 框架\n\n- Spring: &#x2B50;&#x2B50;&#x2B50;\n- Spring Cloud: &#x2B50;&#x2B50;\n- MyBatis: &#x2B50;&#x2B50;&#x2B50;\n- Vue: &#x2B50;&#x2B50;\n- JUnit: &#x2B50;\n\n### 中间件\n\n- MySQL: &#x2B50;&#x2B50;\n- Oracle: &#x2B50;&#x2B50;\n- RocketMQ: &#x2B50;\n- Zookeeper: &#x2B50;\n- Redis: &#x2B50;&#x2B50;\n\n### 其他\n\n- Docker：&#x2B50;\n- K8s：&#x2B50;\n- Jenkins：&#x2B50;\n- Flink：&#x2B50;\n\n---\n\n## 开源作品\n\n- ftp文件下载工具 [github:downloadFiles](https://github.com/evilRat/downloadFiles)\n\n- testIVR配置文件生成工具 [github:GuiGenerateTestIVRConfig](https://github.com/evilRat/GuiGenerateTestIVRConfig)\n\n- 使用node.js+zookeeper+redis实现服务发现 [github:evil-service-discovery](https://github.com/evilRat/evil-service-discovery)\n\n- springboot+quartz+mysql定时任务集群 [github:EvilTask](https://github.com/evilRat/Eviltask)\n\n**更多请查看我的[GitHub](https://github.com/evilRat)**\n\n## 自我评价\n\n有较好的职业素养，对工作积极负责，有创新意识和团队合作精神。热爱技术、热爱编码、热爱学习，喜欢阅读技术书刊、源码，学习能力较强，能快速将学习内容转化为生产力。态度乐观，有较好的沟通能力，为人热情，可以在工作中统合综效，实现共赢。\n\n---\n\n## 致谢\n\n感谢您花时间阅读我的简历，期待能有机会和您共事。\n","slug":"kongzheng1993-resume","published":1,"updated":"2024-05-19T03:13:04.661Z","_id":"clg0k2aog00hct26fsr149y42","photos":[],"link":"","content":"<h2 id=\"联系方式\"><a href=\"#联系方式\" class=\"headerlink\" title=\"联系方式\"></a>联系方式</h2><ul>\n<li>手机/微信：15810692477</li>\n<li>Email：<a href=\"mailto:kongzheng1993@hotmail.com\" target=\"_blank\" rel=\"noopener\">kongzheng1993@hotmail.com</a></li>\n<li>QQ：767141624</li>\n</ul>\n<hr>\n<h2 id=\"个人信息\"><a href=\"#个人信息\" class=\"headerlink\" title=\"个人信息\"></a>个人信息</h2><ul>\n<li>孔征/男/1992</li>\n<li>本科/菏泽学院/计算机与信息工程系</li>\n<li>毕业时间：2016年7月</li>\n<li>技术博客：<a href=\"https://evilRat.github.io\" target=\"_blank\" rel=\"noopener\">https://evilRat.github.io</a></li>\n<li>Github: <a href=\"https://github.com/evilRat\" target=\"_blank\" rel=\"noopener\">https://github.com/evilRat</a></li>\n<li>微信公众号：evilRat</li>\n</ul>\n<hr>\n<h2 id=\"近况简介\"><a href=\"#近况简介\" class=\"headerlink\" title=\"近况简介\"></a>近况简介</h2><p>在理想汽车负责销服计划和交付质量两条业务线，系统相关人员包括开发3人、测试2人、产品1人、业务1人。</p>\n<p>研发过程为敏捷迭代：</p>\n<ul>\n<li>使用飞书（项目、IM、文档、视频会议、OKR、日历）工具进行协作和项目管理</li>\n<li>使用Git进行代码版本控制</li>\n<li>使用Gerrit（CR）、Jenkins（BV）、Sonar（SV）保证代码质量</li>\n<li>使用Jenkins、K8s、Docker、Git实现全流程的CI/CD。</li>\n</ul>\n<p>作为系统负责人，参与需求研发的全流程，包括需求评审、产品评审、排期、技术方案设计、任务分配、功能开发、测试用例评审和bug修复。关注相关服务的健康状态，适时进行重构、优化。保障上线操作无误，至今0回滚，系统常年可用性在99.99%以上。</p>\n<p>此外，作为研发部核心骨干参与发布会等重大项目。</p>\n<h2 id=\"工作经验\"><a href=\"#工作经验\" class=\"headerlink\" title=\"工作经验\"></a>工作经验</h2><h3 id=\"理想汽车-（2020年9月至今）\"><a href=\"#理想汽车-（2020年9月至今）\" class=\"headerlink\" title=\"理想汽车  （2020年9月至今）\"></a>理想汽车  （2020年9月至今）</h3><p>企业系统部，负责交付、物流和质量相关系统研发工作。</p>\n<h3 id=\"亚信科技-（2018年10月-2020年6月）\"><a href=\"#亚信科技-（2018年10月-2020年6月）\" class=\"headerlink\" title=\"亚信科技 （2018年10月-2020年6月）\"></a>亚信科技 （2018年10月-2020年6月）</h3><p>北京移动客服项目、中移在线北京分公司统一接口平台、移动营业厅一体机等项目开发。作为组内主力开发，组内5人，解决开发过程中的难点、重点问题，保证需求按时高质量交付。</p>\n<h3 id=\"软通动力-（2016年8月-2018年10月）\"><a href=\"#软通动力-（2016年8月-2018年10月）\" class=\"headerlink\" title=\"软通动力 （2016年8月-2018年10月）\"></a>软通动力 （2016年8月-2018年10月）</h3><p>中国移动在线服务公司北京10086&amp;12580呼叫中心开发运维工作，包括呼叫中心流程开发、数据库开发和接口开发。</p>\n<hr>\n<h2 id=\"项目经验\"><a href=\"#项目经验\" class=\"headerlink\" title=\"项目经验\"></a>项目经验</h2><h3 id=\"销服计划（2023年6月至今）\"><a href=\"#销服计划（2023年6月至今）\" class=\"headerlink\" title=\"销服计划（2023年6月至今）\"></a>销服计划（2023年6月至今）</h3><p>负责从0到1建设销服计划业务线，包含PSI产供销计划、分车系统和销服驾驶舱三个系统。</p>\n<ul>\n<li>PSI产供销计划平台<ol>\n<li>生产量、订单量、销售量、上线量等数据卷积预测</li>\n<li>周维度、月维度的历史实际值查看</li>\n<li>分价格段的市占率计算</li>\n<li>PSI滚动看板：DOS、要货需求等数据计算和查看</li>\n</ol>\n</li>\n<li>分车系统：现货模式下，为了保证健康的DOS，实现中央到省区、VDC，省区到门店的铺货与运输，以及门店主动挑车、释放的功能。</li>\n<li>销服驾驶舱：为公司高层提供的战略级看板，目前主要是上线量和市占率数据的多维度、多形式的展示。</li>\n</ul>\n<h3 id=\"理想汽车L7发布会项目（2022年10月–2023年2月）\"><a href=\"#理想汽车L7发布会项目（2022年10月–2023年2月）\" class=\"headerlink\" title=\"理想汽车L7发布会项目（2022年10月–2023年2月）\"></a>理想汽车L7发布会项目（2022年10月–2023年2月）</h3><p>理想汽车新车发布会是公司级重点项目，是对企业系统的一次大流量考验，是理想汽车的“双11”。本人在项目中参与了服务核心链路梳理，交易系统Code Review和重构，服务扩容、限流、降级功能梳理，应急预案设计，作战手册制定，发布会排练以及最终发布会保障。发布会过程中负责服务的监控和水位播报，按照作战手册完成发布会中的服务降级、限流等操作，监控网关异常流量，配合安全团队封禁恶意IP。最终0失误完成发布会保障工作，呈现了一场完美的发布会，2月8日当晚理想发布会很“苹果”冲上微博热搜。</p>\n<h3 id=\"交付准备系统（2021年5月至今）\"><a href=\"#交付准备系统（2021年5月至今）\" class=\"headerlink\" title=\"交付准备系统（2021年5月至今）\"></a>交付准备系统（2021年5月至今）</h3><p>交付准备管理系统（PC&amp;APP），车辆清洗、PDI、整备、终检、OTA升级和质量登记等功能，主要是交付中心PDI团队人员和管理者使用。车辆交付周期内节点事件触发系统自动生成响应的工单，PDI人员可以通过PC或者APP操作相关工单或手动创建/取消工单，管理者可以通过系统查看数据、管理团队。</p>\n<ul>\n<li>作为系统负责人，参与需求评审、产品评审、排期、任务分配、功能开发、测试用例评审和bug修复工作</li>\n<li>服务监控、告警跟进处理、代码重构、需求自驱等</li>\n<li>负责理想家APP交付准备系统研发项目。系统上线后，交付中心的pdi时间由原来的半小时以上，降低到13分钟。<strong>本人也因此在2021年Q4得到绩效E（超出预期）</strong></li>\n<li>打通售后服务系统，质损创建维修工单耗时缩短80%</li>\n<li>从0建设自动&amp;手动OTA能力，通过较强的抽象能力，为公司节省4HC，推送覆盖70%交付车辆，极大提高了交付效率</li>\n</ul>\n<h3 id=\"整车物流系统（2020年9月至今）\"><a href=\"#整车物流系统（2020年9月至今）\" class=\"headerlink\" title=\"整车物流系统（2020年9月至今）\"></a>整车物流系统（2020年9月至今）</h3><p>车辆下产线到交付交接完成期间的车辆运输和仓储相关的业务系统，事件驱动，实现车辆的自动/手动释放，出入库单、运输单、提交车计划和司机板车的管理，以及车辆运输的质量管理和供应商绩效的管理，系统包括PC端管理系统、APP（车辆维护、远程交付、特殊运输）和车辆交接微信小程序。参与新功能开发和旧有功能的维护和优化。</p>\n<ul>\n<li>车辆维护APP后台的开发和上线，其中对于生成车辆维护工单的逻辑优化，使工单生成的业务节点更准确，避免了重复生成维护工单，APP的使用提高人效50%</li>\n<li>车辆交接小程序中提车计划的重构，规范了板车司机、门卫、仓管和运管的操作，闭环了车辆生产完成到交付完成之间每一次运输的提车和交车流程</li>\n<li>理想汽车远程交付功能开发（PC端+APP端），支持配送车辆到客户指定地点进行交接，简化业务流程，提升用户体验。获得了<strong>2022年中国汽车物流行业创新奖</strong></li>\n</ul>\n<h3 id=\"整车交付系统（2020年9月–2021年6月）\"><a href=\"#整车交付系统（2020年9月–2021年6月）\" class=\"headerlink\" title=\"整车交付系统（2020年9月–2021年6月）\"></a>整车交付系统（2020年9月–2021年6月）</h3><p>用户主要是交付专家和中央管理人员，主要功能包括交付单管理、交付任务管理等。本人的工作是在添加新功能的同时维护已有功能，通过技术手段提高交付人员的效率，降低交付成本。负责开发了交付违约管理、交付pipeline等功能。交付违约管理功能，在客户无法在预约时间提车时，交付专家可以手动或者订单取消、挂起等事件自动触发进入违约流程，创建违约工单群，并将产品专家、零售店长、交付专家、交付店长等订单相关人员拉入群聊，在飞书机器人的引导下，完成发送提醒短信给用户等跟进手段，提高了人效、降低了沟通成本，<strong>客户违约率降低30%</strong>。</p>\n<h3 id=\"中移在线北京统一接口平台（2018年10月–2020年6月）\"><a href=\"#中移在线北京统一接口平台（2018年10月–2020年6月）\" class=\"headerlink\" title=\"中移在线北京统一接口平台（2018年10月–2020年6月）\"></a>中移在线北京统一接口平台（2018年10月–2020年6月）</h3><p>此项目为中国移动在线公司北京分公司统一接口平台。此系统为中间层，为中移在线北京分公司10086IVR、营业厅一体机、app、微信、门户网站等渠道提供接入转接服务。各渠道过来的请求，由接口平台转接到能力提供方，再将能力响应信息返回给调用方。大部分接口要做一些数据格式的转换和数据内容的映射，以适应各个渠道的调用。此系统为分布式架构（nginx、tomcat、redis、mysql、zookeeper、dubbo），使用spring作为ioc容器，使用jersey提供RESTful接口。在页面可以进行接入接口、转接接口、接口映射、接口编排、接入参数、转接参数、参数映射、接入渠道、渠道权限等的配置。接收请求后，程序会通过调用url获取到通过redis/mysql获取到此接口的相关配置，并根据获取到的参数配置进行参数校验、参数处理、参数映射，调用转接接口获取响应后处理并返回给调用方。根据需求完成各类接口的开发、测试、联调、发布。负责实现了项目的动态数据源和redis集群搭建与集成。</p>\n<ul>\n<li>“移娃”项目中，引入redis实现了用户和“移娃”的会话上下文记录10min，利用redis速度和过期时间的天然优势，完美实现了功能</li>\n<li>优化了接口平台字段名大写蛇形（XXX_YYY）转驼峰（xxxYYY）算法，<strong>500ms优化到20ms</strong>，极大提高了接口RT。<a href=\"https://evilRat.github.io/2020/03/25/kongzheng1993-%E4%B8%80%E6%AC%A1%E8%80%81%E4%BB%A3%E7%A0%81%E4%BC%98%E5%8C%96/\" target=\"_blank\" rel=\"noopener\"><strong>查看详情</strong></a></li>\n</ul>\n<hr>\n<h2 id=\"专业技能\"><a href=\"#专业技能\" class=\"headerlink\" title=\"专业技能\"></a>专业技能</h2><h3 id=\"编程语言\"><a href=\"#编程语言\" class=\"headerlink\" title=\"编程语言\"></a>编程语言</h3><ul>\n<li>Java: &#x2B50;&#x2B50;&#x2B50;</li>\n<li>SQL: &#x2B50;&#x2B50;&#x2B50;</li>\n<li>JavaScript: &#x2B50;&#x2B50;</li>\n<li>HTML: &#x2B50;&#x2B50;</li>\n<li>CSS: &#x2B50;&#x2B50;</li>\n<li>Python: &#x2B50;</li>\n<li>Shell: &#x2B50;</li>\n</ul>\n<h3 id=\"工具\"><a href=\"#工具\" class=\"headerlink\" title=\"工具\"></a>工具</h3><ul>\n<li>Maven: &#x2B50;&#x2B50;&#x2B50;</li>\n<li>Git: &#x2B50;&#x2B50;&#x2B50;</li>\n<li>SVN: &#x2B50;&#x2B50;&#x2B50;</li>\n<li>Element UI: &#x2B50;&#x2B50;&#x2B50;</li>\n</ul>\n<h3 id=\"框架\"><a href=\"#框架\" class=\"headerlink\" title=\"框架\"></a>框架</h3><ul>\n<li>Spring: &#x2B50;&#x2B50;&#x2B50;</li>\n<li>Spring Cloud: &#x2B50;&#x2B50;</li>\n<li>MyBatis: &#x2B50;&#x2B50;&#x2B50;</li>\n<li>Vue: &#x2B50;&#x2B50;</li>\n<li>JUnit: &#x2B50;</li>\n</ul>\n<h3 id=\"中间件\"><a href=\"#中间件\" class=\"headerlink\" title=\"中间件\"></a>中间件</h3><ul>\n<li>MySQL: &#x2B50;&#x2B50;</li>\n<li>Oracle: &#x2B50;&#x2B50;</li>\n<li>RocketMQ: &#x2B50;</li>\n<li>Zookeeper: &#x2B50;</li>\n<li>Redis: &#x2B50;&#x2B50;</li>\n</ul>\n<h3 id=\"其他\"><a href=\"#其他\" class=\"headerlink\" title=\"其他\"></a>其他</h3><ul>\n<li>Docker：&#x2B50;</li>\n<li>K8s：&#x2B50;</li>\n<li>Jenkins：&#x2B50;</li>\n<li>Flink：&#x2B50;</li>\n</ul>\n<hr>\n<h2 id=\"开源作品\"><a href=\"#开源作品\" class=\"headerlink\" title=\"开源作品\"></a>开源作品</h2><ul>\n<li><p>ftp文件下载工具 <a href=\"https://github.com/evilRat/downloadFiles\" target=\"_blank\" rel=\"noopener\">github:downloadFiles</a></p>\n</li>\n<li><p>testIVR配置文件生成工具 <a href=\"https://github.com/evilRat/GuiGenerateTestIVRConfig\" target=\"_blank\" rel=\"noopener\">github:GuiGenerateTestIVRConfig</a></p>\n</li>\n<li><p>使用node.js+zookeeper+redis实现服务发现 <a href=\"https://github.com/evilRat/evil-service-discovery\" target=\"_blank\" rel=\"noopener\">github:evil-service-discovery</a></p>\n</li>\n<li><p>springboot+quartz+mysql定时任务集群 <a href=\"https://github.com/evilRat/Eviltask\" target=\"_blank\" rel=\"noopener\">github:EvilTask</a></p>\n</li>\n</ul>\n<p><strong>更多请查看我的<a href=\"https://github.com/evilRat\" target=\"_blank\" rel=\"noopener\">GitHub</a></strong></p>\n<h2 id=\"自我评价\"><a href=\"#自我评价\" class=\"headerlink\" title=\"自我评价\"></a>自我评价</h2><p>有较好的职业素养，对工作积极负责，有创新意识和团队合作精神。热爱技术、热爱编码、热爱学习，喜欢阅读技术书刊、源码，学习能力较强，能快速将学习内容转化为生产力。态度乐观，有较好的沟通能力，为人热情，可以在工作中统合综效，实现共赢。</p>\n<hr>\n<h2 id=\"致谢\"><a href=\"#致谢\" class=\"headerlink\" title=\"致谢\"></a>致谢</h2><p>感谢您花时间阅读我的简历，期待能有机会和您共事。</p>\n","site":{"data":{}},"more":"<h2 id=\"联系方式\"><a href=\"#联系方式\" class=\"headerlink\" title=\"联系方式\"></a>联系方式</h2><ul>\n<li>手机/微信：15810692477</li>\n<li>Email：<a href=\"mailto:kongzheng1993@hotmail.com\" target=\"_blank\" rel=\"noopener\">kongzheng1993@hotmail.com</a></li>\n<li>QQ：767141624</li>\n</ul>\n<hr>\n<h2 id=\"个人信息\"><a href=\"#个人信息\" class=\"headerlink\" title=\"个人信息\"></a>个人信息</h2><ul>\n<li>孔征/男/1992</li>\n<li>本科/菏泽学院/计算机与信息工程系</li>\n<li>毕业时间：2016年7月</li>\n<li>技术博客：<a href=\"https://evilRat.github.io\" target=\"_blank\" rel=\"noopener\">https://evilRat.github.io</a></li>\n<li>Github: <a href=\"https://github.com/evilRat\" target=\"_blank\" rel=\"noopener\">https://github.com/evilRat</a></li>\n<li>微信公众号：evilRat</li>\n</ul>\n<hr>\n<h2 id=\"近况简介\"><a href=\"#近况简介\" class=\"headerlink\" title=\"近况简介\"></a>近况简介</h2><p>在理想汽车负责销服计划和交付质量两条业务线，系统相关人员包括开发3人、测试2人、产品1人、业务1人。</p>\n<p>研发过程为敏捷迭代：</p>\n<ul>\n<li>使用飞书（项目、IM、文档、视频会议、OKR、日历）工具进行协作和项目管理</li>\n<li>使用Git进行代码版本控制</li>\n<li>使用Gerrit（CR）、Jenkins（BV）、Sonar（SV）保证代码质量</li>\n<li>使用Jenkins、K8s、Docker、Git实现全流程的CI/CD。</li>\n</ul>\n<p>作为系统负责人，参与需求研发的全流程，包括需求评审、产品评审、排期、技术方案设计、任务分配、功能开发、测试用例评审和bug修复。关注相关服务的健康状态，适时进行重构、优化。保障上线操作无误，至今0回滚，系统常年可用性在99.99%以上。</p>\n<p>此外，作为研发部核心骨干参与发布会等重大项目。</p>\n<h2 id=\"工作经验\"><a href=\"#工作经验\" class=\"headerlink\" title=\"工作经验\"></a>工作经验</h2><h3 id=\"理想汽车-（2020年9月至今）\"><a href=\"#理想汽车-（2020年9月至今）\" class=\"headerlink\" title=\"理想汽车  （2020年9月至今）\"></a>理想汽车  （2020年9月至今）</h3><p>企业系统部，负责交付、物流和质量相关系统研发工作。</p>\n<h3 id=\"亚信科技-（2018年10月-2020年6月）\"><a href=\"#亚信科技-（2018年10月-2020年6月）\" class=\"headerlink\" title=\"亚信科技 （2018年10月-2020年6月）\"></a>亚信科技 （2018年10月-2020年6月）</h3><p>北京移动客服项目、中移在线北京分公司统一接口平台、移动营业厅一体机等项目开发。作为组内主力开发，组内5人，解决开发过程中的难点、重点问题，保证需求按时高质量交付。</p>\n<h3 id=\"软通动力-（2016年8月-2018年10月）\"><a href=\"#软通动力-（2016年8月-2018年10月）\" class=\"headerlink\" title=\"软通动力 （2016年8月-2018年10月）\"></a>软通动力 （2016年8月-2018年10月）</h3><p>中国移动在线服务公司北京10086&amp;12580呼叫中心开发运维工作，包括呼叫中心流程开发、数据库开发和接口开发。</p>\n<hr>\n<h2 id=\"项目经验\"><a href=\"#项目经验\" class=\"headerlink\" title=\"项目经验\"></a>项目经验</h2><h3 id=\"销服计划（2023年6月至今）\"><a href=\"#销服计划（2023年6月至今）\" class=\"headerlink\" title=\"销服计划（2023年6月至今）\"></a>销服计划（2023年6月至今）</h3><p>负责从0到1建设销服计划业务线，包含PSI产供销计划、分车系统和销服驾驶舱三个系统。</p>\n<ul>\n<li>PSI产供销计划平台<ol>\n<li>生产量、订单量、销售量、上线量等数据卷积预测</li>\n<li>周维度、月维度的历史实际值查看</li>\n<li>分价格段的市占率计算</li>\n<li>PSI滚动看板：DOS、要货需求等数据计算和查看</li>\n</ol>\n</li>\n<li>分车系统：现货模式下，为了保证健康的DOS，实现中央到省区、VDC，省区到门店的铺货与运输，以及门店主动挑车、释放的功能。</li>\n<li>销服驾驶舱：为公司高层提供的战略级看板，目前主要是上线量和市占率数据的多维度、多形式的展示。</li>\n</ul>\n<h3 id=\"理想汽车L7发布会项目（2022年10月–2023年2月）\"><a href=\"#理想汽车L7发布会项目（2022年10月–2023年2月）\" class=\"headerlink\" title=\"理想汽车L7发布会项目（2022年10月–2023年2月）\"></a>理想汽车L7发布会项目（2022年10月–2023年2月）</h3><p>理想汽车新车发布会是公司级重点项目，是对企业系统的一次大流量考验，是理想汽车的“双11”。本人在项目中参与了服务核心链路梳理，交易系统Code Review和重构，服务扩容、限流、降级功能梳理，应急预案设计，作战手册制定，发布会排练以及最终发布会保障。发布会过程中负责服务的监控和水位播报，按照作战手册完成发布会中的服务降级、限流等操作，监控网关异常流量，配合安全团队封禁恶意IP。最终0失误完成发布会保障工作，呈现了一场完美的发布会，2月8日当晚理想发布会很“苹果”冲上微博热搜。</p>\n<h3 id=\"交付准备系统（2021年5月至今）\"><a href=\"#交付准备系统（2021年5月至今）\" class=\"headerlink\" title=\"交付准备系统（2021年5月至今）\"></a>交付准备系统（2021年5月至今）</h3><p>交付准备管理系统（PC&amp;APP），车辆清洗、PDI、整备、终检、OTA升级和质量登记等功能，主要是交付中心PDI团队人员和管理者使用。车辆交付周期内节点事件触发系统自动生成响应的工单，PDI人员可以通过PC或者APP操作相关工单或手动创建/取消工单，管理者可以通过系统查看数据、管理团队。</p>\n<ul>\n<li>作为系统负责人，参与需求评审、产品评审、排期、任务分配、功能开发、测试用例评审和bug修复工作</li>\n<li>服务监控、告警跟进处理、代码重构、需求自驱等</li>\n<li>负责理想家APP交付准备系统研发项目。系统上线后，交付中心的pdi时间由原来的半小时以上，降低到13分钟。<strong>本人也因此在2021年Q4得到绩效E（超出预期）</strong></li>\n<li>打通售后服务系统，质损创建维修工单耗时缩短80%</li>\n<li>从0建设自动&amp;手动OTA能力，通过较强的抽象能力，为公司节省4HC，推送覆盖70%交付车辆，极大提高了交付效率</li>\n</ul>\n<h3 id=\"整车物流系统（2020年9月至今）\"><a href=\"#整车物流系统（2020年9月至今）\" class=\"headerlink\" title=\"整车物流系统（2020年9月至今）\"></a>整车物流系统（2020年9月至今）</h3><p>车辆下产线到交付交接完成期间的车辆运输和仓储相关的业务系统，事件驱动，实现车辆的自动/手动释放，出入库单、运输单、提交车计划和司机板车的管理，以及车辆运输的质量管理和供应商绩效的管理，系统包括PC端管理系统、APP（车辆维护、远程交付、特殊运输）和车辆交接微信小程序。参与新功能开发和旧有功能的维护和优化。</p>\n<ul>\n<li>车辆维护APP后台的开发和上线，其中对于生成车辆维护工单的逻辑优化，使工单生成的业务节点更准确，避免了重复生成维护工单，APP的使用提高人效50%</li>\n<li>车辆交接小程序中提车计划的重构，规范了板车司机、门卫、仓管和运管的操作，闭环了车辆生产完成到交付完成之间每一次运输的提车和交车流程</li>\n<li>理想汽车远程交付功能开发（PC端+APP端），支持配送车辆到客户指定地点进行交接，简化业务流程，提升用户体验。获得了<strong>2022年中国汽车物流行业创新奖</strong></li>\n</ul>\n<h3 id=\"整车交付系统（2020年9月–2021年6月）\"><a href=\"#整车交付系统（2020年9月–2021年6月）\" class=\"headerlink\" title=\"整车交付系统（2020年9月–2021年6月）\"></a>整车交付系统（2020年9月–2021年6月）</h3><p>用户主要是交付专家和中央管理人员，主要功能包括交付单管理、交付任务管理等。本人的工作是在添加新功能的同时维护已有功能，通过技术手段提高交付人员的效率，降低交付成本。负责开发了交付违约管理、交付pipeline等功能。交付违约管理功能，在客户无法在预约时间提车时，交付专家可以手动或者订单取消、挂起等事件自动触发进入违约流程，创建违约工单群，并将产品专家、零售店长、交付专家、交付店长等订单相关人员拉入群聊，在飞书机器人的引导下，完成发送提醒短信给用户等跟进手段，提高了人效、降低了沟通成本，<strong>客户违约率降低30%</strong>。</p>\n<h3 id=\"中移在线北京统一接口平台（2018年10月–2020年6月）\"><a href=\"#中移在线北京统一接口平台（2018年10月–2020年6月）\" class=\"headerlink\" title=\"中移在线北京统一接口平台（2018年10月–2020年6月）\"></a>中移在线北京统一接口平台（2018年10月–2020年6月）</h3><p>此项目为中国移动在线公司北京分公司统一接口平台。此系统为中间层，为中移在线北京分公司10086IVR、营业厅一体机、app、微信、门户网站等渠道提供接入转接服务。各渠道过来的请求，由接口平台转接到能力提供方，再将能力响应信息返回给调用方。大部分接口要做一些数据格式的转换和数据内容的映射，以适应各个渠道的调用。此系统为分布式架构（nginx、tomcat、redis、mysql、zookeeper、dubbo），使用spring作为ioc容器，使用jersey提供RESTful接口。在页面可以进行接入接口、转接接口、接口映射、接口编排、接入参数、转接参数、参数映射、接入渠道、渠道权限等的配置。接收请求后，程序会通过调用url获取到通过redis/mysql获取到此接口的相关配置，并根据获取到的参数配置进行参数校验、参数处理、参数映射，调用转接接口获取响应后处理并返回给调用方。根据需求完成各类接口的开发、测试、联调、发布。负责实现了项目的动态数据源和redis集群搭建与集成。</p>\n<ul>\n<li>“移娃”项目中，引入redis实现了用户和“移娃”的会话上下文记录10min，利用redis速度和过期时间的天然优势，完美实现了功能</li>\n<li>优化了接口平台字段名大写蛇形（XXX_YYY）转驼峰（xxxYYY）算法，<strong>500ms优化到20ms</strong>，极大提高了接口RT。<a href=\"https://evilRat.github.io/2020/03/25/kongzheng1993-%E4%B8%80%E6%AC%A1%E8%80%81%E4%BB%A3%E7%A0%81%E4%BC%98%E5%8C%96/\" target=\"_blank\" rel=\"noopener\"><strong>查看详情</strong></a></li>\n</ul>\n<hr>\n<h2 id=\"专业技能\"><a href=\"#专业技能\" class=\"headerlink\" title=\"专业技能\"></a>专业技能</h2><h3 id=\"编程语言\"><a href=\"#编程语言\" class=\"headerlink\" title=\"编程语言\"></a>编程语言</h3><ul>\n<li>Java: &#x2B50;&#x2B50;&#x2B50;</li>\n<li>SQL: &#x2B50;&#x2B50;&#x2B50;</li>\n<li>JavaScript: &#x2B50;&#x2B50;</li>\n<li>HTML: &#x2B50;&#x2B50;</li>\n<li>CSS: &#x2B50;&#x2B50;</li>\n<li>Python: &#x2B50;</li>\n<li>Shell: &#x2B50;</li>\n</ul>\n<h3 id=\"工具\"><a href=\"#工具\" class=\"headerlink\" title=\"工具\"></a>工具</h3><ul>\n<li>Maven: &#x2B50;&#x2B50;&#x2B50;</li>\n<li>Git: &#x2B50;&#x2B50;&#x2B50;</li>\n<li>SVN: &#x2B50;&#x2B50;&#x2B50;</li>\n<li>Element UI: &#x2B50;&#x2B50;&#x2B50;</li>\n</ul>\n<h3 id=\"框架\"><a href=\"#框架\" class=\"headerlink\" title=\"框架\"></a>框架</h3><ul>\n<li>Spring: &#x2B50;&#x2B50;&#x2B50;</li>\n<li>Spring Cloud: &#x2B50;&#x2B50;</li>\n<li>MyBatis: &#x2B50;&#x2B50;&#x2B50;</li>\n<li>Vue: &#x2B50;&#x2B50;</li>\n<li>JUnit: &#x2B50;</li>\n</ul>\n<h3 id=\"中间件\"><a href=\"#中间件\" class=\"headerlink\" title=\"中间件\"></a>中间件</h3><ul>\n<li>MySQL: &#x2B50;&#x2B50;</li>\n<li>Oracle: &#x2B50;&#x2B50;</li>\n<li>RocketMQ: &#x2B50;</li>\n<li>Zookeeper: &#x2B50;</li>\n<li>Redis: &#x2B50;&#x2B50;</li>\n</ul>\n<h3 id=\"其他\"><a href=\"#其他\" class=\"headerlink\" title=\"其他\"></a>其他</h3><ul>\n<li>Docker：&#x2B50;</li>\n<li>K8s：&#x2B50;</li>\n<li>Jenkins：&#x2B50;</li>\n<li>Flink：&#x2B50;</li>\n</ul>\n<hr>\n<h2 id=\"开源作品\"><a href=\"#开源作品\" class=\"headerlink\" title=\"开源作品\"></a>开源作品</h2><ul>\n<li><p>ftp文件下载工具 <a href=\"https://github.com/evilRat/downloadFiles\" target=\"_blank\" rel=\"noopener\">github:downloadFiles</a></p>\n</li>\n<li><p>testIVR配置文件生成工具 <a href=\"https://github.com/evilRat/GuiGenerateTestIVRConfig\" target=\"_blank\" rel=\"noopener\">github:GuiGenerateTestIVRConfig</a></p>\n</li>\n<li><p>使用node.js+zookeeper+redis实现服务发现 <a href=\"https://github.com/evilRat/evil-service-discovery\" target=\"_blank\" rel=\"noopener\">github:evil-service-discovery</a></p>\n</li>\n<li><p>springboot+quartz+mysql定时任务集群 <a href=\"https://github.com/evilRat/Eviltask\" target=\"_blank\" rel=\"noopener\">github:EvilTask</a></p>\n</li>\n</ul>\n<p><strong>更多请查看我的<a href=\"https://github.com/evilRat\" target=\"_blank\" rel=\"noopener\">GitHub</a></strong></p>\n<h2 id=\"自我评价\"><a href=\"#自我评价\" class=\"headerlink\" title=\"自我评价\"></a>自我评价</h2><p>有较好的职业素养，对工作积极负责，有创新意识和团队合作精神。热爱技术、热爱编码、热爱学习，喜欢阅读技术书刊、源码，学习能力较强，能快速将学习内容转化为生产力。态度乐观，有较好的沟通能力，为人热情，可以在工作中统合综效，实现共赢。</p>\n<hr>\n<h2 id=\"致谢\"><a href=\"#致谢\" class=\"headerlink\" title=\"致谢\"></a>致谢</h2><p>感谢您花时间阅读我的简历，期待能有机会和您共事。</p>\n"},{"layout":"post","title":"About the Usage of Final","date":"2016-06-12T16:00:00.000Z","excerpt":"","comments":1,"_content":"\n\n\n\n## 浅析Java中的final关键字\n\n　　谈到final关键字，想必很多人都不陌生，在使用匿名内部类的时候可能会经常用到final关键字。另外，Java中的String类就是一个final类，那么今天我们就来了解final这个关键字的用法。下面是本文的目录大纲：\n\n\n\n\n### 一.final关键字的基本用法\n\n　　在Java中，final关键字可以用来修饰类、方法和变量（包括成员变量和局部变量）。下面就从这三个方面来了解一下final关键字的基本用法。\n\n#### 1.修饰类\n\n　　当用final修饰一个类时，表明这个类不能被继承。也就是说，如果一个类你永远不会让他被继承，就可以用final进行修饰。final类中的成员变量可以根据需要设为final，但是要注意final类中的所有成员方法都会被隐式地指定为final方法。\n\n\n\n　　在使用final修饰类的时候，要注意谨慎选择，除非这个类真的在以后不会用来继承或者出于安全的考虑，尽量不要将类设计为final类。\n\n#### 2.修饰方法\n\n　　下面这段话摘自《Java编程思想》第四版第143页：\n\n　　“使用final方法的原因有两个。第一个原因是把方法锁定，以防任何继承类修改它的含义；第二个原因是效率。在早期的Java实现版本中，会将final方法转为内嵌调用。但是如果方法过于庞大，可能看不到内嵌调用带来的任何性能提升。在最近的Java版本中，不需要使用final方法进行这些优化了。“\n\n　　因此，如果只有在想明确禁止 该方法在子类中被覆盖的情况下才将方法设置为final的。\n\n　　注：类的private方法会隐式地被指定为final方法。\n\n#### 3.修饰变量\n\n　　修饰变量是final用得最多的地方，也是本文接下来要重点阐述的内容。首先了解一下final变量的基本语法：\n\n　　对于一个final变量，如果是基本数据类型的变量，则其数值一旦在初始化之后便不能更改；如果是引用类型的变量，则在对其初始化之后便不能再让其指向另一个对象。\n\n　　举个例子：\n\n```\n\n    class Man{\n        private final int a=0;\n        pbulic Man{\n            i=1;\n            final Object obj=new Object();\n            obj=new Object();\n        }\n\n    }\n\n\n```\n\n\n　　上面的一段代码中，对变量i和obj的重新赋值都报错了。\n\n### 二.深入理解final关键字\n\n　　在了解了final关键字的基本用法之后，这一节我们来看一下final关键字容易混淆的地方。\n\n#### 1.类的final变量和普通变量有什么区别？\n\n　　当用final作用于类的成员变量时，成员变量（注意是类的成员变量，局部变量只需要保证在使用之前被初始化赋值即可）必须在定义时或者构造器中进行初始化赋值，而且final变量一旦被初始化赋值之后，就不能再被赋值了。\n\n　　那么final变量和普通变量到底有何区别呢？下面请看一个例子：\n \n```\n\npublic class Test {\n    public static void main(String[] args)  {\n        String a = \"hello2\";  \n        final String b = \"hello\";\n        String d = \"hello\";\n        String c = b + 2;  \n        String e = d + 2;\n        System.out.println((a == c));\n        System.out.println((a == e));\n    }\n} \n\n\n```\n　　\n　　大家可以先想一下这道题的输出结果。为什么第一个比较结果为true，而第二个比较结果为fasle。这里面就是final变量和普通变量的区别了，当final变量是基本数据类型以及String类型时，如果在编译期间能知道它的确切值，则编译器会把它当做编译期常量使用。也就是说在用到该final变量的地方，相当于直接访问的这个常量，不需要在运行时确定。这种和C语言中的宏替换有点像。因此在上面的一段代码中，由于变量b被final修饰，因此会被当做编译器常量，所以在使用到b的地方会直接将变量b 替换为它的  值。而对于变量d的访问却需要在运行时通过链接来进行。想必其中的区别大家应该明白了，不过要注意，只有在编译期间能确切知道final变量值的情况下，编译器才会进行这样的优化，比如下面的这段代码就不会进行优化：\n\n```java\n\npublic class Test {\n    public static void main(String[] args)  {\n\n        String a = \"hello2\";  \n        final String b = getHello();\n        String c = b + 2;  \n        System.out.println((a == c));\n    }\n    public static String getHello() {\n        return \"hello\";\n    }\n}\n\n```\n\n\n　　这段代码的输出结果为false。\n\n#### 2.被final修饰的引用变量指向的对象内容可变吗？\n\n　　在上面提到被final修饰的引用变量一旦初始化赋值之后就不能再指向其他的对象，那么该引用变量指向的对象的内容可变吗？看下面这个例子：\n\n```java\n\npublic class Test {\n    public static void main(String[] args)  {\n        final MyClass myClass = new MyClass();\n        System.out.println(++myClass.i);\n    }\n}\nclass MyClass {\n    public int i = 0;\n}\n\n```\n\n　　这段代码可以顺利编译通过并且有输出结果，输出结果为1。这说明引用变量被final修饰之后，虽然不能再指向其他对象，但是它指向的对象的内容是可变的。\n\n#### 3.final和static\n\n　　很多时候会容易把static和final关键字混淆，static作用于成员变量用来表示只保存一份副本，而final的作用是用来保证变量不可变。看下面这个例子：\n\n```java\n\npublic class Test {\n    public static void main(String[] args)  {\n        MyClass myClass1 = new MyClass();\n        MyClass myClass2 = new MyClass();\n        System.out.println(myClass1.i);\n        System.out.println(myClass1.j);\n        System.out.println(myClass2.i);\n        System.out.println(myClass2.j);\n    }\n}\n\nclass MyClass {\n    public final double i = Math.random();\n    public static double j = Math.random();\n}\n\n```\n\n　　运行这段代码就会发现，每次打印的两个j值都是一样的，而i的值却是不同的。从这里就可以知道final和static变量的区别了。\n\n#### 4.匿名内部类中使用的外部局部变量为什么只能是final变量？\n\n　　这个问题请参见上一篇博文中《Java内部类详解》中的解释，在此处不再赘述。\n\n#### 5.关于final参数的问题\n\n　　关于网上流传的”当你在方法中不需要改变作为参数的对象变量时，明确使用final进行声明，会防止你无意的修改而影响到调用方法外的变量“这句话，我个人理解这样说是不恰当的。\n\n　　因为无论参数是基本数据类型的变量还是引用类型的变量，使用final声明都不会达到上面所说的效果。\n\n　　看这个例子就清楚了：\n\n　　上面这段代码好像让人觉得用final修饰之后，就不能在方法中更改变量i的值了。殊不知，方法changeValue和main方法中的变量i根本就不是一个变量，因为java参数传递采用的是值传递，对于基本类型的变量，相当于直接将变量进行了拷贝。所以即使没有final修饰的情况下，在方法内部改变了变量i的值也不会影响方法外的i。\n\n　　再看下面这段代码：\n\n```java\n\n\npublic class Test {\n\n    public static void main(String[] args)  {\n\n        MyClass myClass = new MyClass();\n\n        StringBuffer buffer = new StringBuffer(\"hello\");\n\n        myClass.changeValue(buffer);\n\n        System.out.println(buffer.toString());\n\n    }\n\n}\n\n\n\nclass MyClass {\n\n    void changeValue(final StringBuffer buffer) {\n\n        buffer.append(\"world\");\n\n    }\n\n}\n\n\n```\n\n　　运行这段代码就会发现输出结果为 helloworld。很显然，用final进行修饰并没有阻止在changeValue中改变buffer指向的对象的内容。有人说假如把final去掉了，万一在changeValue中让buffer指向了其他对象怎么办。有这种想法的朋友可以自己动手写代码试一下这样的结果是什么，如果把final去掉了，然后在changeValue中让buffer指向了其他对象，也不会影响到main方法中的buffer，原因在于java采用的是值传递，对于引用变量，传递的是引用的值，也就是说让实参和形参同时指向了同一个对象，因此让形参重新指向另一个对象对实参并没有任何影响。\n\n　　所以关于网上流传的final参数的说法，我个人不是很赞同。\n\n参考资料：\n\n　　《Java编程思想》\n\n##### 本文摘自http://www.cnblogs.com/dolphin0520/p/3736238.html\n\n\n<html>\n<div class=\"ds-thread\" data-thread-key=\"http://kongzheng1993.github.io/kongzheng1993-aboutFinal/\" data-title=\"about the usage of final\" data-url=\"http://kongzheng1993.github.io/kongzheng1993-aboutFinal/\"></div>\n<!-- 多说评论框 end -->\n<!-- 多说公共JS代码 start (一个网页只需插入一次) -->\n<script type=\"text/javascript\">\nvar duoshuoQuery = {short_name:\"kongzheng1993\"};\n    (function() {\n        var ds = document.createElement('script');\n        ds.type = 'text/javascript';ds.async = true;\n        ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';\n        ds.charset = 'UTF-8';\n        (document.getElementsByTagName('head')[0] \n         || document.getElementsByTagName('body')[0]).appendChild(ds);\n    })();\n</script>\n</html>\n","source":"_posts/2016-06-13-kongzheng1993-aboutFinal.md","raw":"---\nlayout: post\ntitle: \"About the Usage of Final\"\ndate: 2016-06-13\nexcerpt: \"code or die\"\ntags: [sample post, images, test]\ncomments: true\n---\n\n\n\n\n## 浅析Java中的final关键字\n\n　　谈到final关键字，想必很多人都不陌生，在使用匿名内部类的时候可能会经常用到final关键字。另外，Java中的String类就是一个final类，那么今天我们就来了解final这个关键字的用法。下面是本文的目录大纲：\n\n\n\n\n### 一.final关键字的基本用法\n\n　　在Java中，final关键字可以用来修饰类、方法和变量（包括成员变量和局部变量）。下面就从这三个方面来了解一下final关键字的基本用法。\n\n#### 1.修饰类\n\n　　当用final修饰一个类时，表明这个类不能被继承。也就是说，如果一个类你永远不会让他被继承，就可以用final进行修饰。final类中的成员变量可以根据需要设为final，但是要注意final类中的所有成员方法都会被隐式地指定为final方法。\n\n\n\n　　在使用final修饰类的时候，要注意谨慎选择，除非这个类真的在以后不会用来继承或者出于安全的考虑，尽量不要将类设计为final类。\n\n#### 2.修饰方法\n\n　　下面这段话摘自《Java编程思想》第四版第143页：\n\n　　“使用final方法的原因有两个。第一个原因是把方法锁定，以防任何继承类修改它的含义；第二个原因是效率。在早期的Java实现版本中，会将final方法转为内嵌调用。但是如果方法过于庞大，可能看不到内嵌调用带来的任何性能提升。在最近的Java版本中，不需要使用final方法进行这些优化了。“\n\n　　因此，如果只有在想明确禁止 该方法在子类中被覆盖的情况下才将方法设置为final的。\n\n　　注：类的private方法会隐式地被指定为final方法。\n\n#### 3.修饰变量\n\n　　修饰变量是final用得最多的地方，也是本文接下来要重点阐述的内容。首先了解一下final变量的基本语法：\n\n　　对于一个final变量，如果是基本数据类型的变量，则其数值一旦在初始化之后便不能更改；如果是引用类型的变量，则在对其初始化之后便不能再让其指向另一个对象。\n\n　　举个例子：\n\n```\n\n    class Man{\n        private final int a=0;\n        pbulic Man{\n            i=1;\n            final Object obj=new Object();\n            obj=new Object();\n        }\n\n    }\n\n\n```\n\n\n　　上面的一段代码中，对变量i和obj的重新赋值都报错了。\n\n### 二.深入理解final关键字\n\n　　在了解了final关键字的基本用法之后，这一节我们来看一下final关键字容易混淆的地方。\n\n#### 1.类的final变量和普通变量有什么区别？\n\n　　当用final作用于类的成员变量时，成员变量（注意是类的成员变量，局部变量只需要保证在使用之前被初始化赋值即可）必须在定义时或者构造器中进行初始化赋值，而且final变量一旦被初始化赋值之后，就不能再被赋值了。\n\n　　那么final变量和普通变量到底有何区别呢？下面请看一个例子：\n \n```\n\npublic class Test {\n    public static void main(String[] args)  {\n        String a = \"hello2\";  \n        final String b = \"hello\";\n        String d = \"hello\";\n        String c = b + 2;  \n        String e = d + 2;\n        System.out.println((a == c));\n        System.out.println((a == e));\n    }\n} \n\n\n```\n　　\n　　大家可以先想一下这道题的输出结果。为什么第一个比较结果为true，而第二个比较结果为fasle。这里面就是final变量和普通变量的区别了，当final变量是基本数据类型以及String类型时，如果在编译期间能知道它的确切值，则编译器会把它当做编译期常量使用。也就是说在用到该final变量的地方，相当于直接访问的这个常量，不需要在运行时确定。这种和C语言中的宏替换有点像。因此在上面的一段代码中，由于变量b被final修饰，因此会被当做编译器常量，所以在使用到b的地方会直接将变量b 替换为它的  值。而对于变量d的访问却需要在运行时通过链接来进行。想必其中的区别大家应该明白了，不过要注意，只有在编译期间能确切知道final变量值的情况下，编译器才会进行这样的优化，比如下面的这段代码就不会进行优化：\n\n```java\n\npublic class Test {\n    public static void main(String[] args)  {\n\n        String a = \"hello2\";  \n        final String b = getHello();\n        String c = b + 2;  \n        System.out.println((a == c));\n    }\n    public static String getHello() {\n        return \"hello\";\n    }\n}\n\n```\n\n\n　　这段代码的输出结果为false。\n\n#### 2.被final修饰的引用变量指向的对象内容可变吗？\n\n　　在上面提到被final修饰的引用变量一旦初始化赋值之后就不能再指向其他的对象，那么该引用变量指向的对象的内容可变吗？看下面这个例子：\n\n```java\n\npublic class Test {\n    public static void main(String[] args)  {\n        final MyClass myClass = new MyClass();\n        System.out.println(++myClass.i);\n    }\n}\nclass MyClass {\n    public int i = 0;\n}\n\n```\n\n　　这段代码可以顺利编译通过并且有输出结果，输出结果为1。这说明引用变量被final修饰之后，虽然不能再指向其他对象，但是它指向的对象的内容是可变的。\n\n#### 3.final和static\n\n　　很多时候会容易把static和final关键字混淆，static作用于成员变量用来表示只保存一份副本，而final的作用是用来保证变量不可变。看下面这个例子：\n\n```java\n\npublic class Test {\n    public static void main(String[] args)  {\n        MyClass myClass1 = new MyClass();\n        MyClass myClass2 = new MyClass();\n        System.out.println(myClass1.i);\n        System.out.println(myClass1.j);\n        System.out.println(myClass2.i);\n        System.out.println(myClass2.j);\n    }\n}\n\nclass MyClass {\n    public final double i = Math.random();\n    public static double j = Math.random();\n}\n\n```\n\n　　运行这段代码就会发现，每次打印的两个j值都是一样的，而i的值却是不同的。从这里就可以知道final和static变量的区别了。\n\n#### 4.匿名内部类中使用的外部局部变量为什么只能是final变量？\n\n　　这个问题请参见上一篇博文中《Java内部类详解》中的解释，在此处不再赘述。\n\n#### 5.关于final参数的问题\n\n　　关于网上流传的”当你在方法中不需要改变作为参数的对象变量时，明确使用final进行声明，会防止你无意的修改而影响到调用方法外的变量“这句话，我个人理解这样说是不恰当的。\n\n　　因为无论参数是基本数据类型的变量还是引用类型的变量，使用final声明都不会达到上面所说的效果。\n\n　　看这个例子就清楚了：\n\n　　上面这段代码好像让人觉得用final修饰之后，就不能在方法中更改变量i的值了。殊不知，方法changeValue和main方法中的变量i根本就不是一个变量，因为java参数传递采用的是值传递，对于基本类型的变量，相当于直接将变量进行了拷贝。所以即使没有final修饰的情况下，在方法内部改变了变量i的值也不会影响方法外的i。\n\n　　再看下面这段代码：\n\n```java\n\n\npublic class Test {\n\n    public static void main(String[] args)  {\n\n        MyClass myClass = new MyClass();\n\n        StringBuffer buffer = new StringBuffer(\"hello\");\n\n        myClass.changeValue(buffer);\n\n        System.out.println(buffer.toString());\n\n    }\n\n}\n\n\n\nclass MyClass {\n\n    void changeValue(final StringBuffer buffer) {\n\n        buffer.append(\"world\");\n\n    }\n\n}\n\n\n```\n\n　　运行这段代码就会发现输出结果为 helloworld。很显然，用final进行修饰并没有阻止在changeValue中改变buffer指向的对象的内容。有人说假如把final去掉了，万一在changeValue中让buffer指向了其他对象怎么办。有这种想法的朋友可以自己动手写代码试一下这样的结果是什么，如果把final去掉了，然后在changeValue中让buffer指向了其他对象，也不会影响到main方法中的buffer，原因在于java采用的是值传递，对于引用变量，传递的是引用的值，也就是说让实参和形参同时指向了同一个对象，因此让形参重新指向另一个对象对实参并没有任何影响。\n\n　　所以关于网上流传的final参数的说法，我个人不是很赞同。\n\n参考资料：\n\n　　《Java编程思想》\n\n##### 本文摘自http://www.cnblogs.com/dolphin0520/p/3736238.html\n\n\n<html>\n<div class=\"ds-thread\" data-thread-key=\"http://kongzheng1993.github.io/kongzheng1993-aboutFinal/\" data-title=\"about the usage of final\" data-url=\"http://kongzheng1993.github.io/kongzheng1993-aboutFinal/\"></div>\n<!-- 多说评论框 end -->\n<!-- 多说公共JS代码 start (一个网页只需插入一次) -->\n<script type=\"text/javascript\">\nvar duoshuoQuery = {short_name:\"kongzheng1993\"};\n    (function() {\n        var ds = document.createElement('script');\n        ds.type = 'text/javascript';ds.async = true;\n        ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';\n        ds.charset = 'UTF-8';\n        (document.getElementsByTagName('head')[0] \n         || document.getElementsByTagName('body')[0]).appendChild(ds);\n    })();\n</script>\n</html>\n","slug":"kongzheng1993-aboutFinal","published":1,"updated":"2023-03-08T07:05:58.771Z","photos":[],"link":"","_id":"clg0k2aol00hdt26fry5jx7oj","content":"<h2 id=\"浅析Java中的final关键字\"><a href=\"#浅析Java中的final关键字\" class=\"headerlink\" title=\"浅析Java中的final关键字\"></a>浅析Java中的final关键字</h2><p>　　谈到final关键字，想必很多人都不陌生，在使用匿名内部类的时候可能会经常用到final关键字。另外，Java中的String类就是一个final类，那么今天我们就来了解final这个关键字的用法。下面是本文的目录大纲：</p>\n<h3 id=\"一-final关键字的基本用法\"><a href=\"#一-final关键字的基本用法\" class=\"headerlink\" title=\"一.final关键字的基本用法\"></a>一.final关键字的基本用法</h3><p>　　在Java中，final关键字可以用来修饰类、方法和变量（包括成员变量和局部变量）。下面就从这三个方面来了解一下final关键字的基本用法。</p>\n<h4 id=\"1-修饰类\"><a href=\"#1-修饰类\" class=\"headerlink\" title=\"1.修饰类\"></a>1.修饰类</h4><p>　　当用final修饰一个类时，表明这个类不能被继承。也就是说，如果一个类你永远不会让他被继承，就可以用final进行修饰。final类中的成员变量可以根据需要设为final，但是要注意final类中的所有成员方法都会被隐式地指定为final方法。</p>\n<p>　　在使用final修饰类的时候，要注意谨慎选择，除非这个类真的在以后不会用来继承或者出于安全的考虑，尽量不要将类设计为final类。</p>\n<h4 id=\"2-修饰方法\"><a href=\"#2-修饰方法\" class=\"headerlink\" title=\"2.修饰方法\"></a>2.修饰方法</h4><p>　　下面这段话摘自《Java编程思想》第四版第143页：</p>\n<p>　　“使用final方法的原因有两个。第一个原因是把方法锁定，以防任何继承类修改它的含义；第二个原因是效率。在早期的Java实现版本中，会将final方法转为内嵌调用。但是如果方法过于庞大，可能看不到内嵌调用带来的任何性能提升。在最近的Java版本中，不需要使用final方法进行这些优化了。“</p>\n<p>　　因此，如果只有在想明确禁止 该方法在子类中被覆盖的情况下才将方法设置为final的。</p>\n<p>　　注：类的private方法会隐式地被指定为final方法。</p>\n<h4 id=\"3-修饰变量\"><a href=\"#3-修饰变量\" class=\"headerlink\" title=\"3.修饰变量\"></a>3.修饰变量</h4><p>　　修饰变量是final用得最多的地方，也是本文接下来要重点阐述的内容。首先了解一下final变量的基本语法：</p>\n<p>　　对于一个final变量，如果是基本数据类型的变量，则其数值一旦在初始化之后便不能更改；如果是引用类型的变量，则在对其初始化之后便不能再让其指向另一个对象。</p>\n<p>　　举个例子：</p>\n<pre><code>\n    class Man{\n        private final int a=0;\n        pbulic Man{\n            i=1;\n            final Object obj=new Object();\n            obj=new Object();\n        }\n\n    }\n\n</code></pre><p>　　上面的一段代码中，对变量i和obj的重新赋值都报错了。</p>\n<h3 id=\"二-深入理解final关键字\"><a href=\"#二-深入理解final关键字\" class=\"headerlink\" title=\"二.深入理解final关键字\"></a>二.深入理解final关键字</h3><p>　　在了解了final关键字的基本用法之后，这一节我们来看一下final关键字容易混淆的地方。</p>\n<h4 id=\"1-类的final变量和普通变量有什么区别？\"><a href=\"#1-类的final变量和普通变量有什么区别？\" class=\"headerlink\" title=\"1.类的final变量和普通变量有什么区别？\"></a>1.类的final变量和普通变量有什么区别？</h4><p>　　当用final作用于类的成员变量时，成员变量（注意是类的成员变量，局部变量只需要保证在使用之前被初始化赋值即可）必须在定义时或者构造器中进行初始化赋值，而且final变量一旦被初始化赋值之后，就不能再被赋值了。</p>\n<p>　　那么final变量和普通变量到底有何区别呢？下面请看一个例子：</p>\n<pre><code>\npublic class Test {\n    public static void main(String[] args)  {\n        String a = &quot;hello2&quot;;  \n        final String b = &quot;hello&quot;;\n        String d = &quot;hello&quot;;\n        String c = b + 2;  \n        String e = d + 2;\n        System.out.println((a == c));\n        System.out.println((a == e));\n    }\n} \n\n</code></pre><p>　　<br>　　大家可以先想一下这道题的输出结果。为什么第一个比较结果为true，而第二个比较结果为fasle。这里面就是final变量和普通变量的区别了，当final变量是基本数据类型以及String类型时，如果在编译期间能知道它的确切值，则编译器会把它当做编译期常量使用。也就是说在用到该final变量的地方，相当于直接访问的这个常量，不需要在运行时确定。这种和C语言中的宏替换有点像。因此在上面的一段代码中，由于变量b被final修饰，因此会被当做编译器常量，所以在使用到b的地方会直接将变量b 替换为它的  值。而对于变量d的访问却需要在运行时通过链接来进行。想必其中的区别大家应该明白了，不过要注意，只有在编译期间能确切知道final变量值的情况下，编译器才会进行这样的优化，比如下面的这段代码就不会进行优化：</p>\n<pre><code class=\"java\">\npublic class Test {\n    public static void main(String[] args)  {\n\n        String a = &quot;hello2&quot;;  \n        final String b = getHello();\n        String c = b + 2;  \n        System.out.println((a == c));\n    }\n    public static String getHello() {\n        return &quot;hello&quot;;\n    }\n}\n</code></pre>\n<p>　　这段代码的输出结果为false。</p>\n<h4 id=\"2-被final修饰的引用变量指向的对象内容可变吗？\"><a href=\"#2-被final修饰的引用变量指向的对象内容可变吗？\" class=\"headerlink\" title=\"2.被final修饰的引用变量指向的对象内容可变吗？\"></a>2.被final修饰的引用变量指向的对象内容可变吗？</h4><p>　　在上面提到被final修饰的引用变量一旦初始化赋值之后就不能再指向其他的对象，那么该引用变量指向的对象的内容可变吗？看下面这个例子：</p>\n<pre><code class=\"java\">\npublic class Test {\n    public static void main(String[] args)  {\n        final MyClass myClass = new MyClass();\n        System.out.println(++myClass.i);\n    }\n}\nclass MyClass {\n    public int i = 0;\n}\n</code></pre>\n<p>　　这段代码可以顺利编译通过并且有输出结果，输出结果为1。这说明引用变量被final修饰之后，虽然不能再指向其他对象，但是它指向的对象的内容是可变的。</p>\n<h4 id=\"3-final和static\"><a href=\"#3-final和static\" class=\"headerlink\" title=\"3.final和static\"></a>3.final和static</h4><p>　　很多时候会容易把static和final关键字混淆，static作用于成员变量用来表示只保存一份副本，而final的作用是用来保证变量不可变。看下面这个例子：</p>\n<pre><code class=\"java\">\npublic class Test {\n    public static void main(String[] args)  {\n        MyClass myClass1 = new MyClass();\n        MyClass myClass2 = new MyClass();\n        System.out.println(myClass1.i);\n        System.out.println(myClass1.j);\n        System.out.println(myClass2.i);\n        System.out.println(myClass2.j);\n    }\n}\n\nclass MyClass {\n    public final double i = Math.random();\n    public static double j = Math.random();\n}\n</code></pre>\n<p>　　运行这段代码就会发现，每次打印的两个j值都是一样的，而i的值却是不同的。从这里就可以知道final和static变量的区别了。</p>\n<h4 id=\"4-匿名内部类中使用的外部局部变量为什么只能是final变量？\"><a href=\"#4-匿名内部类中使用的外部局部变量为什么只能是final变量？\" class=\"headerlink\" title=\"4.匿名内部类中使用的外部局部变量为什么只能是final变量？\"></a>4.匿名内部类中使用的外部局部变量为什么只能是final变量？</h4><p>　　这个问题请参见上一篇博文中《Java内部类详解》中的解释，在此处不再赘述。</p>\n<h4 id=\"5-关于final参数的问题\"><a href=\"#5-关于final参数的问题\" class=\"headerlink\" title=\"5.关于final参数的问题\"></a>5.关于final参数的问题</h4><p>　　关于网上流传的”当你在方法中不需要改变作为参数的对象变量时，明确使用final进行声明，会防止你无意的修改而影响到调用方法外的变量“这句话，我个人理解这样说是不恰当的。</p>\n<p>　　因为无论参数是基本数据类型的变量还是引用类型的变量，使用final声明都不会达到上面所说的效果。</p>\n<p>　　看这个例子就清楚了：</p>\n<p>　　上面这段代码好像让人觉得用final修饰之后，就不能在方法中更改变量i的值了。殊不知，方法changeValue和main方法中的变量i根本就不是一个变量，因为java参数传递采用的是值传递，对于基本类型的变量，相当于直接将变量进行了拷贝。所以即使没有final修饰的情况下，在方法内部改变了变量i的值也不会影响方法外的i。</p>\n<p>　　再看下面这段代码：</p>\n<pre><code class=\"java\">\n\npublic class Test {\n\n    public static void main(String[] args)  {\n\n        MyClass myClass = new MyClass();\n\n        StringBuffer buffer = new StringBuffer(&quot;hello&quot;);\n\n        myClass.changeValue(buffer);\n\n        System.out.println(buffer.toString());\n\n    }\n\n}\n\n\n\nclass MyClass {\n\n    void changeValue(final StringBuffer buffer) {\n\n        buffer.append(&quot;world&quot;);\n\n    }\n\n}\n\n</code></pre>\n<p>　　运行这段代码就会发现输出结果为 helloworld。很显然，用final进行修饰并没有阻止在changeValue中改变buffer指向的对象的内容。有人说假如把final去掉了，万一在changeValue中让buffer指向了其他对象怎么办。有这种想法的朋友可以自己动手写代码试一下这样的结果是什么，如果把final去掉了，然后在changeValue中让buffer指向了其他对象，也不会影响到main方法中的buffer，原因在于java采用的是值传递，对于引用变量，传递的是引用的值，也就是说让实参和形参同时指向了同一个对象，因此让形参重新指向另一个对象对实参并没有任何影响。</p>\n<p>　　所以关于网上流传的final参数的说法，我个人不是很赞同。</p>\n<p>参考资料：</p>\n<p>　　《Java编程思想》</p>\n<h5 id=\"本文摘自http-www-cnblogs-com-dolphin0520-p-3736238-html\"><a href=\"#本文摘自http-www-cnblogs-com-dolphin0520-p-3736238-html\" class=\"headerlink\" title=\"本文摘自http://www.cnblogs.com/dolphin0520/p/3736238.html\"></a>本文摘自<a href=\"http://www.cnblogs.com/dolphin0520/p/3736238.html\" target=\"_blank\" rel=\"noopener\">http://www.cnblogs.com/dolphin0520/p/3736238.html</a></h5><html>\n<div class=\"ds-thread\" data-thread-key=\"http://kongzheng1993.github.io/kongzheng1993-aboutFinal/\" data-title=\"about the usage of final\" data-url=\"http://kongzheng1993.github.io/kongzheng1993-aboutFinal/\"></div>\n<!-- 多说评论框 end -->\n<!-- 多说公共JS代码 start (一个网页只需插入一次) -->\n<script type=\"text/javascript\">\nvar duoshuoQuery = {short_name:\"kongzheng1993\"};\n    (function() {\n        var ds = document.createElement('script');\n        ds.type = 'text/javascript';ds.async = true;\n        ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';\n        ds.charset = 'UTF-8';\n        (document.getElementsByTagName('head')[0] \n         || document.getElementsByTagName('body')[0]).appendChild(ds);\n    })();\n</script>\n</html>\n","site":{"data":{}},"more":"<h2 id=\"浅析Java中的final关键字\"><a href=\"#浅析Java中的final关键字\" class=\"headerlink\" title=\"浅析Java中的final关键字\"></a>浅析Java中的final关键字</h2><p>　　谈到final关键字，想必很多人都不陌生，在使用匿名内部类的时候可能会经常用到final关键字。另外，Java中的String类就是一个final类，那么今天我们就来了解final这个关键字的用法。下面是本文的目录大纲：</p>\n<h3 id=\"一-final关键字的基本用法\"><a href=\"#一-final关键字的基本用法\" class=\"headerlink\" title=\"一.final关键字的基本用法\"></a>一.final关键字的基本用法</h3><p>　　在Java中，final关键字可以用来修饰类、方法和变量（包括成员变量和局部变量）。下面就从这三个方面来了解一下final关键字的基本用法。</p>\n<h4 id=\"1-修饰类\"><a href=\"#1-修饰类\" class=\"headerlink\" title=\"1.修饰类\"></a>1.修饰类</h4><p>　　当用final修饰一个类时，表明这个类不能被继承。也就是说，如果一个类你永远不会让他被继承，就可以用final进行修饰。final类中的成员变量可以根据需要设为final，但是要注意final类中的所有成员方法都会被隐式地指定为final方法。</p>\n<p>　　在使用final修饰类的时候，要注意谨慎选择，除非这个类真的在以后不会用来继承或者出于安全的考虑，尽量不要将类设计为final类。</p>\n<h4 id=\"2-修饰方法\"><a href=\"#2-修饰方法\" class=\"headerlink\" title=\"2.修饰方法\"></a>2.修饰方法</h4><p>　　下面这段话摘自《Java编程思想》第四版第143页：</p>\n<p>　　“使用final方法的原因有两个。第一个原因是把方法锁定，以防任何继承类修改它的含义；第二个原因是效率。在早期的Java实现版本中，会将final方法转为内嵌调用。但是如果方法过于庞大，可能看不到内嵌调用带来的任何性能提升。在最近的Java版本中，不需要使用final方法进行这些优化了。“</p>\n<p>　　因此，如果只有在想明确禁止 该方法在子类中被覆盖的情况下才将方法设置为final的。</p>\n<p>　　注：类的private方法会隐式地被指定为final方法。</p>\n<h4 id=\"3-修饰变量\"><a href=\"#3-修饰变量\" class=\"headerlink\" title=\"3.修饰变量\"></a>3.修饰变量</h4><p>　　修饰变量是final用得最多的地方，也是本文接下来要重点阐述的内容。首先了解一下final变量的基本语法：</p>\n<p>　　对于一个final变量，如果是基本数据类型的变量，则其数值一旦在初始化之后便不能更改；如果是引用类型的变量，则在对其初始化之后便不能再让其指向另一个对象。</p>\n<p>　　举个例子：</p>\n<pre><code>\n    class Man{\n        private final int a=0;\n        pbulic Man{\n            i=1;\n            final Object obj=new Object();\n            obj=new Object();\n        }\n\n    }\n\n</code></pre><p>　　上面的一段代码中，对变量i和obj的重新赋值都报错了。</p>\n<h3 id=\"二-深入理解final关键字\"><a href=\"#二-深入理解final关键字\" class=\"headerlink\" title=\"二.深入理解final关键字\"></a>二.深入理解final关键字</h3><p>　　在了解了final关键字的基本用法之后，这一节我们来看一下final关键字容易混淆的地方。</p>\n<h4 id=\"1-类的final变量和普通变量有什么区别？\"><a href=\"#1-类的final变量和普通变量有什么区别？\" class=\"headerlink\" title=\"1.类的final变量和普通变量有什么区别？\"></a>1.类的final变量和普通变量有什么区别？</h4><p>　　当用final作用于类的成员变量时，成员变量（注意是类的成员变量，局部变量只需要保证在使用之前被初始化赋值即可）必须在定义时或者构造器中进行初始化赋值，而且final变量一旦被初始化赋值之后，就不能再被赋值了。</p>\n<p>　　那么final变量和普通变量到底有何区别呢？下面请看一个例子：</p>\n<pre><code>\npublic class Test {\n    public static void main(String[] args)  {\n        String a = &quot;hello2&quot;;  \n        final String b = &quot;hello&quot;;\n        String d = &quot;hello&quot;;\n        String c = b + 2;  \n        String e = d + 2;\n        System.out.println((a == c));\n        System.out.println((a == e));\n    }\n} \n\n</code></pre><p>　　<br>　　大家可以先想一下这道题的输出结果。为什么第一个比较结果为true，而第二个比较结果为fasle。这里面就是final变量和普通变量的区别了，当final变量是基本数据类型以及String类型时，如果在编译期间能知道它的确切值，则编译器会把它当做编译期常量使用。也就是说在用到该final变量的地方，相当于直接访问的这个常量，不需要在运行时确定。这种和C语言中的宏替换有点像。因此在上面的一段代码中，由于变量b被final修饰，因此会被当做编译器常量，所以在使用到b的地方会直接将变量b 替换为它的  值。而对于变量d的访问却需要在运行时通过链接来进行。想必其中的区别大家应该明白了，不过要注意，只有在编译期间能确切知道final变量值的情况下，编译器才会进行这样的优化，比如下面的这段代码就不会进行优化：</p>\n<pre><code class=\"java\">\npublic class Test {\n    public static void main(String[] args)  {\n\n        String a = &quot;hello2&quot;;  \n        final String b = getHello();\n        String c = b + 2;  \n        System.out.println((a == c));\n    }\n    public static String getHello() {\n        return &quot;hello&quot;;\n    }\n}\n</code></pre>\n<p>　　这段代码的输出结果为false。</p>\n<h4 id=\"2-被final修饰的引用变量指向的对象内容可变吗？\"><a href=\"#2-被final修饰的引用变量指向的对象内容可变吗？\" class=\"headerlink\" title=\"2.被final修饰的引用变量指向的对象内容可变吗？\"></a>2.被final修饰的引用变量指向的对象内容可变吗？</h4><p>　　在上面提到被final修饰的引用变量一旦初始化赋值之后就不能再指向其他的对象，那么该引用变量指向的对象的内容可变吗？看下面这个例子：</p>\n<pre><code class=\"java\">\npublic class Test {\n    public static void main(String[] args)  {\n        final MyClass myClass = new MyClass();\n        System.out.println(++myClass.i);\n    }\n}\nclass MyClass {\n    public int i = 0;\n}\n</code></pre>\n<p>　　这段代码可以顺利编译通过并且有输出结果，输出结果为1。这说明引用变量被final修饰之后，虽然不能再指向其他对象，但是它指向的对象的内容是可变的。</p>\n<h4 id=\"3-final和static\"><a href=\"#3-final和static\" class=\"headerlink\" title=\"3.final和static\"></a>3.final和static</h4><p>　　很多时候会容易把static和final关键字混淆，static作用于成员变量用来表示只保存一份副本，而final的作用是用来保证变量不可变。看下面这个例子：</p>\n<pre><code class=\"java\">\npublic class Test {\n    public static void main(String[] args)  {\n        MyClass myClass1 = new MyClass();\n        MyClass myClass2 = new MyClass();\n        System.out.println(myClass1.i);\n        System.out.println(myClass1.j);\n        System.out.println(myClass2.i);\n        System.out.println(myClass2.j);\n    }\n}\n\nclass MyClass {\n    public final double i = Math.random();\n    public static double j = Math.random();\n}\n</code></pre>\n<p>　　运行这段代码就会发现，每次打印的两个j值都是一样的，而i的值却是不同的。从这里就可以知道final和static变量的区别了。</p>\n<h4 id=\"4-匿名内部类中使用的外部局部变量为什么只能是final变量？\"><a href=\"#4-匿名内部类中使用的外部局部变量为什么只能是final变量？\" class=\"headerlink\" title=\"4.匿名内部类中使用的外部局部变量为什么只能是final变量？\"></a>4.匿名内部类中使用的外部局部变量为什么只能是final变量？</h4><p>　　这个问题请参见上一篇博文中《Java内部类详解》中的解释，在此处不再赘述。</p>\n<h4 id=\"5-关于final参数的问题\"><a href=\"#5-关于final参数的问题\" class=\"headerlink\" title=\"5.关于final参数的问题\"></a>5.关于final参数的问题</h4><p>　　关于网上流传的”当你在方法中不需要改变作为参数的对象变量时，明确使用final进行声明，会防止你无意的修改而影响到调用方法外的变量“这句话，我个人理解这样说是不恰当的。</p>\n<p>　　因为无论参数是基本数据类型的变量还是引用类型的变量，使用final声明都不会达到上面所说的效果。</p>\n<p>　　看这个例子就清楚了：</p>\n<p>　　上面这段代码好像让人觉得用final修饰之后，就不能在方法中更改变量i的值了。殊不知，方法changeValue和main方法中的变量i根本就不是一个变量，因为java参数传递采用的是值传递，对于基本类型的变量，相当于直接将变量进行了拷贝。所以即使没有final修饰的情况下，在方法内部改变了变量i的值也不会影响方法外的i。</p>\n<p>　　再看下面这段代码：</p>\n<pre><code class=\"java\">\n\npublic class Test {\n\n    public static void main(String[] args)  {\n\n        MyClass myClass = new MyClass();\n\n        StringBuffer buffer = new StringBuffer(&quot;hello&quot;);\n\n        myClass.changeValue(buffer);\n\n        System.out.println(buffer.toString());\n\n    }\n\n}\n\n\n\nclass MyClass {\n\n    void changeValue(final StringBuffer buffer) {\n\n        buffer.append(&quot;world&quot;);\n\n    }\n\n}\n\n</code></pre>\n<p>　　运行这段代码就会发现输出结果为 helloworld。很显然，用final进行修饰并没有阻止在changeValue中改变buffer指向的对象的内容。有人说假如把final去掉了，万一在changeValue中让buffer指向了其他对象怎么办。有这种想法的朋友可以自己动手写代码试一下这样的结果是什么，如果把final去掉了，然后在changeValue中让buffer指向了其他对象，也不会影响到main方法中的buffer，原因在于java采用的是值传递，对于引用变量，传递的是引用的值，也就是说让实参和形参同时指向了同一个对象，因此让形参重新指向另一个对象对实参并没有任何影响。</p>\n<p>　　所以关于网上流传的final参数的说法，我个人不是很赞同。</p>\n<p>参考资料：</p>\n<p>　　《Java编程思想》</p>\n<h5 id=\"本文摘自http-www-cnblogs-com-dolphin0520-p-3736238-html\"><a href=\"#本文摘自http-www-cnblogs-com-dolphin0520-p-3736238-html\" class=\"headerlink\" title=\"本文摘自http://www.cnblogs.com/dolphin0520/p/3736238.html\"></a>本文摘自<a href=\"http://www.cnblogs.com/dolphin0520/p/3736238.html\" target=\"_blank\" rel=\"noopener\">http://www.cnblogs.com/dolphin0520/p/3736238.html</a></h5><html>\n<div class=\"ds-thread\" data-thread-key=\"http://kongzheng1993.github.io/kongzheng1993-aboutFinal/\" data-title=\"about the usage of final\" data-url=\"http://kongzheng1993.github.io/kongzheng1993-aboutFinal/\"></div>\n<!-- 多说评论框 end -->\n<!-- 多说公共JS代码 start (一个网页只需插入一次) -->\n<script type=\"text/javascript\">\nvar duoshuoQuery = {short_name:\"kongzheng1993\"};\n    (function() {\n        var ds = document.createElement('script');\n        ds.type = 'text/javascript';ds.async = true;\n        ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';\n        ds.charset = 'UTF-8';\n        (document.getElementsByTagName('head')[0] \n         || document.getElementsByTagName('body')[0]).appendChild(ds);\n    })();\n</script>\n</html>\n"},{"layout":"post","title":"centos 7 安装mysql遇到的问题","date":"2016-07-25T16:00:00.000Z","excerpt":"","comments":1,"_content":"\n\n## cent os 7安装mysql遇到的问题\n\n1.在centos 7上装mysql，但是运行的话会报错，服务未启动\n\n```\n\n[evilrat@evilRat_desktop ~]$ mysql status\nERROR 2002 (HY000): Can't connect to local MySQL server through socket '/var/lib/mysql/mysql.sock' (2)\n\n\n```\n\n2.尝试启动服务：\n\n```\n\n[evilrat@evilRat_desktop ~]$ systemctl enable mysql.service\nFailed to execute operation: Access denied\n\n\n```\n这样也不行……\n\n```\n\n[evilrat@evilRat_desktop ~]$ service mysql start\nRedirecting to /bin/systemctl start  mysql.service\n\n\n\n```\n\n3.通过百度找到这个\nmariaDB\n\n\nMariaDB数据库管理系统是MySQL的一个分支，主要由开源社区在维护，采用GPL授权许可 MariaDB的目的是完全兼容MySQL，包括API和命令行，使之能轻松成为MySQL的代替品。在存储引擎方面，使用XtraDB（英语：XtraDB）来代替MySQL的InnoDB。 MariaDB由MySQL的创始人Michael Widenius（英语：Michael Widenius）主导开发，他早前曾以10亿美元的价格，将自己创建的公司MySQL AB卖给了SUN，此后，随着SUN被甲骨文收购，MySQL的所有权也落入Oracle的手中。MariaDB名称来自Michael Widenius的女儿Maria的名字。\nMariaDB基于事务的Maria存储引擎，替换了MySQL的MyISAM存储引擎，它使用了Percona的 XtraDB，InnoDB的变体，分支的开发者希望提供访问即将到来的MySQL 5.4 InnoDB性能。这个版本还包括了 PrimeBase XT (PBXT) 和 FederatedX存储引擎。\n\n\n4.于是我尝试安装了一下\n\n\n```\n\n[root@evilRat_desktop evilrat]# yum install mariadb-server -y\nLoaded plugins: fastestmirror, langpacks\nRepository epel is listed more than once in the configuration\nRepository epel-debuginfo is listed more than once in the configuration\nRepository epel-source is listed more than once in the configuration\nRepodata is over 2 weeks old. Install yum-cron? Or run: yum makecache fast\nadobe-linux-x86_64                                       |  951 B     00:00     \nbase                                                     | 3.6 kB     00:00     \nepel                                                     | 4.3 kB     00:00     \nextras                                                   | 3.4 kB     00:00     \nnux-dextop                                               | 2.9 kB     00:00     \nupdates                                                  | 3.4 kB     00:00     \n(1/5): extras/7/x86_64/primary_db                          | 139 kB   00:00     \n(2/5): epel/x86_64/updateinfo                              | 765 kB   00:01     \n(3/5): epel/x86_64/primary_db                              | 4.6 MB   00:10     \n(4/5): updates/7/x86_64/primary_db                         | 3.8 MB   00:11     \n(5/5): nux-dextop/x86_64/primary_db                        | 1.7 MB   00:29     \nadobe-linux-x86_64/primary                                 | 1.3 kB   00:00     \nLoading mirror speeds from cached hostfile\n * base: mirrors.aliyun.com\n * epel: mirrors.aliyun.com\n * extras: mirrors.aliyun.com\n * nux-dextop: li.nux.ro\n * updates: mirrors.aliyun.com\nadobe-linux-x86_64                                                          3/3\nResolving Dependencies\n--> Running transaction check\n---> Package mariadb-server.x86_64 1:5.5.52-1.el7 will be installed\n--> Processing Dependency: perl-DBI for package: 1:mariadb-server-5.5.52-1.el7.x86_64\n--> Processing Dependency: perl-DBD-MySQL for package: 1:mariadb-server-5.5.52-1.el7.x86_64\n--> Processing Dependency: perl(DBI) for package: 1:mariadb-server-5.5.52-1.el7.x86_64\n--> Running transaction check\n---> Package perl-DBD-MySQL.x86_64 0:4.023-5.el7 will be installed\n---> Package perl-DBI.x86_64 0:1.627-4.el7 will be installed\n--> Processing Dependency: perl(RPC::PlServer) >= 0.2001 for package: perl-DBI-1.627-4.el7.x86_64\n--> Processing Dependency: perl(RPC::PlClient) >= 0.2000 for package: perl-DBI-1.627-4.el7.x86_64\n--> Running transaction check\n---> Package perl-PlRPC.noarch 0:0.2020-14.el7 will be installed\n--> Processing Dependency: perl(Net::Daemon) >= 0.13 for package: perl-PlRPC-0.2020-14.el7.noarch\n--> Processing Dependency: perl(Net::Daemon::Test) for package: perl-PlRPC-0.2020-14.el7.noarch\n--> Processing Dependency: perl(Net::Daemon::Log) for package: perl-PlRPC-0.2020-14.el7.noarch\n--> Processing Dependency: perl(Compress::Zlib) for package: perl-PlRPC-0.2020-14.el7.noarch\n--> Running transaction check\n---> Package perl-IO-Compress.noarch 0:2.061-2.el7 will be installed\n--> Processing Dependency: perl(Compress::Raw::Zlib) >= 2.061 for package: perl-IO-Compress-2.061-2.el7.noarch\n--> Processing Dependency: perl(Compress::Raw::Bzip2) >= 2.061 for package: perl-IO-Compress-2.061-2.el7.noarch\n---> Package perl-Net-Daemon.noarch 0:0.48-5.el7 will be installed\n--> Running transaction check\n---> Package perl-Compress-Raw-Bzip2.x86_64 0:2.061-3.el7 will be installed\n---> Package perl-Compress-Raw-Zlib.x86_64 1:2.061-4.el7 will be installed\n--> Finished Dependency Resolution\n\nDependencies Resolved\n\n================================================================================\n Package                      Arch        Version               Repository\n                                                                           Size\n================================================================================\nInstalling:\n mariadb-server               x86_64      1:5.5.52-1.el7        base       11 M\nInstalling for dependencies:\n perl-Compress-Raw-Bzip2      x86_64      2.061-3.el7           base       32 k\n perl-Compress-Raw-Zlib       x86_64      1:2.061-4.el7         base       57 k\n perl-DBD-MySQL               x86_64      4.023-5.el7           base      140 k\n perl-DBI                     x86_64      1.627-4.el7           base      802 k\n perl-IO-Compress             noarch      2.061-2.el7           base      260 k\n perl-Net-Daemon              noarch      0.48-5.el7            base       51 k\n perl-PlRPC                   noarch      0.2020-14.el7         base       36 k\n\nTransaction Summary\n================================================================================\nInstall  1 Package (+7 Dependent packages)\n\nTotal download size: 12 M\nInstalled size: 59 M\nDownloading packages:\n(1/8): perl-Compress-Raw-Bzip2-2.061-3.el7.x86_64.rpm      |  32 kB   00:00     \n(2/8): perl-Compress-Raw-Zlib-2.061-4.el7.x86_64.rpm       |  57 kB   00:00     \n(3/8): perl-DBD-MySQL-4.023-5.el7.x86_64.rpm               | 140 kB   00:00     \n(4/8): perl-DBI-1.627-4.el7.x86_64.rpm                     | 802 kB   00:00     \n(5/8): perl-IO-Compress-2.061-2.el7.noarch.rpm             | 260 kB   00:00     \n(6/8): perl-Net-Daemon-0.48-5.el7.noarch.rpm               |  51 kB   00:00     \n(7/8): perl-PlRPC-0.2020-14.el7.noarch.rpm                 |  36 kB   00:00     \n(8/8): mariadb-server-5.5.52-1.el7.x86_64.rpm              |  11 MB   00:12     \n--------------------------------------------------------------------------------\nTotal                                              1.0 MB/s |  12 MB  00:12     \nRunning transaction check\nRunning transaction test\nTransaction test succeeded\nRunning transaction\n  Installing : perl-Compress-Raw-Bzip2-2.061-3.el7.x86_64                   1/8 \n  Installing : 1:perl-Compress-Raw-Zlib-2.061-4.el7.x86_64                  2/8 \n  Installing : perl-IO-Compress-2.061-2.el7.noarch                          3/8 \n  Installing : perl-Net-Daemon-0.48-5.el7.noarch                            4/8 \n  Installing : perl-PlRPC-0.2020-14.el7.noarch                              5/8 \n  Installing : perl-DBI-1.627-4.el7.x86_64                                  6/8 \n  Installing : perl-DBD-MySQL-4.023-5.el7.x86_64                            7/8 \n  Installing : 1:mariadb-server-5.5.52-1.el7.x86_64                         8/8 \n  Verifying  : perl-Net-Daemon-0.48-5.el7.noarch                            1/8 \n  Verifying  : 1:mariadb-server-5.5.52-1.el7.x86_64                         2/8 \n  Verifying  : perl-IO-Compress-2.061-2.el7.noarch                          3/8 \n  Verifying  : 1:perl-Compress-Raw-Zlib-2.061-4.el7.x86_64                  4/8 \n  Verifying  : perl-PlRPC-0.2020-14.el7.noarch                              5/8 \n  Verifying  : perl-DBI-1.627-4.el7.x86_64                                  6/8 \n  Verifying  : perl-Compress-Raw-Bzip2-2.061-3.el7.x86_64                   7/8 \n  Verifying  : perl-DBD-MySQL-4.023-5.el7.x86_64                            8/8 \n\nInstalled:\n  mariadb-server.x86_64 1:5.5.52-1.el7                                          \n\nDependency Installed:\n  perl-Compress-Raw-Bzip2.x86_64 0:2.061-3.el7                                  \n  perl-Compress-Raw-Zlib.x86_64 1:2.061-4.el7                                   \n  perl-DBD-MySQL.x86_64 0:4.023-5.el7                                           \n  perl-DBI.x86_64 0:1.627-4.el7                                                 \n  perl-IO-Compress.noarch 0:2.061-2.el7                                         \n  perl-Net-Daemon.noarch 0:0.48-5.el7                                           \n  perl-PlRPC.noarch 0:0.2020-14.el7                                             \n\nComplete!\n\n\n\n\n```\n\n5.然后我启动服务，尝试启动mysql\n\n```\n\n[root@evilRat_desktop evilrat]# systemctl start mariadb.service\n[root@evilRat_desktop evilrat]# systemctl enable mariadb.service\nCreated symlink from /etc/systemd/system/multi-user.target.wants/mariadb.service to /usr/lib/systemd/system/mariadb.service.\n[root@evilRat_desktop evilrat]# mysql\nWelcome to the MariaDB monitor.  Commands end with ; or \\g.\nYour MariaDB connection id is 2\nServer version: 5.5.52-MariaDB MariaDB Server\n\nCopyright (c) 2000, 2016, Oracle, MariaDB Corporation Ab and others.\n\nType 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.\n\nMariaDB [(none)]> show databases\n    -> ;\n+--------------------+\n| Database           |\n+--------------------+\n| information_schema |\n| mysql              |\n| performance_schema |\n| test               |\n+--------------------+\n4 rows in set (0.00 sec)\n\nMariaDB [(none)]> exit\nBye\n\n\n\n```\n\n\n\n\n<html>\n<div class=\"ds-thread\" data-thread-key=\"http://kongzheng1993.github.io/kongzheng1993-centos7_mysql/\" data-title=\"centos7_mysql\" data-url=\"http://kongzheng1993.github.io/kongzheng1993-centos7_mysql/\"></div>\n<!-- 多说评论框 end -->\n<!-- 多说公共JS代码 start (一个网页只需插入一次) -->\n<script type=\"text/javascript\">\nvar duoshuoQuery = {short_name:\"kongzheng1993\"};\n    (function() {\n        var ds = document.createElement('script');\n        ds.type = 'text/javascript';ds.async = true;\n        ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';\n        ds.charset = 'UTF-8';\n        (document.getElementsByTagName('head')[0] \n         || document.getElementsByTagName('body')[0]).appendChild(ds);\n    })();\n</script>\n</html>\n\n","source":"_posts/2017-03-28-kongzheng1993-centos7_mysql.md","raw":"---\nlayout: post\ntitle: \"centos 7 安装mysql遇到的问题\"\ndate: 2016-07-26\nexcerpt: \"getRequestDispatcher,forword,sendRedirect\"\ntags: [re]\ncomments: true\n---\n\n\n## cent os 7安装mysql遇到的问题\n\n1.在centos 7上装mysql，但是运行的话会报错，服务未启动\n\n```\n\n[evilrat@evilRat_desktop ~]$ mysql status\nERROR 2002 (HY000): Can't connect to local MySQL server through socket '/var/lib/mysql/mysql.sock' (2)\n\n\n```\n\n2.尝试启动服务：\n\n```\n\n[evilrat@evilRat_desktop ~]$ systemctl enable mysql.service\nFailed to execute operation: Access denied\n\n\n```\n这样也不行……\n\n```\n\n[evilrat@evilRat_desktop ~]$ service mysql start\nRedirecting to /bin/systemctl start  mysql.service\n\n\n\n```\n\n3.通过百度找到这个\nmariaDB\n\n\nMariaDB数据库管理系统是MySQL的一个分支，主要由开源社区在维护，采用GPL授权许可 MariaDB的目的是完全兼容MySQL，包括API和命令行，使之能轻松成为MySQL的代替品。在存储引擎方面，使用XtraDB（英语：XtraDB）来代替MySQL的InnoDB。 MariaDB由MySQL的创始人Michael Widenius（英语：Michael Widenius）主导开发，他早前曾以10亿美元的价格，将自己创建的公司MySQL AB卖给了SUN，此后，随着SUN被甲骨文收购，MySQL的所有权也落入Oracle的手中。MariaDB名称来自Michael Widenius的女儿Maria的名字。\nMariaDB基于事务的Maria存储引擎，替换了MySQL的MyISAM存储引擎，它使用了Percona的 XtraDB，InnoDB的变体，分支的开发者希望提供访问即将到来的MySQL 5.4 InnoDB性能。这个版本还包括了 PrimeBase XT (PBXT) 和 FederatedX存储引擎。\n\n\n4.于是我尝试安装了一下\n\n\n```\n\n[root@evilRat_desktop evilrat]# yum install mariadb-server -y\nLoaded plugins: fastestmirror, langpacks\nRepository epel is listed more than once in the configuration\nRepository epel-debuginfo is listed more than once in the configuration\nRepository epel-source is listed more than once in the configuration\nRepodata is over 2 weeks old. Install yum-cron? Or run: yum makecache fast\nadobe-linux-x86_64                                       |  951 B     00:00     \nbase                                                     | 3.6 kB     00:00     \nepel                                                     | 4.3 kB     00:00     \nextras                                                   | 3.4 kB     00:00     \nnux-dextop                                               | 2.9 kB     00:00     \nupdates                                                  | 3.4 kB     00:00     \n(1/5): extras/7/x86_64/primary_db                          | 139 kB   00:00     \n(2/5): epel/x86_64/updateinfo                              | 765 kB   00:01     \n(3/5): epel/x86_64/primary_db                              | 4.6 MB   00:10     \n(4/5): updates/7/x86_64/primary_db                         | 3.8 MB   00:11     \n(5/5): nux-dextop/x86_64/primary_db                        | 1.7 MB   00:29     \nadobe-linux-x86_64/primary                                 | 1.3 kB   00:00     \nLoading mirror speeds from cached hostfile\n * base: mirrors.aliyun.com\n * epel: mirrors.aliyun.com\n * extras: mirrors.aliyun.com\n * nux-dextop: li.nux.ro\n * updates: mirrors.aliyun.com\nadobe-linux-x86_64                                                          3/3\nResolving Dependencies\n--> Running transaction check\n---> Package mariadb-server.x86_64 1:5.5.52-1.el7 will be installed\n--> Processing Dependency: perl-DBI for package: 1:mariadb-server-5.5.52-1.el7.x86_64\n--> Processing Dependency: perl-DBD-MySQL for package: 1:mariadb-server-5.5.52-1.el7.x86_64\n--> Processing Dependency: perl(DBI) for package: 1:mariadb-server-5.5.52-1.el7.x86_64\n--> Running transaction check\n---> Package perl-DBD-MySQL.x86_64 0:4.023-5.el7 will be installed\n---> Package perl-DBI.x86_64 0:1.627-4.el7 will be installed\n--> Processing Dependency: perl(RPC::PlServer) >= 0.2001 for package: perl-DBI-1.627-4.el7.x86_64\n--> Processing Dependency: perl(RPC::PlClient) >= 0.2000 for package: perl-DBI-1.627-4.el7.x86_64\n--> Running transaction check\n---> Package perl-PlRPC.noarch 0:0.2020-14.el7 will be installed\n--> Processing Dependency: perl(Net::Daemon) >= 0.13 for package: perl-PlRPC-0.2020-14.el7.noarch\n--> Processing Dependency: perl(Net::Daemon::Test) for package: perl-PlRPC-0.2020-14.el7.noarch\n--> Processing Dependency: perl(Net::Daemon::Log) for package: perl-PlRPC-0.2020-14.el7.noarch\n--> Processing Dependency: perl(Compress::Zlib) for package: perl-PlRPC-0.2020-14.el7.noarch\n--> Running transaction check\n---> Package perl-IO-Compress.noarch 0:2.061-2.el7 will be installed\n--> Processing Dependency: perl(Compress::Raw::Zlib) >= 2.061 for package: perl-IO-Compress-2.061-2.el7.noarch\n--> Processing Dependency: perl(Compress::Raw::Bzip2) >= 2.061 for package: perl-IO-Compress-2.061-2.el7.noarch\n---> Package perl-Net-Daemon.noarch 0:0.48-5.el7 will be installed\n--> Running transaction check\n---> Package perl-Compress-Raw-Bzip2.x86_64 0:2.061-3.el7 will be installed\n---> Package perl-Compress-Raw-Zlib.x86_64 1:2.061-4.el7 will be installed\n--> Finished Dependency Resolution\n\nDependencies Resolved\n\n================================================================================\n Package                      Arch        Version               Repository\n                                                                           Size\n================================================================================\nInstalling:\n mariadb-server               x86_64      1:5.5.52-1.el7        base       11 M\nInstalling for dependencies:\n perl-Compress-Raw-Bzip2      x86_64      2.061-3.el7           base       32 k\n perl-Compress-Raw-Zlib       x86_64      1:2.061-4.el7         base       57 k\n perl-DBD-MySQL               x86_64      4.023-5.el7           base      140 k\n perl-DBI                     x86_64      1.627-4.el7           base      802 k\n perl-IO-Compress             noarch      2.061-2.el7           base      260 k\n perl-Net-Daemon              noarch      0.48-5.el7            base       51 k\n perl-PlRPC                   noarch      0.2020-14.el7         base       36 k\n\nTransaction Summary\n================================================================================\nInstall  1 Package (+7 Dependent packages)\n\nTotal download size: 12 M\nInstalled size: 59 M\nDownloading packages:\n(1/8): perl-Compress-Raw-Bzip2-2.061-3.el7.x86_64.rpm      |  32 kB   00:00     \n(2/8): perl-Compress-Raw-Zlib-2.061-4.el7.x86_64.rpm       |  57 kB   00:00     \n(3/8): perl-DBD-MySQL-4.023-5.el7.x86_64.rpm               | 140 kB   00:00     \n(4/8): perl-DBI-1.627-4.el7.x86_64.rpm                     | 802 kB   00:00     \n(5/8): perl-IO-Compress-2.061-2.el7.noarch.rpm             | 260 kB   00:00     \n(6/8): perl-Net-Daemon-0.48-5.el7.noarch.rpm               |  51 kB   00:00     \n(7/8): perl-PlRPC-0.2020-14.el7.noarch.rpm                 |  36 kB   00:00     \n(8/8): mariadb-server-5.5.52-1.el7.x86_64.rpm              |  11 MB   00:12     \n--------------------------------------------------------------------------------\nTotal                                              1.0 MB/s |  12 MB  00:12     \nRunning transaction check\nRunning transaction test\nTransaction test succeeded\nRunning transaction\n  Installing : perl-Compress-Raw-Bzip2-2.061-3.el7.x86_64                   1/8 \n  Installing : 1:perl-Compress-Raw-Zlib-2.061-4.el7.x86_64                  2/8 \n  Installing : perl-IO-Compress-2.061-2.el7.noarch                          3/8 \n  Installing : perl-Net-Daemon-0.48-5.el7.noarch                            4/8 \n  Installing : perl-PlRPC-0.2020-14.el7.noarch                              5/8 \n  Installing : perl-DBI-1.627-4.el7.x86_64                                  6/8 \n  Installing : perl-DBD-MySQL-4.023-5.el7.x86_64                            7/8 \n  Installing : 1:mariadb-server-5.5.52-1.el7.x86_64                         8/8 \n  Verifying  : perl-Net-Daemon-0.48-5.el7.noarch                            1/8 \n  Verifying  : 1:mariadb-server-5.5.52-1.el7.x86_64                         2/8 \n  Verifying  : perl-IO-Compress-2.061-2.el7.noarch                          3/8 \n  Verifying  : 1:perl-Compress-Raw-Zlib-2.061-4.el7.x86_64                  4/8 \n  Verifying  : perl-PlRPC-0.2020-14.el7.noarch                              5/8 \n  Verifying  : perl-DBI-1.627-4.el7.x86_64                                  6/8 \n  Verifying  : perl-Compress-Raw-Bzip2-2.061-3.el7.x86_64                   7/8 \n  Verifying  : perl-DBD-MySQL-4.023-5.el7.x86_64                            8/8 \n\nInstalled:\n  mariadb-server.x86_64 1:5.5.52-1.el7                                          \n\nDependency Installed:\n  perl-Compress-Raw-Bzip2.x86_64 0:2.061-3.el7                                  \n  perl-Compress-Raw-Zlib.x86_64 1:2.061-4.el7                                   \n  perl-DBD-MySQL.x86_64 0:4.023-5.el7                                           \n  perl-DBI.x86_64 0:1.627-4.el7                                                 \n  perl-IO-Compress.noarch 0:2.061-2.el7                                         \n  perl-Net-Daemon.noarch 0:0.48-5.el7                                           \n  perl-PlRPC.noarch 0:0.2020-14.el7                                             \n\nComplete!\n\n\n\n\n```\n\n5.然后我启动服务，尝试启动mysql\n\n```\n\n[root@evilRat_desktop evilrat]# systemctl start mariadb.service\n[root@evilRat_desktop evilrat]# systemctl enable mariadb.service\nCreated symlink from /etc/systemd/system/multi-user.target.wants/mariadb.service to /usr/lib/systemd/system/mariadb.service.\n[root@evilRat_desktop evilrat]# mysql\nWelcome to the MariaDB monitor.  Commands end with ; or \\g.\nYour MariaDB connection id is 2\nServer version: 5.5.52-MariaDB MariaDB Server\n\nCopyright (c) 2000, 2016, Oracle, MariaDB Corporation Ab and others.\n\nType 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.\n\nMariaDB [(none)]> show databases\n    -> ;\n+--------------------+\n| Database           |\n+--------------------+\n| information_schema |\n| mysql              |\n| performance_schema |\n| test               |\n+--------------------+\n4 rows in set (0.00 sec)\n\nMariaDB [(none)]> exit\nBye\n\n\n\n```\n\n\n\n\n<html>\n<div class=\"ds-thread\" data-thread-key=\"http://kongzheng1993.github.io/kongzheng1993-centos7_mysql/\" data-title=\"centos7_mysql\" data-url=\"http://kongzheng1993.github.io/kongzheng1993-centos7_mysql/\"></div>\n<!-- 多说评论框 end -->\n<!-- 多说公共JS代码 start (一个网页只需插入一次) -->\n<script type=\"text/javascript\">\nvar duoshuoQuery = {short_name:\"kongzheng1993\"};\n    (function() {\n        var ds = document.createElement('script');\n        ds.type = 'text/javascript';ds.async = true;\n        ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';\n        ds.charset = 'UTF-8';\n        (document.getElementsByTagName('head')[0] \n         || document.getElementsByTagName('body')[0]).appendChild(ds);\n    })();\n</script>\n</html>\n\n","slug":"kongzheng1993-centos7_mysql","published":1,"updated":"2023-03-08T07:05:58.773Z","photos":[],"link":"","_id":"clg0k2aos00hgt26f42a7km0i","content":"<h2 id=\"cent-os-7安装mysql遇到的问题\"><a href=\"#cent-os-7安装mysql遇到的问题\" class=\"headerlink\" title=\"cent os 7安装mysql遇到的问题\"></a>cent os 7安装mysql遇到的问题</h2><p>1.在centos 7上装mysql，但是运行的话会报错，服务未启动</p>\n<pre><code>\n[evilrat@evilRat_desktop ~]$ mysql status\nERROR 2002 (HY000): Can&#39;t connect to local MySQL server through socket &#39;/var/lib/mysql/mysql.sock&#39; (2)\n\n</code></pre><p>2.尝试启动服务：</p>\n<pre><code>\n[evilrat@evilRat_desktop ~]$ systemctl enable mysql.service\nFailed to execute operation: Access denied\n\n</code></pre><p>这样也不行……</p>\n<pre><code>\n[evilrat@evilRat_desktop ~]$ service mysql start\nRedirecting to /bin/systemctl start  mysql.service\n\n\n</code></pre><p>3.通过百度找到这个<br>mariaDB</p>\n<p>MariaDB数据库管理系统是MySQL的一个分支，主要由开源社区在维护，采用GPL授权许可 MariaDB的目的是完全兼容MySQL，包括API和命令行，使之能轻松成为MySQL的代替品。在存储引擎方面，使用XtraDB（英语：XtraDB）来代替MySQL的InnoDB。 MariaDB由MySQL的创始人Michael Widenius（英语：Michael Widenius）主导开发，他早前曾以10亿美元的价格，将自己创建的公司MySQL AB卖给了SUN，此后，随着SUN被甲骨文收购，MySQL的所有权也落入Oracle的手中。MariaDB名称来自Michael Widenius的女儿Maria的名字。<br>MariaDB基于事务的Maria存储引擎，替换了MySQL的MyISAM存储引擎，它使用了Percona的 XtraDB，InnoDB的变体，分支的开发者希望提供访问即将到来的MySQL 5.4 InnoDB性能。这个版本还包括了 PrimeBase XT (PBXT) 和 FederatedX存储引擎。</p>\n<p>4.于是我尝试安装了一下</p>\n<pre><code>\n[root@evilRat_desktop evilrat]# yum install mariadb-server -y\nLoaded plugins: fastestmirror, langpacks\nRepository epel is listed more than once in the configuration\nRepository epel-debuginfo is listed more than once in the configuration\nRepository epel-source is listed more than once in the configuration\nRepodata is over 2 weeks old. Install yum-cron? Or run: yum makecache fast\nadobe-linux-x86_64                                       |  951 B     00:00     \nbase                                                     | 3.6 kB     00:00     \nepel                                                     | 4.3 kB     00:00     \nextras                                                   | 3.4 kB     00:00     \nnux-dextop                                               | 2.9 kB     00:00     \nupdates                                                  | 3.4 kB     00:00     \n(1/5): extras/7/x86_64/primary_db                          | 139 kB   00:00     \n(2/5): epel/x86_64/updateinfo                              | 765 kB   00:01     \n(3/5): epel/x86_64/primary_db                              | 4.6 MB   00:10     \n(4/5): updates/7/x86_64/primary_db                         | 3.8 MB   00:11     \n(5/5): nux-dextop/x86_64/primary_db                        | 1.7 MB   00:29     \nadobe-linux-x86_64/primary                                 | 1.3 kB   00:00     \nLoading mirror speeds from cached hostfile\n * base: mirrors.aliyun.com\n * epel: mirrors.aliyun.com\n * extras: mirrors.aliyun.com\n * nux-dextop: li.nux.ro\n * updates: mirrors.aliyun.com\nadobe-linux-x86_64                                                          3/3\nResolving Dependencies\n--&gt; Running transaction check\n---&gt; Package mariadb-server.x86_64 1:5.5.52-1.el7 will be installed\n--&gt; Processing Dependency: perl-DBI for package: 1:mariadb-server-5.5.52-1.el7.x86_64\n--&gt; Processing Dependency: perl-DBD-MySQL for package: 1:mariadb-server-5.5.52-1.el7.x86_64\n--&gt; Processing Dependency: perl(DBI) for package: 1:mariadb-server-5.5.52-1.el7.x86_64\n--&gt; Running transaction check\n---&gt; Package perl-DBD-MySQL.x86_64 0:4.023-5.el7 will be installed\n---&gt; Package perl-DBI.x86_64 0:1.627-4.el7 will be installed\n--&gt; Processing Dependency: perl(RPC::PlServer) &gt;= 0.2001 for package: perl-DBI-1.627-4.el7.x86_64\n--&gt; Processing Dependency: perl(RPC::PlClient) &gt;= 0.2000 for package: perl-DBI-1.627-4.el7.x86_64\n--&gt; Running transaction check\n---&gt; Package perl-PlRPC.noarch 0:0.2020-14.el7 will be installed\n--&gt; Processing Dependency: perl(Net::Daemon) &gt;= 0.13 for package: perl-PlRPC-0.2020-14.el7.noarch\n--&gt; Processing Dependency: perl(Net::Daemon::Test) for package: perl-PlRPC-0.2020-14.el7.noarch\n--&gt; Processing Dependency: perl(Net::Daemon::Log) for package: perl-PlRPC-0.2020-14.el7.noarch\n--&gt; Processing Dependency: perl(Compress::Zlib) for package: perl-PlRPC-0.2020-14.el7.noarch\n--&gt; Running transaction check\n---&gt; Package perl-IO-Compress.noarch 0:2.061-2.el7 will be installed\n--&gt; Processing Dependency: perl(Compress::Raw::Zlib) &gt;= 2.061 for package: perl-IO-Compress-2.061-2.el7.noarch\n--&gt; Processing Dependency: perl(Compress::Raw::Bzip2) &gt;= 2.061 for package: perl-IO-Compress-2.061-2.el7.noarch\n---&gt; Package perl-Net-Daemon.noarch 0:0.48-5.el7 will be installed\n--&gt; Running transaction check\n---&gt; Package perl-Compress-Raw-Bzip2.x86_64 0:2.061-3.el7 will be installed\n---&gt; Package perl-Compress-Raw-Zlib.x86_64 1:2.061-4.el7 will be installed\n--&gt; Finished Dependency Resolution\n\nDependencies Resolved\n\n================================================================================\n Package                      Arch        Version               Repository\n                                                                           Size\n================================================================================\nInstalling:\n mariadb-server               x86_64      1:5.5.52-1.el7        base       11 M\nInstalling for dependencies:\n perl-Compress-Raw-Bzip2      x86_64      2.061-3.el7           base       32 k\n perl-Compress-Raw-Zlib       x86_64      1:2.061-4.el7         base       57 k\n perl-DBD-MySQL               x86_64      4.023-5.el7           base      140 k\n perl-DBI                     x86_64      1.627-4.el7           base      802 k\n perl-IO-Compress             noarch      2.061-2.el7           base      260 k\n perl-Net-Daemon              noarch      0.48-5.el7            base       51 k\n perl-PlRPC                   noarch      0.2020-14.el7         base       36 k\n\nTransaction Summary\n================================================================================\nInstall  1 Package (+7 Dependent packages)\n\nTotal download size: 12 M\nInstalled size: 59 M\nDownloading packages:\n(1/8): perl-Compress-Raw-Bzip2-2.061-3.el7.x86_64.rpm      |  32 kB   00:00     \n(2/8): perl-Compress-Raw-Zlib-2.061-4.el7.x86_64.rpm       |  57 kB   00:00     \n(3/8): perl-DBD-MySQL-4.023-5.el7.x86_64.rpm               | 140 kB   00:00     \n(4/8): perl-DBI-1.627-4.el7.x86_64.rpm                     | 802 kB   00:00     \n(5/8): perl-IO-Compress-2.061-2.el7.noarch.rpm             | 260 kB   00:00     \n(6/8): perl-Net-Daemon-0.48-5.el7.noarch.rpm               |  51 kB   00:00     \n(7/8): perl-PlRPC-0.2020-14.el7.noarch.rpm                 |  36 kB   00:00     \n(8/8): mariadb-server-5.5.52-1.el7.x86_64.rpm              |  11 MB   00:12     \n--------------------------------------------------------------------------------\nTotal                                              1.0 MB/s |  12 MB  00:12     \nRunning transaction check\nRunning transaction test\nTransaction test succeeded\nRunning transaction\n  Installing : perl-Compress-Raw-Bzip2-2.061-3.el7.x86_64                   1/8 \n  Installing : 1:perl-Compress-Raw-Zlib-2.061-4.el7.x86_64                  2/8 \n  Installing : perl-IO-Compress-2.061-2.el7.noarch                          3/8 \n  Installing : perl-Net-Daemon-0.48-5.el7.noarch                            4/8 \n  Installing : perl-PlRPC-0.2020-14.el7.noarch                              5/8 \n  Installing : perl-DBI-1.627-4.el7.x86_64                                  6/8 \n  Installing : perl-DBD-MySQL-4.023-5.el7.x86_64                            7/8 \n  Installing : 1:mariadb-server-5.5.52-1.el7.x86_64                         8/8 \n  Verifying  : perl-Net-Daemon-0.48-5.el7.noarch                            1/8 \n  Verifying  : 1:mariadb-server-5.5.52-1.el7.x86_64                         2/8 \n  Verifying  : perl-IO-Compress-2.061-2.el7.noarch                          3/8 \n  Verifying  : 1:perl-Compress-Raw-Zlib-2.061-4.el7.x86_64                  4/8 \n  Verifying  : perl-PlRPC-0.2020-14.el7.noarch                              5/8 \n  Verifying  : perl-DBI-1.627-4.el7.x86_64                                  6/8 \n  Verifying  : perl-Compress-Raw-Bzip2-2.061-3.el7.x86_64                   7/8 \n  Verifying  : perl-DBD-MySQL-4.023-5.el7.x86_64                            8/8 \n\nInstalled:\n  mariadb-server.x86_64 1:5.5.52-1.el7                                          \n\nDependency Installed:\n  perl-Compress-Raw-Bzip2.x86_64 0:2.061-3.el7                                  \n  perl-Compress-Raw-Zlib.x86_64 1:2.061-4.el7                                   \n  perl-DBD-MySQL.x86_64 0:4.023-5.el7                                           \n  perl-DBI.x86_64 0:1.627-4.el7                                                 \n  perl-IO-Compress.noarch 0:2.061-2.el7                                         \n  perl-Net-Daemon.noarch 0:0.48-5.el7                                           \n  perl-PlRPC.noarch 0:0.2020-14.el7                                             \n\nComplete!\n\n\n\n</code></pre><p>5.然后我启动服务，尝试启动mysql</p>\n<pre><code>\n[root@evilRat_desktop evilrat]# systemctl start mariadb.service\n[root@evilRat_desktop evilrat]# systemctl enable mariadb.service\nCreated symlink from /etc/systemd/system/multi-user.target.wants/mariadb.service to /usr/lib/systemd/system/mariadb.service.\n[root@evilRat_desktop evilrat]# mysql\nWelcome to the MariaDB monitor.  Commands end with ; or \\g.\nYour MariaDB connection id is 2\nServer version: 5.5.52-MariaDB MariaDB Server\n\nCopyright (c) 2000, 2016, Oracle, MariaDB Corporation Ab and others.\n\nType &#39;help;&#39; or &#39;\\h&#39; for help. Type &#39;\\c&#39; to clear the current input statement.\n\nMariaDB [(none)]&gt; show databases\n    -&gt; ;\n+--------------------+\n| Database           |\n+--------------------+\n| information_schema |\n| mysql              |\n| performance_schema |\n| test               |\n+--------------------+\n4 rows in set (0.00 sec)\n\nMariaDB [(none)]&gt; exit\nBye\n\n\n</code></pre><html>\n<div class=\"ds-thread\" data-thread-key=\"http://kongzheng1993.github.io/kongzheng1993-centos7_mysql/\" data-title=\"centos7_mysql\" data-url=\"http://kongzheng1993.github.io/kongzheng1993-centos7_mysql/\"></div>\n<!-- 多说评论框 end -->\n<!-- 多说公共JS代码 start (一个网页只需插入一次) -->\n<script type=\"text/javascript\">\nvar duoshuoQuery = {short_name:\"kongzheng1993\"};\n    (function() {\n        var ds = document.createElement('script');\n        ds.type = 'text/javascript';ds.async = true;\n        ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';\n        ds.charset = 'UTF-8';\n        (document.getElementsByTagName('head')[0] \n         || document.getElementsByTagName('body')[0]).appendChild(ds);\n    })();\n</script>\n</html>\n\n","site":{"data":{}},"more":"<h2 id=\"cent-os-7安装mysql遇到的问题\"><a href=\"#cent-os-7安装mysql遇到的问题\" class=\"headerlink\" title=\"cent os 7安装mysql遇到的问题\"></a>cent os 7安装mysql遇到的问题</h2><p>1.在centos 7上装mysql，但是运行的话会报错，服务未启动</p>\n<pre><code>\n[evilrat@evilRat_desktop ~]$ mysql status\nERROR 2002 (HY000): Can&#39;t connect to local MySQL server through socket &#39;/var/lib/mysql/mysql.sock&#39; (2)\n\n</code></pre><p>2.尝试启动服务：</p>\n<pre><code>\n[evilrat@evilRat_desktop ~]$ systemctl enable mysql.service\nFailed to execute operation: Access denied\n\n</code></pre><p>这样也不行……</p>\n<pre><code>\n[evilrat@evilRat_desktop ~]$ service mysql start\nRedirecting to /bin/systemctl start  mysql.service\n\n\n</code></pre><p>3.通过百度找到这个<br>mariaDB</p>\n<p>MariaDB数据库管理系统是MySQL的一个分支，主要由开源社区在维护，采用GPL授权许可 MariaDB的目的是完全兼容MySQL，包括API和命令行，使之能轻松成为MySQL的代替品。在存储引擎方面，使用XtraDB（英语：XtraDB）来代替MySQL的InnoDB。 MariaDB由MySQL的创始人Michael Widenius（英语：Michael Widenius）主导开发，他早前曾以10亿美元的价格，将自己创建的公司MySQL AB卖给了SUN，此后，随着SUN被甲骨文收购，MySQL的所有权也落入Oracle的手中。MariaDB名称来自Michael Widenius的女儿Maria的名字。<br>MariaDB基于事务的Maria存储引擎，替换了MySQL的MyISAM存储引擎，它使用了Percona的 XtraDB，InnoDB的变体，分支的开发者希望提供访问即将到来的MySQL 5.4 InnoDB性能。这个版本还包括了 PrimeBase XT (PBXT) 和 FederatedX存储引擎。</p>\n<p>4.于是我尝试安装了一下</p>\n<pre><code>\n[root@evilRat_desktop evilrat]# yum install mariadb-server -y\nLoaded plugins: fastestmirror, langpacks\nRepository epel is listed more than once in the configuration\nRepository epel-debuginfo is listed more than once in the configuration\nRepository epel-source is listed more than once in the configuration\nRepodata is over 2 weeks old. Install yum-cron? Or run: yum makecache fast\nadobe-linux-x86_64                                       |  951 B     00:00     \nbase                                                     | 3.6 kB     00:00     \nepel                                                     | 4.3 kB     00:00     \nextras                                                   | 3.4 kB     00:00     \nnux-dextop                                               | 2.9 kB     00:00     \nupdates                                                  | 3.4 kB     00:00     \n(1/5): extras/7/x86_64/primary_db                          | 139 kB   00:00     \n(2/5): epel/x86_64/updateinfo                              | 765 kB   00:01     \n(3/5): epel/x86_64/primary_db                              | 4.6 MB   00:10     \n(4/5): updates/7/x86_64/primary_db                         | 3.8 MB   00:11     \n(5/5): nux-dextop/x86_64/primary_db                        | 1.7 MB   00:29     \nadobe-linux-x86_64/primary                                 | 1.3 kB   00:00     \nLoading mirror speeds from cached hostfile\n * base: mirrors.aliyun.com\n * epel: mirrors.aliyun.com\n * extras: mirrors.aliyun.com\n * nux-dextop: li.nux.ro\n * updates: mirrors.aliyun.com\nadobe-linux-x86_64                                                          3/3\nResolving Dependencies\n--&gt; Running transaction check\n---&gt; Package mariadb-server.x86_64 1:5.5.52-1.el7 will be installed\n--&gt; Processing Dependency: perl-DBI for package: 1:mariadb-server-5.5.52-1.el7.x86_64\n--&gt; Processing Dependency: perl-DBD-MySQL for package: 1:mariadb-server-5.5.52-1.el7.x86_64\n--&gt; Processing Dependency: perl(DBI) for package: 1:mariadb-server-5.5.52-1.el7.x86_64\n--&gt; Running transaction check\n---&gt; Package perl-DBD-MySQL.x86_64 0:4.023-5.el7 will be installed\n---&gt; Package perl-DBI.x86_64 0:1.627-4.el7 will be installed\n--&gt; Processing Dependency: perl(RPC::PlServer) &gt;= 0.2001 for package: perl-DBI-1.627-4.el7.x86_64\n--&gt; Processing Dependency: perl(RPC::PlClient) &gt;= 0.2000 for package: perl-DBI-1.627-4.el7.x86_64\n--&gt; Running transaction check\n---&gt; Package perl-PlRPC.noarch 0:0.2020-14.el7 will be installed\n--&gt; Processing Dependency: perl(Net::Daemon) &gt;= 0.13 for package: perl-PlRPC-0.2020-14.el7.noarch\n--&gt; Processing Dependency: perl(Net::Daemon::Test) for package: perl-PlRPC-0.2020-14.el7.noarch\n--&gt; Processing Dependency: perl(Net::Daemon::Log) for package: perl-PlRPC-0.2020-14.el7.noarch\n--&gt; Processing Dependency: perl(Compress::Zlib) for package: perl-PlRPC-0.2020-14.el7.noarch\n--&gt; Running transaction check\n---&gt; Package perl-IO-Compress.noarch 0:2.061-2.el7 will be installed\n--&gt; Processing Dependency: perl(Compress::Raw::Zlib) &gt;= 2.061 for package: perl-IO-Compress-2.061-2.el7.noarch\n--&gt; Processing Dependency: perl(Compress::Raw::Bzip2) &gt;= 2.061 for package: perl-IO-Compress-2.061-2.el7.noarch\n---&gt; Package perl-Net-Daemon.noarch 0:0.48-5.el7 will be installed\n--&gt; Running transaction check\n---&gt; Package perl-Compress-Raw-Bzip2.x86_64 0:2.061-3.el7 will be installed\n---&gt; Package perl-Compress-Raw-Zlib.x86_64 1:2.061-4.el7 will be installed\n--&gt; Finished Dependency Resolution\n\nDependencies Resolved\n\n================================================================================\n Package                      Arch        Version               Repository\n                                                                           Size\n================================================================================\nInstalling:\n mariadb-server               x86_64      1:5.5.52-1.el7        base       11 M\nInstalling for dependencies:\n perl-Compress-Raw-Bzip2      x86_64      2.061-3.el7           base       32 k\n perl-Compress-Raw-Zlib       x86_64      1:2.061-4.el7         base       57 k\n perl-DBD-MySQL               x86_64      4.023-5.el7           base      140 k\n perl-DBI                     x86_64      1.627-4.el7           base      802 k\n perl-IO-Compress             noarch      2.061-2.el7           base      260 k\n perl-Net-Daemon              noarch      0.48-5.el7            base       51 k\n perl-PlRPC                   noarch      0.2020-14.el7         base       36 k\n\nTransaction Summary\n================================================================================\nInstall  1 Package (+7 Dependent packages)\n\nTotal download size: 12 M\nInstalled size: 59 M\nDownloading packages:\n(1/8): perl-Compress-Raw-Bzip2-2.061-3.el7.x86_64.rpm      |  32 kB   00:00     \n(2/8): perl-Compress-Raw-Zlib-2.061-4.el7.x86_64.rpm       |  57 kB   00:00     \n(3/8): perl-DBD-MySQL-4.023-5.el7.x86_64.rpm               | 140 kB   00:00     \n(4/8): perl-DBI-1.627-4.el7.x86_64.rpm                     | 802 kB   00:00     \n(5/8): perl-IO-Compress-2.061-2.el7.noarch.rpm             | 260 kB   00:00     \n(6/8): perl-Net-Daemon-0.48-5.el7.noarch.rpm               |  51 kB   00:00     \n(7/8): perl-PlRPC-0.2020-14.el7.noarch.rpm                 |  36 kB   00:00     \n(8/8): mariadb-server-5.5.52-1.el7.x86_64.rpm              |  11 MB   00:12     \n--------------------------------------------------------------------------------\nTotal                                              1.0 MB/s |  12 MB  00:12     \nRunning transaction check\nRunning transaction test\nTransaction test succeeded\nRunning transaction\n  Installing : perl-Compress-Raw-Bzip2-2.061-3.el7.x86_64                   1/8 \n  Installing : 1:perl-Compress-Raw-Zlib-2.061-4.el7.x86_64                  2/8 \n  Installing : perl-IO-Compress-2.061-2.el7.noarch                          3/8 \n  Installing : perl-Net-Daemon-0.48-5.el7.noarch                            4/8 \n  Installing : perl-PlRPC-0.2020-14.el7.noarch                              5/8 \n  Installing : perl-DBI-1.627-4.el7.x86_64                                  6/8 \n  Installing : perl-DBD-MySQL-4.023-5.el7.x86_64                            7/8 \n  Installing : 1:mariadb-server-5.5.52-1.el7.x86_64                         8/8 \n  Verifying  : perl-Net-Daemon-0.48-5.el7.noarch                            1/8 \n  Verifying  : 1:mariadb-server-5.5.52-1.el7.x86_64                         2/8 \n  Verifying  : perl-IO-Compress-2.061-2.el7.noarch                          3/8 \n  Verifying  : 1:perl-Compress-Raw-Zlib-2.061-4.el7.x86_64                  4/8 \n  Verifying  : perl-PlRPC-0.2020-14.el7.noarch                              5/8 \n  Verifying  : perl-DBI-1.627-4.el7.x86_64                                  6/8 \n  Verifying  : perl-Compress-Raw-Bzip2-2.061-3.el7.x86_64                   7/8 \n  Verifying  : perl-DBD-MySQL-4.023-5.el7.x86_64                            8/8 \n\nInstalled:\n  mariadb-server.x86_64 1:5.5.52-1.el7                                          \n\nDependency Installed:\n  perl-Compress-Raw-Bzip2.x86_64 0:2.061-3.el7                                  \n  perl-Compress-Raw-Zlib.x86_64 1:2.061-4.el7                                   \n  perl-DBD-MySQL.x86_64 0:4.023-5.el7                                           \n  perl-DBI.x86_64 0:1.627-4.el7                                                 \n  perl-IO-Compress.noarch 0:2.061-2.el7                                         \n  perl-Net-Daemon.noarch 0:0.48-5.el7                                           \n  perl-PlRPC.noarch 0:0.2020-14.el7                                             \n\nComplete!\n\n\n\n</code></pre><p>5.然后我启动服务，尝试启动mysql</p>\n<pre><code>\n[root@evilRat_desktop evilrat]# systemctl start mariadb.service\n[root@evilRat_desktop evilrat]# systemctl enable mariadb.service\nCreated symlink from /etc/systemd/system/multi-user.target.wants/mariadb.service to /usr/lib/systemd/system/mariadb.service.\n[root@evilRat_desktop evilrat]# mysql\nWelcome to the MariaDB monitor.  Commands end with ; or \\g.\nYour MariaDB connection id is 2\nServer version: 5.5.52-MariaDB MariaDB Server\n\nCopyright (c) 2000, 2016, Oracle, MariaDB Corporation Ab and others.\n\nType &#39;help;&#39; or &#39;\\h&#39; for help. Type &#39;\\c&#39; to clear the current input statement.\n\nMariaDB [(none)]&gt; show databases\n    -&gt; ;\n+--------------------+\n| Database           |\n+--------------------+\n| information_schema |\n| mysql              |\n| performance_schema |\n| test               |\n+--------------------+\n4 rows in set (0.00 sec)\n\nMariaDB [(none)]&gt; exit\nBye\n\n\n</code></pre><html>\n<div class=\"ds-thread\" data-thread-key=\"http://kongzheng1993.github.io/kongzheng1993-centos7_mysql/\" data-title=\"centos7_mysql\" data-url=\"http://kongzheng1993.github.io/kongzheng1993-centos7_mysql/\"></div>\n<!-- 多说评论框 end -->\n<!-- 多说公共JS代码 start (一个网页只需插入一次) -->\n<script type=\"text/javascript\">\nvar duoshuoQuery = {short_name:\"kongzheng1993\"};\n    (function() {\n        var ds = document.createElement('script');\n        ds.type = 'text/javascript';ds.async = true;\n        ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';\n        ds.charset = 'UTF-8';\n        (document.getElementsByTagName('head')[0] \n         || document.getElementsByTagName('body')[0]).appendChild(ds);\n    })();\n</script>\n</html>\n\n"},{"title":"HashMap&ConcurrentHashMap","excerpt":"","comments":1,"date":"2019-08-17T16:30:52.000Z","_content":"\n## jdk1.7\n\n### HashMap\n\n1. HashMap默认大小是16，1 << 4\n2. 可以使用构造方法`HashMap(int initialCapacity, float loadFactor)`来创建一个HashMap，实际上使用无参的构造函数也会调用这个有参的构造方法。这里只会将初始容量和加载因子赋值给对象的成员变量。这里并没有创建HashMap的中的Entry数组\n3. 加载因子决定了什么时候扩充HashMap的容量。比如默认的加载因子是0.75L，也就是当容量已经占用到4/3的时候就会触发扩容。\n4. 当我们调用`public V put(K key, V value)`的时候，会判断table（Entry数组）是否为空。如果为空，会调用`inflateTable(threshold)`，这里的threshold就是一开始创建HashMap的初始容量。在这里threshold会被处理成比它自身大的最小的2的幂，比如传3，这里就会是4，10这里就会是16。然后接下来就会创建一个Entry数组了。在inflateTable方法初始化了Entry数组后，就会判断key是否为空，如果为空就调用`putForNullKey(value)`，也就是说HashMap允许key为null\n5. 为什么创建对象的时候容量一定要是2的幂呢？这和HashMap计算每个key的位置有关系。怎么确定应该放在什么位置？\n\n```java\nfinal int hash(Object k) {\n    int h = hashSeed;\n    if (0 != h && k instanceof String) {\n        return sun.misc.Hashing.stringHash32((String) k);\n    }\n\n    h ^= k.hashCode();\n    // This function ensures that hashCodes that differ only by\n    // constant multiples at each bit position have a bounded\n    // number of collisions (approximately 8 at default load factor).\n    h ^= (h >>> 20) ^ (h >>> 12);\n    return h ^ (h >>> 7) ^ (h >>> 4);\n    }\n```\n\n如果我们直接拿到key的hashcode，然后和数组长度进行取余，每次都会返回0~entry.length()之间的数字，也就可以唯一确认一个位置。\n\n但是考虑到效率问题，jdk里并没有这么做，因为计算机进行二进制的位运算是最快的，所以这里选择了位与运算。\n\n```java\nstatic int indexFor(int h, int length) {\n    // assert Integer.bitCount(length) == 1 : \"length must be a non-zero power of 2\";\n    return h & (length-1);\n}\n```\n\n这里返回的是最终存在数组中的位置。这里是hash方法结果与长度-1做与运算。\n\n先搞懂为什么是长度-1？\n之前我们了解到数组长度肯定是2的幂，\n比如key的hashcode的二进制为1010 1010\n数组大小为8，也就是1000，减去1后就是0111\n做与运算：\n1010 1010\n0000 0111\n&\n0000 0010\n\n可以看出，数组长度为2的幂，减一后，低位一定全是1，也就是会把key的hashcode的低位保留下来，而且低几位也是确定的，而这低几位，不论key的hashcode是多少，肯定也是在0-entry.length-1之间。达到了和取余一样的效果，而且性能更好。\n\n但是我们看到hash方法后面一顿位移操作，这又是为什么呢？\n\n我们刚才所说的方法，如果直接那key的hashcode来做的话，那么大的数，只有最后几位有用，高位的值对最终的位置不会有影响，这样会有很大机率发生哈希冲突。\n\n前面的hash方法中，在返回之前，做了右移和异或操作，这样的话把高位移到右边，再加上异或操作，使得高位也可以影响到最后产生的hash值，这样就可以减小发生hash冲突的可能性。这个操作也是因为`hash(Object k)`的参数可以是自定义的，那么这个自定义类的hashCode方法也是可以重写的，如果程序员设计的hashCode方法散列性不高，jdk源码中的右移和异或操作也可以增大散列性。\n6. put方法中确定了位置之后，就开始遍历该位置的entry链表，如果有重复的，会将旧的值返回出去，并且把该位置的entry的value修改为新的value。如果没有重复的值，就回modCount++，然后调用`addEntry(hash, key, value, i)`，这个方法的逻辑就是，先判断size是否到达了阈值，也就是当前的容量大小*扩容因子，并且table[i]!=null，就会触发扩容（也就是table当前位置不为空的时候才会进行扩容，jdk1.8已经去掉），扩容是new一个新的entry数组，长度为之前容量的两倍，然后调用transfer方法，二重循环将旧数组中每个entry放到新的数组中，最后新数组会被赋值给旧数组变量，旧数组对象就会被回收。扩容处理完以后就会拿到数组中i位置的entry对象，然后调用new一个entry，next指向之前table[i]的entry，也就是放在了i位置的头部，然后把这个entry放在了table的i位置，之后size++，记录size是为了当调用map.size()的时候，更快的返回结果。\n7. 到这里HashMap线程不安全的原因就明确了，当多线程中数组需要扩容时，new新数组的时候，就会发生一些预期外的结果。HashMap通过设置足够的容量可以避免线程不安全问题。\n\n### HashTable\n\nHashTable为了解决线程安全问题，在HashMap的基础上加入了锁，在方法中加入synchronized。但是这样做回严重影响效率，所以很少使用。\n\n### ConcurrentHashMap\n\n像HashTable，每个线程要去竞争同一把锁，这样回严重影响效率，但是如果分段加锁，可以减少竞争同一把锁的线程数，就可以有效的缓解线程之间的竞争，提高效率。\n\n1. 增加了属性，并发级别，就是控制分多少段，默认16。\n2. 增加了一个对象，segment，每个segment就像之前的一个HashMap。\nConcurrentHashMap中有个多个segment(小HashMap)，而且segment继承了ReentrantLock，也就是它自带锁，segment在执行put方法时会先去获取锁，操作完成后会释放锁。segment中有Entry数组。\n3. ConcurrentHashMap在执行put方法时，要先计算出应该放在哪个segment中，然后调用这个segment的put方法。segment的put方法逻辑就像之前HashMap的put方法了。\n4. 初始化segment数组的时候，要根据构造方法传入的容量和并发级别计算出每个segment多大。\n\n```java\n    int ssize = 1;\n    while (ssize < concurrencyLevel) {\n        ++sshift;\n        ssize <<= 1;\n    }\n```\n\n这里的ssize就是初始话segment数组的大小。计算ssize，就是得到最小的大于并发级别的2的幂。\n\n- 容量为16，并发级别是8，那么segment数组的容量就是8\n- 容量是16，并发级别是4，那么segment数组的容量就是4\n- 容量为16，并发级别是5，那么segment数组的容量就是8\n\n5. put时，会根据key计算出hash值，计算方法和HashMap稍有不同，不过思想是一样的。根据hash值得到要放在哪一个segment中，如果这个位置的segment是null，就要new一个segment。而一个segment有是一个entry数组，就要计算这个entry数组的大小应该是多少。不过这里很简单，就是整个ConcurrentHashMap的容量除以segment的容量\n\n## jdk1.8\n\n如果Map中的链表随着插入的entry的增多越来越长，就会导致每次操作越来越慢，因为链表是需要遍历的，每次put/get都要遍历判断链表上的每个entry。所以在jdk1.8引入了红黑树。\n\n### HashMap\n\n1. 当链表长度大于8并且**Node数组长度大于等于64**时就会把这个链表修改为空黑树，再把新的entry加入到红黑树中。\n2. 已经引入了红黑树，所以jdk1.8在计算hash的时候也是1.7的思路，但是没有那么多的右移了。\n3. 1.8把之前的Entry改成了Node\n4. 思路大致和1.7一致，putVal方法中，会根据key计算hash，然后计算出应该存放在table哪个位置，如果这个位置是null，就会new一个Node，放在table的该位置。如果这个位置不是null，先判断table数组中该位置的node是否key是一致的，如果是一致的，就直接替换这个node，如果不一致，就会先判断这个node是不是一个TreeNode(红黑树)，如果不是红黑树，也就是一个链表，有一个和1.7不一样的地方是，1.8会直接将这个node插入到链表的尾部，而1.7是插入到头部，插入到尾部是因为加入了红黑树，插入的时候一定要判断链表长度，好决定要不要转换成红黑树，所以遍历完以后不如直接插入到尾部，而且这样还有一个好处，就是扩容的时候，移动node时不会导致顺序变化，多线程的时候就不会导致循环链表的问题（因为每次扩容都变化node顺序，另外一个线程获取到的next可能时这个线程的上一个），插入完成后，会判断长度是否到达了8，如果是就会转换成红黑树。如果是红黑树，就插入到红黑树。\n\n### ConcurrentHashMap\n\n1. 1.8的ConcurrentHashMap基于1.8的HashMap来的。\n2. 1.7的ConcurrentHashMap是分段加锁，即每个segment一把锁，而基于1.8HashMap的思想，每次操作一个链表或者红黑树，都会操作table上的node，也就是链表的头部，或者树的根节点，所以只在table的node上加锁就可以了。\n3. 1.8的ConcurrentHashMap中就没有segment这个概念了，因为旨在table上的node加锁嘛。\n4. 怎么加的锁呢？在操作ConcurrentHashMap时，获取到当前key在table上所在的位置的时候，就给table上这个位置的node对象加锁，使用synchronized给node对象加锁。这样减少了对象的创建，节省了内存。\n\n```java\nfinal V putVal(K key, V value, boolean onlyIfAbsent) {\n        if (key == null || value == null) throw new NullPointerException();\n        int hash = spread(key.hashCode());\n        int binCount = 0;\n        for (Node<K,V>[] tab = table;;) {\n            Node<K,V> f; int n, i, fh;\n            if (tab == null || (n = tab.length) == 0)\n                tab = initTable();\n            else if ((f = tabAt(tab, i = (n - 1) & hash)) == null) {\n                if (casTabAt(tab, i, null,\n                             new Node<K,V>(hash, key, value, null)))\n                    break;                   // no lock when adding to empty bin\n            }\n            else if ((fh = f.hash) == MOVED)\n                tab = helpTransfer(tab, f);\n            else {\n                V oldVal = null;\n                synchronized (f) {\n                    if (tabAt(tab, i) == f) {\n                        if (fh >= 0) {\n                            binCount = 1;\n                            for (Node<K,V> e = f;; ++binCount) {\n                                K ek;\n                                if (e.hash == hash &&\n                                    ((ek = e.key) == key ||\n                                     (ek != null && key.equals(ek)))) {\n                                    oldVal = e.val;\n                                    if (!onlyIfAbsent)\n                                        e.val = value;\n                                    break;\n                                }\n                                Node<K,V> pred = e;\n                                if ((e = e.next) == null) {\n                                    pred.next = new Node<K,V>(hash, key,\n                                                              value, null);\n                                    break;\n                                }\n                            }\n                        }\n                        else if (f instanceof TreeBin) {\n                            Node<K,V> p;\n                            binCount = 2;\n                            if ((p = ((TreeBin<K,V>)f).putTreeVal(hash, key,\n                                                           value)) != null) {\n                                oldVal = p.val;\n                                if (!onlyIfAbsent)\n                                    p.val = value;\n                            }\n                        }\n                    }\n                }\n                if (binCount != 0) {\n                    if (binCount >= TREEIFY_THRESHOLD)\n                        treeifyBin(tab, i);\n                    if (oldVal != null)\n                        return oldVal;\n                    break;\n                }\n            }\n        }\n        addCount(1L, binCount);\n        return null;\n    }\n```\n","source":"_posts/2019-08-18-kongzheng1993-HashMap&ConcurrentHashMap.md","raw":"---\ntitle: HashMap&ConcurrentHashMap\nexcerpt: ''\ntags: [jdk]\ncategories: [jdk]\ncomments: true\ndate: 2019-08-18 00:30:52\n---\n\n## jdk1.7\n\n### HashMap\n\n1. HashMap默认大小是16，1 << 4\n2. 可以使用构造方法`HashMap(int initialCapacity, float loadFactor)`来创建一个HashMap，实际上使用无参的构造函数也会调用这个有参的构造方法。这里只会将初始容量和加载因子赋值给对象的成员变量。这里并没有创建HashMap的中的Entry数组\n3. 加载因子决定了什么时候扩充HashMap的容量。比如默认的加载因子是0.75L，也就是当容量已经占用到4/3的时候就会触发扩容。\n4. 当我们调用`public V put(K key, V value)`的时候，会判断table（Entry数组）是否为空。如果为空，会调用`inflateTable(threshold)`，这里的threshold就是一开始创建HashMap的初始容量。在这里threshold会被处理成比它自身大的最小的2的幂，比如传3，这里就会是4，10这里就会是16。然后接下来就会创建一个Entry数组了。在inflateTable方法初始化了Entry数组后，就会判断key是否为空，如果为空就调用`putForNullKey(value)`，也就是说HashMap允许key为null\n5. 为什么创建对象的时候容量一定要是2的幂呢？这和HashMap计算每个key的位置有关系。怎么确定应该放在什么位置？\n\n```java\nfinal int hash(Object k) {\n    int h = hashSeed;\n    if (0 != h && k instanceof String) {\n        return sun.misc.Hashing.stringHash32((String) k);\n    }\n\n    h ^= k.hashCode();\n    // This function ensures that hashCodes that differ only by\n    // constant multiples at each bit position have a bounded\n    // number of collisions (approximately 8 at default load factor).\n    h ^= (h >>> 20) ^ (h >>> 12);\n    return h ^ (h >>> 7) ^ (h >>> 4);\n    }\n```\n\n如果我们直接拿到key的hashcode，然后和数组长度进行取余，每次都会返回0~entry.length()之间的数字，也就可以唯一确认一个位置。\n\n但是考虑到效率问题，jdk里并没有这么做，因为计算机进行二进制的位运算是最快的，所以这里选择了位与运算。\n\n```java\nstatic int indexFor(int h, int length) {\n    // assert Integer.bitCount(length) == 1 : \"length must be a non-zero power of 2\";\n    return h & (length-1);\n}\n```\n\n这里返回的是最终存在数组中的位置。这里是hash方法结果与长度-1做与运算。\n\n先搞懂为什么是长度-1？\n之前我们了解到数组长度肯定是2的幂，\n比如key的hashcode的二进制为1010 1010\n数组大小为8，也就是1000，减去1后就是0111\n做与运算：\n1010 1010\n0000 0111\n&\n0000 0010\n\n可以看出，数组长度为2的幂，减一后，低位一定全是1，也就是会把key的hashcode的低位保留下来，而且低几位也是确定的，而这低几位，不论key的hashcode是多少，肯定也是在0-entry.length-1之间。达到了和取余一样的效果，而且性能更好。\n\n但是我们看到hash方法后面一顿位移操作，这又是为什么呢？\n\n我们刚才所说的方法，如果直接那key的hashcode来做的话，那么大的数，只有最后几位有用，高位的值对最终的位置不会有影响，这样会有很大机率发生哈希冲突。\n\n前面的hash方法中，在返回之前，做了右移和异或操作，这样的话把高位移到右边，再加上异或操作，使得高位也可以影响到最后产生的hash值，这样就可以减小发生hash冲突的可能性。这个操作也是因为`hash(Object k)`的参数可以是自定义的，那么这个自定义类的hashCode方法也是可以重写的，如果程序员设计的hashCode方法散列性不高，jdk源码中的右移和异或操作也可以增大散列性。\n6. put方法中确定了位置之后，就开始遍历该位置的entry链表，如果有重复的，会将旧的值返回出去，并且把该位置的entry的value修改为新的value。如果没有重复的值，就回modCount++，然后调用`addEntry(hash, key, value, i)`，这个方法的逻辑就是，先判断size是否到达了阈值，也就是当前的容量大小*扩容因子，并且table[i]!=null，就会触发扩容（也就是table当前位置不为空的时候才会进行扩容，jdk1.8已经去掉），扩容是new一个新的entry数组，长度为之前容量的两倍，然后调用transfer方法，二重循环将旧数组中每个entry放到新的数组中，最后新数组会被赋值给旧数组变量，旧数组对象就会被回收。扩容处理完以后就会拿到数组中i位置的entry对象，然后调用new一个entry，next指向之前table[i]的entry，也就是放在了i位置的头部，然后把这个entry放在了table的i位置，之后size++，记录size是为了当调用map.size()的时候，更快的返回结果。\n7. 到这里HashMap线程不安全的原因就明确了，当多线程中数组需要扩容时，new新数组的时候，就会发生一些预期外的结果。HashMap通过设置足够的容量可以避免线程不安全问题。\n\n### HashTable\n\nHashTable为了解决线程安全问题，在HashMap的基础上加入了锁，在方法中加入synchronized。但是这样做回严重影响效率，所以很少使用。\n\n### ConcurrentHashMap\n\n像HashTable，每个线程要去竞争同一把锁，这样回严重影响效率，但是如果分段加锁，可以减少竞争同一把锁的线程数，就可以有效的缓解线程之间的竞争，提高效率。\n\n1. 增加了属性，并发级别，就是控制分多少段，默认16。\n2. 增加了一个对象，segment，每个segment就像之前的一个HashMap。\nConcurrentHashMap中有个多个segment(小HashMap)，而且segment继承了ReentrantLock，也就是它自带锁，segment在执行put方法时会先去获取锁，操作完成后会释放锁。segment中有Entry数组。\n3. ConcurrentHashMap在执行put方法时，要先计算出应该放在哪个segment中，然后调用这个segment的put方法。segment的put方法逻辑就像之前HashMap的put方法了。\n4. 初始化segment数组的时候，要根据构造方法传入的容量和并发级别计算出每个segment多大。\n\n```java\n    int ssize = 1;\n    while (ssize < concurrencyLevel) {\n        ++sshift;\n        ssize <<= 1;\n    }\n```\n\n这里的ssize就是初始话segment数组的大小。计算ssize，就是得到最小的大于并发级别的2的幂。\n\n- 容量为16，并发级别是8，那么segment数组的容量就是8\n- 容量是16，并发级别是4，那么segment数组的容量就是4\n- 容量为16，并发级别是5，那么segment数组的容量就是8\n\n5. put时，会根据key计算出hash值，计算方法和HashMap稍有不同，不过思想是一样的。根据hash值得到要放在哪一个segment中，如果这个位置的segment是null，就要new一个segment。而一个segment有是一个entry数组，就要计算这个entry数组的大小应该是多少。不过这里很简单，就是整个ConcurrentHashMap的容量除以segment的容量\n\n## jdk1.8\n\n如果Map中的链表随着插入的entry的增多越来越长，就会导致每次操作越来越慢，因为链表是需要遍历的，每次put/get都要遍历判断链表上的每个entry。所以在jdk1.8引入了红黑树。\n\n### HashMap\n\n1. 当链表长度大于8并且**Node数组长度大于等于64**时就会把这个链表修改为空黑树，再把新的entry加入到红黑树中。\n2. 已经引入了红黑树，所以jdk1.8在计算hash的时候也是1.7的思路，但是没有那么多的右移了。\n3. 1.8把之前的Entry改成了Node\n4. 思路大致和1.7一致，putVal方法中，会根据key计算hash，然后计算出应该存放在table哪个位置，如果这个位置是null，就会new一个Node，放在table的该位置。如果这个位置不是null，先判断table数组中该位置的node是否key是一致的，如果是一致的，就直接替换这个node，如果不一致，就会先判断这个node是不是一个TreeNode(红黑树)，如果不是红黑树，也就是一个链表，有一个和1.7不一样的地方是，1.8会直接将这个node插入到链表的尾部，而1.7是插入到头部，插入到尾部是因为加入了红黑树，插入的时候一定要判断链表长度，好决定要不要转换成红黑树，所以遍历完以后不如直接插入到尾部，而且这样还有一个好处，就是扩容的时候，移动node时不会导致顺序变化，多线程的时候就不会导致循环链表的问题（因为每次扩容都变化node顺序，另外一个线程获取到的next可能时这个线程的上一个），插入完成后，会判断长度是否到达了8，如果是就会转换成红黑树。如果是红黑树，就插入到红黑树。\n\n### ConcurrentHashMap\n\n1. 1.8的ConcurrentHashMap基于1.8的HashMap来的。\n2. 1.7的ConcurrentHashMap是分段加锁，即每个segment一把锁，而基于1.8HashMap的思想，每次操作一个链表或者红黑树，都会操作table上的node，也就是链表的头部，或者树的根节点，所以只在table的node上加锁就可以了。\n3. 1.8的ConcurrentHashMap中就没有segment这个概念了，因为旨在table上的node加锁嘛。\n4. 怎么加的锁呢？在操作ConcurrentHashMap时，获取到当前key在table上所在的位置的时候，就给table上这个位置的node对象加锁，使用synchronized给node对象加锁。这样减少了对象的创建，节省了内存。\n\n```java\nfinal V putVal(K key, V value, boolean onlyIfAbsent) {\n        if (key == null || value == null) throw new NullPointerException();\n        int hash = spread(key.hashCode());\n        int binCount = 0;\n        for (Node<K,V>[] tab = table;;) {\n            Node<K,V> f; int n, i, fh;\n            if (tab == null || (n = tab.length) == 0)\n                tab = initTable();\n            else if ((f = tabAt(tab, i = (n - 1) & hash)) == null) {\n                if (casTabAt(tab, i, null,\n                             new Node<K,V>(hash, key, value, null)))\n                    break;                   // no lock when adding to empty bin\n            }\n            else if ((fh = f.hash) == MOVED)\n                tab = helpTransfer(tab, f);\n            else {\n                V oldVal = null;\n                synchronized (f) {\n                    if (tabAt(tab, i) == f) {\n                        if (fh >= 0) {\n                            binCount = 1;\n                            for (Node<K,V> e = f;; ++binCount) {\n                                K ek;\n                                if (e.hash == hash &&\n                                    ((ek = e.key) == key ||\n                                     (ek != null && key.equals(ek)))) {\n                                    oldVal = e.val;\n                                    if (!onlyIfAbsent)\n                                        e.val = value;\n                                    break;\n                                }\n                                Node<K,V> pred = e;\n                                if ((e = e.next) == null) {\n                                    pred.next = new Node<K,V>(hash, key,\n                                                              value, null);\n                                    break;\n                                }\n                            }\n                        }\n                        else if (f instanceof TreeBin) {\n                            Node<K,V> p;\n                            binCount = 2;\n                            if ((p = ((TreeBin<K,V>)f).putTreeVal(hash, key,\n                                                           value)) != null) {\n                                oldVal = p.val;\n                                if (!onlyIfAbsent)\n                                    p.val = value;\n                            }\n                        }\n                    }\n                }\n                if (binCount != 0) {\n                    if (binCount >= TREEIFY_THRESHOLD)\n                        treeifyBin(tab, i);\n                    if (oldVal != null)\n                        return oldVal;\n                    break;\n                }\n            }\n        }\n        addCount(1L, binCount);\n        return null;\n    }\n```\n","slug":"kongzheng1993-HashMap&ConcurrentHashMap","published":1,"updated":"2023-03-08T07:05:58.776Z","layout":"post","photos":[],"link":"","_id":"clg0k2aou00hit26f1qbykpdj","content":"<h2 id=\"jdk1-7\"><a href=\"#jdk1-7\" class=\"headerlink\" title=\"jdk1.7\"></a>jdk1.7</h2><h3 id=\"HashMap\"><a href=\"#HashMap\" class=\"headerlink\" title=\"HashMap\"></a>HashMap</h3><ol>\n<li>HashMap默认大小是16，1 &lt;&lt; 4</li>\n<li>可以使用构造方法<code>HashMap(int initialCapacity, float loadFactor)</code>来创建一个HashMap，实际上使用无参的构造函数也会调用这个有参的构造方法。这里只会将初始容量和加载因子赋值给对象的成员变量。这里并没有创建HashMap的中的Entry数组</li>\n<li>加载因子决定了什么时候扩充HashMap的容量。比如默认的加载因子是0.75L，也就是当容量已经占用到4/3的时候就会触发扩容。</li>\n<li>当我们调用<code>public V put(K key, V value)</code>的时候，会判断table（Entry数组）是否为空。如果为空，会调用<code>inflateTable(threshold)</code>，这里的threshold就是一开始创建HashMap的初始容量。在这里threshold会被处理成比它自身大的最小的2的幂，比如传3，这里就会是4，10这里就会是16。然后接下来就会创建一个Entry数组了。在inflateTable方法初始化了Entry数组后，就会判断key是否为空，如果为空就调用<code>putForNullKey(value)</code>，也就是说HashMap允许key为null</li>\n<li>为什么创建对象的时候容量一定要是2的幂呢？这和HashMap计算每个key的位置有关系。怎么确定应该放在什么位置？</li>\n</ol>\n<pre><code class=\"java\">final int hash(Object k) {\n    int h = hashSeed;\n    if (0 != h &amp;&amp; k instanceof String) {\n        return sun.misc.Hashing.stringHash32((String) k);\n    }\n\n    h ^= k.hashCode();\n    // This function ensures that hashCodes that differ only by\n    // constant multiples at each bit position have a bounded\n    // number of collisions (approximately 8 at default load factor).\n    h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12);\n    return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4);\n    }</code></pre>\n<p>如果我们直接拿到key的hashcode，然后和数组长度进行取余，每次都会返回0~entry.length()之间的数字，也就可以唯一确认一个位置。</p>\n<p>但是考虑到效率问题，jdk里并没有这么做，因为计算机进行二进制的位运算是最快的，所以这里选择了位与运算。</p>\n<pre><code class=\"java\">static int indexFor(int h, int length) {\n    // assert Integer.bitCount(length) == 1 : &quot;length must be a non-zero power of 2&quot;;\n    return h &amp; (length-1);\n}</code></pre>\n<p>这里返回的是最终存在数组中的位置。这里是hash方法结果与长度-1做与运算。</p>\n<p>先搞懂为什么是长度-1？<br>之前我们了解到数组长度肯定是2的幂，<br>比如key的hashcode的二进制为1010 1010<br>数组大小为8，也就是1000，减去1后就是0111<br>做与运算：<br>1010 1010<br>0000 0111<br>&amp;\n0000 0010</p>\n<p>可以看出，数组长度为2的幂，减一后，低位一定全是1，也就是会把key的hashcode的低位保留下来，而且低几位也是确定的，而这低几位，不论key的hashcode是多少，肯定也是在0-entry.length-1之间。达到了和取余一样的效果，而且性能更好。</p>\n<p>但是我们看到hash方法后面一顿位移操作，这又是为什么呢？</p>\n<p>我们刚才所说的方法，如果直接那key的hashcode来做的话，那么大的数，只有最后几位有用，高位的值对最终的位置不会有影响，这样会有很大机率发生哈希冲突。</p>\n<p>前面的hash方法中，在返回之前，做了右移和异或操作，这样的话把高位移到右边，再加上异或操作，使得高位也可以影响到最后产生的hash值，这样就可以减小发生hash冲突的可能性。这个操作也是因为<code>hash(Object k)</code>的参数可以是自定义的，那么这个自定义类的hashCode方法也是可以重写的，如果程序员设计的hashCode方法散列性不高，jdk源码中的右移和异或操作也可以增大散列性。</p>\n<ol start=\"6\">\n<li>put方法中确定了位置之后，就开始遍历该位置的entry链表，如果有重复的，会将旧的值返回出去，并且把该位置的entry的value修改为新的value。如果没有重复的值，就回modCount++，然后调用<code>addEntry(hash, key, value, i)</code>，这个方法的逻辑就是，先判断size是否到达了阈值，也就是当前的容量大小*扩容因子，并且table[i]!=null，就会触发扩容（也就是table当前位置不为空的时候才会进行扩容，jdk1.8已经去掉），扩容是new一个新的entry数组，长度为之前容量的两倍，然后调用transfer方法，二重循环将旧数组中每个entry放到新的数组中，最后新数组会被赋值给旧数组变量，旧数组对象就会被回收。扩容处理完以后就会拿到数组中i位置的entry对象，然后调用new一个entry，next指向之前table[i]的entry，也就是放在了i位置的头部，然后把这个entry放在了table的i位置，之后size++，记录size是为了当调用map.size()的时候，更快的返回结果。</li>\n<li>到这里HashMap线程不安全的原因就明确了，当多线程中数组需要扩容时，new新数组的时候，就会发生一些预期外的结果。HashMap通过设置足够的容量可以避免线程不安全问题。</li>\n</ol>\n<h3 id=\"HashTable\"><a href=\"#HashTable\" class=\"headerlink\" title=\"HashTable\"></a>HashTable</h3><p>HashTable为了解决线程安全问题，在HashMap的基础上加入了锁，在方法中加入synchronized。但是这样做回严重影响效率，所以很少使用。</p>\n<h3 id=\"ConcurrentHashMap\"><a href=\"#ConcurrentHashMap\" class=\"headerlink\" title=\"ConcurrentHashMap\"></a>ConcurrentHashMap</h3><p>像HashTable，每个线程要去竞争同一把锁，这样回严重影响效率，但是如果分段加锁，可以减少竞争同一把锁的线程数，就可以有效的缓解线程之间的竞争，提高效率。</p>\n<ol>\n<li>增加了属性，并发级别，就是控制分多少段，默认16。</li>\n<li>增加了一个对象，segment，每个segment就像之前的一个HashMap。<br>ConcurrentHashMap中有个多个segment(小HashMap)，而且segment继承了ReentrantLock，也就是它自带锁，segment在执行put方法时会先去获取锁，操作完成后会释放锁。segment中有Entry数组。</li>\n<li>ConcurrentHashMap在执行put方法时，要先计算出应该放在哪个segment中，然后调用这个segment的put方法。segment的put方法逻辑就像之前HashMap的put方法了。</li>\n<li>初始化segment数组的时候，要根据构造方法传入的容量和并发级别计算出每个segment多大。</li>\n</ol>\n<pre><code class=\"java\">    int ssize = 1;\n    while (ssize &lt; concurrencyLevel) {\n        ++sshift;\n        ssize &lt;&lt;= 1;\n    }</code></pre>\n<p>这里的ssize就是初始话segment数组的大小。计算ssize，就是得到最小的大于并发级别的2的幂。</p>\n<ul>\n<li>容量为16，并发级别是8，那么segment数组的容量就是8</li>\n<li>容量是16，并发级别是4，那么segment数组的容量就是4</li>\n<li>容量为16，并发级别是5，那么segment数组的容量就是8</li>\n</ul>\n<ol start=\"5\">\n<li>put时，会根据key计算出hash值，计算方法和HashMap稍有不同，不过思想是一样的。根据hash值得到要放在哪一个segment中，如果这个位置的segment是null，就要new一个segment。而一个segment有是一个entry数组，就要计算这个entry数组的大小应该是多少。不过这里很简单，就是整个ConcurrentHashMap的容量除以segment的容量</li>\n</ol>\n<h2 id=\"jdk1-8\"><a href=\"#jdk1-8\" class=\"headerlink\" title=\"jdk1.8\"></a>jdk1.8</h2><p>如果Map中的链表随着插入的entry的增多越来越长，就会导致每次操作越来越慢，因为链表是需要遍历的，每次put/get都要遍历判断链表上的每个entry。所以在jdk1.8引入了红黑树。</p>\n<h3 id=\"HashMap-1\"><a href=\"#HashMap-1\" class=\"headerlink\" title=\"HashMap\"></a>HashMap</h3><ol>\n<li>当链表长度大于8并且<strong>Node数组长度大于等于64</strong>时就会把这个链表修改为空黑树，再把新的entry加入到红黑树中。</li>\n<li>已经引入了红黑树，所以jdk1.8在计算hash的时候也是1.7的思路，但是没有那么多的右移了。</li>\n<li>1.8把之前的Entry改成了Node</li>\n<li>思路大致和1.7一致，putVal方法中，会根据key计算hash，然后计算出应该存放在table哪个位置，如果这个位置是null，就会new一个Node，放在table的该位置。如果这个位置不是null，先判断table数组中该位置的node是否key是一致的，如果是一致的，就直接替换这个node，如果不一致，就会先判断这个node是不是一个TreeNode(红黑树)，如果不是红黑树，也就是一个链表，有一个和1.7不一样的地方是，1.8会直接将这个node插入到链表的尾部，而1.7是插入到头部，插入到尾部是因为加入了红黑树，插入的时候一定要判断链表长度，好决定要不要转换成红黑树，所以遍历完以后不如直接插入到尾部，而且这样还有一个好处，就是扩容的时候，移动node时不会导致顺序变化，多线程的时候就不会导致循环链表的问题（因为每次扩容都变化node顺序，另外一个线程获取到的next可能时这个线程的上一个），插入完成后，会判断长度是否到达了8，如果是就会转换成红黑树。如果是红黑树，就插入到红黑树。</li>\n</ol>\n<h3 id=\"ConcurrentHashMap-1\"><a href=\"#ConcurrentHashMap-1\" class=\"headerlink\" title=\"ConcurrentHashMap\"></a>ConcurrentHashMap</h3><ol>\n<li>1.8的ConcurrentHashMap基于1.8的HashMap来的。</li>\n<li>1.7的ConcurrentHashMap是分段加锁，即每个segment一把锁，而基于1.8HashMap的思想，每次操作一个链表或者红黑树，都会操作table上的node，也就是链表的头部，或者树的根节点，所以只在table的node上加锁就可以了。</li>\n<li>1.8的ConcurrentHashMap中就没有segment这个概念了，因为旨在table上的node加锁嘛。</li>\n<li>怎么加的锁呢？在操作ConcurrentHashMap时，获取到当前key在table上所在的位置的时候，就给table上这个位置的node对象加锁，使用synchronized给node对象加锁。这样减少了对象的创建，节省了内存。</li>\n</ol>\n<pre><code class=\"java\">final V putVal(K key, V value, boolean onlyIfAbsent) {\n        if (key == null || value == null) throw new NullPointerException();\n        int hash = spread(key.hashCode());\n        int binCount = 0;\n        for (Node&lt;K,V&gt;[] tab = table;;) {\n            Node&lt;K,V&gt; f; int n, i, fh;\n            if (tab == null || (n = tab.length) == 0)\n                tab = initTable();\n            else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) {\n                if (casTabAt(tab, i, null,\n                             new Node&lt;K,V&gt;(hash, key, value, null)))\n                    break;                   // no lock when adding to empty bin\n            }\n            else if ((fh = f.hash) == MOVED)\n                tab = helpTransfer(tab, f);\n            else {\n                V oldVal = null;\n                synchronized (f) {\n                    if (tabAt(tab, i) == f) {\n                        if (fh &gt;= 0) {\n                            binCount = 1;\n                            for (Node&lt;K,V&gt; e = f;; ++binCount) {\n                                K ek;\n                                if (e.hash == hash &amp;&amp;\n                                    ((ek = e.key) == key ||\n                                     (ek != null &amp;&amp; key.equals(ek)))) {\n                                    oldVal = e.val;\n                                    if (!onlyIfAbsent)\n                                        e.val = value;\n                                    break;\n                                }\n                                Node&lt;K,V&gt; pred = e;\n                                if ((e = e.next) == null) {\n                                    pred.next = new Node&lt;K,V&gt;(hash, key,\n                                                              value, null);\n                                    break;\n                                }\n                            }\n                        }\n                        else if (f instanceof TreeBin) {\n                            Node&lt;K,V&gt; p;\n                            binCount = 2;\n                            if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key,\n                                                           value)) != null) {\n                                oldVal = p.val;\n                                if (!onlyIfAbsent)\n                                    p.val = value;\n                            }\n                        }\n                    }\n                }\n                if (binCount != 0) {\n                    if (binCount &gt;= TREEIFY_THRESHOLD)\n                        treeifyBin(tab, i);\n                    if (oldVal != null)\n                        return oldVal;\n                    break;\n                }\n            }\n        }\n        addCount(1L, binCount);\n        return null;\n    }</code></pre>\n","site":{"data":{}},"more":"<h2 id=\"jdk1-7\"><a href=\"#jdk1-7\" class=\"headerlink\" title=\"jdk1.7\"></a>jdk1.7</h2><h3 id=\"HashMap\"><a href=\"#HashMap\" class=\"headerlink\" title=\"HashMap\"></a>HashMap</h3><ol>\n<li>HashMap默认大小是16，1 &lt;&lt; 4</li>\n<li>可以使用构造方法<code>HashMap(int initialCapacity, float loadFactor)</code>来创建一个HashMap，实际上使用无参的构造函数也会调用这个有参的构造方法。这里只会将初始容量和加载因子赋值给对象的成员变量。这里并没有创建HashMap的中的Entry数组</li>\n<li>加载因子决定了什么时候扩充HashMap的容量。比如默认的加载因子是0.75L，也就是当容量已经占用到4/3的时候就会触发扩容。</li>\n<li>当我们调用<code>public V put(K key, V value)</code>的时候，会判断table（Entry数组）是否为空。如果为空，会调用<code>inflateTable(threshold)</code>，这里的threshold就是一开始创建HashMap的初始容量。在这里threshold会被处理成比它自身大的最小的2的幂，比如传3，这里就会是4，10这里就会是16。然后接下来就会创建一个Entry数组了。在inflateTable方法初始化了Entry数组后，就会判断key是否为空，如果为空就调用<code>putForNullKey(value)</code>，也就是说HashMap允许key为null</li>\n<li>为什么创建对象的时候容量一定要是2的幂呢？这和HashMap计算每个key的位置有关系。怎么确定应该放在什么位置？</li>\n</ol>\n<pre><code class=\"java\">final int hash(Object k) {\n    int h = hashSeed;\n    if (0 != h &amp;&amp; k instanceof String) {\n        return sun.misc.Hashing.stringHash32((String) k);\n    }\n\n    h ^= k.hashCode();\n    // This function ensures that hashCodes that differ only by\n    // constant multiples at each bit position have a bounded\n    // number of collisions (approximately 8 at default load factor).\n    h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12);\n    return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4);\n    }</code></pre>\n<p>如果我们直接拿到key的hashcode，然后和数组长度进行取余，每次都会返回0~entry.length()之间的数字，也就可以唯一确认一个位置。</p>\n<p>但是考虑到效率问题，jdk里并没有这么做，因为计算机进行二进制的位运算是最快的，所以这里选择了位与运算。</p>\n<pre><code class=\"java\">static int indexFor(int h, int length) {\n    // assert Integer.bitCount(length) == 1 : &quot;length must be a non-zero power of 2&quot;;\n    return h &amp; (length-1);\n}</code></pre>\n<p>这里返回的是最终存在数组中的位置。这里是hash方法结果与长度-1做与运算。</p>\n<p>先搞懂为什么是长度-1？<br>之前我们了解到数组长度肯定是2的幂，<br>比如key的hashcode的二进制为1010 1010<br>数组大小为8，也就是1000，减去1后就是0111<br>做与运算：<br>1010 1010<br>0000 0111<br>&amp;\n0000 0010</p>\n<p>可以看出，数组长度为2的幂，减一后，低位一定全是1，也就是会把key的hashcode的低位保留下来，而且低几位也是确定的，而这低几位，不论key的hashcode是多少，肯定也是在0-entry.length-1之间。达到了和取余一样的效果，而且性能更好。</p>\n<p>但是我们看到hash方法后面一顿位移操作，这又是为什么呢？</p>\n<p>我们刚才所说的方法，如果直接那key的hashcode来做的话，那么大的数，只有最后几位有用，高位的值对最终的位置不会有影响，这样会有很大机率发生哈希冲突。</p>\n<p>前面的hash方法中，在返回之前，做了右移和异或操作，这样的话把高位移到右边，再加上异或操作，使得高位也可以影响到最后产生的hash值，这样就可以减小发生hash冲突的可能性。这个操作也是因为<code>hash(Object k)</code>的参数可以是自定义的，那么这个自定义类的hashCode方法也是可以重写的，如果程序员设计的hashCode方法散列性不高，jdk源码中的右移和异或操作也可以增大散列性。</p>\n<ol start=\"6\">\n<li>put方法中确定了位置之后，就开始遍历该位置的entry链表，如果有重复的，会将旧的值返回出去，并且把该位置的entry的value修改为新的value。如果没有重复的值，就回modCount++，然后调用<code>addEntry(hash, key, value, i)</code>，这个方法的逻辑就是，先判断size是否到达了阈值，也就是当前的容量大小*扩容因子，并且table[i]!=null，就会触发扩容（也就是table当前位置不为空的时候才会进行扩容，jdk1.8已经去掉），扩容是new一个新的entry数组，长度为之前容量的两倍，然后调用transfer方法，二重循环将旧数组中每个entry放到新的数组中，最后新数组会被赋值给旧数组变量，旧数组对象就会被回收。扩容处理完以后就会拿到数组中i位置的entry对象，然后调用new一个entry，next指向之前table[i]的entry，也就是放在了i位置的头部，然后把这个entry放在了table的i位置，之后size++，记录size是为了当调用map.size()的时候，更快的返回结果。</li>\n<li>到这里HashMap线程不安全的原因就明确了，当多线程中数组需要扩容时，new新数组的时候，就会发生一些预期外的结果。HashMap通过设置足够的容量可以避免线程不安全问题。</li>\n</ol>\n<h3 id=\"HashTable\"><a href=\"#HashTable\" class=\"headerlink\" title=\"HashTable\"></a>HashTable</h3><p>HashTable为了解决线程安全问题，在HashMap的基础上加入了锁，在方法中加入synchronized。但是这样做回严重影响效率，所以很少使用。</p>\n<h3 id=\"ConcurrentHashMap\"><a href=\"#ConcurrentHashMap\" class=\"headerlink\" title=\"ConcurrentHashMap\"></a>ConcurrentHashMap</h3><p>像HashTable，每个线程要去竞争同一把锁，这样回严重影响效率，但是如果分段加锁，可以减少竞争同一把锁的线程数，就可以有效的缓解线程之间的竞争，提高效率。</p>\n<ol>\n<li>增加了属性，并发级别，就是控制分多少段，默认16。</li>\n<li>增加了一个对象，segment，每个segment就像之前的一个HashMap。<br>ConcurrentHashMap中有个多个segment(小HashMap)，而且segment继承了ReentrantLock，也就是它自带锁，segment在执行put方法时会先去获取锁，操作完成后会释放锁。segment中有Entry数组。</li>\n<li>ConcurrentHashMap在执行put方法时，要先计算出应该放在哪个segment中，然后调用这个segment的put方法。segment的put方法逻辑就像之前HashMap的put方法了。</li>\n<li>初始化segment数组的时候，要根据构造方法传入的容量和并发级别计算出每个segment多大。</li>\n</ol>\n<pre><code class=\"java\">    int ssize = 1;\n    while (ssize &lt; concurrencyLevel) {\n        ++sshift;\n        ssize &lt;&lt;= 1;\n    }</code></pre>\n<p>这里的ssize就是初始话segment数组的大小。计算ssize，就是得到最小的大于并发级别的2的幂。</p>\n<ul>\n<li>容量为16，并发级别是8，那么segment数组的容量就是8</li>\n<li>容量是16，并发级别是4，那么segment数组的容量就是4</li>\n<li>容量为16，并发级别是5，那么segment数组的容量就是8</li>\n</ul>\n<ol start=\"5\">\n<li>put时，会根据key计算出hash值，计算方法和HashMap稍有不同，不过思想是一样的。根据hash值得到要放在哪一个segment中，如果这个位置的segment是null，就要new一个segment。而一个segment有是一个entry数组，就要计算这个entry数组的大小应该是多少。不过这里很简单，就是整个ConcurrentHashMap的容量除以segment的容量</li>\n</ol>\n<h2 id=\"jdk1-8\"><a href=\"#jdk1-8\" class=\"headerlink\" title=\"jdk1.8\"></a>jdk1.8</h2><p>如果Map中的链表随着插入的entry的增多越来越长，就会导致每次操作越来越慢，因为链表是需要遍历的，每次put/get都要遍历判断链表上的每个entry。所以在jdk1.8引入了红黑树。</p>\n<h3 id=\"HashMap-1\"><a href=\"#HashMap-1\" class=\"headerlink\" title=\"HashMap\"></a>HashMap</h3><ol>\n<li>当链表长度大于8并且<strong>Node数组长度大于等于64</strong>时就会把这个链表修改为空黑树，再把新的entry加入到红黑树中。</li>\n<li>已经引入了红黑树，所以jdk1.8在计算hash的时候也是1.7的思路，但是没有那么多的右移了。</li>\n<li>1.8把之前的Entry改成了Node</li>\n<li>思路大致和1.7一致，putVal方法中，会根据key计算hash，然后计算出应该存放在table哪个位置，如果这个位置是null，就会new一个Node，放在table的该位置。如果这个位置不是null，先判断table数组中该位置的node是否key是一致的，如果是一致的，就直接替换这个node，如果不一致，就会先判断这个node是不是一个TreeNode(红黑树)，如果不是红黑树，也就是一个链表，有一个和1.7不一样的地方是，1.8会直接将这个node插入到链表的尾部，而1.7是插入到头部，插入到尾部是因为加入了红黑树，插入的时候一定要判断链表长度，好决定要不要转换成红黑树，所以遍历完以后不如直接插入到尾部，而且这样还有一个好处，就是扩容的时候，移动node时不会导致顺序变化，多线程的时候就不会导致循环链表的问题（因为每次扩容都变化node顺序，另外一个线程获取到的next可能时这个线程的上一个），插入完成后，会判断长度是否到达了8，如果是就会转换成红黑树。如果是红黑树，就插入到红黑树。</li>\n</ol>\n<h3 id=\"ConcurrentHashMap-1\"><a href=\"#ConcurrentHashMap-1\" class=\"headerlink\" title=\"ConcurrentHashMap\"></a>ConcurrentHashMap</h3><ol>\n<li>1.8的ConcurrentHashMap基于1.8的HashMap来的。</li>\n<li>1.7的ConcurrentHashMap是分段加锁，即每个segment一把锁，而基于1.8HashMap的思想，每次操作一个链表或者红黑树，都会操作table上的node，也就是链表的头部，或者树的根节点，所以只在table的node上加锁就可以了。</li>\n<li>1.8的ConcurrentHashMap中就没有segment这个概念了，因为旨在table上的node加锁嘛。</li>\n<li>怎么加的锁呢？在操作ConcurrentHashMap时，获取到当前key在table上所在的位置的时候，就给table上这个位置的node对象加锁，使用synchronized给node对象加锁。这样减少了对象的创建，节省了内存。</li>\n</ol>\n<pre><code class=\"java\">final V putVal(K key, V value, boolean onlyIfAbsent) {\n        if (key == null || value == null) throw new NullPointerException();\n        int hash = spread(key.hashCode());\n        int binCount = 0;\n        for (Node&lt;K,V&gt;[] tab = table;;) {\n            Node&lt;K,V&gt; f; int n, i, fh;\n            if (tab == null || (n = tab.length) == 0)\n                tab = initTable();\n            else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) {\n                if (casTabAt(tab, i, null,\n                             new Node&lt;K,V&gt;(hash, key, value, null)))\n                    break;                   // no lock when adding to empty bin\n            }\n            else if ((fh = f.hash) == MOVED)\n                tab = helpTransfer(tab, f);\n            else {\n                V oldVal = null;\n                synchronized (f) {\n                    if (tabAt(tab, i) == f) {\n                        if (fh &gt;= 0) {\n                            binCount = 1;\n                            for (Node&lt;K,V&gt; e = f;; ++binCount) {\n                                K ek;\n                                if (e.hash == hash &amp;&amp;\n                                    ((ek = e.key) == key ||\n                                     (ek != null &amp;&amp; key.equals(ek)))) {\n                                    oldVal = e.val;\n                                    if (!onlyIfAbsent)\n                                        e.val = value;\n                                    break;\n                                }\n                                Node&lt;K,V&gt; pred = e;\n                                if ((e = e.next) == null) {\n                                    pred.next = new Node&lt;K,V&gt;(hash, key,\n                                                              value, null);\n                                    break;\n                                }\n                            }\n                        }\n                        else if (f instanceof TreeBin) {\n                            Node&lt;K,V&gt; p;\n                            binCount = 2;\n                            if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key,\n                                                           value)) != null) {\n                                oldVal = p.val;\n                                if (!onlyIfAbsent)\n                                    p.val = value;\n                            }\n                        }\n                    }\n                }\n                if (binCount != 0) {\n                    if (binCount &gt;= TREEIFY_THRESHOLD)\n                        treeifyBin(tab, i);\n                    if (oldVal != null)\n                        return oldVal;\n                    break;\n                }\n            }\n        }\n        addCount(1L, binCount);\n        return null;\n    }</code></pre>\n"},{"title":"MySQL基础","excerpt":"","comments":1,"date":"2019-09-11T10:30:52.000Z","_content":"\n## MySQL\n\n之前一只觉得数据库没什么，会用就行了，最近面试总是碰壁，很多又是数据库的问题打不上来，不够深入是我的大问题。所以准备总结一下。\n\n\n### 索引\n索引是数据库查询操作中提升速度的一种手段，索引是一种数据结构。\n索引是一个排序的列表，这个列表中存储着索引的值和包含这个值的数据所在的物理地址，数据量庞大的时候，索引可以快速定位需要查找的数据对应的物理地址，不需要扫描全表的数据。\n\n1. 建标时创建索引\n```sql\nCREATE TABLE t_table(\n    ID INT NOT NULL,\n    USER_NAME VARCHAR(16) NOT NULL,\n    INDEX USER_NAME_INDEX (USER_NAME), #单列索引\n    INDEX (ID,USER_NAME) #组合索引\n) ENGINE = INNODB DEFAULT CHARSET = utf8 COMMENT '注释';\n```\n\n2. 建表后创建索引\n```sql\nALTER TABLE t_TABLE ADD UNIQUE INDEX (ID);\nALTER TABLE T_TABLE ADD INDEX (ID,USER_NAME);\nALTER TABLE T_TABLE ADD PRIMARY KEY (ID);\n```\n\n3. 查看已经创建的索引\n```sql\nshow index from t_table;\n```\n\n4. 删除索引\n```sql\ndrop index user_name_index on t_table;\nalter table t_table drop index user_name_index;\n```\n\n5. 查看索引使用情况（执行计划）\n```sql\nexplain select * from t_table where user_name = 'Tom';\n```\n\n```\nmysql> explain select * from t_test where username = 'Tom';\n+----+-------------+--------+------------+------+-----------------------+-----------------------+---------+-------+------+----------+-------------+\n| id | select_type | table  | partitions | type | possible_keys         | key                   | key_len | ref   | rows | filtered | Extra       |\n+----+-------------+--------+------------+------+-----------------------+-----------------------+---------+-------+------+----------+-------------+\n|  1 | SIMPLE      | t_test | NULL       | ref  | t_test_index_username | t_test_index_username | 67      | const |    1 |   100.00 | Using index |\n+----+-------------+--------+------------+------+-----------------------+-----------------------+---------+-------+------+----------+-------------+\n1 row in set, 1 warning (0.00 sec)\n```\n\n说明：\n\nid：SELECT识别符。这是SELECT的查询序列号。\n\nselect_type：SELECT类型。\n\n    SIMPLE： 简单SELECT(不使用UNION或子查询)\n    PRIMARY： 最外面的SELECT\n    UNION：UNION中的第二个或后面的SELECT语句\n    DEPENDENT UNION：UNION中的第二个或后面的SELECT语句，取决于外面的查询\n    UNION RESULT：UNION的结果\n    SUBQUERY：子查询中的第一个SELECT\n    DEPENDENT SUBQUERY：子查询中的第一个SELECT，取决于外面的查询\n    DERIVED：导出表的SELECT(FROM子句的子查询)\n\ntable：表名\n\ntype：联接类型。是SQL性能的非常重要的一个指标，结果值从好到坏依次是：system > const > eq_ref > ref > fulltext > ref_or_null > index_merge > unique_subquery > index_subquery > range > index > ALL。\n一般来说，得保证查询至少达到range级别。\n\n    system：表仅有一行(=系统表)。这是const联接类型的一个特例。\n    const：表最多有一个匹配行，它将在查询开始时被读取。因为仅有一行，在这行的列值可被优化器剩余部分认为是常数。const用于用常数值比较PRIMARY KEY或UNIQUE索引的所有部分时。\n    eq_ref：对于每个来自于前面的表的行组合，从该表中读取一行。这可能是最好的联接类型，除了const类型。它用在一个索引的所有部分被联接使用并且索引是UNIQUE或PRIMARY KEY。eq_ref可以用于使用= 操作符比较的带索引的列。比较值可以为常量或一个使用在该表前面所读取的表的列的表达式。\n    ref：对于每个来自于前面的表的行组合，所有有匹配索引值的行将从这张表中读取。如果联接只使用键的最左边的前缀，或如果键不是UNIQUE或PRIMARY KEY(换句话说，如果联接不能基于关键字选择单个行的话)，则使用ref。如果使用的键仅仅匹配少量行，该联接类型是不错的。ref可以用于使用=或<=>操作符的带索引的列。\n    ref_or_null：该联接类型如同ref，但是添加了MySQL可以专门搜索包含NULL值的行。在解决子查询中经常使用该联接类型的优化。\n    index_merge：该联接类型表示使用了索引合并优化方法。在这种情况下，key列包含了使用的索引的清单，key_len包含了使用的索引的最长的关键元素。\n    unique_subquery：该类型替换了下面形式的IN子查询的ref：value IN (SELECT primary_key FROMsingle_table WHERE some_expr);unique_subquery是一个索引查找函数，可以完全替换子查询，效率更高。\n    index_subquery：该联接类型类似于unique_subquery。可以替换IN子查询，但只适合下列形式的子查询中的非唯一索引：value IN (SELECT key_column FROM single_table WHERE some_expr)\n    range：只检索给定范围的行，使用一个索引来选择行。key列显示使用了哪个索引。key_len包含所使用索引的最长关键元素。在该类型中ref列为NULL。当使用=、<>、>、>=、<、<=、IS NULL、<=>、BETWEEN或者IN操作符，用常量比较关键字列时，可以使用range\n    index：该联接类型与ALL相同，除了只有索引树被扫描。这通常比ALL快，因为索引文件通常比数据文件小。\n    all：对于每个来自于先前的表的行组合，进行完整的表扫描。如果表是第一个没标记const的表，这通常不好，并且通常在它情况下很差。通常可以增加更多的索引而不要使用ALL，使得行能基于前面的表中的常数值或列值被检索出。\n\npossible_keys：possible_keys列指出MySQL能使用哪个索引在该表中找到行。注意，该列完全独立于EXPLAIN输出所示的表的次序。这意味着在possible_keys中的某些键实际上不能按生成的表次序使用。\n\nkey：key列显示MySQL实际决定使用的键(索引)。如果没有选择索引，键是NULL。要想强制MySQL使用或忽视possible_keys列中的索引，在查询中使用FORCE INDEX、USE INDEX或者IGNORE INDEX。\n\nkey_len：key_len列显示MySQL决定使用的键长度。如果键是NULL，则长度为NULL。注意通过key_len值我们可以确定MySQL将实际使用一个多部关键字的几个部分。\n\nref：ref列显示使用哪个列或常数与key一起从表中选择行。\n\nrows：rows列显示MySQL认为它执行查询时必须检查的行数。\n\nExtra：该列包含MySQL解决查询的详细信息。\n\n    Distinct：MySQL发现第1个匹配行后，停止为当前的行组合搜索更多的行。\n    Not exists：MySQL能够对查询进行LEFT JOIN优化，发现1个匹配LEFT JOIN标准的行后，不再为前面的的行组合在该表内检查更多的行。\n    range checked for each record (index map: #)：MySQL没有发现好的可以使用的索引，但发现如果来自前面的表的列值已知，可能部分索引可以使用。对前面的表的每个行组合，MySQL检查是否可以使用range或index_merge访问方法来索取行。\n    Using filesort：MySQL需要额外的一次传递，以找出如何按排序顺序检索行。通过根据联接类型浏览所有行并为所有匹配WHERE子句的行保存排序关键字和行的指针来完成排序。然后关键字被排序，并按排序顺序检索行。\n    Using index：从只使用索引树中的信息而不需要进一步搜索读取实际的行来检索表中的列信息。当查询只使用作为单一索引一部分的列时，可以使用该策略。\n    Using temporary：为了解决查询，MySQL需要创建一个临时表来容纳结果。典型情况如查询包含可以按不同情况列出列的GROUP BY和ORDER BY子句时。\n    Using where：WHERE子句用于限制哪一个行匹配下一个表或发送到客户。除非你专门从表中索取或检查所有行，如果Extra值不为Using where并且表联接类型为ALL或index，查询可能会有一些错误。\n    Using sort_union(...), Using union(...), Using intersect(...)：这些函数说明如何为index_merge联接类型合并索引扫描。\n    Using index for group-by：类似于访问表的Using index方式，Using index for group-by表示MySQL发现了一个索引，可以用来查询GROUP BY或DISTINCT查询的所有列，而不要额外搜索硬盘访问实际的表。并且，按最有效的方式使用索引，以便对于每个组，只读取少量索引条目。\n\n6. 模糊查询时，%如果在前面，那么不会使用索引。涉及到多个索引字段时,如果这些索引字段中，不存在主键索引的话，那么就会使用该使用的索引。多个索引时，先使用哪个索引后使用哪个索引，是由MySQL的优化器经过一些列计算后作出的抉择。当对索引字段进行 >， <，>=， <=，not in，between …… and ……，函数(索引字段)，like模糊查询%在字段前时，不会使用该索引.在实际使用时，如果涉及到多列，我们一般都不会将这些列一 一创建为单列索引，而是将这些列创建为组合索引。\n\n\n7. 组合索引的使用\n    最左原则\n    假设组合索引为：a,b,c的话;那么当SQL中对应有：a或a，b或a，b，c的时候，可称为完全满足最左原则；当SQL中对应只有a，c的时候，可称为部分满足最左原则；当SQL中没有a的时候，可称为不满足最左原则。\n    注：SQL语句中的对应条件的先后顺序与创建组合索引中列的顺序无关。如果完全满足最左原则，所有的列都会走索引，部分满足最左原则，那么最左的列会走索引，剩下的不会走索引。不满足最左原则的话就不会走索引。\n\n8. 索引无法存储null值\n        \n    a. 单列索引无法储null值，复合索引无法储全为null的值。\n    b. 查询时，采用is null条件时，不能利用到索引，只能全表扫描。\n    为什么索引列无法存储Null值？\n    a.索引是有序的。NULL值进入索引时，无法确定其应该放在哪里。（将索引列值进行建树，其中必然涉及到诸多的比较操作，null值是不确定值，无法比较，无法确定null出现在索引树的叶子节点位置。）　\n    b.如果需要把空值存入索引，方法有二：其一，把NULL值转为一个特定的值，在WHERE中检索时，用该特定值查找。其二，建立一个复合索引。例如`create index ind_a on table(col1,1);`通过在复合索引中指定一个非空常量值，而使构成索引的列的组合中，不可能出现全空值。　\n    \n9. 不适合键值较少的列（重复数据较多的列）\n    假如索引列TYPE有5个键值，如果有1万条数据，那么`WHERE TYPE = 1`将访问表中的2000个数据块。再加上访问索引块，一共要访问大于200个的数据块。如果全表扫描，假设10条数据一个数据块，那么只需访问1000个数据块，既然全表扫描访问的数据块少一些，肯定就不会利用索引了。\n    \n    3.前导模糊查询不能利用索引(like '%XX'或者like '%XX%')\n    假如有这样一列code的值为'AAA','AAB','BAA','BAB' ,如果`where code like '%AB'`条件，由于前面是模糊的，所以不能利用索引的顺序，必须一个个去找，看是否满足条件。这样会导致全索引扫描或者全表扫描。如果是这样的条件`where code like 'A%'`，就可以查找CODE中A开头的CODE的位置，当碰到B开头的数据时，就可以停止查找了，因为后面的数据一定不满足要求。这样就可以利用索引了。\n\n10. 索引失效的几种情况\n    1.如果条件中有or，即使其中有条件带索引也不会使用(这也是为什么尽量少用or的原因)要想使用or，又想让索引生效，只能将or条件中的每个列都加上索引\n    2.对于多列索引，不是使用的第一部分，则不会使用索引\n    3.like查询以%开头\n    4.如果列类型是字符串，那一定要在条件中将数据使用引号引用起来,否则不使用索引\n    5.如果mysql估计使用全表扫描要比使用索引快,则不使用索引\n\n11. MySQL主要提供2种方式的索引：B-Tree索引，Hash索引\n    B树索引具有范围查找和前缀查找的能力，对于有N节点的B树，检索一条记录的复杂度为O(LogN)。相当于二分查找。哈希索引只能做等于查找，但是无论多大的Hash表，查找复杂度都是O(1)。\n    显然，如果值的差异性大，并且以等值查找（=、 <、>、in）为主，Hash索引是更高效的选择，它有O(1)的查找复杂度。\n    如果值的差异性相对较差，并且以范围查找为主，B树是更好的选择，它支持范围查找。\n\n","source":"_posts/2019-09-11-kongzheng1993-MySQL基础.md","raw":"---\ntitle: MySQL基础\nexcerpt: 'mysql'\ntags: [mysql]\ncategories: [mysql]\ncomments: true\ndate: 2019-09-11 18:30:52\n---\n\n## MySQL\n\n之前一只觉得数据库没什么，会用就行了，最近面试总是碰壁，很多又是数据库的问题打不上来，不够深入是我的大问题。所以准备总结一下。\n\n\n### 索引\n索引是数据库查询操作中提升速度的一种手段，索引是一种数据结构。\n索引是一个排序的列表，这个列表中存储着索引的值和包含这个值的数据所在的物理地址，数据量庞大的时候，索引可以快速定位需要查找的数据对应的物理地址，不需要扫描全表的数据。\n\n1. 建标时创建索引\n```sql\nCREATE TABLE t_table(\n    ID INT NOT NULL,\n    USER_NAME VARCHAR(16) NOT NULL,\n    INDEX USER_NAME_INDEX (USER_NAME), #单列索引\n    INDEX (ID,USER_NAME) #组合索引\n) ENGINE = INNODB DEFAULT CHARSET = utf8 COMMENT '注释';\n```\n\n2. 建表后创建索引\n```sql\nALTER TABLE t_TABLE ADD UNIQUE INDEX (ID);\nALTER TABLE T_TABLE ADD INDEX (ID,USER_NAME);\nALTER TABLE T_TABLE ADD PRIMARY KEY (ID);\n```\n\n3. 查看已经创建的索引\n```sql\nshow index from t_table;\n```\n\n4. 删除索引\n```sql\ndrop index user_name_index on t_table;\nalter table t_table drop index user_name_index;\n```\n\n5. 查看索引使用情况（执行计划）\n```sql\nexplain select * from t_table where user_name = 'Tom';\n```\n\n```\nmysql> explain select * from t_test where username = 'Tom';\n+----+-------------+--------+------------+------+-----------------------+-----------------------+---------+-------+------+----------+-------------+\n| id | select_type | table  | partitions | type | possible_keys         | key                   | key_len | ref   | rows | filtered | Extra       |\n+----+-------------+--------+------------+------+-----------------------+-----------------------+---------+-------+------+----------+-------------+\n|  1 | SIMPLE      | t_test | NULL       | ref  | t_test_index_username | t_test_index_username | 67      | const |    1 |   100.00 | Using index |\n+----+-------------+--------+------------+------+-----------------------+-----------------------+---------+-------+------+----------+-------------+\n1 row in set, 1 warning (0.00 sec)\n```\n\n说明：\n\nid：SELECT识别符。这是SELECT的查询序列号。\n\nselect_type：SELECT类型。\n\n    SIMPLE： 简单SELECT(不使用UNION或子查询)\n    PRIMARY： 最外面的SELECT\n    UNION：UNION中的第二个或后面的SELECT语句\n    DEPENDENT UNION：UNION中的第二个或后面的SELECT语句，取决于外面的查询\n    UNION RESULT：UNION的结果\n    SUBQUERY：子查询中的第一个SELECT\n    DEPENDENT SUBQUERY：子查询中的第一个SELECT，取决于外面的查询\n    DERIVED：导出表的SELECT(FROM子句的子查询)\n\ntable：表名\n\ntype：联接类型。是SQL性能的非常重要的一个指标，结果值从好到坏依次是：system > const > eq_ref > ref > fulltext > ref_or_null > index_merge > unique_subquery > index_subquery > range > index > ALL。\n一般来说，得保证查询至少达到range级别。\n\n    system：表仅有一行(=系统表)。这是const联接类型的一个特例。\n    const：表最多有一个匹配行，它将在查询开始时被读取。因为仅有一行，在这行的列值可被优化器剩余部分认为是常数。const用于用常数值比较PRIMARY KEY或UNIQUE索引的所有部分时。\n    eq_ref：对于每个来自于前面的表的行组合，从该表中读取一行。这可能是最好的联接类型，除了const类型。它用在一个索引的所有部分被联接使用并且索引是UNIQUE或PRIMARY KEY。eq_ref可以用于使用= 操作符比较的带索引的列。比较值可以为常量或一个使用在该表前面所读取的表的列的表达式。\n    ref：对于每个来自于前面的表的行组合，所有有匹配索引值的行将从这张表中读取。如果联接只使用键的最左边的前缀，或如果键不是UNIQUE或PRIMARY KEY(换句话说，如果联接不能基于关键字选择单个行的话)，则使用ref。如果使用的键仅仅匹配少量行，该联接类型是不错的。ref可以用于使用=或<=>操作符的带索引的列。\n    ref_or_null：该联接类型如同ref，但是添加了MySQL可以专门搜索包含NULL值的行。在解决子查询中经常使用该联接类型的优化。\n    index_merge：该联接类型表示使用了索引合并优化方法。在这种情况下，key列包含了使用的索引的清单，key_len包含了使用的索引的最长的关键元素。\n    unique_subquery：该类型替换了下面形式的IN子查询的ref：value IN (SELECT primary_key FROMsingle_table WHERE some_expr);unique_subquery是一个索引查找函数，可以完全替换子查询，效率更高。\n    index_subquery：该联接类型类似于unique_subquery。可以替换IN子查询，但只适合下列形式的子查询中的非唯一索引：value IN (SELECT key_column FROM single_table WHERE some_expr)\n    range：只检索给定范围的行，使用一个索引来选择行。key列显示使用了哪个索引。key_len包含所使用索引的最长关键元素。在该类型中ref列为NULL。当使用=、<>、>、>=、<、<=、IS NULL、<=>、BETWEEN或者IN操作符，用常量比较关键字列时，可以使用range\n    index：该联接类型与ALL相同，除了只有索引树被扫描。这通常比ALL快，因为索引文件通常比数据文件小。\n    all：对于每个来自于先前的表的行组合，进行完整的表扫描。如果表是第一个没标记const的表，这通常不好，并且通常在它情况下很差。通常可以增加更多的索引而不要使用ALL，使得行能基于前面的表中的常数值或列值被检索出。\n\npossible_keys：possible_keys列指出MySQL能使用哪个索引在该表中找到行。注意，该列完全独立于EXPLAIN输出所示的表的次序。这意味着在possible_keys中的某些键实际上不能按生成的表次序使用。\n\nkey：key列显示MySQL实际决定使用的键(索引)。如果没有选择索引，键是NULL。要想强制MySQL使用或忽视possible_keys列中的索引，在查询中使用FORCE INDEX、USE INDEX或者IGNORE INDEX。\n\nkey_len：key_len列显示MySQL决定使用的键长度。如果键是NULL，则长度为NULL。注意通过key_len值我们可以确定MySQL将实际使用一个多部关键字的几个部分。\n\nref：ref列显示使用哪个列或常数与key一起从表中选择行。\n\nrows：rows列显示MySQL认为它执行查询时必须检查的行数。\n\nExtra：该列包含MySQL解决查询的详细信息。\n\n    Distinct：MySQL发现第1个匹配行后，停止为当前的行组合搜索更多的行。\n    Not exists：MySQL能够对查询进行LEFT JOIN优化，发现1个匹配LEFT JOIN标准的行后，不再为前面的的行组合在该表内检查更多的行。\n    range checked for each record (index map: #)：MySQL没有发现好的可以使用的索引，但发现如果来自前面的表的列值已知，可能部分索引可以使用。对前面的表的每个行组合，MySQL检查是否可以使用range或index_merge访问方法来索取行。\n    Using filesort：MySQL需要额外的一次传递，以找出如何按排序顺序检索行。通过根据联接类型浏览所有行并为所有匹配WHERE子句的行保存排序关键字和行的指针来完成排序。然后关键字被排序，并按排序顺序检索行。\n    Using index：从只使用索引树中的信息而不需要进一步搜索读取实际的行来检索表中的列信息。当查询只使用作为单一索引一部分的列时，可以使用该策略。\n    Using temporary：为了解决查询，MySQL需要创建一个临时表来容纳结果。典型情况如查询包含可以按不同情况列出列的GROUP BY和ORDER BY子句时。\n    Using where：WHERE子句用于限制哪一个行匹配下一个表或发送到客户。除非你专门从表中索取或检查所有行，如果Extra值不为Using where并且表联接类型为ALL或index，查询可能会有一些错误。\n    Using sort_union(...), Using union(...), Using intersect(...)：这些函数说明如何为index_merge联接类型合并索引扫描。\n    Using index for group-by：类似于访问表的Using index方式，Using index for group-by表示MySQL发现了一个索引，可以用来查询GROUP BY或DISTINCT查询的所有列，而不要额外搜索硬盘访问实际的表。并且，按最有效的方式使用索引，以便对于每个组，只读取少量索引条目。\n\n6. 模糊查询时，%如果在前面，那么不会使用索引。涉及到多个索引字段时,如果这些索引字段中，不存在主键索引的话，那么就会使用该使用的索引。多个索引时，先使用哪个索引后使用哪个索引，是由MySQL的优化器经过一些列计算后作出的抉择。当对索引字段进行 >， <，>=， <=，not in，between …… and ……，函数(索引字段)，like模糊查询%在字段前时，不会使用该索引.在实际使用时，如果涉及到多列，我们一般都不会将这些列一 一创建为单列索引，而是将这些列创建为组合索引。\n\n\n7. 组合索引的使用\n    最左原则\n    假设组合索引为：a,b,c的话;那么当SQL中对应有：a或a，b或a，b，c的时候，可称为完全满足最左原则；当SQL中对应只有a，c的时候，可称为部分满足最左原则；当SQL中没有a的时候，可称为不满足最左原则。\n    注：SQL语句中的对应条件的先后顺序与创建组合索引中列的顺序无关。如果完全满足最左原则，所有的列都会走索引，部分满足最左原则，那么最左的列会走索引，剩下的不会走索引。不满足最左原则的话就不会走索引。\n\n8. 索引无法存储null值\n        \n    a. 单列索引无法储null值，复合索引无法储全为null的值。\n    b. 查询时，采用is null条件时，不能利用到索引，只能全表扫描。\n    为什么索引列无法存储Null值？\n    a.索引是有序的。NULL值进入索引时，无法确定其应该放在哪里。（将索引列值进行建树，其中必然涉及到诸多的比较操作，null值是不确定值，无法比较，无法确定null出现在索引树的叶子节点位置。）　\n    b.如果需要把空值存入索引，方法有二：其一，把NULL值转为一个特定的值，在WHERE中检索时，用该特定值查找。其二，建立一个复合索引。例如`create index ind_a on table(col1,1);`通过在复合索引中指定一个非空常量值，而使构成索引的列的组合中，不可能出现全空值。　\n    \n9. 不适合键值较少的列（重复数据较多的列）\n    假如索引列TYPE有5个键值，如果有1万条数据，那么`WHERE TYPE = 1`将访问表中的2000个数据块。再加上访问索引块，一共要访问大于200个的数据块。如果全表扫描，假设10条数据一个数据块，那么只需访问1000个数据块，既然全表扫描访问的数据块少一些，肯定就不会利用索引了。\n    \n    3.前导模糊查询不能利用索引(like '%XX'或者like '%XX%')\n    假如有这样一列code的值为'AAA','AAB','BAA','BAB' ,如果`where code like '%AB'`条件，由于前面是模糊的，所以不能利用索引的顺序，必须一个个去找，看是否满足条件。这样会导致全索引扫描或者全表扫描。如果是这样的条件`where code like 'A%'`，就可以查找CODE中A开头的CODE的位置，当碰到B开头的数据时，就可以停止查找了，因为后面的数据一定不满足要求。这样就可以利用索引了。\n\n10. 索引失效的几种情况\n    1.如果条件中有or，即使其中有条件带索引也不会使用(这也是为什么尽量少用or的原因)要想使用or，又想让索引生效，只能将or条件中的每个列都加上索引\n    2.对于多列索引，不是使用的第一部分，则不会使用索引\n    3.like查询以%开头\n    4.如果列类型是字符串，那一定要在条件中将数据使用引号引用起来,否则不使用索引\n    5.如果mysql估计使用全表扫描要比使用索引快,则不使用索引\n\n11. MySQL主要提供2种方式的索引：B-Tree索引，Hash索引\n    B树索引具有范围查找和前缀查找的能力，对于有N节点的B树，检索一条记录的复杂度为O(LogN)。相当于二分查找。哈希索引只能做等于查找，但是无论多大的Hash表，查找复杂度都是O(1)。\n    显然，如果值的差异性大，并且以等值查找（=、 <、>、in）为主，Hash索引是更高效的选择，它有O(1)的查找复杂度。\n    如果值的差异性相对较差，并且以范围查找为主，B树是更好的选择，它支持范围查找。\n\n","slug":"kongzheng1993-MySQL基础","published":1,"updated":"2023-03-08T07:05:58.776Z","layout":"post","photos":[],"link":"","_id":"clg0k2aou00hkt26fbyn9gewu","content":"<h2 id=\"MySQL\"><a href=\"#MySQL\" class=\"headerlink\" title=\"MySQL\"></a>MySQL</h2><p>之前一只觉得数据库没什么，会用就行了，最近面试总是碰壁，很多又是数据库的问题打不上来，不够深入是我的大问题。所以准备总结一下。</p>\n<h3 id=\"索引\"><a href=\"#索引\" class=\"headerlink\" title=\"索引\"></a>索引</h3><p>索引是数据库查询操作中提升速度的一种手段，索引是一种数据结构。<br>索引是一个排序的列表，这个列表中存储着索引的值和包含这个值的数据所在的物理地址，数据量庞大的时候，索引可以快速定位需要查找的数据对应的物理地址，不需要扫描全表的数据。</p>\n<ol>\n<li><p>建标时创建索引</p>\n<pre><code class=\"sql\">CREATE TABLE t_table(\n ID INT NOT NULL,\n USER_NAME VARCHAR(16) NOT NULL,\n INDEX USER_NAME_INDEX (USER_NAME), #单列索引\n INDEX (ID,USER_NAME) #组合索引\n) ENGINE = INNODB DEFAULT CHARSET = utf8 COMMENT &#39;注释&#39;;</code></pre>\n</li>\n<li><p>建表后创建索引</p>\n<pre><code class=\"sql\">ALTER TABLE t_TABLE ADD UNIQUE INDEX (ID);\nALTER TABLE T_TABLE ADD INDEX (ID,USER_NAME);\nALTER TABLE T_TABLE ADD PRIMARY KEY (ID);</code></pre>\n</li>\n<li><p>查看已经创建的索引</p>\n<pre><code class=\"sql\">show index from t_table;</code></pre>\n</li>\n<li><p>删除索引</p>\n<pre><code class=\"sql\">drop index user_name_index on t_table;\nalter table t_table drop index user_name_index;</code></pre>\n</li>\n<li><p>查看索引使用情况（执行计划）</p>\n<pre><code class=\"sql\">explain select * from t_table where user_name = &#39;Tom&#39;;</code></pre>\n</li>\n</ol>\n<pre><code>mysql&gt; explain select * from t_test where username = &#39;Tom&#39;;\n+----+-------------+--------+------------+------+-----------------------+-----------------------+---------+-------+------+----------+-------------+\n| id | select_type | table  | partitions | type | possible_keys         | key                   | key_len | ref   | rows | filtered | Extra       |\n+----+-------------+--------+------------+------+-----------------------+-----------------------+---------+-------+------+----------+-------------+\n|  1 | SIMPLE      | t_test | NULL       | ref  | t_test_index_username | t_test_index_username | 67      | const |    1 |   100.00 | Using index |\n+----+-------------+--------+------------+------+-----------------------+-----------------------+---------+-------+------+----------+-------------+\n1 row in set, 1 warning (0.00 sec)</code></pre><p>说明：</p>\n<p>id：SELECT识别符。这是SELECT的查询序列号。</p>\n<p>select_type：SELECT类型。</p>\n<pre><code>SIMPLE： 简单SELECT(不使用UNION或子查询)\nPRIMARY： 最外面的SELECT\nUNION：UNION中的第二个或后面的SELECT语句\nDEPENDENT UNION：UNION中的第二个或后面的SELECT语句，取决于外面的查询\nUNION RESULT：UNION的结果\nSUBQUERY：子查询中的第一个SELECT\nDEPENDENT SUBQUERY：子查询中的第一个SELECT，取决于外面的查询\nDERIVED：导出表的SELECT(FROM子句的子查询)</code></pre><p>table：表名</p>\n<p>type：联接类型。是SQL性能的非常重要的一个指标，结果值从好到坏依次是：system &gt; const &gt; eq_ref &gt; ref &gt; fulltext &gt; ref_or_null &gt; index_merge &gt; unique_subquery &gt; index_subquery &gt; range &gt; index &gt; ALL。<br>一般来说，得保证查询至少达到range级别。</p>\n<pre><code>system：表仅有一行(=系统表)。这是const联接类型的一个特例。\nconst：表最多有一个匹配行，它将在查询开始时被读取。因为仅有一行，在这行的列值可被优化器剩余部分认为是常数。const用于用常数值比较PRIMARY KEY或UNIQUE索引的所有部分时。\neq_ref：对于每个来自于前面的表的行组合，从该表中读取一行。这可能是最好的联接类型，除了const类型。它用在一个索引的所有部分被联接使用并且索引是UNIQUE或PRIMARY KEY。eq_ref可以用于使用= 操作符比较的带索引的列。比较值可以为常量或一个使用在该表前面所读取的表的列的表达式。\nref：对于每个来自于前面的表的行组合，所有有匹配索引值的行将从这张表中读取。如果联接只使用键的最左边的前缀，或如果键不是UNIQUE或PRIMARY KEY(换句话说，如果联接不能基于关键字选择单个行的话)，则使用ref。如果使用的键仅仅匹配少量行，该联接类型是不错的。ref可以用于使用=或&lt;=&gt;操作符的带索引的列。\nref_or_null：该联接类型如同ref，但是添加了MySQL可以专门搜索包含NULL值的行。在解决子查询中经常使用该联接类型的优化。\nindex_merge：该联接类型表示使用了索引合并优化方法。在这种情况下，key列包含了使用的索引的清单，key_len包含了使用的索引的最长的关键元素。\nunique_subquery：该类型替换了下面形式的IN子查询的ref：value IN (SELECT primary_key FROMsingle_table WHERE some_expr);unique_subquery是一个索引查找函数，可以完全替换子查询，效率更高。\nindex_subquery：该联接类型类似于unique_subquery。可以替换IN子查询，但只适合下列形式的子查询中的非唯一索引：value IN (SELECT key_column FROM single_table WHERE some_expr)\nrange：只检索给定范围的行，使用一个索引来选择行。key列显示使用了哪个索引。key_len包含所使用索引的最长关键元素。在该类型中ref列为NULL。当使用=、&lt;&gt;、&gt;、&gt;=、&lt;、&lt;=、IS NULL、&lt;=&gt;、BETWEEN或者IN操作符，用常量比较关键字列时，可以使用range\nindex：该联接类型与ALL相同，除了只有索引树被扫描。这通常比ALL快，因为索引文件通常比数据文件小。\nall：对于每个来自于先前的表的行组合，进行完整的表扫描。如果表是第一个没标记const的表，这通常不好，并且通常在它情况下很差。通常可以增加更多的索引而不要使用ALL，使得行能基于前面的表中的常数值或列值被检索出。</code></pre><p>possible_keys：possible_keys列指出MySQL能使用哪个索引在该表中找到行。注意，该列完全独立于EXPLAIN输出所示的表的次序。这意味着在possible_keys中的某些键实际上不能按生成的表次序使用。</p>\n<p>key：key列显示MySQL实际决定使用的键(索引)。如果没有选择索引，键是NULL。要想强制MySQL使用或忽视possible_keys列中的索引，在查询中使用FORCE INDEX、USE INDEX或者IGNORE INDEX。</p>\n<p>key_len：key_len列显示MySQL决定使用的键长度。如果键是NULL，则长度为NULL。注意通过key_len值我们可以确定MySQL将实际使用一个多部关键字的几个部分。</p>\n<p>ref：ref列显示使用哪个列或常数与key一起从表中选择行。</p>\n<p>rows：rows列显示MySQL认为它执行查询时必须检查的行数。</p>\n<p>Extra：该列包含MySQL解决查询的详细信息。</p>\n<pre><code>Distinct：MySQL发现第1个匹配行后，停止为当前的行组合搜索更多的行。\nNot exists：MySQL能够对查询进行LEFT JOIN优化，发现1个匹配LEFT JOIN标准的行后，不再为前面的的行组合在该表内检查更多的行。\nrange checked for each record (index map: #)：MySQL没有发现好的可以使用的索引，但发现如果来自前面的表的列值已知，可能部分索引可以使用。对前面的表的每个行组合，MySQL检查是否可以使用range或index_merge访问方法来索取行。\nUsing filesort：MySQL需要额外的一次传递，以找出如何按排序顺序检索行。通过根据联接类型浏览所有行并为所有匹配WHERE子句的行保存排序关键字和行的指针来完成排序。然后关键字被排序，并按排序顺序检索行。\nUsing index：从只使用索引树中的信息而不需要进一步搜索读取实际的行来检索表中的列信息。当查询只使用作为单一索引一部分的列时，可以使用该策略。\nUsing temporary：为了解决查询，MySQL需要创建一个临时表来容纳结果。典型情况如查询包含可以按不同情况列出列的GROUP BY和ORDER BY子句时。\nUsing where：WHERE子句用于限制哪一个行匹配下一个表或发送到客户。除非你专门从表中索取或检查所有行，如果Extra值不为Using where并且表联接类型为ALL或index，查询可能会有一些错误。\nUsing sort_union(...), Using union(...), Using intersect(...)：这些函数说明如何为index_merge联接类型合并索引扫描。\nUsing index for group-by：类似于访问表的Using index方式，Using index for group-by表示MySQL发现了一个索引，可以用来查询GROUP BY或DISTINCT查询的所有列，而不要额外搜索硬盘访问实际的表。并且，按最有效的方式使用索引，以便对于每个组，只读取少量索引条目。</code></pre><ol start=\"6\">\n<li>模糊查询时，%如果在前面，那么不会使用索引。涉及到多个索引字段时,如果这些索引字段中，不存在主键索引的话，那么就会使用该使用的索引。多个索引时，先使用哪个索引后使用哪个索引，是由MySQL的优化器经过一些列计算后作出的抉择。当对索引字段进行 &gt;， &lt;，&gt;=， &lt;=，not in，between …… and ……，函数(索引字段)，like模糊查询%在字段前时，不会使用该索引.在实际使用时，如果涉及到多列，我们一般都不会将这些列一 一创建为单列索引，而是将这些列创建为组合索引。</li>\n</ol>\n<ol start=\"7\">\n<li><p>组合索引的使用<br> 最左原则<br> 假设组合索引为：a,b,c的话;那么当SQL中对应有：a或a，b或a，b，c的时候，可称为完全满足最左原则；当SQL中对应只有a，c的时候，可称为部分满足最左原则；当SQL中没有a的时候，可称为不满足最左原则。<br> 注：SQL语句中的对应条件的先后顺序与创建组合索引中列的顺序无关。如果完全满足最左原则，所有的列都会走索引，部分满足最左原则，那么最左的列会走索引，剩下的不会走索引。不满足最左原则的话就不会走索引。</p>\n</li>\n<li><p>索引无法存储null值</p>\n<p> a. 单列索引无法储null值，复合索引无法储全为null的值。<br> b. 查询时，采用is null条件时，不能利用到索引，只能全表扫描。<br> 为什么索引列无法存储Null值？<br> a.索引是有序的。NULL值进入索引时，无法确定其应该放在哪里。（将索引列值进行建树，其中必然涉及到诸多的比较操作，null值是不确定值，无法比较，无法确定null出现在索引树的叶子节点位置。）　<br> b.如果需要把空值存入索引，方法有二：其一，把NULL值转为一个特定的值，在WHERE中检索时，用该特定值查找。其二，建立一个复合索引。例如<code>create index ind_a on table(col1,1);</code>通过在复合索引中指定一个非空常量值，而使构成索引的列的组合中，不可能出现全空值。　</p>\n</li>\n<li><p>不适合键值较少的列（重复数据较多的列）<br> 假如索引列TYPE有5个键值，如果有1万条数据，那么<code>WHERE TYPE = 1</code>将访问表中的2000个数据块。再加上访问索引块，一共要访问大于200个的数据块。如果全表扫描，假设10条数据一个数据块，那么只需访问1000个数据块，既然全表扫描访问的数据块少一些，肯定就不会利用索引了。</p>\n<p> 3.前导模糊查询不能利用索引(like ‘%XX’或者like ‘%XX%’)<br> 假如有这样一列code的值为’AAA’,’AAB’,’BAA’,’BAB’ ,如果<code>where code like &#39;%AB&#39;</code>条件，由于前面是模糊的，所以不能利用索引的顺序，必须一个个去找，看是否满足条件。这样会导致全索引扫描或者全表扫描。如果是这样的条件<code>where code like &#39;A%&#39;</code>，就可以查找CODE中A开头的CODE的位置，当碰到B开头的数据时，就可以停止查找了，因为后面的数据一定不满足要求。这样就可以利用索引了。</p>\n</li>\n<li><p>索引失效的几种情况<br>1.如果条件中有or，即使其中有条件带索引也不会使用(这也是为什么尽量少用or的原因)要想使用or，又想让索引生效，只能将or条件中的每个列都加上索引<br>2.对于多列索引，不是使用的第一部分，则不会使用索引<br>3.like查询以%开头<br>4.如果列类型是字符串，那一定要在条件中将数据使用引号引用起来,否则不使用索引<br>5.如果mysql估计使用全表扫描要比使用索引快,则不使用索引</p>\n</li>\n<li><p>MySQL主要提供2种方式的索引：B-Tree索引，Hash索引<br>B树索引具有范围查找和前缀查找的能力，对于有N节点的B树，检索一条记录的复杂度为O(LogN)。相当于二分查找。哈希索引只能做等于查找，但是无论多大的Hash表，查找复杂度都是O(1)。<br>显然，如果值的差异性大，并且以等值查找（=、 &lt;、&gt;、in）为主，Hash索引是更高效的选择，它有O(1)的查找复杂度。<br>如果值的差异性相对较差，并且以范围查找为主，B树是更好的选择，它支持范围查找。</p>\n</li>\n</ol>\n","site":{"data":{}},"more":"<h2 id=\"MySQL\"><a href=\"#MySQL\" class=\"headerlink\" title=\"MySQL\"></a>MySQL</h2><p>之前一只觉得数据库没什么，会用就行了，最近面试总是碰壁，很多又是数据库的问题打不上来，不够深入是我的大问题。所以准备总结一下。</p>\n<h3 id=\"索引\"><a href=\"#索引\" class=\"headerlink\" title=\"索引\"></a>索引</h3><p>索引是数据库查询操作中提升速度的一种手段，索引是一种数据结构。<br>索引是一个排序的列表，这个列表中存储着索引的值和包含这个值的数据所在的物理地址，数据量庞大的时候，索引可以快速定位需要查找的数据对应的物理地址，不需要扫描全表的数据。</p>\n<ol>\n<li><p>建标时创建索引</p>\n<pre><code class=\"sql\">CREATE TABLE t_table(\n ID INT NOT NULL,\n USER_NAME VARCHAR(16) NOT NULL,\n INDEX USER_NAME_INDEX (USER_NAME), #单列索引\n INDEX (ID,USER_NAME) #组合索引\n) ENGINE = INNODB DEFAULT CHARSET = utf8 COMMENT &#39;注释&#39;;</code></pre>\n</li>\n<li><p>建表后创建索引</p>\n<pre><code class=\"sql\">ALTER TABLE t_TABLE ADD UNIQUE INDEX (ID);\nALTER TABLE T_TABLE ADD INDEX (ID,USER_NAME);\nALTER TABLE T_TABLE ADD PRIMARY KEY (ID);</code></pre>\n</li>\n<li><p>查看已经创建的索引</p>\n<pre><code class=\"sql\">show index from t_table;</code></pre>\n</li>\n<li><p>删除索引</p>\n<pre><code class=\"sql\">drop index user_name_index on t_table;\nalter table t_table drop index user_name_index;</code></pre>\n</li>\n<li><p>查看索引使用情况（执行计划）</p>\n<pre><code class=\"sql\">explain select * from t_table where user_name = &#39;Tom&#39;;</code></pre>\n</li>\n</ol>\n<pre><code>mysql&gt; explain select * from t_test where username = &#39;Tom&#39;;\n+----+-------------+--------+------------+------+-----------------------+-----------------------+---------+-------+------+----------+-------------+\n| id | select_type | table  | partitions | type | possible_keys         | key                   | key_len | ref   | rows | filtered | Extra       |\n+----+-------------+--------+------------+------+-----------------------+-----------------------+---------+-------+------+----------+-------------+\n|  1 | SIMPLE      | t_test | NULL       | ref  | t_test_index_username | t_test_index_username | 67      | const |    1 |   100.00 | Using index |\n+----+-------------+--------+------------+------+-----------------------+-----------------------+---------+-------+------+----------+-------------+\n1 row in set, 1 warning (0.00 sec)</code></pre><p>说明：</p>\n<p>id：SELECT识别符。这是SELECT的查询序列号。</p>\n<p>select_type：SELECT类型。</p>\n<pre><code>SIMPLE： 简单SELECT(不使用UNION或子查询)\nPRIMARY： 最外面的SELECT\nUNION：UNION中的第二个或后面的SELECT语句\nDEPENDENT UNION：UNION中的第二个或后面的SELECT语句，取决于外面的查询\nUNION RESULT：UNION的结果\nSUBQUERY：子查询中的第一个SELECT\nDEPENDENT SUBQUERY：子查询中的第一个SELECT，取决于外面的查询\nDERIVED：导出表的SELECT(FROM子句的子查询)</code></pre><p>table：表名</p>\n<p>type：联接类型。是SQL性能的非常重要的一个指标，结果值从好到坏依次是：system &gt; const &gt; eq_ref &gt; ref &gt; fulltext &gt; ref_or_null &gt; index_merge &gt; unique_subquery &gt; index_subquery &gt; range &gt; index &gt; ALL。<br>一般来说，得保证查询至少达到range级别。</p>\n<pre><code>system：表仅有一行(=系统表)。这是const联接类型的一个特例。\nconst：表最多有一个匹配行，它将在查询开始时被读取。因为仅有一行，在这行的列值可被优化器剩余部分认为是常数。const用于用常数值比较PRIMARY KEY或UNIQUE索引的所有部分时。\neq_ref：对于每个来自于前面的表的行组合，从该表中读取一行。这可能是最好的联接类型，除了const类型。它用在一个索引的所有部分被联接使用并且索引是UNIQUE或PRIMARY KEY。eq_ref可以用于使用= 操作符比较的带索引的列。比较值可以为常量或一个使用在该表前面所读取的表的列的表达式。\nref：对于每个来自于前面的表的行组合，所有有匹配索引值的行将从这张表中读取。如果联接只使用键的最左边的前缀，或如果键不是UNIQUE或PRIMARY KEY(换句话说，如果联接不能基于关键字选择单个行的话)，则使用ref。如果使用的键仅仅匹配少量行，该联接类型是不错的。ref可以用于使用=或&lt;=&gt;操作符的带索引的列。\nref_or_null：该联接类型如同ref，但是添加了MySQL可以专门搜索包含NULL值的行。在解决子查询中经常使用该联接类型的优化。\nindex_merge：该联接类型表示使用了索引合并优化方法。在这种情况下，key列包含了使用的索引的清单，key_len包含了使用的索引的最长的关键元素。\nunique_subquery：该类型替换了下面形式的IN子查询的ref：value IN (SELECT primary_key FROMsingle_table WHERE some_expr);unique_subquery是一个索引查找函数，可以完全替换子查询，效率更高。\nindex_subquery：该联接类型类似于unique_subquery。可以替换IN子查询，但只适合下列形式的子查询中的非唯一索引：value IN (SELECT key_column FROM single_table WHERE some_expr)\nrange：只检索给定范围的行，使用一个索引来选择行。key列显示使用了哪个索引。key_len包含所使用索引的最长关键元素。在该类型中ref列为NULL。当使用=、&lt;&gt;、&gt;、&gt;=、&lt;、&lt;=、IS NULL、&lt;=&gt;、BETWEEN或者IN操作符，用常量比较关键字列时，可以使用range\nindex：该联接类型与ALL相同，除了只有索引树被扫描。这通常比ALL快，因为索引文件通常比数据文件小。\nall：对于每个来自于先前的表的行组合，进行完整的表扫描。如果表是第一个没标记const的表，这通常不好，并且通常在它情况下很差。通常可以增加更多的索引而不要使用ALL，使得行能基于前面的表中的常数值或列值被检索出。</code></pre><p>possible_keys：possible_keys列指出MySQL能使用哪个索引在该表中找到行。注意，该列完全独立于EXPLAIN输出所示的表的次序。这意味着在possible_keys中的某些键实际上不能按生成的表次序使用。</p>\n<p>key：key列显示MySQL实际决定使用的键(索引)。如果没有选择索引，键是NULL。要想强制MySQL使用或忽视possible_keys列中的索引，在查询中使用FORCE INDEX、USE INDEX或者IGNORE INDEX。</p>\n<p>key_len：key_len列显示MySQL决定使用的键长度。如果键是NULL，则长度为NULL。注意通过key_len值我们可以确定MySQL将实际使用一个多部关键字的几个部分。</p>\n<p>ref：ref列显示使用哪个列或常数与key一起从表中选择行。</p>\n<p>rows：rows列显示MySQL认为它执行查询时必须检查的行数。</p>\n<p>Extra：该列包含MySQL解决查询的详细信息。</p>\n<pre><code>Distinct：MySQL发现第1个匹配行后，停止为当前的行组合搜索更多的行。\nNot exists：MySQL能够对查询进行LEFT JOIN优化，发现1个匹配LEFT JOIN标准的行后，不再为前面的的行组合在该表内检查更多的行。\nrange checked for each record (index map: #)：MySQL没有发现好的可以使用的索引，但发现如果来自前面的表的列值已知，可能部分索引可以使用。对前面的表的每个行组合，MySQL检查是否可以使用range或index_merge访问方法来索取行。\nUsing filesort：MySQL需要额外的一次传递，以找出如何按排序顺序检索行。通过根据联接类型浏览所有行并为所有匹配WHERE子句的行保存排序关键字和行的指针来完成排序。然后关键字被排序，并按排序顺序检索行。\nUsing index：从只使用索引树中的信息而不需要进一步搜索读取实际的行来检索表中的列信息。当查询只使用作为单一索引一部分的列时，可以使用该策略。\nUsing temporary：为了解决查询，MySQL需要创建一个临时表来容纳结果。典型情况如查询包含可以按不同情况列出列的GROUP BY和ORDER BY子句时。\nUsing where：WHERE子句用于限制哪一个行匹配下一个表或发送到客户。除非你专门从表中索取或检查所有行，如果Extra值不为Using where并且表联接类型为ALL或index，查询可能会有一些错误。\nUsing sort_union(...), Using union(...), Using intersect(...)：这些函数说明如何为index_merge联接类型合并索引扫描。\nUsing index for group-by：类似于访问表的Using index方式，Using index for group-by表示MySQL发现了一个索引，可以用来查询GROUP BY或DISTINCT查询的所有列，而不要额外搜索硬盘访问实际的表。并且，按最有效的方式使用索引，以便对于每个组，只读取少量索引条目。</code></pre><ol start=\"6\">\n<li>模糊查询时，%如果在前面，那么不会使用索引。涉及到多个索引字段时,如果这些索引字段中，不存在主键索引的话，那么就会使用该使用的索引。多个索引时，先使用哪个索引后使用哪个索引，是由MySQL的优化器经过一些列计算后作出的抉择。当对索引字段进行 &gt;， &lt;，&gt;=， &lt;=，not in，between …… and ……，函数(索引字段)，like模糊查询%在字段前时，不会使用该索引.在实际使用时，如果涉及到多列，我们一般都不会将这些列一 一创建为单列索引，而是将这些列创建为组合索引。</li>\n</ol>\n<ol start=\"7\">\n<li><p>组合索引的使用<br> 最左原则<br> 假设组合索引为：a,b,c的话;那么当SQL中对应有：a或a，b或a，b，c的时候，可称为完全满足最左原则；当SQL中对应只有a，c的时候，可称为部分满足最左原则；当SQL中没有a的时候，可称为不满足最左原则。<br> 注：SQL语句中的对应条件的先后顺序与创建组合索引中列的顺序无关。如果完全满足最左原则，所有的列都会走索引，部分满足最左原则，那么最左的列会走索引，剩下的不会走索引。不满足最左原则的话就不会走索引。</p>\n</li>\n<li><p>索引无法存储null值</p>\n<p> a. 单列索引无法储null值，复合索引无法储全为null的值。<br> b. 查询时，采用is null条件时，不能利用到索引，只能全表扫描。<br> 为什么索引列无法存储Null值？<br> a.索引是有序的。NULL值进入索引时，无法确定其应该放在哪里。（将索引列值进行建树，其中必然涉及到诸多的比较操作，null值是不确定值，无法比较，无法确定null出现在索引树的叶子节点位置。）　<br> b.如果需要把空值存入索引，方法有二：其一，把NULL值转为一个特定的值，在WHERE中检索时，用该特定值查找。其二，建立一个复合索引。例如<code>create index ind_a on table(col1,1);</code>通过在复合索引中指定一个非空常量值，而使构成索引的列的组合中，不可能出现全空值。　</p>\n</li>\n<li><p>不适合键值较少的列（重复数据较多的列）<br> 假如索引列TYPE有5个键值，如果有1万条数据，那么<code>WHERE TYPE = 1</code>将访问表中的2000个数据块。再加上访问索引块，一共要访问大于200个的数据块。如果全表扫描，假设10条数据一个数据块，那么只需访问1000个数据块，既然全表扫描访问的数据块少一些，肯定就不会利用索引了。</p>\n<p> 3.前导模糊查询不能利用索引(like ‘%XX’或者like ‘%XX%’)<br> 假如有这样一列code的值为’AAA’,’AAB’,’BAA’,’BAB’ ,如果<code>where code like &#39;%AB&#39;</code>条件，由于前面是模糊的，所以不能利用索引的顺序，必须一个个去找，看是否满足条件。这样会导致全索引扫描或者全表扫描。如果是这样的条件<code>where code like &#39;A%&#39;</code>，就可以查找CODE中A开头的CODE的位置，当碰到B开头的数据时，就可以停止查找了，因为后面的数据一定不满足要求。这样就可以利用索引了。</p>\n</li>\n<li><p>索引失效的几种情况<br>1.如果条件中有or，即使其中有条件带索引也不会使用(这也是为什么尽量少用or的原因)要想使用or，又想让索引生效，只能将or条件中的每个列都加上索引<br>2.对于多列索引，不是使用的第一部分，则不会使用索引<br>3.like查询以%开头<br>4.如果列类型是字符串，那一定要在条件中将数据使用引号引用起来,否则不使用索引<br>5.如果mysql估计使用全表扫描要比使用索引快,则不使用索引</p>\n</li>\n<li><p>MySQL主要提供2种方式的索引：B-Tree索引，Hash索引<br>B树索引具有范围查找和前缀查找的能力，对于有N节点的B树，检索一条记录的复杂度为O(LogN)。相当于二分查找。哈希索引只能做等于查找，但是无论多大的Hash表，查找复杂度都是O(1)。<br>显然，如果值的差异性大，并且以等值查找（=、 &lt;、&gt;、in）为主，Hash索引是更高效的选择，它有O(1)的查找复杂度。<br>如果值的差异性相对较差，并且以范围查找为主，B树是更好的选择，它支持范围查找。</p>\n</li>\n</ol>\n"},{"title":"URLEncoder","excerpt":"","comments":1,"date":"2020-03-07T16:30:52.000Z","_content":"\n# URLEncoder\n\n今天写代码要发起一个HTTP GET请求，WebService接口我们随处可见，作为一个“业务程序员”我们也每天都在写。。。所以指尖跳动，分分钟就出现了下面的代码：\n\n```java\n try {\n            encode = URLEncoder.encode(JsonUtil.convertObject2Json(reqParamsMap), \"UTF-8\").replace(\"\\\\+\", \"%20\");\n        } catch (UnsupportedEncodingException e) {\n            logger.error(\"URLEncoder.encodec出错： \", e);\n        }\n```\n\n撸完码我回头看了一眼，我习以为常的URL编码，到底是为什么呢？我想大概是怕传输数据中的特殊字符造成什么不可预知的问题吧。\n\n工作完成，测试没有问题。我今天打算打破砂锅问到底，让我们一探究竟，到底为什么要编码？\n\n<font color=red>知道了How，我们还要知道Why！！！</font>\n\n## 找资料\n\n打开bing，国际搜索（梯子断了很久了……）在`stackoverflow`上看到也有很多人提出了这个问题，很多的人回答都指向了一个RFC\n\n\tRFC(Request For Comments)-意即“请求评议”，包含了关于Internet的几乎所有重要的文字资料。\n\t通常，当某家机构或团体开发出了一套标准或提出对某种标准的设想，\n\t想要征询外界的意见时，就会在Internet上发放一份RFC，\n\t对这一问题感兴趣的人可以阅读该RFC并提出自己的意见；\n\t\n\t绝大部分网络标准的指定都是以RFC的形式开始，经过大量的论证和修改过程，\n\t由主要的标准化组织所指定的，但在RFC中所收录的文件并不都是正在使用或为大家所公认的，\n\t也有很大一部分只在某个局部领域被使用或并没有被采用，\n\t一份RFC具体处于什么状态都在文件中作了明确的标识.\n\n[RFC1738](https://tools.ietf.org/html/rfc1738)\n\n![image-20200317175415033](C:\\Users\\kongz\\AppData\\Roaming\\Typora\\typora-user-images\\image-20200317175415033.png)\n\n可以看到这个RFC是小LEE提出来的，里面规定了很多东西，比如url的格式、编码、字符，还有很多scheme，我没看全，看到了FTP和HTTP。\n\n## 总结一波\n\nURL（统一资源定位符）是万维网中资源的地址。URL具有明确定义的结构，该结构由[万维网](https://en.wikipedia.org/wiki/Tim_Berners-Lee)的发明者[Tim Berners-Lee](https://en.wikipedia.org/wiki/Tim_Berners-Lee)在[RFC 1738](https://tools.ietf.org/html/rfc1738)中提出。\n\n每个网址都采用*通用语法*，如下所示：\n\n```bash\nscheme:[//[user:password@]host[:port]]path[?query][#fragment]\n```\n\n`[user:password@]`由于安全原因，不建议使用URL语法的某些部分，因此很少使用。以下是您在互联网上经常看到的URL的示例-\n\n```bash\nhttps://www.google.com/search?q=hello+world#brs\n```\n\n对定义统一资源定位符（URL）语法的初始RFC进行了许多改进。当前定义通用URI语法的[RFC](https://tools.ietf.org/html/rfc3986)是[RFC 3986](https://tools.ietf.org/html/rfc3986)。这篇文章包含最新RFC文档中的信息。\n\nURL由属于US-ASCII字符集的有限字符集组成。这些字符包括数字（0-9），字母（AZ，az），以及一些特殊字符（`\"-\"`，`\".\"`，`\"_\"`，`\"~\"`）。\n\nASCII控制字符（例如退格，垂直制表符，水平制表，换行等），不安全的字符像`space`，`\\`，`<`，`>`，`{`，`}`等等，以及ASCII字符以外的任何字符被不允许直接的URL内放置。\n\n此外，URL中有些字符具有特殊含义。这些字符称为**保留**字符。的保留字符的一些例子是`?`，`/`，`#`，`:`等作为URL的一部分发送，无论是在查询字符串或路径段，必须不包含这些字符的任何数据。\n\n那么，当我们需要在URL中传输包含这些不允许的字符的任何数据时，我们该怎么办？好吧，**我们对它们进行编码！**\n\n> URL编码将URL中保留的，不安全的和非ASCII字符转换为所有Web浏览器和服务器普遍接受并理解的格式。它首先将字符转换为一个或多个字节。然后，每个字节由两个十六进制数字表示，后跟一个百分号（`%`）-（例如`%xy`）。百分号用作转义字符。\n\nURL编码也称为百分比编码，因为它使用百分号（`%`）作为转义字符。\n\n#### URL编码示例\n\n**空格：**您可能会遇到的最常见的URL编码字符是`space`。`space`十进制字符的ASCII码为`32`，转换为十六进制时为`20`。现在，我们在十六进制表示形式之前加一个百分号（`%`），这使我们获得了URL编码值- `%20`。\n\n**+:** 看到我一开始代码里的replace，那是因为：\n\n![image-20200317181423078](C:\\Users\\kongz\\AppData\\Roaming\\Typora\\typora-user-images\\image-20200317181423078.png)\n\nw3c的规定是空格被替换为`+`，Java中的URLEncoder正式这种情况，会把空格转成`+`\n\n![image-20200317182519016](C:\\Users\\kongz\\AppData\\Roaming\\Typora\\typora-user-images\\image-20200317182519016.png)\n\n这就会导致在一些遵循RFC的应用上无法解码或其他问题，所以我们取一个折中的方法，要在`URLEncoder.encode()`之后把`+`替换为`%20`\n\n## ASCII字符编码参考\n\n下表是ASCII字符对其相应的URL编码形式的引用。\n\n> 请注意，不需要编码字母数字ASCII字符。例如，您不需要编码字符`'0'`以`%30`如图所示下表。可以原样发送。但是根据RFC编码仍然有效。表格中所有可以安全地在URL中传输的字符都显示为绿色。\n\n**下表使用RFC 3986中定义的URL编码规则。**\n\n| Decimal | Character                   | URL Encoding (UTF-8) |\n| :------ | :-------------------------- | :------------------- |\n| 0       | NUL(null character)         | %00                  |\n| 1       | SOH(start of header)        | %01                  |\n| 2       | STX(start of text)          | %02                  |\n| 3       | ETX(end of text)            | %03                  |\n| 4       | EOT(end of transmission)    | %04                  |\n| 5       | ENQ(enquiry)                | %05                  |\n| 6       | ACK(acknowledge)            | %06                  |\n| 7       | BEL(bell (ring))            | %07                  |\n| 8       | BS(backspace)               | %08                  |\n| 9       | HT(horizontal tab)          | %09                  |\n| 10      | LF(line feed)               | %0A                  |\n| 11      | VT(vertical tab)            | %0B                  |\n| 12      | FF(form feed)               | %0C                  |\n| 13      | CR(carriage return)         | %0D                  |\n| 14      | SO(shift out)               | %0E                  |\n| 15      | SI(shift in)                | %0F                  |\n| 16      | DLE(data link escape)       | %10                  |\n| 17      | DC1(device control 1)       | %11                  |\n| 18      | DC2(device control 2)       | %12                  |\n| 19      | DC3(device control 3)       | %13                  |\n| 20      | DC4(device control 4)       | %14                  |\n| 21      | NAK(negative acknowledge)   | %15                  |\n| 22      | SYN(synchronize)            | %16                  |\n| 23      | ETB(end transmission block) | %17                  |\n| 24      | CAN(cancel)                 | %18                  |\n| 25      | EM(end of medium)           | %19                  |\n| 26      | SUB(substitute)             | %1A                  |\n| 27      | ESC(escape)                 | %1B                  |\n| 28      | FS(file separator)          | %1C                  |\n| 29      | GS(group separator)         | %1D                  |\n| 30      | RS(record separator)        | %1E                  |\n| 31      | US(unit separator)          | %1F                  |\n| 32      | space                       | %20                  |\n| 33      | !                           | %21                  |\n| 34      | \"                           | %22                  |\n| 35      | #                           | %23                  |\n| 36      | $                           | %24                  |\n| 37      | %                           | %25                  |\n| 38      | &                           | %26                  |\n| 39      | '                           | %27                  |\n| 40      | (                           | %28                  |\n| 41      | )                           | %29                  |\n| 42      | *                           | %2A                  |\n| 43      | +                           | %2B                  |\n| 44      | ,                           | %2C                  |\n| 45      | -                           | %2D                  |\n| 46      | .                           | %2E                  |\n| 47      | /                           | %2F                  |\n| 48      | 0                           | %30                  |\n| 49      | 1                           | %31                  |\n| 50      | 2                           | %32                  |\n| 51      | 3                           | %33                  |\n| 52      | 4                           | %34                  |\n| 53      | 5                           | %35                  |\n| 54      | 6                           | %36                  |\n| 55      | 7                           | %37                  |\n| 56      | 8                           | %38                  |\n| 57      | 9                           | %39                  |\n| 58      | :                           | %3A                  |\n| 59      | ;                           | %3B                  |\n| 60      | <                           | %3C                  |\n| 61      | =                           | %3D                  |\n| 62      | >                           | %3E                  |\n| 63      | ?                           | %3F                  |\n| 64      | @                           | %40                  |\n| 65      | A                           | %41                  |\n| 66      | B                           | %42                  |\n| 67      | C                           | %43                  |\n| 68      | D                           | %44                  |\n| 69      | E                           | %45                  |\n| 70      | F                           | %46                  |\n| 71      | G                           | %47                  |\n| 72      | H                           | %48                  |\n| 73      | I                           | %49                  |\n| 74      | J                           | %4A                  |\n| 75      | K                           | %4B                  |\n| 76      | L                           | %4C                  |\n| 77      | M                           | %4D                  |\n| 78      | N                           | %4E                  |\n| 79      | O                           | %4F                  |\n| 80      | P                           | %50                  |\n| 81      | Q                           | %51                  |\n| 82      | R                           | %52                  |\n| 83      | S                           | %53                  |\n| 84      | T                           | %54                  |\n| 85      | U                           | %55                  |\n| 86      | V                           | %56                  |\n| 87      | W                           | %57                  |\n| 88      | X                           | %58                  |\n| 89      | Y                           | %59                  |\n| 90      | Z                           | %5A                  |\n| 91      | [                           | %5B                  |\n| 92      | \\                           | %5C                  |\n| 93      | ]                           | %5D                  |\n| 94      | ^                           | %5E                  |\n| 95      | _                           | %5F                  |\n| 96      | `                           | %60                  |\n| 97      | a                           | %61                  |\n| 98      | b                           | %62                  |\n| 99      | c                           | %63                  |\n| 100     | d                           | %64                  |\n| 101     | e                           | %65                  |\n| 102     | f                           | %66                  |\n| 103     | g                           | %67                  |\n| 104     | h                           | %68                  |\n| 105     | i                           | %69                  |\n| 106     | j                           | %6A                  |\n| 107     | k                           | %6B                  |\n| 108     | l                           | %6C                  |\n| 109     | m                           | %6D                  |\n| 110     | n                           | %6E                  |\n| 111     | o                           | %6F                  |\n| 112     | p                           | %70                  |\n| 113     | q                           | %71                  |\n| 114     | r                           | %72                  |\n| 115     | s                           | %73                  |\n| 116     | t                           | %74                  |\n| 117     | u                           | %75                  |\n| 118     | v                           | %76                  |\n| 119     | w                           | %77                  |\n| 120     | x                           | %78                  |\n| 121     | y                           | %79                  |\n| 122     | z                           | %7A                  |\n| 123     | {                           | %7B                  |\n| 124     | \\|                          | %7C                  |\n| 125     | }                           | %7D                  |\n| 126     | ~                           | %7E                  |\n| 127     | DEL(delete (rubout))        | %7F                  |","source":"_posts/2020-03-08-kongzheng1993-URLEncode.md","raw":"---\ntitle: URLEncoder\nexcerpt: ''\ntags: [Web]\ncategories: [Web]\ncomments: true\ndate: 2020-03-08 00:30:52\n---\n\n# URLEncoder\n\n今天写代码要发起一个HTTP GET请求，WebService接口我们随处可见，作为一个“业务程序员”我们也每天都在写。。。所以指尖跳动，分分钟就出现了下面的代码：\n\n```java\n try {\n            encode = URLEncoder.encode(JsonUtil.convertObject2Json(reqParamsMap), \"UTF-8\").replace(\"\\\\+\", \"%20\");\n        } catch (UnsupportedEncodingException e) {\n            logger.error(\"URLEncoder.encodec出错： \", e);\n        }\n```\n\n撸完码我回头看了一眼，我习以为常的URL编码，到底是为什么呢？我想大概是怕传输数据中的特殊字符造成什么不可预知的问题吧。\n\n工作完成，测试没有问题。我今天打算打破砂锅问到底，让我们一探究竟，到底为什么要编码？\n\n<font color=red>知道了How，我们还要知道Why！！！</font>\n\n## 找资料\n\n打开bing，国际搜索（梯子断了很久了……）在`stackoverflow`上看到也有很多人提出了这个问题，很多的人回答都指向了一个RFC\n\n\tRFC(Request For Comments)-意即“请求评议”，包含了关于Internet的几乎所有重要的文字资料。\n\t通常，当某家机构或团体开发出了一套标准或提出对某种标准的设想，\n\t想要征询外界的意见时，就会在Internet上发放一份RFC，\n\t对这一问题感兴趣的人可以阅读该RFC并提出自己的意见；\n\t\n\t绝大部分网络标准的指定都是以RFC的形式开始，经过大量的论证和修改过程，\n\t由主要的标准化组织所指定的，但在RFC中所收录的文件并不都是正在使用或为大家所公认的，\n\t也有很大一部分只在某个局部领域被使用或并没有被采用，\n\t一份RFC具体处于什么状态都在文件中作了明确的标识.\n\n[RFC1738](https://tools.ietf.org/html/rfc1738)\n\n![image-20200317175415033](C:\\Users\\kongz\\AppData\\Roaming\\Typora\\typora-user-images\\image-20200317175415033.png)\n\n可以看到这个RFC是小LEE提出来的，里面规定了很多东西，比如url的格式、编码、字符，还有很多scheme，我没看全，看到了FTP和HTTP。\n\n## 总结一波\n\nURL（统一资源定位符）是万维网中资源的地址。URL具有明确定义的结构，该结构由[万维网](https://en.wikipedia.org/wiki/Tim_Berners-Lee)的发明者[Tim Berners-Lee](https://en.wikipedia.org/wiki/Tim_Berners-Lee)在[RFC 1738](https://tools.ietf.org/html/rfc1738)中提出。\n\n每个网址都采用*通用语法*，如下所示：\n\n```bash\nscheme:[//[user:password@]host[:port]]path[?query][#fragment]\n```\n\n`[user:password@]`由于安全原因，不建议使用URL语法的某些部分，因此很少使用。以下是您在互联网上经常看到的URL的示例-\n\n```bash\nhttps://www.google.com/search?q=hello+world#brs\n```\n\n对定义统一资源定位符（URL）语法的初始RFC进行了许多改进。当前定义通用URI语法的[RFC](https://tools.ietf.org/html/rfc3986)是[RFC 3986](https://tools.ietf.org/html/rfc3986)。这篇文章包含最新RFC文档中的信息。\n\nURL由属于US-ASCII字符集的有限字符集组成。这些字符包括数字（0-9），字母（AZ，az），以及一些特殊字符（`\"-\"`，`\".\"`，`\"_\"`，`\"~\"`）。\n\nASCII控制字符（例如退格，垂直制表符，水平制表，换行等），不安全的字符像`space`，`\\`，`<`，`>`，`{`，`}`等等，以及ASCII字符以外的任何字符被不允许直接的URL内放置。\n\n此外，URL中有些字符具有特殊含义。这些字符称为**保留**字符。的保留字符的一些例子是`?`，`/`，`#`，`:`等作为URL的一部分发送，无论是在查询字符串或路径段，必须不包含这些字符的任何数据。\n\n那么，当我们需要在URL中传输包含这些不允许的字符的任何数据时，我们该怎么办？好吧，**我们对它们进行编码！**\n\n> URL编码将URL中保留的，不安全的和非ASCII字符转换为所有Web浏览器和服务器普遍接受并理解的格式。它首先将字符转换为一个或多个字节。然后，每个字节由两个十六进制数字表示，后跟一个百分号（`%`）-（例如`%xy`）。百分号用作转义字符。\n\nURL编码也称为百分比编码，因为它使用百分号（`%`）作为转义字符。\n\n#### URL编码示例\n\n**空格：**您可能会遇到的最常见的URL编码字符是`space`。`space`十进制字符的ASCII码为`32`，转换为十六进制时为`20`。现在，我们在十六进制表示形式之前加一个百分号（`%`），这使我们获得了URL编码值- `%20`。\n\n**+:** 看到我一开始代码里的replace，那是因为：\n\n![image-20200317181423078](C:\\Users\\kongz\\AppData\\Roaming\\Typora\\typora-user-images\\image-20200317181423078.png)\n\nw3c的规定是空格被替换为`+`，Java中的URLEncoder正式这种情况，会把空格转成`+`\n\n![image-20200317182519016](C:\\Users\\kongz\\AppData\\Roaming\\Typora\\typora-user-images\\image-20200317182519016.png)\n\n这就会导致在一些遵循RFC的应用上无法解码或其他问题，所以我们取一个折中的方法，要在`URLEncoder.encode()`之后把`+`替换为`%20`\n\n## ASCII字符编码参考\n\n下表是ASCII字符对其相应的URL编码形式的引用。\n\n> 请注意，不需要编码字母数字ASCII字符。例如，您不需要编码字符`'0'`以`%30`如图所示下表。可以原样发送。但是根据RFC编码仍然有效。表格中所有可以安全地在URL中传输的字符都显示为绿色。\n\n**下表使用RFC 3986中定义的URL编码规则。**\n\n| Decimal | Character                   | URL Encoding (UTF-8) |\n| :------ | :-------------------------- | :------------------- |\n| 0       | NUL(null character)         | %00                  |\n| 1       | SOH(start of header)        | %01                  |\n| 2       | STX(start of text)          | %02                  |\n| 3       | ETX(end of text)            | %03                  |\n| 4       | EOT(end of transmission)    | %04                  |\n| 5       | ENQ(enquiry)                | %05                  |\n| 6       | ACK(acknowledge)            | %06                  |\n| 7       | BEL(bell (ring))            | %07                  |\n| 8       | BS(backspace)               | %08                  |\n| 9       | HT(horizontal tab)          | %09                  |\n| 10      | LF(line feed)               | %0A                  |\n| 11      | VT(vertical tab)            | %0B                  |\n| 12      | FF(form feed)               | %0C                  |\n| 13      | CR(carriage return)         | %0D                  |\n| 14      | SO(shift out)               | %0E                  |\n| 15      | SI(shift in)                | %0F                  |\n| 16      | DLE(data link escape)       | %10                  |\n| 17      | DC1(device control 1)       | %11                  |\n| 18      | DC2(device control 2)       | %12                  |\n| 19      | DC3(device control 3)       | %13                  |\n| 20      | DC4(device control 4)       | %14                  |\n| 21      | NAK(negative acknowledge)   | %15                  |\n| 22      | SYN(synchronize)            | %16                  |\n| 23      | ETB(end transmission block) | %17                  |\n| 24      | CAN(cancel)                 | %18                  |\n| 25      | EM(end of medium)           | %19                  |\n| 26      | SUB(substitute)             | %1A                  |\n| 27      | ESC(escape)                 | %1B                  |\n| 28      | FS(file separator)          | %1C                  |\n| 29      | GS(group separator)         | %1D                  |\n| 30      | RS(record separator)        | %1E                  |\n| 31      | US(unit separator)          | %1F                  |\n| 32      | space                       | %20                  |\n| 33      | !                           | %21                  |\n| 34      | \"                           | %22                  |\n| 35      | #                           | %23                  |\n| 36      | $                           | %24                  |\n| 37      | %                           | %25                  |\n| 38      | &                           | %26                  |\n| 39      | '                           | %27                  |\n| 40      | (                           | %28                  |\n| 41      | )                           | %29                  |\n| 42      | *                           | %2A                  |\n| 43      | +                           | %2B                  |\n| 44      | ,                           | %2C                  |\n| 45      | -                           | %2D                  |\n| 46      | .                           | %2E                  |\n| 47      | /                           | %2F                  |\n| 48      | 0                           | %30                  |\n| 49      | 1                           | %31                  |\n| 50      | 2                           | %32                  |\n| 51      | 3                           | %33                  |\n| 52      | 4                           | %34                  |\n| 53      | 5                           | %35                  |\n| 54      | 6                           | %36                  |\n| 55      | 7                           | %37                  |\n| 56      | 8                           | %38                  |\n| 57      | 9                           | %39                  |\n| 58      | :                           | %3A                  |\n| 59      | ;                           | %3B                  |\n| 60      | <                           | %3C                  |\n| 61      | =                           | %3D                  |\n| 62      | >                           | %3E                  |\n| 63      | ?                           | %3F                  |\n| 64      | @                           | %40                  |\n| 65      | A                           | %41                  |\n| 66      | B                           | %42                  |\n| 67      | C                           | %43                  |\n| 68      | D                           | %44                  |\n| 69      | E                           | %45                  |\n| 70      | F                           | %46                  |\n| 71      | G                           | %47                  |\n| 72      | H                           | %48                  |\n| 73      | I                           | %49                  |\n| 74      | J                           | %4A                  |\n| 75      | K                           | %4B                  |\n| 76      | L                           | %4C                  |\n| 77      | M                           | %4D                  |\n| 78      | N                           | %4E                  |\n| 79      | O                           | %4F                  |\n| 80      | P                           | %50                  |\n| 81      | Q                           | %51                  |\n| 82      | R                           | %52                  |\n| 83      | S                           | %53                  |\n| 84      | T                           | %54                  |\n| 85      | U                           | %55                  |\n| 86      | V                           | %56                  |\n| 87      | W                           | %57                  |\n| 88      | X                           | %58                  |\n| 89      | Y                           | %59                  |\n| 90      | Z                           | %5A                  |\n| 91      | [                           | %5B                  |\n| 92      | \\                           | %5C                  |\n| 93      | ]                           | %5D                  |\n| 94      | ^                           | %5E                  |\n| 95      | _                           | %5F                  |\n| 96      | `                           | %60                  |\n| 97      | a                           | %61                  |\n| 98      | b                           | %62                  |\n| 99      | c                           | %63                  |\n| 100     | d                           | %64                  |\n| 101     | e                           | %65                  |\n| 102     | f                           | %66                  |\n| 103     | g                           | %67                  |\n| 104     | h                           | %68                  |\n| 105     | i                           | %69                  |\n| 106     | j                           | %6A                  |\n| 107     | k                           | %6B                  |\n| 108     | l                           | %6C                  |\n| 109     | m                           | %6D                  |\n| 110     | n                           | %6E                  |\n| 111     | o                           | %6F                  |\n| 112     | p                           | %70                  |\n| 113     | q                           | %71                  |\n| 114     | r                           | %72                  |\n| 115     | s                           | %73                  |\n| 116     | t                           | %74                  |\n| 117     | u                           | %75                  |\n| 118     | v                           | %76                  |\n| 119     | w                           | %77                  |\n| 120     | x                           | %78                  |\n| 121     | y                           | %79                  |\n| 122     | z                           | %7A                  |\n| 123     | {                           | %7B                  |\n| 124     | \\|                          | %7C                  |\n| 125     | }                           | %7D                  |\n| 126     | ~                           | %7E                  |\n| 127     | DEL(delete (rubout))        | %7F                  |","slug":"kongzheng1993-URLEncode","published":1,"updated":"2023-03-08T07:05:58.777Z","layout":"post","photos":[],"link":"","_id":"clg0k2aov00hot26fpkth3z3s","content":"<h1 id=\"URLEncoder\"><a href=\"#URLEncoder\" class=\"headerlink\" title=\"URLEncoder\"></a>URLEncoder</h1><p>今天写代码要发起一个HTTP GET请求，WebService接口我们随处可见，作为一个“业务程序员”我们也每天都在写。。。所以指尖跳动，分分钟就出现了下面的代码：</p>\n<pre><code class=\"java\"> try {\n            encode = URLEncoder.encode(JsonUtil.convertObject2Json(reqParamsMap), &quot;UTF-8&quot;).replace(&quot;\\\\+&quot;, &quot;%20&quot;);\n        } catch (UnsupportedEncodingException e) {\n            logger.error(&quot;URLEncoder.encodec出错： &quot;, e);\n        }</code></pre>\n<p>撸完码我回头看了一眼，我习以为常的URL编码，到底是为什么呢？我想大概是怕传输数据中的特殊字符造成什么不可预知的问题吧。</p>\n<p>工作完成，测试没有问题。我今天打算打破砂锅问到底，让我们一探究竟，到底为什么要编码？</p>\n<p><font color=\"red\">知道了How，我们还要知道Why！！！</font></p>\n<h2 id=\"找资料\"><a href=\"#找资料\" class=\"headerlink\" title=\"找资料\"></a>找资料</h2><p>打开bing，国际搜索（梯子断了很久了……）在<code>stackoverflow</code>上看到也有很多人提出了这个问题，很多的人回答都指向了一个RFC</p>\n<pre><code>RFC(Request For Comments)-意即“请求评议”，包含了关于Internet的几乎所有重要的文字资料。\n通常，当某家机构或团体开发出了一套标准或提出对某种标准的设想，\n想要征询外界的意见时，就会在Internet上发放一份RFC，\n对这一问题感兴趣的人可以阅读该RFC并提出自己的意见；\n\n绝大部分网络标准的指定都是以RFC的形式开始，经过大量的论证和修改过程，\n由主要的标准化组织所指定的，但在RFC中所收录的文件并不都是正在使用或为大家所公认的，\n也有很大一部分只在某个局部领域被使用或并没有被采用，\n一份RFC具体处于什么状态都在文件中作了明确的标识.</code></pre><p><a href=\"https://tools.ietf.org/html/rfc1738\" target=\"_blank\" rel=\"noopener\">RFC1738</a></p>\n<p><img src=\"/2020/03/08/kongzheng1993-URLEncode/C:%5CUsers%5Ckongz%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200317175415033.png\" alt=\"image-20200317175415033\"></p>\n<p>可以看到这个RFC是小LEE提出来的，里面规定了很多东西，比如url的格式、编码、字符，还有很多scheme，我没看全，看到了FTP和HTTP。</p>\n<h2 id=\"总结一波\"><a href=\"#总结一波\" class=\"headerlink\" title=\"总结一波\"></a>总结一波</h2><p>URL（统一资源定位符）是万维网中资源的地址。URL具有明确定义的结构，该结构由<a href=\"https://en.wikipedia.org/wiki/Tim_Berners-Lee\" target=\"_blank\" rel=\"noopener\">万维网</a>的发明者<a href=\"https://en.wikipedia.org/wiki/Tim_Berners-Lee\" target=\"_blank\" rel=\"noopener\">Tim Berners-Lee</a>在<a href=\"https://tools.ietf.org/html/rfc1738\" target=\"_blank\" rel=\"noopener\">RFC 1738</a>中提出。</p>\n<p>每个网址都采用<em>通用语法</em>，如下所示：</p>\n<pre><code class=\"bash\">scheme:[//[user:password@]host[:port]]path[?query][#fragment]</code></pre>\n<p><code>[user:password@]</code>由于安全原因，不建议使用URL语法的某些部分，因此很少使用。以下是您在互联网上经常看到的URL的示例-</p>\n<pre><code class=\"bash\">https://www.google.com/search?q=hello+world#brs</code></pre>\n<p>对定义统一资源定位符（URL）语法的初始RFC进行了许多改进。当前定义通用URI语法的<a href=\"https://tools.ietf.org/html/rfc3986\" target=\"_blank\" rel=\"noopener\">RFC</a>是<a href=\"https://tools.ietf.org/html/rfc3986\" target=\"_blank\" rel=\"noopener\">RFC 3986</a>。这篇文章包含最新RFC文档中的信息。</p>\n<p>URL由属于US-ASCII字符集的有限字符集组成。这些字符包括数字（0-9），字母（AZ，az），以及一些特殊字符（<code>&quot;-&quot;</code>，<code>&quot;.&quot;</code>，<code>&quot;_&quot;</code>，<code>&quot;~&quot;</code>）。</p>\n<p>ASCII控制字符（例如退格，垂直制表符，水平制表，换行等），不安全的字符像<code>space</code>，<code>\\</code>，<code>&lt;</code>，<code>&gt;</code>，<code>{</code>，<code>}</code>等等，以及ASCII字符以外的任何字符被不允许直接的URL内放置。</p>\n<p>此外，URL中有些字符具有特殊含义。这些字符称为<strong>保留</strong>字符。的保留字符的一些例子是<code>?</code>，<code>/</code>，<code>#</code>，<code>:</code>等作为URL的一部分发送，无论是在查询字符串或路径段，必须不包含这些字符的任何数据。</p>\n<p>那么，当我们需要在URL中传输包含这些不允许的字符的任何数据时，我们该怎么办？好吧，<strong>我们对它们进行编码！</strong></p>\n<blockquote>\n<p>URL编码将URL中保留的，不安全的和非ASCII字符转换为所有Web浏览器和服务器普遍接受并理解的格式。它首先将字符转换为一个或多个字节。然后，每个字节由两个十六进制数字表示，后跟一个百分号（<code>%</code>）-（例如<code>%xy</code>）。百分号用作转义字符。</p>\n</blockquote>\n<p>URL编码也称为百分比编码，因为它使用百分号（<code>%</code>）作为转义字符。</p>\n<h4 id=\"URL编码示例\"><a href=\"#URL编码示例\" class=\"headerlink\" title=\"URL编码示例\"></a>URL编码示例</h4><p><strong>空格：</strong>您可能会遇到的最常见的URL编码字符是<code>space</code>。<code>space</code>十进制字符的ASCII码为<code>32</code>，转换为十六进制时为<code>20</code>。现在，我们在十六进制表示形式之前加一个百分号（<code>%</code>），这使我们获得了URL编码值- <code>%20</code>。</p>\n<p><strong>+:</strong> 看到我一开始代码里的replace，那是因为：</p>\n<p><img src=\"/2020/03/08/kongzheng1993-URLEncode/C:%5CUsers%5Ckongz%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200317181423078.png\" alt=\"image-20200317181423078\"></p>\n<p>w3c的规定是空格被替换为<code>+</code>，Java中的URLEncoder正式这种情况，会把空格转成<code>+</code></p>\n<p><img src=\"/2020/03/08/kongzheng1993-URLEncode/C:%5CUsers%5Ckongz%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200317182519016.png\" alt=\"image-20200317182519016\"></p>\n<p>这就会导致在一些遵循RFC的应用上无法解码或其他问题，所以我们取一个折中的方法，要在<code>URLEncoder.encode()</code>之后把<code>+</code>替换为<code>%20</code></p>\n<h2 id=\"ASCII字符编码参考\"><a href=\"#ASCII字符编码参考\" class=\"headerlink\" title=\"ASCII字符编码参考\"></a>ASCII字符编码参考</h2><p>下表是ASCII字符对其相应的URL编码形式的引用。</p>\n<blockquote>\n<p>请注意，不需要编码字母数字ASCII字符。例如，您不需要编码字符<code>&#39;0&#39;</code>以<code>%30</code>如图所示下表。可以原样发送。但是根据RFC编码仍然有效。表格中所有可以安全地在URL中传输的字符都显示为绿色。</p>\n</blockquote>\n<p><strong>下表使用RFC 3986中定义的URL编码规则。</strong></p>\n<table>\n<thead>\n<tr>\n<th align=\"left\">Decimal</th>\n<th align=\"left\">Character</th>\n<th align=\"left\">URL Encoding (UTF-8)</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\">0</td>\n<td align=\"left\">NUL(null character)</td>\n<td align=\"left\">%00</td>\n</tr>\n<tr>\n<td align=\"left\">1</td>\n<td align=\"left\">SOH(start of header)</td>\n<td align=\"left\">%01</td>\n</tr>\n<tr>\n<td align=\"left\">2</td>\n<td align=\"left\">STX(start of text)</td>\n<td align=\"left\">%02</td>\n</tr>\n<tr>\n<td align=\"left\">3</td>\n<td align=\"left\">ETX(end of text)</td>\n<td align=\"left\">%03</td>\n</tr>\n<tr>\n<td align=\"left\">4</td>\n<td align=\"left\">EOT(end of transmission)</td>\n<td align=\"left\">%04</td>\n</tr>\n<tr>\n<td align=\"left\">5</td>\n<td align=\"left\">ENQ(enquiry)</td>\n<td align=\"left\">%05</td>\n</tr>\n<tr>\n<td align=\"left\">6</td>\n<td align=\"left\">ACK(acknowledge)</td>\n<td align=\"left\">%06</td>\n</tr>\n<tr>\n<td align=\"left\">7</td>\n<td align=\"left\">BEL(bell (ring))</td>\n<td align=\"left\">%07</td>\n</tr>\n<tr>\n<td align=\"left\">8</td>\n<td align=\"left\">BS(backspace)</td>\n<td align=\"left\">%08</td>\n</tr>\n<tr>\n<td align=\"left\">9</td>\n<td align=\"left\">HT(horizontal tab)</td>\n<td align=\"left\">%09</td>\n</tr>\n<tr>\n<td align=\"left\">10</td>\n<td align=\"left\">LF(line feed)</td>\n<td align=\"left\">%0A</td>\n</tr>\n<tr>\n<td align=\"left\">11</td>\n<td align=\"left\">VT(vertical tab)</td>\n<td align=\"left\">%0B</td>\n</tr>\n<tr>\n<td align=\"left\">12</td>\n<td align=\"left\">FF(form feed)</td>\n<td align=\"left\">%0C</td>\n</tr>\n<tr>\n<td align=\"left\">13</td>\n<td align=\"left\">CR(carriage return)</td>\n<td align=\"left\">%0D</td>\n</tr>\n<tr>\n<td align=\"left\">14</td>\n<td align=\"left\">SO(shift out)</td>\n<td align=\"left\">%0E</td>\n</tr>\n<tr>\n<td align=\"left\">15</td>\n<td align=\"left\">SI(shift in)</td>\n<td align=\"left\">%0F</td>\n</tr>\n<tr>\n<td align=\"left\">16</td>\n<td align=\"left\">DLE(data link escape)</td>\n<td align=\"left\">%10</td>\n</tr>\n<tr>\n<td align=\"left\">17</td>\n<td align=\"left\">DC1(device control 1)</td>\n<td align=\"left\">%11</td>\n</tr>\n<tr>\n<td align=\"left\">18</td>\n<td align=\"left\">DC2(device control 2)</td>\n<td align=\"left\">%12</td>\n</tr>\n<tr>\n<td align=\"left\">19</td>\n<td align=\"left\">DC3(device control 3)</td>\n<td align=\"left\">%13</td>\n</tr>\n<tr>\n<td align=\"left\">20</td>\n<td align=\"left\">DC4(device control 4)</td>\n<td align=\"left\">%14</td>\n</tr>\n<tr>\n<td align=\"left\">21</td>\n<td align=\"left\">NAK(negative acknowledge)</td>\n<td align=\"left\">%15</td>\n</tr>\n<tr>\n<td align=\"left\">22</td>\n<td align=\"left\">SYN(synchronize)</td>\n<td align=\"left\">%16</td>\n</tr>\n<tr>\n<td align=\"left\">23</td>\n<td align=\"left\">ETB(end transmission block)</td>\n<td align=\"left\">%17</td>\n</tr>\n<tr>\n<td align=\"left\">24</td>\n<td align=\"left\">CAN(cancel)</td>\n<td align=\"left\">%18</td>\n</tr>\n<tr>\n<td align=\"left\">25</td>\n<td align=\"left\">EM(end of medium)</td>\n<td align=\"left\">%19</td>\n</tr>\n<tr>\n<td align=\"left\">26</td>\n<td align=\"left\">SUB(substitute)</td>\n<td align=\"left\">%1A</td>\n</tr>\n<tr>\n<td align=\"left\">27</td>\n<td align=\"left\">ESC(escape)</td>\n<td align=\"left\">%1B</td>\n</tr>\n<tr>\n<td align=\"left\">28</td>\n<td align=\"left\">FS(file separator)</td>\n<td align=\"left\">%1C</td>\n</tr>\n<tr>\n<td align=\"left\">29</td>\n<td align=\"left\">GS(group separator)</td>\n<td align=\"left\">%1D</td>\n</tr>\n<tr>\n<td align=\"left\">30</td>\n<td align=\"left\">RS(record separator)</td>\n<td align=\"left\">%1E</td>\n</tr>\n<tr>\n<td align=\"left\">31</td>\n<td align=\"left\">US(unit separator)</td>\n<td align=\"left\">%1F</td>\n</tr>\n<tr>\n<td align=\"left\">32</td>\n<td align=\"left\">space</td>\n<td align=\"left\">%20</td>\n</tr>\n<tr>\n<td align=\"left\">33</td>\n<td align=\"left\">!</td>\n<td align=\"left\">%21</td>\n</tr>\n<tr>\n<td align=\"left\">34</td>\n<td align=\"left\">“</td>\n<td align=\"left\">%22</td>\n</tr>\n<tr>\n<td align=\"left\">35</td>\n<td align=\"left\">#</td>\n<td align=\"left\">%23</td>\n</tr>\n<tr>\n<td align=\"left\">36</td>\n<td align=\"left\">$</td>\n<td align=\"left\">%24</td>\n</tr>\n<tr>\n<td align=\"left\">37</td>\n<td align=\"left\">%</td>\n<td align=\"left\">%25</td>\n</tr>\n<tr>\n<td align=\"left\">38</td>\n<td align=\"left\">&amp;</td>\n<td align=\"left\">%26</td>\n</tr>\n<tr>\n<td align=\"left\">39</td>\n<td align=\"left\">‘</td>\n<td align=\"left\">%27</td>\n</tr>\n<tr>\n<td align=\"left\">40</td>\n<td align=\"left\">(</td>\n<td align=\"left\">%28</td>\n</tr>\n<tr>\n<td align=\"left\">41</td>\n<td align=\"left\">)</td>\n<td align=\"left\">%29</td>\n</tr>\n<tr>\n<td align=\"left\">42</td>\n<td align=\"left\">*</td>\n<td align=\"left\">%2A</td>\n</tr>\n<tr>\n<td align=\"left\">43</td>\n<td align=\"left\">+</td>\n<td align=\"left\">%2B</td>\n</tr>\n<tr>\n<td align=\"left\">44</td>\n<td align=\"left\">,</td>\n<td align=\"left\">%2C</td>\n</tr>\n<tr>\n<td align=\"left\">45</td>\n<td align=\"left\">-</td>\n<td align=\"left\">%2D</td>\n</tr>\n<tr>\n<td align=\"left\">46</td>\n<td align=\"left\">.</td>\n<td align=\"left\">%2E</td>\n</tr>\n<tr>\n<td align=\"left\">47</td>\n<td align=\"left\">/</td>\n<td align=\"left\">%2F</td>\n</tr>\n<tr>\n<td align=\"left\">48</td>\n<td align=\"left\">0</td>\n<td align=\"left\">%30</td>\n</tr>\n<tr>\n<td align=\"left\">49</td>\n<td align=\"left\">1</td>\n<td align=\"left\">%31</td>\n</tr>\n<tr>\n<td align=\"left\">50</td>\n<td align=\"left\">2</td>\n<td align=\"left\">%32</td>\n</tr>\n<tr>\n<td align=\"left\">51</td>\n<td align=\"left\">3</td>\n<td align=\"left\">%33</td>\n</tr>\n<tr>\n<td align=\"left\">52</td>\n<td align=\"left\">4</td>\n<td align=\"left\">%34</td>\n</tr>\n<tr>\n<td align=\"left\">53</td>\n<td align=\"left\">5</td>\n<td align=\"left\">%35</td>\n</tr>\n<tr>\n<td align=\"left\">54</td>\n<td align=\"left\">6</td>\n<td align=\"left\">%36</td>\n</tr>\n<tr>\n<td align=\"left\">55</td>\n<td align=\"left\">7</td>\n<td align=\"left\">%37</td>\n</tr>\n<tr>\n<td align=\"left\">56</td>\n<td align=\"left\">8</td>\n<td align=\"left\">%38</td>\n</tr>\n<tr>\n<td align=\"left\">57</td>\n<td align=\"left\">9</td>\n<td align=\"left\">%39</td>\n</tr>\n<tr>\n<td align=\"left\">58</td>\n<td align=\"left\">:</td>\n<td align=\"left\">%3A</td>\n</tr>\n<tr>\n<td align=\"left\">59</td>\n<td align=\"left\">;</td>\n<td align=\"left\">%3B</td>\n</tr>\n<tr>\n<td align=\"left\">60</td>\n<td align=\"left\">&lt;</td>\n<td align=\"left\">%3C</td>\n</tr>\n<tr>\n<td align=\"left\">61</td>\n<td align=\"left\">=</td>\n<td align=\"left\">%3D</td>\n</tr>\n<tr>\n<td align=\"left\">62</td>\n<td align=\"left\">&gt;</td>\n<td align=\"left\">%3E</td>\n</tr>\n<tr>\n<td align=\"left\">63</td>\n<td align=\"left\">?</td>\n<td align=\"left\">%3F</td>\n</tr>\n<tr>\n<td align=\"left\">64</td>\n<td align=\"left\">@</td>\n<td align=\"left\">%40</td>\n</tr>\n<tr>\n<td align=\"left\">65</td>\n<td align=\"left\">A</td>\n<td align=\"left\">%41</td>\n</tr>\n<tr>\n<td align=\"left\">66</td>\n<td align=\"left\">B</td>\n<td align=\"left\">%42</td>\n</tr>\n<tr>\n<td align=\"left\">67</td>\n<td align=\"left\">C</td>\n<td align=\"left\">%43</td>\n</tr>\n<tr>\n<td align=\"left\">68</td>\n<td align=\"left\">D</td>\n<td align=\"left\">%44</td>\n</tr>\n<tr>\n<td align=\"left\">69</td>\n<td align=\"left\">E</td>\n<td align=\"left\">%45</td>\n</tr>\n<tr>\n<td align=\"left\">70</td>\n<td align=\"left\">F</td>\n<td align=\"left\">%46</td>\n</tr>\n<tr>\n<td align=\"left\">71</td>\n<td align=\"left\">G</td>\n<td align=\"left\">%47</td>\n</tr>\n<tr>\n<td align=\"left\">72</td>\n<td align=\"left\">H</td>\n<td align=\"left\">%48</td>\n</tr>\n<tr>\n<td align=\"left\">73</td>\n<td align=\"left\">I</td>\n<td align=\"left\">%49</td>\n</tr>\n<tr>\n<td align=\"left\">74</td>\n<td align=\"left\">J</td>\n<td align=\"left\">%4A</td>\n</tr>\n<tr>\n<td align=\"left\">75</td>\n<td align=\"left\">K</td>\n<td align=\"left\">%4B</td>\n</tr>\n<tr>\n<td align=\"left\">76</td>\n<td align=\"left\">L</td>\n<td align=\"left\">%4C</td>\n</tr>\n<tr>\n<td align=\"left\">77</td>\n<td align=\"left\">M</td>\n<td align=\"left\">%4D</td>\n</tr>\n<tr>\n<td align=\"left\">78</td>\n<td align=\"left\">N</td>\n<td align=\"left\">%4E</td>\n</tr>\n<tr>\n<td align=\"left\">79</td>\n<td align=\"left\">O</td>\n<td align=\"left\">%4F</td>\n</tr>\n<tr>\n<td align=\"left\">80</td>\n<td align=\"left\">P</td>\n<td align=\"left\">%50</td>\n</tr>\n<tr>\n<td align=\"left\">81</td>\n<td align=\"left\">Q</td>\n<td align=\"left\">%51</td>\n</tr>\n<tr>\n<td align=\"left\">82</td>\n<td align=\"left\">R</td>\n<td align=\"left\">%52</td>\n</tr>\n<tr>\n<td align=\"left\">83</td>\n<td align=\"left\">S</td>\n<td align=\"left\">%53</td>\n</tr>\n<tr>\n<td align=\"left\">84</td>\n<td align=\"left\">T</td>\n<td align=\"left\">%54</td>\n</tr>\n<tr>\n<td align=\"left\">85</td>\n<td align=\"left\">U</td>\n<td align=\"left\">%55</td>\n</tr>\n<tr>\n<td align=\"left\">86</td>\n<td align=\"left\">V</td>\n<td align=\"left\">%56</td>\n</tr>\n<tr>\n<td align=\"left\">87</td>\n<td align=\"left\">W</td>\n<td align=\"left\">%57</td>\n</tr>\n<tr>\n<td align=\"left\">88</td>\n<td align=\"left\">X</td>\n<td align=\"left\">%58</td>\n</tr>\n<tr>\n<td align=\"left\">89</td>\n<td align=\"left\">Y</td>\n<td align=\"left\">%59</td>\n</tr>\n<tr>\n<td align=\"left\">90</td>\n<td align=\"left\">Z</td>\n<td align=\"left\">%5A</td>\n</tr>\n<tr>\n<td align=\"left\">91</td>\n<td align=\"left\">[</td>\n<td align=\"left\">%5B</td>\n</tr>\n<tr>\n<td align=\"left\">92</td>\n<td align=\"left\">\\</td>\n<td align=\"left\">%5C</td>\n</tr>\n<tr>\n<td align=\"left\">93</td>\n<td align=\"left\">]</td>\n<td align=\"left\">%5D</td>\n</tr>\n<tr>\n<td align=\"left\">94</td>\n<td align=\"left\">^</td>\n<td align=\"left\">%5E</td>\n</tr>\n<tr>\n<td align=\"left\">95</td>\n<td align=\"left\">_</td>\n<td align=\"left\">%5F</td>\n</tr>\n<tr>\n<td align=\"left\">96</td>\n<td align=\"left\">`</td>\n<td align=\"left\">%60</td>\n</tr>\n<tr>\n<td align=\"left\">97</td>\n<td align=\"left\">a</td>\n<td align=\"left\">%61</td>\n</tr>\n<tr>\n<td align=\"left\">98</td>\n<td align=\"left\">b</td>\n<td align=\"left\">%62</td>\n</tr>\n<tr>\n<td align=\"left\">99</td>\n<td align=\"left\">c</td>\n<td align=\"left\">%63</td>\n</tr>\n<tr>\n<td align=\"left\">100</td>\n<td align=\"left\">d</td>\n<td align=\"left\">%64</td>\n</tr>\n<tr>\n<td align=\"left\">101</td>\n<td align=\"left\">e</td>\n<td align=\"left\">%65</td>\n</tr>\n<tr>\n<td align=\"left\">102</td>\n<td align=\"left\">f</td>\n<td align=\"left\">%66</td>\n</tr>\n<tr>\n<td align=\"left\">103</td>\n<td align=\"left\">g</td>\n<td align=\"left\">%67</td>\n</tr>\n<tr>\n<td align=\"left\">104</td>\n<td align=\"left\">h</td>\n<td align=\"left\">%68</td>\n</tr>\n<tr>\n<td align=\"left\">105</td>\n<td align=\"left\">i</td>\n<td align=\"left\">%69</td>\n</tr>\n<tr>\n<td align=\"left\">106</td>\n<td align=\"left\">j</td>\n<td align=\"left\">%6A</td>\n</tr>\n<tr>\n<td align=\"left\">107</td>\n<td align=\"left\">k</td>\n<td align=\"left\">%6B</td>\n</tr>\n<tr>\n<td align=\"left\">108</td>\n<td align=\"left\">l</td>\n<td align=\"left\">%6C</td>\n</tr>\n<tr>\n<td align=\"left\">109</td>\n<td align=\"left\">m</td>\n<td align=\"left\">%6D</td>\n</tr>\n<tr>\n<td align=\"left\">110</td>\n<td align=\"left\">n</td>\n<td align=\"left\">%6E</td>\n</tr>\n<tr>\n<td align=\"left\">111</td>\n<td align=\"left\">o</td>\n<td align=\"left\">%6F</td>\n</tr>\n<tr>\n<td align=\"left\">112</td>\n<td align=\"left\">p</td>\n<td align=\"left\">%70</td>\n</tr>\n<tr>\n<td align=\"left\">113</td>\n<td align=\"left\">q</td>\n<td align=\"left\">%71</td>\n</tr>\n<tr>\n<td align=\"left\">114</td>\n<td align=\"left\">r</td>\n<td align=\"left\">%72</td>\n</tr>\n<tr>\n<td align=\"left\">115</td>\n<td align=\"left\">s</td>\n<td align=\"left\">%73</td>\n</tr>\n<tr>\n<td align=\"left\">116</td>\n<td align=\"left\">t</td>\n<td align=\"left\">%74</td>\n</tr>\n<tr>\n<td align=\"left\">117</td>\n<td align=\"left\">u</td>\n<td align=\"left\">%75</td>\n</tr>\n<tr>\n<td align=\"left\">118</td>\n<td align=\"left\">v</td>\n<td align=\"left\">%76</td>\n</tr>\n<tr>\n<td align=\"left\">119</td>\n<td align=\"left\">w</td>\n<td align=\"left\">%77</td>\n</tr>\n<tr>\n<td align=\"left\">120</td>\n<td align=\"left\">x</td>\n<td align=\"left\">%78</td>\n</tr>\n<tr>\n<td align=\"left\">121</td>\n<td align=\"left\">y</td>\n<td align=\"left\">%79</td>\n</tr>\n<tr>\n<td align=\"left\">122</td>\n<td align=\"left\">z</td>\n<td align=\"left\">%7A</td>\n</tr>\n<tr>\n<td align=\"left\">123</td>\n<td align=\"left\">{</td>\n<td align=\"left\">%7B</td>\n</tr>\n<tr>\n<td align=\"left\">124</td>\n<td align=\"left\">|</td>\n<td align=\"left\">%7C</td>\n</tr>\n<tr>\n<td align=\"left\">125</td>\n<td align=\"left\">}</td>\n<td align=\"left\">%7D</td>\n</tr>\n<tr>\n<td align=\"left\">126</td>\n<td align=\"left\">~</td>\n<td align=\"left\">%7E</td>\n</tr>\n<tr>\n<td align=\"left\">127</td>\n<td align=\"left\">DEL(delete (rubout))</td>\n<td align=\"left\">%7F</td>\n</tr>\n</tbody></table>\n","site":{"data":{}},"more":"<h1 id=\"URLEncoder\"><a href=\"#URLEncoder\" class=\"headerlink\" title=\"URLEncoder\"></a>URLEncoder</h1><p>今天写代码要发起一个HTTP GET请求，WebService接口我们随处可见，作为一个“业务程序员”我们也每天都在写。。。所以指尖跳动，分分钟就出现了下面的代码：</p>\n<pre><code class=\"java\"> try {\n            encode = URLEncoder.encode(JsonUtil.convertObject2Json(reqParamsMap), &quot;UTF-8&quot;).replace(&quot;\\\\+&quot;, &quot;%20&quot;);\n        } catch (UnsupportedEncodingException e) {\n            logger.error(&quot;URLEncoder.encodec出错： &quot;, e);\n        }</code></pre>\n<p>撸完码我回头看了一眼，我习以为常的URL编码，到底是为什么呢？我想大概是怕传输数据中的特殊字符造成什么不可预知的问题吧。</p>\n<p>工作完成，测试没有问题。我今天打算打破砂锅问到底，让我们一探究竟，到底为什么要编码？</p>\n<p><font color=\"red\">知道了How，我们还要知道Why！！！</font></p>\n<h2 id=\"找资料\"><a href=\"#找资料\" class=\"headerlink\" title=\"找资料\"></a>找资料</h2><p>打开bing，国际搜索（梯子断了很久了……）在<code>stackoverflow</code>上看到也有很多人提出了这个问题，很多的人回答都指向了一个RFC</p>\n<pre><code>RFC(Request For Comments)-意即“请求评议”，包含了关于Internet的几乎所有重要的文字资料。\n通常，当某家机构或团体开发出了一套标准或提出对某种标准的设想，\n想要征询外界的意见时，就会在Internet上发放一份RFC，\n对这一问题感兴趣的人可以阅读该RFC并提出自己的意见；\n\n绝大部分网络标准的指定都是以RFC的形式开始，经过大量的论证和修改过程，\n由主要的标准化组织所指定的，但在RFC中所收录的文件并不都是正在使用或为大家所公认的，\n也有很大一部分只在某个局部领域被使用或并没有被采用，\n一份RFC具体处于什么状态都在文件中作了明确的标识.</code></pre><p><a href=\"https://tools.ietf.org/html/rfc1738\" target=\"_blank\" rel=\"noopener\">RFC1738</a></p>\n<p><img src=\"/2020/03/08/kongzheng1993-URLEncode/C:%5CUsers%5Ckongz%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200317175415033.png\" alt=\"image-20200317175415033\"></p>\n<p>可以看到这个RFC是小LEE提出来的，里面规定了很多东西，比如url的格式、编码、字符，还有很多scheme，我没看全，看到了FTP和HTTP。</p>\n<h2 id=\"总结一波\"><a href=\"#总结一波\" class=\"headerlink\" title=\"总结一波\"></a>总结一波</h2><p>URL（统一资源定位符）是万维网中资源的地址。URL具有明确定义的结构，该结构由<a href=\"https://en.wikipedia.org/wiki/Tim_Berners-Lee\" target=\"_blank\" rel=\"noopener\">万维网</a>的发明者<a href=\"https://en.wikipedia.org/wiki/Tim_Berners-Lee\" target=\"_blank\" rel=\"noopener\">Tim Berners-Lee</a>在<a href=\"https://tools.ietf.org/html/rfc1738\" target=\"_blank\" rel=\"noopener\">RFC 1738</a>中提出。</p>\n<p>每个网址都采用<em>通用语法</em>，如下所示：</p>\n<pre><code class=\"bash\">scheme:[//[user:password@]host[:port]]path[?query][#fragment]</code></pre>\n<p><code>[user:password@]</code>由于安全原因，不建议使用URL语法的某些部分，因此很少使用。以下是您在互联网上经常看到的URL的示例-</p>\n<pre><code class=\"bash\">https://www.google.com/search?q=hello+world#brs</code></pre>\n<p>对定义统一资源定位符（URL）语法的初始RFC进行了许多改进。当前定义通用URI语法的<a href=\"https://tools.ietf.org/html/rfc3986\" target=\"_blank\" rel=\"noopener\">RFC</a>是<a href=\"https://tools.ietf.org/html/rfc3986\" target=\"_blank\" rel=\"noopener\">RFC 3986</a>。这篇文章包含最新RFC文档中的信息。</p>\n<p>URL由属于US-ASCII字符集的有限字符集组成。这些字符包括数字（0-9），字母（AZ，az），以及一些特殊字符（<code>&quot;-&quot;</code>，<code>&quot;.&quot;</code>，<code>&quot;_&quot;</code>，<code>&quot;~&quot;</code>）。</p>\n<p>ASCII控制字符（例如退格，垂直制表符，水平制表，换行等），不安全的字符像<code>space</code>，<code>\\</code>，<code>&lt;</code>，<code>&gt;</code>，<code>{</code>，<code>}</code>等等，以及ASCII字符以外的任何字符被不允许直接的URL内放置。</p>\n<p>此外，URL中有些字符具有特殊含义。这些字符称为<strong>保留</strong>字符。的保留字符的一些例子是<code>?</code>，<code>/</code>，<code>#</code>，<code>:</code>等作为URL的一部分发送，无论是在查询字符串或路径段，必须不包含这些字符的任何数据。</p>\n<p>那么，当我们需要在URL中传输包含这些不允许的字符的任何数据时，我们该怎么办？好吧，<strong>我们对它们进行编码！</strong></p>\n<blockquote>\n<p>URL编码将URL中保留的，不安全的和非ASCII字符转换为所有Web浏览器和服务器普遍接受并理解的格式。它首先将字符转换为一个或多个字节。然后，每个字节由两个十六进制数字表示，后跟一个百分号（<code>%</code>）-（例如<code>%xy</code>）。百分号用作转义字符。</p>\n</blockquote>\n<p>URL编码也称为百分比编码，因为它使用百分号（<code>%</code>）作为转义字符。</p>\n<h4 id=\"URL编码示例\"><a href=\"#URL编码示例\" class=\"headerlink\" title=\"URL编码示例\"></a>URL编码示例</h4><p><strong>空格：</strong>您可能会遇到的最常见的URL编码字符是<code>space</code>。<code>space</code>十进制字符的ASCII码为<code>32</code>，转换为十六进制时为<code>20</code>。现在，我们在十六进制表示形式之前加一个百分号（<code>%</code>），这使我们获得了URL编码值- <code>%20</code>。</p>\n<p><strong>+:</strong> 看到我一开始代码里的replace，那是因为：</p>\n<p><img src=\"/2020/03/08/kongzheng1993-URLEncode/C:%5CUsers%5Ckongz%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200317181423078.png\" alt=\"image-20200317181423078\"></p>\n<p>w3c的规定是空格被替换为<code>+</code>，Java中的URLEncoder正式这种情况，会把空格转成<code>+</code></p>\n<p><img src=\"/2020/03/08/kongzheng1993-URLEncode/C:%5CUsers%5Ckongz%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200317182519016.png\" alt=\"image-20200317182519016\"></p>\n<p>这就会导致在一些遵循RFC的应用上无法解码或其他问题，所以我们取一个折中的方法，要在<code>URLEncoder.encode()</code>之后把<code>+</code>替换为<code>%20</code></p>\n<h2 id=\"ASCII字符编码参考\"><a href=\"#ASCII字符编码参考\" class=\"headerlink\" title=\"ASCII字符编码参考\"></a>ASCII字符编码参考</h2><p>下表是ASCII字符对其相应的URL编码形式的引用。</p>\n<blockquote>\n<p>请注意，不需要编码字母数字ASCII字符。例如，您不需要编码字符<code>&#39;0&#39;</code>以<code>%30</code>如图所示下表。可以原样发送。但是根据RFC编码仍然有效。表格中所有可以安全地在URL中传输的字符都显示为绿色。</p>\n</blockquote>\n<p><strong>下表使用RFC 3986中定义的URL编码规则。</strong></p>\n<table>\n<thead>\n<tr>\n<th align=\"left\">Decimal</th>\n<th align=\"left\">Character</th>\n<th align=\"left\">URL Encoding (UTF-8)</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\">0</td>\n<td align=\"left\">NUL(null character)</td>\n<td align=\"left\">%00</td>\n</tr>\n<tr>\n<td align=\"left\">1</td>\n<td align=\"left\">SOH(start of header)</td>\n<td align=\"left\">%01</td>\n</tr>\n<tr>\n<td align=\"left\">2</td>\n<td align=\"left\">STX(start of text)</td>\n<td align=\"left\">%02</td>\n</tr>\n<tr>\n<td align=\"left\">3</td>\n<td align=\"left\">ETX(end of text)</td>\n<td align=\"left\">%03</td>\n</tr>\n<tr>\n<td align=\"left\">4</td>\n<td align=\"left\">EOT(end of transmission)</td>\n<td align=\"left\">%04</td>\n</tr>\n<tr>\n<td align=\"left\">5</td>\n<td align=\"left\">ENQ(enquiry)</td>\n<td align=\"left\">%05</td>\n</tr>\n<tr>\n<td align=\"left\">6</td>\n<td align=\"left\">ACK(acknowledge)</td>\n<td align=\"left\">%06</td>\n</tr>\n<tr>\n<td align=\"left\">7</td>\n<td align=\"left\">BEL(bell (ring))</td>\n<td align=\"left\">%07</td>\n</tr>\n<tr>\n<td align=\"left\">8</td>\n<td align=\"left\">BS(backspace)</td>\n<td align=\"left\">%08</td>\n</tr>\n<tr>\n<td align=\"left\">9</td>\n<td align=\"left\">HT(horizontal tab)</td>\n<td align=\"left\">%09</td>\n</tr>\n<tr>\n<td align=\"left\">10</td>\n<td align=\"left\">LF(line feed)</td>\n<td align=\"left\">%0A</td>\n</tr>\n<tr>\n<td align=\"left\">11</td>\n<td align=\"left\">VT(vertical tab)</td>\n<td align=\"left\">%0B</td>\n</tr>\n<tr>\n<td align=\"left\">12</td>\n<td align=\"left\">FF(form feed)</td>\n<td align=\"left\">%0C</td>\n</tr>\n<tr>\n<td align=\"left\">13</td>\n<td align=\"left\">CR(carriage return)</td>\n<td align=\"left\">%0D</td>\n</tr>\n<tr>\n<td align=\"left\">14</td>\n<td align=\"left\">SO(shift out)</td>\n<td align=\"left\">%0E</td>\n</tr>\n<tr>\n<td align=\"left\">15</td>\n<td align=\"left\">SI(shift in)</td>\n<td align=\"left\">%0F</td>\n</tr>\n<tr>\n<td align=\"left\">16</td>\n<td align=\"left\">DLE(data link escape)</td>\n<td align=\"left\">%10</td>\n</tr>\n<tr>\n<td align=\"left\">17</td>\n<td align=\"left\">DC1(device control 1)</td>\n<td align=\"left\">%11</td>\n</tr>\n<tr>\n<td align=\"left\">18</td>\n<td align=\"left\">DC2(device control 2)</td>\n<td align=\"left\">%12</td>\n</tr>\n<tr>\n<td align=\"left\">19</td>\n<td align=\"left\">DC3(device control 3)</td>\n<td align=\"left\">%13</td>\n</tr>\n<tr>\n<td align=\"left\">20</td>\n<td align=\"left\">DC4(device control 4)</td>\n<td align=\"left\">%14</td>\n</tr>\n<tr>\n<td align=\"left\">21</td>\n<td align=\"left\">NAK(negative acknowledge)</td>\n<td align=\"left\">%15</td>\n</tr>\n<tr>\n<td align=\"left\">22</td>\n<td align=\"left\">SYN(synchronize)</td>\n<td align=\"left\">%16</td>\n</tr>\n<tr>\n<td align=\"left\">23</td>\n<td align=\"left\">ETB(end transmission block)</td>\n<td align=\"left\">%17</td>\n</tr>\n<tr>\n<td align=\"left\">24</td>\n<td align=\"left\">CAN(cancel)</td>\n<td align=\"left\">%18</td>\n</tr>\n<tr>\n<td align=\"left\">25</td>\n<td align=\"left\">EM(end of medium)</td>\n<td align=\"left\">%19</td>\n</tr>\n<tr>\n<td align=\"left\">26</td>\n<td align=\"left\">SUB(substitute)</td>\n<td align=\"left\">%1A</td>\n</tr>\n<tr>\n<td align=\"left\">27</td>\n<td align=\"left\">ESC(escape)</td>\n<td align=\"left\">%1B</td>\n</tr>\n<tr>\n<td align=\"left\">28</td>\n<td align=\"left\">FS(file separator)</td>\n<td align=\"left\">%1C</td>\n</tr>\n<tr>\n<td align=\"left\">29</td>\n<td align=\"left\">GS(group separator)</td>\n<td align=\"left\">%1D</td>\n</tr>\n<tr>\n<td align=\"left\">30</td>\n<td align=\"left\">RS(record separator)</td>\n<td align=\"left\">%1E</td>\n</tr>\n<tr>\n<td align=\"left\">31</td>\n<td align=\"left\">US(unit separator)</td>\n<td align=\"left\">%1F</td>\n</tr>\n<tr>\n<td align=\"left\">32</td>\n<td align=\"left\">space</td>\n<td align=\"left\">%20</td>\n</tr>\n<tr>\n<td align=\"left\">33</td>\n<td align=\"left\">!</td>\n<td align=\"left\">%21</td>\n</tr>\n<tr>\n<td align=\"left\">34</td>\n<td align=\"left\">“</td>\n<td align=\"left\">%22</td>\n</tr>\n<tr>\n<td align=\"left\">35</td>\n<td align=\"left\">#</td>\n<td align=\"left\">%23</td>\n</tr>\n<tr>\n<td align=\"left\">36</td>\n<td align=\"left\">$</td>\n<td align=\"left\">%24</td>\n</tr>\n<tr>\n<td align=\"left\">37</td>\n<td align=\"left\">%</td>\n<td align=\"left\">%25</td>\n</tr>\n<tr>\n<td align=\"left\">38</td>\n<td align=\"left\">&amp;</td>\n<td align=\"left\">%26</td>\n</tr>\n<tr>\n<td align=\"left\">39</td>\n<td align=\"left\">‘</td>\n<td align=\"left\">%27</td>\n</tr>\n<tr>\n<td align=\"left\">40</td>\n<td align=\"left\">(</td>\n<td align=\"left\">%28</td>\n</tr>\n<tr>\n<td align=\"left\">41</td>\n<td align=\"left\">)</td>\n<td align=\"left\">%29</td>\n</tr>\n<tr>\n<td align=\"left\">42</td>\n<td align=\"left\">*</td>\n<td align=\"left\">%2A</td>\n</tr>\n<tr>\n<td align=\"left\">43</td>\n<td align=\"left\">+</td>\n<td align=\"left\">%2B</td>\n</tr>\n<tr>\n<td align=\"left\">44</td>\n<td align=\"left\">,</td>\n<td align=\"left\">%2C</td>\n</tr>\n<tr>\n<td align=\"left\">45</td>\n<td align=\"left\">-</td>\n<td align=\"left\">%2D</td>\n</tr>\n<tr>\n<td align=\"left\">46</td>\n<td align=\"left\">.</td>\n<td align=\"left\">%2E</td>\n</tr>\n<tr>\n<td align=\"left\">47</td>\n<td align=\"left\">/</td>\n<td align=\"left\">%2F</td>\n</tr>\n<tr>\n<td align=\"left\">48</td>\n<td align=\"left\">0</td>\n<td align=\"left\">%30</td>\n</tr>\n<tr>\n<td align=\"left\">49</td>\n<td align=\"left\">1</td>\n<td align=\"left\">%31</td>\n</tr>\n<tr>\n<td align=\"left\">50</td>\n<td align=\"left\">2</td>\n<td align=\"left\">%32</td>\n</tr>\n<tr>\n<td align=\"left\">51</td>\n<td align=\"left\">3</td>\n<td align=\"left\">%33</td>\n</tr>\n<tr>\n<td align=\"left\">52</td>\n<td align=\"left\">4</td>\n<td align=\"left\">%34</td>\n</tr>\n<tr>\n<td align=\"left\">53</td>\n<td align=\"left\">5</td>\n<td align=\"left\">%35</td>\n</tr>\n<tr>\n<td align=\"left\">54</td>\n<td align=\"left\">6</td>\n<td align=\"left\">%36</td>\n</tr>\n<tr>\n<td align=\"left\">55</td>\n<td align=\"left\">7</td>\n<td align=\"left\">%37</td>\n</tr>\n<tr>\n<td align=\"left\">56</td>\n<td align=\"left\">8</td>\n<td align=\"left\">%38</td>\n</tr>\n<tr>\n<td align=\"left\">57</td>\n<td align=\"left\">9</td>\n<td align=\"left\">%39</td>\n</tr>\n<tr>\n<td align=\"left\">58</td>\n<td align=\"left\">:</td>\n<td align=\"left\">%3A</td>\n</tr>\n<tr>\n<td align=\"left\">59</td>\n<td align=\"left\">;</td>\n<td align=\"left\">%3B</td>\n</tr>\n<tr>\n<td align=\"left\">60</td>\n<td align=\"left\">&lt;</td>\n<td align=\"left\">%3C</td>\n</tr>\n<tr>\n<td align=\"left\">61</td>\n<td align=\"left\">=</td>\n<td align=\"left\">%3D</td>\n</tr>\n<tr>\n<td align=\"left\">62</td>\n<td align=\"left\">&gt;</td>\n<td align=\"left\">%3E</td>\n</tr>\n<tr>\n<td align=\"left\">63</td>\n<td align=\"left\">?</td>\n<td align=\"left\">%3F</td>\n</tr>\n<tr>\n<td align=\"left\">64</td>\n<td align=\"left\">@</td>\n<td align=\"left\">%40</td>\n</tr>\n<tr>\n<td align=\"left\">65</td>\n<td align=\"left\">A</td>\n<td align=\"left\">%41</td>\n</tr>\n<tr>\n<td align=\"left\">66</td>\n<td align=\"left\">B</td>\n<td align=\"left\">%42</td>\n</tr>\n<tr>\n<td align=\"left\">67</td>\n<td align=\"left\">C</td>\n<td align=\"left\">%43</td>\n</tr>\n<tr>\n<td align=\"left\">68</td>\n<td align=\"left\">D</td>\n<td align=\"left\">%44</td>\n</tr>\n<tr>\n<td align=\"left\">69</td>\n<td align=\"left\">E</td>\n<td align=\"left\">%45</td>\n</tr>\n<tr>\n<td align=\"left\">70</td>\n<td align=\"left\">F</td>\n<td align=\"left\">%46</td>\n</tr>\n<tr>\n<td align=\"left\">71</td>\n<td align=\"left\">G</td>\n<td align=\"left\">%47</td>\n</tr>\n<tr>\n<td align=\"left\">72</td>\n<td align=\"left\">H</td>\n<td align=\"left\">%48</td>\n</tr>\n<tr>\n<td align=\"left\">73</td>\n<td align=\"left\">I</td>\n<td align=\"left\">%49</td>\n</tr>\n<tr>\n<td align=\"left\">74</td>\n<td align=\"left\">J</td>\n<td align=\"left\">%4A</td>\n</tr>\n<tr>\n<td align=\"left\">75</td>\n<td align=\"left\">K</td>\n<td align=\"left\">%4B</td>\n</tr>\n<tr>\n<td align=\"left\">76</td>\n<td align=\"left\">L</td>\n<td align=\"left\">%4C</td>\n</tr>\n<tr>\n<td align=\"left\">77</td>\n<td align=\"left\">M</td>\n<td align=\"left\">%4D</td>\n</tr>\n<tr>\n<td align=\"left\">78</td>\n<td align=\"left\">N</td>\n<td align=\"left\">%4E</td>\n</tr>\n<tr>\n<td align=\"left\">79</td>\n<td align=\"left\">O</td>\n<td align=\"left\">%4F</td>\n</tr>\n<tr>\n<td align=\"left\">80</td>\n<td align=\"left\">P</td>\n<td align=\"left\">%50</td>\n</tr>\n<tr>\n<td align=\"left\">81</td>\n<td align=\"left\">Q</td>\n<td align=\"left\">%51</td>\n</tr>\n<tr>\n<td align=\"left\">82</td>\n<td align=\"left\">R</td>\n<td align=\"left\">%52</td>\n</tr>\n<tr>\n<td align=\"left\">83</td>\n<td align=\"left\">S</td>\n<td align=\"left\">%53</td>\n</tr>\n<tr>\n<td align=\"left\">84</td>\n<td align=\"left\">T</td>\n<td align=\"left\">%54</td>\n</tr>\n<tr>\n<td align=\"left\">85</td>\n<td align=\"left\">U</td>\n<td align=\"left\">%55</td>\n</tr>\n<tr>\n<td align=\"left\">86</td>\n<td align=\"left\">V</td>\n<td align=\"left\">%56</td>\n</tr>\n<tr>\n<td align=\"left\">87</td>\n<td align=\"left\">W</td>\n<td align=\"left\">%57</td>\n</tr>\n<tr>\n<td align=\"left\">88</td>\n<td align=\"left\">X</td>\n<td align=\"left\">%58</td>\n</tr>\n<tr>\n<td align=\"left\">89</td>\n<td align=\"left\">Y</td>\n<td align=\"left\">%59</td>\n</tr>\n<tr>\n<td align=\"left\">90</td>\n<td align=\"left\">Z</td>\n<td align=\"left\">%5A</td>\n</tr>\n<tr>\n<td align=\"left\">91</td>\n<td align=\"left\">[</td>\n<td align=\"left\">%5B</td>\n</tr>\n<tr>\n<td align=\"left\">92</td>\n<td align=\"left\">\\</td>\n<td align=\"left\">%5C</td>\n</tr>\n<tr>\n<td align=\"left\">93</td>\n<td align=\"left\">]</td>\n<td align=\"left\">%5D</td>\n</tr>\n<tr>\n<td align=\"left\">94</td>\n<td align=\"left\">^</td>\n<td align=\"left\">%5E</td>\n</tr>\n<tr>\n<td align=\"left\">95</td>\n<td align=\"left\">_</td>\n<td align=\"left\">%5F</td>\n</tr>\n<tr>\n<td align=\"left\">96</td>\n<td align=\"left\">`</td>\n<td align=\"left\">%60</td>\n</tr>\n<tr>\n<td align=\"left\">97</td>\n<td align=\"left\">a</td>\n<td align=\"left\">%61</td>\n</tr>\n<tr>\n<td align=\"left\">98</td>\n<td align=\"left\">b</td>\n<td align=\"left\">%62</td>\n</tr>\n<tr>\n<td align=\"left\">99</td>\n<td align=\"left\">c</td>\n<td align=\"left\">%63</td>\n</tr>\n<tr>\n<td align=\"left\">100</td>\n<td align=\"left\">d</td>\n<td align=\"left\">%64</td>\n</tr>\n<tr>\n<td align=\"left\">101</td>\n<td align=\"left\">e</td>\n<td align=\"left\">%65</td>\n</tr>\n<tr>\n<td align=\"left\">102</td>\n<td align=\"left\">f</td>\n<td align=\"left\">%66</td>\n</tr>\n<tr>\n<td align=\"left\">103</td>\n<td align=\"left\">g</td>\n<td align=\"left\">%67</td>\n</tr>\n<tr>\n<td align=\"left\">104</td>\n<td align=\"left\">h</td>\n<td align=\"left\">%68</td>\n</tr>\n<tr>\n<td align=\"left\">105</td>\n<td align=\"left\">i</td>\n<td align=\"left\">%69</td>\n</tr>\n<tr>\n<td align=\"left\">106</td>\n<td align=\"left\">j</td>\n<td align=\"left\">%6A</td>\n</tr>\n<tr>\n<td align=\"left\">107</td>\n<td align=\"left\">k</td>\n<td align=\"left\">%6B</td>\n</tr>\n<tr>\n<td align=\"left\">108</td>\n<td align=\"left\">l</td>\n<td align=\"left\">%6C</td>\n</tr>\n<tr>\n<td align=\"left\">109</td>\n<td align=\"left\">m</td>\n<td align=\"left\">%6D</td>\n</tr>\n<tr>\n<td align=\"left\">110</td>\n<td align=\"left\">n</td>\n<td align=\"left\">%6E</td>\n</tr>\n<tr>\n<td align=\"left\">111</td>\n<td align=\"left\">o</td>\n<td align=\"left\">%6F</td>\n</tr>\n<tr>\n<td align=\"left\">112</td>\n<td align=\"left\">p</td>\n<td align=\"left\">%70</td>\n</tr>\n<tr>\n<td align=\"left\">113</td>\n<td align=\"left\">q</td>\n<td align=\"left\">%71</td>\n</tr>\n<tr>\n<td align=\"left\">114</td>\n<td align=\"left\">r</td>\n<td align=\"left\">%72</td>\n</tr>\n<tr>\n<td align=\"left\">115</td>\n<td align=\"left\">s</td>\n<td align=\"left\">%73</td>\n</tr>\n<tr>\n<td align=\"left\">116</td>\n<td align=\"left\">t</td>\n<td align=\"left\">%74</td>\n</tr>\n<tr>\n<td align=\"left\">117</td>\n<td align=\"left\">u</td>\n<td align=\"left\">%75</td>\n</tr>\n<tr>\n<td align=\"left\">118</td>\n<td align=\"left\">v</td>\n<td align=\"left\">%76</td>\n</tr>\n<tr>\n<td align=\"left\">119</td>\n<td align=\"left\">w</td>\n<td align=\"left\">%77</td>\n</tr>\n<tr>\n<td align=\"left\">120</td>\n<td align=\"left\">x</td>\n<td align=\"left\">%78</td>\n</tr>\n<tr>\n<td align=\"left\">121</td>\n<td align=\"left\">y</td>\n<td align=\"left\">%79</td>\n</tr>\n<tr>\n<td align=\"left\">122</td>\n<td align=\"left\">z</td>\n<td align=\"left\">%7A</td>\n</tr>\n<tr>\n<td align=\"left\">123</td>\n<td align=\"left\">{</td>\n<td align=\"left\">%7B</td>\n</tr>\n<tr>\n<td align=\"left\">124</td>\n<td align=\"left\">|</td>\n<td align=\"left\">%7C</td>\n</tr>\n<tr>\n<td align=\"left\">125</td>\n<td align=\"left\">}</td>\n<td align=\"left\">%7D</td>\n</tr>\n<tr>\n<td align=\"left\">126</td>\n<td align=\"left\">~</td>\n<td align=\"left\">%7E</td>\n</tr>\n<tr>\n<td align=\"left\">127</td>\n<td align=\"left\">DEL(delete (rubout))</td>\n<td align=\"left\">%7F</td>\n</tr>\n</tbody></table>\n"},{"title":"记一次老代码优化","excerpt":"","comments":1,"top":1,"date":"2020-03-24T16:30:52.000Z","_content":"\n\n# 记一次老代码优化\n\n## 为什么要优化\n\n之前经常收到服务器告警信息，CPU占用率过高，当时用jstack分析了线程状态，确认是我们在处理接口返回报文时的大写+`_`转驼峰时效率太低导致的。\n\n同时我们发现很多调用超3s的接口都是因为响应报文太长，报文转换时间太长导致的。这是个亟待解决的问题。\n\n## 老代码分析\n\n我看了下老代码，之前的处理逻辑上很简单，但是效率上真的问题有点大。服务方给我们返回的报文是xml的，我们会转成json，这里的转换都是框架里的方法，作者都是大佬，很多人都在用，这里出问题的可能性微乎其微。往下是json格式的报文中key的转换，服务方返回的key都是大写的，`_`分隔单词。业务要求，我们要转成驼峰的。\n而这个转驼峰的方法，是用正则表达式，从json格式的字符串中匹配`\"xxx\":`来进行处理。正则表达式如下：\n\n```t\n\"([a-zA-z0-9_]*)\":\n```\n\n然后一个循环，如果找到一个符合此正则的字符串，就拿出来进行处理：\n\n1. 转换成小写\n2. 查找`_`，将`_X`替换为`x`\n\n如果报文比较短小，这问题不大，如果报文很多，这个查找的过程是很麻烦的。是在这个字符串里尝试各个子序列，各种组合…… 还要在匹配的子序列里查找`_`，想想就替cpu心累。\n\n## 优化思路\n\n根据老代码的分析，我们可以了解到，cpu占用率过高，应该就是在匹配正则的过程中，想想整个系统，多少qps，报文动辄几千个字符，多少子序列组合，多少次match操作。\n\n其实最简单的方法很快就能想到，接口都是有规范的，服务提供方返回的报文，和我们需要的驼峰样式，其实就是简单的字符串替换，但是要得到对应的驼峰样式的key，免不了解析收到的报文。\n\n### 第一个方案\n\n我们第一个思路就是，写死这些key\n\n比如，我们直接在代码里写如下的代码：\n\n```java\nresultMap.put(\"aaaBbb\",responContentMap.get(\"AAA_BBB\"));\nresultMap.put(\"cccDdd\",responContentMap.get(\"CCC_DDD\"));\nresultMap.put(\"xxxYyy\",responContentMap.get(\"XXX_YYY\"));\n```\n\n这么写没什么不行，不过同事们都不同意啊，麻烦啊，再说要是万一又有什么改动，还得改啊。而且我们很多接口只是单纯的将底层的报文转驼峰返回给调用方，本来不用这些`get`、`put`操作的，现在都要加上，几百个接口，各种查文档，改代码，想想谁都不愿意干吧。\n\n### 第二个方案\n\n我跟领导反映，说第一个方案这种改动真的是大，虽然是不难，但是量大啊。我把心想到的方案说出来，我想建一个表，反正`XXX_YYY`对应的就是`xxxYyy`，不会变，我们把它记下来，然后每次报文过来，直接查一遍表，把存在的都替换了。\n\n有人说，查数据库太慢了，几百个key，一次一次查是不是有点慢。这不算问题，我们可以用缓存，应用内缓存，guava cache、spring cache都很好用。再不济我们还可以手写一个静态map，启动的时候把数据从库里加载过来，直接把所有的key都替换一遍，不查找了。\n\n但是这样还有个问题，这个数据表得维护啊，每次如果新增一个接口，有个没出现过的key，我们得加上啊，不然到时候这个key替换不了的啊，每次手动去搞，我真的是不行啊，不知道啥时候就忘记了。\n\n### 第三个方案\n\n我想了一下，又一次拨通了领导的电话。\n这次我想，之前的算法，还得用，不过只用一次，那就是第一次。我们依然用正则匹配出所有的key，但是我们不直接去计算它对应的驼峰key，而是先去缓存查，如果有，直接替换，如果没有，还是之前的算法，整出来之后存到数据库，并加载到缓存。\n\n当然，存数据库这个毕竟还得有一次数据库连接，至少一次数据库操作，也是耗时的嘛，所以我起一个线程，异步去操作数据库。\n\n经过领导的同意，开始搞。\n\n## 编码\n\n- 旧方法\n\n```java\npublic static String ospInOutParmConvert(String str) {\n    Matcher m=p1.matcher(str);\n    String strTmp = \"\";\n    String strTmp1= \"\";\n    while(m.find()){\n        strTmp = m.group();\n        str = str.replace(strTmp, strTmp.toLowerCase());\n        if (StringUtil.isNotEmpty(strTmp) && strTmp != \"null\") {\n            strTmp1= strTmp.toLowerCase();\n            if (strTmp1.indexOf(\"_\") > 0) {\n                String[] strTmp1s = strTmp1.split(\"_\");\n                for(int i=0; i<strTmp1s.length-1; i++){\n                    int subInt = strTmp1.indexOf(\"_\");\n                    str = str.replace(strTmp1.substring(subInt,subInt + 2), strTmp1.substring(subInt + 1, subInt + 2).toUpperCase());\n                    if(strTmp1s.length>1){\n                        strTmp1 = strTmp1.substring(subInt+1);\n                    }\n                }\n            }\n        }\n    }\n    return str;\n}\n```\n\n- 新版（无缓存）\n\n```java\n    public static String ospInOutParmConvert1(String str) {\n        Map<String, String> nkCamelKeys = LocalJDBCUtil.getCamelKeyByNKKeys();\n        for (Map.Entry<String, String> entry : nkCamelKeys.entrySet()) {\n            str = str.replace(\"\\\"\" + entry.getKey() + \"\\\"\", \"\\\"\" + entry.getValue() + \"\\\"\");\n        }\n        return str;\n    }\n```\n\n- 新版（缓存）\n\n```java\npublic static String ospInOutParmConvert2(String str) {\n    Matcher m=p1.matcher(str);\n    String strTmp = \"\";\n    String strTmp1= \"\";\n    String nkKey = \"\";\n    String camelKey = \"\";\n    final Map<String, String> unSaveKeys = Maps.newHashMap();\n    while(m.find()){\n        strTmp = m.group();\n        nkKey = strTmp.replace(\"\\\"\", \"\").replace(\":\", \"\");\n        camelKey = nkCamelKeyCacheService.getCamelKeyByNKKey(nkKey);\n        if (StringUtils.isNotBlank(camelKey)) {\n            str = str.replace(nkKey, camelKey);\n            continue;\n        } else {\n            camelKey = nkKey.toLowerCase();\n            str = str.replace(strTmp, strTmp.toLowerCase());\n            if (StringUtil.isNotEmpty(strTmp) && strTmp != \"null\") {\n                strTmp1= strTmp.toLowerCase();\n                if (strTmp1.indexOf(\"_\") > 0) {\n                    String[] strTmp1s = strTmp1.split(\"_\");\n                    for(int i=0; i<strTmp1s.length-1; i++){\n                        int subInt = strTmp1.indexOf(\"_\");\n                        camelKey = camelKey.replace(strTmp1.substring(subInt,subInt + 2),strTmp1.substring(subInt + 1, subInt + 2).toUpperCase());\n                        if(strTmp1s.length>1){\n                            strTmp1 = strTmp1.substring(subInt+1);\n                        }\n                    }\n                    str = str.replace(nkKey, camelKey);\n                }\n                unSaveKeys.put(nkKey, camelKey);\n            }\n        }\n    }\n    if (unSaveKeys.size() > 0) {\n        new Thread(new Runnable() {\n            @Override\n            public void run() {\n                LocalJDBCUtil.addNkCamelKeys(unSaveKeys);\n            }\n        }).start();\n    }\n    return str;\n}\n```\n\n新的带缓存方法，也是用正则去匹配到key，然后拿key调用`getCamelKeyByNKKey`方法，这个方法用了`@Cacheable`注解，也就是用了spring cache来实现缓存。\n\n下面是缓存配置类：\n\n```java\n@Configuration\n@EnableCaching\npublic class CacheConfig {\n    @Primary\n    @Bean\n    public SimpleCacheManager simpleCacheManager(List<Cache> caches) {\n        SimpleCacheManager cacheManager = new SimpleCacheManager();\n\n        cacheManager.setCaches(caches);\n        return cacheManager;\n    }\n\n    @Bean(\"nkCamelKeysCache\")\n    public ConcurrentMapCacheFactoryBean nkCamelKeysCache() {\n        ConcurrentMapCacheFactoryBean nkCamelKeysCache = new ConcurrentMapCacheFactoryBean();\n        nkCamelKeysCache.setName(\"nkCamelKeysCache\");\n        return nkCamelKeysCache;\n    }\n}\n```\n\n下面是缓存服务：\n\n```java\n@Service(\"nkCamelKeyCacheService\")\npublic class NKCamelKeyCacheService {\n    @Cacheable(value = \"nkCamelKeysCache\")\n    public String getCamelKeyByNKKey(String nkKey) {\n        return LocalJDBCUtil.getCamelKeyByNKKey(nkKey);\n    }\n}\n```\n\n如果缓存没有命中，那么还是通过之前的老方法，不过这里我修改了一下用一个`unSaveKeys`变量来记录没有保存的key映射，然后起了一个匿名线程，去调用`addNkCamelKeys`方法，将`unSaveKeys`中的key存进数据库。\n\n## 测试\n\n我们用一个生产环境的报文来测试，16415个字符，应该算是较大的报文了。\n\n### 测试用例\n\n```java\n@BeforeClass\npublic static void init() {\n    AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext();\n    context.register(CacheConfig.class);\n    context.register(NKCamelKeyCacheService.class);\n    context.register(InterfacePlatformTools.class);\n    context.refresh();\n    nkCamelKeyCacheService = (NKCamelKeyCacheService) context.getBean(\"nkCamelKeyCacheService\");\n}\n@Before\npublic void getBeginTime() {\n    beginTime = System.currentTimeMillis();\n}\n@After\npublic void getEndTime() {\n    System.out.println(\"耗时:\" + (System.currentTimeMillis()-beginTime) + \"ms\");\n}\n@Test\npublic void test0() {\n    System.out.println(\"旧版驼峰转换测试结果：\" + InterfacePlatformTools.ospInOutParmConvert(content));\n}\n@Test\npublic void test1() {\n    System.out.println(\"新版驼峰转换测试结果：\" + InterfacePlatformTools.ospInOutParmConvert1(content));\n}\n@Test\npublic void test2() {\n    System.out.println(\"缓存版第一次（需要入库）测试结果：\" + InterfacePlatformTools.ospInOutParmConvert2(content));\n}\n@Test\npublic void test3() {\n    System.out.println(\"缓存版第二次（直接在缓存中读取）测试结果：\" + InterfacePlatformTools.ospInOutParmConvert2(content));\n}\n```\n\n### 测试结果\n\n```shell\n旧版驼峰转换测试结果：{\"errorinfo\":{\"message\":\"成功\",\"code\":0,\"busiSerialNo\":\"\"\n耗时:204ms\n2020-03-29 19:19:46,869 INFO  [main] com.cmos.crmpfcore.util.LocalJDBCUtil - ==\n新版驼峰转换(无缓存)测试结果：{\"errorinfo\":{\"message\":\"成功\",\"code\":0,\"busiSerialNo\":\"\"\n耗时:531ms\n缓存版第一次（需要入库）测试结果：{\"errorinfo\":{\"message\":\"成功\",\"code\":0,\"busi\n耗时:500ms\n缓存版第二次（直接在缓存中读取）测试结果：{\"errorinfo\":{\"message\":\"成功\",\"code\"\n耗时:24ms\n```\n\n可以看出，老版本的转换方法用了204ms，每次去查数据库因为要多次连接数据库进行查询操作，需要531ms，而使用了缓存的方法，第一次我们还没有加载缓存，需要500ms，而第二次直接在缓存中读取，24ms，只用了之前方法的1/10。\n\n如果你有更好的方案，欢迎联系我哦。","source":"_posts/2020-03-25-kongzheng1993-一次老代码优化.md","raw":"---\ntitle: 记一次老代码优化\nexcerpt: ''\ntags: [Java]\ncategories: [Java]\ncomments: true\ntop: 1\ndate: 2020-03-25 00:30:52\n---\n\n\n# 记一次老代码优化\n\n## 为什么要优化\n\n之前经常收到服务器告警信息，CPU占用率过高，当时用jstack分析了线程状态，确认是我们在处理接口返回报文时的大写+`_`转驼峰时效率太低导致的。\n\n同时我们发现很多调用超3s的接口都是因为响应报文太长，报文转换时间太长导致的。这是个亟待解决的问题。\n\n## 老代码分析\n\n我看了下老代码，之前的处理逻辑上很简单，但是效率上真的问题有点大。服务方给我们返回的报文是xml的，我们会转成json，这里的转换都是框架里的方法，作者都是大佬，很多人都在用，这里出问题的可能性微乎其微。往下是json格式的报文中key的转换，服务方返回的key都是大写的，`_`分隔单词。业务要求，我们要转成驼峰的。\n而这个转驼峰的方法，是用正则表达式，从json格式的字符串中匹配`\"xxx\":`来进行处理。正则表达式如下：\n\n```t\n\"([a-zA-z0-9_]*)\":\n```\n\n然后一个循环，如果找到一个符合此正则的字符串，就拿出来进行处理：\n\n1. 转换成小写\n2. 查找`_`，将`_X`替换为`x`\n\n如果报文比较短小，这问题不大，如果报文很多，这个查找的过程是很麻烦的。是在这个字符串里尝试各个子序列，各种组合…… 还要在匹配的子序列里查找`_`，想想就替cpu心累。\n\n## 优化思路\n\n根据老代码的分析，我们可以了解到，cpu占用率过高，应该就是在匹配正则的过程中，想想整个系统，多少qps，报文动辄几千个字符，多少子序列组合，多少次match操作。\n\n其实最简单的方法很快就能想到，接口都是有规范的，服务提供方返回的报文，和我们需要的驼峰样式，其实就是简单的字符串替换，但是要得到对应的驼峰样式的key，免不了解析收到的报文。\n\n### 第一个方案\n\n我们第一个思路就是，写死这些key\n\n比如，我们直接在代码里写如下的代码：\n\n```java\nresultMap.put(\"aaaBbb\",responContentMap.get(\"AAA_BBB\"));\nresultMap.put(\"cccDdd\",responContentMap.get(\"CCC_DDD\"));\nresultMap.put(\"xxxYyy\",responContentMap.get(\"XXX_YYY\"));\n```\n\n这么写没什么不行，不过同事们都不同意啊，麻烦啊，再说要是万一又有什么改动，还得改啊。而且我们很多接口只是单纯的将底层的报文转驼峰返回给调用方，本来不用这些`get`、`put`操作的，现在都要加上，几百个接口，各种查文档，改代码，想想谁都不愿意干吧。\n\n### 第二个方案\n\n我跟领导反映，说第一个方案这种改动真的是大，虽然是不难，但是量大啊。我把心想到的方案说出来，我想建一个表，反正`XXX_YYY`对应的就是`xxxYyy`，不会变，我们把它记下来，然后每次报文过来，直接查一遍表，把存在的都替换了。\n\n有人说，查数据库太慢了，几百个key，一次一次查是不是有点慢。这不算问题，我们可以用缓存，应用内缓存，guava cache、spring cache都很好用。再不济我们还可以手写一个静态map，启动的时候把数据从库里加载过来，直接把所有的key都替换一遍，不查找了。\n\n但是这样还有个问题，这个数据表得维护啊，每次如果新增一个接口，有个没出现过的key，我们得加上啊，不然到时候这个key替换不了的啊，每次手动去搞，我真的是不行啊，不知道啥时候就忘记了。\n\n### 第三个方案\n\n我想了一下，又一次拨通了领导的电话。\n这次我想，之前的算法，还得用，不过只用一次，那就是第一次。我们依然用正则匹配出所有的key，但是我们不直接去计算它对应的驼峰key，而是先去缓存查，如果有，直接替换，如果没有，还是之前的算法，整出来之后存到数据库，并加载到缓存。\n\n当然，存数据库这个毕竟还得有一次数据库连接，至少一次数据库操作，也是耗时的嘛，所以我起一个线程，异步去操作数据库。\n\n经过领导的同意，开始搞。\n\n## 编码\n\n- 旧方法\n\n```java\npublic static String ospInOutParmConvert(String str) {\n    Matcher m=p1.matcher(str);\n    String strTmp = \"\";\n    String strTmp1= \"\";\n    while(m.find()){\n        strTmp = m.group();\n        str = str.replace(strTmp, strTmp.toLowerCase());\n        if (StringUtil.isNotEmpty(strTmp) && strTmp != \"null\") {\n            strTmp1= strTmp.toLowerCase();\n            if (strTmp1.indexOf(\"_\") > 0) {\n                String[] strTmp1s = strTmp1.split(\"_\");\n                for(int i=0; i<strTmp1s.length-1; i++){\n                    int subInt = strTmp1.indexOf(\"_\");\n                    str = str.replace(strTmp1.substring(subInt,subInt + 2), strTmp1.substring(subInt + 1, subInt + 2).toUpperCase());\n                    if(strTmp1s.length>1){\n                        strTmp1 = strTmp1.substring(subInt+1);\n                    }\n                }\n            }\n        }\n    }\n    return str;\n}\n```\n\n- 新版（无缓存）\n\n```java\n    public static String ospInOutParmConvert1(String str) {\n        Map<String, String> nkCamelKeys = LocalJDBCUtil.getCamelKeyByNKKeys();\n        for (Map.Entry<String, String> entry : nkCamelKeys.entrySet()) {\n            str = str.replace(\"\\\"\" + entry.getKey() + \"\\\"\", \"\\\"\" + entry.getValue() + \"\\\"\");\n        }\n        return str;\n    }\n```\n\n- 新版（缓存）\n\n```java\npublic static String ospInOutParmConvert2(String str) {\n    Matcher m=p1.matcher(str);\n    String strTmp = \"\";\n    String strTmp1= \"\";\n    String nkKey = \"\";\n    String camelKey = \"\";\n    final Map<String, String> unSaveKeys = Maps.newHashMap();\n    while(m.find()){\n        strTmp = m.group();\n        nkKey = strTmp.replace(\"\\\"\", \"\").replace(\":\", \"\");\n        camelKey = nkCamelKeyCacheService.getCamelKeyByNKKey(nkKey);\n        if (StringUtils.isNotBlank(camelKey)) {\n            str = str.replace(nkKey, camelKey);\n            continue;\n        } else {\n            camelKey = nkKey.toLowerCase();\n            str = str.replace(strTmp, strTmp.toLowerCase());\n            if (StringUtil.isNotEmpty(strTmp) && strTmp != \"null\") {\n                strTmp1= strTmp.toLowerCase();\n                if (strTmp1.indexOf(\"_\") > 0) {\n                    String[] strTmp1s = strTmp1.split(\"_\");\n                    for(int i=0; i<strTmp1s.length-1; i++){\n                        int subInt = strTmp1.indexOf(\"_\");\n                        camelKey = camelKey.replace(strTmp1.substring(subInt,subInt + 2),strTmp1.substring(subInt + 1, subInt + 2).toUpperCase());\n                        if(strTmp1s.length>1){\n                            strTmp1 = strTmp1.substring(subInt+1);\n                        }\n                    }\n                    str = str.replace(nkKey, camelKey);\n                }\n                unSaveKeys.put(nkKey, camelKey);\n            }\n        }\n    }\n    if (unSaveKeys.size() > 0) {\n        new Thread(new Runnable() {\n            @Override\n            public void run() {\n                LocalJDBCUtil.addNkCamelKeys(unSaveKeys);\n            }\n        }).start();\n    }\n    return str;\n}\n```\n\n新的带缓存方法，也是用正则去匹配到key，然后拿key调用`getCamelKeyByNKKey`方法，这个方法用了`@Cacheable`注解，也就是用了spring cache来实现缓存。\n\n下面是缓存配置类：\n\n```java\n@Configuration\n@EnableCaching\npublic class CacheConfig {\n    @Primary\n    @Bean\n    public SimpleCacheManager simpleCacheManager(List<Cache> caches) {\n        SimpleCacheManager cacheManager = new SimpleCacheManager();\n\n        cacheManager.setCaches(caches);\n        return cacheManager;\n    }\n\n    @Bean(\"nkCamelKeysCache\")\n    public ConcurrentMapCacheFactoryBean nkCamelKeysCache() {\n        ConcurrentMapCacheFactoryBean nkCamelKeysCache = new ConcurrentMapCacheFactoryBean();\n        nkCamelKeysCache.setName(\"nkCamelKeysCache\");\n        return nkCamelKeysCache;\n    }\n}\n```\n\n下面是缓存服务：\n\n```java\n@Service(\"nkCamelKeyCacheService\")\npublic class NKCamelKeyCacheService {\n    @Cacheable(value = \"nkCamelKeysCache\")\n    public String getCamelKeyByNKKey(String nkKey) {\n        return LocalJDBCUtil.getCamelKeyByNKKey(nkKey);\n    }\n}\n```\n\n如果缓存没有命中，那么还是通过之前的老方法，不过这里我修改了一下用一个`unSaveKeys`变量来记录没有保存的key映射，然后起了一个匿名线程，去调用`addNkCamelKeys`方法，将`unSaveKeys`中的key存进数据库。\n\n## 测试\n\n我们用一个生产环境的报文来测试，16415个字符，应该算是较大的报文了。\n\n### 测试用例\n\n```java\n@BeforeClass\npublic static void init() {\n    AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext();\n    context.register(CacheConfig.class);\n    context.register(NKCamelKeyCacheService.class);\n    context.register(InterfacePlatformTools.class);\n    context.refresh();\n    nkCamelKeyCacheService = (NKCamelKeyCacheService) context.getBean(\"nkCamelKeyCacheService\");\n}\n@Before\npublic void getBeginTime() {\n    beginTime = System.currentTimeMillis();\n}\n@After\npublic void getEndTime() {\n    System.out.println(\"耗时:\" + (System.currentTimeMillis()-beginTime) + \"ms\");\n}\n@Test\npublic void test0() {\n    System.out.println(\"旧版驼峰转换测试结果：\" + InterfacePlatformTools.ospInOutParmConvert(content));\n}\n@Test\npublic void test1() {\n    System.out.println(\"新版驼峰转换测试结果：\" + InterfacePlatformTools.ospInOutParmConvert1(content));\n}\n@Test\npublic void test2() {\n    System.out.println(\"缓存版第一次（需要入库）测试结果：\" + InterfacePlatformTools.ospInOutParmConvert2(content));\n}\n@Test\npublic void test3() {\n    System.out.println(\"缓存版第二次（直接在缓存中读取）测试结果：\" + InterfacePlatformTools.ospInOutParmConvert2(content));\n}\n```\n\n### 测试结果\n\n```shell\n旧版驼峰转换测试结果：{\"errorinfo\":{\"message\":\"成功\",\"code\":0,\"busiSerialNo\":\"\"\n耗时:204ms\n2020-03-29 19:19:46,869 INFO  [main] com.cmos.crmpfcore.util.LocalJDBCUtil - ==\n新版驼峰转换(无缓存)测试结果：{\"errorinfo\":{\"message\":\"成功\",\"code\":0,\"busiSerialNo\":\"\"\n耗时:531ms\n缓存版第一次（需要入库）测试结果：{\"errorinfo\":{\"message\":\"成功\",\"code\":0,\"busi\n耗时:500ms\n缓存版第二次（直接在缓存中读取）测试结果：{\"errorinfo\":{\"message\":\"成功\",\"code\"\n耗时:24ms\n```\n\n可以看出，老版本的转换方法用了204ms，每次去查数据库因为要多次连接数据库进行查询操作，需要531ms，而使用了缓存的方法，第一次我们还没有加载缓存，需要500ms，而第二次直接在缓存中读取，24ms，只用了之前方法的1/10。\n\n如果你有更好的方案，欢迎联系我哦。","slug":"kongzheng1993-一次老代码优化","published":1,"updated":"2023-03-08T07:05:58.783Z","layout":"post","photos":[],"link":"","_id":"clg0k2apb00hqt26ff1sxdw6z","content":"<h1 id=\"记一次老代码优化\"><a href=\"#记一次老代码优化\" class=\"headerlink\" title=\"记一次老代码优化\"></a>记一次老代码优化</h1><h2 id=\"为什么要优化\"><a href=\"#为什么要优化\" class=\"headerlink\" title=\"为什么要优化\"></a>为什么要优化</h2><p>之前经常收到服务器告警信息，CPU占用率过高，当时用jstack分析了线程状态，确认是我们在处理接口返回报文时的大写+<code>_</code>转驼峰时效率太低导致的。</p>\n<p>同时我们发现很多调用超3s的接口都是因为响应报文太长，报文转换时间太长导致的。这是个亟待解决的问题。</p>\n<h2 id=\"老代码分析\"><a href=\"#老代码分析\" class=\"headerlink\" title=\"老代码分析\"></a>老代码分析</h2><p>我看了下老代码，之前的处理逻辑上很简单，但是效率上真的问题有点大。服务方给我们返回的报文是xml的，我们会转成json，这里的转换都是框架里的方法，作者都是大佬，很多人都在用，这里出问题的可能性微乎其微。往下是json格式的报文中key的转换，服务方返回的key都是大写的，<code>_</code>分隔单词。业务要求，我们要转成驼峰的。<br>而这个转驼峰的方法，是用正则表达式，从json格式的字符串中匹配<code>&quot;xxx&quot;:</code>来进行处理。正则表达式如下：</p>\n<pre><code class=\"t\">&quot;([a-zA-z0-9_]*)&quot;:</code></pre>\n<p>然后一个循环，如果找到一个符合此正则的字符串，就拿出来进行处理：</p>\n<ol>\n<li>转换成小写</li>\n<li>查找<code>_</code>，将<code>_X</code>替换为<code>x</code></li>\n</ol>\n<p>如果报文比较短小，这问题不大，如果报文很多，这个查找的过程是很麻烦的。是在这个字符串里尝试各个子序列，各种组合…… 还要在匹配的子序列里查找<code>_</code>，想想就替cpu心累。</p>\n<h2 id=\"优化思路\"><a href=\"#优化思路\" class=\"headerlink\" title=\"优化思路\"></a>优化思路</h2><p>根据老代码的分析，我们可以了解到，cpu占用率过高，应该就是在匹配正则的过程中，想想整个系统，多少qps，报文动辄几千个字符，多少子序列组合，多少次match操作。</p>\n<p>其实最简单的方法很快就能想到，接口都是有规范的，服务提供方返回的报文，和我们需要的驼峰样式，其实就是简单的字符串替换，但是要得到对应的驼峰样式的key，免不了解析收到的报文。</p>\n<h3 id=\"第一个方案\"><a href=\"#第一个方案\" class=\"headerlink\" title=\"第一个方案\"></a>第一个方案</h3><p>我们第一个思路就是，写死这些key</p>\n<p>比如，我们直接在代码里写如下的代码：</p>\n<pre><code class=\"java\">resultMap.put(&quot;aaaBbb&quot;,responContentMap.get(&quot;AAA_BBB&quot;));\nresultMap.put(&quot;cccDdd&quot;,responContentMap.get(&quot;CCC_DDD&quot;));\nresultMap.put(&quot;xxxYyy&quot;,responContentMap.get(&quot;XXX_YYY&quot;));</code></pre>\n<p>这么写没什么不行，不过同事们都不同意啊，麻烦啊，再说要是万一又有什么改动，还得改啊。而且我们很多接口只是单纯的将底层的报文转驼峰返回给调用方，本来不用这些<code>get</code>、<code>put</code>操作的，现在都要加上，几百个接口，各种查文档，改代码，想想谁都不愿意干吧。</p>\n<h3 id=\"第二个方案\"><a href=\"#第二个方案\" class=\"headerlink\" title=\"第二个方案\"></a>第二个方案</h3><p>我跟领导反映，说第一个方案这种改动真的是大，虽然是不难，但是量大啊。我把心想到的方案说出来，我想建一个表，反正<code>XXX_YYY</code>对应的就是<code>xxxYyy</code>，不会变，我们把它记下来，然后每次报文过来，直接查一遍表，把存在的都替换了。</p>\n<p>有人说，查数据库太慢了，几百个key，一次一次查是不是有点慢。这不算问题，我们可以用缓存，应用内缓存，guava cache、spring cache都很好用。再不济我们还可以手写一个静态map，启动的时候把数据从库里加载过来，直接把所有的key都替换一遍，不查找了。</p>\n<p>但是这样还有个问题，这个数据表得维护啊，每次如果新增一个接口，有个没出现过的key，我们得加上啊，不然到时候这个key替换不了的啊，每次手动去搞，我真的是不行啊，不知道啥时候就忘记了。</p>\n<h3 id=\"第三个方案\"><a href=\"#第三个方案\" class=\"headerlink\" title=\"第三个方案\"></a>第三个方案</h3><p>我想了一下，又一次拨通了领导的电话。<br>这次我想，之前的算法，还得用，不过只用一次，那就是第一次。我们依然用正则匹配出所有的key，但是我们不直接去计算它对应的驼峰key，而是先去缓存查，如果有，直接替换，如果没有，还是之前的算法，整出来之后存到数据库，并加载到缓存。</p>\n<p>当然，存数据库这个毕竟还得有一次数据库连接，至少一次数据库操作，也是耗时的嘛，所以我起一个线程，异步去操作数据库。</p>\n<p>经过领导的同意，开始搞。</p>\n<h2 id=\"编码\"><a href=\"#编码\" class=\"headerlink\" title=\"编码\"></a>编码</h2><ul>\n<li>旧方法</li>\n</ul>\n<pre><code class=\"java\">public static String ospInOutParmConvert(String str) {\n    Matcher m=p1.matcher(str);\n    String strTmp = &quot;&quot;;\n    String strTmp1= &quot;&quot;;\n    while(m.find()){\n        strTmp = m.group();\n        str = str.replace(strTmp, strTmp.toLowerCase());\n        if (StringUtil.isNotEmpty(strTmp) &amp;&amp; strTmp != &quot;null&quot;) {\n            strTmp1= strTmp.toLowerCase();\n            if (strTmp1.indexOf(&quot;_&quot;) &gt; 0) {\n                String[] strTmp1s = strTmp1.split(&quot;_&quot;);\n                for(int i=0; i&lt;strTmp1s.length-1; i++){\n                    int subInt = strTmp1.indexOf(&quot;_&quot;);\n                    str = str.replace(strTmp1.substring(subInt,subInt + 2), strTmp1.substring(subInt + 1, subInt + 2).toUpperCase());\n                    if(strTmp1s.length&gt;1){\n                        strTmp1 = strTmp1.substring(subInt+1);\n                    }\n                }\n            }\n        }\n    }\n    return str;\n}</code></pre>\n<ul>\n<li>新版（无缓存）</li>\n</ul>\n<pre><code class=\"java\">    public static String ospInOutParmConvert1(String str) {\n        Map&lt;String, String&gt; nkCamelKeys = LocalJDBCUtil.getCamelKeyByNKKeys();\n        for (Map.Entry&lt;String, String&gt; entry : nkCamelKeys.entrySet()) {\n            str = str.replace(&quot;\\&quot;&quot; + entry.getKey() + &quot;\\&quot;&quot;, &quot;\\&quot;&quot; + entry.getValue() + &quot;\\&quot;&quot;);\n        }\n        return str;\n    }</code></pre>\n<ul>\n<li>新版（缓存）</li>\n</ul>\n<pre><code class=\"java\">public static String ospInOutParmConvert2(String str) {\n    Matcher m=p1.matcher(str);\n    String strTmp = &quot;&quot;;\n    String strTmp1= &quot;&quot;;\n    String nkKey = &quot;&quot;;\n    String camelKey = &quot;&quot;;\n    final Map&lt;String, String&gt; unSaveKeys = Maps.newHashMap();\n    while(m.find()){\n        strTmp = m.group();\n        nkKey = strTmp.replace(&quot;\\&quot;&quot;, &quot;&quot;).replace(&quot;:&quot;, &quot;&quot;);\n        camelKey = nkCamelKeyCacheService.getCamelKeyByNKKey(nkKey);\n        if (StringUtils.isNotBlank(camelKey)) {\n            str = str.replace(nkKey, camelKey);\n            continue;\n        } else {\n            camelKey = nkKey.toLowerCase();\n            str = str.replace(strTmp, strTmp.toLowerCase());\n            if (StringUtil.isNotEmpty(strTmp) &amp;&amp; strTmp != &quot;null&quot;) {\n                strTmp1= strTmp.toLowerCase();\n                if (strTmp1.indexOf(&quot;_&quot;) &gt; 0) {\n                    String[] strTmp1s = strTmp1.split(&quot;_&quot;);\n                    for(int i=0; i&lt;strTmp1s.length-1; i++){\n                        int subInt = strTmp1.indexOf(&quot;_&quot;);\n                        camelKey = camelKey.replace(strTmp1.substring(subInt,subInt + 2),strTmp1.substring(subInt + 1, subInt + 2).toUpperCase());\n                        if(strTmp1s.length&gt;1){\n                            strTmp1 = strTmp1.substring(subInt+1);\n                        }\n                    }\n                    str = str.replace(nkKey, camelKey);\n                }\n                unSaveKeys.put(nkKey, camelKey);\n            }\n        }\n    }\n    if (unSaveKeys.size() &gt; 0) {\n        new Thread(new Runnable() {\n            @Override\n            public void run() {\n                LocalJDBCUtil.addNkCamelKeys(unSaveKeys);\n            }\n        }).start();\n    }\n    return str;\n}</code></pre>\n<p>新的带缓存方法，也是用正则去匹配到key，然后拿key调用<code>getCamelKeyByNKKey</code>方法，这个方法用了<code>@Cacheable</code>注解，也就是用了spring cache来实现缓存。</p>\n<p>下面是缓存配置类：</p>\n<pre><code class=\"java\">@Configuration\n@EnableCaching\npublic class CacheConfig {\n    @Primary\n    @Bean\n    public SimpleCacheManager simpleCacheManager(List&lt;Cache&gt; caches) {\n        SimpleCacheManager cacheManager = new SimpleCacheManager();\n\n        cacheManager.setCaches(caches);\n        return cacheManager;\n    }\n\n    @Bean(&quot;nkCamelKeysCache&quot;)\n    public ConcurrentMapCacheFactoryBean nkCamelKeysCache() {\n        ConcurrentMapCacheFactoryBean nkCamelKeysCache = new ConcurrentMapCacheFactoryBean();\n        nkCamelKeysCache.setName(&quot;nkCamelKeysCache&quot;);\n        return nkCamelKeysCache;\n    }\n}</code></pre>\n<p>下面是缓存服务：</p>\n<pre><code class=\"java\">@Service(&quot;nkCamelKeyCacheService&quot;)\npublic class NKCamelKeyCacheService {\n    @Cacheable(value = &quot;nkCamelKeysCache&quot;)\n    public String getCamelKeyByNKKey(String nkKey) {\n        return LocalJDBCUtil.getCamelKeyByNKKey(nkKey);\n    }\n}</code></pre>\n<p>如果缓存没有命中，那么还是通过之前的老方法，不过这里我修改了一下用一个<code>unSaveKeys</code>变量来记录没有保存的key映射，然后起了一个匿名线程，去调用<code>addNkCamelKeys</code>方法，将<code>unSaveKeys</code>中的key存进数据库。</p>\n<h2 id=\"测试\"><a href=\"#测试\" class=\"headerlink\" title=\"测试\"></a>测试</h2><p>我们用一个生产环境的报文来测试，16415个字符，应该算是较大的报文了。</p>\n<h3 id=\"测试用例\"><a href=\"#测试用例\" class=\"headerlink\" title=\"测试用例\"></a>测试用例</h3><pre><code class=\"java\">@BeforeClass\npublic static void init() {\n    AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext();\n    context.register(CacheConfig.class);\n    context.register(NKCamelKeyCacheService.class);\n    context.register(InterfacePlatformTools.class);\n    context.refresh();\n    nkCamelKeyCacheService = (NKCamelKeyCacheService) context.getBean(&quot;nkCamelKeyCacheService&quot;);\n}\n@Before\npublic void getBeginTime() {\n    beginTime = System.currentTimeMillis();\n}\n@After\npublic void getEndTime() {\n    System.out.println(&quot;耗时:&quot; + (System.currentTimeMillis()-beginTime) + &quot;ms&quot;);\n}\n@Test\npublic void test0() {\n    System.out.println(&quot;旧版驼峰转换测试结果：&quot; + InterfacePlatformTools.ospInOutParmConvert(content));\n}\n@Test\npublic void test1() {\n    System.out.println(&quot;新版驼峰转换测试结果：&quot; + InterfacePlatformTools.ospInOutParmConvert1(content));\n}\n@Test\npublic void test2() {\n    System.out.println(&quot;缓存版第一次（需要入库）测试结果：&quot; + InterfacePlatformTools.ospInOutParmConvert2(content));\n}\n@Test\npublic void test3() {\n    System.out.println(&quot;缓存版第二次（直接在缓存中读取）测试结果：&quot; + InterfacePlatformTools.ospInOutParmConvert2(content));\n}</code></pre>\n<h3 id=\"测试结果\"><a href=\"#测试结果\" class=\"headerlink\" title=\"测试结果\"></a>测试结果</h3><pre><code class=\"shell\">旧版驼峰转换测试结果：{&quot;errorinfo&quot;:{&quot;message&quot;:&quot;成功&quot;,&quot;code&quot;:0,&quot;busiSerialNo&quot;:&quot;&quot;\n耗时:204ms\n2020-03-29 19:19:46,869 INFO  [main] com.cmos.crmpfcore.util.LocalJDBCUtil - ==\n新版驼峰转换(无缓存)测试结果：{&quot;errorinfo&quot;:{&quot;message&quot;:&quot;成功&quot;,&quot;code&quot;:0,&quot;busiSerialNo&quot;:&quot;&quot;\n耗时:531ms\n缓存版第一次（需要入库）测试结果：{&quot;errorinfo&quot;:{&quot;message&quot;:&quot;成功&quot;,&quot;code&quot;:0,&quot;busi\n耗时:500ms\n缓存版第二次（直接在缓存中读取）测试结果：{&quot;errorinfo&quot;:{&quot;message&quot;:&quot;成功&quot;,&quot;code&quot;\n耗时:24ms</code></pre>\n<p>可以看出，老版本的转换方法用了204ms，每次去查数据库因为要多次连接数据库进行查询操作，需要531ms，而使用了缓存的方法，第一次我们还没有加载缓存，需要500ms，而第二次直接在缓存中读取，24ms，只用了之前方法的1/10。</p>\n<p>如果你有更好的方案，欢迎联系我哦。</p>\n","site":{"data":{}},"more":"<h1 id=\"记一次老代码优化\"><a href=\"#记一次老代码优化\" class=\"headerlink\" title=\"记一次老代码优化\"></a>记一次老代码优化</h1><h2 id=\"为什么要优化\"><a href=\"#为什么要优化\" class=\"headerlink\" title=\"为什么要优化\"></a>为什么要优化</h2><p>之前经常收到服务器告警信息，CPU占用率过高，当时用jstack分析了线程状态，确认是我们在处理接口返回报文时的大写+<code>_</code>转驼峰时效率太低导致的。</p>\n<p>同时我们发现很多调用超3s的接口都是因为响应报文太长，报文转换时间太长导致的。这是个亟待解决的问题。</p>\n<h2 id=\"老代码分析\"><a href=\"#老代码分析\" class=\"headerlink\" title=\"老代码分析\"></a>老代码分析</h2><p>我看了下老代码，之前的处理逻辑上很简单，但是效率上真的问题有点大。服务方给我们返回的报文是xml的，我们会转成json，这里的转换都是框架里的方法，作者都是大佬，很多人都在用，这里出问题的可能性微乎其微。往下是json格式的报文中key的转换，服务方返回的key都是大写的，<code>_</code>分隔单词。业务要求，我们要转成驼峰的。<br>而这个转驼峰的方法，是用正则表达式，从json格式的字符串中匹配<code>&quot;xxx&quot;:</code>来进行处理。正则表达式如下：</p>\n<pre><code class=\"t\">&quot;([a-zA-z0-9_]*)&quot;:</code></pre>\n<p>然后一个循环，如果找到一个符合此正则的字符串，就拿出来进行处理：</p>\n<ol>\n<li>转换成小写</li>\n<li>查找<code>_</code>，将<code>_X</code>替换为<code>x</code></li>\n</ol>\n<p>如果报文比较短小，这问题不大，如果报文很多，这个查找的过程是很麻烦的。是在这个字符串里尝试各个子序列，各种组合…… 还要在匹配的子序列里查找<code>_</code>，想想就替cpu心累。</p>\n<h2 id=\"优化思路\"><a href=\"#优化思路\" class=\"headerlink\" title=\"优化思路\"></a>优化思路</h2><p>根据老代码的分析，我们可以了解到，cpu占用率过高，应该就是在匹配正则的过程中，想想整个系统，多少qps，报文动辄几千个字符，多少子序列组合，多少次match操作。</p>\n<p>其实最简单的方法很快就能想到，接口都是有规范的，服务提供方返回的报文，和我们需要的驼峰样式，其实就是简单的字符串替换，但是要得到对应的驼峰样式的key，免不了解析收到的报文。</p>\n<h3 id=\"第一个方案\"><a href=\"#第一个方案\" class=\"headerlink\" title=\"第一个方案\"></a>第一个方案</h3><p>我们第一个思路就是，写死这些key</p>\n<p>比如，我们直接在代码里写如下的代码：</p>\n<pre><code class=\"java\">resultMap.put(&quot;aaaBbb&quot;,responContentMap.get(&quot;AAA_BBB&quot;));\nresultMap.put(&quot;cccDdd&quot;,responContentMap.get(&quot;CCC_DDD&quot;));\nresultMap.put(&quot;xxxYyy&quot;,responContentMap.get(&quot;XXX_YYY&quot;));</code></pre>\n<p>这么写没什么不行，不过同事们都不同意啊，麻烦啊，再说要是万一又有什么改动，还得改啊。而且我们很多接口只是单纯的将底层的报文转驼峰返回给调用方，本来不用这些<code>get</code>、<code>put</code>操作的，现在都要加上，几百个接口，各种查文档，改代码，想想谁都不愿意干吧。</p>\n<h3 id=\"第二个方案\"><a href=\"#第二个方案\" class=\"headerlink\" title=\"第二个方案\"></a>第二个方案</h3><p>我跟领导反映，说第一个方案这种改动真的是大，虽然是不难，但是量大啊。我把心想到的方案说出来，我想建一个表，反正<code>XXX_YYY</code>对应的就是<code>xxxYyy</code>，不会变，我们把它记下来，然后每次报文过来，直接查一遍表，把存在的都替换了。</p>\n<p>有人说，查数据库太慢了，几百个key，一次一次查是不是有点慢。这不算问题，我们可以用缓存，应用内缓存，guava cache、spring cache都很好用。再不济我们还可以手写一个静态map，启动的时候把数据从库里加载过来，直接把所有的key都替换一遍，不查找了。</p>\n<p>但是这样还有个问题，这个数据表得维护啊，每次如果新增一个接口，有个没出现过的key，我们得加上啊，不然到时候这个key替换不了的啊，每次手动去搞，我真的是不行啊，不知道啥时候就忘记了。</p>\n<h3 id=\"第三个方案\"><a href=\"#第三个方案\" class=\"headerlink\" title=\"第三个方案\"></a>第三个方案</h3><p>我想了一下，又一次拨通了领导的电话。<br>这次我想，之前的算法，还得用，不过只用一次，那就是第一次。我们依然用正则匹配出所有的key，但是我们不直接去计算它对应的驼峰key，而是先去缓存查，如果有，直接替换，如果没有，还是之前的算法，整出来之后存到数据库，并加载到缓存。</p>\n<p>当然，存数据库这个毕竟还得有一次数据库连接，至少一次数据库操作，也是耗时的嘛，所以我起一个线程，异步去操作数据库。</p>\n<p>经过领导的同意，开始搞。</p>\n<h2 id=\"编码\"><a href=\"#编码\" class=\"headerlink\" title=\"编码\"></a>编码</h2><ul>\n<li>旧方法</li>\n</ul>\n<pre><code class=\"java\">public static String ospInOutParmConvert(String str) {\n    Matcher m=p1.matcher(str);\n    String strTmp = &quot;&quot;;\n    String strTmp1= &quot;&quot;;\n    while(m.find()){\n        strTmp = m.group();\n        str = str.replace(strTmp, strTmp.toLowerCase());\n        if (StringUtil.isNotEmpty(strTmp) &amp;&amp; strTmp != &quot;null&quot;) {\n            strTmp1= strTmp.toLowerCase();\n            if (strTmp1.indexOf(&quot;_&quot;) &gt; 0) {\n                String[] strTmp1s = strTmp1.split(&quot;_&quot;);\n                for(int i=0; i&lt;strTmp1s.length-1; i++){\n                    int subInt = strTmp1.indexOf(&quot;_&quot;);\n                    str = str.replace(strTmp1.substring(subInt,subInt + 2), strTmp1.substring(subInt + 1, subInt + 2).toUpperCase());\n                    if(strTmp1s.length&gt;1){\n                        strTmp1 = strTmp1.substring(subInt+1);\n                    }\n                }\n            }\n        }\n    }\n    return str;\n}</code></pre>\n<ul>\n<li>新版（无缓存）</li>\n</ul>\n<pre><code class=\"java\">    public static String ospInOutParmConvert1(String str) {\n        Map&lt;String, String&gt; nkCamelKeys = LocalJDBCUtil.getCamelKeyByNKKeys();\n        for (Map.Entry&lt;String, String&gt; entry : nkCamelKeys.entrySet()) {\n            str = str.replace(&quot;\\&quot;&quot; + entry.getKey() + &quot;\\&quot;&quot;, &quot;\\&quot;&quot; + entry.getValue() + &quot;\\&quot;&quot;);\n        }\n        return str;\n    }</code></pre>\n<ul>\n<li>新版（缓存）</li>\n</ul>\n<pre><code class=\"java\">public static String ospInOutParmConvert2(String str) {\n    Matcher m=p1.matcher(str);\n    String strTmp = &quot;&quot;;\n    String strTmp1= &quot;&quot;;\n    String nkKey = &quot;&quot;;\n    String camelKey = &quot;&quot;;\n    final Map&lt;String, String&gt; unSaveKeys = Maps.newHashMap();\n    while(m.find()){\n        strTmp = m.group();\n        nkKey = strTmp.replace(&quot;\\&quot;&quot;, &quot;&quot;).replace(&quot;:&quot;, &quot;&quot;);\n        camelKey = nkCamelKeyCacheService.getCamelKeyByNKKey(nkKey);\n        if (StringUtils.isNotBlank(camelKey)) {\n            str = str.replace(nkKey, camelKey);\n            continue;\n        } else {\n            camelKey = nkKey.toLowerCase();\n            str = str.replace(strTmp, strTmp.toLowerCase());\n            if (StringUtil.isNotEmpty(strTmp) &amp;&amp; strTmp != &quot;null&quot;) {\n                strTmp1= strTmp.toLowerCase();\n                if (strTmp1.indexOf(&quot;_&quot;) &gt; 0) {\n                    String[] strTmp1s = strTmp1.split(&quot;_&quot;);\n                    for(int i=0; i&lt;strTmp1s.length-1; i++){\n                        int subInt = strTmp1.indexOf(&quot;_&quot;);\n                        camelKey = camelKey.replace(strTmp1.substring(subInt,subInt + 2),strTmp1.substring(subInt + 1, subInt + 2).toUpperCase());\n                        if(strTmp1s.length&gt;1){\n                            strTmp1 = strTmp1.substring(subInt+1);\n                        }\n                    }\n                    str = str.replace(nkKey, camelKey);\n                }\n                unSaveKeys.put(nkKey, camelKey);\n            }\n        }\n    }\n    if (unSaveKeys.size() &gt; 0) {\n        new Thread(new Runnable() {\n            @Override\n            public void run() {\n                LocalJDBCUtil.addNkCamelKeys(unSaveKeys);\n            }\n        }).start();\n    }\n    return str;\n}</code></pre>\n<p>新的带缓存方法，也是用正则去匹配到key，然后拿key调用<code>getCamelKeyByNKKey</code>方法，这个方法用了<code>@Cacheable</code>注解，也就是用了spring cache来实现缓存。</p>\n<p>下面是缓存配置类：</p>\n<pre><code class=\"java\">@Configuration\n@EnableCaching\npublic class CacheConfig {\n    @Primary\n    @Bean\n    public SimpleCacheManager simpleCacheManager(List&lt;Cache&gt; caches) {\n        SimpleCacheManager cacheManager = new SimpleCacheManager();\n\n        cacheManager.setCaches(caches);\n        return cacheManager;\n    }\n\n    @Bean(&quot;nkCamelKeysCache&quot;)\n    public ConcurrentMapCacheFactoryBean nkCamelKeysCache() {\n        ConcurrentMapCacheFactoryBean nkCamelKeysCache = new ConcurrentMapCacheFactoryBean();\n        nkCamelKeysCache.setName(&quot;nkCamelKeysCache&quot;);\n        return nkCamelKeysCache;\n    }\n}</code></pre>\n<p>下面是缓存服务：</p>\n<pre><code class=\"java\">@Service(&quot;nkCamelKeyCacheService&quot;)\npublic class NKCamelKeyCacheService {\n    @Cacheable(value = &quot;nkCamelKeysCache&quot;)\n    public String getCamelKeyByNKKey(String nkKey) {\n        return LocalJDBCUtil.getCamelKeyByNKKey(nkKey);\n    }\n}</code></pre>\n<p>如果缓存没有命中，那么还是通过之前的老方法，不过这里我修改了一下用一个<code>unSaveKeys</code>变量来记录没有保存的key映射，然后起了一个匿名线程，去调用<code>addNkCamelKeys</code>方法，将<code>unSaveKeys</code>中的key存进数据库。</p>\n<h2 id=\"测试\"><a href=\"#测试\" class=\"headerlink\" title=\"测试\"></a>测试</h2><p>我们用一个生产环境的报文来测试，16415个字符，应该算是较大的报文了。</p>\n<h3 id=\"测试用例\"><a href=\"#测试用例\" class=\"headerlink\" title=\"测试用例\"></a>测试用例</h3><pre><code class=\"java\">@BeforeClass\npublic static void init() {\n    AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext();\n    context.register(CacheConfig.class);\n    context.register(NKCamelKeyCacheService.class);\n    context.register(InterfacePlatformTools.class);\n    context.refresh();\n    nkCamelKeyCacheService = (NKCamelKeyCacheService) context.getBean(&quot;nkCamelKeyCacheService&quot;);\n}\n@Before\npublic void getBeginTime() {\n    beginTime = System.currentTimeMillis();\n}\n@After\npublic void getEndTime() {\n    System.out.println(&quot;耗时:&quot; + (System.currentTimeMillis()-beginTime) + &quot;ms&quot;);\n}\n@Test\npublic void test0() {\n    System.out.println(&quot;旧版驼峰转换测试结果：&quot; + InterfacePlatformTools.ospInOutParmConvert(content));\n}\n@Test\npublic void test1() {\n    System.out.println(&quot;新版驼峰转换测试结果：&quot; + InterfacePlatformTools.ospInOutParmConvert1(content));\n}\n@Test\npublic void test2() {\n    System.out.println(&quot;缓存版第一次（需要入库）测试结果：&quot; + InterfacePlatformTools.ospInOutParmConvert2(content));\n}\n@Test\npublic void test3() {\n    System.out.println(&quot;缓存版第二次（直接在缓存中读取）测试结果：&quot; + InterfacePlatformTools.ospInOutParmConvert2(content));\n}</code></pre>\n<h3 id=\"测试结果\"><a href=\"#测试结果\" class=\"headerlink\" title=\"测试结果\"></a>测试结果</h3><pre><code class=\"shell\">旧版驼峰转换测试结果：{&quot;errorinfo&quot;:{&quot;message&quot;:&quot;成功&quot;,&quot;code&quot;:0,&quot;busiSerialNo&quot;:&quot;&quot;\n耗时:204ms\n2020-03-29 19:19:46,869 INFO  [main] com.cmos.crmpfcore.util.LocalJDBCUtil - ==\n新版驼峰转换(无缓存)测试结果：{&quot;errorinfo&quot;:{&quot;message&quot;:&quot;成功&quot;,&quot;code&quot;:0,&quot;busiSerialNo&quot;:&quot;&quot;\n耗时:531ms\n缓存版第一次（需要入库）测试结果：{&quot;errorinfo&quot;:{&quot;message&quot;:&quot;成功&quot;,&quot;code&quot;:0,&quot;busi\n耗时:500ms\n缓存版第二次（直接在缓存中读取）测试结果：{&quot;errorinfo&quot;:{&quot;message&quot;:&quot;成功&quot;,&quot;code&quot;\n耗时:24ms</code></pre>\n<p>可以看出，老版本的转换方法用了204ms，每次去查数据库因为要多次连接数据库进行查询操作，需要531ms，而使用了缓存的方法，第一次我们还没有加载缓存，需要500ms，而第二次直接在缓存中读取，24ms，只用了之前方法的1/10。</p>\n<p>如果你有更好的方案，欢迎联系我哦。</p>\n"},{"title":"TCP三次握手&四次挥手","excerpt":"","comments":1,"top":1,"date":"2020-04-03T16:30:52.000Z","_content":"\n# TCP三次握手&四次挥手\n\n今天无意间注意到垫显示器的《TCP/IP协议族》，书皮最上面一行字：世界著名计算机教材精选。\n\n<img src=\"11111.png\">\n\n这是我大学的教材，我的专业是网络工程，大学没能好好学习，惭愧，惭愧。打开随便翻了一下， 发现很多折角，应该是学期末老师划重点的时候折的，唉，回忆袭来。\n看到这本书，想到的就是之前几次面试的一个高频问题：tcp三次握手和四次挥手。赶紧翻到运输层TCP那一节。映入眼帘的是我没交的作业。。。\n\n<img src='11585992522_.pic.jpg'>\n\n万千思绪啊，怀念啊。。\n\n## TCP\n\nTCP使用端口号提供进程到进程的通信。tcp和udp都是属于运输层。tcp使用的我们常见的端口号有**FTP（20/21）**、**TELNET（23）**、**SMTP（25）**、**DNS（53）**、**HTTP（80）**。\n和UDP不同，TCP是一种面向流的协议。所谓**面向流**，我理解的就是：UDP报文之间没有没有任何关联，而TCP则允许发送进程以字节流的形式来传送数据，并且也允许接受进程把数据作为字节流来接收，也就是是说建立了一条连接，这条连接就像一个管道，以此进行全双工的通信。\n\n<img src=\"21585993169_.pic_hd.jpg\">\n\n由于发送进程和接收进程写入和读取数据的速度可能不同，TCP会用缓存来存储数据。所以TCP有两个缓存，即发送缓存和接收缓存。这些缓存还被TCP用来进行流量控制和差错控制。\n\nTCP是一个可靠的运输协议，它使用确认机制来检查数据是否安全完好地到达。\n\nTCP报文的首部有很多字段，包括**源端口地址、目的端口地址、序号、确认号、首部长度、保留、控制、窗口大小、检验和、紧急指针、选项**。\n其中**控制**字段定义了6中不同的控制位或标志：\n- URG： 紧急指针有效\n- ACK： 确认是有效的\n- PSH： 请求推送\n- RST： 连接复位\n- SYN： 同步序号\n- FIN： 终止连接\n\n## TCP连接\n\nTCP是面向连接的，需要经历三个阶段：**建立连接、数据传输、连接终止**。\n\n### 建立连接\nTCP建立连接的过程成为**三向握手（three-way handshaking）**。\n\n<img src=\"31585998651_.pic_hd.jpg\">\n\n过程：\n\n准备条件：服务器程序告诉服务器的TCP自己已经准备好接收连接。这个请求被成为**被动打开**请求。这个打开是针对连接的，而不是端口。这一步就是我们的服务启动了，开放了端口，等待连接。\n1. 客户端程序发出请求，称为**主动打开**。客户端发送第一个报文段（SYN报文段），这个报文中只有SYN标志被置为1，并且客户端选择了一个随机数作为**序号**，并把这个序号发送给服务端。这里同时是客户端在同步它的初始序号。\n2. 服务器发送第二个报文，即SYN+ACK报文段，其中两个标志（SYN和ACK）置为1。这个报文有两个目的。首先，他是另一个方向上的SYN报文段，服务器使用这个报文来同步自己的初始序号。其次，服务器还通过ACK标志来确认已收到来自客户端的SYN报文段，同时给出期望从客户端收到的下一个序号。\n3. 客户端发送第三个报文。这仅仅是一个ACK报文段。它使用ACK标志和确认号字段来确认收到了第二个报文。**这个报文的序号和SYN报文段使用的序号是一样的**，这样可以节省一个序号。当然在某些实现中，这个报文可以携带客户端的第一个数据块，这种情况下，第三个报文必须有一个新的序号来表示数据中的第一个字节编号。但是通常第三个报文段是不包含数据的，因而不消耗序号。\n\n**SYN洪泛攻击：**\n了解了上面的连接过程，很多人会想到，如果我向一个服务端发送大量的SYN报文段，是不是可以把连接占满，导致服务不可用？\n当然，之前我们公司的一些服务使用socket长连接，这些连接通过心跳保持连接，但是由于存在bug，客户端在关闭连接的时候不会发送确认，导致服务端的连接状态一直是**close wait**，无法真正关闭连接。而客户端却认为这些连接已经断开了，再次申请新的连接，导致长时间不重启服务的话，连接就会被占满。这个问题有一段时间一直困扰着我们，不得不定期重启服务端才能保证业务。\n这样的机制也让一些不怀好意的人所利用，伪造大量假源IP地址的SYN报文段发送给服务端。服务端认为这是客户端发来的主动打开请求，于是分配必要的资源，并发送SYN+ACK报文段给对应的源IP，奈何这些IP都是假的，这些报文终将超时，服务端却已经分配了资源。大量的资源被占用却未被利用，服务器最终会因为资源耗尽而不能接收合法客户的连接请求。这就是**SYN洪泛攻击**。\n当然也有一些解决的办法，常见的是使用Cookie，做到推迟资源的分配，直到服务器能够正式连接请求来自合法的IP地址。\n\n### 数据传输\n\n按照建立连接是双方已经确定的序号发送数据。\n\n**举例子得有背景！**\n背景：\n- 建立连接第一个报文，客户端在SYN时使用的序号（seq）是8000，\n- 建立连接第二个报文，服务器初始seq是15000，ack是8001\n- 建立连接第三个报文，客户端没有发送数据块，即当时seq也是8000，ack是15001。那么正式开始传输数据，客户端推送数据开始。\n\n<img src=\"41585998713_.pic_hd.jpg\">\n\n1. 客户端推送数据，seq为8001（序号排着来，建立连接用的是8000），ack：15001，携带1000字节数据。控制方面，PSH（推送）标志为1，代表推送数据。\n2. 服务端收到seq为8001的报文，它了解到PSH标志为1，就会尽快把这些数据交给服务端对应端口上的程序。如果由于资源占用等原因不能及时把数据交给程序，TCP有缓存机制，可以先缓存下来，回头再给程序。这里服务器可以直接发送确认报文，也可能因为忙碌没能及时发送确认，但是服务端会在超时时间内发送确认。我们这里假定服务端没立即返回确认，而是收到了客户端发来的第二个数据块。\n3. 客户端发送第二个报文块，seq为8001+1000=9001，**序号就是数据的offset嘛，很好理解**。ack还是15001，因为服务端没来新的报文嘛。PSH标志还是1，因为还是推送数据。\n4. 服务端这时候收到两个报文，客户端的数据也都传输完了。服务端终于有时间给客户端确认了。这时候它直接发了一个报文，seq为15001，**各自按各自的序号来，必定这是告诉对方自己数据的offset**，ack为8001+1000+1000=10001，**要发确认就一起确认了，没必要每个来自客户端的都得单独确认，记住，序号就是数据的offset**。服务端在确认的同时可能还会返回一些数据，就像上面我说的那个socket接口的例子，这时候就会携带接口的响应数据。比如携带了2000字节的数据。这个报文PSH是不是1，不同的TCP实现不一样。\n5. 服务端收到报文，已经传输完所有的数据，就不需要携带数据了，但是得确认收到服务端的报文，seq为10000，**不携带数据，offset还是之前的10000**，ack为15001+2000=17001。\n\n### 连接终止\n\n参与连接的任何一方都可以关闭连接，一般都是客户端发起。\n\n<img src=\"51585999731_.pic_hd.jpg\">\n\n\n1. 客户进程告诉自己的TCP关闭连接，TCP发送第一个报文，这个报文把FIN位置1，成为FIN报文段。这个FIN报文段，可以是最后一个数据块，也可以只是一个控制报文段。不携带数据的话，只消耗一个序号。seq：x，ack：y\n2. 服务器TCP在收到合格FIN报文段后，把这种情况告诉它的进程，并发送第二个报文--FIN+ACK报文段，确定客户端的FIN报文，同时也宣布另一个方向正在关闭连接。当然这个报文也可能带着来自服务端的最后一个数据块。如果不携带数据，只消耗一个序号。seq：y，ack：x+1\n3. 客户端TCP发送最后一个报文段，这是一个ACK报文段，确认服务端的FIN报文段。seq：x，ack：y+1\n","source":"_posts/2020-04-04-kongzheng1993-TCP三次握手&四次挥手.md","raw":"---\ntitle: TCP三次握手&四次挥手\nexcerpt: ''\ntags: [网络]\ncategories: [网络]\ncomments: true\ntop: 1\ndate: 2020-04-04 00:30:52\n---\n\n# TCP三次握手&四次挥手\n\n今天无意间注意到垫显示器的《TCP/IP协议族》，书皮最上面一行字：世界著名计算机教材精选。\n\n<img src=\"11111.png\">\n\n这是我大学的教材，我的专业是网络工程，大学没能好好学习，惭愧，惭愧。打开随便翻了一下， 发现很多折角，应该是学期末老师划重点的时候折的，唉，回忆袭来。\n看到这本书，想到的就是之前几次面试的一个高频问题：tcp三次握手和四次挥手。赶紧翻到运输层TCP那一节。映入眼帘的是我没交的作业。。。\n\n<img src='11585992522_.pic.jpg'>\n\n万千思绪啊，怀念啊。。\n\n## TCP\n\nTCP使用端口号提供进程到进程的通信。tcp和udp都是属于运输层。tcp使用的我们常见的端口号有**FTP（20/21）**、**TELNET（23）**、**SMTP（25）**、**DNS（53）**、**HTTP（80）**。\n和UDP不同，TCP是一种面向流的协议。所谓**面向流**，我理解的就是：UDP报文之间没有没有任何关联，而TCP则允许发送进程以字节流的形式来传送数据，并且也允许接受进程把数据作为字节流来接收，也就是是说建立了一条连接，这条连接就像一个管道，以此进行全双工的通信。\n\n<img src=\"21585993169_.pic_hd.jpg\">\n\n由于发送进程和接收进程写入和读取数据的速度可能不同，TCP会用缓存来存储数据。所以TCP有两个缓存，即发送缓存和接收缓存。这些缓存还被TCP用来进行流量控制和差错控制。\n\nTCP是一个可靠的运输协议，它使用确认机制来检查数据是否安全完好地到达。\n\nTCP报文的首部有很多字段，包括**源端口地址、目的端口地址、序号、确认号、首部长度、保留、控制、窗口大小、检验和、紧急指针、选项**。\n其中**控制**字段定义了6中不同的控制位或标志：\n- URG： 紧急指针有效\n- ACK： 确认是有效的\n- PSH： 请求推送\n- RST： 连接复位\n- SYN： 同步序号\n- FIN： 终止连接\n\n## TCP连接\n\nTCP是面向连接的，需要经历三个阶段：**建立连接、数据传输、连接终止**。\n\n### 建立连接\nTCP建立连接的过程成为**三向握手（three-way handshaking）**。\n\n<img src=\"31585998651_.pic_hd.jpg\">\n\n过程：\n\n准备条件：服务器程序告诉服务器的TCP自己已经准备好接收连接。这个请求被成为**被动打开**请求。这个打开是针对连接的，而不是端口。这一步就是我们的服务启动了，开放了端口，等待连接。\n1. 客户端程序发出请求，称为**主动打开**。客户端发送第一个报文段（SYN报文段），这个报文中只有SYN标志被置为1，并且客户端选择了一个随机数作为**序号**，并把这个序号发送给服务端。这里同时是客户端在同步它的初始序号。\n2. 服务器发送第二个报文，即SYN+ACK报文段，其中两个标志（SYN和ACK）置为1。这个报文有两个目的。首先，他是另一个方向上的SYN报文段，服务器使用这个报文来同步自己的初始序号。其次，服务器还通过ACK标志来确认已收到来自客户端的SYN报文段，同时给出期望从客户端收到的下一个序号。\n3. 客户端发送第三个报文。这仅仅是一个ACK报文段。它使用ACK标志和确认号字段来确认收到了第二个报文。**这个报文的序号和SYN报文段使用的序号是一样的**，这样可以节省一个序号。当然在某些实现中，这个报文可以携带客户端的第一个数据块，这种情况下，第三个报文必须有一个新的序号来表示数据中的第一个字节编号。但是通常第三个报文段是不包含数据的，因而不消耗序号。\n\n**SYN洪泛攻击：**\n了解了上面的连接过程，很多人会想到，如果我向一个服务端发送大量的SYN报文段，是不是可以把连接占满，导致服务不可用？\n当然，之前我们公司的一些服务使用socket长连接，这些连接通过心跳保持连接，但是由于存在bug，客户端在关闭连接的时候不会发送确认，导致服务端的连接状态一直是**close wait**，无法真正关闭连接。而客户端却认为这些连接已经断开了，再次申请新的连接，导致长时间不重启服务的话，连接就会被占满。这个问题有一段时间一直困扰着我们，不得不定期重启服务端才能保证业务。\n这样的机制也让一些不怀好意的人所利用，伪造大量假源IP地址的SYN报文段发送给服务端。服务端认为这是客户端发来的主动打开请求，于是分配必要的资源，并发送SYN+ACK报文段给对应的源IP，奈何这些IP都是假的，这些报文终将超时，服务端却已经分配了资源。大量的资源被占用却未被利用，服务器最终会因为资源耗尽而不能接收合法客户的连接请求。这就是**SYN洪泛攻击**。\n当然也有一些解决的办法，常见的是使用Cookie，做到推迟资源的分配，直到服务器能够正式连接请求来自合法的IP地址。\n\n### 数据传输\n\n按照建立连接是双方已经确定的序号发送数据。\n\n**举例子得有背景！**\n背景：\n- 建立连接第一个报文，客户端在SYN时使用的序号（seq）是8000，\n- 建立连接第二个报文，服务器初始seq是15000，ack是8001\n- 建立连接第三个报文，客户端没有发送数据块，即当时seq也是8000，ack是15001。那么正式开始传输数据，客户端推送数据开始。\n\n<img src=\"41585998713_.pic_hd.jpg\">\n\n1. 客户端推送数据，seq为8001（序号排着来，建立连接用的是8000），ack：15001，携带1000字节数据。控制方面，PSH（推送）标志为1，代表推送数据。\n2. 服务端收到seq为8001的报文，它了解到PSH标志为1，就会尽快把这些数据交给服务端对应端口上的程序。如果由于资源占用等原因不能及时把数据交给程序，TCP有缓存机制，可以先缓存下来，回头再给程序。这里服务器可以直接发送确认报文，也可能因为忙碌没能及时发送确认，但是服务端会在超时时间内发送确认。我们这里假定服务端没立即返回确认，而是收到了客户端发来的第二个数据块。\n3. 客户端发送第二个报文块，seq为8001+1000=9001，**序号就是数据的offset嘛，很好理解**。ack还是15001，因为服务端没来新的报文嘛。PSH标志还是1，因为还是推送数据。\n4. 服务端这时候收到两个报文，客户端的数据也都传输完了。服务端终于有时间给客户端确认了。这时候它直接发了一个报文，seq为15001，**各自按各自的序号来，必定这是告诉对方自己数据的offset**，ack为8001+1000+1000=10001，**要发确认就一起确认了，没必要每个来自客户端的都得单独确认，记住，序号就是数据的offset**。服务端在确认的同时可能还会返回一些数据，就像上面我说的那个socket接口的例子，这时候就会携带接口的响应数据。比如携带了2000字节的数据。这个报文PSH是不是1，不同的TCP实现不一样。\n5. 服务端收到报文，已经传输完所有的数据，就不需要携带数据了，但是得确认收到服务端的报文，seq为10000，**不携带数据，offset还是之前的10000**，ack为15001+2000=17001。\n\n### 连接终止\n\n参与连接的任何一方都可以关闭连接，一般都是客户端发起。\n\n<img src=\"51585999731_.pic_hd.jpg\">\n\n\n1. 客户进程告诉自己的TCP关闭连接，TCP发送第一个报文，这个报文把FIN位置1，成为FIN报文段。这个FIN报文段，可以是最后一个数据块，也可以只是一个控制报文段。不携带数据的话，只消耗一个序号。seq：x，ack：y\n2. 服务器TCP在收到合格FIN报文段后，把这种情况告诉它的进程，并发送第二个报文--FIN+ACK报文段，确定客户端的FIN报文，同时也宣布另一个方向正在关闭连接。当然这个报文也可能带着来自服务端的最后一个数据块。如果不携带数据，只消耗一个序号。seq：y，ack：x+1\n3. 客户端TCP发送最后一个报文段，这是一个ACK报文段，确认服务端的FIN报文段。seq：x，ack：y+1\n","slug":"kongzheng1993-TCP三次握手&四次挥手","published":1,"updated":"2023-03-08T07:05:58.785Z","layout":"post","photos":[],"link":"","_id":"clg0k2apn00hut26f8tbkns9e","content":"<h1 id=\"TCP三次握手-amp-四次挥手\"><a href=\"#TCP三次握手-amp-四次挥手\" class=\"headerlink\" title=\"TCP三次握手&amp;四次挥手\"></a>TCP三次握手&amp;四次挥手</h1><p>今天无意间注意到垫显示器的《TCP/IP协议族》，书皮最上面一行字：世界著名计算机教材精选。</p>\n<img src=\"/2020/04/04/kongzheng1993-TCP三次握手&四次挥手/11111.png\">\n\n<p>这是我大学的教材，我的专业是网络工程，大学没能好好学习，惭愧，惭愧。打开随便翻了一下， 发现很多折角，应该是学期末老师划重点的时候折的，唉，回忆袭来。<br>看到这本书，想到的就是之前几次面试的一个高频问题：tcp三次握手和四次挥手。赶紧翻到运输层TCP那一节。映入眼帘的是我没交的作业。。。</p>\n<img src=\"/2020/04/04/kongzheng1993-TCP三次握手&四次挥手/11585992522_.pic.jpg\">\n\n<p>万千思绪啊，怀念啊。。</p>\n<h2 id=\"TCP\"><a href=\"#TCP\" class=\"headerlink\" title=\"TCP\"></a>TCP</h2><p>TCP使用端口号提供进程到进程的通信。tcp和udp都是属于运输层。tcp使用的我们常见的端口号有<strong>FTP（20/21）</strong>、<strong>TELNET（23）</strong>、<strong>SMTP（25）</strong>、<strong>DNS（53）</strong>、<strong>HTTP（80）</strong>。\n和UDP不同，TCP是一种面向流的协议。所谓<strong>面向流</strong>，我理解的就是：UDP报文之间没有没有任何关联，而TCP则允许发送进程以字节流的形式来传送数据，并且也允许接受进程把数据作为字节流来接收，也就是是说建立了一条连接，这条连接就像一个管道，以此进行全双工的通信。</p>\n<img src=\"/2020/04/04/kongzheng1993-TCP三次握手&四次挥手/21585993169_.pic_hd.jpg\">\n\n<p>由于发送进程和接收进程写入和读取数据的速度可能不同，TCP会用缓存来存储数据。所以TCP有两个缓存，即发送缓存和接收缓存。这些缓存还被TCP用来进行流量控制和差错控制。</p>\n<p>TCP是一个可靠的运输协议，它使用确认机制来检查数据是否安全完好地到达。</p>\n<p>TCP报文的首部有很多字段，包括<strong>源端口地址、目的端口地址、序号、确认号、首部长度、保留、控制、窗口大小、检验和、紧急指针、选项</strong>。\n其中<strong>控制</strong>字段定义了6中不同的控制位或标志：</p>\n<ul>\n<li>URG： 紧急指针有效</li>\n<li>ACK： 确认是有效的</li>\n<li>PSH： 请求推送</li>\n<li>RST： 连接复位</li>\n<li>SYN： 同步序号</li>\n<li>FIN： 终止连接</li>\n</ul>\n<h2 id=\"TCP连接\"><a href=\"#TCP连接\" class=\"headerlink\" title=\"TCP连接\"></a>TCP连接</h2><p>TCP是面向连接的，需要经历三个阶段：<strong>建立连接、数据传输、连接终止</strong>。</p>\n<h3 id=\"建立连接\"><a href=\"#建立连接\" class=\"headerlink\" title=\"建立连接\"></a>建立连接</h3><p>TCP建立连接的过程成为<strong>三向握手（three-way handshaking）</strong>。</p>\n<img src=\"/2020/04/04/kongzheng1993-TCP三次握手&四次挥手/31585998651_.pic_hd.jpg\">\n\n<p>过程：</p>\n<p>准备条件：服务器程序告诉服务器的TCP自己已经准备好接收连接。这个请求被成为<strong>被动打开</strong>请求。这个打开是针对连接的，而不是端口。这一步就是我们的服务启动了，开放了端口，等待连接。</p>\n<ol>\n<li>客户端程序发出请求，称为<strong>主动打开</strong>。客户端发送第一个报文段（SYN报文段），这个报文中只有SYN标志被置为1，并且客户端选择了一个随机数作为<strong>序号</strong>，并把这个序号发送给服务端。这里同时是客户端在同步它的初始序号。</li>\n<li>服务器发送第二个报文，即SYN+ACK报文段，其中两个标志（SYN和ACK）置为1。这个报文有两个目的。首先，他是另一个方向上的SYN报文段，服务器使用这个报文来同步自己的初始序号。其次，服务器还通过ACK标志来确认已收到来自客户端的SYN报文段，同时给出期望从客户端收到的下一个序号。</li>\n<li>客户端发送第三个报文。这仅仅是一个ACK报文段。它使用ACK标志和确认号字段来确认收到了第二个报文。<strong>这个报文的序号和SYN报文段使用的序号是一样的</strong>，这样可以节省一个序号。当然在某些实现中，这个报文可以携带客户端的第一个数据块，这种情况下，第三个报文必须有一个新的序号来表示数据中的第一个字节编号。但是通常第三个报文段是不包含数据的，因而不消耗序号。</li>\n</ol>\n<p><strong>SYN洪泛攻击：</strong><br>了解了上面的连接过程，很多人会想到，如果我向一个服务端发送大量的SYN报文段，是不是可以把连接占满，导致服务不可用？<br>当然，之前我们公司的一些服务使用socket长连接，这些连接通过心跳保持连接，但是由于存在bug，客户端在关闭连接的时候不会发送确认，导致服务端的连接状态一直是<strong>close wait</strong>，无法真正关闭连接。而客户端却认为这些连接已经断开了，再次申请新的连接，导致长时间不重启服务的话，连接就会被占满。这个问题有一段时间一直困扰着我们，不得不定期重启服务端才能保证业务。<br>这样的机制也让一些不怀好意的人所利用，伪造大量假源IP地址的SYN报文段发送给服务端。服务端认为这是客户端发来的主动打开请求，于是分配必要的资源，并发送SYN+ACK报文段给对应的源IP，奈何这些IP都是假的，这些报文终将超时，服务端却已经分配了资源。大量的资源被占用却未被利用，服务器最终会因为资源耗尽而不能接收合法客户的连接请求。这就是<strong>SYN洪泛攻击</strong>。\n当然也有一些解决的办法，常见的是使用Cookie，做到推迟资源的分配，直到服务器能够正式连接请求来自合法的IP地址。</p>\n<h3 id=\"数据传输\"><a href=\"#数据传输\" class=\"headerlink\" title=\"数据传输\"></a>数据传输</h3><p>按照建立连接是双方已经确定的序号发送数据。</p>\n<p><strong>举例子得有背景！</strong><br>背景：</p>\n<ul>\n<li>建立连接第一个报文，客户端在SYN时使用的序号（seq）是8000，</li>\n<li>建立连接第二个报文，服务器初始seq是15000，ack是8001</li>\n<li>建立连接第三个报文，客户端没有发送数据块，即当时seq也是8000，ack是15001。那么正式开始传输数据，客户端推送数据开始。</li>\n</ul>\n<img src=\"/2020/04/04/kongzheng1993-TCP三次握手&四次挥手/41585998713_.pic_hd.jpg\">\n\n<ol>\n<li>客户端推送数据，seq为8001（序号排着来，建立连接用的是8000），ack：15001，携带1000字节数据。控制方面，PSH（推送）标志为1，代表推送数据。</li>\n<li>服务端收到seq为8001的报文，它了解到PSH标志为1，就会尽快把这些数据交给服务端对应端口上的程序。如果由于资源占用等原因不能及时把数据交给程序，TCP有缓存机制，可以先缓存下来，回头再给程序。这里服务器可以直接发送确认报文，也可能因为忙碌没能及时发送确认，但是服务端会在超时时间内发送确认。我们这里假定服务端没立即返回确认，而是收到了客户端发来的第二个数据块。</li>\n<li>客户端发送第二个报文块，seq为8001+1000=9001，<strong>序号就是数据的offset嘛，很好理解</strong>。ack还是15001，因为服务端没来新的报文嘛。PSH标志还是1，因为还是推送数据。</li>\n<li>服务端这时候收到两个报文，客户端的数据也都传输完了。服务端终于有时间给客户端确认了。这时候它直接发了一个报文，seq为15001，<strong>各自按各自的序号来，必定这是告诉对方自己数据的offset</strong>，ack为8001+1000+1000=10001，<strong>要发确认就一起确认了，没必要每个来自客户端的都得单独确认，记住，序号就是数据的offset</strong>。服务端在确认的同时可能还会返回一些数据，就像上面我说的那个socket接口的例子，这时候就会携带接口的响应数据。比如携带了2000字节的数据。这个报文PSH是不是1，不同的TCP实现不一样。</li>\n<li>服务端收到报文，已经传输完所有的数据，就不需要携带数据了，但是得确认收到服务端的报文，seq为10000，<strong>不携带数据，offset还是之前的10000</strong>，ack为15001+2000=17001。</li>\n</ol>\n<h3 id=\"连接终止\"><a href=\"#连接终止\" class=\"headerlink\" title=\"连接终止\"></a>连接终止</h3><p>参与连接的任何一方都可以关闭连接，一般都是客户端发起。</p>\n<img src=\"/2020/04/04/kongzheng1993-TCP三次握手&四次挥手/51585999731_.pic_hd.jpg\">\n\n\n<ol>\n<li>客户进程告诉自己的TCP关闭连接，TCP发送第一个报文，这个报文把FIN位置1，成为FIN报文段。这个FIN报文段，可以是最后一个数据块，也可以只是一个控制报文段。不携带数据的话，只消耗一个序号。seq：x，ack：y</li>\n<li>服务器TCP在收到合格FIN报文段后，把这种情况告诉它的进程，并发送第二个报文–FIN+ACK报文段，确定客户端的FIN报文，同时也宣布另一个方向正在关闭连接。当然这个报文也可能带着来自服务端的最后一个数据块。如果不携带数据，只消耗一个序号。seq：y，ack：x+1</li>\n<li>客户端TCP发送最后一个报文段，这是一个ACK报文段，确认服务端的FIN报文段。seq：x，ack：y+1</li>\n</ol>\n","site":{"data":{}},"more":"<h1 id=\"TCP三次握手-amp-四次挥手\"><a href=\"#TCP三次握手-amp-四次挥手\" class=\"headerlink\" title=\"TCP三次握手&amp;四次挥手\"></a>TCP三次握手&amp;四次挥手</h1><p>今天无意间注意到垫显示器的《TCP/IP协议族》，书皮最上面一行字：世界著名计算机教材精选。</p>\n<img src=\"/2020/04/04/kongzheng1993-TCP三次握手&四次挥手/11111.png\">\n\n<p>这是我大学的教材，我的专业是网络工程，大学没能好好学习，惭愧，惭愧。打开随便翻了一下， 发现很多折角，应该是学期末老师划重点的时候折的，唉，回忆袭来。<br>看到这本书，想到的就是之前几次面试的一个高频问题：tcp三次握手和四次挥手。赶紧翻到运输层TCP那一节。映入眼帘的是我没交的作业。。。</p>\n<img src=\"/2020/04/04/kongzheng1993-TCP三次握手&四次挥手/11585992522_.pic.jpg\">\n\n<p>万千思绪啊，怀念啊。。</p>\n<h2 id=\"TCP\"><a href=\"#TCP\" class=\"headerlink\" title=\"TCP\"></a>TCP</h2><p>TCP使用端口号提供进程到进程的通信。tcp和udp都是属于运输层。tcp使用的我们常见的端口号有<strong>FTP（20/21）</strong>、<strong>TELNET（23）</strong>、<strong>SMTP（25）</strong>、<strong>DNS（53）</strong>、<strong>HTTP（80）</strong>。\n和UDP不同，TCP是一种面向流的协议。所谓<strong>面向流</strong>，我理解的就是：UDP报文之间没有没有任何关联，而TCP则允许发送进程以字节流的形式来传送数据，并且也允许接受进程把数据作为字节流来接收，也就是是说建立了一条连接，这条连接就像一个管道，以此进行全双工的通信。</p>\n<img src=\"/2020/04/04/kongzheng1993-TCP三次握手&四次挥手/21585993169_.pic_hd.jpg\">\n\n<p>由于发送进程和接收进程写入和读取数据的速度可能不同，TCP会用缓存来存储数据。所以TCP有两个缓存，即发送缓存和接收缓存。这些缓存还被TCP用来进行流量控制和差错控制。</p>\n<p>TCP是一个可靠的运输协议，它使用确认机制来检查数据是否安全完好地到达。</p>\n<p>TCP报文的首部有很多字段，包括<strong>源端口地址、目的端口地址、序号、确认号、首部长度、保留、控制、窗口大小、检验和、紧急指针、选项</strong>。\n其中<strong>控制</strong>字段定义了6中不同的控制位或标志：</p>\n<ul>\n<li>URG： 紧急指针有效</li>\n<li>ACK： 确认是有效的</li>\n<li>PSH： 请求推送</li>\n<li>RST： 连接复位</li>\n<li>SYN： 同步序号</li>\n<li>FIN： 终止连接</li>\n</ul>\n<h2 id=\"TCP连接\"><a href=\"#TCP连接\" class=\"headerlink\" title=\"TCP连接\"></a>TCP连接</h2><p>TCP是面向连接的，需要经历三个阶段：<strong>建立连接、数据传输、连接终止</strong>。</p>\n<h3 id=\"建立连接\"><a href=\"#建立连接\" class=\"headerlink\" title=\"建立连接\"></a>建立连接</h3><p>TCP建立连接的过程成为<strong>三向握手（three-way handshaking）</strong>。</p>\n<img src=\"/2020/04/04/kongzheng1993-TCP三次握手&四次挥手/31585998651_.pic_hd.jpg\">\n\n<p>过程：</p>\n<p>准备条件：服务器程序告诉服务器的TCP自己已经准备好接收连接。这个请求被成为<strong>被动打开</strong>请求。这个打开是针对连接的，而不是端口。这一步就是我们的服务启动了，开放了端口，等待连接。</p>\n<ol>\n<li>客户端程序发出请求，称为<strong>主动打开</strong>。客户端发送第一个报文段（SYN报文段），这个报文中只有SYN标志被置为1，并且客户端选择了一个随机数作为<strong>序号</strong>，并把这个序号发送给服务端。这里同时是客户端在同步它的初始序号。</li>\n<li>服务器发送第二个报文，即SYN+ACK报文段，其中两个标志（SYN和ACK）置为1。这个报文有两个目的。首先，他是另一个方向上的SYN报文段，服务器使用这个报文来同步自己的初始序号。其次，服务器还通过ACK标志来确认已收到来自客户端的SYN报文段，同时给出期望从客户端收到的下一个序号。</li>\n<li>客户端发送第三个报文。这仅仅是一个ACK报文段。它使用ACK标志和确认号字段来确认收到了第二个报文。<strong>这个报文的序号和SYN报文段使用的序号是一样的</strong>，这样可以节省一个序号。当然在某些实现中，这个报文可以携带客户端的第一个数据块，这种情况下，第三个报文必须有一个新的序号来表示数据中的第一个字节编号。但是通常第三个报文段是不包含数据的，因而不消耗序号。</li>\n</ol>\n<p><strong>SYN洪泛攻击：</strong><br>了解了上面的连接过程，很多人会想到，如果我向一个服务端发送大量的SYN报文段，是不是可以把连接占满，导致服务不可用？<br>当然，之前我们公司的一些服务使用socket长连接，这些连接通过心跳保持连接，但是由于存在bug，客户端在关闭连接的时候不会发送确认，导致服务端的连接状态一直是<strong>close wait</strong>，无法真正关闭连接。而客户端却认为这些连接已经断开了，再次申请新的连接，导致长时间不重启服务的话，连接就会被占满。这个问题有一段时间一直困扰着我们，不得不定期重启服务端才能保证业务。<br>这样的机制也让一些不怀好意的人所利用，伪造大量假源IP地址的SYN报文段发送给服务端。服务端认为这是客户端发来的主动打开请求，于是分配必要的资源，并发送SYN+ACK报文段给对应的源IP，奈何这些IP都是假的，这些报文终将超时，服务端却已经分配了资源。大量的资源被占用却未被利用，服务器最终会因为资源耗尽而不能接收合法客户的连接请求。这就是<strong>SYN洪泛攻击</strong>。\n当然也有一些解决的办法，常见的是使用Cookie，做到推迟资源的分配，直到服务器能够正式连接请求来自合法的IP地址。</p>\n<h3 id=\"数据传输\"><a href=\"#数据传输\" class=\"headerlink\" title=\"数据传输\"></a>数据传输</h3><p>按照建立连接是双方已经确定的序号发送数据。</p>\n<p><strong>举例子得有背景！</strong><br>背景：</p>\n<ul>\n<li>建立连接第一个报文，客户端在SYN时使用的序号（seq）是8000，</li>\n<li>建立连接第二个报文，服务器初始seq是15000，ack是8001</li>\n<li>建立连接第三个报文，客户端没有发送数据块，即当时seq也是8000，ack是15001。那么正式开始传输数据，客户端推送数据开始。</li>\n</ul>\n<img src=\"/2020/04/04/kongzheng1993-TCP三次握手&四次挥手/41585998713_.pic_hd.jpg\">\n\n<ol>\n<li>客户端推送数据，seq为8001（序号排着来，建立连接用的是8000），ack：15001，携带1000字节数据。控制方面，PSH（推送）标志为1，代表推送数据。</li>\n<li>服务端收到seq为8001的报文，它了解到PSH标志为1，就会尽快把这些数据交给服务端对应端口上的程序。如果由于资源占用等原因不能及时把数据交给程序，TCP有缓存机制，可以先缓存下来，回头再给程序。这里服务器可以直接发送确认报文，也可能因为忙碌没能及时发送确认，但是服务端会在超时时间内发送确认。我们这里假定服务端没立即返回确认，而是收到了客户端发来的第二个数据块。</li>\n<li>客户端发送第二个报文块，seq为8001+1000=9001，<strong>序号就是数据的offset嘛，很好理解</strong>。ack还是15001，因为服务端没来新的报文嘛。PSH标志还是1，因为还是推送数据。</li>\n<li>服务端这时候收到两个报文，客户端的数据也都传输完了。服务端终于有时间给客户端确认了。这时候它直接发了一个报文，seq为15001，<strong>各自按各自的序号来，必定这是告诉对方自己数据的offset</strong>，ack为8001+1000+1000=10001，<strong>要发确认就一起确认了，没必要每个来自客户端的都得单独确认，记住，序号就是数据的offset</strong>。服务端在确认的同时可能还会返回一些数据，就像上面我说的那个socket接口的例子，这时候就会携带接口的响应数据。比如携带了2000字节的数据。这个报文PSH是不是1，不同的TCP实现不一样。</li>\n<li>服务端收到报文，已经传输完所有的数据，就不需要携带数据了，但是得确认收到服务端的报文，seq为10000，<strong>不携带数据，offset还是之前的10000</strong>，ack为15001+2000=17001。</li>\n</ol>\n<h3 id=\"连接终止\"><a href=\"#连接终止\" class=\"headerlink\" title=\"连接终止\"></a>连接终止</h3><p>参与连接的任何一方都可以关闭连接，一般都是客户端发起。</p>\n<img src=\"/2020/04/04/kongzheng1993-TCP三次握手&四次挥手/51585999731_.pic_hd.jpg\">\n\n\n<ol>\n<li>客户进程告诉自己的TCP关闭连接，TCP发送第一个报文，这个报文把FIN位置1，成为FIN报文段。这个FIN报文段，可以是最后一个数据块，也可以只是一个控制报文段。不携带数据的话，只消耗一个序号。seq：x，ack：y</li>\n<li>服务器TCP在收到合格FIN报文段后，把这种情况告诉它的进程，并发送第二个报文–FIN+ACK报文段，确定客户端的FIN报文，同时也宣布另一个方向正在关闭连接。当然这个报文也可能带着来自服务端的最后一个数据块。如果不携带数据，只消耗一个序号。seq：y，ack：x+1</li>\n<li>客户端TCP发送最后一个报文段，这是一个ACK报文段，确认服务端的FIN报文段。seq：x，ack：y+1</li>\n</ol>\n"},{"title":"chromebook再次折腾crouton","excerpt":"","comments":1,"date":"2020-04-07T16:30:52.000Z","_content":"\n# chromebook再次折腾crouton\n\n## 学生时代的梦想\n\n大学那会儿就梦想有个chromebook，想象着带着这个满满黑科技的笔记本，出入校园，秒杀一众macbook。无奈家境贫寒，而且找不到靠谱的渠道。16年9月刚毕业不久，拿到第一笔工资，我就下单买了这个asus flip c100p chromebook。\n\n<img src=\"taobao.jpg\">\n\n## 无数次折腾\n\n拿到这个chromebook，小巧精美，略微使用了一下，就开始着手折腾装Linux，毕竟这是我买它的初衷，低廉的价格、炫酷的外表、极客的内在，这是我对它爱不释手的原因。\n\n当初不懂事，买的时候没有做攻略，光看着这款chromebook能各种翻折，小，而且会旋转就买了。没仔细看这款chromebook是arm架构的，后面折腾系统真的是折腾死个人啊。\n\nx86架构的本子可以刷bios，从而装各种linux、win，走向它的人生巅峰，可我这个arm的，兼容它的linux发行版真的是少的很，而且折腾的人少，没有战友，也没有经验。\n\n我知道的给asus flip c100p装Linux的方法有下面几种：\n\n- **kali linux：** kali出了一个适配这个本的系统，按照官网的doc可以顺利安装。\n- **arch linux：** arch也出过一个适配的系统，也是按照官网doc安装，但是我死活装不上，在github上提了好几个issue，好不容易装完了，却没法启动。说好的`ctrl+d`进chromeOS，`ctrl+u`进扩展卡里的arch呢?\n- **crouton:** 这个方法是我最想成的，因为他是在chromeOS的系统之上的一个系统，类似于win10的WSL，两个系统可以随时切换而不用重启。可是我之前总是挂在装audio的时候，因为根据crouton的脚本，这时候要去google下载驱动，当时也用了代理，浏览器都能访问，他这掉链子，一怒之下差点卖了它。\n\n我喜欢它的chromeOS，但是也垂涎Linux，开启它的更多使用场景。就这样，我来回折腾了很多次，断断续续，吃灰俩月，再拿出来折腾，折腾累了，再扔到角落吃灰，如此以往，几年都过去了。\n\n## 重新启用\n\n之前很久不用了，前段时间开始写公众号了，想着拿出它来，从chrome store找个好使的markdown编辑器，超强续航，写点东西，岂不美哉。\n\n于是我拿出来开始折腾，看了下空间，之前倒腾系统，乱分区，导致可用空间太少了，所以我打算重新来过。\n\n找了个U盘，装了`chromebook recovery utility`，重装了下系统，正好清一下磁盘。\n\n<img src=\"recovery.bmp\">\n\n新装的系统，录了个视频。有兴趣可以点下面链接看下。\n\n[我的chromebook](https://www.bilibili.com/video/BV1NE411G7fn/)\n\n昨天晚上又疯了，想用chromebook写博客，毕竟它那么小巧，我把它安置在最舒服的地方----我的床头，毕竟躺床上最舒服了。\n\n我的blog用的hexo，就算我能用chromeOS的terminal，vi写博客，也需要`git`、`node.js`来编译和发布啊。\n\n所以没办法，在折腾一次装Linux，鉴于我的chromeOS已经整的比较完美了，想留着用，所以选择`crouton`。\n\n## 如果这次不行，我真挂咸鱼卖了，200就卖！\n\n之前折腾过无数次crouton，会卡在audio，当时翻遍了github，了解到有个大佬，搞了个代理地址，修改crouton源码，把地址替换，可以解决网络的麻烦。\n\n[dubuqingfeng/Chromebook-For-Chinese](https://github.com/dubuqingfeng/Chromebook-For-Chinese)\n\n```shell\n声卡驱动修改说明：\n1.下载Cronton，打包下载，Download Zip\n\n2.更改targets/audio文件:\n\n第47行：\n\n( wget -O \"$archive\" \"$urlbase/$ADHD_HEAD.tar.gz\" 2>&1 \\\n                                    || echo \"Error fetching CRAS\" ) | tee \"$log\"\n改为：\n\n( wget -O \"$archive\" \"http://t.cn/R46YOzM\" 2>&1 \\\n                                    || echo \"Error fetching CRAS\" ) | tee \"$log\"\n\n3.直接运行installer/main.sh,或者make自己的crouton。\n```\n\n这个方法我当年试过，代理地址肯定是不可用了，毕竟几年前的方案了，人家不可能一直负责维护。\n\n关于这块代码我也尝试过修改，它是把驱动文件下载`/tmp`目录，我的思路是直接fq，把文件搞下来，这块改代码复制到`/tmp`目录下呗。\n\n我把这块的代码全给注释，然后加上了下面的代码。\n\n```shell\ncp /home/chronos/user/Dwonloads/xxxxx.tar.gz \"$archive\"\n```\n\n然后满心欢喜的`sudo sh install/main.sh`，可是不行啊，每次都找不到文件，我单独执行这个命令却完全可以复制……后来怀疑是每次进chronos，用户目录名都会发生变化才导致这个原因。\n\n通过查看crouton的帮助能知道`-P`选项可以设置代理地址，`-m`可以设置镜像地址。\n\n于是使用自己的代理和中科大的镜像开始安装：\n\n```shell\nsudo crouton -r trusty -t core,xorg,x11,gtk-extra,xfce,keyboard,cli-extra  -m http://mirrors.ustc.edu.cn/ubuntu-ports -P 10.10.10.185:1077\n```\n\n卡在声卡驱动的地方，通过看输出的日志了解到并没有走代理地址。后来尝试修改代理地址为`http://10.10.10.185:1077`。\n这次走代理了，声卡也能正常下载文件，但是最后还是有问题：\n\n```shell\nnstalling target audio...\nFetching CRAS (branch aefe8a7296df698ba86e49b181e93ca2fa2510d1)...\n--2020-04-08 16:59:50--  https://chromium.googlesource.com/chromiumos/third_party/adhd/+archive/aefe8a7296df698ba86e49b181e93ca2fa2510d1.tar.gz\nConnecting to 10.10.10.185:1077... connected.\nProxy request sent, awaiting response... 200 OK\nLength: unspecified [application/x-gzip]\nSaving to: '/tmp/crouton-cras.RSihAP/adhd.tar.gz'\n\n     0K .......... .......... .......... .......... ..........  106K\n    50K .......... .......... .......... .......... ..........  242K\n   100K .......... .......... .......... .......... .......... 99.5K\n   150K .......... .......... .......... .......... ..........  769K\n   200K .......... .......... .......... .......... .......... 1.22M\n   250K .......... .......... .......... .......... ..........  408K\n   300K .......... .......... .......... .......... .......... 1.35M\n   350K .......... .......... .......... .......... .......... 3.36M\n   400K .......... .......... .......... .......... ..........  739K\n   450K .......... .......... .......... .......... ..........  793K\n   500K .......... .......... .......... .......... ..........  859K\n   550K .......... .......... .......... .......... .......... 1.48M\n   600K .......... .......... .......... .......... ..........  273K\n   650K .......... .......... .......... .......... .......... 2.24M\n   700K .......... .......... .......... .......... .......... 2.57M\n   750K .......... .......... .......... .......... .....      4.13M=1.9s\n\n2020-04-08 16:59:54 (416 KB/s) - '/tmp/crouton-cras.RSihAP/adhd.tar.gz' saved [814734]\n\nReading package lists... Done\nBuilding dependency tree\nReading state information... Done\nThe following extra packages will be installed:\n  libasound2-data libsamplerate0\nSuggested packages:\n  libasound2-plugins\nRecommended packages:\n  alsa-base\nThe following NEW packages will be installed:\n  alsa-utils libasound2 libasound2-data libsamplerate0 libspeexdsp1\n0 upgraded, 5 newly installed, 0 to remove and 0 not upgraded.\nNeed to get 2196 kB of archives.\nAfter this operation, 4784 kB of additional disk space will be used.\nWARNING: The following packages cannot be authenticated!\n  libasound2-data libasound2 libsamplerate0 libspeexdsp1 alsa-utils\nE: There are problems and -y was used without --force-yes\nFailed to complete chroot setup.\nUnmounting /mnt/stateful_partition/crouton/chroots/trusty...\n```\n\n启动试了下，还是之前的报错：\n\n```shell\nUID 1000 not found in trusty\n```\n\n往前翻了一下日志，发现从中科大镜像站下载竟然有很多失败的。我复制了其中一个url到浏览器，网络确实不通。\n\n**陷入沉思。。。**\n\n中间吃了个火锅，女朋友从菜市场买来的牛肉^^_^^\n\n填饱肚子，静下心来，突然灵光乍现----我用了代理，代理服务器在国外，那么代理服务器到中科大不通？？我通过代理访问中科大镜像站，没问题，但是顺着目录一步一步往下走，到`trusty`下，就再也不能前进了，我突然明白了什么，但是又不明白为什么主站能访问到，这个目录却无法访问。。\n\n怎么解决？\n\n1. 代理服务器到中科大镜像站不通\n2. 不用代理没法正常安装audio\n\n综上两点，我决定换成ubuntu官方源试试，先通过代理试了下，能正常访问，然后开始安装：\n\n```shell\nsudo crouton -r trusty -t core,xorg,x11,gtk-extra,xfce,keyboard,cli-extra  -m http://ports.ubuntu.com/ubuntu-ports -P http://10.10.10.185:1077\n```\n\n**功夫不负有心人！！！**\n\n<img src=\"finishInstall.jpg\">\n\n启动xfce试试：\n\n```shell\nsudo startxfce4\n```\n\n略微卡顿，来到了我期待已久的桌面！！！\n\n<img src=\"xfce4.jpg\">\n\n看下系统版本\n\n<img src=\"linuxRelease.jpg\">\n\n圆满成功！！！\n接下来就是好好整整这个ubuntu了，装各种环境，啦啦啦。。\n","source":"_posts/2020-04-08-kongzheng1993-chromebook再次折腾crouton.md","raw":"---\ntitle: chromebook再次折腾crouton\nexcerpt: ''\ntags: [other]\ncategories: [other]\ncomments: true\ndate: 2020-04-08 00:30:52\n---\n\n# chromebook再次折腾crouton\n\n## 学生时代的梦想\n\n大学那会儿就梦想有个chromebook，想象着带着这个满满黑科技的笔记本，出入校园，秒杀一众macbook。无奈家境贫寒，而且找不到靠谱的渠道。16年9月刚毕业不久，拿到第一笔工资，我就下单买了这个asus flip c100p chromebook。\n\n<img src=\"taobao.jpg\">\n\n## 无数次折腾\n\n拿到这个chromebook，小巧精美，略微使用了一下，就开始着手折腾装Linux，毕竟这是我买它的初衷，低廉的价格、炫酷的外表、极客的内在，这是我对它爱不释手的原因。\n\n当初不懂事，买的时候没有做攻略，光看着这款chromebook能各种翻折，小，而且会旋转就买了。没仔细看这款chromebook是arm架构的，后面折腾系统真的是折腾死个人啊。\n\nx86架构的本子可以刷bios，从而装各种linux、win，走向它的人生巅峰，可我这个arm的，兼容它的linux发行版真的是少的很，而且折腾的人少，没有战友，也没有经验。\n\n我知道的给asus flip c100p装Linux的方法有下面几种：\n\n- **kali linux：** kali出了一个适配这个本的系统，按照官网的doc可以顺利安装。\n- **arch linux：** arch也出过一个适配的系统，也是按照官网doc安装，但是我死活装不上，在github上提了好几个issue，好不容易装完了，却没法启动。说好的`ctrl+d`进chromeOS，`ctrl+u`进扩展卡里的arch呢?\n- **crouton:** 这个方法是我最想成的，因为他是在chromeOS的系统之上的一个系统，类似于win10的WSL，两个系统可以随时切换而不用重启。可是我之前总是挂在装audio的时候，因为根据crouton的脚本，这时候要去google下载驱动，当时也用了代理，浏览器都能访问，他这掉链子，一怒之下差点卖了它。\n\n我喜欢它的chromeOS，但是也垂涎Linux，开启它的更多使用场景。就这样，我来回折腾了很多次，断断续续，吃灰俩月，再拿出来折腾，折腾累了，再扔到角落吃灰，如此以往，几年都过去了。\n\n## 重新启用\n\n之前很久不用了，前段时间开始写公众号了，想着拿出它来，从chrome store找个好使的markdown编辑器，超强续航，写点东西，岂不美哉。\n\n于是我拿出来开始折腾，看了下空间，之前倒腾系统，乱分区，导致可用空间太少了，所以我打算重新来过。\n\n找了个U盘，装了`chromebook recovery utility`，重装了下系统，正好清一下磁盘。\n\n<img src=\"recovery.bmp\">\n\n新装的系统，录了个视频。有兴趣可以点下面链接看下。\n\n[我的chromebook](https://www.bilibili.com/video/BV1NE411G7fn/)\n\n昨天晚上又疯了，想用chromebook写博客，毕竟它那么小巧，我把它安置在最舒服的地方----我的床头，毕竟躺床上最舒服了。\n\n我的blog用的hexo，就算我能用chromeOS的terminal，vi写博客，也需要`git`、`node.js`来编译和发布啊。\n\n所以没办法，在折腾一次装Linux，鉴于我的chromeOS已经整的比较完美了，想留着用，所以选择`crouton`。\n\n## 如果这次不行，我真挂咸鱼卖了，200就卖！\n\n之前折腾过无数次crouton，会卡在audio，当时翻遍了github，了解到有个大佬，搞了个代理地址，修改crouton源码，把地址替换，可以解决网络的麻烦。\n\n[dubuqingfeng/Chromebook-For-Chinese](https://github.com/dubuqingfeng/Chromebook-For-Chinese)\n\n```shell\n声卡驱动修改说明：\n1.下载Cronton，打包下载，Download Zip\n\n2.更改targets/audio文件:\n\n第47行：\n\n( wget -O \"$archive\" \"$urlbase/$ADHD_HEAD.tar.gz\" 2>&1 \\\n                                    || echo \"Error fetching CRAS\" ) | tee \"$log\"\n改为：\n\n( wget -O \"$archive\" \"http://t.cn/R46YOzM\" 2>&1 \\\n                                    || echo \"Error fetching CRAS\" ) | tee \"$log\"\n\n3.直接运行installer/main.sh,或者make自己的crouton。\n```\n\n这个方法我当年试过，代理地址肯定是不可用了，毕竟几年前的方案了，人家不可能一直负责维护。\n\n关于这块代码我也尝试过修改，它是把驱动文件下载`/tmp`目录，我的思路是直接fq，把文件搞下来，这块改代码复制到`/tmp`目录下呗。\n\n我把这块的代码全给注释，然后加上了下面的代码。\n\n```shell\ncp /home/chronos/user/Dwonloads/xxxxx.tar.gz \"$archive\"\n```\n\n然后满心欢喜的`sudo sh install/main.sh`，可是不行啊，每次都找不到文件，我单独执行这个命令却完全可以复制……后来怀疑是每次进chronos，用户目录名都会发生变化才导致这个原因。\n\n通过查看crouton的帮助能知道`-P`选项可以设置代理地址，`-m`可以设置镜像地址。\n\n于是使用自己的代理和中科大的镜像开始安装：\n\n```shell\nsudo crouton -r trusty -t core,xorg,x11,gtk-extra,xfce,keyboard,cli-extra  -m http://mirrors.ustc.edu.cn/ubuntu-ports -P 10.10.10.185:1077\n```\n\n卡在声卡驱动的地方，通过看输出的日志了解到并没有走代理地址。后来尝试修改代理地址为`http://10.10.10.185:1077`。\n这次走代理了，声卡也能正常下载文件，但是最后还是有问题：\n\n```shell\nnstalling target audio...\nFetching CRAS (branch aefe8a7296df698ba86e49b181e93ca2fa2510d1)...\n--2020-04-08 16:59:50--  https://chromium.googlesource.com/chromiumos/third_party/adhd/+archive/aefe8a7296df698ba86e49b181e93ca2fa2510d1.tar.gz\nConnecting to 10.10.10.185:1077... connected.\nProxy request sent, awaiting response... 200 OK\nLength: unspecified [application/x-gzip]\nSaving to: '/tmp/crouton-cras.RSihAP/adhd.tar.gz'\n\n     0K .......... .......... .......... .......... ..........  106K\n    50K .......... .......... .......... .......... ..........  242K\n   100K .......... .......... .......... .......... .......... 99.5K\n   150K .......... .......... .......... .......... ..........  769K\n   200K .......... .......... .......... .......... .......... 1.22M\n   250K .......... .......... .......... .......... ..........  408K\n   300K .......... .......... .......... .......... .......... 1.35M\n   350K .......... .......... .......... .......... .......... 3.36M\n   400K .......... .......... .......... .......... ..........  739K\n   450K .......... .......... .......... .......... ..........  793K\n   500K .......... .......... .......... .......... ..........  859K\n   550K .......... .......... .......... .......... .......... 1.48M\n   600K .......... .......... .......... .......... ..........  273K\n   650K .......... .......... .......... .......... .......... 2.24M\n   700K .......... .......... .......... .......... .......... 2.57M\n   750K .......... .......... .......... .......... .....      4.13M=1.9s\n\n2020-04-08 16:59:54 (416 KB/s) - '/tmp/crouton-cras.RSihAP/adhd.tar.gz' saved [814734]\n\nReading package lists... Done\nBuilding dependency tree\nReading state information... Done\nThe following extra packages will be installed:\n  libasound2-data libsamplerate0\nSuggested packages:\n  libasound2-plugins\nRecommended packages:\n  alsa-base\nThe following NEW packages will be installed:\n  alsa-utils libasound2 libasound2-data libsamplerate0 libspeexdsp1\n0 upgraded, 5 newly installed, 0 to remove and 0 not upgraded.\nNeed to get 2196 kB of archives.\nAfter this operation, 4784 kB of additional disk space will be used.\nWARNING: The following packages cannot be authenticated!\n  libasound2-data libasound2 libsamplerate0 libspeexdsp1 alsa-utils\nE: There are problems and -y was used without --force-yes\nFailed to complete chroot setup.\nUnmounting /mnt/stateful_partition/crouton/chroots/trusty...\n```\n\n启动试了下，还是之前的报错：\n\n```shell\nUID 1000 not found in trusty\n```\n\n往前翻了一下日志，发现从中科大镜像站下载竟然有很多失败的。我复制了其中一个url到浏览器，网络确实不通。\n\n**陷入沉思。。。**\n\n中间吃了个火锅，女朋友从菜市场买来的牛肉^^_^^\n\n填饱肚子，静下心来，突然灵光乍现----我用了代理，代理服务器在国外，那么代理服务器到中科大不通？？我通过代理访问中科大镜像站，没问题，但是顺着目录一步一步往下走，到`trusty`下，就再也不能前进了，我突然明白了什么，但是又不明白为什么主站能访问到，这个目录却无法访问。。\n\n怎么解决？\n\n1. 代理服务器到中科大镜像站不通\n2. 不用代理没法正常安装audio\n\n综上两点，我决定换成ubuntu官方源试试，先通过代理试了下，能正常访问，然后开始安装：\n\n```shell\nsudo crouton -r trusty -t core,xorg,x11,gtk-extra,xfce,keyboard,cli-extra  -m http://ports.ubuntu.com/ubuntu-ports -P http://10.10.10.185:1077\n```\n\n**功夫不负有心人！！！**\n\n<img src=\"finishInstall.jpg\">\n\n启动xfce试试：\n\n```shell\nsudo startxfce4\n```\n\n略微卡顿，来到了我期待已久的桌面！！！\n\n<img src=\"xfce4.jpg\">\n\n看下系统版本\n\n<img src=\"linuxRelease.jpg\">\n\n圆满成功！！！\n接下来就是好好整整这个ubuntu了，装各种环境，啦啦啦。。\n","slug":"kongzheng1993-chromebook再次折腾crouton","published":1,"updated":"2023-03-08T07:05:58.792Z","layout":"post","photos":[],"link":"","_id":"clg0k2aq200hxt26f3l518d6l","content":"<h1 id=\"chromebook再次折腾crouton\"><a href=\"#chromebook再次折腾crouton\" class=\"headerlink\" title=\"chromebook再次折腾crouton\"></a>chromebook再次折腾crouton</h1><h2 id=\"学生时代的梦想\"><a href=\"#学生时代的梦想\" class=\"headerlink\" title=\"学生时代的梦想\"></a>学生时代的梦想</h2><p>大学那会儿就梦想有个chromebook，想象着带着这个满满黑科技的笔记本，出入校园，秒杀一众macbook。无奈家境贫寒，而且找不到靠谱的渠道。16年9月刚毕业不久，拿到第一笔工资，我就下单买了这个asus flip c100p chromebook。</p>\n<img src=\"/2020/04/08/kongzheng1993-chromebook再次折腾crouton/taobao.jpg\">\n\n<h2 id=\"无数次折腾\"><a href=\"#无数次折腾\" class=\"headerlink\" title=\"无数次折腾\"></a>无数次折腾</h2><p>拿到这个chromebook，小巧精美，略微使用了一下，就开始着手折腾装Linux，毕竟这是我买它的初衷，低廉的价格、炫酷的外表、极客的内在，这是我对它爱不释手的原因。</p>\n<p>当初不懂事，买的时候没有做攻略，光看着这款chromebook能各种翻折，小，而且会旋转就买了。没仔细看这款chromebook是arm架构的，后面折腾系统真的是折腾死个人啊。</p>\n<p>x86架构的本子可以刷bios，从而装各种linux、win，走向它的人生巅峰，可我这个arm的，兼容它的linux发行版真的是少的很，而且折腾的人少，没有战友，也没有经验。</p>\n<p>我知道的给asus flip c100p装Linux的方法有下面几种：</p>\n<ul>\n<li><strong>kali linux：</strong> kali出了一个适配这个本的系统，按照官网的doc可以顺利安装。</li>\n<li><strong>arch linux：</strong> arch也出过一个适配的系统，也是按照官网doc安装，但是我死活装不上，在github上提了好几个issue，好不容易装完了，却没法启动。说好的<code>ctrl+d</code>进chromeOS，<code>ctrl+u</code>进扩展卡里的arch呢?</li>\n<li><strong>crouton:</strong> 这个方法是我最想成的，因为他是在chromeOS的系统之上的一个系统，类似于win10的WSL，两个系统可以随时切换而不用重启。可是我之前总是挂在装audio的时候，因为根据crouton的脚本，这时候要去google下载驱动，当时也用了代理，浏览器都能访问，他这掉链子，一怒之下差点卖了它。</li>\n</ul>\n<p>我喜欢它的chromeOS，但是也垂涎Linux，开启它的更多使用场景。就这样，我来回折腾了很多次，断断续续，吃灰俩月，再拿出来折腾，折腾累了，再扔到角落吃灰，如此以往，几年都过去了。</p>\n<h2 id=\"重新启用\"><a href=\"#重新启用\" class=\"headerlink\" title=\"重新启用\"></a>重新启用</h2><p>之前很久不用了，前段时间开始写公众号了，想着拿出它来，从chrome store找个好使的markdown编辑器，超强续航，写点东西，岂不美哉。</p>\n<p>于是我拿出来开始折腾，看了下空间，之前倒腾系统，乱分区，导致可用空间太少了，所以我打算重新来过。</p>\n<p>找了个U盘，装了<code>chromebook recovery utility</code>，重装了下系统，正好清一下磁盘。</p>\n<img src=\"/2020/04/08/kongzheng1993-chromebook再次折腾crouton/recovery.bmp\">\n\n<p>新装的系统，录了个视频。有兴趣可以点下面链接看下。</p>\n<p><a href=\"https://www.bilibili.com/video/BV1NE411G7fn/\" target=\"_blank\" rel=\"noopener\">我的chromebook</a></p>\n<p>昨天晚上又疯了，想用chromebook写博客，毕竟它那么小巧，我把它安置在最舒服的地方—-我的床头，毕竟躺床上最舒服了。</p>\n<p>我的blog用的hexo，就算我能用chromeOS的terminal，vi写博客，也需要<code>git</code>、<code>node.js</code>来编译和发布啊。</p>\n<p>所以没办法，在折腾一次装Linux，鉴于我的chromeOS已经整的比较完美了，想留着用，所以选择<code>crouton</code>。</p>\n<h2 id=\"如果这次不行，我真挂咸鱼卖了，200就卖！\"><a href=\"#如果这次不行，我真挂咸鱼卖了，200就卖！\" class=\"headerlink\" title=\"如果这次不行，我真挂咸鱼卖了，200就卖！\"></a>如果这次不行，我真挂咸鱼卖了，200就卖！</h2><p>之前折腾过无数次crouton，会卡在audio，当时翻遍了github，了解到有个大佬，搞了个代理地址，修改crouton源码，把地址替换，可以解决网络的麻烦。</p>\n<p><a href=\"https://github.com/dubuqingfeng/Chromebook-For-Chinese\" target=\"_blank\" rel=\"noopener\">dubuqingfeng/Chromebook-For-Chinese</a></p>\n<pre><code class=\"shell\">声卡驱动修改说明：\n1.下载Cronton，打包下载，Download Zip\n\n2.更改targets/audio文件:\n\n第47行：\n\n( wget -O &quot;$archive&quot; &quot;$urlbase/$ADHD_HEAD.tar.gz&quot; 2&gt;&amp;1 \\\n                                    || echo &quot;Error fetching CRAS&quot; ) | tee &quot;$log&quot;\n改为：\n\n( wget -O &quot;$archive&quot; &quot;http://t.cn/R46YOzM&quot; 2&gt;&amp;1 \\\n                                    || echo &quot;Error fetching CRAS&quot; ) | tee &quot;$log&quot;\n\n3.直接运行installer/main.sh,或者make自己的crouton。</code></pre>\n<p>这个方法我当年试过，代理地址肯定是不可用了，毕竟几年前的方案了，人家不可能一直负责维护。</p>\n<p>关于这块代码我也尝试过修改，它是把驱动文件下载<code>/tmp</code>目录，我的思路是直接fq，把文件搞下来，这块改代码复制到<code>/tmp</code>目录下呗。</p>\n<p>我把这块的代码全给注释，然后加上了下面的代码。</p>\n<pre><code class=\"shell\">cp /home/chronos/user/Dwonloads/xxxxx.tar.gz &quot;$archive&quot;</code></pre>\n<p>然后满心欢喜的<code>sudo sh install/main.sh</code>，可是不行啊，每次都找不到文件，我单独执行这个命令却完全可以复制……后来怀疑是每次进chronos，用户目录名都会发生变化才导致这个原因。</p>\n<p>通过查看crouton的帮助能知道<code>-P</code>选项可以设置代理地址，<code>-m</code>可以设置镜像地址。</p>\n<p>于是使用自己的代理和中科大的镜像开始安装：</p>\n<pre><code class=\"shell\">sudo crouton -r trusty -t core,xorg,x11,gtk-extra,xfce,keyboard,cli-extra  -m http://mirrors.ustc.edu.cn/ubuntu-ports -P 10.10.10.185:1077</code></pre>\n<p>卡在声卡驱动的地方，通过看输出的日志了解到并没有走代理地址。后来尝试修改代理地址为<code>http://10.10.10.185:1077</code>。\n这次走代理了，声卡也能正常下载文件，但是最后还是有问题：</p>\n<pre><code class=\"shell\">nstalling target audio...\nFetching CRAS (branch aefe8a7296df698ba86e49b181e93ca2fa2510d1)...\n--2020-04-08 16:59:50--  https://chromium.googlesource.com/chromiumos/third_party/adhd/+archive/aefe8a7296df698ba86e49b181e93ca2fa2510d1.tar.gz\nConnecting to 10.10.10.185:1077... connected.\nProxy request sent, awaiting response... 200 OK\nLength: unspecified [application/x-gzip]\nSaving to: &#39;/tmp/crouton-cras.RSihAP/adhd.tar.gz&#39;\n\n     0K .......... .......... .......... .......... ..........  106K\n    50K .......... .......... .......... .......... ..........  242K\n   100K .......... .......... .......... .......... .......... 99.5K\n   150K .......... .......... .......... .......... ..........  769K\n   200K .......... .......... .......... .......... .......... 1.22M\n   250K .......... .......... .......... .......... ..........  408K\n   300K .......... .......... .......... .......... .......... 1.35M\n   350K .......... .......... .......... .......... .......... 3.36M\n   400K .......... .......... .......... .......... ..........  739K\n   450K .......... .......... .......... .......... ..........  793K\n   500K .......... .......... .......... .......... ..........  859K\n   550K .......... .......... .......... .......... .......... 1.48M\n   600K .......... .......... .......... .......... ..........  273K\n   650K .......... .......... .......... .......... .......... 2.24M\n   700K .......... .......... .......... .......... .......... 2.57M\n   750K .......... .......... .......... .......... .....      4.13M=1.9s\n\n2020-04-08 16:59:54 (416 KB/s) - &#39;/tmp/crouton-cras.RSihAP/adhd.tar.gz&#39; saved [814734]\n\nReading package lists... Done\nBuilding dependency tree\nReading state information... Done\nThe following extra packages will be installed:\n  libasound2-data libsamplerate0\nSuggested packages:\n  libasound2-plugins\nRecommended packages:\n  alsa-base\nThe following NEW packages will be installed:\n  alsa-utils libasound2 libasound2-data libsamplerate0 libspeexdsp1\n0 upgraded, 5 newly installed, 0 to remove and 0 not upgraded.\nNeed to get 2196 kB of archives.\nAfter this operation, 4784 kB of additional disk space will be used.\nWARNING: The following packages cannot be authenticated!\n  libasound2-data libasound2 libsamplerate0 libspeexdsp1 alsa-utils\nE: There are problems and -y was used without --force-yes\nFailed to complete chroot setup.\nUnmounting /mnt/stateful_partition/crouton/chroots/trusty...</code></pre>\n<p>启动试了下，还是之前的报错：</p>\n<pre><code class=\"shell\">UID 1000 not found in trusty</code></pre>\n<p>往前翻了一下日志，发现从中科大镜像站下载竟然有很多失败的。我复制了其中一个url到浏览器，网络确实不通。</p>\n<p><strong>陷入沉思。。。</strong></p>\n<p>中间吃了个火锅，女朋友从菜市场买来的牛肉^^_^^</p>\n<p>填饱肚子，静下心来，突然灵光乍现—-我用了代理，代理服务器在国外，那么代理服务器到中科大不通？？我通过代理访问中科大镜像站，没问题，但是顺着目录一步一步往下走，到<code>trusty</code>下，就再也不能前进了，我突然明白了什么，但是又不明白为什么主站能访问到，这个目录却无法访问。。</p>\n<p>怎么解决？</p>\n<ol>\n<li>代理服务器到中科大镜像站不通</li>\n<li>不用代理没法正常安装audio</li>\n</ol>\n<p>综上两点，我决定换成ubuntu官方源试试，先通过代理试了下，能正常访问，然后开始安装：</p>\n<pre><code class=\"shell\">sudo crouton -r trusty -t core,xorg,x11,gtk-extra,xfce,keyboard,cli-extra  -m http://ports.ubuntu.com/ubuntu-ports -P http://10.10.10.185:1077</code></pre>\n<p><strong>功夫不负有心人！！！</strong></p>\n<img src=\"/2020/04/08/kongzheng1993-chromebook再次折腾crouton/finishInstall.jpg\">\n\n<p>启动xfce试试：</p>\n<pre><code class=\"shell\">sudo startxfce4</code></pre>\n<p>略微卡顿，来到了我期待已久的桌面！！！</p>\n<img src=\"/2020/04/08/kongzheng1993-chromebook再次折腾crouton/xfce4.jpg\">\n\n<p>看下系统版本</p>\n<img src=\"/2020/04/08/kongzheng1993-chromebook再次折腾crouton/linuxRelease.jpg\">\n\n<p>圆满成功！！！<br>接下来就是好好整整这个ubuntu了，装各种环境，啦啦啦。。</p>\n","site":{"data":{}},"more":"<h1 id=\"chromebook再次折腾crouton\"><a href=\"#chromebook再次折腾crouton\" class=\"headerlink\" title=\"chromebook再次折腾crouton\"></a>chromebook再次折腾crouton</h1><h2 id=\"学生时代的梦想\"><a href=\"#学生时代的梦想\" class=\"headerlink\" title=\"学生时代的梦想\"></a>学生时代的梦想</h2><p>大学那会儿就梦想有个chromebook，想象着带着这个满满黑科技的笔记本，出入校园，秒杀一众macbook。无奈家境贫寒，而且找不到靠谱的渠道。16年9月刚毕业不久，拿到第一笔工资，我就下单买了这个asus flip c100p chromebook。</p>\n<img src=\"/2020/04/08/kongzheng1993-chromebook再次折腾crouton/taobao.jpg\">\n\n<h2 id=\"无数次折腾\"><a href=\"#无数次折腾\" class=\"headerlink\" title=\"无数次折腾\"></a>无数次折腾</h2><p>拿到这个chromebook，小巧精美，略微使用了一下，就开始着手折腾装Linux，毕竟这是我买它的初衷，低廉的价格、炫酷的外表、极客的内在，这是我对它爱不释手的原因。</p>\n<p>当初不懂事，买的时候没有做攻略，光看着这款chromebook能各种翻折，小，而且会旋转就买了。没仔细看这款chromebook是arm架构的，后面折腾系统真的是折腾死个人啊。</p>\n<p>x86架构的本子可以刷bios，从而装各种linux、win，走向它的人生巅峰，可我这个arm的，兼容它的linux发行版真的是少的很，而且折腾的人少，没有战友，也没有经验。</p>\n<p>我知道的给asus flip c100p装Linux的方法有下面几种：</p>\n<ul>\n<li><strong>kali linux：</strong> kali出了一个适配这个本的系统，按照官网的doc可以顺利安装。</li>\n<li><strong>arch linux：</strong> arch也出过一个适配的系统，也是按照官网doc安装，但是我死活装不上，在github上提了好几个issue，好不容易装完了，却没法启动。说好的<code>ctrl+d</code>进chromeOS，<code>ctrl+u</code>进扩展卡里的arch呢?</li>\n<li><strong>crouton:</strong> 这个方法是我最想成的，因为他是在chromeOS的系统之上的一个系统，类似于win10的WSL，两个系统可以随时切换而不用重启。可是我之前总是挂在装audio的时候，因为根据crouton的脚本，这时候要去google下载驱动，当时也用了代理，浏览器都能访问，他这掉链子，一怒之下差点卖了它。</li>\n</ul>\n<p>我喜欢它的chromeOS，但是也垂涎Linux，开启它的更多使用场景。就这样，我来回折腾了很多次，断断续续，吃灰俩月，再拿出来折腾，折腾累了，再扔到角落吃灰，如此以往，几年都过去了。</p>\n<h2 id=\"重新启用\"><a href=\"#重新启用\" class=\"headerlink\" title=\"重新启用\"></a>重新启用</h2><p>之前很久不用了，前段时间开始写公众号了，想着拿出它来，从chrome store找个好使的markdown编辑器，超强续航，写点东西，岂不美哉。</p>\n<p>于是我拿出来开始折腾，看了下空间，之前倒腾系统，乱分区，导致可用空间太少了，所以我打算重新来过。</p>\n<p>找了个U盘，装了<code>chromebook recovery utility</code>，重装了下系统，正好清一下磁盘。</p>\n<img src=\"/2020/04/08/kongzheng1993-chromebook再次折腾crouton/recovery.bmp\">\n\n<p>新装的系统，录了个视频。有兴趣可以点下面链接看下。</p>\n<p><a href=\"https://www.bilibili.com/video/BV1NE411G7fn/\" target=\"_blank\" rel=\"noopener\">我的chromebook</a></p>\n<p>昨天晚上又疯了，想用chromebook写博客，毕竟它那么小巧，我把它安置在最舒服的地方—-我的床头，毕竟躺床上最舒服了。</p>\n<p>我的blog用的hexo，就算我能用chromeOS的terminal，vi写博客，也需要<code>git</code>、<code>node.js</code>来编译和发布啊。</p>\n<p>所以没办法，在折腾一次装Linux，鉴于我的chromeOS已经整的比较完美了，想留着用，所以选择<code>crouton</code>。</p>\n<h2 id=\"如果这次不行，我真挂咸鱼卖了，200就卖！\"><a href=\"#如果这次不行，我真挂咸鱼卖了，200就卖！\" class=\"headerlink\" title=\"如果这次不行，我真挂咸鱼卖了，200就卖！\"></a>如果这次不行，我真挂咸鱼卖了，200就卖！</h2><p>之前折腾过无数次crouton，会卡在audio，当时翻遍了github，了解到有个大佬，搞了个代理地址，修改crouton源码，把地址替换，可以解决网络的麻烦。</p>\n<p><a href=\"https://github.com/dubuqingfeng/Chromebook-For-Chinese\" target=\"_blank\" rel=\"noopener\">dubuqingfeng/Chromebook-For-Chinese</a></p>\n<pre><code class=\"shell\">声卡驱动修改说明：\n1.下载Cronton，打包下载，Download Zip\n\n2.更改targets/audio文件:\n\n第47行：\n\n( wget -O &quot;$archive&quot; &quot;$urlbase/$ADHD_HEAD.tar.gz&quot; 2&gt;&amp;1 \\\n                                    || echo &quot;Error fetching CRAS&quot; ) | tee &quot;$log&quot;\n改为：\n\n( wget -O &quot;$archive&quot; &quot;http://t.cn/R46YOzM&quot; 2&gt;&amp;1 \\\n                                    || echo &quot;Error fetching CRAS&quot; ) | tee &quot;$log&quot;\n\n3.直接运行installer/main.sh,或者make自己的crouton。</code></pre>\n<p>这个方法我当年试过，代理地址肯定是不可用了，毕竟几年前的方案了，人家不可能一直负责维护。</p>\n<p>关于这块代码我也尝试过修改，它是把驱动文件下载<code>/tmp</code>目录，我的思路是直接fq，把文件搞下来，这块改代码复制到<code>/tmp</code>目录下呗。</p>\n<p>我把这块的代码全给注释，然后加上了下面的代码。</p>\n<pre><code class=\"shell\">cp /home/chronos/user/Dwonloads/xxxxx.tar.gz &quot;$archive&quot;</code></pre>\n<p>然后满心欢喜的<code>sudo sh install/main.sh</code>，可是不行啊，每次都找不到文件，我单独执行这个命令却完全可以复制……后来怀疑是每次进chronos，用户目录名都会发生变化才导致这个原因。</p>\n<p>通过查看crouton的帮助能知道<code>-P</code>选项可以设置代理地址，<code>-m</code>可以设置镜像地址。</p>\n<p>于是使用自己的代理和中科大的镜像开始安装：</p>\n<pre><code class=\"shell\">sudo crouton -r trusty -t core,xorg,x11,gtk-extra,xfce,keyboard,cli-extra  -m http://mirrors.ustc.edu.cn/ubuntu-ports -P 10.10.10.185:1077</code></pre>\n<p>卡在声卡驱动的地方，通过看输出的日志了解到并没有走代理地址。后来尝试修改代理地址为<code>http://10.10.10.185:1077</code>。\n这次走代理了，声卡也能正常下载文件，但是最后还是有问题：</p>\n<pre><code class=\"shell\">nstalling target audio...\nFetching CRAS (branch aefe8a7296df698ba86e49b181e93ca2fa2510d1)...\n--2020-04-08 16:59:50--  https://chromium.googlesource.com/chromiumos/third_party/adhd/+archive/aefe8a7296df698ba86e49b181e93ca2fa2510d1.tar.gz\nConnecting to 10.10.10.185:1077... connected.\nProxy request sent, awaiting response... 200 OK\nLength: unspecified [application/x-gzip]\nSaving to: &#39;/tmp/crouton-cras.RSihAP/adhd.tar.gz&#39;\n\n     0K .......... .......... .......... .......... ..........  106K\n    50K .......... .......... .......... .......... ..........  242K\n   100K .......... .......... .......... .......... .......... 99.5K\n   150K .......... .......... .......... .......... ..........  769K\n   200K .......... .......... .......... .......... .......... 1.22M\n   250K .......... .......... .......... .......... ..........  408K\n   300K .......... .......... .......... .......... .......... 1.35M\n   350K .......... .......... .......... .......... .......... 3.36M\n   400K .......... .......... .......... .......... ..........  739K\n   450K .......... .......... .......... .......... ..........  793K\n   500K .......... .......... .......... .......... ..........  859K\n   550K .......... .......... .......... .......... .......... 1.48M\n   600K .......... .......... .......... .......... ..........  273K\n   650K .......... .......... .......... .......... .......... 2.24M\n   700K .......... .......... .......... .......... .......... 2.57M\n   750K .......... .......... .......... .......... .....      4.13M=1.9s\n\n2020-04-08 16:59:54 (416 KB/s) - &#39;/tmp/crouton-cras.RSihAP/adhd.tar.gz&#39; saved [814734]\n\nReading package lists... Done\nBuilding dependency tree\nReading state information... Done\nThe following extra packages will be installed:\n  libasound2-data libsamplerate0\nSuggested packages:\n  libasound2-plugins\nRecommended packages:\n  alsa-base\nThe following NEW packages will be installed:\n  alsa-utils libasound2 libasound2-data libsamplerate0 libspeexdsp1\n0 upgraded, 5 newly installed, 0 to remove and 0 not upgraded.\nNeed to get 2196 kB of archives.\nAfter this operation, 4784 kB of additional disk space will be used.\nWARNING: The following packages cannot be authenticated!\n  libasound2-data libasound2 libsamplerate0 libspeexdsp1 alsa-utils\nE: There are problems and -y was used without --force-yes\nFailed to complete chroot setup.\nUnmounting /mnt/stateful_partition/crouton/chroots/trusty...</code></pre>\n<p>启动试了下，还是之前的报错：</p>\n<pre><code class=\"shell\">UID 1000 not found in trusty</code></pre>\n<p>往前翻了一下日志，发现从中科大镜像站下载竟然有很多失败的。我复制了其中一个url到浏览器，网络确实不通。</p>\n<p><strong>陷入沉思。。。</strong></p>\n<p>中间吃了个火锅，女朋友从菜市场买来的牛肉^^_^^</p>\n<p>填饱肚子，静下心来，突然灵光乍现—-我用了代理，代理服务器在国外，那么代理服务器到中科大不通？？我通过代理访问中科大镜像站，没问题，但是顺着目录一步一步往下走，到<code>trusty</code>下，就再也不能前进了，我突然明白了什么，但是又不明白为什么主站能访问到，这个目录却无法访问。。</p>\n<p>怎么解决？</p>\n<ol>\n<li>代理服务器到中科大镜像站不通</li>\n<li>不用代理没法正常安装audio</li>\n</ol>\n<p>综上两点，我决定换成ubuntu官方源试试，先通过代理试了下，能正常访问，然后开始安装：</p>\n<pre><code class=\"shell\">sudo crouton -r trusty -t core,xorg,x11,gtk-extra,xfce,keyboard,cli-extra  -m http://ports.ubuntu.com/ubuntu-ports -P http://10.10.10.185:1077</code></pre>\n<p><strong>功夫不负有心人！！！</strong></p>\n<img src=\"/2020/04/08/kongzheng1993-chromebook再次折腾crouton/finishInstall.jpg\">\n\n<p>启动xfce试试：</p>\n<pre><code class=\"shell\">sudo startxfce4</code></pre>\n<p>略微卡顿，来到了我期待已久的桌面！！！</p>\n<img src=\"/2020/04/08/kongzheng1993-chromebook再次折腾crouton/xfce4.jpg\">\n\n<p>看下系统版本</p>\n<img src=\"/2020/04/08/kongzheng1993-chromebook再次折腾crouton/linuxRelease.jpg\">\n\n<p>圆满成功！！！<br>接下来就是好好整整这个ubuntu了，装各种环境，啦啦啦。。</p>\n"},{"title":"ThreadPool总结","excerpt":"","comments":1,"date":"2020-05-17T16:30:52.000Z","_content":"\n## 线程池\n\n线程池就是一个线程的集合，它帮我们来管理线程。\n\n- 管理线程，避免创建和销毁线程的资源开销。创建一个对象要类加载，销毁一个对象要GC，都是需要占用资源的。\n- 提高响应速度，不需要创建线程，直接将任务交给线程池运行。\n- 重复利用，线程执行完毕，放回线程池，重复利用。\n\n### 创建线程池\n\n```java\npublic ThreadPoolExecutor(int corePoolSize, int maximumPoolSize,long keepAliveTime,TimeUnit unit,\n   BlockingQueue<Runnable> workQueue,\n   ThreadFactory threadFactory,\n   RejectedExecutionHandler handler)\n```\n\n几个核心参数的作用：\n- corePoolSize： 线程池核心线程数最大值\n- maximumPoolSize： 线程池最大线程数大小\n- keepAliveTime： 线程池中非核心线程空闲的存活时间大小\n- unit： 线程空闲存活时间单位\n- workQueue： 存放任务的阻塞队列\n- threadFactory： 用于设置创建线程的工厂，可以给创建的线程设置有意义的名字，可方便排查问题。\n- handler： 线程池的饱和策略事件，主要有四种类型。\n\n### 几个东东的关系\n\n我们经常可以看到有通过new ThreadPoolExecutor()来创建线程池，也有通过Executors.newFixedThreadPool()等方法来创建线程池的，再加上Executor、ExecutorService，感觉乱七八糟的，屡屡关系。\n\n先看下Executors：\n\n```java\n    public static ExecutorService newFixedThreadPool(int nThreads) {\n        return new ThreadPoolExecutor(nThreads, nThreads,\n                                      0L, TimeUnit.MILLISECONDS,\n                                      new LinkedBlockingQueue<Runnable>());\n    }\n\n    public static ExecutorService newSingleThreadExecutor() {\n        return new FinalizableDelegatedExecutorService\n            (new ThreadPoolExecutor(1, 1,\n                                    0L, TimeUnit.MILLISECONDS,\n                                    new LinkedBlockingQueue<Runnable>()));\n    }\n\n    public static ExecutorService newCachedThreadPool() {\n        return new ThreadPoolExecutor(0, Integer.MAX_VALUE,\n                                      60L, TimeUnit.SECONDS,\n                                      new SynchronousQueue<Runnable>());\n    }\n\n```\n\n也就是Executors归根到底还是通过new ThreadPoolExecutor()来实现的。\n\n再看看我们的ThreadPoolExecutor类：\n\n```java\npublic class ThreadPoolExecutor extends AbstractExecutorService {\n    ...\n}\n```\n\n他继承了AbstractExecutorService抽象类，而AbstractExecutorService呢？\n\n```java\npublic abstract class AbstractExecutorService implements ExecutorService {\n    ...\n}\n```\n\n他实现了ExecutorService接口。\n\n```java\npublic interface ExecutorService extends Executor {\n    ...\n}\n```\n\nExecutorService又继承了Executor。\n\n\n### 线程池工作流程\n\n1. 提交一个任务，线程池里存活的核心线程数小于线程数corePoolSize时，线程池会创建一个核心线程去处理提交的任务。\n2. 如果线程池核心线程数已满，即线程数已经等于corePoolSize，一个新提交的任务，会被放进任务队列workQueue排队等待执行。\n3. 当线程池里面存活的线程数已经等于corePoolSize了,并且任务队列workQueue也满，判断线程数是否达到maximumPoolSize，即最大线程数是否已满，如果没到达，创建一个非核心线程执行提交的任务。\n4. 如果当前的线程数达到了maximumPoolSize，还有新的任务过来的话，直接采用拒绝策略处理。\n\n### 四种拒绝策略\n\n- AbortPolicy(抛出一个异常，默认的)\n- DiscardPolicy(直接丢弃任务)\n- DiscardOldestPolicy（丢弃队列里最老的任务，将当前这个任务继续提交给线程池\n- CallerRunsPolicy（交给线程池调用所在的线程进行处理)\n\n### 线程池的工作队列\n\n线程池都有哪几种工作队列？\n\n- ArrayBlockingQueue\n- LinkedBlockingQueue\n- DelayQueue\n- PriorityBlockingQueue\n- SynchronousQueue\n\n1. ArrayBlockingQueue（有界队列）是一个用数组实现的有界阻塞队列，按FIFO排序量。\n2. LinkedBlockingQueue（可设置容量队列）基于链表结构的阻塞队列，按FIFO排序任务，容量可以选择进行设置，不设置的话，将是一个无边界的阻塞队列，最大长度为Integer.MAX_VALUE，吞吐量通常要高于ArrayBlockingQuene，newFixedThreadPool线程池使用了这个队列\n3. DelayQueueDelayQueue（延迟队列）是一个任务定时周期的延迟执行的队列。根据指定的执行时间从小到大排序，否则根据插入到队列的先后排序。newScheduledThreadPool线程池使用了这个队列。\n4. PriorityBlockingQueue（优先级队列）是具有优先级的无界阻塞队列\n5. SynchronousQueueSynchronousQueue（同步队列）一个不存储元素的阻塞队列，每个插入操作必须等到另一个线程调用移除操作，否则插入操作一直处于阻塞状态，吞吐量通常要高于LinkedBlockingQuene，newCachedThreadPool线程池使用了这个队列。\n\n## 几种常用的线程池\n\n几种常用的线程池\n1. newFixedThreadPool (固定数目线程的线程池)\n\n```java\npublic static ExecutorService newFixedThreadPool(int nThreads, ThreadFactory threadFactory) {\n        return new ThreadPoolExecutor(nThreads, nThreads,\n                                      0L, TimeUnit.MILLISECONDS,\n                                      new LinkedBlockingQueue<Runnable>(),\n                                      threadFactory);\n    }\n```\n\n特点：\n\n    - 核心线程数和最大线程数大小一样\n    - 没有所谓的非空闲时间，即keepAliveTime为0\n    - 阻塞队列为无界队列LinkedBlockingQueue\n\n- newCachedThreadPool(可缓存线程的线程池)\n\n```java\npublic static ExecutorService newCachedThreadPool(ThreadFactory threadFactory) {\n        return new ThreadPoolExecutor(0, Integer.MAX_VALUE,\n                                      60L, TimeUnit.SECONDS,\n                                      new SynchronousQueue<Runnable>(),\n                                      threadFactory);\n    }\n```\n\n特点：\n        - 核心线程数为0\n        - 最大线程数为Integer.MAX_VALUE\n        - 阻塞队列是SynchronousQueue\n        - 非核心线程空闲存活时间为60秒\n\n- newSingleThreadExecutor(单线程的线程池)\n\n```java\npublic static ExecutorService newSingleThreadExecutor(ThreadFactory threadFactory) {\n        return new FinalizableDelegatedExecutorService\n            (new ThreadPoolExecutor(1, 1,\n                                    0L, TimeUnit.MILLISECONDS,\n                                    new LinkedBlockingQueue<Runnable>(),\n                                    threadFactory));\n    }\n```\n\n特点：\n        - 核心线程数为1\n        - 最大线程数也为1\n        - 阻塞队列是LinkedBlockingQueue\n        - keepAliveTime为0\n\n- newScheduledThreadPool(定时及周期执行的线程池)\n\n```java\npublic ScheduledThreadPoolExecutor(int corePoolSize) {\n        super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS,\n              new DelayedWorkQueue());\n    }\n```\n\n特点：\n        - 最大线程数为Integer.MAX_VALUE\n        - 阻塞队列是DelayedWorkQueue\n        - keepAliveTime为0scheduleAtFixedRate() ：按某种速率周期执行\n        - scheduleWithFixedDelay()：在某个延迟后执行\n\n## 线程池状态\n\n```java\n    // runState is stored in the high-order bits\n    private static final int RUNNING    = -1 << COUNT_BITS;\n    private static final int SHUTDOWN   =  0 << COUNT_BITS;\n    private static final int STOP       =  1 << COUNT_BITS;\n    private static final int TIDYING    =  2 << COUNT_BITS;\n    private static final int TERMINATED =  3 << COUNT_BITS;\n```\n\n**RUNNING**\n- 该状态的线程池会接收新任务，并处理阻塞队列中的任务;\n- 调用线程池的shutdown()方法，可以切换到SHUTDOWN状态;\n- 调用线程池的shutdownNow()方法，可以切换到STOP状态;\n\n**SHUTDOWN**\n- 该状态的线程池不会接收新任务，但会处理阻塞队列中的任务；\n- 队列为空，并且线程池中执行的任务也为空,进入TIDYING状态;\n\n**STOP**\n- 该状态的线程不会接收新任务，也不会处理阻塞队列中的任务，而且会中断正在运行的任务；\n- 线程池中执行的任务为空,进入TIDYING状态;\n\n**TIDYING**\n- 该状态表明所有的任务已经运行终止，记录的任务数量为0。\n- terminated()执行完毕，进入TERMINATED状态\n\n**TERMINATED**\n- 该状态表示线程池彻底终止\n\n\n<img src=\"2020-05-18 12-50-13屏幕截图.png\">\n\n## 线程池异常处理\n\n常用的几种方法：\n\n- 在我们提供的Runnable的run方法中捕获（try/catch）任务代码可能抛出的所有异常，包括未检测异常\n- 使用ExecutorService.submit执行任务，利用返回的Future对象的get方法接收抛出的异常，然后进行处理\n- 重写ThreadPoolExecutor.afterExecute方法，处理传递到afterExecute方法中的异常\n- 为工作者线程设置UncaughtExceptionHandler，在uncaughtException方法中处理异常 (不推荐)\n\n\n查资料的时候看到有人引用了[crossoverJie的文章](https://mp.weixin.qq.com/s/dqOy2eeeOsDa1AN3nNUftg)，之前也在b站看过他分享的程序员的一天，也拜读了一下。\n\n他分享的是一个生产问题的定位，线程池中，一个线程报错导致线程池remove掉这个worker，又new了一个worker，然后这个worker会卡在去队列take的地方。\n\n\n","source":"_posts/2020-05-15-kongzheng1993-ThreadPool总结.md","raw":"---\ntitle: ThreadPool总结\nexcerpt: ''\ntags: [Java, 并发]\ncategories: [Java, 并发]\ncomments: true\ndate: 2020-05-18 00:30:52\n---\n\n## 线程池\n\n线程池就是一个线程的集合，它帮我们来管理线程。\n\n- 管理线程，避免创建和销毁线程的资源开销。创建一个对象要类加载，销毁一个对象要GC，都是需要占用资源的。\n- 提高响应速度，不需要创建线程，直接将任务交给线程池运行。\n- 重复利用，线程执行完毕，放回线程池，重复利用。\n\n### 创建线程池\n\n```java\npublic ThreadPoolExecutor(int corePoolSize, int maximumPoolSize,long keepAliveTime,TimeUnit unit,\n   BlockingQueue<Runnable> workQueue,\n   ThreadFactory threadFactory,\n   RejectedExecutionHandler handler)\n```\n\n几个核心参数的作用：\n- corePoolSize： 线程池核心线程数最大值\n- maximumPoolSize： 线程池最大线程数大小\n- keepAliveTime： 线程池中非核心线程空闲的存活时间大小\n- unit： 线程空闲存活时间单位\n- workQueue： 存放任务的阻塞队列\n- threadFactory： 用于设置创建线程的工厂，可以给创建的线程设置有意义的名字，可方便排查问题。\n- handler： 线程池的饱和策略事件，主要有四种类型。\n\n### 几个东东的关系\n\n我们经常可以看到有通过new ThreadPoolExecutor()来创建线程池，也有通过Executors.newFixedThreadPool()等方法来创建线程池的，再加上Executor、ExecutorService，感觉乱七八糟的，屡屡关系。\n\n先看下Executors：\n\n```java\n    public static ExecutorService newFixedThreadPool(int nThreads) {\n        return new ThreadPoolExecutor(nThreads, nThreads,\n                                      0L, TimeUnit.MILLISECONDS,\n                                      new LinkedBlockingQueue<Runnable>());\n    }\n\n    public static ExecutorService newSingleThreadExecutor() {\n        return new FinalizableDelegatedExecutorService\n            (new ThreadPoolExecutor(1, 1,\n                                    0L, TimeUnit.MILLISECONDS,\n                                    new LinkedBlockingQueue<Runnable>()));\n    }\n\n    public static ExecutorService newCachedThreadPool() {\n        return new ThreadPoolExecutor(0, Integer.MAX_VALUE,\n                                      60L, TimeUnit.SECONDS,\n                                      new SynchronousQueue<Runnable>());\n    }\n\n```\n\n也就是Executors归根到底还是通过new ThreadPoolExecutor()来实现的。\n\n再看看我们的ThreadPoolExecutor类：\n\n```java\npublic class ThreadPoolExecutor extends AbstractExecutorService {\n    ...\n}\n```\n\n他继承了AbstractExecutorService抽象类，而AbstractExecutorService呢？\n\n```java\npublic abstract class AbstractExecutorService implements ExecutorService {\n    ...\n}\n```\n\n他实现了ExecutorService接口。\n\n```java\npublic interface ExecutorService extends Executor {\n    ...\n}\n```\n\nExecutorService又继承了Executor。\n\n\n### 线程池工作流程\n\n1. 提交一个任务，线程池里存活的核心线程数小于线程数corePoolSize时，线程池会创建一个核心线程去处理提交的任务。\n2. 如果线程池核心线程数已满，即线程数已经等于corePoolSize，一个新提交的任务，会被放进任务队列workQueue排队等待执行。\n3. 当线程池里面存活的线程数已经等于corePoolSize了,并且任务队列workQueue也满，判断线程数是否达到maximumPoolSize，即最大线程数是否已满，如果没到达，创建一个非核心线程执行提交的任务。\n4. 如果当前的线程数达到了maximumPoolSize，还有新的任务过来的话，直接采用拒绝策略处理。\n\n### 四种拒绝策略\n\n- AbortPolicy(抛出一个异常，默认的)\n- DiscardPolicy(直接丢弃任务)\n- DiscardOldestPolicy（丢弃队列里最老的任务，将当前这个任务继续提交给线程池\n- CallerRunsPolicy（交给线程池调用所在的线程进行处理)\n\n### 线程池的工作队列\n\n线程池都有哪几种工作队列？\n\n- ArrayBlockingQueue\n- LinkedBlockingQueue\n- DelayQueue\n- PriorityBlockingQueue\n- SynchronousQueue\n\n1. ArrayBlockingQueue（有界队列）是一个用数组实现的有界阻塞队列，按FIFO排序量。\n2. LinkedBlockingQueue（可设置容量队列）基于链表结构的阻塞队列，按FIFO排序任务，容量可以选择进行设置，不设置的话，将是一个无边界的阻塞队列，最大长度为Integer.MAX_VALUE，吞吐量通常要高于ArrayBlockingQuene，newFixedThreadPool线程池使用了这个队列\n3. DelayQueueDelayQueue（延迟队列）是一个任务定时周期的延迟执行的队列。根据指定的执行时间从小到大排序，否则根据插入到队列的先后排序。newScheduledThreadPool线程池使用了这个队列。\n4. PriorityBlockingQueue（优先级队列）是具有优先级的无界阻塞队列\n5. SynchronousQueueSynchronousQueue（同步队列）一个不存储元素的阻塞队列，每个插入操作必须等到另一个线程调用移除操作，否则插入操作一直处于阻塞状态，吞吐量通常要高于LinkedBlockingQuene，newCachedThreadPool线程池使用了这个队列。\n\n## 几种常用的线程池\n\n几种常用的线程池\n1. newFixedThreadPool (固定数目线程的线程池)\n\n```java\npublic static ExecutorService newFixedThreadPool(int nThreads, ThreadFactory threadFactory) {\n        return new ThreadPoolExecutor(nThreads, nThreads,\n                                      0L, TimeUnit.MILLISECONDS,\n                                      new LinkedBlockingQueue<Runnable>(),\n                                      threadFactory);\n    }\n```\n\n特点：\n\n    - 核心线程数和最大线程数大小一样\n    - 没有所谓的非空闲时间，即keepAliveTime为0\n    - 阻塞队列为无界队列LinkedBlockingQueue\n\n- newCachedThreadPool(可缓存线程的线程池)\n\n```java\npublic static ExecutorService newCachedThreadPool(ThreadFactory threadFactory) {\n        return new ThreadPoolExecutor(0, Integer.MAX_VALUE,\n                                      60L, TimeUnit.SECONDS,\n                                      new SynchronousQueue<Runnable>(),\n                                      threadFactory);\n    }\n```\n\n特点：\n        - 核心线程数为0\n        - 最大线程数为Integer.MAX_VALUE\n        - 阻塞队列是SynchronousQueue\n        - 非核心线程空闲存活时间为60秒\n\n- newSingleThreadExecutor(单线程的线程池)\n\n```java\npublic static ExecutorService newSingleThreadExecutor(ThreadFactory threadFactory) {\n        return new FinalizableDelegatedExecutorService\n            (new ThreadPoolExecutor(1, 1,\n                                    0L, TimeUnit.MILLISECONDS,\n                                    new LinkedBlockingQueue<Runnable>(),\n                                    threadFactory));\n    }\n```\n\n特点：\n        - 核心线程数为1\n        - 最大线程数也为1\n        - 阻塞队列是LinkedBlockingQueue\n        - keepAliveTime为0\n\n- newScheduledThreadPool(定时及周期执行的线程池)\n\n```java\npublic ScheduledThreadPoolExecutor(int corePoolSize) {\n        super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS,\n              new DelayedWorkQueue());\n    }\n```\n\n特点：\n        - 最大线程数为Integer.MAX_VALUE\n        - 阻塞队列是DelayedWorkQueue\n        - keepAliveTime为0scheduleAtFixedRate() ：按某种速率周期执行\n        - scheduleWithFixedDelay()：在某个延迟后执行\n\n## 线程池状态\n\n```java\n    // runState is stored in the high-order bits\n    private static final int RUNNING    = -1 << COUNT_BITS;\n    private static final int SHUTDOWN   =  0 << COUNT_BITS;\n    private static final int STOP       =  1 << COUNT_BITS;\n    private static final int TIDYING    =  2 << COUNT_BITS;\n    private static final int TERMINATED =  3 << COUNT_BITS;\n```\n\n**RUNNING**\n- 该状态的线程池会接收新任务，并处理阻塞队列中的任务;\n- 调用线程池的shutdown()方法，可以切换到SHUTDOWN状态;\n- 调用线程池的shutdownNow()方法，可以切换到STOP状态;\n\n**SHUTDOWN**\n- 该状态的线程池不会接收新任务，但会处理阻塞队列中的任务；\n- 队列为空，并且线程池中执行的任务也为空,进入TIDYING状态;\n\n**STOP**\n- 该状态的线程不会接收新任务，也不会处理阻塞队列中的任务，而且会中断正在运行的任务；\n- 线程池中执行的任务为空,进入TIDYING状态;\n\n**TIDYING**\n- 该状态表明所有的任务已经运行终止，记录的任务数量为0。\n- terminated()执行完毕，进入TERMINATED状态\n\n**TERMINATED**\n- 该状态表示线程池彻底终止\n\n\n<img src=\"2020-05-18 12-50-13屏幕截图.png\">\n\n## 线程池异常处理\n\n常用的几种方法：\n\n- 在我们提供的Runnable的run方法中捕获（try/catch）任务代码可能抛出的所有异常，包括未检测异常\n- 使用ExecutorService.submit执行任务，利用返回的Future对象的get方法接收抛出的异常，然后进行处理\n- 重写ThreadPoolExecutor.afterExecute方法，处理传递到afterExecute方法中的异常\n- 为工作者线程设置UncaughtExceptionHandler，在uncaughtException方法中处理异常 (不推荐)\n\n\n查资料的时候看到有人引用了[crossoverJie的文章](https://mp.weixin.qq.com/s/dqOy2eeeOsDa1AN3nNUftg)，之前也在b站看过他分享的程序员的一天，也拜读了一下。\n\n他分享的是一个生产问题的定位，线程池中，一个线程报错导致线程池remove掉这个worker，又new了一个worker，然后这个worker会卡在去队列take的地方。\n\n\n","slug":"kongzheng1993-ThreadPool总结","published":1,"updated":"2023-03-08T07:05:58.801Z","layout":"post","photos":[],"link":"","_id":"clg0k2aqb00i2t26fscm8v1yn","content":"<h2 id=\"线程池\"><a href=\"#线程池\" class=\"headerlink\" title=\"线程池\"></a>线程池</h2><p>线程池就是一个线程的集合，它帮我们来管理线程。</p>\n<ul>\n<li>管理线程，避免创建和销毁线程的资源开销。创建一个对象要类加载，销毁一个对象要GC，都是需要占用资源的。</li>\n<li>提高响应速度，不需要创建线程，直接将任务交给线程池运行。</li>\n<li>重复利用，线程执行完毕，放回线程池，重复利用。</li>\n</ul>\n<h3 id=\"创建线程池\"><a href=\"#创建线程池\" class=\"headerlink\" title=\"创建线程池\"></a>创建线程池</h3><pre><code class=\"java\">public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize,long keepAliveTime,TimeUnit unit,\n   BlockingQueue&lt;Runnable&gt; workQueue,\n   ThreadFactory threadFactory,\n   RejectedExecutionHandler handler)</code></pre>\n<p>几个核心参数的作用：</p>\n<ul>\n<li>corePoolSize： 线程池核心线程数最大值</li>\n<li>maximumPoolSize： 线程池最大线程数大小</li>\n<li>keepAliveTime： 线程池中非核心线程空闲的存活时间大小</li>\n<li>unit： 线程空闲存活时间单位</li>\n<li>workQueue： 存放任务的阻塞队列</li>\n<li>threadFactory： 用于设置创建线程的工厂，可以给创建的线程设置有意义的名字，可方便排查问题。</li>\n<li>handler： 线程池的饱和策略事件，主要有四种类型。</li>\n</ul>\n<h3 id=\"几个东东的关系\"><a href=\"#几个东东的关系\" class=\"headerlink\" title=\"几个东东的关系\"></a>几个东东的关系</h3><p>我们经常可以看到有通过new ThreadPoolExecutor()来创建线程池，也有通过Executors.newFixedThreadPool()等方法来创建线程池的，再加上Executor、ExecutorService，感觉乱七八糟的，屡屡关系。</p>\n<p>先看下Executors：</p>\n<pre><code class=\"java\">    public static ExecutorService newFixedThreadPool(int nThreads) {\n        return new ThreadPoolExecutor(nThreads, nThreads,\n                                      0L, TimeUnit.MILLISECONDS,\n                                      new LinkedBlockingQueue&lt;Runnable&gt;());\n    }\n\n    public static ExecutorService newSingleThreadExecutor() {\n        return new FinalizableDelegatedExecutorService\n            (new ThreadPoolExecutor(1, 1,\n                                    0L, TimeUnit.MILLISECONDS,\n                                    new LinkedBlockingQueue&lt;Runnable&gt;()));\n    }\n\n    public static ExecutorService newCachedThreadPool() {\n        return new ThreadPoolExecutor(0, Integer.MAX_VALUE,\n                                      60L, TimeUnit.SECONDS,\n                                      new SynchronousQueue&lt;Runnable&gt;());\n    }\n</code></pre>\n<p>也就是Executors归根到底还是通过new ThreadPoolExecutor()来实现的。</p>\n<p>再看看我们的ThreadPoolExecutor类：</p>\n<pre><code class=\"java\">public class ThreadPoolExecutor extends AbstractExecutorService {\n    ...\n}</code></pre>\n<p>他继承了AbstractExecutorService抽象类，而AbstractExecutorService呢？</p>\n<pre><code class=\"java\">public abstract class AbstractExecutorService implements ExecutorService {\n    ...\n}</code></pre>\n<p>他实现了ExecutorService接口。</p>\n<pre><code class=\"java\">public interface ExecutorService extends Executor {\n    ...\n}</code></pre>\n<p>ExecutorService又继承了Executor。</p>\n<h3 id=\"线程池工作流程\"><a href=\"#线程池工作流程\" class=\"headerlink\" title=\"线程池工作流程\"></a>线程池工作流程</h3><ol>\n<li>提交一个任务，线程池里存活的核心线程数小于线程数corePoolSize时，线程池会创建一个核心线程去处理提交的任务。</li>\n<li>如果线程池核心线程数已满，即线程数已经等于corePoolSize，一个新提交的任务，会被放进任务队列workQueue排队等待执行。</li>\n<li>当线程池里面存活的线程数已经等于corePoolSize了,并且任务队列workQueue也满，判断线程数是否达到maximumPoolSize，即最大线程数是否已满，如果没到达，创建一个非核心线程执行提交的任务。</li>\n<li>如果当前的线程数达到了maximumPoolSize，还有新的任务过来的话，直接采用拒绝策略处理。</li>\n</ol>\n<h3 id=\"四种拒绝策略\"><a href=\"#四种拒绝策略\" class=\"headerlink\" title=\"四种拒绝策略\"></a>四种拒绝策略</h3><ul>\n<li>AbortPolicy(抛出一个异常，默认的)</li>\n<li>DiscardPolicy(直接丢弃任务)</li>\n<li>DiscardOldestPolicy（丢弃队列里最老的任务，将当前这个任务继续提交给线程池</li>\n<li>CallerRunsPolicy（交给线程池调用所在的线程进行处理)</li>\n</ul>\n<h3 id=\"线程池的工作队列\"><a href=\"#线程池的工作队列\" class=\"headerlink\" title=\"线程池的工作队列\"></a>线程池的工作队列</h3><p>线程池都有哪几种工作队列？</p>\n<ul>\n<li>ArrayBlockingQueue</li>\n<li>LinkedBlockingQueue</li>\n<li>DelayQueue</li>\n<li>PriorityBlockingQueue</li>\n<li>SynchronousQueue</li>\n</ul>\n<ol>\n<li>ArrayBlockingQueue（有界队列）是一个用数组实现的有界阻塞队列，按FIFO排序量。</li>\n<li>LinkedBlockingQueue（可设置容量队列）基于链表结构的阻塞队列，按FIFO排序任务，容量可以选择进行设置，不设置的话，将是一个无边界的阻塞队列，最大长度为Integer.MAX_VALUE，吞吐量通常要高于ArrayBlockingQuene，newFixedThreadPool线程池使用了这个队列</li>\n<li>DelayQueueDelayQueue（延迟队列）是一个任务定时周期的延迟执行的队列。根据指定的执行时间从小到大排序，否则根据插入到队列的先后排序。newScheduledThreadPool线程池使用了这个队列。</li>\n<li>PriorityBlockingQueue（优先级队列）是具有优先级的无界阻塞队列</li>\n<li>SynchronousQueueSynchronousQueue（同步队列）一个不存储元素的阻塞队列，每个插入操作必须等到另一个线程调用移除操作，否则插入操作一直处于阻塞状态，吞吐量通常要高于LinkedBlockingQuene，newCachedThreadPool线程池使用了这个队列。</li>\n</ol>\n<h2 id=\"几种常用的线程池\"><a href=\"#几种常用的线程池\" class=\"headerlink\" title=\"几种常用的线程池\"></a>几种常用的线程池</h2><p>几种常用的线程池</p>\n<ol>\n<li>newFixedThreadPool (固定数目线程的线程池)</li>\n</ol>\n<pre><code class=\"java\">public static ExecutorService newFixedThreadPool(int nThreads, ThreadFactory threadFactory) {\n        return new ThreadPoolExecutor(nThreads, nThreads,\n                                      0L, TimeUnit.MILLISECONDS,\n                                      new LinkedBlockingQueue&lt;Runnable&gt;(),\n                                      threadFactory);\n    }</code></pre>\n<p>特点：</p>\n<pre><code>- 核心线程数和最大线程数大小一样\n- 没有所谓的非空闲时间，即keepAliveTime为0\n- 阻塞队列为无界队列LinkedBlockingQueue</code></pre><ul>\n<li>newCachedThreadPool(可缓存线程的线程池)</li>\n</ul>\n<pre><code class=\"java\">public static ExecutorService newCachedThreadPool(ThreadFactory threadFactory) {\n        return new ThreadPoolExecutor(0, Integer.MAX_VALUE,\n                                      60L, TimeUnit.SECONDS,\n                                      new SynchronousQueue&lt;Runnable&gt;(),\n                                      threadFactory);\n    }</code></pre>\n<p>特点：<br>        - 核心线程数为0<br>        - 最大线程数为Integer.MAX_VALUE<br>        - 阻塞队列是SynchronousQueue<br>        - 非核心线程空闲存活时间为60秒</p>\n<ul>\n<li>newSingleThreadExecutor(单线程的线程池)</li>\n</ul>\n<pre><code class=\"java\">public static ExecutorService newSingleThreadExecutor(ThreadFactory threadFactory) {\n        return new FinalizableDelegatedExecutorService\n            (new ThreadPoolExecutor(1, 1,\n                                    0L, TimeUnit.MILLISECONDS,\n                                    new LinkedBlockingQueue&lt;Runnable&gt;(),\n                                    threadFactory));\n    }</code></pre>\n<p>特点：<br>        - 核心线程数为1<br>        - 最大线程数也为1<br>        - 阻塞队列是LinkedBlockingQueue<br>        - keepAliveTime为0</p>\n<ul>\n<li>newScheduledThreadPool(定时及周期执行的线程池)</li>\n</ul>\n<pre><code class=\"java\">public ScheduledThreadPoolExecutor(int corePoolSize) {\n        super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS,\n              new DelayedWorkQueue());\n    }</code></pre>\n<p>特点：<br>        - 最大线程数为Integer.MAX_VALUE<br>        - 阻塞队列是DelayedWorkQueue<br>        - keepAliveTime为0scheduleAtFixedRate() ：按某种速率周期执行<br>        - scheduleWithFixedDelay()：在某个延迟后执行</p>\n<h2 id=\"线程池状态\"><a href=\"#线程池状态\" class=\"headerlink\" title=\"线程池状态\"></a>线程池状态</h2><pre><code class=\"java\">    // runState is stored in the high-order bits\n    private static final int RUNNING    = -1 &lt;&lt; COUNT_BITS;\n    private static final int SHUTDOWN   =  0 &lt;&lt; COUNT_BITS;\n    private static final int STOP       =  1 &lt;&lt; COUNT_BITS;\n    private static final int TIDYING    =  2 &lt;&lt; COUNT_BITS;\n    private static final int TERMINATED =  3 &lt;&lt; COUNT_BITS;</code></pre>\n<p><strong>RUNNING</strong></p>\n<ul>\n<li>该状态的线程池会接收新任务，并处理阻塞队列中的任务;</li>\n<li>调用线程池的shutdown()方法，可以切换到SHUTDOWN状态;</li>\n<li>调用线程池的shutdownNow()方法，可以切换到STOP状态;</li>\n</ul>\n<p><strong>SHUTDOWN</strong></p>\n<ul>\n<li>该状态的线程池不会接收新任务，但会处理阻塞队列中的任务；</li>\n<li>队列为空，并且线程池中执行的任务也为空,进入TIDYING状态;</li>\n</ul>\n<p><strong>STOP</strong></p>\n<ul>\n<li>该状态的线程不会接收新任务，也不会处理阻塞队列中的任务，而且会中断正在运行的任务；</li>\n<li>线程池中执行的任务为空,进入TIDYING状态;</li>\n</ul>\n<p><strong>TIDYING</strong></p>\n<ul>\n<li>该状态表明所有的任务已经运行终止，记录的任务数量为0。</li>\n<li>terminated()执行完毕，进入TERMINATED状态</li>\n</ul>\n<p><strong>TERMINATED</strong></p>\n<ul>\n<li>该状态表示线程池彻底终止</li>\n</ul>\n<img src=\"/2020/05/18/kongzheng1993-ThreadPool总结/2020-05-18 12-50-13屏幕截图.png\">\n\n<h2 id=\"线程池异常处理\"><a href=\"#线程池异常处理\" class=\"headerlink\" title=\"线程池异常处理\"></a>线程池异常处理</h2><p>常用的几种方法：</p>\n<ul>\n<li>在我们提供的Runnable的run方法中捕获（try/catch）任务代码可能抛出的所有异常，包括未检测异常</li>\n<li>使用ExecutorService.submit执行任务，利用返回的Future对象的get方法接收抛出的异常，然后进行处理</li>\n<li>重写ThreadPoolExecutor.afterExecute方法，处理传递到afterExecute方法中的异常</li>\n<li>为工作者线程设置UncaughtExceptionHandler，在uncaughtException方法中处理异常 (不推荐)</li>\n</ul>\n<p>查资料的时候看到有人引用了<a href=\"https://mp.weixin.qq.com/s/dqOy2eeeOsDa1AN3nNUftg\" target=\"_blank\" rel=\"noopener\">crossoverJie的文章</a>，之前也在b站看过他分享的程序员的一天，也拜读了一下。</p>\n<p>他分享的是一个生产问题的定位，线程池中，一个线程报错导致线程池remove掉这个worker，又new了一个worker，然后这个worker会卡在去队列take的地方。</p>\n","site":{"data":{}},"more":"<h2 id=\"线程池\"><a href=\"#线程池\" class=\"headerlink\" title=\"线程池\"></a>线程池</h2><p>线程池就是一个线程的集合，它帮我们来管理线程。</p>\n<ul>\n<li>管理线程，避免创建和销毁线程的资源开销。创建一个对象要类加载，销毁一个对象要GC，都是需要占用资源的。</li>\n<li>提高响应速度，不需要创建线程，直接将任务交给线程池运行。</li>\n<li>重复利用，线程执行完毕，放回线程池，重复利用。</li>\n</ul>\n<h3 id=\"创建线程池\"><a href=\"#创建线程池\" class=\"headerlink\" title=\"创建线程池\"></a>创建线程池</h3><pre><code class=\"java\">public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize,long keepAliveTime,TimeUnit unit,\n   BlockingQueue&lt;Runnable&gt; workQueue,\n   ThreadFactory threadFactory,\n   RejectedExecutionHandler handler)</code></pre>\n<p>几个核心参数的作用：</p>\n<ul>\n<li>corePoolSize： 线程池核心线程数最大值</li>\n<li>maximumPoolSize： 线程池最大线程数大小</li>\n<li>keepAliveTime： 线程池中非核心线程空闲的存活时间大小</li>\n<li>unit： 线程空闲存活时间单位</li>\n<li>workQueue： 存放任务的阻塞队列</li>\n<li>threadFactory： 用于设置创建线程的工厂，可以给创建的线程设置有意义的名字，可方便排查问题。</li>\n<li>handler： 线程池的饱和策略事件，主要有四种类型。</li>\n</ul>\n<h3 id=\"几个东东的关系\"><a href=\"#几个东东的关系\" class=\"headerlink\" title=\"几个东东的关系\"></a>几个东东的关系</h3><p>我们经常可以看到有通过new ThreadPoolExecutor()来创建线程池，也有通过Executors.newFixedThreadPool()等方法来创建线程池的，再加上Executor、ExecutorService，感觉乱七八糟的，屡屡关系。</p>\n<p>先看下Executors：</p>\n<pre><code class=\"java\">    public static ExecutorService newFixedThreadPool(int nThreads) {\n        return new ThreadPoolExecutor(nThreads, nThreads,\n                                      0L, TimeUnit.MILLISECONDS,\n                                      new LinkedBlockingQueue&lt;Runnable&gt;());\n    }\n\n    public static ExecutorService newSingleThreadExecutor() {\n        return new FinalizableDelegatedExecutorService\n            (new ThreadPoolExecutor(1, 1,\n                                    0L, TimeUnit.MILLISECONDS,\n                                    new LinkedBlockingQueue&lt;Runnable&gt;()));\n    }\n\n    public static ExecutorService newCachedThreadPool() {\n        return new ThreadPoolExecutor(0, Integer.MAX_VALUE,\n                                      60L, TimeUnit.SECONDS,\n                                      new SynchronousQueue&lt;Runnable&gt;());\n    }\n</code></pre>\n<p>也就是Executors归根到底还是通过new ThreadPoolExecutor()来实现的。</p>\n<p>再看看我们的ThreadPoolExecutor类：</p>\n<pre><code class=\"java\">public class ThreadPoolExecutor extends AbstractExecutorService {\n    ...\n}</code></pre>\n<p>他继承了AbstractExecutorService抽象类，而AbstractExecutorService呢？</p>\n<pre><code class=\"java\">public abstract class AbstractExecutorService implements ExecutorService {\n    ...\n}</code></pre>\n<p>他实现了ExecutorService接口。</p>\n<pre><code class=\"java\">public interface ExecutorService extends Executor {\n    ...\n}</code></pre>\n<p>ExecutorService又继承了Executor。</p>\n<h3 id=\"线程池工作流程\"><a href=\"#线程池工作流程\" class=\"headerlink\" title=\"线程池工作流程\"></a>线程池工作流程</h3><ol>\n<li>提交一个任务，线程池里存活的核心线程数小于线程数corePoolSize时，线程池会创建一个核心线程去处理提交的任务。</li>\n<li>如果线程池核心线程数已满，即线程数已经等于corePoolSize，一个新提交的任务，会被放进任务队列workQueue排队等待执行。</li>\n<li>当线程池里面存活的线程数已经等于corePoolSize了,并且任务队列workQueue也满，判断线程数是否达到maximumPoolSize，即最大线程数是否已满，如果没到达，创建一个非核心线程执行提交的任务。</li>\n<li>如果当前的线程数达到了maximumPoolSize，还有新的任务过来的话，直接采用拒绝策略处理。</li>\n</ol>\n<h3 id=\"四种拒绝策略\"><a href=\"#四种拒绝策略\" class=\"headerlink\" title=\"四种拒绝策略\"></a>四种拒绝策略</h3><ul>\n<li>AbortPolicy(抛出一个异常，默认的)</li>\n<li>DiscardPolicy(直接丢弃任务)</li>\n<li>DiscardOldestPolicy（丢弃队列里最老的任务，将当前这个任务继续提交给线程池</li>\n<li>CallerRunsPolicy（交给线程池调用所在的线程进行处理)</li>\n</ul>\n<h3 id=\"线程池的工作队列\"><a href=\"#线程池的工作队列\" class=\"headerlink\" title=\"线程池的工作队列\"></a>线程池的工作队列</h3><p>线程池都有哪几种工作队列？</p>\n<ul>\n<li>ArrayBlockingQueue</li>\n<li>LinkedBlockingQueue</li>\n<li>DelayQueue</li>\n<li>PriorityBlockingQueue</li>\n<li>SynchronousQueue</li>\n</ul>\n<ol>\n<li>ArrayBlockingQueue（有界队列）是一个用数组实现的有界阻塞队列，按FIFO排序量。</li>\n<li>LinkedBlockingQueue（可设置容量队列）基于链表结构的阻塞队列，按FIFO排序任务，容量可以选择进行设置，不设置的话，将是一个无边界的阻塞队列，最大长度为Integer.MAX_VALUE，吞吐量通常要高于ArrayBlockingQuene，newFixedThreadPool线程池使用了这个队列</li>\n<li>DelayQueueDelayQueue（延迟队列）是一个任务定时周期的延迟执行的队列。根据指定的执行时间从小到大排序，否则根据插入到队列的先后排序。newScheduledThreadPool线程池使用了这个队列。</li>\n<li>PriorityBlockingQueue（优先级队列）是具有优先级的无界阻塞队列</li>\n<li>SynchronousQueueSynchronousQueue（同步队列）一个不存储元素的阻塞队列，每个插入操作必须等到另一个线程调用移除操作，否则插入操作一直处于阻塞状态，吞吐量通常要高于LinkedBlockingQuene，newCachedThreadPool线程池使用了这个队列。</li>\n</ol>\n<h2 id=\"几种常用的线程池\"><a href=\"#几种常用的线程池\" class=\"headerlink\" title=\"几种常用的线程池\"></a>几种常用的线程池</h2><p>几种常用的线程池</p>\n<ol>\n<li>newFixedThreadPool (固定数目线程的线程池)</li>\n</ol>\n<pre><code class=\"java\">public static ExecutorService newFixedThreadPool(int nThreads, ThreadFactory threadFactory) {\n        return new ThreadPoolExecutor(nThreads, nThreads,\n                                      0L, TimeUnit.MILLISECONDS,\n                                      new LinkedBlockingQueue&lt;Runnable&gt;(),\n                                      threadFactory);\n    }</code></pre>\n<p>特点：</p>\n<pre><code>- 核心线程数和最大线程数大小一样\n- 没有所谓的非空闲时间，即keepAliveTime为0\n- 阻塞队列为无界队列LinkedBlockingQueue</code></pre><ul>\n<li>newCachedThreadPool(可缓存线程的线程池)</li>\n</ul>\n<pre><code class=\"java\">public static ExecutorService newCachedThreadPool(ThreadFactory threadFactory) {\n        return new ThreadPoolExecutor(0, Integer.MAX_VALUE,\n                                      60L, TimeUnit.SECONDS,\n                                      new SynchronousQueue&lt;Runnable&gt;(),\n                                      threadFactory);\n    }</code></pre>\n<p>特点：<br>        - 核心线程数为0<br>        - 最大线程数为Integer.MAX_VALUE<br>        - 阻塞队列是SynchronousQueue<br>        - 非核心线程空闲存活时间为60秒</p>\n<ul>\n<li>newSingleThreadExecutor(单线程的线程池)</li>\n</ul>\n<pre><code class=\"java\">public static ExecutorService newSingleThreadExecutor(ThreadFactory threadFactory) {\n        return new FinalizableDelegatedExecutorService\n            (new ThreadPoolExecutor(1, 1,\n                                    0L, TimeUnit.MILLISECONDS,\n                                    new LinkedBlockingQueue&lt;Runnable&gt;(),\n                                    threadFactory));\n    }</code></pre>\n<p>特点：<br>        - 核心线程数为1<br>        - 最大线程数也为1<br>        - 阻塞队列是LinkedBlockingQueue<br>        - keepAliveTime为0</p>\n<ul>\n<li>newScheduledThreadPool(定时及周期执行的线程池)</li>\n</ul>\n<pre><code class=\"java\">public ScheduledThreadPoolExecutor(int corePoolSize) {\n        super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS,\n              new DelayedWorkQueue());\n    }</code></pre>\n<p>特点：<br>        - 最大线程数为Integer.MAX_VALUE<br>        - 阻塞队列是DelayedWorkQueue<br>        - keepAliveTime为0scheduleAtFixedRate() ：按某种速率周期执行<br>        - scheduleWithFixedDelay()：在某个延迟后执行</p>\n<h2 id=\"线程池状态\"><a href=\"#线程池状态\" class=\"headerlink\" title=\"线程池状态\"></a>线程池状态</h2><pre><code class=\"java\">    // runState is stored in the high-order bits\n    private static final int RUNNING    = -1 &lt;&lt; COUNT_BITS;\n    private static final int SHUTDOWN   =  0 &lt;&lt; COUNT_BITS;\n    private static final int STOP       =  1 &lt;&lt; COUNT_BITS;\n    private static final int TIDYING    =  2 &lt;&lt; COUNT_BITS;\n    private static final int TERMINATED =  3 &lt;&lt; COUNT_BITS;</code></pre>\n<p><strong>RUNNING</strong></p>\n<ul>\n<li>该状态的线程池会接收新任务，并处理阻塞队列中的任务;</li>\n<li>调用线程池的shutdown()方法，可以切换到SHUTDOWN状态;</li>\n<li>调用线程池的shutdownNow()方法，可以切换到STOP状态;</li>\n</ul>\n<p><strong>SHUTDOWN</strong></p>\n<ul>\n<li>该状态的线程池不会接收新任务，但会处理阻塞队列中的任务；</li>\n<li>队列为空，并且线程池中执行的任务也为空,进入TIDYING状态;</li>\n</ul>\n<p><strong>STOP</strong></p>\n<ul>\n<li>该状态的线程不会接收新任务，也不会处理阻塞队列中的任务，而且会中断正在运行的任务；</li>\n<li>线程池中执行的任务为空,进入TIDYING状态;</li>\n</ul>\n<p><strong>TIDYING</strong></p>\n<ul>\n<li>该状态表明所有的任务已经运行终止，记录的任务数量为0。</li>\n<li>terminated()执行完毕，进入TERMINATED状态</li>\n</ul>\n<p><strong>TERMINATED</strong></p>\n<ul>\n<li>该状态表示线程池彻底终止</li>\n</ul>\n<img src=\"/2020/05/18/kongzheng1993-ThreadPool总结/2020-05-18 12-50-13屏幕截图.png\">\n\n<h2 id=\"线程池异常处理\"><a href=\"#线程池异常处理\" class=\"headerlink\" title=\"线程池异常处理\"></a>线程池异常处理</h2><p>常用的几种方法：</p>\n<ul>\n<li>在我们提供的Runnable的run方法中捕获（try/catch）任务代码可能抛出的所有异常，包括未检测异常</li>\n<li>使用ExecutorService.submit执行任务，利用返回的Future对象的get方法接收抛出的异常，然后进行处理</li>\n<li>重写ThreadPoolExecutor.afterExecute方法，处理传递到afterExecute方法中的异常</li>\n<li>为工作者线程设置UncaughtExceptionHandler，在uncaughtException方法中处理异常 (不推荐)</li>\n</ul>\n<p>查资料的时候看到有人引用了<a href=\"https://mp.weixin.qq.com/s/dqOy2eeeOsDa1AN3nNUftg\" target=\"_blank\" rel=\"noopener\">crossoverJie的文章</a>，之前也在b站看过他分享的程序员的一天，也拜读了一下。</p>\n<p>他分享的是一个生产问题的定位，线程池中，一个线程报错导致线程池remove掉这个worker，又new了一个worker，然后这个worker会卡在去队列take的地方。</p>\n"},{"title":"Nginx","excerpt":"","comments":1,"date":"2020-05-11T16:30:52.000Z","_content":"\n前两天客户那边说检测出我们的nginx有漏洞，让我们搞一下，其实就是nginx出新版本了，老版本有个重大bug，跟着我们也应该升级。但是一来二去不知道为啥落我头上了，我是开发啊。。不过也无所谓，正好趁着这个机会好好了解一下。\n\n## 什么是Nginx\n\nNginx是一款轻量级的Web服务器、反向代理服务器，由于它的内存占用少，启动极快，高并发能力强，在互联网项目中广泛应用。除了http它还支持IMAP/POP3等协议。\n\n目前比较常见的系统架构中，nginx一般都是在入口处，作为反向代理。\n\n<img src=\"v2-e1826bab1d07df8e97d61aa809b94a10_r.jpg\"/>\n\n提到Nginx就不能不提反向代理。。\n\n\n- **正向代理：**  代理客户端去请求服务器，然后将服务器的响应返回给客户端。我们平常科学上网用的代理服务器起到的作用就是正向代理。*正向代理代理的是客户端*。\n- **反向代理：** 代理服务器来接受客户端的请求，然后将客户端的请求转发到内部网络，并将服务器上得到的结果返回给客户端。*反向代理代理的是服务端*。\n\n## 安装Nginx\n\n安装Nignx和一般软件一样，也是一顿configure、make、make install。。\n\n1. 首先是安装依赖\n\n```shell\nyum -y install gcc openssl-devel pcre-devel zlib-devel\n```\n\n已经有了的就不用装了，pcre库是用来支持正则表达式的，也就是我们想在nginx的配置文件里用正则，还是老老实实把pcre编译进nginx。zlib是对于http包的内容做gzip格式的压缩，如果我们在nginx.conf中配置了`gzip on`，并指定对于某些类型（content-type）的http响应使用gzip来进行压缩以减少网络传输量，就需要把zlib编译进nginx。openssl是用来支持ssl协议，也包含MD5、SHA1等散列函数。\n\n2. 下载解压nginx\n\n```shell\nwget -o XX/nginx-X.X.X.tar.gz\ntar -zxvf nginx-X.X.X.tar.gz\n```\n\n3. configure配置\n\n进入源码根目录，执行：\n\n```shell\n./configure --prefix=/**/**/**\n```\n\n通过`--prefix`来指定软件安装位置。\n\n4. 编译安装\n\n```shell\nmake && make install\n```\n\n在安装完后，就会在你制定的目录出现nginx目录了，一些可执行文件在`sbin`目录下。执行`./nginx`就可以启动nginx了。\n\n使用`nginx -s $sign`可以来控制启动的nginx进程。\n\n$sign有：\n- stop  快速关闭\n- quit  优雅的关闭\n- reload  重新加载配置文件\n- reopen  重新打开日志文件\n\n\n## 运行中的nginx\n\nnginx在启动后，在unix系统中会以daemon的方式在后台运行，后台进程包含一个master进程和多个worker进程。所以，nginx是以多进程的方式来工作的，当然nginx也是支持多线程的方式的，只是我们主流的方式还是多进程的方式，也是nginx的默认方式。我们也可以手动关掉后台模式，让nginx在前台运行，并且也可以通过配置取消master进程，也就是让nginx以单进程运行。这样可以让我们更方便debug。\n\nmaster进程主要是来管理worker进程的，包含：\n\n- 读取并验证nginx.conf\n- 接受外来的信号\n- 向各worker进程发送信号\n- 监控worker的运行状态，当worker进程退出后，master会启动新的worker\n\nworker进程处理的是基本的网络事件，多个worker之间是平等的，他们同等竞争来自客户端的请求，各进程之间是独立的。一个请求只会在一个worker中处理。worker的数量是可以设置的，一般会和cpu核心数一致。worker默认是单线程的，这样可以避免线程切换。\n\n## nginx的热部署\n\n我们在使用nginx一般修改的都是nginx.conf配置文件。每次我们修改nginx.conf后都不需要重启nginx，而是直接执行`nginx -s reload`，让nginx重新加载一下配置就好。\n\nnginx在重新加载配置文件后，会新建新建worker来处理新的请求，旧的请求还是走之前的worker，等老worker处理完请求后，就会被kill掉。\n\n## nginx的高并发\n\n前面的配置worker个数和cpu核心数一致，worker单线程来防止线程切换浪费资源，都是nginx高并发的原因。\n\n还有就是nginx使用的是epoll模型的IO，我理解的就是和redis一样的IO多路复用，通过一个选择器来监听成千上万的连接。（之前在看一本书，用netty、redis、zk做高并发实战，上面讲了文件句柄，nginx是不是也修改了？）\n\n## nginx高可用\n\n请求不要直接打在nginx上，应该先通过虚拟IP（VIP）。\n然后就是通过keepalived来监控nginx的状态，通过执行脚本来检查nginx进程状态。\n\nkeepalived是一种高性能的服务器高可用或热备解决方案，Keepalived可以用来防止服务器单点故障的发生，通过配合 Nginx 可以实现 web 前端服务的高可用。Keepalived以VRRP协议为实现基础，用 VRRP协议来实现高可用性(HA)。VRRP(Virtual Router Redundancy Protocol)协议是用于实现路由器冗余的协议，VRRP 协议将两台或多台路由器设备虚拟成一个设备，对外提供虚拟路由器IP(一个或多个)，而在路由器组内部，如果实际拥有这个对外IP的路由器如果工作正常的话就是MASTER，或者是通过算法选举产生，MASTER 实现针对虚拟路由器 IP 的各种网络功能，如 ARP 请求，ICMP，以及数据的转发等；其他设备不拥有该虚拟 IP，状态是 BACKUP，除了接收 MASTER 的VRRP 状态通告信息外，不执行对外的网络功能。当主机失效时，BACKUP 将接管原先 MASTER 的网络功能。VRRP 协议使用多播数据来传输 VRRP 数据， VRRP 数据使用特殊的虚拟源 MAC 地址发送数据而不是自身网卡的 MAC 地址，VRRP 运行时只有 MASTER 路由器定时发送 VRRP 通告信息，表示 MASTER 工作正常以及虚拟路由器 IP(组)，BACKUP 只接收 VRRP 数据，不发送数据，如果一定时间内没有接收到 MASTER 的通告信息，各 BACKUP 将宣告自己成为 MASTER，发送通告信息，重新进行 MASTER 选举状态。\n\n\n## nginx.conf\n\n我们一般修改的都是nginx.conf文件。\n\n下面是nginx官方给的完整例子：\n\n```shell\n#!nginx\n: # 使用的用户和组\n: user  www www;\n: # 指定工作衍生进程数\n: worker_processes  2;\n: # 指定 pid 存放的路径\n: pid /var/run/nginx.pid;\n\n: # [ debug | info | notice | warn | error | crit ] \n: # 可以在下方直接使用 [ debug | info | notice | warn | error | crit ]  参数\n: error_log  /var/log/nginx.error_log  info;\n\n: events {\n: # 允许的连接数\n: connections   2000;\n: # use [ kqueue | rtsig | epoll | /dev/poll | select | poll ] ;\n: # 具体内容查看 http://wiki.codemongers.com/事件模型\n: use kqueue;\n: }\n\n: http {\n: include       conf/mime.types;\n: default_type  application/octet-stream;\n\n: log_format main      '$remote_addr - $remote_user [$time_local]  '\n: '\"$request\" $status $bytes_sent '\n: '\"$http_referer\" \"$http_user_agent\" '\n: '\"$gzip_ratio\"';\n\n: log_format download  '$remote_addr - $remote_user [$time_local]  '\n: '\"$request\" $status $bytes_sent '\n: '\"$http_referer\" \"$http_user_agent\" '\n: '\"$http_range\" \"$sent_http_content_range\"';\n\n: client_header_timeout  3m;\n: client_body_timeout    3m;\n: send_timeout           3m;\n\n: client_header_buffer_size    1k;\n: large_client_header_buffers  4 4k;\n\n: gzip on;\n: gzip_min_length  1100;\n: gzip_buffers     4 8k;\n: gzip_types       text/plain;\n\n: output_buffers   1 32k;\n: postpone_output  1460;\n\n: sendfile         on;\n: tcp_nopush       on;\n: tcp_nodelay      on;\n: send_lowat       12000;\n\n: keepalive_timeout  75 20;\n\n: #lingering_time     30;\n: #lingering_timeout  10;\n: #reset_timedout_connection  on;\n\n\n: server {\n: listen        one.example.com;\n: server_name   one.example.com  www.one.example.com;\n\n: access_log   /var/log/nginx.access_log  main;\n\n: location / {\n: proxy_pass         http://127.0.0.1/;\n: proxy_redirect     off;\n\n: proxy_set_header   Host             $host;\n: proxy_set_header   X-Real-IP        $remote_addr;\n: #proxy_set_header  X-Forwarded-For  $proxy_add_x_forwarded_for;\n\n: client_max_body_size       10m;\n: client_body_buffer_size    128k;\n\n: client_body_temp_path      /var/nginx/client_body_temp;\n\n: proxy_connect_timeout      90;\n: proxy_send_timeout         90;\n: proxy_read_timeout         90;\n: proxy_send_lowat           12000;\n\n: proxy_buffer_size          4k;\n: proxy_buffers              4 32k;\n: proxy_busy_buffers_size    64k;\n: proxy_temp_file_write_size 64k;\n\n: proxy_temp_path            /var/nginx/proxy_temp;\n\n: charset  koi8-r;\n: }\n\n: error_page  404  /404.html;\n\n: location /404.html {\n: root  /spool/www;\n\n: charset         on;\n: source_charset  koi8-r;\n: }\n\n: location /old_stuff/ {\n: rewrite   ^/old_stuff/(.*)$  /new_stuff/$1  permanent;\n: }\n\n: location /download/ {\n\n: valid_referers  none  blocked  server_names  *.example.com;\n\n: if ($invalid_referer) {\n: #rewrite   ^/   http://www.example.com/;\n: return   403;\n: }\n\n: #rewrite_log  on;\n\n: # rewrite /download/*/mp3/*.any_ext to /download/*/mp3/*.mp3\n: rewrite ^/(download/.*)/mp3/(.*)\\..*$\n: /$1/mp3/$2.mp3                   break;\n\n: root         /spool/www;\n: #autoindex    on;\n: access_log   /var/log/nginx-download.access_log  download;\n: }\n\n: location ~* ^.+\\.(jpg|jpeg|gif)$ {\n: root         /spool/www;\n: access_log   off;\n: expires      30d;\n: }\n: }\n: }\n```\n\n## nginx缓存\n\nnginx支持缓存，这个缓存是将URL及相关组合当作key，用md5编码哈希后保存在硬盘上。\n\n## 均衡负载\n\n在upstream中配置，有权重、轮询、ip_hash、least_conn四种方式。\n","source":"_posts/2020-05-15-kongzheng1993-Nginx.md","raw":"---\ntitle: Nginx\nexcerpt: ''\ntags: [Nginx]\ncategories: [Nginx]\ncomments: true\ndate: 2020-05-12 00:30:52\n---\n\n前两天客户那边说检测出我们的nginx有漏洞，让我们搞一下，其实就是nginx出新版本了，老版本有个重大bug，跟着我们也应该升级。但是一来二去不知道为啥落我头上了，我是开发啊。。不过也无所谓，正好趁着这个机会好好了解一下。\n\n## 什么是Nginx\n\nNginx是一款轻量级的Web服务器、反向代理服务器，由于它的内存占用少，启动极快，高并发能力强，在互联网项目中广泛应用。除了http它还支持IMAP/POP3等协议。\n\n目前比较常见的系统架构中，nginx一般都是在入口处，作为反向代理。\n\n<img src=\"v2-e1826bab1d07df8e97d61aa809b94a10_r.jpg\"/>\n\n提到Nginx就不能不提反向代理。。\n\n\n- **正向代理：**  代理客户端去请求服务器，然后将服务器的响应返回给客户端。我们平常科学上网用的代理服务器起到的作用就是正向代理。*正向代理代理的是客户端*。\n- **反向代理：** 代理服务器来接受客户端的请求，然后将客户端的请求转发到内部网络，并将服务器上得到的结果返回给客户端。*反向代理代理的是服务端*。\n\n## 安装Nginx\n\n安装Nignx和一般软件一样，也是一顿configure、make、make install。。\n\n1. 首先是安装依赖\n\n```shell\nyum -y install gcc openssl-devel pcre-devel zlib-devel\n```\n\n已经有了的就不用装了，pcre库是用来支持正则表达式的，也就是我们想在nginx的配置文件里用正则，还是老老实实把pcre编译进nginx。zlib是对于http包的内容做gzip格式的压缩，如果我们在nginx.conf中配置了`gzip on`，并指定对于某些类型（content-type）的http响应使用gzip来进行压缩以减少网络传输量，就需要把zlib编译进nginx。openssl是用来支持ssl协议，也包含MD5、SHA1等散列函数。\n\n2. 下载解压nginx\n\n```shell\nwget -o XX/nginx-X.X.X.tar.gz\ntar -zxvf nginx-X.X.X.tar.gz\n```\n\n3. configure配置\n\n进入源码根目录，执行：\n\n```shell\n./configure --prefix=/**/**/**\n```\n\n通过`--prefix`来指定软件安装位置。\n\n4. 编译安装\n\n```shell\nmake && make install\n```\n\n在安装完后，就会在你制定的目录出现nginx目录了，一些可执行文件在`sbin`目录下。执行`./nginx`就可以启动nginx了。\n\n使用`nginx -s $sign`可以来控制启动的nginx进程。\n\n$sign有：\n- stop  快速关闭\n- quit  优雅的关闭\n- reload  重新加载配置文件\n- reopen  重新打开日志文件\n\n\n## 运行中的nginx\n\nnginx在启动后，在unix系统中会以daemon的方式在后台运行，后台进程包含一个master进程和多个worker进程。所以，nginx是以多进程的方式来工作的，当然nginx也是支持多线程的方式的，只是我们主流的方式还是多进程的方式，也是nginx的默认方式。我们也可以手动关掉后台模式，让nginx在前台运行，并且也可以通过配置取消master进程，也就是让nginx以单进程运行。这样可以让我们更方便debug。\n\nmaster进程主要是来管理worker进程的，包含：\n\n- 读取并验证nginx.conf\n- 接受外来的信号\n- 向各worker进程发送信号\n- 监控worker的运行状态，当worker进程退出后，master会启动新的worker\n\nworker进程处理的是基本的网络事件，多个worker之间是平等的，他们同等竞争来自客户端的请求，各进程之间是独立的。一个请求只会在一个worker中处理。worker的数量是可以设置的，一般会和cpu核心数一致。worker默认是单线程的，这样可以避免线程切换。\n\n## nginx的热部署\n\n我们在使用nginx一般修改的都是nginx.conf配置文件。每次我们修改nginx.conf后都不需要重启nginx，而是直接执行`nginx -s reload`，让nginx重新加载一下配置就好。\n\nnginx在重新加载配置文件后，会新建新建worker来处理新的请求，旧的请求还是走之前的worker，等老worker处理完请求后，就会被kill掉。\n\n## nginx的高并发\n\n前面的配置worker个数和cpu核心数一致，worker单线程来防止线程切换浪费资源，都是nginx高并发的原因。\n\n还有就是nginx使用的是epoll模型的IO，我理解的就是和redis一样的IO多路复用，通过一个选择器来监听成千上万的连接。（之前在看一本书，用netty、redis、zk做高并发实战，上面讲了文件句柄，nginx是不是也修改了？）\n\n## nginx高可用\n\n请求不要直接打在nginx上，应该先通过虚拟IP（VIP）。\n然后就是通过keepalived来监控nginx的状态，通过执行脚本来检查nginx进程状态。\n\nkeepalived是一种高性能的服务器高可用或热备解决方案，Keepalived可以用来防止服务器单点故障的发生，通过配合 Nginx 可以实现 web 前端服务的高可用。Keepalived以VRRP协议为实现基础，用 VRRP协议来实现高可用性(HA)。VRRP(Virtual Router Redundancy Protocol)协议是用于实现路由器冗余的协议，VRRP 协议将两台或多台路由器设备虚拟成一个设备，对外提供虚拟路由器IP(一个或多个)，而在路由器组内部，如果实际拥有这个对外IP的路由器如果工作正常的话就是MASTER，或者是通过算法选举产生，MASTER 实现针对虚拟路由器 IP 的各种网络功能，如 ARP 请求，ICMP，以及数据的转发等；其他设备不拥有该虚拟 IP，状态是 BACKUP，除了接收 MASTER 的VRRP 状态通告信息外，不执行对外的网络功能。当主机失效时，BACKUP 将接管原先 MASTER 的网络功能。VRRP 协议使用多播数据来传输 VRRP 数据， VRRP 数据使用特殊的虚拟源 MAC 地址发送数据而不是自身网卡的 MAC 地址，VRRP 运行时只有 MASTER 路由器定时发送 VRRP 通告信息，表示 MASTER 工作正常以及虚拟路由器 IP(组)，BACKUP 只接收 VRRP 数据，不发送数据，如果一定时间内没有接收到 MASTER 的通告信息，各 BACKUP 将宣告自己成为 MASTER，发送通告信息，重新进行 MASTER 选举状态。\n\n\n## nginx.conf\n\n我们一般修改的都是nginx.conf文件。\n\n下面是nginx官方给的完整例子：\n\n```shell\n#!nginx\n: # 使用的用户和组\n: user  www www;\n: # 指定工作衍生进程数\n: worker_processes  2;\n: # 指定 pid 存放的路径\n: pid /var/run/nginx.pid;\n\n: # [ debug | info | notice | warn | error | crit ] \n: # 可以在下方直接使用 [ debug | info | notice | warn | error | crit ]  参数\n: error_log  /var/log/nginx.error_log  info;\n\n: events {\n: # 允许的连接数\n: connections   2000;\n: # use [ kqueue | rtsig | epoll | /dev/poll | select | poll ] ;\n: # 具体内容查看 http://wiki.codemongers.com/事件模型\n: use kqueue;\n: }\n\n: http {\n: include       conf/mime.types;\n: default_type  application/octet-stream;\n\n: log_format main      '$remote_addr - $remote_user [$time_local]  '\n: '\"$request\" $status $bytes_sent '\n: '\"$http_referer\" \"$http_user_agent\" '\n: '\"$gzip_ratio\"';\n\n: log_format download  '$remote_addr - $remote_user [$time_local]  '\n: '\"$request\" $status $bytes_sent '\n: '\"$http_referer\" \"$http_user_agent\" '\n: '\"$http_range\" \"$sent_http_content_range\"';\n\n: client_header_timeout  3m;\n: client_body_timeout    3m;\n: send_timeout           3m;\n\n: client_header_buffer_size    1k;\n: large_client_header_buffers  4 4k;\n\n: gzip on;\n: gzip_min_length  1100;\n: gzip_buffers     4 8k;\n: gzip_types       text/plain;\n\n: output_buffers   1 32k;\n: postpone_output  1460;\n\n: sendfile         on;\n: tcp_nopush       on;\n: tcp_nodelay      on;\n: send_lowat       12000;\n\n: keepalive_timeout  75 20;\n\n: #lingering_time     30;\n: #lingering_timeout  10;\n: #reset_timedout_connection  on;\n\n\n: server {\n: listen        one.example.com;\n: server_name   one.example.com  www.one.example.com;\n\n: access_log   /var/log/nginx.access_log  main;\n\n: location / {\n: proxy_pass         http://127.0.0.1/;\n: proxy_redirect     off;\n\n: proxy_set_header   Host             $host;\n: proxy_set_header   X-Real-IP        $remote_addr;\n: #proxy_set_header  X-Forwarded-For  $proxy_add_x_forwarded_for;\n\n: client_max_body_size       10m;\n: client_body_buffer_size    128k;\n\n: client_body_temp_path      /var/nginx/client_body_temp;\n\n: proxy_connect_timeout      90;\n: proxy_send_timeout         90;\n: proxy_read_timeout         90;\n: proxy_send_lowat           12000;\n\n: proxy_buffer_size          4k;\n: proxy_buffers              4 32k;\n: proxy_busy_buffers_size    64k;\n: proxy_temp_file_write_size 64k;\n\n: proxy_temp_path            /var/nginx/proxy_temp;\n\n: charset  koi8-r;\n: }\n\n: error_page  404  /404.html;\n\n: location /404.html {\n: root  /spool/www;\n\n: charset         on;\n: source_charset  koi8-r;\n: }\n\n: location /old_stuff/ {\n: rewrite   ^/old_stuff/(.*)$  /new_stuff/$1  permanent;\n: }\n\n: location /download/ {\n\n: valid_referers  none  blocked  server_names  *.example.com;\n\n: if ($invalid_referer) {\n: #rewrite   ^/   http://www.example.com/;\n: return   403;\n: }\n\n: #rewrite_log  on;\n\n: # rewrite /download/*/mp3/*.any_ext to /download/*/mp3/*.mp3\n: rewrite ^/(download/.*)/mp3/(.*)\\..*$\n: /$1/mp3/$2.mp3                   break;\n\n: root         /spool/www;\n: #autoindex    on;\n: access_log   /var/log/nginx-download.access_log  download;\n: }\n\n: location ~* ^.+\\.(jpg|jpeg|gif)$ {\n: root         /spool/www;\n: access_log   off;\n: expires      30d;\n: }\n: }\n: }\n```\n\n## nginx缓存\n\nnginx支持缓存，这个缓存是将URL及相关组合当作key，用md5编码哈希后保存在硬盘上。\n\n## 均衡负载\n\n在upstream中配置，有权重、轮询、ip_hash、least_conn四种方式。\n","slug":"kongzheng1993-Nginx","published":1,"updated":"2023-03-08T07:05:58.801Z","layout":"post","photos":[],"link":"","_id":"clg0k2aqn00i5t26fwobzynza","content":"<p>前两天客户那边说检测出我们的nginx有漏洞，让我们搞一下，其实就是nginx出新版本了，老版本有个重大bug，跟着我们也应该升级。但是一来二去不知道为啥落我头上了，我是开发啊。。不过也无所谓，正好趁着这个机会好好了解一下。</p>\n<h2 id=\"什么是Nginx\"><a href=\"#什么是Nginx\" class=\"headerlink\" title=\"什么是Nginx\"></a>什么是Nginx</h2><p>Nginx是一款轻量级的Web服务器、反向代理服务器，由于它的内存占用少，启动极快，高并发能力强，在互联网项目中广泛应用。除了http它还支持IMAP/POP3等协议。</p>\n<p>目前比较常见的系统架构中，nginx一般都是在入口处，作为反向代理。</p>\n<img src=\"/2020/05/12/kongzheng1993-Nginx/v2-e1826bab1d07df8e97d61aa809b94a10_r.jpg\">\n\n<p>提到Nginx就不能不提反向代理。。</p>\n<ul>\n<li><strong>正向代理：</strong>  代理客户端去请求服务器，然后将服务器的响应返回给客户端。我们平常科学上网用的代理服务器起到的作用就是正向代理。<em>正向代理代理的是客户端</em>。</li>\n<li><strong>反向代理：</strong> 代理服务器来接受客户端的请求，然后将客户端的请求转发到内部网络，并将服务器上得到的结果返回给客户端。<em>反向代理代理的是服务端</em>。</li>\n</ul>\n<h2 id=\"安装Nginx\"><a href=\"#安装Nginx\" class=\"headerlink\" title=\"安装Nginx\"></a>安装Nginx</h2><p>安装Nignx和一般软件一样，也是一顿configure、make、make install。。</p>\n<ol>\n<li>首先是安装依赖</li>\n</ol>\n<pre><code class=\"shell\">yum -y install gcc openssl-devel pcre-devel zlib-devel</code></pre>\n<p>已经有了的就不用装了，pcre库是用来支持正则表达式的，也就是我们想在nginx的配置文件里用正则，还是老老实实把pcre编译进nginx。zlib是对于http包的内容做gzip格式的压缩，如果我们在nginx.conf中配置了<code>gzip on</code>，并指定对于某些类型（content-type）的http响应使用gzip来进行压缩以减少网络传输量，就需要把zlib编译进nginx。openssl是用来支持ssl协议，也包含MD5、SHA1等散列函数。</p>\n<ol start=\"2\">\n<li>下载解压nginx</li>\n</ol>\n<pre><code class=\"shell\">wget -o XX/nginx-X.X.X.tar.gz\ntar -zxvf nginx-X.X.X.tar.gz</code></pre>\n<ol start=\"3\">\n<li>configure配置</li>\n</ol>\n<p>进入源码根目录，执行：</p>\n<pre><code class=\"shell\">./configure --prefix=/**/**/**</code></pre>\n<p>通过<code>--prefix</code>来指定软件安装位置。</p>\n<ol start=\"4\">\n<li>编译安装</li>\n</ol>\n<pre><code class=\"shell\">make &amp;&amp; make install</code></pre>\n<p>在安装完后，就会在你制定的目录出现nginx目录了，一些可执行文件在<code>sbin</code>目录下。执行<code>./nginx</code>就可以启动nginx了。</p>\n<p>使用<code>nginx -s $sign</code>可以来控制启动的nginx进程。</p>\n<p>$sign有：</p>\n<ul>\n<li>stop  快速关闭</li>\n<li>quit  优雅的关闭</li>\n<li>reload  重新加载配置文件</li>\n<li>reopen  重新打开日志文件</li>\n</ul>\n<h2 id=\"运行中的nginx\"><a href=\"#运行中的nginx\" class=\"headerlink\" title=\"运行中的nginx\"></a>运行中的nginx</h2><p>nginx在启动后，在unix系统中会以daemon的方式在后台运行，后台进程包含一个master进程和多个worker进程。所以，nginx是以多进程的方式来工作的，当然nginx也是支持多线程的方式的，只是我们主流的方式还是多进程的方式，也是nginx的默认方式。我们也可以手动关掉后台模式，让nginx在前台运行，并且也可以通过配置取消master进程，也就是让nginx以单进程运行。这样可以让我们更方便debug。</p>\n<p>master进程主要是来管理worker进程的，包含：</p>\n<ul>\n<li>读取并验证nginx.conf</li>\n<li>接受外来的信号</li>\n<li>向各worker进程发送信号</li>\n<li>监控worker的运行状态，当worker进程退出后，master会启动新的worker</li>\n</ul>\n<p>worker进程处理的是基本的网络事件，多个worker之间是平等的，他们同等竞争来自客户端的请求，各进程之间是独立的。一个请求只会在一个worker中处理。worker的数量是可以设置的，一般会和cpu核心数一致。worker默认是单线程的，这样可以避免线程切换。</p>\n<h2 id=\"nginx的热部署\"><a href=\"#nginx的热部署\" class=\"headerlink\" title=\"nginx的热部署\"></a>nginx的热部署</h2><p>我们在使用nginx一般修改的都是nginx.conf配置文件。每次我们修改nginx.conf后都不需要重启nginx，而是直接执行<code>nginx -s reload</code>，让nginx重新加载一下配置就好。</p>\n<p>nginx在重新加载配置文件后，会新建新建worker来处理新的请求，旧的请求还是走之前的worker，等老worker处理完请求后，就会被kill掉。</p>\n<h2 id=\"nginx的高并发\"><a href=\"#nginx的高并发\" class=\"headerlink\" title=\"nginx的高并发\"></a>nginx的高并发</h2><p>前面的配置worker个数和cpu核心数一致，worker单线程来防止线程切换浪费资源，都是nginx高并发的原因。</p>\n<p>还有就是nginx使用的是epoll模型的IO，我理解的就是和redis一样的IO多路复用，通过一个选择器来监听成千上万的连接。（之前在看一本书，用netty、redis、zk做高并发实战，上面讲了文件句柄，nginx是不是也修改了？）</p>\n<h2 id=\"nginx高可用\"><a href=\"#nginx高可用\" class=\"headerlink\" title=\"nginx高可用\"></a>nginx高可用</h2><p>请求不要直接打在nginx上，应该先通过虚拟IP（VIP）。<br>然后就是通过keepalived来监控nginx的状态，通过执行脚本来检查nginx进程状态。</p>\n<p>keepalived是一种高性能的服务器高可用或热备解决方案，Keepalived可以用来防止服务器单点故障的发生，通过配合 Nginx 可以实现 web 前端服务的高可用。Keepalived以VRRP协议为实现基础，用 VRRP协议来实现高可用性(HA)。VRRP(Virtual Router Redundancy Protocol)协议是用于实现路由器冗余的协议，VRRP 协议将两台或多台路由器设备虚拟成一个设备，对外提供虚拟路由器IP(一个或多个)，而在路由器组内部，如果实际拥有这个对外IP的路由器如果工作正常的话就是MASTER，或者是通过算法选举产生，MASTER 实现针对虚拟路由器 IP 的各种网络功能，如 ARP 请求，ICMP，以及数据的转发等；其他设备不拥有该虚拟 IP，状态是 BACKUP，除了接收 MASTER 的VRRP 状态通告信息外，不执行对外的网络功能。当主机失效时，BACKUP 将接管原先 MASTER 的网络功能。VRRP 协议使用多播数据来传输 VRRP 数据， VRRP 数据使用特殊的虚拟源 MAC 地址发送数据而不是自身网卡的 MAC 地址，VRRP 运行时只有 MASTER 路由器定时发送 VRRP 通告信息，表示 MASTER 工作正常以及虚拟路由器 IP(组)，BACKUP 只接收 VRRP 数据，不发送数据，如果一定时间内没有接收到 MASTER 的通告信息，各 BACKUP 将宣告自己成为 MASTER，发送通告信息，重新进行 MASTER 选举状态。</p>\n<h2 id=\"nginx-conf\"><a href=\"#nginx-conf\" class=\"headerlink\" title=\"nginx.conf\"></a>nginx.conf</h2><p>我们一般修改的都是nginx.conf文件。</p>\n<p>下面是nginx官方给的完整例子：</p>\n<pre><code class=\"shell\">#!nginx\n: # 使用的用户和组\n: user  www www;\n: # 指定工作衍生进程数\n: worker_processes  2;\n: # 指定 pid 存放的路径\n: pid /var/run/nginx.pid;\n\n: # [ debug | info | notice | warn | error | crit ] \n: # 可以在下方直接使用 [ debug | info | notice | warn | error | crit ]  参数\n: error_log  /var/log/nginx.error_log  info;\n\n: events {\n: # 允许的连接数\n: connections   2000;\n: # use [ kqueue | rtsig | epoll | /dev/poll | select | poll ] ;\n: # 具体内容查看 http://wiki.codemongers.com/事件模型\n: use kqueue;\n: }\n\n: http {\n: include       conf/mime.types;\n: default_type  application/octet-stream;\n\n: log_format main      &#39;$remote_addr - $remote_user [$time_local]  &#39;\n: &#39;&quot;$request&quot; $status $bytes_sent &#39;\n: &#39;&quot;$http_referer&quot; &quot;$http_user_agent&quot; &#39;\n: &#39;&quot;$gzip_ratio&quot;&#39;;\n\n: log_format download  &#39;$remote_addr - $remote_user [$time_local]  &#39;\n: &#39;&quot;$request&quot; $status $bytes_sent &#39;\n: &#39;&quot;$http_referer&quot; &quot;$http_user_agent&quot; &#39;\n: &#39;&quot;$http_range&quot; &quot;$sent_http_content_range&quot;&#39;;\n\n: client_header_timeout  3m;\n: client_body_timeout    3m;\n: send_timeout           3m;\n\n: client_header_buffer_size    1k;\n: large_client_header_buffers  4 4k;\n\n: gzip on;\n: gzip_min_length  1100;\n: gzip_buffers     4 8k;\n: gzip_types       text/plain;\n\n: output_buffers   1 32k;\n: postpone_output  1460;\n\n: sendfile         on;\n: tcp_nopush       on;\n: tcp_nodelay      on;\n: send_lowat       12000;\n\n: keepalive_timeout  75 20;\n\n: #lingering_time     30;\n: #lingering_timeout  10;\n: #reset_timedout_connection  on;\n\n\n: server {\n: listen        one.example.com;\n: server_name   one.example.com  www.one.example.com;\n\n: access_log   /var/log/nginx.access_log  main;\n\n: location / {\n: proxy_pass         http://127.0.0.1/;\n: proxy_redirect     off;\n\n: proxy_set_header   Host             $host;\n: proxy_set_header   X-Real-IP        $remote_addr;\n: #proxy_set_header  X-Forwarded-For  $proxy_add_x_forwarded_for;\n\n: client_max_body_size       10m;\n: client_body_buffer_size    128k;\n\n: client_body_temp_path      /var/nginx/client_body_temp;\n\n: proxy_connect_timeout      90;\n: proxy_send_timeout         90;\n: proxy_read_timeout         90;\n: proxy_send_lowat           12000;\n\n: proxy_buffer_size          4k;\n: proxy_buffers              4 32k;\n: proxy_busy_buffers_size    64k;\n: proxy_temp_file_write_size 64k;\n\n: proxy_temp_path            /var/nginx/proxy_temp;\n\n: charset  koi8-r;\n: }\n\n: error_page  404  /404.html;\n\n: location /404.html {\n: root  /spool/www;\n\n: charset         on;\n: source_charset  koi8-r;\n: }\n\n: location /old_stuff/ {\n: rewrite   ^/old_stuff/(.*)$  /new_stuff/$1  permanent;\n: }\n\n: location /download/ {\n\n: valid_referers  none  blocked  server_names  *.example.com;\n\n: if ($invalid_referer) {\n: #rewrite   ^/   http://www.example.com/;\n: return   403;\n: }\n\n: #rewrite_log  on;\n\n: # rewrite /download/*/mp3/*.any_ext to /download/*/mp3/*.mp3\n: rewrite ^/(download/.*)/mp3/(.*)\\..*$\n: /$1/mp3/$2.mp3                   break;\n\n: root         /spool/www;\n: #autoindex    on;\n: access_log   /var/log/nginx-download.access_log  download;\n: }\n\n: location ~* ^.+\\.(jpg|jpeg|gif)$ {\n: root         /spool/www;\n: access_log   off;\n: expires      30d;\n: }\n: }\n: }</code></pre>\n<h2 id=\"nginx缓存\"><a href=\"#nginx缓存\" class=\"headerlink\" title=\"nginx缓存\"></a>nginx缓存</h2><p>nginx支持缓存，这个缓存是将URL及相关组合当作key，用md5编码哈希后保存在硬盘上。</p>\n<h2 id=\"均衡负载\"><a href=\"#均衡负载\" class=\"headerlink\" title=\"均衡负载\"></a>均衡负载</h2><p>在upstream中配置，有权重、轮询、ip_hash、least_conn四种方式。</p>\n","site":{"data":{}},"more":"<p>前两天客户那边说检测出我们的nginx有漏洞，让我们搞一下，其实就是nginx出新版本了，老版本有个重大bug，跟着我们也应该升级。但是一来二去不知道为啥落我头上了，我是开发啊。。不过也无所谓，正好趁着这个机会好好了解一下。</p>\n<h2 id=\"什么是Nginx\"><a href=\"#什么是Nginx\" class=\"headerlink\" title=\"什么是Nginx\"></a>什么是Nginx</h2><p>Nginx是一款轻量级的Web服务器、反向代理服务器，由于它的内存占用少，启动极快，高并发能力强，在互联网项目中广泛应用。除了http它还支持IMAP/POP3等协议。</p>\n<p>目前比较常见的系统架构中，nginx一般都是在入口处，作为反向代理。</p>\n<img src=\"/2020/05/12/kongzheng1993-Nginx/v2-e1826bab1d07df8e97d61aa809b94a10_r.jpg\">\n\n<p>提到Nginx就不能不提反向代理。。</p>\n<ul>\n<li><strong>正向代理：</strong>  代理客户端去请求服务器，然后将服务器的响应返回给客户端。我们平常科学上网用的代理服务器起到的作用就是正向代理。<em>正向代理代理的是客户端</em>。</li>\n<li><strong>反向代理：</strong> 代理服务器来接受客户端的请求，然后将客户端的请求转发到内部网络，并将服务器上得到的结果返回给客户端。<em>反向代理代理的是服务端</em>。</li>\n</ul>\n<h2 id=\"安装Nginx\"><a href=\"#安装Nginx\" class=\"headerlink\" title=\"安装Nginx\"></a>安装Nginx</h2><p>安装Nignx和一般软件一样，也是一顿configure、make、make install。。</p>\n<ol>\n<li>首先是安装依赖</li>\n</ol>\n<pre><code class=\"shell\">yum -y install gcc openssl-devel pcre-devel zlib-devel</code></pre>\n<p>已经有了的就不用装了，pcre库是用来支持正则表达式的，也就是我们想在nginx的配置文件里用正则，还是老老实实把pcre编译进nginx。zlib是对于http包的内容做gzip格式的压缩，如果我们在nginx.conf中配置了<code>gzip on</code>，并指定对于某些类型（content-type）的http响应使用gzip来进行压缩以减少网络传输量，就需要把zlib编译进nginx。openssl是用来支持ssl协议，也包含MD5、SHA1等散列函数。</p>\n<ol start=\"2\">\n<li>下载解压nginx</li>\n</ol>\n<pre><code class=\"shell\">wget -o XX/nginx-X.X.X.tar.gz\ntar -zxvf nginx-X.X.X.tar.gz</code></pre>\n<ol start=\"3\">\n<li>configure配置</li>\n</ol>\n<p>进入源码根目录，执行：</p>\n<pre><code class=\"shell\">./configure --prefix=/**/**/**</code></pre>\n<p>通过<code>--prefix</code>来指定软件安装位置。</p>\n<ol start=\"4\">\n<li>编译安装</li>\n</ol>\n<pre><code class=\"shell\">make &amp;&amp; make install</code></pre>\n<p>在安装完后，就会在你制定的目录出现nginx目录了，一些可执行文件在<code>sbin</code>目录下。执行<code>./nginx</code>就可以启动nginx了。</p>\n<p>使用<code>nginx -s $sign</code>可以来控制启动的nginx进程。</p>\n<p>$sign有：</p>\n<ul>\n<li>stop  快速关闭</li>\n<li>quit  优雅的关闭</li>\n<li>reload  重新加载配置文件</li>\n<li>reopen  重新打开日志文件</li>\n</ul>\n<h2 id=\"运行中的nginx\"><a href=\"#运行中的nginx\" class=\"headerlink\" title=\"运行中的nginx\"></a>运行中的nginx</h2><p>nginx在启动后，在unix系统中会以daemon的方式在后台运行，后台进程包含一个master进程和多个worker进程。所以，nginx是以多进程的方式来工作的，当然nginx也是支持多线程的方式的，只是我们主流的方式还是多进程的方式，也是nginx的默认方式。我们也可以手动关掉后台模式，让nginx在前台运行，并且也可以通过配置取消master进程，也就是让nginx以单进程运行。这样可以让我们更方便debug。</p>\n<p>master进程主要是来管理worker进程的，包含：</p>\n<ul>\n<li>读取并验证nginx.conf</li>\n<li>接受外来的信号</li>\n<li>向各worker进程发送信号</li>\n<li>监控worker的运行状态，当worker进程退出后，master会启动新的worker</li>\n</ul>\n<p>worker进程处理的是基本的网络事件，多个worker之间是平等的，他们同等竞争来自客户端的请求，各进程之间是独立的。一个请求只会在一个worker中处理。worker的数量是可以设置的，一般会和cpu核心数一致。worker默认是单线程的，这样可以避免线程切换。</p>\n<h2 id=\"nginx的热部署\"><a href=\"#nginx的热部署\" class=\"headerlink\" title=\"nginx的热部署\"></a>nginx的热部署</h2><p>我们在使用nginx一般修改的都是nginx.conf配置文件。每次我们修改nginx.conf后都不需要重启nginx，而是直接执行<code>nginx -s reload</code>，让nginx重新加载一下配置就好。</p>\n<p>nginx在重新加载配置文件后，会新建新建worker来处理新的请求，旧的请求还是走之前的worker，等老worker处理完请求后，就会被kill掉。</p>\n<h2 id=\"nginx的高并发\"><a href=\"#nginx的高并发\" class=\"headerlink\" title=\"nginx的高并发\"></a>nginx的高并发</h2><p>前面的配置worker个数和cpu核心数一致，worker单线程来防止线程切换浪费资源，都是nginx高并发的原因。</p>\n<p>还有就是nginx使用的是epoll模型的IO，我理解的就是和redis一样的IO多路复用，通过一个选择器来监听成千上万的连接。（之前在看一本书，用netty、redis、zk做高并发实战，上面讲了文件句柄，nginx是不是也修改了？）</p>\n<h2 id=\"nginx高可用\"><a href=\"#nginx高可用\" class=\"headerlink\" title=\"nginx高可用\"></a>nginx高可用</h2><p>请求不要直接打在nginx上，应该先通过虚拟IP（VIP）。<br>然后就是通过keepalived来监控nginx的状态，通过执行脚本来检查nginx进程状态。</p>\n<p>keepalived是一种高性能的服务器高可用或热备解决方案，Keepalived可以用来防止服务器单点故障的发生，通过配合 Nginx 可以实现 web 前端服务的高可用。Keepalived以VRRP协议为实现基础，用 VRRP协议来实现高可用性(HA)。VRRP(Virtual Router Redundancy Protocol)协议是用于实现路由器冗余的协议，VRRP 协议将两台或多台路由器设备虚拟成一个设备，对外提供虚拟路由器IP(一个或多个)，而在路由器组内部，如果实际拥有这个对外IP的路由器如果工作正常的话就是MASTER，或者是通过算法选举产生，MASTER 实现针对虚拟路由器 IP 的各种网络功能，如 ARP 请求，ICMP，以及数据的转发等；其他设备不拥有该虚拟 IP，状态是 BACKUP，除了接收 MASTER 的VRRP 状态通告信息外，不执行对外的网络功能。当主机失效时，BACKUP 将接管原先 MASTER 的网络功能。VRRP 协议使用多播数据来传输 VRRP 数据， VRRP 数据使用特殊的虚拟源 MAC 地址发送数据而不是自身网卡的 MAC 地址，VRRP 运行时只有 MASTER 路由器定时发送 VRRP 通告信息，表示 MASTER 工作正常以及虚拟路由器 IP(组)，BACKUP 只接收 VRRP 数据，不发送数据，如果一定时间内没有接收到 MASTER 的通告信息，各 BACKUP 将宣告自己成为 MASTER，发送通告信息，重新进行 MASTER 选举状态。</p>\n<h2 id=\"nginx-conf\"><a href=\"#nginx-conf\" class=\"headerlink\" title=\"nginx.conf\"></a>nginx.conf</h2><p>我们一般修改的都是nginx.conf文件。</p>\n<p>下面是nginx官方给的完整例子：</p>\n<pre><code class=\"shell\">#!nginx\n: # 使用的用户和组\n: user  www www;\n: # 指定工作衍生进程数\n: worker_processes  2;\n: # 指定 pid 存放的路径\n: pid /var/run/nginx.pid;\n\n: # [ debug | info | notice | warn | error | crit ] \n: # 可以在下方直接使用 [ debug | info | notice | warn | error | crit ]  参数\n: error_log  /var/log/nginx.error_log  info;\n\n: events {\n: # 允许的连接数\n: connections   2000;\n: # use [ kqueue | rtsig | epoll | /dev/poll | select | poll ] ;\n: # 具体内容查看 http://wiki.codemongers.com/事件模型\n: use kqueue;\n: }\n\n: http {\n: include       conf/mime.types;\n: default_type  application/octet-stream;\n\n: log_format main      &#39;$remote_addr - $remote_user [$time_local]  &#39;\n: &#39;&quot;$request&quot; $status $bytes_sent &#39;\n: &#39;&quot;$http_referer&quot; &quot;$http_user_agent&quot; &#39;\n: &#39;&quot;$gzip_ratio&quot;&#39;;\n\n: log_format download  &#39;$remote_addr - $remote_user [$time_local]  &#39;\n: &#39;&quot;$request&quot; $status $bytes_sent &#39;\n: &#39;&quot;$http_referer&quot; &quot;$http_user_agent&quot; &#39;\n: &#39;&quot;$http_range&quot; &quot;$sent_http_content_range&quot;&#39;;\n\n: client_header_timeout  3m;\n: client_body_timeout    3m;\n: send_timeout           3m;\n\n: client_header_buffer_size    1k;\n: large_client_header_buffers  4 4k;\n\n: gzip on;\n: gzip_min_length  1100;\n: gzip_buffers     4 8k;\n: gzip_types       text/plain;\n\n: output_buffers   1 32k;\n: postpone_output  1460;\n\n: sendfile         on;\n: tcp_nopush       on;\n: tcp_nodelay      on;\n: send_lowat       12000;\n\n: keepalive_timeout  75 20;\n\n: #lingering_time     30;\n: #lingering_timeout  10;\n: #reset_timedout_connection  on;\n\n\n: server {\n: listen        one.example.com;\n: server_name   one.example.com  www.one.example.com;\n\n: access_log   /var/log/nginx.access_log  main;\n\n: location / {\n: proxy_pass         http://127.0.0.1/;\n: proxy_redirect     off;\n\n: proxy_set_header   Host             $host;\n: proxy_set_header   X-Real-IP        $remote_addr;\n: #proxy_set_header  X-Forwarded-For  $proxy_add_x_forwarded_for;\n\n: client_max_body_size       10m;\n: client_body_buffer_size    128k;\n\n: client_body_temp_path      /var/nginx/client_body_temp;\n\n: proxy_connect_timeout      90;\n: proxy_send_timeout         90;\n: proxy_read_timeout         90;\n: proxy_send_lowat           12000;\n\n: proxy_buffer_size          4k;\n: proxy_buffers              4 32k;\n: proxy_busy_buffers_size    64k;\n: proxy_temp_file_write_size 64k;\n\n: proxy_temp_path            /var/nginx/proxy_temp;\n\n: charset  koi8-r;\n: }\n\n: error_page  404  /404.html;\n\n: location /404.html {\n: root  /spool/www;\n\n: charset         on;\n: source_charset  koi8-r;\n: }\n\n: location /old_stuff/ {\n: rewrite   ^/old_stuff/(.*)$  /new_stuff/$1  permanent;\n: }\n\n: location /download/ {\n\n: valid_referers  none  blocked  server_names  *.example.com;\n\n: if ($invalid_referer) {\n: #rewrite   ^/   http://www.example.com/;\n: return   403;\n: }\n\n: #rewrite_log  on;\n\n: # rewrite /download/*/mp3/*.any_ext to /download/*/mp3/*.mp3\n: rewrite ^/(download/.*)/mp3/(.*)\\..*$\n: /$1/mp3/$2.mp3                   break;\n\n: root         /spool/www;\n: #autoindex    on;\n: access_log   /var/log/nginx-download.access_log  download;\n: }\n\n: location ~* ^.+\\.(jpg|jpeg|gif)$ {\n: root         /spool/www;\n: access_log   off;\n: expires      30d;\n: }\n: }\n: }</code></pre>\n<h2 id=\"nginx缓存\"><a href=\"#nginx缓存\" class=\"headerlink\" title=\"nginx缓存\"></a>nginx缓存</h2><p>nginx支持缓存，这个缓存是将URL及相关组合当作key，用md5编码哈希后保存在硬盘上。</p>\n<h2 id=\"均衡负载\"><a href=\"#均衡负载\" class=\"headerlink\" title=\"均衡负载\"></a>均衡负载</h2><p>在upstream中配置，有权重、轮询、ip_hash、least_conn四种方式。</p>\n"},{"title":"MongoDB笔记","excerpt":"","comments":1,"date":"2023-03-08T07:05:58.813Z","_content":"\n## 1. 主要特性\n\n1. mongoDB的数据模型是面向文档的\n\n2. 不像关系型数据库，每张表都有严格定义的Schema，规定了列和类型。mongoDB没有Schema，特别适合项目初期使用（表设计经常变化）。\n\n3. 支持即时查询。\n\n4. 二级索引。MongoDB中的二级索引也是用B树实现的。每个集合最多可以创建64个索引。它支持能在RDBMS中找到的各种索引，升序、降序、唯一性、复合键索引，甚至地理空间索引都支持。因为mongoDB和关系型数据库使用相同的索引数据结构。\n\n5. 复制。mongoDB通过副本集（replica set）的拓扑结构提供了复制功能。副本集将数据分布在多台机器上以实现冗余，在服务器和网络故障时能提供自动故障转移。并且复制功能还能扩展数据库的读能力，如果有一个读密集型的应用，可以把数据库读操作分散到副本集集群中的各台机器上。**副本集由一个主节点和一个或多个从节点构成。**与我们熟悉的其他数据库的主从复制类似。副本集的主节点既能接受读操作又能接受写操作，但是从节点是只读的。**副本集与众不同的是它支持自动故障转移：如果主节点出现问题，集群会选择一个从节点自动将它提升为主节点。在先前的主节点恢复后会变成一个从节点**。\n\n<img src = \"image-20210715174420382.png\"/>\n\n6. 速度和持久性。用户可以选择写入语义，决定是否开启Journaling日志，通过这种方式来控制速度和持久性的平衡。默认所有的写操作都是`fire-and-forget`（射后不理）的，也就是通过TCP套接字发送，不要求数据库应答。如果用户需要获得应答，可以使用特殊的安全模式发起写操作，所有驱动都提供这个安全模式。该模式强制数据库做出应答，确保数据库正确无误地接收到了写操作。安全模式是可配置的，还可用于阻塞操作，直到写操作被复制到特定数量的服务器。对于高容量、低价值的数据（例如点击流和日志）,`fire-and-forget`风格的写操作是很理想的。对于重要的数据，则更倾向于安全模式。**在MongoDB 2.0中，Journaling日志是默认开启的。**有了这个功能，所有写操作都会被提交到一个只能追加的日志里。即使服务器非正常关闭（比如电源故障）,该日志也能保证重启服务器后MongoDB的数据文件被恢复到一致的状态。这是运行MongoDB最安全的方式。Journaling日志类似MySQL的InnoDB的事务日志，先写日志，再写内存，而后日志会同步到磁盘。先写日志，而不是直接去写主数据文件，是因为**顺序IO要比随机IO快的多**\n7. 数据库扩展。**提升单一节点的硬件来进行扩展成为垂直扩展或者向上扩展**。垂直扩展的优势在于简单可靠，但是终有一天更强的服务器成本会让人望而却步。这时就应该考虑水平扩展或向外扩展了。**水平扩展不是提升单一节点的性能，而是将数据库分布到多台机器上**。MongoDB的水平扩展非常易于管理，通过基于范围的分区机制即**自动分片**来实现这一设计目标，自动分片机制会自动管理各个节点之间的数据分布。分片系统会处理分片节点的增加，帮助进行自动故障转移。单独的分片由一个副本集组成，其中包含至少两个节点，保证能够自动恢复，没有单点失败。\n\n## MongoDB核心服务器\n\nMongoDB是用C++编写的，由10gen积极维护。开源的。\n\n1. 通过可执行文件mongod（windows上是mongodb.exe）可以运行核心服务器。mongod服务器进程使用一个自定义的二进制协议从网络套接字上接收命令，mongod进程的所有数据文件默认存储在`/data/db`里\n2. mongod有多种运行模式，最常见的是作为副本集中的一员，因为推荐使用复制，通常副本集由两个副本组成，再加上一个部署在第三台服务器上的**仲裁进程**。\n3. 对于MongoDB的自动分片架构而言，其组件包含配置为预先分片的副本集的mongod进程，以及特殊的元数据服务器，称为配置服务器（config server）。另外还有单独的名为mongos的路由服务器向适当的分片发送请求。\n4. mongodb除了指定标准端口和数据目录，没有什么调优数据库的选项。但是这并不是缺陷，而是一个系统设计亮点，因为MongoDB的设计哲学指出，内存管理最好是由操作系统而非DBA或者应用程序开发者来处理，如此一来，数据文件通过mmap()系统调用被映射成了系统的虚拟内存，这一举措行之有效的将内存管理交给了操作系统内核。\n\n## MongoDB工具\n\n1. JavaScript Shell： MongoDB命令行shell是一个基于JavaScript的工具，用户管理数据库和操作数据。可执行文件mongo会加载shell并连接到指定的mongod进程。MongoDB Shell的功能和Mysql Shell差不多，但并不是使用SQL，大多数命令使用的是Javascript表达式。比如`db.users.insert({name: \"Tom\"})`。\n2. 数据库驱动。\n3. 命令行工具：\n   1. mongodump和mongorestore：备份和恢复数据库的工具\n   2. mongoexport和mongoimport：用来导入导出JSON、CSV和TSV数据\n   3. mongosniff：一个网络嗅探工具，用来观察发送到数据库的操作。基本就是把网络上传输的BSON转换为易于人们阅读的Shell语句。\n   4. mongostat：持续轮询MongoDB和系统以便提供有磅数的统计信息，包括每秒操作数、分配的虚拟内存数量以及服务器的连接数。\n\n## 2. MongoDB JavaScript Shell\n\n### 1. 通过shell增删改查\n\n### 2. 索引\n\n1. 创建一个大集合，因为mongoDB Shell是javaScript解释器，所以可以像下面一样使用js\n\n   ```javascript\n   for(i=0; i<200000; i++) {\n       db.numbers.save({num: i});\n   }\n   ```\n\n2. explain\n\n   ```javascript\n   db.numbers.find({num: {\"$gt\": 199995}}).explain()\n   ```\n\n   \n\n3. 创建索引\n\n   ```javascript\n   // 创建索引\n   db.numbers.ensureIndex({num: 1})\n   // 查看索引\n   db.numbers.getIndexes()\n   ```\n\n   \n\n### 3. 基本管理\n\n1. 获取数据库信息\n\n   ```javascript\n   // 显示系统上所有的数据库\n   show dbs\n   // 显示定义在当前数据库里的所有集合\n   show collections\n   // 获取数据库与集合更底层的统计数据\n   db.stats()\n   // 获取集合的统计数据\n   db.numbers.stats()\n   ```\n\n   \n\n2. 命令工作原理\n\nMongoDB Shell会输出所有方法的实现，只要这些方法忽略括号就可以了。比如查看db.runCommand()的方法实现，输入db.runCommand就可以查看。\n\nrunCommand函数中的最后一行就是查询“$cmd”集合。\n\n- 数据库命令是对特殊集合$cmd的查询。\n\n- 查询选择器就是对命令本身的定义。\n\n3. 获得帮助\n   1. 通过tab不全命令\n   2. 通过上面说的执行不带括号的方法名，查看方法实现\n\n## 3. 使用MongoDB\n\n### 1. 驱动是如何工作的\n\nMongoDB驱动都有三个主要功能：\n\n1. 生成MongoDB对象ID，这是存储在所有文档_id字段里的默认值\n2. 驱动会把所有语言特定的文档描述和BSON互相转换，BSON是MongoDB使用的二进制数据格式\n3. 使用MongoDB的网络协议通过TCP套接字与数据库通信\n\n对象ID：对象ID不会重复，由12个字节构成，前四个字节是时间戳，接下来3个字节存储了机器ID，随后2个字节记录的进程ID，最后3个字节存储了进程局部的计数器，每次生成对象计数器都会加1。通过id可以获取创建的时间戳，精度是最接近的一秒钟。\n\nBSON：是MongoDB中用来表示文档的二进制格式，即使存储格式，也是命令格式。BSON规范包含了19种数据格式，包含UTF-8字符串、32位和64位整数、双精度浮点数、布尔值、时间戳和UTC日期时间（datetime）。其他一部分类型是MongoDB特定的。比如对象ID就有自己的格式，还有模糊大字段的二进制类型等。\n\n### 2. 数据的细节\n\n1. 管理数据库\n\n   MongoDB没有显示创建数据库的方法，而是在向集合写入数据的时候会自动创建，可以通过下面的方法删除数据库，但是这个操作一定要小心，因为这个操作是无法撤回的。\n\n   ```javascript\n   use garden\n   db.dropDatabase();\n   ```\n\n2. 数据文件与空间分配\n\n   创建数据库时，MongoDB会在磁盘上分配一组数据文件，把所有集合、索引和数据库的其他元数据保存在这些文件里。数据文件都被放置在启动mongod时指定的dbpath里。在未指定dbpath时，mongod会把文件全保存在data/db里：\n\n   - .ns文件：namespaces，命名空间。每个集合和索引都有自己的命名空间。默认情况下，.ns文件大小固定16MB，大约可以存储24000个命名空间。也就是说数据库中的索引和集合的总数不能超过24000。\n   - 集合与索引文件：从0开始的整数结尾。garden.0和garden.1。两个文件大小分别为64MB和128MB。之所以初始化这么大空间，是因为能让数据尽可能的连续存储，查询和更新数据时效率会高。向数据库添加数据时，MongoDB会继续分配更多的数据文件，而且每个文件都是上一个文件的两倍大，也就是garden.2会是256MB，直到预分配文件大小的上线2GB。\n\n### 集合的细节\n\n1. 管理集合\n\n   可以像创建数据库一样，通过插入数据来隐式地创建集合，但是由于存在多种集合，所以MongoDB还提供了创建集合的命令。\n\n   ```javascript\n   db.createCollection(\"users\"， {size: 2000})\n   ```\n\n   集合名是用它的命名空间名称来标志的，其中包含了它所属的数据库的名称，比如garden.users，这个完全限定集合名不能超过128个字符。\n\n2. 固定集合（capped collection）\n\n   固定集合原本是针对高性能日志场景设计的。他们与标准集合的区别在于其大小是固定的。一旦固定集合到达容量上限，后续的插入会覆盖集合中最先插入的文档。在只有最近的数据才有价值的情况下，这种设计避免了用户手工清理集合的烦恼。固定集合默认不为`_id`创建索引，这是为了优化性能，没有索引，插入会更快，如果需要`_id`索引，可以手动创建。在不定义索引的情况下，最好把固定集合当作用于顺序处理的数据结构，而非随机查询的数据结构。如果需要逆序输出，必须使用`$natural`排序操作符：\n\n   ```javascript\n   db.user.actions.find().sort({\"$natural\": -1})\n   ```\n\n   此外，固定集合还显示了CRUD操作，不能从固定集合中删除文档，也不能执行任何会增加文档大小的更新操作。\n\n3. 系统集合\n\n   类似mysql、oracle的系统表，system.namespace和system.indexes就属于这些特殊系统集合，它俩都是标准集合，但是MongoDB使用固定集合来做复制，每个副本集的成员都会把所有的写操作记录到一个特殊的oplog.rs固定集合里。从节点顺序读取这个集合的内容，再把这些新操作应用到自己的数据库里。\n\n### 文档的细节\n\n1. 为了可以正确序列化为BSON，键名必须是合法的：合法的键名由null结尾的字符串组成，最大长度为255字节，字符传可以包含任意ASCII字符的组合，但是不能以`$`开头，不能包含`.`,除了结尾处外不能包含`null`字节。可以用符号充当散列的键，因为他们在序列化时会被转换为等效的字符串。\n\n2. RDBMS的列名属于元数据，和数据时分开存储的，而MongoDB的BSON不同，每个文档都会保存每个键名，所以尽量设置短小的键名。\n\n3. BSON规定了三种数字类型：double、int和long。在动态语言里序列化整数时，驱动会自己决定时将其序列化为int还是long。实际上，只有一种常见情况需要显示地决定数字类型，那就是通过JavaScript Shell插入数字数据时。JavaScript天生就只支持一种数字类型--Number，它等价于IEEE的双精度浮点数。因此，如果希望在Shell里将一个数字保存为整数，需要使用NumberLong()或NumberInt()显示指出。\n\n   ```javascript\n   db.numbers.save({n: 5}); // double\n   db.numbers.save({n: NumberLong(5)}); // long\n   ```\n\n   查询所有n为5的文档，会将上面两个文档一起返回。\n\n   使用`$type`操作符来查询BSON类型，每种BSON类型都由1开始的整数来标识。双精度浮点数类型是1，64位整数类型是18。\n\n   ```javascript\n   db.numbers.find({n: {$type: 1}}); // 只能查到上面第一条文档\n   db.numbers.find({n: {$type: 18}}); // 只能查到上面第二条文档\n   ```\n\n4. 自定义类型\n\n   可以根据几个不同的原生BSON值，创建自己的虚拟类型。\n\n5. 文档大小限制\n\n   MonggoDB v2.0中BSON文档的大小被限制在16MB，两个原因：\n\n   1. 防止开发者创建难看的数据模型。\n   2. 性能相关。在服务器端查询大文档，将结果发送到客户端之前需要将文档复制到缓冲区，这个复制动作代价可能很大，尤其在客户端并不需要整个文档时。而且还要反序列化。。。\n\n6. 批量插入\n\n   实现构造多个文档的数组，随后将整个文档数组传递给insert方法。与单独返回一个对象ID有所不同，批量插入会返回所有插入文档的对象ID数组。批量插入理想的数量范围为10~200（具体情况还要看基准测试结果）。数据库单方面唯一的限制是单次插入操作不能超过16MB上限。\n\n","source":"_posts/2021-07-15-kongzheng1993-MongoDB.md","raw":"---\ntitle: MongoDB笔记\nexcerpt: 'MongoDB'\ntags: [MongoDB]\ncategories: [MongoDB]\ncomments: true\ndate: 2021-07-15 116:30:10\n---\n\n## 1. 主要特性\n\n1. mongoDB的数据模型是面向文档的\n\n2. 不像关系型数据库，每张表都有严格定义的Schema，规定了列和类型。mongoDB没有Schema，特别适合项目初期使用（表设计经常变化）。\n\n3. 支持即时查询。\n\n4. 二级索引。MongoDB中的二级索引也是用B树实现的。每个集合最多可以创建64个索引。它支持能在RDBMS中找到的各种索引，升序、降序、唯一性、复合键索引，甚至地理空间索引都支持。因为mongoDB和关系型数据库使用相同的索引数据结构。\n\n5. 复制。mongoDB通过副本集（replica set）的拓扑结构提供了复制功能。副本集将数据分布在多台机器上以实现冗余，在服务器和网络故障时能提供自动故障转移。并且复制功能还能扩展数据库的读能力，如果有一个读密集型的应用，可以把数据库读操作分散到副本集集群中的各台机器上。**副本集由一个主节点和一个或多个从节点构成。**与我们熟悉的其他数据库的主从复制类似。副本集的主节点既能接受读操作又能接受写操作，但是从节点是只读的。**副本集与众不同的是它支持自动故障转移：如果主节点出现问题，集群会选择一个从节点自动将它提升为主节点。在先前的主节点恢复后会变成一个从节点**。\n\n<img src = \"image-20210715174420382.png\"/>\n\n6. 速度和持久性。用户可以选择写入语义，决定是否开启Journaling日志，通过这种方式来控制速度和持久性的平衡。默认所有的写操作都是`fire-and-forget`（射后不理）的，也就是通过TCP套接字发送，不要求数据库应答。如果用户需要获得应答，可以使用特殊的安全模式发起写操作，所有驱动都提供这个安全模式。该模式强制数据库做出应答，确保数据库正确无误地接收到了写操作。安全模式是可配置的，还可用于阻塞操作，直到写操作被复制到特定数量的服务器。对于高容量、低价值的数据（例如点击流和日志）,`fire-and-forget`风格的写操作是很理想的。对于重要的数据，则更倾向于安全模式。**在MongoDB 2.0中，Journaling日志是默认开启的。**有了这个功能，所有写操作都会被提交到一个只能追加的日志里。即使服务器非正常关闭（比如电源故障）,该日志也能保证重启服务器后MongoDB的数据文件被恢复到一致的状态。这是运行MongoDB最安全的方式。Journaling日志类似MySQL的InnoDB的事务日志，先写日志，再写内存，而后日志会同步到磁盘。先写日志，而不是直接去写主数据文件，是因为**顺序IO要比随机IO快的多**\n7. 数据库扩展。**提升单一节点的硬件来进行扩展成为垂直扩展或者向上扩展**。垂直扩展的优势在于简单可靠，但是终有一天更强的服务器成本会让人望而却步。这时就应该考虑水平扩展或向外扩展了。**水平扩展不是提升单一节点的性能，而是将数据库分布到多台机器上**。MongoDB的水平扩展非常易于管理，通过基于范围的分区机制即**自动分片**来实现这一设计目标，自动分片机制会自动管理各个节点之间的数据分布。分片系统会处理分片节点的增加，帮助进行自动故障转移。单独的分片由一个副本集组成，其中包含至少两个节点，保证能够自动恢复，没有单点失败。\n\n## MongoDB核心服务器\n\nMongoDB是用C++编写的，由10gen积极维护。开源的。\n\n1. 通过可执行文件mongod（windows上是mongodb.exe）可以运行核心服务器。mongod服务器进程使用一个自定义的二进制协议从网络套接字上接收命令，mongod进程的所有数据文件默认存储在`/data/db`里\n2. mongod有多种运行模式，最常见的是作为副本集中的一员，因为推荐使用复制，通常副本集由两个副本组成，再加上一个部署在第三台服务器上的**仲裁进程**。\n3. 对于MongoDB的自动分片架构而言，其组件包含配置为预先分片的副本集的mongod进程，以及特殊的元数据服务器，称为配置服务器（config server）。另外还有单独的名为mongos的路由服务器向适当的分片发送请求。\n4. mongodb除了指定标准端口和数据目录，没有什么调优数据库的选项。但是这并不是缺陷，而是一个系统设计亮点，因为MongoDB的设计哲学指出，内存管理最好是由操作系统而非DBA或者应用程序开发者来处理，如此一来，数据文件通过mmap()系统调用被映射成了系统的虚拟内存，这一举措行之有效的将内存管理交给了操作系统内核。\n\n## MongoDB工具\n\n1. JavaScript Shell： MongoDB命令行shell是一个基于JavaScript的工具，用户管理数据库和操作数据。可执行文件mongo会加载shell并连接到指定的mongod进程。MongoDB Shell的功能和Mysql Shell差不多，但并不是使用SQL，大多数命令使用的是Javascript表达式。比如`db.users.insert({name: \"Tom\"})`。\n2. 数据库驱动。\n3. 命令行工具：\n   1. mongodump和mongorestore：备份和恢复数据库的工具\n   2. mongoexport和mongoimport：用来导入导出JSON、CSV和TSV数据\n   3. mongosniff：一个网络嗅探工具，用来观察发送到数据库的操作。基本就是把网络上传输的BSON转换为易于人们阅读的Shell语句。\n   4. mongostat：持续轮询MongoDB和系统以便提供有磅数的统计信息，包括每秒操作数、分配的虚拟内存数量以及服务器的连接数。\n\n## 2. MongoDB JavaScript Shell\n\n### 1. 通过shell增删改查\n\n### 2. 索引\n\n1. 创建一个大集合，因为mongoDB Shell是javaScript解释器，所以可以像下面一样使用js\n\n   ```javascript\n   for(i=0; i<200000; i++) {\n       db.numbers.save({num: i});\n   }\n   ```\n\n2. explain\n\n   ```javascript\n   db.numbers.find({num: {\"$gt\": 199995}}).explain()\n   ```\n\n   \n\n3. 创建索引\n\n   ```javascript\n   // 创建索引\n   db.numbers.ensureIndex({num: 1})\n   // 查看索引\n   db.numbers.getIndexes()\n   ```\n\n   \n\n### 3. 基本管理\n\n1. 获取数据库信息\n\n   ```javascript\n   // 显示系统上所有的数据库\n   show dbs\n   // 显示定义在当前数据库里的所有集合\n   show collections\n   // 获取数据库与集合更底层的统计数据\n   db.stats()\n   // 获取集合的统计数据\n   db.numbers.stats()\n   ```\n\n   \n\n2. 命令工作原理\n\nMongoDB Shell会输出所有方法的实现，只要这些方法忽略括号就可以了。比如查看db.runCommand()的方法实现，输入db.runCommand就可以查看。\n\nrunCommand函数中的最后一行就是查询“$cmd”集合。\n\n- 数据库命令是对特殊集合$cmd的查询。\n\n- 查询选择器就是对命令本身的定义。\n\n3. 获得帮助\n   1. 通过tab不全命令\n   2. 通过上面说的执行不带括号的方法名，查看方法实现\n\n## 3. 使用MongoDB\n\n### 1. 驱动是如何工作的\n\nMongoDB驱动都有三个主要功能：\n\n1. 生成MongoDB对象ID，这是存储在所有文档_id字段里的默认值\n2. 驱动会把所有语言特定的文档描述和BSON互相转换，BSON是MongoDB使用的二进制数据格式\n3. 使用MongoDB的网络协议通过TCP套接字与数据库通信\n\n对象ID：对象ID不会重复，由12个字节构成，前四个字节是时间戳，接下来3个字节存储了机器ID，随后2个字节记录的进程ID，最后3个字节存储了进程局部的计数器，每次生成对象计数器都会加1。通过id可以获取创建的时间戳，精度是最接近的一秒钟。\n\nBSON：是MongoDB中用来表示文档的二进制格式，即使存储格式，也是命令格式。BSON规范包含了19种数据格式，包含UTF-8字符串、32位和64位整数、双精度浮点数、布尔值、时间戳和UTC日期时间（datetime）。其他一部分类型是MongoDB特定的。比如对象ID就有自己的格式，还有模糊大字段的二进制类型等。\n\n### 2. 数据的细节\n\n1. 管理数据库\n\n   MongoDB没有显示创建数据库的方法，而是在向集合写入数据的时候会自动创建，可以通过下面的方法删除数据库，但是这个操作一定要小心，因为这个操作是无法撤回的。\n\n   ```javascript\n   use garden\n   db.dropDatabase();\n   ```\n\n2. 数据文件与空间分配\n\n   创建数据库时，MongoDB会在磁盘上分配一组数据文件，把所有集合、索引和数据库的其他元数据保存在这些文件里。数据文件都被放置在启动mongod时指定的dbpath里。在未指定dbpath时，mongod会把文件全保存在data/db里：\n\n   - .ns文件：namespaces，命名空间。每个集合和索引都有自己的命名空间。默认情况下，.ns文件大小固定16MB，大约可以存储24000个命名空间。也就是说数据库中的索引和集合的总数不能超过24000。\n   - 集合与索引文件：从0开始的整数结尾。garden.0和garden.1。两个文件大小分别为64MB和128MB。之所以初始化这么大空间，是因为能让数据尽可能的连续存储，查询和更新数据时效率会高。向数据库添加数据时，MongoDB会继续分配更多的数据文件，而且每个文件都是上一个文件的两倍大，也就是garden.2会是256MB，直到预分配文件大小的上线2GB。\n\n### 集合的细节\n\n1. 管理集合\n\n   可以像创建数据库一样，通过插入数据来隐式地创建集合，但是由于存在多种集合，所以MongoDB还提供了创建集合的命令。\n\n   ```javascript\n   db.createCollection(\"users\"， {size: 2000})\n   ```\n\n   集合名是用它的命名空间名称来标志的，其中包含了它所属的数据库的名称，比如garden.users，这个完全限定集合名不能超过128个字符。\n\n2. 固定集合（capped collection）\n\n   固定集合原本是针对高性能日志场景设计的。他们与标准集合的区别在于其大小是固定的。一旦固定集合到达容量上限，后续的插入会覆盖集合中最先插入的文档。在只有最近的数据才有价值的情况下，这种设计避免了用户手工清理集合的烦恼。固定集合默认不为`_id`创建索引，这是为了优化性能，没有索引，插入会更快，如果需要`_id`索引，可以手动创建。在不定义索引的情况下，最好把固定集合当作用于顺序处理的数据结构，而非随机查询的数据结构。如果需要逆序输出，必须使用`$natural`排序操作符：\n\n   ```javascript\n   db.user.actions.find().sort({\"$natural\": -1})\n   ```\n\n   此外，固定集合还显示了CRUD操作，不能从固定集合中删除文档，也不能执行任何会增加文档大小的更新操作。\n\n3. 系统集合\n\n   类似mysql、oracle的系统表，system.namespace和system.indexes就属于这些特殊系统集合，它俩都是标准集合，但是MongoDB使用固定集合来做复制，每个副本集的成员都会把所有的写操作记录到一个特殊的oplog.rs固定集合里。从节点顺序读取这个集合的内容，再把这些新操作应用到自己的数据库里。\n\n### 文档的细节\n\n1. 为了可以正确序列化为BSON，键名必须是合法的：合法的键名由null结尾的字符串组成，最大长度为255字节，字符传可以包含任意ASCII字符的组合，但是不能以`$`开头，不能包含`.`,除了结尾处外不能包含`null`字节。可以用符号充当散列的键，因为他们在序列化时会被转换为等效的字符串。\n\n2. RDBMS的列名属于元数据，和数据时分开存储的，而MongoDB的BSON不同，每个文档都会保存每个键名，所以尽量设置短小的键名。\n\n3. BSON规定了三种数字类型：double、int和long。在动态语言里序列化整数时，驱动会自己决定时将其序列化为int还是long。实际上，只有一种常见情况需要显示地决定数字类型，那就是通过JavaScript Shell插入数字数据时。JavaScript天生就只支持一种数字类型--Number，它等价于IEEE的双精度浮点数。因此，如果希望在Shell里将一个数字保存为整数，需要使用NumberLong()或NumberInt()显示指出。\n\n   ```javascript\n   db.numbers.save({n: 5}); // double\n   db.numbers.save({n: NumberLong(5)}); // long\n   ```\n\n   查询所有n为5的文档，会将上面两个文档一起返回。\n\n   使用`$type`操作符来查询BSON类型，每种BSON类型都由1开始的整数来标识。双精度浮点数类型是1，64位整数类型是18。\n\n   ```javascript\n   db.numbers.find({n: {$type: 1}}); // 只能查到上面第一条文档\n   db.numbers.find({n: {$type: 18}}); // 只能查到上面第二条文档\n   ```\n\n4. 自定义类型\n\n   可以根据几个不同的原生BSON值，创建自己的虚拟类型。\n\n5. 文档大小限制\n\n   MonggoDB v2.0中BSON文档的大小被限制在16MB，两个原因：\n\n   1. 防止开发者创建难看的数据模型。\n   2. 性能相关。在服务器端查询大文档，将结果发送到客户端之前需要将文档复制到缓冲区，这个复制动作代价可能很大，尤其在客户端并不需要整个文档时。而且还要反序列化。。。\n\n6. 批量插入\n\n   实现构造多个文档的数组，随后将整个文档数组传递给insert方法。与单独返回一个对象ID有所不同，批量插入会返回所有插入文档的对象ID数组。批量插入理想的数量范围为10~200（具体情况还要看基准测试结果）。数据库单方面唯一的限制是单次插入操作不能超过16MB上限。\n\n","slug":"kongzheng1993-MongoDB","published":1,"updated":"2023-03-08T07:05:58.814Z","layout":"post","photos":[],"link":"","_id":"clg0k2ar100i8t26fs8efff96","content":"<h2 id=\"1-主要特性\"><a href=\"#1-主要特性\" class=\"headerlink\" title=\"1. 主要特性\"></a>1. 主要特性</h2><ol>\n<li><p>mongoDB的数据模型是面向文档的</p>\n</li>\n<li><p>不像关系型数据库，每张表都有严格定义的Schema，规定了列和类型。mongoDB没有Schema，特别适合项目初期使用（表设计经常变化）。</p>\n</li>\n<li><p>支持即时查询。</p>\n</li>\n<li><p>二级索引。MongoDB中的二级索引也是用B树实现的。每个集合最多可以创建64个索引。它支持能在RDBMS中找到的各种索引，升序、降序、唯一性、复合键索引，甚至地理空间索引都支持。因为mongoDB和关系型数据库使用相同的索引数据结构。</p>\n</li>\n<li><p>复制。mongoDB通过副本集（replica set）的拓扑结构提供了复制功能。副本集将数据分布在多台机器上以实现冗余，在服务器和网络故障时能提供自动故障转移。并且复制功能还能扩展数据库的读能力，如果有一个读密集型的应用，可以把数据库读操作分散到副本集集群中的各台机器上。<strong>副本集由一个主节点和一个或多个从节点构成。</strong>与我们熟悉的其他数据库的主从复制类似。副本集的主节点既能接受读操作又能接受写操作，但是从节点是只读的。<strong>副本集与众不同的是它支持自动故障转移：如果主节点出现问题，集群会选择一个从节点自动将它提升为主节点。在先前的主节点恢复后会变成一个从节点</strong>。</p>\n</li>\n</ol>\n<img src=\"/2023/03/08/kongzheng1993-MongoDB/image-20210715174420382.png\">\n\n<ol start=\"6\">\n<li>速度和持久性。用户可以选择写入语义，决定是否开启Journaling日志，通过这种方式来控制速度和持久性的平衡。默认所有的写操作都是<code>fire-and-forget</code>（射后不理）的，也就是通过TCP套接字发送，不要求数据库应答。如果用户需要获得应答，可以使用特殊的安全模式发起写操作，所有驱动都提供这个安全模式。该模式强制数据库做出应答，确保数据库正确无误地接收到了写操作。安全模式是可配置的，还可用于阻塞操作，直到写操作被复制到特定数量的服务器。对于高容量、低价值的数据（例如点击流和日志）,<code>fire-and-forget</code>风格的写操作是很理想的。对于重要的数据，则更倾向于安全模式。<strong>在MongoDB 2.0中，Journaling日志是默认开启的。</strong>有了这个功能，所有写操作都会被提交到一个只能追加的日志里。即使服务器非正常关闭（比如电源故障）,该日志也能保证重启服务器后MongoDB的数据文件被恢复到一致的状态。这是运行MongoDB最安全的方式。Journaling日志类似MySQL的InnoDB的事务日志，先写日志，再写内存，而后日志会同步到磁盘。先写日志，而不是直接去写主数据文件，是因为<strong>顺序IO要比随机IO快的多</strong></li>\n<li>数据库扩展。<strong>提升单一节点的硬件来进行扩展成为垂直扩展或者向上扩展</strong>。垂直扩展的优势在于简单可靠，但是终有一天更强的服务器成本会让人望而却步。这时就应该考虑水平扩展或向外扩展了。<strong>水平扩展不是提升单一节点的性能，而是将数据库分布到多台机器上</strong>。MongoDB的水平扩展非常易于管理，通过基于范围的分区机制即<strong>自动分片</strong>来实现这一设计目标，自动分片机制会自动管理各个节点之间的数据分布。分片系统会处理分片节点的增加，帮助进行自动故障转移。单独的分片由一个副本集组成，其中包含至少两个节点，保证能够自动恢复，没有单点失败。</li>\n</ol>\n<h2 id=\"MongoDB核心服务器\"><a href=\"#MongoDB核心服务器\" class=\"headerlink\" title=\"MongoDB核心服务器\"></a>MongoDB核心服务器</h2><p>MongoDB是用C++编写的，由10gen积极维护。开源的。</p>\n<ol>\n<li>通过可执行文件mongod（windows上是mongodb.exe）可以运行核心服务器。mongod服务器进程使用一个自定义的二进制协议从网络套接字上接收命令，mongod进程的所有数据文件默认存储在<code>/data/db</code>里</li>\n<li>mongod有多种运行模式，最常见的是作为副本集中的一员，因为推荐使用复制，通常副本集由两个副本组成，再加上一个部署在第三台服务器上的<strong>仲裁进程</strong>。</li>\n<li>对于MongoDB的自动分片架构而言，其组件包含配置为预先分片的副本集的mongod进程，以及特殊的元数据服务器，称为配置服务器（config server）。另外还有单独的名为mongos的路由服务器向适当的分片发送请求。</li>\n<li>mongodb除了指定标准端口和数据目录，没有什么调优数据库的选项。但是这并不是缺陷，而是一个系统设计亮点，因为MongoDB的设计哲学指出，内存管理最好是由操作系统而非DBA或者应用程序开发者来处理，如此一来，数据文件通过mmap()系统调用被映射成了系统的虚拟内存，这一举措行之有效的将内存管理交给了操作系统内核。</li>\n</ol>\n<h2 id=\"MongoDB工具\"><a href=\"#MongoDB工具\" class=\"headerlink\" title=\"MongoDB工具\"></a>MongoDB工具</h2><ol>\n<li>JavaScript Shell： MongoDB命令行shell是一个基于JavaScript的工具，用户管理数据库和操作数据。可执行文件mongo会加载shell并连接到指定的mongod进程。MongoDB Shell的功能和Mysql Shell差不多，但并不是使用SQL，大多数命令使用的是Javascript表达式。比如<code>db.users.insert({name: &quot;Tom&quot;})</code>。</li>\n<li>数据库驱动。</li>\n<li>命令行工具：<ol>\n<li>mongodump和mongorestore：备份和恢复数据库的工具</li>\n<li>mongoexport和mongoimport：用来导入导出JSON、CSV和TSV数据</li>\n<li>mongosniff：一个网络嗅探工具，用来观察发送到数据库的操作。基本就是把网络上传输的BSON转换为易于人们阅读的Shell语句。</li>\n<li>mongostat：持续轮询MongoDB和系统以便提供有磅数的统计信息，包括每秒操作数、分配的虚拟内存数量以及服务器的连接数。</li>\n</ol>\n</li>\n</ol>\n<h2 id=\"2-MongoDB-JavaScript-Shell\"><a href=\"#2-MongoDB-JavaScript-Shell\" class=\"headerlink\" title=\"2. MongoDB JavaScript Shell\"></a>2. MongoDB JavaScript Shell</h2><h3 id=\"1-通过shell增删改查\"><a href=\"#1-通过shell增删改查\" class=\"headerlink\" title=\"1. 通过shell增删改查\"></a>1. 通过shell增删改查</h3><h3 id=\"2-索引\"><a href=\"#2-索引\" class=\"headerlink\" title=\"2. 索引\"></a>2. 索引</h3><ol>\n<li><p>创建一个大集合，因为mongoDB Shell是javaScript解释器，所以可以像下面一样使用js</p>\n<pre><code class=\"javascript\">for(i=0; i&lt;200000; i++) {\n    db.numbers.save({num: i});\n}</code></pre>\n</li>\n<li><p>explain</p>\n<pre><code class=\"javascript\">db.numbers.find({num: {&quot;$gt&quot;: 199995}}).explain()</code></pre>\n</li>\n</ol>\n<ol start=\"3\">\n<li><p>创建索引</p>\n<pre><code class=\"javascript\">// 创建索引\ndb.numbers.ensureIndex({num: 1})\n// 查看索引\ndb.numbers.getIndexes()</code></pre>\n</li>\n</ol>\n<h3 id=\"3-基本管理\"><a href=\"#3-基本管理\" class=\"headerlink\" title=\"3. 基本管理\"></a>3. 基本管理</h3><ol>\n<li><p>获取数据库信息</p>\n<pre><code class=\"javascript\">// 显示系统上所有的数据库\nshow dbs\n// 显示定义在当前数据库里的所有集合\nshow collections\n// 获取数据库与集合更底层的统计数据\ndb.stats()\n// 获取集合的统计数据\ndb.numbers.stats()</code></pre>\n</li>\n</ol>\n<ol start=\"2\">\n<li>命令工作原理</li>\n</ol>\n<p>MongoDB Shell会输出所有方法的实现，只要这些方法忽略括号就可以了。比如查看db.runCommand()的方法实现，输入db.runCommand就可以查看。</p>\n<p>runCommand函数中的最后一行就是查询“$cmd”集合。</p>\n<ul>\n<li><p>数据库命令是对特殊集合$cmd的查询。</p>\n</li>\n<li><p>查询选择器就是对命令本身的定义。</p>\n</li>\n</ul>\n<ol start=\"3\">\n<li>获得帮助<ol>\n<li>通过tab不全命令</li>\n<li>通过上面说的执行不带括号的方法名，查看方法实现</li>\n</ol>\n</li>\n</ol>\n<h2 id=\"3-使用MongoDB\"><a href=\"#3-使用MongoDB\" class=\"headerlink\" title=\"3. 使用MongoDB\"></a>3. 使用MongoDB</h2><h3 id=\"1-驱动是如何工作的\"><a href=\"#1-驱动是如何工作的\" class=\"headerlink\" title=\"1. 驱动是如何工作的\"></a>1. 驱动是如何工作的</h3><p>MongoDB驱动都有三个主要功能：</p>\n<ol>\n<li>生成MongoDB对象ID，这是存储在所有文档_id字段里的默认值</li>\n<li>驱动会把所有语言特定的文档描述和BSON互相转换，BSON是MongoDB使用的二进制数据格式</li>\n<li>使用MongoDB的网络协议通过TCP套接字与数据库通信</li>\n</ol>\n<p>对象ID：对象ID不会重复，由12个字节构成，前四个字节是时间戳，接下来3个字节存储了机器ID，随后2个字节记录的进程ID，最后3个字节存储了进程局部的计数器，每次生成对象计数器都会加1。通过id可以获取创建的时间戳，精度是最接近的一秒钟。</p>\n<p>BSON：是MongoDB中用来表示文档的二进制格式，即使存储格式，也是命令格式。BSON规范包含了19种数据格式，包含UTF-8字符串、32位和64位整数、双精度浮点数、布尔值、时间戳和UTC日期时间（datetime）。其他一部分类型是MongoDB特定的。比如对象ID就有自己的格式，还有模糊大字段的二进制类型等。</p>\n<h3 id=\"2-数据的细节\"><a href=\"#2-数据的细节\" class=\"headerlink\" title=\"2. 数据的细节\"></a>2. 数据的细节</h3><ol>\n<li><p>管理数据库</p>\n<p>MongoDB没有显示创建数据库的方法，而是在向集合写入数据的时候会自动创建，可以通过下面的方法删除数据库，但是这个操作一定要小心，因为这个操作是无法撤回的。</p>\n<pre><code class=\"javascript\">use garden\ndb.dropDatabase();</code></pre>\n</li>\n<li><p>数据文件与空间分配</p>\n<p>创建数据库时，MongoDB会在磁盘上分配一组数据文件，把所有集合、索引和数据库的其他元数据保存在这些文件里。数据文件都被放置在启动mongod时指定的dbpath里。在未指定dbpath时，mongod会把文件全保存在data/db里：</p>\n<ul>\n<li>.ns文件：namespaces，命名空间。每个集合和索引都有自己的命名空间。默认情况下，.ns文件大小固定16MB，大约可以存储24000个命名空间。也就是说数据库中的索引和集合的总数不能超过24000。</li>\n<li>集合与索引文件：从0开始的整数结尾。garden.0和garden.1。两个文件大小分别为64MB和128MB。之所以初始化这么大空间，是因为能让数据尽可能的连续存储，查询和更新数据时效率会高。向数据库添加数据时，MongoDB会继续分配更多的数据文件，而且每个文件都是上一个文件的两倍大，也就是garden.2会是256MB，直到预分配文件大小的上线2GB。</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"集合的细节\"><a href=\"#集合的细节\" class=\"headerlink\" title=\"集合的细节\"></a>集合的细节</h3><ol>\n<li><p>管理集合</p>\n<p>可以像创建数据库一样，通过插入数据来隐式地创建集合，但是由于存在多种集合，所以MongoDB还提供了创建集合的命令。</p>\n<pre><code class=\"javascript\">db.createCollection(&quot;users&quot;， {size: 2000})</code></pre>\n<p>集合名是用它的命名空间名称来标志的，其中包含了它所属的数据库的名称，比如garden.users，这个完全限定集合名不能超过128个字符。</p>\n</li>\n<li><p>固定集合（capped collection）</p>\n<p>固定集合原本是针对高性能日志场景设计的。他们与标准集合的区别在于其大小是固定的。一旦固定集合到达容量上限，后续的插入会覆盖集合中最先插入的文档。在只有最近的数据才有价值的情况下，这种设计避免了用户手工清理集合的烦恼。固定集合默认不为<code>_id</code>创建索引，这是为了优化性能，没有索引，插入会更快，如果需要<code>_id</code>索引，可以手动创建。在不定义索引的情况下，最好把固定集合当作用于顺序处理的数据结构，而非随机查询的数据结构。如果需要逆序输出，必须使用<code>$natural</code>排序操作符：</p>\n<pre><code class=\"javascript\">db.user.actions.find().sort({&quot;$natural&quot;: -1})</code></pre>\n<p>此外，固定集合还显示了CRUD操作，不能从固定集合中删除文档，也不能执行任何会增加文档大小的更新操作。</p>\n</li>\n<li><p>系统集合</p>\n<p>类似mysql、oracle的系统表，system.namespace和system.indexes就属于这些特殊系统集合，它俩都是标准集合，但是MongoDB使用固定集合来做复制，每个副本集的成员都会把所有的写操作记录到一个特殊的oplog.rs固定集合里。从节点顺序读取这个集合的内容，再把这些新操作应用到自己的数据库里。</p>\n</li>\n</ol>\n<h3 id=\"文档的细节\"><a href=\"#文档的细节\" class=\"headerlink\" title=\"文档的细节\"></a>文档的细节</h3><ol>\n<li><p>为了可以正确序列化为BSON，键名必须是合法的：合法的键名由null结尾的字符串组成，最大长度为255字节，字符传可以包含任意ASCII字符的组合，但是不能以<code>$</code>开头，不能包含<code>.</code>,除了结尾处外不能包含<code>null</code>字节。可以用符号充当散列的键，因为他们在序列化时会被转换为等效的字符串。</p>\n</li>\n<li><p>RDBMS的列名属于元数据，和数据时分开存储的，而MongoDB的BSON不同，每个文档都会保存每个键名，所以尽量设置短小的键名。</p>\n</li>\n<li><p>BSON规定了三种数字类型：double、int和long。在动态语言里序列化整数时，驱动会自己决定时将其序列化为int还是long。实际上，只有一种常见情况需要显示地决定数字类型，那就是通过JavaScript Shell插入数字数据时。JavaScript天生就只支持一种数字类型–Number，它等价于IEEE的双精度浮点数。因此，如果希望在Shell里将一个数字保存为整数，需要使用NumberLong()或NumberInt()显示指出。</p>\n<pre><code class=\"javascript\">db.numbers.save({n: 5}); // double\ndb.numbers.save({n: NumberLong(5)}); // long</code></pre>\n<p>查询所有n为5的文档，会将上面两个文档一起返回。</p>\n<p>使用<code>$type</code>操作符来查询BSON类型，每种BSON类型都由1开始的整数来标识。双精度浮点数类型是1，64位整数类型是18。</p>\n<pre><code class=\"javascript\">db.numbers.find({n: {$type: 1}}); // 只能查到上面第一条文档\ndb.numbers.find({n: {$type: 18}}); // 只能查到上面第二条文档</code></pre>\n</li>\n<li><p>自定义类型</p>\n<p>可以根据几个不同的原生BSON值，创建自己的虚拟类型。</p>\n</li>\n<li><p>文档大小限制</p>\n<p>MonggoDB v2.0中BSON文档的大小被限制在16MB，两个原因：</p>\n<ol>\n<li>防止开发者创建难看的数据模型。</li>\n<li>性能相关。在服务器端查询大文档，将结果发送到客户端之前需要将文档复制到缓冲区，这个复制动作代价可能很大，尤其在客户端并不需要整个文档时。而且还要反序列化。。。</li>\n</ol>\n</li>\n<li><p>批量插入</p>\n<p>实现构造多个文档的数组，随后将整个文档数组传递给insert方法。与单独返回一个对象ID有所不同，批量插入会返回所有插入文档的对象ID数组。批量插入理想的数量范围为10~200（具体情况还要看基准测试结果）。数据库单方面唯一的限制是单次插入操作不能超过16MB上限。</p>\n</li>\n</ol>\n","site":{"data":{}},"more":"<h2 id=\"1-主要特性\"><a href=\"#1-主要特性\" class=\"headerlink\" title=\"1. 主要特性\"></a>1. 主要特性</h2><ol>\n<li><p>mongoDB的数据模型是面向文档的</p>\n</li>\n<li><p>不像关系型数据库，每张表都有严格定义的Schema，规定了列和类型。mongoDB没有Schema，特别适合项目初期使用（表设计经常变化）。</p>\n</li>\n<li><p>支持即时查询。</p>\n</li>\n<li><p>二级索引。MongoDB中的二级索引也是用B树实现的。每个集合最多可以创建64个索引。它支持能在RDBMS中找到的各种索引，升序、降序、唯一性、复合键索引，甚至地理空间索引都支持。因为mongoDB和关系型数据库使用相同的索引数据结构。</p>\n</li>\n<li><p>复制。mongoDB通过副本集（replica set）的拓扑结构提供了复制功能。副本集将数据分布在多台机器上以实现冗余，在服务器和网络故障时能提供自动故障转移。并且复制功能还能扩展数据库的读能力，如果有一个读密集型的应用，可以把数据库读操作分散到副本集集群中的各台机器上。<strong>副本集由一个主节点和一个或多个从节点构成。</strong>与我们熟悉的其他数据库的主从复制类似。副本集的主节点既能接受读操作又能接受写操作，但是从节点是只读的。<strong>副本集与众不同的是它支持自动故障转移：如果主节点出现问题，集群会选择一个从节点自动将它提升为主节点。在先前的主节点恢复后会变成一个从节点</strong>。</p>\n</li>\n</ol>\n<img src=\"/2023/03/08/kongzheng1993-MongoDB/image-20210715174420382.png\">\n\n<ol start=\"6\">\n<li>速度和持久性。用户可以选择写入语义，决定是否开启Journaling日志，通过这种方式来控制速度和持久性的平衡。默认所有的写操作都是<code>fire-and-forget</code>（射后不理）的，也就是通过TCP套接字发送，不要求数据库应答。如果用户需要获得应答，可以使用特殊的安全模式发起写操作，所有驱动都提供这个安全模式。该模式强制数据库做出应答，确保数据库正确无误地接收到了写操作。安全模式是可配置的，还可用于阻塞操作，直到写操作被复制到特定数量的服务器。对于高容量、低价值的数据（例如点击流和日志）,<code>fire-and-forget</code>风格的写操作是很理想的。对于重要的数据，则更倾向于安全模式。<strong>在MongoDB 2.0中，Journaling日志是默认开启的。</strong>有了这个功能，所有写操作都会被提交到一个只能追加的日志里。即使服务器非正常关闭（比如电源故障）,该日志也能保证重启服务器后MongoDB的数据文件被恢复到一致的状态。这是运行MongoDB最安全的方式。Journaling日志类似MySQL的InnoDB的事务日志，先写日志，再写内存，而后日志会同步到磁盘。先写日志，而不是直接去写主数据文件，是因为<strong>顺序IO要比随机IO快的多</strong></li>\n<li>数据库扩展。<strong>提升单一节点的硬件来进行扩展成为垂直扩展或者向上扩展</strong>。垂直扩展的优势在于简单可靠，但是终有一天更强的服务器成本会让人望而却步。这时就应该考虑水平扩展或向外扩展了。<strong>水平扩展不是提升单一节点的性能，而是将数据库分布到多台机器上</strong>。MongoDB的水平扩展非常易于管理，通过基于范围的分区机制即<strong>自动分片</strong>来实现这一设计目标，自动分片机制会自动管理各个节点之间的数据分布。分片系统会处理分片节点的增加，帮助进行自动故障转移。单独的分片由一个副本集组成，其中包含至少两个节点，保证能够自动恢复，没有单点失败。</li>\n</ol>\n<h2 id=\"MongoDB核心服务器\"><a href=\"#MongoDB核心服务器\" class=\"headerlink\" title=\"MongoDB核心服务器\"></a>MongoDB核心服务器</h2><p>MongoDB是用C++编写的，由10gen积极维护。开源的。</p>\n<ol>\n<li>通过可执行文件mongod（windows上是mongodb.exe）可以运行核心服务器。mongod服务器进程使用一个自定义的二进制协议从网络套接字上接收命令，mongod进程的所有数据文件默认存储在<code>/data/db</code>里</li>\n<li>mongod有多种运行模式，最常见的是作为副本集中的一员，因为推荐使用复制，通常副本集由两个副本组成，再加上一个部署在第三台服务器上的<strong>仲裁进程</strong>。</li>\n<li>对于MongoDB的自动分片架构而言，其组件包含配置为预先分片的副本集的mongod进程，以及特殊的元数据服务器，称为配置服务器（config server）。另外还有单独的名为mongos的路由服务器向适当的分片发送请求。</li>\n<li>mongodb除了指定标准端口和数据目录，没有什么调优数据库的选项。但是这并不是缺陷，而是一个系统设计亮点，因为MongoDB的设计哲学指出，内存管理最好是由操作系统而非DBA或者应用程序开发者来处理，如此一来，数据文件通过mmap()系统调用被映射成了系统的虚拟内存，这一举措行之有效的将内存管理交给了操作系统内核。</li>\n</ol>\n<h2 id=\"MongoDB工具\"><a href=\"#MongoDB工具\" class=\"headerlink\" title=\"MongoDB工具\"></a>MongoDB工具</h2><ol>\n<li>JavaScript Shell： MongoDB命令行shell是一个基于JavaScript的工具，用户管理数据库和操作数据。可执行文件mongo会加载shell并连接到指定的mongod进程。MongoDB Shell的功能和Mysql Shell差不多，但并不是使用SQL，大多数命令使用的是Javascript表达式。比如<code>db.users.insert({name: &quot;Tom&quot;})</code>。</li>\n<li>数据库驱动。</li>\n<li>命令行工具：<ol>\n<li>mongodump和mongorestore：备份和恢复数据库的工具</li>\n<li>mongoexport和mongoimport：用来导入导出JSON、CSV和TSV数据</li>\n<li>mongosniff：一个网络嗅探工具，用来观察发送到数据库的操作。基本就是把网络上传输的BSON转换为易于人们阅读的Shell语句。</li>\n<li>mongostat：持续轮询MongoDB和系统以便提供有磅数的统计信息，包括每秒操作数、分配的虚拟内存数量以及服务器的连接数。</li>\n</ol>\n</li>\n</ol>\n<h2 id=\"2-MongoDB-JavaScript-Shell\"><a href=\"#2-MongoDB-JavaScript-Shell\" class=\"headerlink\" title=\"2. MongoDB JavaScript Shell\"></a>2. MongoDB JavaScript Shell</h2><h3 id=\"1-通过shell增删改查\"><a href=\"#1-通过shell增删改查\" class=\"headerlink\" title=\"1. 通过shell增删改查\"></a>1. 通过shell增删改查</h3><h3 id=\"2-索引\"><a href=\"#2-索引\" class=\"headerlink\" title=\"2. 索引\"></a>2. 索引</h3><ol>\n<li><p>创建一个大集合，因为mongoDB Shell是javaScript解释器，所以可以像下面一样使用js</p>\n<pre><code class=\"javascript\">for(i=0; i&lt;200000; i++) {\n    db.numbers.save({num: i});\n}</code></pre>\n</li>\n<li><p>explain</p>\n<pre><code class=\"javascript\">db.numbers.find({num: {&quot;$gt&quot;: 199995}}).explain()</code></pre>\n</li>\n</ol>\n<ol start=\"3\">\n<li><p>创建索引</p>\n<pre><code class=\"javascript\">// 创建索引\ndb.numbers.ensureIndex({num: 1})\n// 查看索引\ndb.numbers.getIndexes()</code></pre>\n</li>\n</ol>\n<h3 id=\"3-基本管理\"><a href=\"#3-基本管理\" class=\"headerlink\" title=\"3. 基本管理\"></a>3. 基本管理</h3><ol>\n<li><p>获取数据库信息</p>\n<pre><code class=\"javascript\">// 显示系统上所有的数据库\nshow dbs\n// 显示定义在当前数据库里的所有集合\nshow collections\n// 获取数据库与集合更底层的统计数据\ndb.stats()\n// 获取集合的统计数据\ndb.numbers.stats()</code></pre>\n</li>\n</ol>\n<ol start=\"2\">\n<li>命令工作原理</li>\n</ol>\n<p>MongoDB Shell会输出所有方法的实现，只要这些方法忽略括号就可以了。比如查看db.runCommand()的方法实现，输入db.runCommand就可以查看。</p>\n<p>runCommand函数中的最后一行就是查询“$cmd”集合。</p>\n<ul>\n<li><p>数据库命令是对特殊集合$cmd的查询。</p>\n</li>\n<li><p>查询选择器就是对命令本身的定义。</p>\n</li>\n</ul>\n<ol start=\"3\">\n<li>获得帮助<ol>\n<li>通过tab不全命令</li>\n<li>通过上面说的执行不带括号的方法名，查看方法实现</li>\n</ol>\n</li>\n</ol>\n<h2 id=\"3-使用MongoDB\"><a href=\"#3-使用MongoDB\" class=\"headerlink\" title=\"3. 使用MongoDB\"></a>3. 使用MongoDB</h2><h3 id=\"1-驱动是如何工作的\"><a href=\"#1-驱动是如何工作的\" class=\"headerlink\" title=\"1. 驱动是如何工作的\"></a>1. 驱动是如何工作的</h3><p>MongoDB驱动都有三个主要功能：</p>\n<ol>\n<li>生成MongoDB对象ID，这是存储在所有文档_id字段里的默认值</li>\n<li>驱动会把所有语言特定的文档描述和BSON互相转换，BSON是MongoDB使用的二进制数据格式</li>\n<li>使用MongoDB的网络协议通过TCP套接字与数据库通信</li>\n</ol>\n<p>对象ID：对象ID不会重复，由12个字节构成，前四个字节是时间戳，接下来3个字节存储了机器ID，随后2个字节记录的进程ID，最后3个字节存储了进程局部的计数器，每次生成对象计数器都会加1。通过id可以获取创建的时间戳，精度是最接近的一秒钟。</p>\n<p>BSON：是MongoDB中用来表示文档的二进制格式，即使存储格式，也是命令格式。BSON规范包含了19种数据格式，包含UTF-8字符串、32位和64位整数、双精度浮点数、布尔值、时间戳和UTC日期时间（datetime）。其他一部分类型是MongoDB特定的。比如对象ID就有自己的格式，还有模糊大字段的二进制类型等。</p>\n<h3 id=\"2-数据的细节\"><a href=\"#2-数据的细节\" class=\"headerlink\" title=\"2. 数据的细节\"></a>2. 数据的细节</h3><ol>\n<li><p>管理数据库</p>\n<p>MongoDB没有显示创建数据库的方法，而是在向集合写入数据的时候会自动创建，可以通过下面的方法删除数据库，但是这个操作一定要小心，因为这个操作是无法撤回的。</p>\n<pre><code class=\"javascript\">use garden\ndb.dropDatabase();</code></pre>\n</li>\n<li><p>数据文件与空间分配</p>\n<p>创建数据库时，MongoDB会在磁盘上分配一组数据文件，把所有集合、索引和数据库的其他元数据保存在这些文件里。数据文件都被放置在启动mongod时指定的dbpath里。在未指定dbpath时，mongod会把文件全保存在data/db里：</p>\n<ul>\n<li>.ns文件：namespaces，命名空间。每个集合和索引都有自己的命名空间。默认情况下，.ns文件大小固定16MB，大约可以存储24000个命名空间。也就是说数据库中的索引和集合的总数不能超过24000。</li>\n<li>集合与索引文件：从0开始的整数结尾。garden.0和garden.1。两个文件大小分别为64MB和128MB。之所以初始化这么大空间，是因为能让数据尽可能的连续存储，查询和更新数据时效率会高。向数据库添加数据时，MongoDB会继续分配更多的数据文件，而且每个文件都是上一个文件的两倍大，也就是garden.2会是256MB，直到预分配文件大小的上线2GB。</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"集合的细节\"><a href=\"#集合的细节\" class=\"headerlink\" title=\"集合的细节\"></a>集合的细节</h3><ol>\n<li><p>管理集合</p>\n<p>可以像创建数据库一样，通过插入数据来隐式地创建集合，但是由于存在多种集合，所以MongoDB还提供了创建集合的命令。</p>\n<pre><code class=\"javascript\">db.createCollection(&quot;users&quot;， {size: 2000})</code></pre>\n<p>集合名是用它的命名空间名称来标志的，其中包含了它所属的数据库的名称，比如garden.users，这个完全限定集合名不能超过128个字符。</p>\n</li>\n<li><p>固定集合（capped collection）</p>\n<p>固定集合原本是针对高性能日志场景设计的。他们与标准集合的区别在于其大小是固定的。一旦固定集合到达容量上限，后续的插入会覆盖集合中最先插入的文档。在只有最近的数据才有价值的情况下，这种设计避免了用户手工清理集合的烦恼。固定集合默认不为<code>_id</code>创建索引，这是为了优化性能，没有索引，插入会更快，如果需要<code>_id</code>索引，可以手动创建。在不定义索引的情况下，最好把固定集合当作用于顺序处理的数据结构，而非随机查询的数据结构。如果需要逆序输出，必须使用<code>$natural</code>排序操作符：</p>\n<pre><code class=\"javascript\">db.user.actions.find().sort({&quot;$natural&quot;: -1})</code></pre>\n<p>此外，固定集合还显示了CRUD操作，不能从固定集合中删除文档，也不能执行任何会增加文档大小的更新操作。</p>\n</li>\n<li><p>系统集合</p>\n<p>类似mysql、oracle的系统表，system.namespace和system.indexes就属于这些特殊系统集合，它俩都是标准集合，但是MongoDB使用固定集合来做复制，每个副本集的成员都会把所有的写操作记录到一个特殊的oplog.rs固定集合里。从节点顺序读取这个集合的内容，再把这些新操作应用到自己的数据库里。</p>\n</li>\n</ol>\n<h3 id=\"文档的细节\"><a href=\"#文档的细节\" class=\"headerlink\" title=\"文档的细节\"></a>文档的细节</h3><ol>\n<li><p>为了可以正确序列化为BSON，键名必须是合法的：合法的键名由null结尾的字符串组成，最大长度为255字节，字符传可以包含任意ASCII字符的组合，但是不能以<code>$</code>开头，不能包含<code>.</code>,除了结尾处外不能包含<code>null</code>字节。可以用符号充当散列的键，因为他们在序列化时会被转换为等效的字符串。</p>\n</li>\n<li><p>RDBMS的列名属于元数据，和数据时分开存储的，而MongoDB的BSON不同，每个文档都会保存每个键名，所以尽量设置短小的键名。</p>\n</li>\n<li><p>BSON规定了三种数字类型：double、int和long。在动态语言里序列化整数时，驱动会自己决定时将其序列化为int还是long。实际上，只有一种常见情况需要显示地决定数字类型，那就是通过JavaScript Shell插入数字数据时。JavaScript天生就只支持一种数字类型–Number，它等价于IEEE的双精度浮点数。因此，如果希望在Shell里将一个数字保存为整数，需要使用NumberLong()或NumberInt()显示指出。</p>\n<pre><code class=\"javascript\">db.numbers.save({n: 5}); // double\ndb.numbers.save({n: NumberLong(5)}); // long</code></pre>\n<p>查询所有n为5的文档，会将上面两个文档一起返回。</p>\n<p>使用<code>$type</code>操作符来查询BSON类型，每种BSON类型都由1开始的整数来标识。双精度浮点数类型是1，64位整数类型是18。</p>\n<pre><code class=\"javascript\">db.numbers.find({n: {$type: 1}}); // 只能查到上面第一条文档\ndb.numbers.find({n: {$type: 18}}); // 只能查到上面第二条文档</code></pre>\n</li>\n<li><p>自定义类型</p>\n<p>可以根据几个不同的原生BSON值，创建自己的虚拟类型。</p>\n</li>\n<li><p>文档大小限制</p>\n<p>MonggoDB v2.0中BSON文档的大小被限制在16MB，两个原因：</p>\n<ol>\n<li>防止开发者创建难看的数据模型。</li>\n<li>性能相关。在服务器端查询大文档，将结果发送到客户端之前需要将文档复制到缓冲区，这个复制动作代价可能很大，尤其在客户端并不需要整个文档时。而且还要反序列化。。。</li>\n</ol>\n</li>\n<li><p>批量插入</p>\n<p>实现构造多个文档的数组，随后将整个文档数组传递给insert方法。与单独返回一个对象ID有所不同，批量插入会返回所有插入文档的对象ID数组。批量插入理想的数量范围为10~200（具体情况还要看基准测试结果）。数据库单方面唯一的限制是单次插入操作不能超过16MB上限。</p>\n</li>\n</ol>\n"},{"title":"JVM知识点总结","excerpt":"","comments":1,"date":"2022-03-05T10:30:52.000Z","_content":"\nClass文件、类加载子系统、运行时数据区、执行引擎、本地接口、本地方法栈\n\n## Class文件\n\nClass文件是一组以8字节为基础单位的二进制流。各个数据项目严格按照顺序紧凑地排列在Class文件之中，中间没有添加任何分隔符。根据Java虚拟机规范的规定，Class文件结构采用一种类似于C语言结构体的伪结构来存储数据，这种伪结构只有两种数据类型：无符号数（下面用u4表示4个字节的无符号数）和表。\n\n<img src=\"Class.png\"/>\n\n构成：\n\n1. 开头就是一个魔数（0xCAFEBABE 咖啡宝贝？），标识它是一个Class文件。（很多文件类型都有自己定义的魔术来表示自己的类型）。\n2. 接下来是次版本号和主版本号，标识JDK的版本，为了解决JDK兼容性的问题。比如高版本的java代码无法在低版本的jdk上运行。\n3. 下面是常量池计数器，记录后面常量池里面的常量的个数，常量池中有字面量和符号引用。字面量比较接近Java语言层面的常量概念，比如文本字符串、被声明为final的常量值等。符号引用则属于编译原理方面的概念，主要包括：\n    - 被模块到处或者开放的包（Package）\n    - 类和接口的全限定名\n    - 字段的名称和描述符\n    - 方法的名称和描述符\n    - 方法句柄和方法类型\n    - 动态调用点和动态变量\n注： 常量池计数器是从1开始的，因为0的位置要留给没有父类的（Object类）、没有类名的（匿名内部类），索引要指向常量池第0个位置，也就是说0是留给无法指向的东西的。\n\n4. 下面是访问标识，占用2个字节，用于识别一些类或者接口层次的访问信息，包括：这个Class是类还是接口；是否定义为public类型；是否定义为abstract类型；如果是类，是否声明为final；等等。一共有16个标志位可以使用，当前只定义了其中9个（ACC_PUBLIC、ACC_FINAL、ACC_SUPER、ACC_INTERFACE、ACC_ABSTRACT、ACC_SYNTHETIC、ACC_ANNOTATION、ACC_ENUM、ACC_MODULE），没有使用到的一律为0。\n5. 类索引、父类索引与接口索引集合。由这三项确定该类型的继承关系。类索引用于确定这个类的全限定名，父类索引用于确定这个类的父类的全限定名，java不允许多重继承，所以父类索引只有一个。除了Object外所有Java类都有父类，因此除了Object外所有Java类的父类索引都不为0。接口索引集合用来描述这个Class实现了那些接口，按照implements从左要右的顺序排列在接口索引集合中。类索引和父类索引各自指向一个类型为CONSTANT_Class_info的类描述符常量，通过CONTANT_Class_info类型的常量中的索引值可以找到定义在CONSTANT_Utf8_info类型的常量中的全限定名字符串。由于接口索引是一个集合，所以入口的第一项u2类型的数据为接口计数器（interface_count），表示索引表的容量，如果没有实现任何接口，则该计数器值为0，后面接口的索引表不在占用任何字节。\n6. 字段表集合，用于描述接口或者类中声明的变量。Java语言中的字段包括类级变量以及实例级变量，但不包括在方法内部声明的变局部变量。字段表包括：access_flags、name—_index、descriptor_index、attributes_count、attributes。字段修饰符放在access_flags项目中，与类中的access_flags项目非常类似。根据语法规则，ACC_PUBLIC、ACC_PRIVATE、ACC_PROTECTED只能三选一，ACC_FINAL和ACC_VOLATILE不能同时选择。接口之中的字段必须有ACC_PUBLIC、ACC_STATIC、ACC_FINAL标识。access_flags后面是两个索引值：name_index和descriptor_index，他们都是对常量池项的引用，分别代表着字段的简单名称以及字段和方法的描述符。descriptor_index之后会跟随一个属性表集合，用于存储一些额外信息。\n7. 方法表集合，和字段表类似，volatile和transient关键字不能修饰方法，所以方法表没有对应的访问标志；但是synchronized、native、strictfp（strict float point，精确浮点，可用于类、接口或者方法。）、abstract关键字可以修饰方法，所以增加了对应的访问标志。而我们编写在方法内的代码，在编译成字节码指令之后，就被保存在自己属性表的一个名为“Code”的属性里面，操作数栈的最大深度、局部变量表所需要的最大空间、整段代码的长度都会被保存到Code属性中，后面代码的执行都会用到。\n8. 属性表，Class文件、字段表、方法表都可以携带自己的属性表集合，以描述某些场景专有的信息。属性表的数据项目不像其他部分要求严格的顺序、长度和内容，只要不与已有属性名重复即可。\n\n## 类加载子系统\n\n### JVM类加载的流程  \n\n加载、链接（验证、准备、解析）、初始化，根据时间顺序其实是下面的过程：\n\n   1. 加载：静态加载，java文件编译为class文件，二进制字节流加载。第一次加载的获得的是一个二进制字节流\n   2. 验证：验证文件类型，魔术+主次版本号\n   3. 加载：通过文件类型验证后，将字节流所代表的静态存储结构转化为方法区的运行时数据结构。class文件的常量池和运行时数据区中的常量池有什么区别和联系？\n   4. 加载：在Java堆内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的访问入口\n   5. 验证：元数据验证\n   6. 验证：字节码验证\n   7. 准备：正式为类定义的变量（即静态变量，被static修饰的变量）分配内存并设置类变量初始值（零值）的阶段。\n   8. 初始化：最后一个步骤，开始执行类中编写的Java程序代码，执行类构造器`<clinit>()`方法的过程，这个构造器并不是程序员编写的那个，而是编译器在编译过程中收集的所有初始化代码（包括类变量的赋值动作和静态语句块中的语句，顺序是和源文件中的顺序一致），会先执行父类的`<clinit>()`，JVM为了保证一个类的`<clinit>()`方法在多线程的环境中正确执行会加锁同步，如果多个线程同时去初始化一个类，那么只会有一个线程去执行，其他线程都会阻塞，知道活动线程执行完毕。\n注：解析是Java虚拟机将常量池内的符号引用替换为直接引用的过程，这个动作可能是随着类加载一直在做的，但是解析一定会在初始化之前完成。\n\n`public static String a = 123;`在准备节点a为0，在初始化节点会被赋值为123。\n\n### 类加载器 && 双亲委派模型\n\n#### 类加载器\n\n类加载阶段中的“通过一个类的全限定名来获取描述该类的二进制字节流”这个而动作被放到JVM外部去实现，以便让应用程序自己决定如何去加载所需要的类，实现这个动作的代码被称为`类加载器`。\n\n类加载器的作用并不只是加载类，还作用域确立一个类在JVM中的唯一性。\n\n站在JVM的角度来看，只存在两种不同的类加载器：一种是启动类加载器（Bootstrap ClassLoader），这个类加载器由C++实现，是虚拟机自身的一部分；另一种就是其他所有的类加载器，这些类加载器都是由Java实现，独立存在于虚拟机之外，全部继承自抽象类java.lang.ClassLoader。\n\n三个系统提供的类加载器：\n\n- 启动类加载器（Bootstrap Class Loader），负责加载存放在`<JAVA_HOME>/lib`目录，或者被`-Xbootclasspath`参数所指定的路径中存放的，而且是JVM能够识别的类库。启动类加载器无法被Java程序直接引用，用户在编写自定义类加载器时，如果需要把加载请求委派给引导类加载器（也就是启动类加载器，意译过来的bootstrap）去处理，拿直接使用null代替即可。\n- 扩展类加载器（Extension Class Loader），是在sun.misc.Launcher$ExtClassLoader中以Java代码的形式实现的。它负责加载`<JAVA_HOME>/lib/ext`目录中，或者被java.ext.dirs系统变量所指定的路径中的类库。开发者可以直接在程序中使用扩展类加载器来加载Class文件\n- 应用程序类加载器（Application Class Loader），由sun.misc.Launcher$Launcher$AppClassLoader来实现，由于应用程序加载器时ClassLoader类中的getSystemClassLoader()方法的返回值，所有有些场合也称它为系统类加载器。负责加载用户类路径（ClassPath）上的所有类库，开发者可以直接在代码中使用这个类加载器。如果应用程序中没有自定义过自己的类加载器，一般情况下这个就是默认类加载器。\n\nJDK9之前的Java应用都是由这三种类加载器互相配合来完成加载的。如果有必要，用户还可以加入自定义的类加载器来进行拓展。典型的如增加磁盘位置之外的Class文件来源，或者通过类加载器实现类的隔离、重载等功能。\n\n#### 双亲委派：向上委托和向下委派\n\n过程：如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委托给父类加载器去完成，每一个层次的类加载器都是如此，因此所有的加载请求最终都应该传送到最顶层的启动类加载器中，只有当父加载器反馈自己无法完成这个加载请求（它的搜索范围中没有找到所需的类）时，子加载器才会尝试自己去完成加载。\n\n好处：Java中的类随着它的类加载器一起具备了一种带有优先级的层次关系。比如rt.jar不论哪一个类加载器要加载这个类，最终都是委派给了处于模型最顶端的启动类加载器进行加载。因此一个类在程序的各种加载器环境中都能够保证是同一个类。如果没有双亲委派模型，如果用户自己编写了一个jdk中同名的类，比如java.lang.Object类，并放在程序的ClassPath中，那么系统中就会出现多个不同的Object类，程序将会变得混乱不堪。\n\n代码逻辑：先检查请求加载的类型是否已经被加载过，如果没有则调用父加载器的loadClass()方法，如果父加载器为空则默认使用启动类加载器作为父加载器，如果父类加载器加载失败，抛出ClassNotFoundException异常的话，才调用自己的findClass()方法尝试进行加载。\n\nJVM加载数组：数组不是通过类加载器加载的，JVM直接就在内存中构造出来的一个内存区域，但是数据类型（比如Student这个Class）是由类加载器加载的。Student这个类是由系统类加载器加载的，那么这个数组就会被标识在系统类加载器的命名空间上；如果数据是基础数据类型（比如int）的，那么这个数组就会被标记到启动类加载器的命名空间上。\n\n## 运行时数据区\n\n线程共享：方法区、堆\n线程私有：虚拟机栈、本地方法栈、程序计数器\n\n- 程序计数器：当前线程所执行的字节码的行号指示器，如果正在执行的是一个Java方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址。如果正在执行的是本地方法，这个计数器的值为空。是唯一一个JVM规范没有规定任何OOM情况的区域。\n- 方法区：存储已经被虚拟机加载的类型信息、常量、静态变量、即时编译器编译后的代码缓存等数据。如果方法区无法满足新的内存分配需求时，将抛出OOM。方法区时JVM规范的一个概念定义，并不是一个具体实现。在JDK8以后使用直接内存元空间来实现方法区的，JDK8以前是用永久代来实现方法区。\n- 运行时常量池：是方法区的一部分。Class文件中有一项信息是常量池表（Constant Pool Table），用于存放编译器生成的各种字面量和符号引用，这部分内容将在类加载后存放到方法区的运行时常量池中。运行时常量池相对Class文件的常量池具备动态性，并不是只有预置在Class文件常量池中的内容在编译器加载到运行时常量池，开发者可以利用String类的intern方法在运行期间将新的常量放入池中。受到方法区的内存限制，也可能会OOM\n- 堆：几乎所有的对象实例都存放在这里（逃逸分析、栈上分配、标量替换）。对象的组成：对象头、实例数据、对齐填充。对象头：hash code、gc分代年龄、锁标识状态、当前锁、偏向锁ID、偏向时间戳。对齐填充时不满8的倍数就需要填充。64位的JVM new一个Object占用多少空间？对象头mark_word 8个字节、默认使用指针压缩，class pointer指向 占用4个字节，对象实例填充0字节，padding4个字节，总共16个字节。如果不开启指针压缩，mark work8字节、class pointer 8字节，对象实例0字节，padding0字节，也是16字节\n- 本地方法栈：与虚拟机栈类似，为本地方法服务。可以StackOverflowError和OOM\n- 虚拟机栈：线程私有，每个方法被执行时，JVM都会同步创建一个栈帧（Stack Frame）用于存储局部变量表、操作数栈、动态连接、方法出口等信息。一个方法执行完毕，栈帧出栈。局部变量表存放局部变量、方法参数，java文件编译成class文件后，class文件的方法表的code属性。操作数栈是方法调用栈的最大深度，也是在code属性里，叫max-stacks，超过这个数，就会StackOverflowError。动态链接：指向运行时常量池中该栈所属方法的符号引用。方法出口：正常完成出口（没有异常）和异常完成出口（抛出异常）\n\n线程怎么访问到对象？直接指针或者句柄，直接指针是直接指向对象的内存地址，句柄是在Java堆中会分配一个专门的区域作为句柄池，线程指向句柄池，句柄池中的地址reference到对象地址。直接指针一次寻址，快，但是直接指针在线程里，当对象位置移动（GC等），还需要反过来修改线程内的直接指针值（对象内存地址），而句柄指向的是句柄池中的reference，在java堆中，线程共享，对象移动位置后，新的内存地址可以直接修改到reference，而线程中句柄的值不需要变化。\n\n\nhttps://www.bilibili.com/video/BV1RP4y1E7pA?spm_id_from=333.999.0.0  25:16\n\n","source":"_posts/2022-03-05-kongzheng1993-JVM知识点总结.md","raw":"---\ntitle: JVM知识点总结\nexcerpt: 'JVM'\ntags: [JVM]\ncategories: [JVM]\ncomments: true\ndate: 2022-03-05 18:30:52\n---\n\nClass文件、类加载子系统、运行时数据区、执行引擎、本地接口、本地方法栈\n\n## Class文件\n\nClass文件是一组以8字节为基础单位的二进制流。各个数据项目严格按照顺序紧凑地排列在Class文件之中，中间没有添加任何分隔符。根据Java虚拟机规范的规定，Class文件结构采用一种类似于C语言结构体的伪结构来存储数据，这种伪结构只有两种数据类型：无符号数（下面用u4表示4个字节的无符号数）和表。\n\n<img src=\"Class.png\"/>\n\n构成：\n\n1. 开头就是一个魔数（0xCAFEBABE 咖啡宝贝？），标识它是一个Class文件。（很多文件类型都有自己定义的魔术来表示自己的类型）。\n2. 接下来是次版本号和主版本号，标识JDK的版本，为了解决JDK兼容性的问题。比如高版本的java代码无法在低版本的jdk上运行。\n3. 下面是常量池计数器，记录后面常量池里面的常量的个数，常量池中有字面量和符号引用。字面量比较接近Java语言层面的常量概念，比如文本字符串、被声明为final的常量值等。符号引用则属于编译原理方面的概念，主要包括：\n    - 被模块到处或者开放的包（Package）\n    - 类和接口的全限定名\n    - 字段的名称和描述符\n    - 方法的名称和描述符\n    - 方法句柄和方法类型\n    - 动态调用点和动态变量\n注： 常量池计数器是从1开始的，因为0的位置要留给没有父类的（Object类）、没有类名的（匿名内部类），索引要指向常量池第0个位置，也就是说0是留给无法指向的东西的。\n\n4. 下面是访问标识，占用2个字节，用于识别一些类或者接口层次的访问信息，包括：这个Class是类还是接口；是否定义为public类型；是否定义为abstract类型；如果是类，是否声明为final；等等。一共有16个标志位可以使用，当前只定义了其中9个（ACC_PUBLIC、ACC_FINAL、ACC_SUPER、ACC_INTERFACE、ACC_ABSTRACT、ACC_SYNTHETIC、ACC_ANNOTATION、ACC_ENUM、ACC_MODULE），没有使用到的一律为0。\n5. 类索引、父类索引与接口索引集合。由这三项确定该类型的继承关系。类索引用于确定这个类的全限定名，父类索引用于确定这个类的父类的全限定名，java不允许多重继承，所以父类索引只有一个。除了Object外所有Java类都有父类，因此除了Object外所有Java类的父类索引都不为0。接口索引集合用来描述这个Class实现了那些接口，按照implements从左要右的顺序排列在接口索引集合中。类索引和父类索引各自指向一个类型为CONSTANT_Class_info的类描述符常量，通过CONTANT_Class_info类型的常量中的索引值可以找到定义在CONSTANT_Utf8_info类型的常量中的全限定名字符串。由于接口索引是一个集合，所以入口的第一项u2类型的数据为接口计数器（interface_count），表示索引表的容量，如果没有实现任何接口，则该计数器值为0，后面接口的索引表不在占用任何字节。\n6. 字段表集合，用于描述接口或者类中声明的变量。Java语言中的字段包括类级变量以及实例级变量，但不包括在方法内部声明的变局部变量。字段表包括：access_flags、name—_index、descriptor_index、attributes_count、attributes。字段修饰符放在access_flags项目中，与类中的access_flags项目非常类似。根据语法规则，ACC_PUBLIC、ACC_PRIVATE、ACC_PROTECTED只能三选一，ACC_FINAL和ACC_VOLATILE不能同时选择。接口之中的字段必须有ACC_PUBLIC、ACC_STATIC、ACC_FINAL标识。access_flags后面是两个索引值：name_index和descriptor_index，他们都是对常量池项的引用，分别代表着字段的简单名称以及字段和方法的描述符。descriptor_index之后会跟随一个属性表集合，用于存储一些额外信息。\n7. 方法表集合，和字段表类似，volatile和transient关键字不能修饰方法，所以方法表没有对应的访问标志；但是synchronized、native、strictfp（strict float point，精确浮点，可用于类、接口或者方法。）、abstract关键字可以修饰方法，所以增加了对应的访问标志。而我们编写在方法内的代码，在编译成字节码指令之后，就被保存在自己属性表的一个名为“Code”的属性里面，操作数栈的最大深度、局部变量表所需要的最大空间、整段代码的长度都会被保存到Code属性中，后面代码的执行都会用到。\n8. 属性表，Class文件、字段表、方法表都可以携带自己的属性表集合，以描述某些场景专有的信息。属性表的数据项目不像其他部分要求严格的顺序、长度和内容，只要不与已有属性名重复即可。\n\n## 类加载子系统\n\n### JVM类加载的流程  \n\n加载、链接（验证、准备、解析）、初始化，根据时间顺序其实是下面的过程：\n\n   1. 加载：静态加载，java文件编译为class文件，二进制字节流加载。第一次加载的获得的是一个二进制字节流\n   2. 验证：验证文件类型，魔术+主次版本号\n   3. 加载：通过文件类型验证后，将字节流所代表的静态存储结构转化为方法区的运行时数据结构。class文件的常量池和运行时数据区中的常量池有什么区别和联系？\n   4. 加载：在Java堆内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的访问入口\n   5. 验证：元数据验证\n   6. 验证：字节码验证\n   7. 准备：正式为类定义的变量（即静态变量，被static修饰的变量）分配内存并设置类变量初始值（零值）的阶段。\n   8. 初始化：最后一个步骤，开始执行类中编写的Java程序代码，执行类构造器`<clinit>()`方法的过程，这个构造器并不是程序员编写的那个，而是编译器在编译过程中收集的所有初始化代码（包括类变量的赋值动作和静态语句块中的语句，顺序是和源文件中的顺序一致），会先执行父类的`<clinit>()`，JVM为了保证一个类的`<clinit>()`方法在多线程的环境中正确执行会加锁同步，如果多个线程同时去初始化一个类，那么只会有一个线程去执行，其他线程都会阻塞，知道活动线程执行完毕。\n注：解析是Java虚拟机将常量池内的符号引用替换为直接引用的过程，这个动作可能是随着类加载一直在做的，但是解析一定会在初始化之前完成。\n\n`public static String a = 123;`在准备节点a为0，在初始化节点会被赋值为123。\n\n### 类加载器 && 双亲委派模型\n\n#### 类加载器\n\n类加载阶段中的“通过一个类的全限定名来获取描述该类的二进制字节流”这个而动作被放到JVM外部去实现，以便让应用程序自己决定如何去加载所需要的类，实现这个动作的代码被称为`类加载器`。\n\n类加载器的作用并不只是加载类，还作用域确立一个类在JVM中的唯一性。\n\n站在JVM的角度来看，只存在两种不同的类加载器：一种是启动类加载器（Bootstrap ClassLoader），这个类加载器由C++实现，是虚拟机自身的一部分；另一种就是其他所有的类加载器，这些类加载器都是由Java实现，独立存在于虚拟机之外，全部继承自抽象类java.lang.ClassLoader。\n\n三个系统提供的类加载器：\n\n- 启动类加载器（Bootstrap Class Loader），负责加载存放在`<JAVA_HOME>/lib`目录，或者被`-Xbootclasspath`参数所指定的路径中存放的，而且是JVM能够识别的类库。启动类加载器无法被Java程序直接引用，用户在编写自定义类加载器时，如果需要把加载请求委派给引导类加载器（也就是启动类加载器，意译过来的bootstrap）去处理，拿直接使用null代替即可。\n- 扩展类加载器（Extension Class Loader），是在sun.misc.Launcher$ExtClassLoader中以Java代码的形式实现的。它负责加载`<JAVA_HOME>/lib/ext`目录中，或者被java.ext.dirs系统变量所指定的路径中的类库。开发者可以直接在程序中使用扩展类加载器来加载Class文件\n- 应用程序类加载器（Application Class Loader），由sun.misc.Launcher$Launcher$AppClassLoader来实现，由于应用程序加载器时ClassLoader类中的getSystemClassLoader()方法的返回值，所有有些场合也称它为系统类加载器。负责加载用户类路径（ClassPath）上的所有类库，开发者可以直接在代码中使用这个类加载器。如果应用程序中没有自定义过自己的类加载器，一般情况下这个就是默认类加载器。\n\nJDK9之前的Java应用都是由这三种类加载器互相配合来完成加载的。如果有必要，用户还可以加入自定义的类加载器来进行拓展。典型的如增加磁盘位置之外的Class文件来源，或者通过类加载器实现类的隔离、重载等功能。\n\n#### 双亲委派：向上委托和向下委派\n\n过程：如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委托给父类加载器去完成，每一个层次的类加载器都是如此，因此所有的加载请求最终都应该传送到最顶层的启动类加载器中，只有当父加载器反馈自己无法完成这个加载请求（它的搜索范围中没有找到所需的类）时，子加载器才会尝试自己去完成加载。\n\n好处：Java中的类随着它的类加载器一起具备了一种带有优先级的层次关系。比如rt.jar不论哪一个类加载器要加载这个类，最终都是委派给了处于模型最顶端的启动类加载器进行加载。因此一个类在程序的各种加载器环境中都能够保证是同一个类。如果没有双亲委派模型，如果用户自己编写了一个jdk中同名的类，比如java.lang.Object类，并放在程序的ClassPath中，那么系统中就会出现多个不同的Object类，程序将会变得混乱不堪。\n\n代码逻辑：先检查请求加载的类型是否已经被加载过，如果没有则调用父加载器的loadClass()方法，如果父加载器为空则默认使用启动类加载器作为父加载器，如果父类加载器加载失败，抛出ClassNotFoundException异常的话，才调用自己的findClass()方法尝试进行加载。\n\nJVM加载数组：数组不是通过类加载器加载的，JVM直接就在内存中构造出来的一个内存区域，但是数据类型（比如Student这个Class）是由类加载器加载的。Student这个类是由系统类加载器加载的，那么这个数组就会被标识在系统类加载器的命名空间上；如果数据是基础数据类型（比如int）的，那么这个数组就会被标记到启动类加载器的命名空间上。\n\n## 运行时数据区\n\n线程共享：方法区、堆\n线程私有：虚拟机栈、本地方法栈、程序计数器\n\n- 程序计数器：当前线程所执行的字节码的行号指示器，如果正在执行的是一个Java方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址。如果正在执行的是本地方法，这个计数器的值为空。是唯一一个JVM规范没有规定任何OOM情况的区域。\n- 方法区：存储已经被虚拟机加载的类型信息、常量、静态变量、即时编译器编译后的代码缓存等数据。如果方法区无法满足新的内存分配需求时，将抛出OOM。方法区时JVM规范的一个概念定义，并不是一个具体实现。在JDK8以后使用直接内存元空间来实现方法区的，JDK8以前是用永久代来实现方法区。\n- 运行时常量池：是方法区的一部分。Class文件中有一项信息是常量池表（Constant Pool Table），用于存放编译器生成的各种字面量和符号引用，这部分内容将在类加载后存放到方法区的运行时常量池中。运行时常量池相对Class文件的常量池具备动态性，并不是只有预置在Class文件常量池中的内容在编译器加载到运行时常量池，开发者可以利用String类的intern方法在运行期间将新的常量放入池中。受到方法区的内存限制，也可能会OOM\n- 堆：几乎所有的对象实例都存放在这里（逃逸分析、栈上分配、标量替换）。对象的组成：对象头、实例数据、对齐填充。对象头：hash code、gc分代年龄、锁标识状态、当前锁、偏向锁ID、偏向时间戳。对齐填充时不满8的倍数就需要填充。64位的JVM new一个Object占用多少空间？对象头mark_word 8个字节、默认使用指针压缩，class pointer指向 占用4个字节，对象实例填充0字节，padding4个字节，总共16个字节。如果不开启指针压缩，mark work8字节、class pointer 8字节，对象实例0字节，padding0字节，也是16字节\n- 本地方法栈：与虚拟机栈类似，为本地方法服务。可以StackOverflowError和OOM\n- 虚拟机栈：线程私有，每个方法被执行时，JVM都会同步创建一个栈帧（Stack Frame）用于存储局部变量表、操作数栈、动态连接、方法出口等信息。一个方法执行完毕，栈帧出栈。局部变量表存放局部变量、方法参数，java文件编译成class文件后，class文件的方法表的code属性。操作数栈是方法调用栈的最大深度，也是在code属性里，叫max-stacks，超过这个数，就会StackOverflowError。动态链接：指向运行时常量池中该栈所属方法的符号引用。方法出口：正常完成出口（没有异常）和异常完成出口（抛出异常）\n\n线程怎么访问到对象？直接指针或者句柄，直接指针是直接指向对象的内存地址，句柄是在Java堆中会分配一个专门的区域作为句柄池，线程指向句柄池，句柄池中的地址reference到对象地址。直接指针一次寻址，快，但是直接指针在线程里，当对象位置移动（GC等），还需要反过来修改线程内的直接指针值（对象内存地址），而句柄指向的是句柄池中的reference，在java堆中，线程共享，对象移动位置后，新的内存地址可以直接修改到reference，而线程中句柄的值不需要变化。\n\n\nhttps://www.bilibili.com/video/BV1RP4y1E7pA?spm_id_from=333.999.0.0  25:16\n\n","slug":"kongzheng1993-JVM知识点总结","published":1,"updated":"2023-03-08T07:05:58.821Z","layout":"post","photos":[],"link":"","_id":"clg0k2arb00idt26f3im7va7s","content":"<p>Class文件、类加载子系统、运行时数据区、执行引擎、本地接口、本地方法栈</p>\n<h2 id=\"Class文件\"><a href=\"#Class文件\" class=\"headerlink\" title=\"Class文件\"></a>Class文件</h2><p>Class文件是一组以8字节为基础单位的二进制流。各个数据项目严格按照顺序紧凑地排列在Class文件之中，中间没有添加任何分隔符。根据Java虚拟机规范的规定，Class文件结构采用一种类似于C语言结构体的伪结构来存储数据，这种伪结构只有两种数据类型：无符号数（下面用u4表示4个字节的无符号数）和表。</p>\n<img src=\"/2022/03/05/kongzheng1993-JVM知识点总结/Class.png\">\n\n<p>构成：</p>\n<ol>\n<li><p>开头就是一个魔数（0xCAFEBABE 咖啡宝贝？），标识它是一个Class文件。（很多文件类型都有自己定义的魔术来表示自己的类型）。</p>\n</li>\n<li><p>接下来是次版本号和主版本号，标识JDK的版本，为了解决JDK兼容性的问题。比如高版本的java代码无法在低版本的jdk上运行。</p>\n</li>\n<li><p>下面是常量池计数器，记录后面常量池里面的常量的个数，常量池中有字面量和符号引用。字面量比较接近Java语言层面的常量概念，比如文本字符串、被声明为final的常量值等。符号引用则属于编译原理方面的概念，主要包括：</p>\n<ul>\n<li>被模块到处或者开放的包（Package）</li>\n<li>类和接口的全限定名</li>\n<li>字段的名称和描述符</li>\n<li>方法的名称和描述符</li>\n<li>方法句柄和方法类型</li>\n<li>动态调用点和动态变量<br>注： 常量池计数器是从1开始的，因为0的位置要留给没有父类的（Object类）、没有类名的（匿名内部类），索引要指向常量池第0个位置，也就是说0是留给无法指向的东西的。</li>\n</ul>\n</li>\n<li><p>下面是访问标识，占用2个字节，用于识别一些类或者接口层次的访问信息，包括：这个Class是类还是接口；是否定义为public类型；是否定义为abstract类型；如果是类，是否声明为final；等等。一共有16个标志位可以使用，当前只定义了其中9个（ACC_PUBLIC、ACC_FINAL、ACC_SUPER、ACC_INTERFACE、ACC_ABSTRACT、ACC_SYNTHETIC、ACC_ANNOTATION、ACC_ENUM、ACC_MODULE），没有使用到的一律为0。</p>\n</li>\n<li><p>类索引、父类索引与接口索引集合。由这三项确定该类型的继承关系。类索引用于确定这个类的全限定名，父类索引用于确定这个类的父类的全限定名，java不允许多重继承，所以父类索引只有一个。除了Object外所有Java类都有父类，因此除了Object外所有Java类的父类索引都不为0。接口索引集合用来描述这个Class实现了那些接口，按照implements从左要右的顺序排列在接口索引集合中。类索引和父类索引各自指向一个类型为CONSTANT_Class_info的类描述符常量，通过CONTANT_Class_info类型的常量中的索引值可以找到定义在CONSTANT_Utf8_info类型的常量中的全限定名字符串。由于接口索引是一个集合，所以入口的第一项u2类型的数据为接口计数器（interface_count），表示索引表的容量，如果没有实现任何接口，则该计数器值为0，后面接口的索引表不在占用任何字节。</p>\n</li>\n<li><p>字段表集合，用于描述接口或者类中声明的变量。Java语言中的字段包括类级变量以及实例级变量，但不包括在方法内部声明的变局部变量。字段表包括：access_flags、name—_index、descriptor_index、attributes_count、attributes。字段修饰符放在access_flags项目中，与类中的access_flags项目非常类似。根据语法规则，ACC_PUBLIC、ACC_PRIVATE、ACC_PROTECTED只能三选一，ACC_FINAL和ACC_VOLATILE不能同时选择。接口之中的字段必须有ACC_PUBLIC、ACC_STATIC、ACC_FINAL标识。access_flags后面是两个索引值：name_index和descriptor_index，他们都是对常量池项的引用，分别代表着字段的简单名称以及字段和方法的描述符。descriptor_index之后会跟随一个属性表集合，用于存储一些额外信息。</p>\n</li>\n<li><p>方法表集合，和字段表类似，volatile和transient关键字不能修饰方法，所以方法表没有对应的访问标志；但是synchronized、native、strictfp（strict float point，精确浮点，可用于类、接口或者方法。）、abstract关键字可以修饰方法，所以增加了对应的访问标志。而我们编写在方法内的代码，在编译成字节码指令之后，就被保存在自己属性表的一个名为“Code”的属性里面，操作数栈的最大深度、局部变量表所需要的最大空间、整段代码的长度都会被保存到Code属性中，后面代码的执行都会用到。</p>\n</li>\n<li><p>属性表，Class文件、字段表、方法表都可以携带自己的属性表集合，以描述某些场景专有的信息。属性表的数据项目不像其他部分要求严格的顺序、长度和内容，只要不与已有属性名重复即可。</p>\n</li>\n</ol>\n<h2 id=\"类加载子系统\"><a href=\"#类加载子系统\" class=\"headerlink\" title=\"类加载子系统\"></a>类加载子系统</h2><h3 id=\"JVM类加载的流程\"><a href=\"#JVM类加载的流程\" class=\"headerlink\" title=\"JVM类加载的流程\"></a>JVM类加载的流程</h3><p>加载、链接（验证、准备、解析）、初始化，根据时间顺序其实是下面的过程：</p>\n<ol>\n<li>加载：静态加载，java文件编译为class文件，二进制字节流加载。第一次加载的获得的是一个二进制字节流</li>\n<li>验证：验证文件类型，魔术+主次版本号</li>\n<li>加载：通过文件类型验证后，将字节流所代表的静态存储结构转化为方法区的运行时数据结构。class文件的常量池和运行时数据区中的常量池有什么区别和联系？</li>\n<li>加载：在Java堆内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的访问入口</li>\n<li>验证：元数据验证</li>\n<li>验证：字节码验证</li>\n<li>准备：正式为类定义的变量（即静态变量，被static修饰的变量）分配内存并设置类变量初始值（零值）的阶段。</li>\n<li>初始化：最后一个步骤，开始执行类中编写的Java程序代码，执行类构造器<code>&lt;clinit&gt;()</code>方法的过程，这个构造器并不是程序员编写的那个，而是编译器在编译过程中收集的所有初始化代码（包括类变量的赋值动作和静态语句块中的语句，顺序是和源文件中的顺序一致），会先执行父类的<code>&lt;clinit&gt;()</code>，JVM为了保证一个类的<code>&lt;clinit&gt;()</code>方法在多线程的环境中正确执行会加锁同步，如果多个线程同时去初始化一个类，那么只会有一个线程去执行，其他线程都会阻塞，知道活动线程执行完毕。<br>注：解析是Java虚拟机将常量池内的符号引用替换为直接引用的过程，这个动作可能是随着类加载一直在做的，但是解析一定会在初始化之前完成。</li>\n</ol>\n<p><code>public static String a = 123;</code>在准备节点a为0，在初始化节点会被赋值为123。</p>\n<h3 id=\"类加载器-amp-amp-双亲委派模型\"><a href=\"#类加载器-amp-amp-双亲委派模型\" class=\"headerlink\" title=\"类加载器 &amp;&amp; 双亲委派模型\"></a>类加载器 &amp;&amp; 双亲委派模型</h3><h4 id=\"类加载器\"><a href=\"#类加载器\" class=\"headerlink\" title=\"类加载器\"></a>类加载器</h4><p>类加载阶段中的“通过一个类的全限定名来获取描述该类的二进制字节流”这个而动作被放到JVM外部去实现，以便让应用程序自己决定如何去加载所需要的类，实现这个动作的代码被称为<code>类加载器</code>。</p>\n<p>类加载器的作用并不只是加载类，还作用域确立一个类在JVM中的唯一性。</p>\n<p>站在JVM的角度来看，只存在两种不同的类加载器：一种是启动类加载器（Bootstrap ClassLoader），这个类加载器由C++实现，是虚拟机自身的一部分；另一种就是其他所有的类加载器，这些类加载器都是由Java实现，独立存在于虚拟机之外，全部继承自抽象类java.lang.ClassLoader。</p>\n<p>三个系统提供的类加载器：</p>\n<ul>\n<li>启动类加载器（Bootstrap Class Loader），负责加载存放在<code>&lt;JAVA_HOME&gt;/lib</code>目录，或者被<code>-Xbootclasspath</code>参数所指定的路径中存放的，而且是JVM能够识别的类库。启动类加载器无法被Java程序直接引用，用户在编写自定义类加载器时，如果需要把加载请求委派给引导类加载器（也就是启动类加载器，意译过来的bootstrap）去处理，拿直接使用null代替即可。</li>\n<li>扩展类加载器（Extension Class Loader），是在sun.misc.Launcher$ExtClassLoader中以Java代码的形式实现的。它负责加载<code>&lt;JAVA_HOME&gt;/lib/ext</code>目录中，或者被java.ext.dirs系统变量所指定的路径中的类库。开发者可以直接在程序中使用扩展类加载器来加载Class文件</li>\n<li>应用程序类加载器（Application Class Loader），由sun.misc.Launcher$Launcher$AppClassLoader来实现，由于应用程序加载器时ClassLoader类中的getSystemClassLoader()方法的返回值，所有有些场合也称它为系统类加载器。负责加载用户类路径（ClassPath）上的所有类库，开发者可以直接在代码中使用这个类加载器。如果应用程序中没有自定义过自己的类加载器，一般情况下这个就是默认类加载器。</li>\n</ul>\n<p>JDK9之前的Java应用都是由这三种类加载器互相配合来完成加载的。如果有必要，用户还可以加入自定义的类加载器来进行拓展。典型的如增加磁盘位置之外的Class文件来源，或者通过类加载器实现类的隔离、重载等功能。</p>\n<h4 id=\"双亲委派：向上委托和向下委派\"><a href=\"#双亲委派：向上委托和向下委派\" class=\"headerlink\" title=\"双亲委派：向上委托和向下委派\"></a>双亲委派：向上委托和向下委派</h4><p>过程：如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委托给父类加载器去完成，每一个层次的类加载器都是如此，因此所有的加载请求最终都应该传送到最顶层的启动类加载器中，只有当父加载器反馈自己无法完成这个加载请求（它的搜索范围中没有找到所需的类）时，子加载器才会尝试自己去完成加载。</p>\n<p>好处：Java中的类随着它的类加载器一起具备了一种带有优先级的层次关系。比如rt.jar不论哪一个类加载器要加载这个类，最终都是委派给了处于模型最顶端的启动类加载器进行加载。因此一个类在程序的各种加载器环境中都能够保证是同一个类。如果没有双亲委派模型，如果用户自己编写了一个jdk中同名的类，比如java.lang.Object类，并放在程序的ClassPath中，那么系统中就会出现多个不同的Object类，程序将会变得混乱不堪。</p>\n<p>代码逻辑：先检查请求加载的类型是否已经被加载过，如果没有则调用父加载器的loadClass()方法，如果父加载器为空则默认使用启动类加载器作为父加载器，如果父类加载器加载失败，抛出ClassNotFoundException异常的话，才调用自己的findClass()方法尝试进行加载。</p>\n<p>JVM加载数组：数组不是通过类加载器加载的，JVM直接就在内存中构造出来的一个内存区域，但是数据类型（比如Student这个Class）是由类加载器加载的。Student这个类是由系统类加载器加载的，那么这个数组就会被标识在系统类加载器的命名空间上；如果数据是基础数据类型（比如int）的，那么这个数组就会被标记到启动类加载器的命名空间上。</p>\n<h2 id=\"运行时数据区\"><a href=\"#运行时数据区\" class=\"headerlink\" title=\"运行时数据区\"></a>运行时数据区</h2><p>线程共享：方法区、堆<br>线程私有：虚拟机栈、本地方法栈、程序计数器</p>\n<ul>\n<li>程序计数器：当前线程所执行的字节码的行号指示器，如果正在执行的是一个Java方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址。如果正在执行的是本地方法，这个计数器的值为空。是唯一一个JVM规范没有规定任何OOM情况的区域。</li>\n<li>方法区：存储已经被虚拟机加载的类型信息、常量、静态变量、即时编译器编译后的代码缓存等数据。如果方法区无法满足新的内存分配需求时，将抛出OOM。方法区时JVM规范的一个概念定义，并不是一个具体实现。在JDK8以后使用直接内存元空间来实现方法区的，JDK8以前是用永久代来实现方法区。</li>\n<li>运行时常量池：是方法区的一部分。Class文件中有一项信息是常量池表（Constant Pool Table），用于存放编译器生成的各种字面量和符号引用，这部分内容将在类加载后存放到方法区的运行时常量池中。运行时常量池相对Class文件的常量池具备动态性，并不是只有预置在Class文件常量池中的内容在编译器加载到运行时常量池，开发者可以利用String类的intern方法在运行期间将新的常量放入池中。受到方法区的内存限制，也可能会OOM</li>\n<li>堆：几乎所有的对象实例都存放在这里（逃逸分析、栈上分配、标量替换）。对象的组成：对象头、实例数据、对齐填充。对象头：hash code、gc分代年龄、锁标识状态、当前锁、偏向锁ID、偏向时间戳。对齐填充时不满8的倍数就需要填充。64位的JVM new一个Object占用多少空间？对象头mark_word 8个字节、默认使用指针压缩，class pointer指向 占用4个字节，对象实例填充0字节，padding4个字节，总共16个字节。如果不开启指针压缩，mark work8字节、class pointer 8字节，对象实例0字节，padding0字节，也是16字节</li>\n<li>本地方法栈：与虚拟机栈类似，为本地方法服务。可以StackOverflowError和OOM</li>\n<li>虚拟机栈：线程私有，每个方法被执行时，JVM都会同步创建一个栈帧（Stack Frame）用于存储局部变量表、操作数栈、动态连接、方法出口等信息。一个方法执行完毕，栈帧出栈。局部变量表存放局部变量、方法参数，java文件编译成class文件后，class文件的方法表的code属性。操作数栈是方法调用栈的最大深度，也是在code属性里，叫max-stacks，超过这个数，就会StackOverflowError。动态链接：指向运行时常量池中该栈所属方法的符号引用。方法出口：正常完成出口（没有异常）和异常完成出口（抛出异常）</li>\n</ul>\n<p>线程怎么访问到对象？直接指针或者句柄，直接指针是直接指向对象的内存地址，句柄是在Java堆中会分配一个专门的区域作为句柄池，线程指向句柄池，句柄池中的地址reference到对象地址。直接指针一次寻址，快，但是直接指针在线程里，当对象位置移动（GC等），还需要反过来修改线程内的直接指针值（对象内存地址），而句柄指向的是句柄池中的reference，在java堆中，线程共享，对象移动位置后，新的内存地址可以直接修改到reference，而线程中句柄的值不需要变化。</p>\n<p><a href=\"https://www.bilibili.com/video/BV1RP4y1E7pA?spm_id_from=333.999.0.0\" target=\"_blank\" rel=\"noopener\">https://www.bilibili.com/video/BV1RP4y1E7pA?spm_id_from=333.999.0.0</a>  25:16</p>\n","site":{"data":{}},"more":"<p>Class文件、类加载子系统、运行时数据区、执行引擎、本地接口、本地方法栈</p>\n<h2 id=\"Class文件\"><a href=\"#Class文件\" class=\"headerlink\" title=\"Class文件\"></a>Class文件</h2><p>Class文件是一组以8字节为基础单位的二进制流。各个数据项目严格按照顺序紧凑地排列在Class文件之中，中间没有添加任何分隔符。根据Java虚拟机规范的规定，Class文件结构采用一种类似于C语言结构体的伪结构来存储数据，这种伪结构只有两种数据类型：无符号数（下面用u4表示4个字节的无符号数）和表。</p>\n<img src=\"/2022/03/05/kongzheng1993-JVM知识点总结/Class.png\">\n\n<p>构成：</p>\n<ol>\n<li><p>开头就是一个魔数（0xCAFEBABE 咖啡宝贝？），标识它是一个Class文件。（很多文件类型都有自己定义的魔术来表示自己的类型）。</p>\n</li>\n<li><p>接下来是次版本号和主版本号，标识JDK的版本，为了解决JDK兼容性的问题。比如高版本的java代码无法在低版本的jdk上运行。</p>\n</li>\n<li><p>下面是常量池计数器，记录后面常量池里面的常量的个数，常量池中有字面量和符号引用。字面量比较接近Java语言层面的常量概念，比如文本字符串、被声明为final的常量值等。符号引用则属于编译原理方面的概念，主要包括：</p>\n<ul>\n<li>被模块到处或者开放的包（Package）</li>\n<li>类和接口的全限定名</li>\n<li>字段的名称和描述符</li>\n<li>方法的名称和描述符</li>\n<li>方法句柄和方法类型</li>\n<li>动态调用点和动态变量<br>注： 常量池计数器是从1开始的，因为0的位置要留给没有父类的（Object类）、没有类名的（匿名内部类），索引要指向常量池第0个位置，也就是说0是留给无法指向的东西的。</li>\n</ul>\n</li>\n<li><p>下面是访问标识，占用2个字节，用于识别一些类或者接口层次的访问信息，包括：这个Class是类还是接口；是否定义为public类型；是否定义为abstract类型；如果是类，是否声明为final；等等。一共有16个标志位可以使用，当前只定义了其中9个（ACC_PUBLIC、ACC_FINAL、ACC_SUPER、ACC_INTERFACE、ACC_ABSTRACT、ACC_SYNTHETIC、ACC_ANNOTATION、ACC_ENUM、ACC_MODULE），没有使用到的一律为0。</p>\n</li>\n<li><p>类索引、父类索引与接口索引集合。由这三项确定该类型的继承关系。类索引用于确定这个类的全限定名，父类索引用于确定这个类的父类的全限定名，java不允许多重继承，所以父类索引只有一个。除了Object外所有Java类都有父类，因此除了Object外所有Java类的父类索引都不为0。接口索引集合用来描述这个Class实现了那些接口，按照implements从左要右的顺序排列在接口索引集合中。类索引和父类索引各自指向一个类型为CONSTANT_Class_info的类描述符常量，通过CONTANT_Class_info类型的常量中的索引值可以找到定义在CONSTANT_Utf8_info类型的常量中的全限定名字符串。由于接口索引是一个集合，所以入口的第一项u2类型的数据为接口计数器（interface_count），表示索引表的容量，如果没有实现任何接口，则该计数器值为0，后面接口的索引表不在占用任何字节。</p>\n</li>\n<li><p>字段表集合，用于描述接口或者类中声明的变量。Java语言中的字段包括类级变量以及实例级变量，但不包括在方法内部声明的变局部变量。字段表包括：access_flags、name—_index、descriptor_index、attributes_count、attributes。字段修饰符放在access_flags项目中，与类中的access_flags项目非常类似。根据语法规则，ACC_PUBLIC、ACC_PRIVATE、ACC_PROTECTED只能三选一，ACC_FINAL和ACC_VOLATILE不能同时选择。接口之中的字段必须有ACC_PUBLIC、ACC_STATIC、ACC_FINAL标识。access_flags后面是两个索引值：name_index和descriptor_index，他们都是对常量池项的引用，分别代表着字段的简单名称以及字段和方法的描述符。descriptor_index之后会跟随一个属性表集合，用于存储一些额外信息。</p>\n</li>\n<li><p>方法表集合，和字段表类似，volatile和transient关键字不能修饰方法，所以方法表没有对应的访问标志；但是synchronized、native、strictfp（strict float point，精确浮点，可用于类、接口或者方法。）、abstract关键字可以修饰方法，所以增加了对应的访问标志。而我们编写在方法内的代码，在编译成字节码指令之后，就被保存在自己属性表的一个名为“Code”的属性里面，操作数栈的最大深度、局部变量表所需要的最大空间、整段代码的长度都会被保存到Code属性中，后面代码的执行都会用到。</p>\n</li>\n<li><p>属性表，Class文件、字段表、方法表都可以携带自己的属性表集合，以描述某些场景专有的信息。属性表的数据项目不像其他部分要求严格的顺序、长度和内容，只要不与已有属性名重复即可。</p>\n</li>\n</ol>\n<h2 id=\"类加载子系统\"><a href=\"#类加载子系统\" class=\"headerlink\" title=\"类加载子系统\"></a>类加载子系统</h2><h3 id=\"JVM类加载的流程\"><a href=\"#JVM类加载的流程\" class=\"headerlink\" title=\"JVM类加载的流程\"></a>JVM类加载的流程</h3><p>加载、链接（验证、准备、解析）、初始化，根据时间顺序其实是下面的过程：</p>\n<ol>\n<li>加载：静态加载，java文件编译为class文件，二进制字节流加载。第一次加载的获得的是一个二进制字节流</li>\n<li>验证：验证文件类型，魔术+主次版本号</li>\n<li>加载：通过文件类型验证后，将字节流所代表的静态存储结构转化为方法区的运行时数据结构。class文件的常量池和运行时数据区中的常量池有什么区别和联系？</li>\n<li>加载：在Java堆内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的访问入口</li>\n<li>验证：元数据验证</li>\n<li>验证：字节码验证</li>\n<li>准备：正式为类定义的变量（即静态变量，被static修饰的变量）分配内存并设置类变量初始值（零值）的阶段。</li>\n<li>初始化：最后一个步骤，开始执行类中编写的Java程序代码，执行类构造器<code>&lt;clinit&gt;()</code>方法的过程，这个构造器并不是程序员编写的那个，而是编译器在编译过程中收集的所有初始化代码（包括类变量的赋值动作和静态语句块中的语句，顺序是和源文件中的顺序一致），会先执行父类的<code>&lt;clinit&gt;()</code>，JVM为了保证一个类的<code>&lt;clinit&gt;()</code>方法在多线程的环境中正确执行会加锁同步，如果多个线程同时去初始化一个类，那么只会有一个线程去执行，其他线程都会阻塞，知道活动线程执行完毕。<br>注：解析是Java虚拟机将常量池内的符号引用替换为直接引用的过程，这个动作可能是随着类加载一直在做的，但是解析一定会在初始化之前完成。</li>\n</ol>\n<p><code>public static String a = 123;</code>在准备节点a为0，在初始化节点会被赋值为123。</p>\n<h3 id=\"类加载器-amp-amp-双亲委派模型\"><a href=\"#类加载器-amp-amp-双亲委派模型\" class=\"headerlink\" title=\"类加载器 &amp;&amp; 双亲委派模型\"></a>类加载器 &amp;&amp; 双亲委派模型</h3><h4 id=\"类加载器\"><a href=\"#类加载器\" class=\"headerlink\" title=\"类加载器\"></a>类加载器</h4><p>类加载阶段中的“通过一个类的全限定名来获取描述该类的二进制字节流”这个而动作被放到JVM外部去实现，以便让应用程序自己决定如何去加载所需要的类，实现这个动作的代码被称为<code>类加载器</code>。</p>\n<p>类加载器的作用并不只是加载类，还作用域确立一个类在JVM中的唯一性。</p>\n<p>站在JVM的角度来看，只存在两种不同的类加载器：一种是启动类加载器（Bootstrap ClassLoader），这个类加载器由C++实现，是虚拟机自身的一部分；另一种就是其他所有的类加载器，这些类加载器都是由Java实现，独立存在于虚拟机之外，全部继承自抽象类java.lang.ClassLoader。</p>\n<p>三个系统提供的类加载器：</p>\n<ul>\n<li>启动类加载器（Bootstrap Class Loader），负责加载存放在<code>&lt;JAVA_HOME&gt;/lib</code>目录，或者被<code>-Xbootclasspath</code>参数所指定的路径中存放的，而且是JVM能够识别的类库。启动类加载器无法被Java程序直接引用，用户在编写自定义类加载器时，如果需要把加载请求委派给引导类加载器（也就是启动类加载器，意译过来的bootstrap）去处理，拿直接使用null代替即可。</li>\n<li>扩展类加载器（Extension Class Loader），是在sun.misc.Launcher$ExtClassLoader中以Java代码的形式实现的。它负责加载<code>&lt;JAVA_HOME&gt;/lib/ext</code>目录中，或者被java.ext.dirs系统变量所指定的路径中的类库。开发者可以直接在程序中使用扩展类加载器来加载Class文件</li>\n<li>应用程序类加载器（Application Class Loader），由sun.misc.Launcher$Launcher$AppClassLoader来实现，由于应用程序加载器时ClassLoader类中的getSystemClassLoader()方法的返回值，所有有些场合也称它为系统类加载器。负责加载用户类路径（ClassPath）上的所有类库，开发者可以直接在代码中使用这个类加载器。如果应用程序中没有自定义过自己的类加载器，一般情况下这个就是默认类加载器。</li>\n</ul>\n<p>JDK9之前的Java应用都是由这三种类加载器互相配合来完成加载的。如果有必要，用户还可以加入自定义的类加载器来进行拓展。典型的如增加磁盘位置之外的Class文件来源，或者通过类加载器实现类的隔离、重载等功能。</p>\n<h4 id=\"双亲委派：向上委托和向下委派\"><a href=\"#双亲委派：向上委托和向下委派\" class=\"headerlink\" title=\"双亲委派：向上委托和向下委派\"></a>双亲委派：向上委托和向下委派</h4><p>过程：如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委托给父类加载器去完成，每一个层次的类加载器都是如此，因此所有的加载请求最终都应该传送到最顶层的启动类加载器中，只有当父加载器反馈自己无法完成这个加载请求（它的搜索范围中没有找到所需的类）时，子加载器才会尝试自己去完成加载。</p>\n<p>好处：Java中的类随着它的类加载器一起具备了一种带有优先级的层次关系。比如rt.jar不论哪一个类加载器要加载这个类，最终都是委派给了处于模型最顶端的启动类加载器进行加载。因此一个类在程序的各种加载器环境中都能够保证是同一个类。如果没有双亲委派模型，如果用户自己编写了一个jdk中同名的类，比如java.lang.Object类，并放在程序的ClassPath中，那么系统中就会出现多个不同的Object类，程序将会变得混乱不堪。</p>\n<p>代码逻辑：先检查请求加载的类型是否已经被加载过，如果没有则调用父加载器的loadClass()方法，如果父加载器为空则默认使用启动类加载器作为父加载器，如果父类加载器加载失败，抛出ClassNotFoundException异常的话，才调用自己的findClass()方法尝试进行加载。</p>\n<p>JVM加载数组：数组不是通过类加载器加载的，JVM直接就在内存中构造出来的一个内存区域，但是数据类型（比如Student这个Class）是由类加载器加载的。Student这个类是由系统类加载器加载的，那么这个数组就会被标识在系统类加载器的命名空间上；如果数据是基础数据类型（比如int）的，那么这个数组就会被标记到启动类加载器的命名空间上。</p>\n<h2 id=\"运行时数据区\"><a href=\"#运行时数据区\" class=\"headerlink\" title=\"运行时数据区\"></a>运行时数据区</h2><p>线程共享：方法区、堆<br>线程私有：虚拟机栈、本地方法栈、程序计数器</p>\n<ul>\n<li>程序计数器：当前线程所执行的字节码的行号指示器，如果正在执行的是一个Java方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址。如果正在执行的是本地方法，这个计数器的值为空。是唯一一个JVM规范没有规定任何OOM情况的区域。</li>\n<li>方法区：存储已经被虚拟机加载的类型信息、常量、静态变量、即时编译器编译后的代码缓存等数据。如果方法区无法满足新的内存分配需求时，将抛出OOM。方法区时JVM规范的一个概念定义，并不是一个具体实现。在JDK8以后使用直接内存元空间来实现方法区的，JDK8以前是用永久代来实现方法区。</li>\n<li>运行时常量池：是方法区的一部分。Class文件中有一项信息是常量池表（Constant Pool Table），用于存放编译器生成的各种字面量和符号引用，这部分内容将在类加载后存放到方法区的运行时常量池中。运行时常量池相对Class文件的常量池具备动态性，并不是只有预置在Class文件常量池中的内容在编译器加载到运行时常量池，开发者可以利用String类的intern方法在运行期间将新的常量放入池中。受到方法区的内存限制，也可能会OOM</li>\n<li>堆：几乎所有的对象实例都存放在这里（逃逸分析、栈上分配、标量替换）。对象的组成：对象头、实例数据、对齐填充。对象头：hash code、gc分代年龄、锁标识状态、当前锁、偏向锁ID、偏向时间戳。对齐填充时不满8的倍数就需要填充。64位的JVM new一个Object占用多少空间？对象头mark_word 8个字节、默认使用指针压缩，class pointer指向 占用4个字节，对象实例填充0字节，padding4个字节，总共16个字节。如果不开启指针压缩，mark work8字节、class pointer 8字节，对象实例0字节，padding0字节，也是16字节</li>\n<li>本地方法栈：与虚拟机栈类似，为本地方法服务。可以StackOverflowError和OOM</li>\n<li>虚拟机栈：线程私有，每个方法被执行时，JVM都会同步创建一个栈帧（Stack Frame）用于存储局部变量表、操作数栈、动态连接、方法出口等信息。一个方法执行完毕，栈帧出栈。局部变量表存放局部变量、方法参数，java文件编译成class文件后，class文件的方法表的code属性。操作数栈是方法调用栈的最大深度，也是在code属性里，叫max-stacks，超过这个数，就会StackOverflowError。动态链接：指向运行时常量池中该栈所属方法的符号引用。方法出口：正常完成出口（没有异常）和异常完成出口（抛出异常）</li>\n</ul>\n<p>线程怎么访问到对象？直接指针或者句柄，直接指针是直接指向对象的内存地址，句柄是在Java堆中会分配一个专门的区域作为句柄池，线程指向句柄池，句柄池中的地址reference到对象地址。直接指针一次寻址，快，但是直接指针在线程里，当对象位置移动（GC等），还需要反过来修改线程内的直接指针值（对象内存地址），而句柄指向的是句柄池中的reference，在java堆中，线程共享，对象移动位置后，新的内存地址可以直接修改到reference，而线程中句柄的值不需要变化。</p>\n<p><a href=\"https://www.bilibili.com/video/BV1RP4y1E7pA?spm_id_from=333.999.0.0\" target=\"_blank\" rel=\"noopener\">https://www.bilibili.com/video/BV1RP4y1E7pA?spm_id_from=333.999.0.0</a>  25:16</p>\n"},{"title":"Netty","excerpt":"","comments":1,"date":"2023-01-30T02:30:52.000Z","_content":"\n# 简介\n\n[Netty](https://netty.io/)是一个异步事件驱动的网络应用程序框架，用于快速开发可维护的高性能协议服务器和客户端。\n\nNetty是基于Java NIO（New IO）封装的，充分结合了Reactor线程模型，奖Netty变成了一个基于异步事件驱动的网络框架。\n\n为什么不用Java远程NIO？\n1. NIO的类库和API繁杂使用麻烦，你需要熟练掌握Selectol,ServerSocketChannel, SocketChannel,ByteBuffer 等。\n2. 需妥具备其他的额外技能做制垫，例如熟悉Java 多线程编程。这是因为NIO编程涉及到Reactor 模式，你必须对多钱程和网络编程非常如悉，才能编写出高质量的NIO程序。\n3. 可靠性能力补齐， 工作量和难度都非常大。例如客户端面临断连重连、网络间断、半包读写、失败缓存、网络拥塞和异常码流的处理等问题， NI0 编程的特点是功能开发相对容易，但是可靠性能力补齐的工作量和难度都非常大。\n4. JDK NIO的BUG，比如epoll bug，这个BUG会在linux上导致cpu 100%，使得nio server/client不可用，这个BUG直到jdk 6u4才解决，但是直到JDK1.7中仍然有这个问题，该问题并未被完全解决，只是发生的频率降低了而已。\n\n\n# 网络\n\n## OSI\n\n[开放式系统互联通信参考模型](https://baike.baidu.com/item/OSI%E6%A8%A1%E5%9E%8B/10119902?fr=aladdin)（英语：Open System Interconnection Reference Model，缩写为 OSI），简称为OSI模型（OSI model），一种概念模型，由国际标准化组织提出，一个试图使各种计算机在世界范围内互连为网络的标准框架。定义于ISO/IEC 7498-1。\n\n\n\n## TCP/IP\n\n抓包，三次握手、四次挥手\n\n\n# IO\n\n    任何程序都有IO，不然没有意义\n\nIO最开始的定义就是计算机的输入流和输出流。随着技术发展，IO产生了分类。分类的维度不同，比如可以从工作层面上分为磁盘IO（本地IO）和网络IO，也可以从工作模式上分为BIO、NIO、AIO。\n\n一般我们将它分成以下几类：\n- BIO：同步阻塞IO\n- NIO：同步非阻塞IO\n- AIO：异步非阻塞IO\n\n**何为同步，何为阻塞？**\n\n同步/异步： 同步IO是指用户空间(进程或者线程)是主动发起IO请求的一方，系统内核是被动接收方。异步IO则反过来，系统内核是主动发起IO请求的一方，用户空间是被动接收方。 \n\n阻塞： 阻塞IO指的是需要内核IO操作彻底完成后才返回到用户空间执行用户程序的操作指令。“阻塞”指的是用户程序(发起IO请求的进程或者线程)的执行状态。可以说传统 的IO模型都是阻塞IO模型，并且在Java中默认创建的socket都属于阻塞IO模型。 \n\n\n\n## BIO(Blocking IO)\n\n同步阻塞IO，需要内核IO操作彻底完成后，才返回用户空间执行用户的操作。\n\n<img src='blockingIO.png'>\n\n用户程序调用内核read后，会一直等待，直到返回数据。\n特点就是在内核执行IO操作的两个阶段，用户线程/进程一直是阻塞的。\n优点：程序开发简单，阻塞期间用户线程挂起，基本不会占用CPU资源。\n缺点：一个连接就是一个线程，在高并发场景下，需要大量的线程来维护大量的网络连接，内存和线程切换的开销非常大，性能很低，基本不可用。\n\n\n## NIO(Non-blocking IO)\n\n同步非阻塞IO，指用户空间的程序不需要等待内核IO操作彻底完成，可以立即返回用户空间执行用户的操作，用户空间的线程处于非阻塞状态。非阻塞IO要求socket被设置为NONBLOCK\n\n<img src=\"nonBLockingIO.png\">\n\n同步非阻塞IO模型中，用户程序发起read调用，如果内核数据没有准备好，内核会立即返回。用户程序为了读到数据，会一直发起系统调用，轮询数据是否准备好，直到数据返回为止。\n\n优点：每次发起IO系统调用，内核准备数据的过程中，调用会被直接返回，用户线程不会阻塞，实时性较好。\n\n缺点：不断轮询内核，将占用大量的CPU时间，效率低下。\n\n## IO多路复用\n\n为了避免同步非阻塞IO模型中轮询等待的问题，就有了IO多路复用模型。IO多路复用的系统调用有select、epoll等，几乎所有的操作系统都支持select，具有良好的跨平台特性。epoll是select的Linux增强版本。\n\n<img src=\"multiplexing.png\">\n\n<img src=\"man2select.png\">\n\n<img src=\"man2kqueue.png\">\n\n**Todo：**\n- 几种Java程序，strace 查看socket、bind、read、select、epoll_create等系统调用，观察阻塞、同步\n- select和epoll的示意图\n\n## 异步IO\n\n<img src=\"asyncIO.png\">\n\n用户线程通过系统调用内核注册某个IO操作，内核在整个IO操作（包括数据准备、数据复制）完成后通知用户程序，用户执行后续的业务操作。异步IO是真正的异步输入输出，它的吞吐量高于IO多路复用模型。就目前而言，Windows系统下通过IOCP实现了真正的异步IO，在Linux系统下，异步IO模型在2.6版本才引入，JDK对它的支持并不完善。\n而大多数高并发服务器的程序都是基于Linux系统的，因此目前高并发网络应用程序的开发大多采用IO多路复用模型，大名鼎鼎的Netty框架使用的就是IO多路复用模型，而不是异步IO模型。\n\n\n\n# Netty\nNetty是一个异步事件驱动的网络应用框架快速开发可维护的高性能协议服务器和客户端。\nNetty是基于Java NIO（New IO）封装的，充分结合了Reactor线程模型，将Netty变成了一个基于异步事件驱动的网络框架。\n\n## Java NIO和NIO\n\nJava1.4之前Java IO类库是阻塞IO，1.4版本之后引进了新的异步IO库，称为Java New IO类库缩写也就是NIO。而老的阻塞式的IO被称为Old IO，OIO。\n\nJava NIO包含以下3个核心组件：\n- Channel--通道\n- Buffer--缓冲区\n- Selector--选择器\n看到这三个组件，就能识别出它用的是IO多路复用模型\nNIO和OIO的区别：\n- OIO是面向流（Stream Oriented）的，NIO是面向缓冲区（Buffer Oriented）的。\n\n**为什么不用Java远程NIO？**\n\n1. NIO的类库和API繁杂使用麻烦，你需要熟练掌握Selectol,ServerSocketChannel, SocketChannel,ByteBuffer 等。\n2. 需要具备其他的额外技能做制垫，例如熟悉Java 多线程编程。这是因为NIO编程涉及到Reactor 模式，你必须对多钱程和网络编程非常熟悉，才能编写出高质量的NIO程序。\n3. 可靠性能力补齐， 工作量和难度都非常大。例如客户端面临断连重连、网络间断、半包读写、失败缓存、网络拥塞和异常码流的处理等问题， NI0 编程的特点是功能开发相对容易，但是可靠性能力补齐的工作量和难度都非常大。\n4. JDK NIO的BUG，比如epoll bug，这个BUG会在linux上导致cpu 100%，使得nio server/client不可用，这个BUG直到jdk 6u4才解决，但是直到JDK1.7中仍然有这个问题，该问题并未被完全解决，只是发生的频率降低了而已。\n\n## Reactor模式\n\nNetty的整体架构是基于Reactor模式的。Reactor模式由Reactor线程、Handlers处理器两大角色组成，两大角色的职责分别如下：\n1. Reactor线程的职责：负责响应IO时间，并且分发到Handlers处理器。\n2. Handlers处理器的职责：非阻塞的执行业务处理逻辑。\n\n<img src=\"asyncIO.png\">\n\nReactor模式中IO事件的处理流程大致分为4步：\n1. 通道注册。IO事件源于通道Channel，IO是和通道（对应于底层连接而言）强相关的。一个IO事件一定属于某个通道。如果要查询通道的事件，首先要将通道注册到选择器。\n2. 查询事件。在Reactor模式中，一个线程会负责一个反映器（或者SubReactor子反映器），不断轮询，查询选择器中的IO事件（选择键）。\n3. 事件分发。如果查询到了IO事件，则分发给与IO事件有绑定关系的Handler业务处理。\n4. 完成真正的IO操作和业务处理，这一步由Handler业务处理器负责。\n\n上面第1、2步其实是Java NIO的功能，Reactor模式仅仅是利用了Java NIO的优势而已。\n\n### Netty中的Channel\n\nNetty中不直接使用Java NIO的Channel组件，对Channel组件进行 了自己的封装。Netty实现了一系列的Channel组件，为了支持多种通 信协议，换句话说，对于每一种通信连接协议，Netty都实现了自己的 通道。除了Java的NIO，Netty还提供了Java面向流的OIO处理通道。 \n\nNetty中常见的通道类型：\n- NioSocketChannel：异步非阻塞TCP Socket传输通道\n- NioServerSocketChannel：异步非阻塞TCP Socket服务端监听通道\n- NioDatagramChannel：异步非阻塞的UDP传输通道\n- NioSctpChannel：异步非阻塞Sctp传输通道\n- NioSctpServerChannel：异步非阻塞Sctp服务端监听通道\n- OioSocketChannel：同步阻塞式TCP Socket传输通道\n- OioServerSocketChannel：同步阻塞式TCP Socket服务端监听通道\n- OioDatagramChannel：同步阻塞式UDP传输通道\n- OioSctpChannel：同步阻塞式Sctp传输通道\n- OioSctpServerChannel：同步阻塞式Sctp服务端监听通道\n\n\n<img src=\"channel.png\">\n\n\n### Netty中的Reactor\n\nNetty中的反映器组件有多个实现类，这些实现类与其通道类型相互匹配。对应NioSocketChannel通道，Netty的反映器类型为NioEventLoop（NIO事件轮询）。\n\nNioEventLoop类有两个重要的成员属性：\n- Thread线程类型成员\n- Java NIO选择器成员\n\n<img src=\"netty_reactor\">\n\n到这里可以看出，NioEventLoop和前面说的反映器思路一致：一个NioEventLoop拥有一个线程，负责一个Java NIO选择器的IO事件轮询。\nEventLoop反映器和Channel的关系：一个EventLoop反映器和NettyChannel通道是一对多的关系：一个反映器可以注册成千上万的通道。\n\n<img src=\"EventLoop.png\">\n\n### Netty中的Handler\n\n在Netty中，EventLoop反映器内部有一个线程负责Java NIO选择器事件的轮询，然后进行对应的事件分发，事件分发（Dispatch）的目标就是Netty的Handler（含用户定义的业务处理器）。\n\nNetty的Handler分为两大类：\n- ChannelInboundHandler入站处理器\n- ChannelOutboundHandler出站处理器\n二者都继承了ChannelHandler处理器接口。\n\n<img src=\"handler.png\">\n\nNetty的IO事件类型：\n- 可读：SelectionKey.OP_READ\n- 可写：SelectionKey.OP_WRITE\n- 连接：SelectionKey.OP_CONNECT\n- 接受：SelectionKey.OP_ACCEPT\n\n### Netty中的Pipeline\n\nNetty设计了一个特殊的组件，叫做ChannelPipeline（通道流水线）。它像一条管道，将绑定到一个通道的多个Handler处理器实例串联在一起，形成一条流水线。ChannelPipeline默认实现被设计成一个双向链表，所有Handler处理器实例被包装成双向链表的节点，被加入到ChannelPipeline中。\n\n","source":"_posts/2023-01-30-kongzheng1993-Netty.md","raw":"---\ntitle: Netty\nexcerpt: 'netty'\ntags: [netty]\ncategories: [netty]\ncomments: true\ndate: 2023-01-30 10:30:52\n---\n\n# 简介\n\n[Netty](https://netty.io/)是一个异步事件驱动的网络应用程序框架，用于快速开发可维护的高性能协议服务器和客户端。\n\nNetty是基于Java NIO（New IO）封装的，充分结合了Reactor线程模型，奖Netty变成了一个基于异步事件驱动的网络框架。\n\n为什么不用Java远程NIO？\n1. NIO的类库和API繁杂使用麻烦，你需要熟练掌握Selectol,ServerSocketChannel, SocketChannel,ByteBuffer 等。\n2. 需妥具备其他的额外技能做制垫，例如熟悉Java 多线程编程。这是因为NIO编程涉及到Reactor 模式，你必须对多钱程和网络编程非常如悉，才能编写出高质量的NIO程序。\n3. 可靠性能力补齐， 工作量和难度都非常大。例如客户端面临断连重连、网络间断、半包读写、失败缓存、网络拥塞和异常码流的处理等问题， NI0 编程的特点是功能开发相对容易，但是可靠性能力补齐的工作量和难度都非常大。\n4. JDK NIO的BUG，比如epoll bug，这个BUG会在linux上导致cpu 100%，使得nio server/client不可用，这个BUG直到jdk 6u4才解决，但是直到JDK1.7中仍然有这个问题，该问题并未被完全解决，只是发生的频率降低了而已。\n\n\n# 网络\n\n## OSI\n\n[开放式系统互联通信参考模型](https://baike.baidu.com/item/OSI%E6%A8%A1%E5%9E%8B/10119902?fr=aladdin)（英语：Open System Interconnection Reference Model，缩写为 OSI），简称为OSI模型（OSI model），一种概念模型，由国际标准化组织提出，一个试图使各种计算机在世界范围内互连为网络的标准框架。定义于ISO/IEC 7498-1。\n\n\n\n## TCP/IP\n\n抓包，三次握手、四次挥手\n\n\n# IO\n\n    任何程序都有IO，不然没有意义\n\nIO最开始的定义就是计算机的输入流和输出流。随着技术发展，IO产生了分类。分类的维度不同，比如可以从工作层面上分为磁盘IO（本地IO）和网络IO，也可以从工作模式上分为BIO、NIO、AIO。\n\n一般我们将它分成以下几类：\n- BIO：同步阻塞IO\n- NIO：同步非阻塞IO\n- AIO：异步非阻塞IO\n\n**何为同步，何为阻塞？**\n\n同步/异步： 同步IO是指用户空间(进程或者线程)是主动发起IO请求的一方，系统内核是被动接收方。异步IO则反过来，系统内核是主动发起IO请求的一方，用户空间是被动接收方。 \n\n阻塞： 阻塞IO指的是需要内核IO操作彻底完成后才返回到用户空间执行用户程序的操作指令。“阻塞”指的是用户程序(发起IO请求的进程或者线程)的执行状态。可以说传统 的IO模型都是阻塞IO模型，并且在Java中默认创建的socket都属于阻塞IO模型。 \n\n\n\n## BIO(Blocking IO)\n\n同步阻塞IO，需要内核IO操作彻底完成后，才返回用户空间执行用户的操作。\n\n<img src='blockingIO.png'>\n\n用户程序调用内核read后，会一直等待，直到返回数据。\n特点就是在内核执行IO操作的两个阶段，用户线程/进程一直是阻塞的。\n优点：程序开发简单，阻塞期间用户线程挂起，基本不会占用CPU资源。\n缺点：一个连接就是一个线程，在高并发场景下，需要大量的线程来维护大量的网络连接，内存和线程切换的开销非常大，性能很低，基本不可用。\n\n\n## NIO(Non-blocking IO)\n\n同步非阻塞IO，指用户空间的程序不需要等待内核IO操作彻底完成，可以立即返回用户空间执行用户的操作，用户空间的线程处于非阻塞状态。非阻塞IO要求socket被设置为NONBLOCK\n\n<img src=\"nonBLockingIO.png\">\n\n同步非阻塞IO模型中，用户程序发起read调用，如果内核数据没有准备好，内核会立即返回。用户程序为了读到数据，会一直发起系统调用，轮询数据是否准备好，直到数据返回为止。\n\n优点：每次发起IO系统调用，内核准备数据的过程中，调用会被直接返回，用户线程不会阻塞，实时性较好。\n\n缺点：不断轮询内核，将占用大量的CPU时间，效率低下。\n\n## IO多路复用\n\n为了避免同步非阻塞IO模型中轮询等待的问题，就有了IO多路复用模型。IO多路复用的系统调用有select、epoll等，几乎所有的操作系统都支持select，具有良好的跨平台特性。epoll是select的Linux增强版本。\n\n<img src=\"multiplexing.png\">\n\n<img src=\"man2select.png\">\n\n<img src=\"man2kqueue.png\">\n\n**Todo：**\n- 几种Java程序，strace 查看socket、bind、read、select、epoll_create等系统调用，观察阻塞、同步\n- select和epoll的示意图\n\n## 异步IO\n\n<img src=\"asyncIO.png\">\n\n用户线程通过系统调用内核注册某个IO操作，内核在整个IO操作（包括数据准备、数据复制）完成后通知用户程序，用户执行后续的业务操作。异步IO是真正的异步输入输出，它的吞吐量高于IO多路复用模型。就目前而言，Windows系统下通过IOCP实现了真正的异步IO，在Linux系统下，异步IO模型在2.6版本才引入，JDK对它的支持并不完善。\n而大多数高并发服务器的程序都是基于Linux系统的，因此目前高并发网络应用程序的开发大多采用IO多路复用模型，大名鼎鼎的Netty框架使用的就是IO多路复用模型，而不是异步IO模型。\n\n\n\n# Netty\nNetty是一个异步事件驱动的网络应用框架快速开发可维护的高性能协议服务器和客户端。\nNetty是基于Java NIO（New IO）封装的，充分结合了Reactor线程模型，将Netty变成了一个基于异步事件驱动的网络框架。\n\n## Java NIO和NIO\n\nJava1.4之前Java IO类库是阻塞IO，1.4版本之后引进了新的异步IO库，称为Java New IO类库缩写也就是NIO。而老的阻塞式的IO被称为Old IO，OIO。\n\nJava NIO包含以下3个核心组件：\n- Channel--通道\n- Buffer--缓冲区\n- Selector--选择器\n看到这三个组件，就能识别出它用的是IO多路复用模型\nNIO和OIO的区别：\n- OIO是面向流（Stream Oriented）的，NIO是面向缓冲区（Buffer Oriented）的。\n\n**为什么不用Java远程NIO？**\n\n1. NIO的类库和API繁杂使用麻烦，你需要熟练掌握Selectol,ServerSocketChannel, SocketChannel,ByteBuffer 等。\n2. 需要具备其他的额外技能做制垫，例如熟悉Java 多线程编程。这是因为NIO编程涉及到Reactor 模式，你必须对多钱程和网络编程非常熟悉，才能编写出高质量的NIO程序。\n3. 可靠性能力补齐， 工作量和难度都非常大。例如客户端面临断连重连、网络间断、半包读写、失败缓存、网络拥塞和异常码流的处理等问题， NI0 编程的特点是功能开发相对容易，但是可靠性能力补齐的工作量和难度都非常大。\n4. JDK NIO的BUG，比如epoll bug，这个BUG会在linux上导致cpu 100%，使得nio server/client不可用，这个BUG直到jdk 6u4才解决，但是直到JDK1.7中仍然有这个问题，该问题并未被完全解决，只是发生的频率降低了而已。\n\n## Reactor模式\n\nNetty的整体架构是基于Reactor模式的。Reactor模式由Reactor线程、Handlers处理器两大角色组成，两大角色的职责分别如下：\n1. Reactor线程的职责：负责响应IO时间，并且分发到Handlers处理器。\n2. Handlers处理器的职责：非阻塞的执行业务处理逻辑。\n\n<img src=\"asyncIO.png\">\n\nReactor模式中IO事件的处理流程大致分为4步：\n1. 通道注册。IO事件源于通道Channel，IO是和通道（对应于底层连接而言）强相关的。一个IO事件一定属于某个通道。如果要查询通道的事件，首先要将通道注册到选择器。\n2. 查询事件。在Reactor模式中，一个线程会负责一个反映器（或者SubReactor子反映器），不断轮询，查询选择器中的IO事件（选择键）。\n3. 事件分发。如果查询到了IO事件，则分发给与IO事件有绑定关系的Handler业务处理。\n4. 完成真正的IO操作和业务处理，这一步由Handler业务处理器负责。\n\n上面第1、2步其实是Java NIO的功能，Reactor模式仅仅是利用了Java NIO的优势而已。\n\n### Netty中的Channel\n\nNetty中不直接使用Java NIO的Channel组件，对Channel组件进行 了自己的封装。Netty实现了一系列的Channel组件，为了支持多种通 信协议，换句话说，对于每一种通信连接协议，Netty都实现了自己的 通道。除了Java的NIO，Netty还提供了Java面向流的OIO处理通道。 \n\nNetty中常见的通道类型：\n- NioSocketChannel：异步非阻塞TCP Socket传输通道\n- NioServerSocketChannel：异步非阻塞TCP Socket服务端监听通道\n- NioDatagramChannel：异步非阻塞的UDP传输通道\n- NioSctpChannel：异步非阻塞Sctp传输通道\n- NioSctpServerChannel：异步非阻塞Sctp服务端监听通道\n- OioSocketChannel：同步阻塞式TCP Socket传输通道\n- OioServerSocketChannel：同步阻塞式TCP Socket服务端监听通道\n- OioDatagramChannel：同步阻塞式UDP传输通道\n- OioSctpChannel：同步阻塞式Sctp传输通道\n- OioSctpServerChannel：同步阻塞式Sctp服务端监听通道\n\n\n<img src=\"channel.png\">\n\n\n### Netty中的Reactor\n\nNetty中的反映器组件有多个实现类，这些实现类与其通道类型相互匹配。对应NioSocketChannel通道，Netty的反映器类型为NioEventLoop（NIO事件轮询）。\n\nNioEventLoop类有两个重要的成员属性：\n- Thread线程类型成员\n- Java NIO选择器成员\n\n<img src=\"netty_reactor\">\n\n到这里可以看出，NioEventLoop和前面说的反映器思路一致：一个NioEventLoop拥有一个线程，负责一个Java NIO选择器的IO事件轮询。\nEventLoop反映器和Channel的关系：一个EventLoop反映器和NettyChannel通道是一对多的关系：一个反映器可以注册成千上万的通道。\n\n<img src=\"EventLoop.png\">\n\n### Netty中的Handler\n\n在Netty中，EventLoop反映器内部有一个线程负责Java NIO选择器事件的轮询，然后进行对应的事件分发，事件分发（Dispatch）的目标就是Netty的Handler（含用户定义的业务处理器）。\n\nNetty的Handler分为两大类：\n- ChannelInboundHandler入站处理器\n- ChannelOutboundHandler出站处理器\n二者都继承了ChannelHandler处理器接口。\n\n<img src=\"handler.png\">\n\nNetty的IO事件类型：\n- 可读：SelectionKey.OP_READ\n- 可写：SelectionKey.OP_WRITE\n- 连接：SelectionKey.OP_CONNECT\n- 接受：SelectionKey.OP_ACCEPT\n\n### Netty中的Pipeline\n\nNetty设计了一个特殊的组件，叫做ChannelPipeline（通道流水线）。它像一条管道，将绑定到一个通道的多个Handler处理器实例串联在一起，形成一条流水线。ChannelPipeline默认实现被设计成一个双向链表，所有Handler处理器实例被包装成双向链表的节点，被加入到ChannelPipeline中。\n\n","slug":"kongzheng1993-Netty","published":1,"updated":"2023-03-31T06:19:29.691Z","layout":"post","photos":[],"link":"","_id":"clg0k2arc00ift26fucipng4b","content":"<h1 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h1><p><a href=\"https://netty.io/\" target=\"_blank\" rel=\"noopener\">Netty</a>是一个异步事件驱动的网络应用程序框架，用于快速开发可维护的高性能协议服务器和客户端。</p>\n<p>Netty是基于Java NIO（New IO）封装的，充分结合了Reactor线程模型，奖Netty变成了一个基于异步事件驱动的网络框架。</p>\n<p>为什么不用Java远程NIO？</p>\n<ol>\n<li>NIO的类库和API繁杂使用麻烦，你需要熟练掌握Selectol,ServerSocketChannel, SocketChannel,ByteBuffer 等。</li>\n<li>需妥具备其他的额外技能做制垫，例如熟悉Java 多线程编程。这是因为NIO编程涉及到Reactor 模式，你必须对多钱程和网络编程非常如悉，才能编写出高质量的NIO程序。</li>\n<li>可靠性能力补齐， 工作量和难度都非常大。例如客户端面临断连重连、网络间断、半包读写、失败缓存、网络拥塞和异常码流的处理等问题， NI0 编程的特点是功能开发相对容易，但是可靠性能力补齐的工作量和难度都非常大。</li>\n<li>JDK NIO的BUG，比如epoll bug，这个BUG会在linux上导致cpu 100%，使得nio server/client不可用，这个BUG直到jdk 6u4才解决，但是直到JDK1.7中仍然有这个问题，该问题并未被完全解决，只是发生的频率降低了而已。</li>\n</ol>\n<h1 id=\"网络\"><a href=\"#网络\" class=\"headerlink\" title=\"网络\"></a>网络</h1><h2 id=\"OSI\"><a href=\"#OSI\" class=\"headerlink\" title=\"OSI\"></a>OSI</h2><p><a href=\"https://baike.baidu.com/item/OSI%E6%A8%A1%E5%9E%8B/10119902?fr=aladdin\" target=\"_blank\" rel=\"noopener\">开放式系统互联通信参考模型</a>（英语：Open System Interconnection Reference Model，缩写为 OSI），简称为OSI模型（OSI model），一种概念模型，由国际标准化组织提出，一个试图使各种计算机在世界范围内互连为网络的标准框架。定义于ISO/IEC 7498-1。</p>\n<h2 id=\"TCP-IP\"><a href=\"#TCP-IP\" class=\"headerlink\" title=\"TCP/IP\"></a>TCP/IP</h2><p>抓包，三次握手、四次挥手</p>\n<h1 id=\"IO\"><a href=\"#IO\" class=\"headerlink\" title=\"IO\"></a>IO</h1><pre><code>任何程序都有IO，不然没有意义</code></pre><p>IO最开始的定义就是计算机的输入流和输出流。随着技术发展，IO产生了分类。分类的维度不同，比如可以从工作层面上分为磁盘IO（本地IO）和网络IO，也可以从工作模式上分为BIO、NIO、AIO。</p>\n<p>一般我们将它分成以下几类：</p>\n<ul>\n<li>BIO：同步阻塞IO</li>\n<li>NIO：同步非阻塞IO</li>\n<li>AIO：异步非阻塞IO</li>\n</ul>\n<p><strong>何为同步，何为阻塞？</strong></p>\n<p>同步/异步： 同步IO是指用户空间(进程或者线程)是主动发起IO请求的一方，系统内核是被动接收方。异步IO则反过来，系统内核是主动发起IO请求的一方，用户空间是被动接收方。 </p>\n<p>阻塞： 阻塞IO指的是需要内核IO操作彻底完成后才返回到用户空间执行用户程序的操作指令。“阻塞”指的是用户程序(发起IO请求的进程或者线程)的执行状态。可以说传统 的IO模型都是阻塞IO模型，并且在Java中默认创建的socket都属于阻塞IO模型。 </p>\n<h2 id=\"BIO-Blocking-IO\"><a href=\"#BIO-Blocking-IO\" class=\"headerlink\" title=\"BIO(Blocking IO)\"></a>BIO(Blocking IO)</h2><p>同步阻塞IO，需要内核IO操作彻底完成后，才返回用户空间执行用户的操作。</p>\n<img src=\"/2023/01/30/kongzheng1993-Netty/blockingIO.png\">\n\n<p>用户程序调用内核read后，会一直等待，直到返回数据。<br>特点就是在内核执行IO操作的两个阶段，用户线程/进程一直是阻塞的。<br>优点：程序开发简单，阻塞期间用户线程挂起，基本不会占用CPU资源。<br>缺点：一个连接就是一个线程，在高并发场景下，需要大量的线程来维护大量的网络连接，内存和线程切换的开销非常大，性能很低，基本不可用。</p>\n<h2 id=\"NIO-Non-blocking-IO\"><a href=\"#NIO-Non-blocking-IO\" class=\"headerlink\" title=\"NIO(Non-blocking IO)\"></a>NIO(Non-blocking IO)</h2><p>同步非阻塞IO，指用户空间的程序不需要等待内核IO操作彻底完成，可以立即返回用户空间执行用户的操作，用户空间的线程处于非阻塞状态。非阻塞IO要求socket被设置为NONBLOCK</p>\n<img src=\"/2023/01/30/kongzheng1993-Netty/nonBLockingIO.png\">\n\n<p>同步非阻塞IO模型中，用户程序发起read调用，如果内核数据没有准备好，内核会立即返回。用户程序为了读到数据，会一直发起系统调用，轮询数据是否准备好，直到数据返回为止。</p>\n<p>优点：每次发起IO系统调用，内核准备数据的过程中，调用会被直接返回，用户线程不会阻塞，实时性较好。</p>\n<p>缺点：不断轮询内核，将占用大量的CPU时间，效率低下。</p>\n<h2 id=\"IO多路复用\"><a href=\"#IO多路复用\" class=\"headerlink\" title=\"IO多路复用\"></a>IO多路复用</h2><p>为了避免同步非阻塞IO模型中轮询等待的问题，就有了IO多路复用模型。IO多路复用的系统调用有select、epoll等，几乎所有的操作系统都支持select，具有良好的跨平台特性。epoll是select的Linux增强版本。</p>\n<img src=\"/2023/01/30/kongzheng1993-Netty/multiplexing.png\">\n\n<img src=\"/2023/01/30/kongzheng1993-Netty/man2select.png\">\n\n<img src=\"/2023/01/30/kongzheng1993-Netty/man2kqueue.png\">\n\n<p><strong>Todo：</strong></p>\n<ul>\n<li>几种Java程序，strace 查看socket、bind、read、select、epoll_create等系统调用，观察阻塞、同步</li>\n<li>select和epoll的示意图</li>\n</ul>\n<h2 id=\"异步IO\"><a href=\"#异步IO\" class=\"headerlink\" title=\"异步IO\"></a>异步IO</h2><img src=\"/2023/01/30/kongzheng1993-Netty/asyncIO.png\">\n\n<p>用户线程通过系统调用内核注册某个IO操作，内核在整个IO操作（包括数据准备、数据复制）完成后通知用户程序，用户执行后续的业务操作。异步IO是真正的异步输入输出，它的吞吐量高于IO多路复用模型。就目前而言，Windows系统下通过IOCP实现了真正的异步IO，在Linux系统下，异步IO模型在2.6版本才引入，JDK对它的支持并不完善。<br>而大多数高并发服务器的程序都是基于Linux系统的，因此目前高并发网络应用程序的开发大多采用IO多路复用模型，大名鼎鼎的Netty框架使用的就是IO多路复用模型，而不是异步IO模型。</p>\n<h1 id=\"Netty\"><a href=\"#Netty\" class=\"headerlink\" title=\"Netty\"></a>Netty</h1><p>Netty是一个异步事件驱动的网络应用框架快速开发可维护的高性能协议服务器和客户端。<br>Netty是基于Java NIO（New IO）封装的，充分结合了Reactor线程模型，将Netty变成了一个基于异步事件驱动的网络框架。</p>\n<h2 id=\"Java-NIO和NIO\"><a href=\"#Java-NIO和NIO\" class=\"headerlink\" title=\"Java NIO和NIO\"></a>Java NIO和NIO</h2><p>Java1.4之前Java IO类库是阻塞IO，1.4版本之后引进了新的异步IO库，称为Java New IO类库缩写也就是NIO。而老的阻塞式的IO被称为Old IO，OIO。</p>\n<p>Java NIO包含以下3个核心组件：</p>\n<ul>\n<li>Channel–通道</li>\n<li>Buffer–缓冲区</li>\n<li>Selector–选择器<br>看到这三个组件，就能识别出它用的是IO多路复用模型<br>NIO和OIO的区别：</li>\n<li>OIO是面向流（Stream Oriented）的，NIO是面向缓冲区（Buffer Oriented）的。</li>\n</ul>\n<p><strong>为什么不用Java远程NIO？</strong></p>\n<ol>\n<li>NIO的类库和API繁杂使用麻烦，你需要熟练掌握Selectol,ServerSocketChannel, SocketChannel,ByteBuffer 等。</li>\n<li>需要具备其他的额外技能做制垫，例如熟悉Java 多线程编程。这是因为NIO编程涉及到Reactor 模式，你必须对多钱程和网络编程非常熟悉，才能编写出高质量的NIO程序。</li>\n<li>可靠性能力补齐， 工作量和难度都非常大。例如客户端面临断连重连、网络间断、半包读写、失败缓存、网络拥塞和异常码流的处理等问题， NI0 编程的特点是功能开发相对容易，但是可靠性能力补齐的工作量和难度都非常大。</li>\n<li>JDK NIO的BUG，比如epoll bug，这个BUG会在linux上导致cpu 100%，使得nio server/client不可用，这个BUG直到jdk 6u4才解决，但是直到JDK1.7中仍然有这个问题，该问题并未被完全解决，只是发生的频率降低了而已。</li>\n</ol>\n<h2 id=\"Reactor模式\"><a href=\"#Reactor模式\" class=\"headerlink\" title=\"Reactor模式\"></a>Reactor模式</h2><p>Netty的整体架构是基于Reactor模式的。Reactor模式由Reactor线程、Handlers处理器两大角色组成，两大角色的职责分别如下：</p>\n<ol>\n<li>Reactor线程的职责：负责响应IO时间，并且分发到Handlers处理器。</li>\n<li>Handlers处理器的职责：非阻塞的执行业务处理逻辑。</li>\n</ol>\n<img src=\"/2023/01/30/kongzheng1993-Netty/asyncIO.png\">\n\n<p>Reactor模式中IO事件的处理流程大致分为4步：</p>\n<ol>\n<li>通道注册。IO事件源于通道Channel，IO是和通道（对应于底层连接而言）强相关的。一个IO事件一定属于某个通道。如果要查询通道的事件，首先要将通道注册到选择器。</li>\n<li>查询事件。在Reactor模式中，一个线程会负责一个反映器（或者SubReactor子反映器），不断轮询，查询选择器中的IO事件（选择键）。</li>\n<li>事件分发。如果查询到了IO事件，则分发给与IO事件有绑定关系的Handler业务处理。</li>\n<li>完成真正的IO操作和业务处理，这一步由Handler业务处理器负责。</li>\n</ol>\n<p>上面第1、2步其实是Java NIO的功能，Reactor模式仅仅是利用了Java NIO的优势而已。</p>\n<h3 id=\"Netty中的Channel\"><a href=\"#Netty中的Channel\" class=\"headerlink\" title=\"Netty中的Channel\"></a>Netty中的Channel</h3><p>Netty中不直接使用Java NIO的Channel组件，对Channel组件进行 了自己的封装。Netty实现了一系列的Channel组件，为了支持多种通 信协议，换句话说，对于每一种通信连接协议，Netty都实现了自己的 通道。除了Java的NIO，Netty还提供了Java面向流的OIO处理通道。 </p>\n<p>Netty中常见的通道类型：</p>\n<ul>\n<li>NioSocketChannel：异步非阻塞TCP Socket传输通道</li>\n<li>NioServerSocketChannel：异步非阻塞TCP Socket服务端监听通道</li>\n<li>NioDatagramChannel：异步非阻塞的UDP传输通道</li>\n<li>NioSctpChannel：异步非阻塞Sctp传输通道</li>\n<li>NioSctpServerChannel：异步非阻塞Sctp服务端监听通道</li>\n<li>OioSocketChannel：同步阻塞式TCP Socket传输通道</li>\n<li>OioServerSocketChannel：同步阻塞式TCP Socket服务端监听通道</li>\n<li>OioDatagramChannel：同步阻塞式UDP传输通道</li>\n<li>OioSctpChannel：同步阻塞式Sctp传输通道</li>\n<li>OioSctpServerChannel：同步阻塞式Sctp服务端监听通道</li>\n</ul>\n<img src=\"/2023/01/30/kongzheng1993-Netty/channel.png\">\n\n\n<h3 id=\"Netty中的Reactor\"><a href=\"#Netty中的Reactor\" class=\"headerlink\" title=\"Netty中的Reactor\"></a>Netty中的Reactor</h3><p>Netty中的反映器组件有多个实现类，这些实现类与其通道类型相互匹配。对应NioSocketChannel通道，Netty的反映器类型为NioEventLoop（NIO事件轮询）。</p>\n<p>NioEventLoop类有两个重要的成员属性：</p>\n<ul>\n<li>Thread线程类型成员</li>\n<li>Java NIO选择器成员</li>\n</ul>\n<img src=\"/2023/01/30/kongzheng1993-Netty/netty_reactor\">\n\n<p>到这里可以看出，NioEventLoop和前面说的反映器思路一致：一个NioEventLoop拥有一个线程，负责一个Java NIO选择器的IO事件轮询。<br>EventLoop反映器和Channel的关系：一个EventLoop反映器和NettyChannel通道是一对多的关系：一个反映器可以注册成千上万的通道。</p>\n<img src=\"/2023/01/30/kongzheng1993-Netty/EventLoop.png\">\n\n<h3 id=\"Netty中的Handler\"><a href=\"#Netty中的Handler\" class=\"headerlink\" title=\"Netty中的Handler\"></a>Netty中的Handler</h3><p>在Netty中，EventLoop反映器内部有一个线程负责Java NIO选择器事件的轮询，然后进行对应的事件分发，事件分发（Dispatch）的目标就是Netty的Handler（含用户定义的业务处理器）。</p>\n<p>Netty的Handler分为两大类：</p>\n<ul>\n<li>ChannelInboundHandler入站处理器</li>\n<li>ChannelOutboundHandler出站处理器<br>二者都继承了ChannelHandler处理器接口。</li>\n</ul>\n<img src=\"/2023/01/30/kongzheng1993-Netty/handler.png\">\n\n<p>Netty的IO事件类型：</p>\n<ul>\n<li>可读：SelectionKey.OP_READ</li>\n<li>可写：SelectionKey.OP_WRITE</li>\n<li>连接：SelectionKey.OP_CONNECT</li>\n<li>接受：SelectionKey.OP_ACCEPT</li>\n</ul>\n<h3 id=\"Netty中的Pipeline\"><a href=\"#Netty中的Pipeline\" class=\"headerlink\" title=\"Netty中的Pipeline\"></a>Netty中的Pipeline</h3><p>Netty设计了一个特殊的组件，叫做ChannelPipeline（通道流水线）。它像一条管道，将绑定到一个通道的多个Handler处理器实例串联在一起，形成一条流水线。ChannelPipeline默认实现被设计成一个双向链表，所有Handler处理器实例被包装成双向链表的节点，被加入到ChannelPipeline中。</p>\n","site":{"data":{}},"more":"<h1 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h1><p><a href=\"https://netty.io/\" target=\"_blank\" rel=\"noopener\">Netty</a>是一个异步事件驱动的网络应用程序框架，用于快速开发可维护的高性能协议服务器和客户端。</p>\n<p>Netty是基于Java NIO（New IO）封装的，充分结合了Reactor线程模型，奖Netty变成了一个基于异步事件驱动的网络框架。</p>\n<p>为什么不用Java远程NIO？</p>\n<ol>\n<li>NIO的类库和API繁杂使用麻烦，你需要熟练掌握Selectol,ServerSocketChannel, SocketChannel,ByteBuffer 等。</li>\n<li>需妥具备其他的额外技能做制垫，例如熟悉Java 多线程编程。这是因为NIO编程涉及到Reactor 模式，你必须对多钱程和网络编程非常如悉，才能编写出高质量的NIO程序。</li>\n<li>可靠性能力补齐， 工作量和难度都非常大。例如客户端面临断连重连、网络间断、半包读写、失败缓存、网络拥塞和异常码流的处理等问题， NI0 编程的特点是功能开发相对容易，但是可靠性能力补齐的工作量和难度都非常大。</li>\n<li>JDK NIO的BUG，比如epoll bug，这个BUG会在linux上导致cpu 100%，使得nio server/client不可用，这个BUG直到jdk 6u4才解决，但是直到JDK1.7中仍然有这个问题，该问题并未被完全解决，只是发生的频率降低了而已。</li>\n</ol>\n<h1 id=\"网络\"><a href=\"#网络\" class=\"headerlink\" title=\"网络\"></a>网络</h1><h2 id=\"OSI\"><a href=\"#OSI\" class=\"headerlink\" title=\"OSI\"></a>OSI</h2><p><a href=\"https://baike.baidu.com/item/OSI%E6%A8%A1%E5%9E%8B/10119902?fr=aladdin\" target=\"_blank\" rel=\"noopener\">开放式系统互联通信参考模型</a>（英语：Open System Interconnection Reference Model，缩写为 OSI），简称为OSI模型（OSI model），一种概念模型，由国际标准化组织提出，一个试图使各种计算机在世界范围内互连为网络的标准框架。定义于ISO/IEC 7498-1。</p>\n<h2 id=\"TCP-IP\"><a href=\"#TCP-IP\" class=\"headerlink\" title=\"TCP/IP\"></a>TCP/IP</h2><p>抓包，三次握手、四次挥手</p>\n<h1 id=\"IO\"><a href=\"#IO\" class=\"headerlink\" title=\"IO\"></a>IO</h1><pre><code>任何程序都有IO，不然没有意义</code></pre><p>IO最开始的定义就是计算机的输入流和输出流。随着技术发展，IO产生了分类。分类的维度不同，比如可以从工作层面上分为磁盘IO（本地IO）和网络IO，也可以从工作模式上分为BIO、NIO、AIO。</p>\n<p>一般我们将它分成以下几类：</p>\n<ul>\n<li>BIO：同步阻塞IO</li>\n<li>NIO：同步非阻塞IO</li>\n<li>AIO：异步非阻塞IO</li>\n</ul>\n<p><strong>何为同步，何为阻塞？</strong></p>\n<p>同步/异步： 同步IO是指用户空间(进程或者线程)是主动发起IO请求的一方，系统内核是被动接收方。异步IO则反过来，系统内核是主动发起IO请求的一方，用户空间是被动接收方。 </p>\n<p>阻塞： 阻塞IO指的是需要内核IO操作彻底完成后才返回到用户空间执行用户程序的操作指令。“阻塞”指的是用户程序(发起IO请求的进程或者线程)的执行状态。可以说传统 的IO模型都是阻塞IO模型，并且在Java中默认创建的socket都属于阻塞IO模型。 </p>\n<h2 id=\"BIO-Blocking-IO\"><a href=\"#BIO-Blocking-IO\" class=\"headerlink\" title=\"BIO(Blocking IO)\"></a>BIO(Blocking IO)</h2><p>同步阻塞IO，需要内核IO操作彻底完成后，才返回用户空间执行用户的操作。</p>\n<img src=\"/2023/01/30/kongzheng1993-Netty/blockingIO.png\">\n\n<p>用户程序调用内核read后，会一直等待，直到返回数据。<br>特点就是在内核执行IO操作的两个阶段，用户线程/进程一直是阻塞的。<br>优点：程序开发简单，阻塞期间用户线程挂起，基本不会占用CPU资源。<br>缺点：一个连接就是一个线程，在高并发场景下，需要大量的线程来维护大量的网络连接，内存和线程切换的开销非常大，性能很低，基本不可用。</p>\n<h2 id=\"NIO-Non-blocking-IO\"><a href=\"#NIO-Non-blocking-IO\" class=\"headerlink\" title=\"NIO(Non-blocking IO)\"></a>NIO(Non-blocking IO)</h2><p>同步非阻塞IO，指用户空间的程序不需要等待内核IO操作彻底完成，可以立即返回用户空间执行用户的操作，用户空间的线程处于非阻塞状态。非阻塞IO要求socket被设置为NONBLOCK</p>\n<img src=\"/2023/01/30/kongzheng1993-Netty/nonBLockingIO.png\">\n\n<p>同步非阻塞IO模型中，用户程序发起read调用，如果内核数据没有准备好，内核会立即返回。用户程序为了读到数据，会一直发起系统调用，轮询数据是否准备好，直到数据返回为止。</p>\n<p>优点：每次发起IO系统调用，内核准备数据的过程中，调用会被直接返回，用户线程不会阻塞，实时性较好。</p>\n<p>缺点：不断轮询内核，将占用大量的CPU时间，效率低下。</p>\n<h2 id=\"IO多路复用\"><a href=\"#IO多路复用\" class=\"headerlink\" title=\"IO多路复用\"></a>IO多路复用</h2><p>为了避免同步非阻塞IO模型中轮询等待的问题，就有了IO多路复用模型。IO多路复用的系统调用有select、epoll等，几乎所有的操作系统都支持select，具有良好的跨平台特性。epoll是select的Linux增强版本。</p>\n<img src=\"/2023/01/30/kongzheng1993-Netty/multiplexing.png\">\n\n<img src=\"/2023/01/30/kongzheng1993-Netty/man2select.png\">\n\n<img src=\"/2023/01/30/kongzheng1993-Netty/man2kqueue.png\">\n\n<p><strong>Todo：</strong></p>\n<ul>\n<li>几种Java程序，strace 查看socket、bind、read、select、epoll_create等系统调用，观察阻塞、同步</li>\n<li>select和epoll的示意图</li>\n</ul>\n<h2 id=\"异步IO\"><a href=\"#异步IO\" class=\"headerlink\" title=\"异步IO\"></a>异步IO</h2><img src=\"/2023/01/30/kongzheng1993-Netty/asyncIO.png\">\n\n<p>用户线程通过系统调用内核注册某个IO操作，内核在整个IO操作（包括数据准备、数据复制）完成后通知用户程序，用户执行后续的业务操作。异步IO是真正的异步输入输出，它的吞吐量高于IO多路复用模型。就目前而言，Windows系统下通过IOCP实现了真正的异步IO，在Linux系统下，异步IO模型在2.6版本才引入，JDK对它的支持并不完善。<br>而大多数高并发服务器的程序都是基于Linux系统的，因此目前高并发网络应用程序的开发大多采用IO多路复用模型，大名鼎鼎的Netty框架使用的就是IO多路复用模型，而不是异步IO模型。</p>\n<h1 id=\"Netty\"><a href=\"#Netty\" class=\"headerlink\" title=\"Netty\"></a>Netty</h1><p>Netty是一个异步事件驱动的网络应用框架快速开发可维护的高性能协议服务器和客户端。<br>Netty是基于Java NIO（New IO）封装的，充分结合了Reactor线程模型，将Netty变成了一个基于异步事件驱动的网络框架。</p>\n<h2 id=\"Java-NIO和NIO\"><a href=\"#Java-NIO和NIO\" class=\"headerlink\" title=\"Java NIO和NIO\"></a>Java NIO和NIO</h2><p>Java1.4之前Java IO类库是阻塞IO，1.4版本之后引进了新的异步IO库，称为Java New IO类库缩写也就是NIO。而老的阻塞式的IO被称为Old IO，OIO。</p>\n<p>Java NIO包含以下3个核心组件：</p>\n<ul>\n<li>Channel–通道</li>\n<li>Buffer–缓冲区</li>\n<li>Selector–选择器<br>看到这三个组件，就能识别出它用的是IO多路复用模型<br>NIO和OIO的区别：</li>\n<li>OIO是面向流（Stream Oriented）的，NIO是面向缓冲区（Buffer Oriented）的。</li>\n</ul>\n<p><strong>为什么不用Java远程NIO？</strong></p>\n<ol>\n<li>NIO的类库和API繁杂使用麻烦，你需要熟练掌握Selectol,ServerSocketChannel, SocketChannel,ByteBuffer 等。</li>\n<li>需要具备其他的额外技能做制垫，例如熟悉Java 多线程编程。这是因为NIO编程涉及到Reactor 模式，你必须对多钱程和网络编程非常熟悉，才能编写出高质量的NIO程序。</li>\n<li>可靠性能力补齐， 工作量和难度都非常大。例如客户端面临断连重连、网络间断、半包读写、失败缓存、网络拥塞和异常码流的处理等问题， NI0 编程的特点是功能开发相对容易，但是可靠性能力补齐的工作量和难度都非常大。</li>\n<li>JDK NIO的BUG，比如epoll bug，这个BUG会在linux上导致cpu 100%，使得nio server/client不可用，这个BUG直到jdk 6u4才解决，但是直到JDK1.7中仍然有这个问题，该问题并未被完全解决，只是发生的频率降低了而已。</li>\n</ol>\n<h2 id=\"Reactor模式\"><a href=\"#Reactor模式\" class=\"headerlink\" title=\"Reactor模式\"></a>Reactor模式</h2><p>Netty的整体架构是基于Reactor模式的。Reactor模式由Reactor线程、Handlers处理器两大角色组成，两大角色的职责分别如下：</p>\n<ol>\n<li>Reactor线程的职责：负责响应IO时间，并且分发到Handlers处理器。</li>\n<li>Handlers处理器的职责：非阻塞的执行业务处理逻辑。</li>\n</ol>\n<img src=\"/2023/01/30/kongzheng1993-Netty/asyncIO.png\">\n\n<p>Reactor模式中IO事件的处理流程大致分为4步：</p>\n<ol>\n<li>通道注册。IO事件源于通道Channel，IO是和通道（对应于底层连接而言）强相关的。一个IO事件一定属于某个通道。如果要查询通道的事件，首先要将通道注册到选择器。</li>\n<li>查询事件。在Reactor模式中，一个线程会负责一个反映器（或者SubReactor子反映器），不断轮询，查询选择器中的IO事件（选择键）。</li>\n<li>事件分发。如果查询到了IO事件，则分发给与IO事件有绑定关系的Handler业务处理。</li>\n<li>完成真正的IO操作和业务处理，这一步由Handler业务处理器负责。</li>\n</ol>\n<p>上面第1、2步其实是Java NIO的功能，Reactor模式仅仅是利用了Java NIO的优势而已。</p>\n<h3 id=\"Netty中的Channel\"><a href=\"#Netty中的Channel\" class=\"headerlink\" title=\"Netty中的Channel\"></a>Netty中的Channel</h3><p>Netty中不直接使用Java NIO的Channel组件，对Channel组件进行 了自己的封装。Netty实现了一系列的Channel组件，为了支持多种通 信协议，换句话说，对于每一种通信连接协议，Netty都实现了自己的 通道。除了Java的NIO，Netty还提供了Java面向流的OIO处理通道。 </p>\n<p>Netty中常见的通道类型：</p>\n<ul>\n<li>NioSocketChannel：异步非阻塞TCP Socket传输通道</li>\n<li>NioServerSocketChannel：异步非阻塞TCP Socket服务端监听通道</li>\n<li>NioDatagramChannel：异步非阻塞的UDP传输通道</li>\n<li>NioSctpChannel：异步非阻塞Sctp传输通道</li>\n<li>NioSctpServerChannel：异步非阻塞Sctp服务端监听通道</li>\n<li>OioSocketChannel：同步阻塞式TCP Socket传输通道</li>\n<li>OioServerSocketChannel：同步阻塞式TCP Socket服务端监听通道</li>\n<li>OioDatagramChannel：同步阻塞式UDP传输通道</li>\n<li>OioSctpChannel：同步阻塞式Sctp传输通道</li>\n<li>OioSctpServerChannel：同步阻塞式Sctp服务端监听通道</li>\n</ul>\n<img src=\"/2023/01/30/kongzheng1993-Netty/channel.png\">\n\n\n<h3 id=\"Netty中的Reactor\"><a href=\"#Netty中的Reactor\" class=\"headerlink\" title=\"Netty中的Reactor\"></a>Netty中的Reactor</h3><p>Netty中的反映器组件有多个实现类，这些实现类与其通道类型相互匹配。对应NioSocketChannel通道，Netty的反映器类型为NioEventLoop（NIO事件轮询）。</p>\n<p>NioEventLoop类有两个重要的成员属性：</p>\n<ul>\n<li>Thread线程类型成员</li>\n<li>Java NIO选择器成员</li>\n</ul>\n<img src=\"/2023/01/30/kongzheng1993-Netty/netty_reactor\">\n\n<p>到这里可以看出，NioEventLoop和前面说的反映器思路一致：一个NioEventLoop拥有一个线程，负责一个Java NIO选择器的IO事件轮询。<br>EventLoop反映器和Channel的关系：一个EventLoop反映器和NettyChannel通道是一对多的关系：一个反映器可以注册成千上万的通道。</p>\n<img src=\"/2023/01/30/kongzheng1993-Netty/EventLoop.png\">\n\n<h3 id=\"Netty中的Handler\"><a href=\"#Netty中的Handler\" class=\"headerlink\" title=\"Netty中的Handler\"></a>Netty中的Handler</h3><p>在Netty中，EventLoop反映器内部有一个线程负责Java NIO选择器事件的轮询，然后进行对应的事件分发，事件分发（Dispatch）的目标就是Netty的Handler（含用户定义的业务处理器）。</p>\n<p>Netty的Handler分为两大类：</p>\n<ul>\n<li>ChannelInboundHandler入站处理器</li>\n<li>ChannelOutboundHandler出站处理器<br>二者都继承了ChannelHandler处理器接口。</li>\n</ul>\n<img src=\"/2023/01/30/kongzheng1993-Netty/handler.png\">\n\n<p>Netty的IO事件类型：</p>\n<ul>\n<li>可读：SelectionKey.OP_READ</li>\n<li>可写：SelectionKey.OP_WRITE</li>\n<li>连接：SelectionKey.OP_CONNECT</li>\n<li>接受：SelectionKey.OP_ACCEPT</li>\n</ul>\n<h3 id=\"Netty中的Pipeline\"><a href=\"#Netty中的Pipeline\" class=\"headerlink\" title=\"Netty中的Pipeline\"></a>Netty中的Pipeline</h3><p>Netty设计了一个特殊的组件，叫做ChannelPipeline（通道流水线）。它像一条管道，将绑定到一个通道的多个Handler处理器实例串联在一起，形成一条流水线。ChannelPipeline默认实现被设计成一个双向链表，所有Handler处理器实例被包装成双向链表的节点，被加入到ChannelPipeline中。</p>\n"},{"title":"服务日志实现方式切换引起的问题","excerpt":"","comments":1,"date":"2023-03-23T02:30:52.000Z","_content":"\n### 背景\n\n最近工程框架切换，自测过程中，发现一个返回xml接口的响应报文后面跟着一个response的json。\n\n如下图：\n<img src=\"old.png\">\n<img src=\"new.png\">\n\n代码如下：\n\n```java\n    @GetMapping(value = \"/{fileName}.xml\")\n    public Response paa(@PathVariable(\"fileName\") String fileName, HttpServletResponse response) throws IOException {\n        log.info(\"fileName={}\", fileName);\n        if(EmptyUtil.isEmpty(fileName) || !fileName.contains(\"-\")){\n            return Response.fail(StatusCode.EXCEPTION.getCode(),\"文件名不存在\");\n        }\n        fileName = fileName.replace(\".xml\", \"\").replace(\"paa-\", \"\");\n        String paaXml = pdiPaaConfigService.selectPaaXml(fileName, PaaConfigStatusEnum.PASS.getValue());\n        if(EmptyUtil.isEmpty(paaXml)){\n            return Response.fail(StatusCode.EXCEPTION.getCode(),\"请确认该版本下的xml是否已经生成\");\n        }\n        response.setCharacterEncoding(\"UTF-8\");\n        response.setContentType(ContentType.TEXT_XML.toString());\n        InputStream resourceAsStream = IOUtils.toInputStream(paaXml, StandardCharsets.UTF_8);\n        assert resourceAsStream != null;\n        byte[] buffer = new byte[1024];\n        int len = 0;\n        ServletOutputStream sos = response.getOutputStream();\n        while ((len = resourceAsStream.read(buffer)) > 0) {\n            sos.write(buffer, 0, len);\n        }\n        sos.flush();\n        sos.close();\n        return Response.success();\n    }\n```\n\n\n查看代码后可以发现，最后却是是返回了一个`Response.success()`，但是这个接口是想直接操作response的输出流，将xml内容返回。\n\n\n### 分析\n\n第一反应肯定是SpringMVC的MessageConverter。\n\n从`org.springframework.web.servlet.DispatcherServlet#doDispatch`一路向北，在`org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod#invokeAndHandle`，如果returnValue（也就是上门的Response.success()）不为空，会通过`org.springframework.web.method.support.HandlerMethodReturnValueHandlerComposite#handleReturnValue`处理returnValue。\n\n```java\n\t/**\n\t * Invoke the method and handle the return value through one of the\n\t * configured {@link HandlerMethodReturnValueHandler}s.\n\t * @param webRequest the current request\n\t * @param mavContainer the ModelAndViewContainer for this request\n\t * @param providedArgs \"given\" arguments matched by type (not resolved)\n\t */\n\tpublic void invokeAndHandle(ServletWebRequest webRequest, ModelAndViewContainer mavContainer,\n\t\t\tObject... providedArgs) throws Exception {\n\n\t\tObject returnValue = invokeForRequest(webRequest, mavContainer, providedArgs);\n\t\tsetResponseStatus(webRequest);\n\n\t\tif (returnValue == null) {\n\t\t\tif (isRequestNotModified(webRequest) || getResponseStatus() != null || mavContainer.isRequestHandled()) {\n\t\t\t\tmavContainer.setRequestHandled(true);\n\t\t\t\treturn;\n\t\t\t}\n\t\t}\n\t\telse if (StringUtils.hasText(getResponseStatusReason())) {\n\t\t\tmavContainer.setRequestHandled(true);\n\t\t\treturn;\n\t\t}\n\n\t\tmavContainer.setRequestHandled(false);\n\t\tAssert.state(this.returnValueHandlers != null, \"No return value handlers\");\n\t\ttry {\n\t\t\tthis.returnValueHandlers.handleReturnValue(\n\t\t\t\t\treturnValue, getReturnValueType(returnValue), mavContainer, webRequest);\n\t\t}\n\t\tcatch (Exception ex) {\n\t\t\tif (logger.isTraceEnabled()) {\n\t\t\t\tlogger.trace(getReturnValueHandlingErrorMessage(\"Error handling return value\", returnValue), ex);\n\t\t\t}\n\t\t\tthrow ex;\n\t\t}\n\t}\n```\n\nhandleReturnValue里会调用`org.springframework.web.servlet.mvc.method.annotation.AbstractMessageConverterMethodProcessor#writeWithMessageConverters(T, org.springframework.core.MethodParameter, org.springframework.http.server.ServletServerHttpRequest, org.springframework.http.server.ServletServerHttpResponse)`，遍历合适的MessageConverter来处理，最后就是把returnValue写到Response的body中，也就是追加到我们的xml后面了。\n\n到这里我觉得，问题不在这里了，因为MessageConverter的处理都是一样的，将返回值写入Response的body里很正常，之前为啥没事儿呢？\n\n这时候注意到这里的`HttpServletResponse`实现类是`ContentCachingResponseWrapper`，而老版本里是`ResponseFacade`。通过debug堆栈往前找，一直到一个类`public class LoggerFilter extends OncePerRequestFilter`，发现里面有这样的代码：\n\n```java\nContentCachingRequestWrapper requestWrapper = new ContentCachingRequestWrapper(request);\nContentCachingResponseWrapper responseWrapper = new ContentCachingResponseWrapper(response);\n```\n\n去`ContentCachingRequestWrapper`看了一下：\n\n```java\n\n/**\n * {@link javax.servlet.http.HttpServletRequest} wrapper that caches all content read from\n * the {@linkplain #getInputStream() input stream} and {@linkplain #getReader() reader},\n * and allows this content to be retrieved via a {@link #getContentAsByteArray() byte array}.\n *\n * <p>Used e.g. by {@link org.springframework.web.filter.AbstractRequestLoggingFilter}.\n * Note: As of Spring Framework 5.0, this wrapper is built on the Servlet 3.1 API.\n *\n * @author Juergen Hoeller\n * @author Brian Clozel\n * @since 4.1.3\n * @see ContentCachingResponseWrapper\n */\npublic class ContentCachingRequestWrapper extends HttpServletRequestWrapper\n```\n\n注释中可以看到，这个包装类是为了方便读取Response的信息，而将`ServletInputStream`中的数据cache下来，以实现流中的数据重复读取。里面一个核心的方法就是：\n\n```java\n\t/**\n\t * Copy the cached body content to the response.\n\t * @param complete whether to set a corresponding content length\n\t * for the complete cached body content\n\t * @since 4.2\n\t */\n\tprotected void copyBodyToResponse(boolean complete) throws IOException {\n\t\tif (this.content.size() > 0) {\n\t\t\tHttpServletResponse rawResponse = (HttpServletResponse) getResponse();\n\t\t\tif ((complete || this.contentLength != null) && !rawResponse.isCommitted()) {\n\t\t\t\trawResponse.setContentLength(complete ? this.content.size() : this.contentLength);\n\t\t\t\tthis.contentLength = null;\n\t\t\t}\n\t\t\tthis.content.writeTo(rawResponse.getOutputStream());\n\t\t\tthis.content.reset();\n\t\t\tif (complete) {\n\t\t\t\tsuper.flushBuffer();\n\t\t\t}\n\t\t}\n\t}\n```\n\n\n看到这里回想到老版本的日志呢？是怎么实现的？难道不需要去读取Resposne流中的数据吗？\n\n\n一看还真是：\n\n```java\n@Slf4j\n@Component\n@Aspect\n@Order(Ordered.HIGHEST_PRECEDENCE)\npublic class ServiceLogAspect {\n    ......\n        @Around(\"@within(org.springframework.stereotype.Controller) || @within(org.springframework.web.bind.annotation.RestController)\")\n    public Object around(ProceedingJoinPoint pjp) throws Throwable {\n        HttpServletRequest request = ServletContextHolder.getRequest();\n        if (Objects.isNull(request)) {\n            return pjp.proceed();\n        }\n}\n\n```\n\n老版本的日志是通过切面，打印的也只是Controller和RestController中方法的参数和返回值。相比之下，新版本打印Request和Resposne的内容，更底层，更真实。\n\n在MessageConverter将returnValue写入到`resposne.getBody()`中没问题，重点是新老版本的respose不同，一个是`ContentCachingRequestWrapper`，一个是`ResponseFacade`。\n\n下面是`ServletServerHttpResponse`的getBody()方法：\n\n```java\n\t@Override\n\tpublic OutputStream getBody() throws IOException {\n\t\tthis.bodyUsed = true;\n\t\twriteHeaders();\n\t\treturn this.servletResponse.getOutputStream();\n\t}\n```\n\n可以了解到就是返回对应的resposne的outputStream。而新旧版本的serveletResponse实现不同。\n\nResposneFacade就是返回真实的outputStream，而ContentCachingRequestWrapper则会返回一个包装的流`ResponseServletOutputStream`\n\n```java\n\t@Override\n\tpublic ServletOutputStream getOutputStream() throws IOException {\n\t\tif (this.outputStream == null) {\n\t\t\tthis.outputStream = new ResponseServletOutputStream(getResponse().getOutputStream());\n\t\t}\n\t\treturn this.outputStream;\n\t}\n```\n\n### 真因\n\n一个是真实的Resposne的流，另一个是假冒的流。再回到一开始业务代码，获取response的outputStream，然后写入xml数据，接着flush，最后close。重点就是这个close的是哪个流？\n\n**老版本关闭的是真实的流，所以后面Response.success()并没有返回给客户端，因为流已经关闭了！而新版本关闭的并不是真实的response流，导致http链接还未断开，后面的Response.sucess()又经过MessageConverter写到了response的outputStream中，使得客户端接收到**\n\n\n### 总结\n\n通过这次分析，了解到了`org.springframework.web.util.ContentCachingResponseWrapper`这样一个Response的包装类，可以重复读取数据流，以后有相关需求可以用一下。","source":"_posts/2023-03-23-kongzheng1993-服务日志实现方式切换引起的问题.md","raw":"---\ntitle: 服务日志实现方式切换引起的问题\nexcerpt: 'log aspect filter'\ntags: [SpringMVC, Logger]\ncategories: [SpringMVC, Logger]\ncomments: true\ndate: 2023-03-23 10:30:52\n---\n\n### 背景\n\n最近工程框架切换，自测过程中，发现一个返回xml接口的响应报文后面跟着一个response的json。\n\n如下图：\n<img src=\"old.png\">\n<img src=\"new.png\">\n\n代码如下：\n\n```java\n    @GetMapping(value = \"/{fileName}.xml\")\n    public Response paa(@PathVariable(\"fileName\") String fileName, HttpServletResponse response) throws IOException {\n        log.info(\"fileName={}\", fileName);\n        if(EmptyUtil.isEmpty(fileName) || !fileName.contains(\"-\")){\n            return Response.fail(StatusCode.EXCEPTION.getCode(),\"文件名不存在\");\n        }\n        fileName = fileName.replace(\".xml\", \"\").replace(\"paa-\", \"\");\n        String paaXml = pdiPaaConfigService.selectPaaXml(fileName, PaaConfigStatusEnum.PASS.getValue());\n        if(EmptyUtil.isEmpty(paaXml)){\n            return Response.fail(StatusCode.EXCEPTION.getCode(),\"请确认该版本下的xml是否已经生成\");\n        }\n        response.setCharacterEncoding(\"UTF-8\");\n        response.setContentType(ContentType.TEXT_XML.toString());\n        InputStream resourceAsStream = IOUtils.toInputStream(paaXml, StandardCharsets.UTF_8);\n        assert resourceAsStream != null;\n        byte[] buffer = new byte[1024];\n        int len = 0;\n        ServletOutputStream sos = response.getOutputStream();\n        while ((len = resourceAsStream.read(buffer)) > 0) {\n            sos.write(buffer, 0, len);\n        }\n        sos.flush();\n        sos.close();\n        return Response.success();\n    }\n```\n\n\n查看代码后可以发现，最后却是是返回了一个`Response.success()`，但是这个接口是想直接操作response的输出流，将xml内容返回。\n\n\n### 分析\n\n第一反应肯定是SpringMVC的MessageConverter。\n\n从`org.springframework.web.servlet.DispatcherServlet#doDispatch`一路向北，在`org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod#invokeAndHandle`，如果returnValue（也就是上门的Response.success()）不为空，会通过`org.springframework.web.method.support.HandlerMethodReturnValueHandlerComposite#handleReturnValue`处理returnValue。\n\n```java\n\t/**\n\t * Invoke the method and handle the return value through one of the\n\t * configured {@link HandlerMethodReturnValueHandler}s.\n\t * @param webRequest the current request\n\t * @param mavContainer the ModelAndViewContainer for this request\n\t * @param providedArgs \"given\" arguments matched by type (not resolved)\n\t */\n\tpublic void invokeAndHandle(ServletWebRequest webRequest, ModelAndViewContainer mavContainer,\n\t\t\tObject... providedArgs) throws Exception {\n\n\t\tObject returnValue = invokeForRequest(webRequest, mavContainer, providedArgs);\n\t\tsetResponseStatus(webRequest);\n\n\t\tif (returnValue == null) {\n\t\t\tif (isRequestNotModified(webRequest) || getResponseStatus() != null || mavContainer.isRequestHandled()) {\n\t\t\t\tmavContainer.setRequestHandled(true);\n\t\t\t\treturn;\n\t\t\t}\n\t\t}\n\t\telse if (StringUtils.hasText(getResponseStatusReason())) {\n\t\t\tmavContainer.setRequestHandled(true);\n\t\t\treturn;\n\t\t}\n\n\t\tmavContainer.setRequestHandled(false);\n\t\tAssert.state(this.returnValueHandlers != null, \"No return value handlers\");\n\t\ttry {\n\t\t\tthis.returnValueHandlers.handleReturnValue(\n\t\t\t\t\treturnValue, getReturnValueType(returnValue), mavContainer, webRequest);\n\t\t}\n\t\tcatch (Exception ex) {\n\t\t\tif (logger.isTraceEnabled()) {\n\t\t\t\tlogger.trace(getReturnValueHandlingErrorMessage(\"Error handling return value\", returnValue), ex);\n\t\t\t}\n\t\t\tthrow ex;\n\t\t}\n\t}\n```\n\nhandleReturnValue里会调用`org.springframework.web.servlet.mvc.method.annotation.AbstractMessageConverterMethodProcessor#writeWithMessageConverters(T, org.springframework.core.MethodParameter, org.springframework.http.server.ServletServerHttpRequest, org.springframework.http.server.ServletServerHttpResponse)`，遍历合适的MessageConverter来处理，最后就是把returnValue写到Response的body中，也就是追加到我们的xml后面了。\n\n到这里我觉得，问题不在这里了，因为MessageConverter的处理都是一样的，将返回值写入Response的body里很正常，之前为啥没事儿呢？\n\n这时候注意到这里的`HttpServletResponse`实现类是`ContentCachingResponseWrapper`，而老版本里是`ResponseFacade`。通过debug堆栈往前找，一直到一个类`public class LoggerFilter extends OncePerRequestFilter`，发现里面有这样的代码：\n\n```java\nContentCachingRequestWrapper requestWrapper = new ContentCachingRequestWrapper(request);\nContentCachingResponseWrapper responseWrapper = new ContentCachingResponseWrapper(response);\n```\n\n去`ContentCachingRequestWrapper`看了一下：\n\n```java\n\n/**\n * {@link javax.servlet.http.HttpServletRequest} wrapper that caches all content read from\n * the {@linkplain #getInputStream() input stream} and {@linkplain #getReader() reader},\n * and allows this content to be retrieved via a {@link #getContentAsByteArray() byte array}.\n *\n * <p>Used e.g. by {@link org.springframework.web.filter.AbstractRequestLoggingFilter}.\n * Note: As of Spring Framework 5.0, this wrapper is built on the Servlet 3.1 API.\n *\n * @author Juergen Hoeller\n * @author Brian Clozel\n * @since 4.1.3\n * @see ContentCachingResponseWrapper\n */\npublic class ContentCachingRequestWrapper extends HttpServletRequestWrapper\n```\n\n注释中可以看到，这个包装类是为了方便读取Response的信息，而将`ServletInputStream`中的数据cache下来，以实现流中的数据重复读取。里面一个核心的方法就是：\n\n```java\n\t/**\n\t * Copy the cached body content to the response.\n\t * @param complete whether to set a corresponding content length\n\t * for the complete cached body content\n\t * @since 4.2\n\t */\n\tprotected void copyBodyToResponse(boolean complete) throws IOException {\n\t\tif (this.content.size() > 0) {\n\t\t\tHttpServletResponse rawResponse = (HttpServletResponse) getResponse();\n\t\t\tif ((complete || this.contentLength != null) && !rawResponse.isCommitted()) {\n\t\t\t\trawResponse.setContentLength(complete ? this.content.size() : this.contentLength);\n\t\t\t\tthis.contentLength = null;\n\t\t\t}\n\t\t\tthis.content.writeTo(rawResponse.getOutputStream());\n\t\t\tthis.content.reset();\n\t\t\tif (complete) {\n\t\t\t\tsuper.flushBuffer();\n\t\t\t}\n\t\t}\n\t}\n```\n\n\n看到这里回想到老版本的日志呢？是怎么实现的？难道不需要去读取Resposne流中的数据吗？\n\n\n一看还真是：\n\n```java\n@Slf4j\n@Component\n@Aspect\n@Order(Ordered.HIGHEST_PRECEDENCE)\npublic class ServiceLogAspect {\n    ......\n        @Around(\"@within(org.springframework.stereotype.Controller) || @within(org.springframework.web.bind.annotation.RestController)\")\n    public Object around(ProceedingJoinPoint pjp) throws Throwable {\n        HttpServletRequest request = ServletContextHolder.getRequest();\n        if (Objects.isNull(request)) {\n            return pjp.proceed();\n        }\n}\n\n```\n\n老版本的日志是通过切面，打印的也只是Controller和RestController中方法的参数和返回值。相比之下，新版本打印Request和Resposne的内容，更底层，更真实。\n\n在MessageConverter将returnValue写入到`resposne.getBody()`中没问题，重点是新老版本的respose不同，一个是`ContentCachingRequestWrapper`，一个是`ResponseFacade`。\n\n下面是`ServletServerHttpResponse`的getBody()方法：\n\n```java\n\t@Override\n\tpublic OutputStream getBody() throws IOException {\n\t\tthis.bodyUsed = true;\n\t\twriteHeaders();\n\t\treturn this.servletResponse.getOutputStream();\n\t}\n```\n\n可以了解到就是返回对应的resposne的outputStream。而新旧版本的serveletResponse实现不同。\n\nResposneFacade就是返回真实的outputStream，而ContentCachingRequestWrapper则会返回一个包装的流`ResponseServletOutputStream`\n\n```java\n\t@Override\n\tpublic ServletOutputStream getOutputStream() throws IOException {\n\t\tif (this.outputStream == null) {\n\t\t\tthis.outputStream = new ResponseServletOutputStream(getResponse().getOutputStream());\n\t\t}\n\t\treturn this.outputStream;\n\t}\n```\n\n### 真因\n\n一个是真实的Resposne的流，另一个是假冒的流。再回到一开始业务代码，获取response的outputStream，然后写入xml数据，接着flush，最后close。重点就是这个close的是哪个流？\n\n**老版本关闭的是真实的流，所以后面Response.success()并没有返回给客户端，因为流已经关闭了！而新版本关闭的并不是真实的response流，导致http链接还未断开，后面的Response.sucess()又经过MessageConverter写到了response的outputStream中，使得客户端接收到**\n\n\n### 总结\n\n通过这次分析，了解到了`org.springframework.web.util.ContentCachingResponseWrapper`这样一个Response的包装类，可以重复读取数据流，以后有相关需求可以用一下。","slug":"kongzheng1993-服务日志实现方式切换引起的问题","published":1,"updated":"2023-03-23T07:30:10.999Z","layout":"post","photos":[],"link":"","_id":"clg0k2ard00ijt26fxbpizrtx","content":"<h3 id=\"背景\"><a href=\"#背景\" class=\"headerlink\" title=\"背景\"></a>背景</h3><p>最近工程框架切换，自测过程中，发现一个返回xml接口的响应报文后面跟着一个response的json。</p>\n<p>如下图：<br><img src=\"/2023/03/23/kongzheng1993-服务日志实现方式切换引起的问题/old.png\"><br><img src=\"/2023/03/23/kongzheng1993-服务日志实现方式切换引起的问题/new.png\"></p>\n<p>代码如下：</p>\n<pre><code class=\"java\">    @GetMapping(value = &quot;/{fileName}.xml&quot;)\n    public Response paa(@PathVariable(&quot;fileName&quot;) String fileName, HttpServletResponse response) throws IOException {\n        log.info(&quot;fileName={}&quot;, fileName);\n        if(EmptyUtil.isEmpty(fileName) || !fileName.contains(&quot;-&quot;)){\n            return Response.fail(StatusCode.EXCEPTION.getCode(),&quot;文件名不存在&quot;);\n        }\n        fileName = fileName.replace(&quot;.xml&quot;, &quot;&quot;).replace(&quot;paa-&quot;, &quot;&quot;);\n        String paaXml = pdiPaaConfigService.selectPaaXml(fileName, PaaConfigStatusEnum.PASS.getValue());\n        if(EmptyUtil.isEmpty(paaXml)){\n            return Response.fail(StatusCode.EXCEPTION.getCode(),&quot;请确认该版本下的xml是否已经生成&quot;);\n        }\n        response.setCharacterEncoding(&quot;UTF-8&quot;);\n        response.setContentType(ContentType.TEXT_XML.toString());\n        InputStream resourceAsStream = IOUtils.toInputStream(paaXml, StandardCharsets.UTF_8);\n        assert resourceAsStream != null;\n        byte[] buffer = new byte[1024];\n        int len = 0;\n        ServletOutputStream sos = response.getOutputStream();\n        while ((len = resourceAsStream.read(buffer)) &gt; 0) {\n            sos.write(buffer, 0, len);\n        }\n        sos.flush();\n        sos.close();\n        return Response.success();\n    }</code></pre>\n<p>查看代码后可以发现，最后却是是返回了一个<code>Response.success()</code>，但是这个接口是想直接操作response的输出流，将xml内容返回。</p>\n<h3 id=\"分析\"><a href=\"#分析\" class=\"headerlink\" title=\"分析\"></a>分析</h3><p>第一反应肯定是SpringMVC的MessageConverter。</p>\n<p>从<code>org.springframework.web.servlet.DispatcherServlet#doDispatch</code>一路向北，在<code>org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod#invokeAndHandle</code>，如果returnValue（也就是上门的Response.success()）不为空，会通过<code>org.springframework.web.method.support.HandlerMethodReturnValueHandlerComposite#handleReturnValue</code>处理returnValue。</p>\n<pre><code class=\"java\">    /**\n     * Invoke the method and handle the return value through one of the\n     * configured {@link HandlerMethodReturnValueHandler}s.\n     * @param webRequest the current request\n     * @param mavContainer the ModelAndViewContainer for this request\n     * @param providedArgs &quot;given&quot; arguments matched by type (not resolved)\n     */\n    public void invokeAndHandle(ServletWebRequest webRequest, ModelAndViewContainer mavContainer,\n            Object... providedArgs) throws Exception {\n\n        Object returnValue = invokeForRequest(webRequest, mavContainer, providedArgs);\n        setResponseStatus(webRequest);\n\n        if (returnValue == null) {\n            if (isRequestNotModified(webRequest) || getResponseStatus() != null || mavContainer.isRequestHandled()) {\n                mavContainer.setRequestHandled(true);\n                return;\n            }\n        }\n        else if (StringUtils.hasText(getResponseStatusReason())) {\n            mavContainer.setRequestHandled(true);\n            return;\n        }\n\n        mavContainer.setRequestHandled(false);\n        Assert.state(this.returnValueHandlers != null, &quot;No return value handlers&quot;);\n        try {\n            this.returnValueHandlers.handleReturnValue(\n                    returnValue, getReturnValueType(returnValue), mavContainer, webRequest);\n        }\n        catch (Exception ex) {\n            if (logger.isTraceEnabled()) {\n                logger.trace(getReturnValueHandlingErrorMessage(&quot;Error handling return value&quot;, returnValue), ex);\n            }\n            throw ex;\n        }\n    }</code></pre>\n<p>handleReturnValue里会调用<code>org.springframework.web.servlet.mvc.method.annotation.AbstractMessageConverterMethodProcessor#writeWithMessageConverters(T, org.springframework.core.MethodParameter, org.springframework.http.server.ServletServerHttpRequest, org.springframework.http.server.ServletServerHttpResponse)</code>，遍历合适的MessageConverter来处理，最后就是把returnValue写到Response的body中，也就是追加到我们的xml后面了。</p>\n<p>到这里我觉得，问题不在这里了，因为MessageConverter的处理都是一样的，将返回值写入Response的body里很正常，之前为啥没事儿呢？</p>\n<p>这时候注意到这里的<code>HttpServletResponse</code>实现类是<code>ContentCachingResponseWrapper</code>，而老版本里是<code>ResponseFacade</code>。通过debug堆栈往前找，一直到一个类<code>public class LoggerFilter extends OncePerRequestFilter</code>，发现里面有这样的代码：</p>\n<pre><code class=\"java\">ContentCachingRequestWrapper requestWrapper = new ContentCachingRequestWrapper(request);\nContentCachingResponseWrapper responseWrapper = new ContentCachingResponseWrapper(response);</code></pre>\n<p>去<code>ContentCachingRequestWrapper</code>看了一下：</p>\n<pre><code class=\"java\">\n/**\n * {@link javax.servlet.http.HttpServletRequest} wrapper that caches all content read from\n * the {@linkplain #getInputStream() input stream} and {@linkplain #getReader() reader},\n * and allows this content to be retrieved via a {@link #getContentAsByteArray() byte array}.\n *\n * &lt;p&gt;Used e.g. by {@link org.springframework.web.filter.AbstractRequestLoggingFilter}.\n * Note: As of Spring Framework 5.0, this wrapper is built on the Servlet 3.1 API.\n *\n * @author Juergen Hoeller\n * @author Brian Clozel\n * @since 4.1.3\n * @see ContentCachingResponseWrapper\n */\npublic class ContentCachingRequestWrapper extends HttpServletRequestWrapper</code></pre>\n<p>注释中可以看到，这个包装类是为了方便读取Response的信息，而将<code>ServletInputStream</code>中的数据cache下来，以实现流中的数据重复读取。里面一个核心的方法就是：</p>\n<pre><code class=\"java\">    /**\n     * Copy the cached body content to the response.\n     * @param complete whether to set a corresponding content length\n     * for the complete cached body content\n     * @since 4.2\n     */\n    protected void copyBodyToResponse(boolean complete) throws IOException {\n        if (this.content.size() &gt; 0) {\n            HttpServletResponse rawResponse = (HttpServletResponse) getResponse();\n            if ((complete || this.contentLength != null) &amp;&amp; !rawResponse.isCommitted()) {\n                rawResponse.setContentLength(complete ? this.content.size() : this.contentLength);\n                this.contentLength = null;\n            }\n            this.content.writeTo(rawResponse.getOutputStream());\n            this.content.reset();\n            if (complete) {\n                super.flushBuffer();\n            }\n        }\n    }</code></pre>\n<p>看到这里回想到老版本的日志呢？是怎么实现的？难道不需要去读取Resposne流中的数据吗？</p>\n<p>一看还真是：</p>\n<pre><code class=\"java\">@Slf4j\n@Component\n@Aspect\n@Order(Ordered.HIGHEST_PRECEDENCE)\npublic class ServiceLogAspect {\n    ......\n        @Around(&quot;@within(org.springframework.stereotype.Controller) || @within(org.springframework.web.bind.annotation.RestController)&quot;)\n    public Object around(ProceedingJoinPoint pjp) throws Throwable {\n        HttpServletRequest request = ServletContextHolder.getRequest();\n        if (Objects.isNull(request)) {\n            return pjp.proceed();\n        }\n}\n</code></pre>\n<p>老版本的日志是通过切面，打印的也只是Controller和RestController中方法的参数和返回值。相比之下，新版本打印Request和Resposne的内容，更底层，更真实。</p>\n<p>在MessageConverter将returnValue写入到<code>resposne.getBody()</code>中没问题，重点是新老版本的respose不同，一个是<code>ContentCachingRequestWrapper</code>，一个是<code>ResponseFacade</code>。</p>\n<p>下面是<code>ServletServerHttpResponse</code>的getBody()方法：</p>\n<pre><code class=\"java\">    @Override\n    public OutputStream getBody() throws IOException {\n        this.bodyUsed = true;\n        writeHeaders();\n        return this.servletResponse.getOutputStream();\n    }</code></pre>\n<p>可以了解到就是返回对应的resposne的outputStream。而新旧版本的serveletResponse实现不同。</p>\n<p>ResposneFacade就是返回真实的outputStream，而ContentCachingRequestWrapper则会返回一个包装的流<code>ResponseServletOutputStream</code></p>\n<pre><code class=\"java\">    @Override\n    public ServletOutputStream getOutputStream() throws IOException {\n        if (this.outputStream == null) {\n            this.outputStream = new ResponseServletOutputStream(getResponse().getOutputStream());\n        }\n        return this.outputStream;\n    }</code></pre>\n<h3 id=\"真因\"><a href=\"#真因\" class=\"headerlink\" title=\"真因\"></a>真因</h3><p>一个是真实的Resposne的流，另一个是假冒的流。再回到一开始业务代码，获取response的outputStream，然后写入xml数据，接着flush，最后close。重点就是这个close的是哪个流？</p>\n<p><strong>老版本关闭的是真实的流，所以后面Response.success()并没有返回给客户端，因为流已经关闭了！而新版本关闭的并不是真实的response流，导致http链接还未断开，后面的Response.sucess()又经过MessageConverter写到了response的outputStream中，使得客户端接收到</strong></p>\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3><p>通过这次分析，了解到了<code>org.springframework.web.util.ContentCachingResponseWrapper</code>这样一个Response的包装类，可以重复读取数据流，以后有相关需求可以用一下。</p>\n","site":{"data":{}},"more":"<h3 id=\"背景\"><a href=\"#背景\" class=\"headerlink\" title=\"背景\"></a>背景</h3><p>最近工程框架切换，自测过程中，发现一个返回xml接口的响应报文后面跟着一个response的json。</p>\n<p>如下图：<br><img src=\"/2023/03/23/kongzheng1993-服务日志实现方式切换引起的问题/old.png\"><br><img src=\"/2023/03/23/kongzheng1993-服务日志实现方式切换引起的问题/new.png\"></p>\n<p>代码如下：</p>\n<pre><code class=\"java\">    @GetMapping(value = &quot;/{fileName}.xml&quot;)\n    public Response paa(@PathVariable(&quot;fileName&quot;) String fileName, HttpServletResponse response) throws IOException {\n        log.info(&quot;fileName={}&quot;, fileName);\n        if(EmptyUtil.isEmpty(fileName) || !fileName.contains(&quot;-&quot;)){\n            return Response.fail(StatusCode.EXCEPTION.getCode(),&quot;文件名不存在&quot;);\n        }\n        fileName = fileName.replace(&quot;.xml&quot;, &quot;&quot;).replace(&quot;paa-&quot;, &quot;&quot;);\n        String paaXml = pdiPaaConfigService.selectPaaXml(fileName, PaaConfigStatusEnum.PASS.getValue());\n        if(EmptyUtil.isEmpty(paaXml)){\n            return Response.fail(StatusCode.EXCEPTION.getCode(),&quot;请确认该版本下的xml是否已经生成&quot;);\n        }\n        response.setCharacterEncoding(&quot;UTF-8&quot;);\n        response.setContentType(ContentType.TEXT_XML.toString());\n        InputStream resourceAsStream = IOUtils.toInputStream(paaXml, StandardCharsets.UTF_8);\n        assert resourceAsStream != null;\n        byte[] buffer = new byte[1024];\n        int len = 0;\n        ServletOutputStream sos = response.getOutputStream();\n        while ((len = resourceAsStream.read(buffer)) &gt; 0) {\n            sos.write(buffer, 0, len);\n        }\n        sos.flush();\n        sos.close();\n        return Response.success();\n    }</code></pre>\n<p>查看代码后可以发现，最后却是是返回了一个<code>Response.success()</code>，但是这个接口是想直接操作response的输出流，将xml内容返回。</p>\n<h3 id=\"分析\"><a href=\"#分析\" class=\"headerlink\" title=\"分析\"></a>分析</h3><p>第一反应肯定是SpringMVC的MessageConverter。</p>\n<p>从<code>org.springframework.web.servlet.DispatcherServlet#doDispatch</code>一路向北，在<code>org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod#invokeAndHandle</code>，如果returnValue（也就是上门的Response.success()）不为空，会通过<code>org.springframework.web.method.support.HandlerMethodReturnValueHandlerComposite#handleReturnValue</code>处理returnValue。</p>\n<pre><code class=\"java\">    /**\n     * Invoke the method and handle the return value through one of the\n     * configured {@link HandlerMethodReturnValueHandler}s.\n     * @param webRequest the current request\n     * @param mavContainer the ModelAndViewContainer for this request\n     * @param providedArgs &quot;given&quot; arguments matched by type (not resolved)\n     */\n    public void invokeAndHandle(ServletWebRequest webRequest, ModelAndViewContainer mavContainer,\n            Object... providedArgs) throws Exception {\n\n        Object returnValue = invokeForRequest(webRequest, mavContainer, providedArgs);\n        setResponseStatus(webRequest);\n\n        if (returnValue == null) {\n            if (isRequestNotModified(webRequest) || getResponseStatus() != null || mavContainer.isRequestHandled()) {\n                mavContainer.setRequestHandled(true);\n                return;\n            }\n        }\n        else if (StringUtils.hasText(getResponseStatusReason())) {\n            mavContainer.setRequestHandled(true);\n            return;\n        }\n\n        mavContainer.setRequestHandled(false);\n        Assert.state(this.returnValueHandlers != null, &quot;No return value handlers&quot;);\n        try {\n            this.returnValueHandlers.handleReturnValue(\n                    returnValue, getReturnValueType(returnValue), mavContainer, webRequest);\n        }\n        catch (Exception ex) {\n            if (logger.isTraceEnabled()) {\n                logger.trace(getReturnValueHandlingErrorMessage(&quot;Error handling return value&quot;, returnValue), ex);\n            }\n            throw ex;\n        }\n    }</code></pre>\n<p>handleReturnValue里会调用<code>org.springframework.web.servlet.mvc.method.annotation.AbstractMessageConverterMethodProcessor#writeWithMessageConverters(T, org.springframework.core.MethodParameter, org.springframework.http.server.ServletServerHttpRequest, org.springframework.http.server.ServletServerHttpResponse)</code>，遍历合适的MessageConverter来处理，最后就是把returnValue写到Response的body中，也就是追加到我们的xml后面了。</p>\n<p>到这里我觉得，问题不在这里了，因为MessageConverter的处理都是一样的，将返回值写入Response的body里很正常，之前为啥没事儿呢？</p>\n<p>这时候注意到这里的<code>HttpServletResponse</code>实现类是<code>ContentCachingResponseWrapper</code>，而老版本里是<code>ResponseFacade</code>。通过debug堆栈往前找，一直到一个类<code>public class LoggerFilter extends OncePerRequestFilter</code>，发现里面有这样的代码：</p>\n<pre><code class=\"java\">ContentCachingRequestWrapper requestWrapper = new ContentCachingRequestWrapper(request);\nContentCachingResponseWrapper responseWrapper = new ContentCachingResponseWrapper(response);</code></pre>\n<p>去<code>ContentCachingRequestWrapper</code>看了一下：</p>\n<pre><code class=\"java\">\n/**\n * {@link javax.servlet.http.HttpServletRequest} wrapper that caches all content read from\n * the {@linkplain #getInputStream() input stream} and {@linkplain #getReader() reader},\n * and allows this content to be retrieved via a {@link #getContentAsByteArray() byte array}.\n *\n * &lt;p&gt;Used e.g. by {@link org.springframework.web.filter.AbstractRequestLoggingFilter}.\n * Note: As of Spring Framework 5.0, this wrapper is built on the Servlet 3.1 API.\n *\n * @author Juergen Hoeller\n * @author Brian Clozel\n * @since 4.1.3\n * @see ContentCachingResponseWrapper\n */\npublic class ContentCachingRequestWrapper extends HttpServletRequestWrapper</code></pre>\n<p>注释中可以看到，这个包装类是为了方便读取Response的信息，而将<code>ServletInputStream</code>中的数据cache下来，以实现流中的数据重复读取。里面一个核心的方法就是：</p>\n<pre><code class=\"java\">    /**\n     * Copy the cached body content to the response.\n     * @param complete whether to set a corresponding content length\n     * for the complete cached body content\n     * @since 4.2\n     */\n    protected void copyBodyToResponse(boolean complete) throws IOException {\n        if (this.content.size() &gt; 0) {\n            HttpServletResponse rawResponse = (HttpServletResponse) getResponse();\n            if ((complete || this.contentLength != null) &amp;&amp; !rawResponse.isCommitted()) {\n                rawResponse.setContentLength(complete ? this.content.size() : this.contentLength);\n                this.contentLength = null;\n            }\n            this.content.writeTo(rawResponse.getOutputStream());\n            this.content.reset();\n            if (complete) {\n                super.flushBuffer();\n            }\n        }\n    }</code></pre>\n<p>看到这里回想到老版本的日志呢？是怎么实现的？难道不需要去读取Resposne流中的数据吗？</p>\n<p>一看还真是：</p>\n<pre><code class=\"java\">@Slf4j\n@Component\n@Aspect\n@Order(Ordered.HIGHEST_PRECEDENCE)\npublic class ServiceLogAspect {\n    ......\n        @Around(&quot;@within(org.springframework.stereotype.Controller) || @within(org.springframework.web.bind.annotation.RestController)&quot;)\n    public Object around(ProceedingJoinPoint pjp) throws Throwable {\n        HttpServletRequest request = ServletContextHolder.getRequest();\n        if (Objects.isNull(request)) {\n            return pjp.proceed();\n        }\n}\n</code></pre>\n<p>老版本的日志是通过切面，打印的也只是Controller和RestController中方法的参数和返回值。相比之下，新版本打印Request和Resposne的内容，更底层，更真实。</p>\n<p>在MessageConverter将returnValue写入到<code>resposne.getBody()</code>中没问题，重点是新老版本的respose不同，一个是<code>ContentCachingRequestWrapper</code>，一个是<code>ResponseFacade</code>。</p>\n<p>下面是<code>ServletServerHttpResponse</code>的getBody()方法：</p>\n<pre><code class=\"java\">    @Override\n    public OutputStream getBody() throws IOException {\n        this.bodyUsed = true;\n        writeHeaders();\n        return this.servletResponse.getOutputStream();\n    }</code></pre>\n<p>可以了解到就是返回对应的resposne的outputStream。而新旧版本的serveletResponse实现不同。</p>\n<p>ResposneFacade就是返回真实的outputStream，而ContentCachingRequestWrapper则会返回一个包装的流<code>ResponseServletOutputStream</code></p>\n<pre><code class=\"java\">    @Override\n    public ServletOutputStream getOutputStream() throws IOException {\n        if (this.outputStream == null) {\n            this.outputStream = new ResponseServletOutputStream(getResponse().getOutputStream());\n        }\n        return this.outputStream;\n    }</code></pre>\n<h3 id=\"真因\"><a href=\"#真因\" class=\"headerlink\" title=\"真因\"></a>真因</h3><p>一个是真实的Resposne的流，另一个是假冒的流。再回到一开始业务代码，获取response的outputStream，然后写入xml数据，接着flush，最后close。重点就是这个close的是哪个流？</p>\n<p><strong>老版本关闭的是真实的流，所以后面Response.success()并没有返回给客户端，因为流已经关闭了！而新版本关闭的并不是真实的response流，导致http链接还未断开，后面的Response.sucess()又经过MessageConverter写到了response的outputStream中，使得客户端接收到</strong></p>\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3><p>通过这次分析，了解到了<code>org.springframework.web.util.ContentCachingResponseWrapper</code>这样一个Response的包装类，可以重复读取数据流，以后有相关需求可以用一下。</p>\n"},{"_content":"<!DOCTYPE html>\n<html>\n<head>\n<title>2016-05-21-kongzheng1993-resume.md</title>\n<meta http-equiv=\"Content-type\" content=\"text/html;charset=UTF-8\">\n\n<style>\n/* https://github.com/microsoft/vscode/blob/master/extensions/markdown-language-features/media/markdown.css */\n/*---------------------------------------------------------------------------------------------\n *  Copyright (c) Microsoft Corporation. All rights reserved.\n *  Licensed under the MIT License. See License.txt in the project root for license information.\n *--------------------------------------------------------------------------------------------*/\n\nbody {\n\tfont-family: var(--vscode-markdown-font-family, -apple-system, BlinkMacSystemFont, \"Segoe WPC\", \"Segoe UI\", \"Ubuntu\", \"Droid Sans\", sans-serif);\n\tfont-size: var(--vscode-markdown-font-size, 14px);\n\tpadding: 0 26px;\n\tline-height: var(--vscode-markdown-line-height, 22px);\n\tword-wrap: break-word;\n}\n\n#code-csp-warning {\n\tposition: fixed;\n\ttop: 0;\n\tright: 0;\n\tcolor: white;\n\tmargin: 16px;\n\ttext-align: center;\n\tfont-size: 12px;\n\tfont-family: sans-serif;\n\tbackground-color:#444444;\n\tcursor: pointer;\n\tpadding: 6px;\n\tbox-shadow: 1px 1px 1px rgba(0,0,0,.25);\n}\n\n#code-csp-warning:hover {\n\ttext-decoration: none;\n\tbackground-color:#007acc;\n\tbox-shadow: 2px 2px 2px rgba(0,0,0,.25);\n}\n\nbody.scrollBeyondLastLine {\n\tmargin-bottom: calc(100vh - 22px);\n}\n\nbody.showEditorSelection .code-line {\n\tposition: relative;\n}\n\nbody.showEditorSelection .code-active-line:before,\nbody.showEditorSelection .code-line:hover:before {\n\tcontent: \"\";\n\tdisplay: block;\n\tposition: absolute;\n\ttop: 0;\n\tleft: -12px;\n\theight: 100%;\n}\n\nbody.showEditorSelection li.code-active-line:before,\nbody.showEditorSelection li.code-line:hover:before {\n\tleft: -30px;\n}\n\n.vscode-light.showEditorSelection .code-active-line:before {\n\tborder-left: 3px solid rgba(0, 0, 0, 0.15);\n}\n\n.vscode-light.showEditorSelection .code-line:hover:before {\n\tborder-left: 3px solid rgba(0, 0, 0, 0.40);\n}\n\n.vscode-light.showEditorSelection .code-line .code-line:hover:before {\n\tborder-left: none;\n}\n\n.vscode-dark.showEditorSelection .code-active-line:before {\n\tborder-left: 3px solid rgba(255, 255, 255, 0.4);\n}\n\n.vscode-dark.showEditorSelection .code-line:hover:before {\n\tborder-left: 3px solid rgba(255, 255, 255, 0.60);\n}\n\n.vscode-dark.showEditorSelection .code-line .code-line:hover:before {\n\tborder-left: none;\n}\n\n.vscode-high-contrast.showEditorSelection .code-active-line:before {\n\tborder-left: 3px solid rgba(255, 160, 0, 0.7);\n}\n\n.vscode-high-contrast.showEditorSelection .code-line:hover:before {\n\tborder-left: 3px solid rgba(255, 160, 0, 1);\n}\n\n.vscode-high-contrast.showEditorSelection .code-line .code-line:hover:before {\n\tborder-left: none;\n}\n\nimg {\n\tmax-width: 100%;\n\tmax-height: 100%;\n}\n\na {\n\ttext-decoration: none;\n}\n\na:hover {\n\ttext-decoration: underline;\n}\n\na:focus,\ninput:focus,\nselect:focus,\ntextarea:focus {\n\toutline: 1px solid -webkit-focus-ring-color;\n\toutline-offset: -1px;\n}\n\nhr {\n\tborder: 0;\n\theight: 2px;\n\tborder-bottom: 2px solid;\n}\n\nh1 {\n\tpadding-bottom: 0.3em;\n\tline-height: 1.2;\n\tborder-bottom-width: 1px;\n\tborder-bottom-style: solid;\n}\n\nh1, h2, h3 {\n\tfont-weight: normal;\n}\n\ntable {\n\tborder-collapse: collapse;\n}\n\ntable > thead > tr > th {\n\ttext-align: left;\n\tborder-bottom: 1px solid;\n}\n\ntable > thead > tr > th,\ntable > thead > tr > td,\ntable > tbody > tr > th,\ntable > tbody > tr > td {\n\tpadding: 5px 10px;\n}\n\ntable > tbody > tr + tr > td {\n\tborder-top: 1px solid;\n}\n\nblockquote {\n\tmargin: 0 7px 0 5px;\n\tpadding: 0 16px 0 10px;\n\tborder-left-width: 5px;\n\tborder-left-style: solid;\n}\n\ncode {\n\tfont-family: Menlo, Monaco, Consolas, \"Droid Sans Mono\", \"Courier New\", monospace, \"Droid Sans Fallback\";\n\tfont-size: 1em;\n\tline-height: 1.357em;\n}\n\nbody.wordWrap pre {\n\twhite-space: pre-wrap;\n}\n\npre:not(.hljs),\npre.hljs code > div {\n\tpadding: 16px;\n\tborder-radius: 3px;\n\toverflow: auto;\n}\n\npre code {\n\tcolor: var(--vscode-editor-foreground);\n\ttab-size: 4;\n}\n\n/** Theming */\n\n.vscode-light pre {\n\tbackground-color: rgba(220, 220, 220, 0.4);\n}\n\n.vscode-dark pre {\n\tbackground-color: rgba(10, 10, 10, 0.4);\n}\n\n.vscode-high-contrast pre {\n\tbackground-color: rgb(0, 0, 0);\n}\n\n.vscode-high-contrast h1 {\n\tborder-color: rgb(0, 0, 0);\n}\n\n.vscode-light table > thead > tr > th {\n\tborder-color: rgba(0, 0, 0, 0.69);\n}\n\n.vscode-dark table > thead > tr > th {\n\tborder-color: rgba(255, 255, 255, 0.69);\n}\n\n.vscode-light h1,\n.vscode-light hr,\n.vscode-light table > tbody > tr + tr > td {\n\tborder-color: rgba(0, 0, 0, 0.18);\n}\n\n.vscode-dark h1,\n.vscode-dark hr,\n.vscode-dark table > tbody > tr + tr > td {\n\tborder-color: rgba(255, 255, 255, 0.18);\n}\n\n</style>\n\n<style>\n/* Tomorrow Theme */\n/* http://jmblog.github.com/color-themes-for-google-code-highlightjs */\n/* Original theme - https://github.com/chriskempson/tomorrow-theme */\n\n/* Tomorrow Comment */\n.hljs-comment,\n.hljs-quote {\n\tcolor: #8e908c;\n}\n\n/* Tomorrow Red */\n.hljs-variable,\n.hljs-template-variable,\n.hljs-tag,\n.hljs-name,\n.hljs-selector-id,\n.hljs-selector-class,\n.hljs-regexp,\n.hljs-deletion {\n\tcolor: #c82829;\n}\n\n/* Tomorrow Orange */\n.hljs-number,\n.hljs-built_in,\n.hljs-builtin-name,\n.hljs-literal,\n.hljs-type,\n.hljs-params,\n.hljs-meta,\n.hljs-link {\n\tcolor: #f5871f;\n}\n\n/* Tomorrow Yellow */\n.hljs-attribute {\n\tcolor: #eab700;\n}\n\n/* Tomorrow Green */\n.hljs-string,\n.hljs-symbol,\n.hljs-bullet,\n.hljs-addition {\n\tcolor: #718c00;\n}\n\n/* Tomorrow Blue */\n.hljs-title,\n.hljs-section {\n\tcolor: #4271ae;\n}\n\n/* Tomorrow Purple */\n.hljs-keyword,\n.hljs-selector-tag {\n\tcolor: #8959a8;\n}\n\n.hljs {\n\tdisplay: block;\n\toverflow-x: auto;\n\tcolor: #4d4d4c;\n\tpadding: 0.5em;\n}\n\n.hljs-emphasis {\n\tfont-style: italic;\n}\n\n.hljs-strong {\n\tfont-weight: bold;\n}\n</style>\n\n<style>\n/*\n * Markdown PDF CSS\n */\n\n body {\n\tfont-family: -apple-system, BlinkMacSystemFont, \"Segoe WPC\", \"Segoe UI\", \"Ubuntu\", \"Droid Sans\", sans-serif, \"Meiryo\";\n\tpadding: 0 12px;\n}\n\npre {\n\tbackground-color: #f8f8f8;\n\tborder: 1px solid #cccccc;\n\tborder-radius: 3px;\n\toverflow-x: auto;\n\twhite-space: pre-wrap;\n\toverflow-wrap: break-word;\n}\n\npre:not(.hljs) {\n\tpadding: 23px;\n\tline-height: 19px;\n}\n\nblockquote {\n\tbackground: rgba(127, 127, 127, 0.1);\n\tborder-color: rgba(0, 122, 204, 0.5);\n}\n\n.emoji {\n\theight: 1.4em;\n}\n\ncode {\n\tfont-size: 14px;\n\tline-height: 19px;\n}\n\n/* for inline code */\n:not(pre):not(.hljs) > code {\n\tcolor: #C9AE75; /* Change the old color so it seems less like an error */\n\tfont-size: inherit;\n}\n\n/* Page Break : use <div class=\"page\"/> to insert page break\n-------------------------------------------------------- */\n.page {\n\tpage-break-after: always;\n}\n\n</style>\n\n<script src=\"https://unpkg.com/mermaid/dist/mermaid.min.js\"></script>\n</head>\n<body>\n  <script>\n    mermaid.initialize({\n      startOnLoad: true,\n      theme: document.body.classList.contains('vscode-dark') || document.body.classList.contains('vscode-high-contrast')\n          ? 'dark'\n          : 'default'\n    });\n  </script>\n<h1 id=\"%E8%81%94%E7%B3%BB%E6%96%B9%E5%BC%8F\">联系方式</h1>\n<ul>\n<li>手机：15810692477</li>\n<li>Email：kongzheng1993@hotmail.com</li>\n<li>QQ/微信号：767141624/evilrat</li>\n</ul>\n<hr>\n<h1 id=\"%E4%B8%AA%E4%BA%BA%E4%BF%A1%E6%81%AF\">个人信息</h1>\n<ul>\n<li>孔征/男/1992</li>\n<li>本科/菏泽学院/计算机与信息工程系</li>\n<li>毕业时间：2016年7月</li>\n<li>技术博客：<a href=\"https://kongzheng1993.github.io\">https://kongzheng1993.github.io</a></li>\n<li>Github: <a href=\"https://github.com/kongzheng1993\">https://github.com/kongzheng1993</a></li>\n<li>微信公众号：evilRat</li>\n</ul>\n<hr>\n<h1 id=\"%E8%BF%91%E5%86%B5%E7%AE%80%E4%BB%8B\">近况简介</h1>\n<p>目前在理想汽车担任<strong>交付准备系统SE（负责人）</strong>，系统相关人员包括开发3人、测试2人、产品1人、业务1人。</p>\n<p>研发过程为敏捷迭代：</p>\n<ul>\n<li>使用飞书（项目、IM、文档、视频会议、OKR、日历）工具进行协作和项目管理</li>\n<li>使用Git进行代码版本控制</li>\n<li>使用Gerrit（CR）、Jenkins（BV）、Sonar（SV）保证代码质量</li>\n<li>使用Jenkins、K8s、Docker、Git实现全流程的CI/CD。</li>\n</ul>\n<p>作为系统负责人，参与需求研发的全流程，包括需求评审、产品评审、排期、技术方案设计、任务分配、功能开发、测试用例评审和bug修复。关注相关服务的健康状态，适时进行重构、优化。保障上线操作无误，至今0回滚，系统常年可用性在99.99%以上。</p>\n<p>此外，作为研发部核心骨干参与发布会等重大项目。</p>\n<h1 id=\"%E5%B7%A5%E4%BD%9C%E7%BB%8F%E9%AA%8C\">工作经验</h1>\n<h2 id=\"%E7%90%86%E6%83%B3%E6%B1%BD%E8%BD%A6-2020%E5%B9%B49%E6%9C%88%E8%87%B3%E4%BB%8A\">理想汽车  （2020年9月至今）</h2>\n<p>企业系统部，负责交付、物流和质量相关系统研发工作。</p>\n<h2 id=\"%E4%BA%9A%E4%BF%A1%E7%A7%91%E6%8A%80-2018%E5%B9%B410%E6%9C%88-2020%E5%B9%B46%E6%9C%88\">亚信科技 （2018年10月-2020年6月）</h2>\n<p>北京移动客服项目、中移在线北京分公司统一接口平台、移动营业厅一体机等项目开发。作为组内主力开发，组内5人，解决开发过程中的难点、重点问题，保证需求按时高质量交付。</p>\n<h2 id=\"%E8%BD%AF%E9%80%9A%E5%8A%A8%E5%8A%9B-2016%E5%B9%B48%E6%9C%88-2018%E5%B9%B410%E6%9C%88\">软通动力 （2016年8月-2018年10月）</h2>\n<p>中国移动在线服务公司北京10086&amp;12580呼叫中心开发运维工作，包括呼叫中心流程开发、数据库开发和接口开发。</p>\n<hr>\n<h1 id=\"%E9%A1%B9%E7%9B%AE%E7%BB%8F%E9%AA%8C\">项目经验</h1>\n<h2 id=\"%E7%90%86%E6%83%B3%E6%B1%BD%E8%BD%A6l7%E5%8F%91%E5%B8%83%E4%BC%9A%E9%A1%B9%E7%9B%AE2022%E5%B9%B410%E6%9C%88--2023%E5%B9%B42%E6%9C%88\">理想汽车L7发布会项目（2022年10月--2023年2月）</h2>\n<p>理想汽车新车发布会是公司级重点项目，是对企业系统的一次大流量考验，是理想汽车的“双11”。本人在项目中参与了服务核心链路梳理，交易系统Code Review和重构，服务扩容、限流、降级功能梳理，应急预案设计，作战手册制定，发布会排练以及最终发布会保障。发布会过程中负责服务的监控和水位播报，按照作战手册完成发布会中的服务降级、限流等操作，监控网关异常流量，配合安全团队封禁恶意IP。最终0失误完成发布会保障工作，呈现了一场完美的发布会，2月8日当晚理想发布会很“苹果”冲上微博热搜。</p>\n<h2 id=\"%E4%BA%A4%E4%BB%98%E5%87%86%E5%A4%87%E7%B3%BB%E7%BB%9F2021%E5%B9%B45%E6%9C%88%E8%87%B3%E4%BB%8A\">交付准备系统（2021年5月至今）</h2>\n<p>交付准备管理系统（PC&amp;APP），车辆清洗、PDI、整备、终检、OTA升级和质量登记等功能，主要是交付中心PDI团队人员和管理者使用。车辆交付周期内节点事件触发系统自动生成响应的工单，PDI人员可以通过PC或者APP操作相关工单或手动创建/取消工单，管理者可以通过系统查看数据、管理团队。</p>\n<ul>\n<li>作为系统负责人，参与需求评审、产品评审、排期、任务分配、功能开发、测试用例评审和bug修复工作</li>\n<li>服务监控、告警跟进处理、代码重构、需求自驱等</li>\n<li>负责理想家APP交付准备系统研发项目。系统上线后，交付中心的pdi时间由原来的半小时以上，降低到13分钟。<strong>本人也因此在2021年Q4得到绩效E（超出预期）</strong></li>\n<li>打通售后服务系统，质损创建维修工单耗时缩短80%</li>\n</ul>\n<h2 id=\"%E6%95%B4%E8%BD%A6%E7%89%A9%E6%B5%81%E7%B3%BB%E7%BB%9F2020%E5%B9%B49%E6%9C%88%E8%87%B3%E4%BB%8A\">整车物流系统（2020年9月至今）</h2>\n<p>车辆下产线到交付交接完成期间的车辆运输和仓储相关的业务系统，事件驱动，实现车辆的自动/手动释放，出入库单、运输单、提交车计划和司机板车的管理，以及车辆运输的质量管理和供应商绩效的管理，系统包括PC端管理系统、APP（车辆维护、远程交付、特殊运输）和车辆交接微信小程序。参与新功能开发和旧有功能的维护和优化。</p>\n<ul>\n<li>车辆维护APP后台的开发和上线，其中对于生成车辆维护工单的逻辑优化，使工单生成的业务节点更准确，避免了重复生成维护工单，APP的使用提高人效50%</li>\n<li>车辆交接小程序中提车计划的重构，规范了板车司机、门卫、仓管和运管的操作，闭环了车辆生产完成到交付完成之间每一次运输的提车和交车流程</li>\n<li>理想汽车远程交付功能开发（PC端+APP端），支持配送车辆到客户指定地点进行交接，简化业务流程，提升用户体验。获得了<strong>2022年中国汽车物流行业创新奖</strong></li>\n</ul>\n<h2 id=\"%E6%95%B4%E8%BD%A6%E4%BA%A4%E4%BB%98%E7%B3%BB%E7%BB%9F2020%E5%B9%B49%E6%9C%88--2021%E5%B9%B46%E6%9C%88\">整车交付系统（2020年9月--2021年6月）</h2>\n<p>用户主要是交付专家和中央管理人员，主要功能包括交付单管理、交付任务管理等。本人的工作是在添加新功能的同时维护已有功能，通过技术手段提高交付人员的效率，降低交付成本。负责开发了交付违约管理、交付pipeline等功能。交付违约管理功能，在客户无法在预约时间提车时，交付专家可以手动或者订单取消、挂起等事件自动触发进入违约流程，创建违约工单群，并将产品专家、零售店长、交付专家、交付店长等订单相关人员拉入群聊，在飞书机器人的引导下，完成发送提醒短信给用户等跟进手段，提高了人效、降低了沟通成本，<strong>客户违约率降低30%</strong>。</p>\n<!-- ## NGTASK任务调度系统（2019年11月-2020年1月）\n\n由于携号转网业务需要同步携转数据，客户要求开发一个任务调度系统，可以通过web页面新增、修改、删除、查询任务。项目框架核心（不含业务代码）我已分享到[github:ngtask](https://github.com/kongzheng1993/ngtask)。独立开发。springboot+quartz+mysql+zookeeper，实现mysql数据导入导出任务，ftp/sftp上传下载任务。任务失败告警功能。\n\n## 中移在线一体机项目 （2019年3月-2019年9月）\n\n中移在线一体机项目是供移动营业厅一体机和pad等移动设备使用的web应用，提供实名制认证、停开机、补卡、开户等业务。使用springboot+vue+mysql。调用接口平台完成客户业务。项目搭建并开发，负责开发了补卡业务流程、包括服务密码验证、人证比对、旧卡校验、补卡、无纸化等流程。随着一体机的上线使用，用户可以通过一体机自助办理业务，减轻了营业厅服务人员的压力，提升了用户满意度。 -->\n<h2 id=\"%E4%B8%AD%E7%A7%BB%E5%9C%A8%E7%BA%BF%E5%8C%97%E4%BA%AC%E7%BB%9F%E4%B8%80%E6%8E%A5%E5%8F%A3%E5%B9%B3%E5%8F%B02018%E5%B9%B410%E6%9C%88--2020%E5%B9%B46%E6%9C%88\">中移在线北京统一接口平台（2018年10月--2020年6月）</h2>\n<p>此项目为中国移动在线公司北京分公司统一接口平台。此系统为中间层，为中移在线北京分公司10086IVR、营业厅一体机、app、微信、门户网站等渠道提供接入转接服务。各渠道过来的请求，由接口平台转接到能力提供方，再将能力响应信息返回给调用方。大部分接口要做一些数据格式的转换和数据内容的映射，以适应各个渠道的调用。此系统为分布式架构（nginx、tomcat、redis、mysql、zookeeper、dubbo），使用spring作为ioc容器，使用jersey提供RESTful接口。在页面可以进行接入接口、转接接口、接口映射、接口编排、接入参数、转接参数、参数映射、接入渠道、渠道权限等的配置。接收请求后，程序会通过调用url获取到通过redis/mysql获取到此接口的相关配置，并根据获取到的参数配置进行参数校验、参数处理、参数映射，调用转接接口获取响应后处理并返回给调用方。根据需求完成各类接口的开发、测试、联调、发布。负责实现了项目的动态数据源和redis集群搭建与集成。</p>\n<ul>\n<li>“移娃”项目中，引入redis实现了用户和“移娃”的会话上下文记录10min，利用redis速度和过期时间的天然优势，完美实现了功能</li>\n<li>优化了接口平台字段名大写蛇形（XXX_YYY）转驼峰（xxxYYY）算法，<strong>500ms优化到20ms</strong>，极大提高了接口RT。<a href=\"https://kongzheng1993.github.io/2020/03/25/kongzheng1993-%E4%B8%80%E6%AC%A1%E8%80%81%E4%BB%A3%E7%A0%81%E4%BC%98%E5%8C%96/\"><strong>查看详情</strong></a></li>\n</ul>\n<!-- ## 北京移动客服系统 （2018年12月-2019年3月）\n\n此系统使用亚信AppFrame（封装了ssh、jquery、html等技术）框架，提供给北京移动客服人员使用，业务比较复杂。\n主要功能：\n\n1. 呼叫中心，集成华为呼叫中心，接听来话，外呼等。\n2. 工单，新建工单、工单派发、认领等功能等。\n3. 服务，提供给其他系统接口。\n4. 客户关系管理，客户黑灰红白名单录入、设置等，客户信息查询、修改等\n5. 后台进程。\n\n在原有基础上新增、修改功能。完成黑灰名单自动填充失效时间、工单流转信息查询功能、向crm提供工单流转信息查询功能接口等需求。认真了解了公司框架，熟练完成前后端开发。 -->\n<hr>\n<h1 id=\"%E4%B8%93%E4%B8%9A%E6%8A%80%E8%83%BD\">专业技能</h1>\n<!-- &#x2B50;：了解，会用\n\n&#x2B50;&#x2B50;：熟悉，框架看过一些源码，中间件知道原理，工具会使用主要功能\n\n&#x2B50;&#x2B50;&#x2B50;：精通，框架看过大部分源码，中间件看过一些源码，工具会使用大部分功能  -->\n<h2 id=\"%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80\">编程语言</h2>\n<ul>\n<li>Java: ⭐⭐⭐</li>\n<li>SQL: ⭐⭐⭐</li>\n<li>JavaScript: ⭐⭐</li>\n<li>HTML: ⭐⭐</li>\n<li>CSS: ⭐⭐</li>\n<li>Python: ⭐</li>\n<li>Shell: ⭐</li>\n</ul>\n<h2 id=\"%E5%B7%A5%E5%85%B7\">工具</h2>\n<ul>\n<li>Maven: ⭐⭐⭐</li>\n<li>Git: ⭐⭐⭐</li>\n<li>SVN: ⭐⭐⭐</li>\n<li>Element UI: ⭐⭐⭐</li>\n</ul>\n<!-- - Ant: &#x2B50; -->\n<!-- - Gradle: &#x2B50; -->\n<h2 id=\"%E6%A1%86%E6%9E%B6\">框架</h2>\n<ul>\n<li>Spring: ⭐⭐⭐</li>\n<li>Spring Cloud: ⭐⭐</li>\n<li>MyBatis: ⭐⭐⭐</li>\n<li>Vue: ⭐⭐</li>\n<li>JUnit: ⭐</li>\n</ul>\n<!-- - ASM: &#x2B50;\n- Netty: &#x2B50;\n- Dubbo: &#x2B50; -->\n<h2 id=\"%E4%B8%AD%E9%97%B4%E4%BB%B6\">中间件</h2>\n<ul>\n<li>MySQL: ⭐⭐</li>\n<li>Oracle: ⭐⭐</li>\n<li>RocketMQ: ⭐</li>\n<li>Zookeeper: ⭐</li>\n<li>Redis: ⭐⭐</li>\n</ul>\n<!-- - Kafka: &#x2B50; -->\n<!-- - Nginx: &#x2B50; -->\n<h2 id=\"%E5%85%B6%E4%BB%96\">其他</h2>\n<ul>\n<li>Docker：⭐</li>\n<li>K8s：⭐</li>\n<li>Jenkins：⭐</li>\n<li>Flink：⭐</li>\n</ul>\n<hr>\n<h1 id=\"%E5%BC%80%E6%BA%90%E4%BD%9C%E5%93%81\">开源作品</h1>\n<h3 id=\"1-ftp%E6%96%87%E4%BB%B6%E4%B8%8B%E8%BD%BD%E5%B7%A5%E5%85%B7-githubdownloadfiles\">1.  ftp文件下载工具 <a href=\"https://github.com/kongzheng1993/downloadFiles\">github:downloadFiles</a></h3>\n<!-- 帮运维同事写的小工具，他手头有个任务，每天一早到工位就要去8台sftp下载录音文件（任务调度平台故障，恢复之前只能手动搞），所以用python帮他做了个小工具。使用paramiko连接sftp、json模块解析配置文件、logging记录日志、zipfile模块压缩文件、threading模拟多线程。最后我还用pyinstaller打包成exe，他写好配置文件，双击就能执行，并且日志会持久化到文件。代码已经分享到[github:downloadFiles](https://github.com/kongzheng1993/downloadFiles)。 -->\n<h3 id=\"2-testivr%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E7%94%9F%E6%88%90%E5%B7%A5%E5%85%B7-githubguigeneratetestivrconfig\">2. testIVR配置文件生成工具 <a href=\"https://github.com/kongzheng1993/GuiGenerateTestIVRConfig\">github:GuiGenerateTestIVRConfig</a></h3>\n<h3 id=\"3-%E4%BD%BF%E7%94%A8nodejszookeeperredis%E5%AE%9E%E7%8E%B0%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0-githubevil-service-discovery\">3. 使用node.js+zookeeper+redis实现服务发现 <a href=\"https://github.com/kongzheng1993/evil-service-discovery\">github:evil-service-discovery</a></h3>\n<h3 id=\"4-springbootquartzmysql%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1%E9%9B%86%E7%BE%A4-githubeviltask\">4. springboot+quartz+mysql定时任务集群 <a href=\"https://github.com/kongzheng1993/Eviltask\">github:EvilTask</a></h3>\n<p><strong>更多请查看我的<a href=\"https://github.com/kongzheng1993\">github</a></strong></p>\n<!-- 来到项目后发现大家使用的调试接口的工具testIVR(模拟ivr流程调用socket和http接口工具) 总是需要手动配置，而且错误率特别高，经常因为一个小问题找半天。在熟悉了testIVR之后，我使用python-tkinter写了一个自动生成testIVR配置文件的工具，在项目组内广泛应用，并得到了领导和客户的好评。\n\n使用python的tkinter库编写gui。通过获取用户在输入控件(Entry)中输入的ivr_id、dtproxy_ip、dtproxy_id和参数配置。编写 cleanparam()函数清洗找出入参，和出参个数。编写dogenerate()函数生成ivr和dtproxy的配置，并循环生成入参、出参配置。使用python的 pyinstaller工具生成exe可执行文件。详情请查看我的[github:GuiGenerateTestIVRConfig](https://github.com/kongzheng1993/GuiGenerateTestIVRConfig) -->\n<h1 id=\"%E8%87%AA%E6%88%91%E8%AF%84%E4%BB%B7\">自我评价</h1>\n<p>有较好的职业素养，对工作积极负责，有创新意识和团队合作精神。热爱技术、热爱编码、热爱学习，喜欢阅读技术书刊、源码，学习能力较强，能快速将学习内容转化为生产力。态度乐观，有较好的沟通能力，为人热情，可以在工作中统合综效，实现共赢。</p>\n<hr>\n<h1 id=\"%E8%87%B4%E8%B0%A2\">致谢</h1>\n<p>感谢您花时间阅读我的简历，期待能有机会和您共事。</p>\n\n</body>\n</html>\n","source":"_posts/2016-05-21-kongzheng1993-resume.html","raw":"<!DOCTYPE html>\n<html>\n<head>\n<title>2016-05-21-kongzheng1993-resume.md</title>\n<meta http-equiv=\"Content-type\" content=\"text/html;charset=UTF-8\">\n\n<style>\n/* https://github.com/microsoft/vscode/blob/master/extensions/markdown-language-features/media/markdown.css */\n/*---------------------------------------------------------------------------------------------\n *  Copyright (c) Microsoft Corporation. All rights reserved.\n *  Licensed under the MIT License. See License.txt in the project root for license information.\n *--------------------------------------------------------------------------------------------*/\n\nbody {\n\tfont-family: var(--vscode-markdown-font-family, -apple-system, BlinkMacSystemFont, \"Segoe WPC\", \"Segoe UI\", \"Ubuntu\", \"Droid Sans\", sans-serif);\n\tfont-size: var(--vscode-markdown-font-size, 14px);\n\tpadding: 0 26px;\n\tline-height: var(--vscode-markdown-line-height, 22px);\n\tword-wrap: break-word;\n}\n\n#code-csp-warning {\n\tposition: fixed;\n\ttop: 0;\n\tright: 0;\n\tcolor: white;\n\tmargin: 16px;\n\ttext-align: center;\n\tfont-size: 12px;\n\tfont-family: sans-serif;\n\tbackground-color:#444444;\n\tcursor: pointer;\n\tpadding: 6px;\n\tbox-shadow: 1px 1px 1px rgba(0,0,0,.25);\n}\n\n#code-csp-warning:hover {\n\ttext-decoration: none;\n\tbackground-color:#007acc;\n\tbox-shadow: 2px 2px 2px rgba(0,0,0,.25);\n}\n\nbody.scrollBeyondLastLine {\n\tmargin-bottom: calc(100vh - 22px);\n}\n\nbody.showEditorSelection .code-line {\n\tposition: relative;\n}\n\nbody.showEditorSelection .code-active-line:before,\nbody.showEditorSelection .code-line:hover:before {\n\tcontent: \"\";\n\tdisplay: block;\n\tposition: absolute;\n\ttop: 0;\n\tleft: -12px;\n\theight: 100%;\n}\n\nbody.showEditorSelection li.code-active-line:before,\nbody.showEditorSelection li.code-line:hover:before {\n\tleft: -30px;\n}\n\n.vscode-light.showEditorSelection .code-active-line:before {\n\tborder-left: 3px solid rgba(0, 0, 0, 0.15);\n}\n\n.vscode-light.showEditorSelection .code-line:hover:before {\n\tborder-left: 3px solid rgba(0, 0, 0, 0.40);\n}\n\n.vscode-light.showEditorSelection .code-line .code-line:hover:before {\n\tborder-left: none;\n}\n\n.vscode-dark.showEditorSelection .code-active-line:before {\n\tborder-left: 3px solid rgba(255, 255, 255, 0.4);\n}\n\n.vscode-dark.showEditorSelection .code-line:hover:before {\n\tborder-left: 3px solid rgba(255, 255, 255, 0.60);\n}\n\n.vscode-dark.showEditorSelection .code-line .code-line:hover:before {\n\tborder-left: none;\n}\n\n.vscode-high-contrast.showEditorSelection .code-active-line:before {\n\tborder-left: 3px solid rgba(255, 160, 0, 0.7);\n}\n\n.vscode-high-contrast.showEditorSelection .code-line:hover:before {\n\tborder-left: 3px solid rgba(255, 160, 0, 1);\n}\n\n.vscode-high-contrast.showEditorSelection .code-line .code-line:hover:before {\n\tborder-left: none;\n}\n\nimg {\n\tmax-width: 100%;\n\tmax-height: 100%;\n}\n\na {\n\ttext-decoration: none;\n}\n\na:hover {\n\ttext-decoration: underline;\n}\n\na:focus,\ninput:focus,\nselect:focus,\ntextarea:focus {\n\toutline: 1px solid -webkit-focus-ring-color;\n\toutline-offset: -1px;\n}\n\nhr {\n\tborder: 0;\n\theight: 2px;\n\tborder-bottom: 2px solid;\n}\n\nh1 {\n\tpadding-bottom: 0.3em;\n\tline-height: 1.2;\n\tborder-bottom-width: 1px;\n\tborder-bottom-style: solid;\n}\n\nh1, h2, h3 {\n\tfont-weight: normal;\n}\n\ntable {\n\tborder-collapse: collapse;\n}\n\ntable > thead > tr > th {\n\ttext-align: left;\n\tborder-bottom: 1px solid;\n}\n\ntable > thead > tr > th,\ntable > thead > tr > td,\ntable > tbody > tr > th,\ntable > tbody > tr > td {\n\tpadding: 5px 10px;\n}\n\ntable > tbody > tr + tr > td {\n\tborder-top: 1px solid;\n}\n\nblockquote {\n\tmargin: 0 7px 0 5px;\n\tpadding: 0 16px 0 10px;\n\tborder-left-width: 5px;\n\tborder-left-style: solid;\n}\n\ncode {\n\tfont-family: Menlo, Monaco, Consolas, \"Droid Sans Mono\", \"Courier New\", monospace, \"Droid Sans Fallback\";\n\tfont-size: 1em;\n\tline-height: 1.357em;\n}\n\nbody.wordWrap pre {\n\twhite-space: pre-wrap;\n}\n\npre:not(.hljs),\npre.hljs code > div {\n\tpadding: 16px;\n\tborder-radius: 3px;\n\toverflow: auto;\n}\n\npre code {\n\tcolor: var(--vscode-editor-foreground);\n\ttab-size: 4;\n}\n\n/** Theming */\n\n.vscode-light pre {\n\tbackground-color: rgba(220, 220, 220, 0.4);\n}\n\n.vscode-dark pre {\n\tbackground-color: rgba(10, 10, 10, 0.4);\n}\n\n.vscode-high-contrast pre {\n\tbackground-color: rgb(0, 0, 0);\n}\n\n.vscode-high-contrast h1 {\n\tborder-color: rgb(0, 0, 0);\n}\n\n.vscode-light table > thead > tr > th {\n\tborder-color: rgba(0, 0, 0, 0.69);\n}\n\n.vscode-dark table > thead > tr > th {\n\tborder-color: rgba(255, 255, 255, 0.69);\n}\n\n.vscode-light h1,\n.vscode-light hr,\n.vscode-light table > tbody > tr + tr > td {\n\tborder-color: rgba(0, 0, 0, 0.18);\n}\n\n.vscode-dark h1,\n.vscode-dark hr,\n.vscode-dark table > tbody > tr + tr > td {\n\tborder-color: rgba(255, 255, 255, 0.18);\n}\n\n</style>\n\n<style>\n/* Tomorrow Theme */\n/* http://jmblog.github.com/color-themes-for-google-code-highlightjs */\n/* Original theme - https://github.com/chriskempson/tomorrow-theme */\n\n/* Tomorrow Comment */\n.hljs-comment,\n.hljs-quote {\n\tcolor: #8e908c;\n}\n\n/* Tomorrow Red */\n.hljs-variable,\n.hljs-template-variable,\n.hljs-tag,\n.hljs-name,\n.hljs-selector-id,\n.hljs-selector-class,\n.hljs-regexp,\n.hljs-deletion {\n\tcolor: #c82829;\n}\n\n/* Tomorrow Orange */\n.hljs-number,\n.hljs-built_in,\n.hljs-builtin-name,\n.hljs-literal,\n.hljs-type,\n.hljs-params,\n.hljs-meta,\n.hljs-link {\n\tcolor: #f5871f;\n}\n\n/* Tomorrow Yellow */\n.hljs-attribute {\n\tcolor: #eab700;\n}\n\n/* Tomorrow Green */\n.hljs-string,\n.hljs-symbol,\n.hljs-bullet,\n.hljs-addition {\n\tcolor: #718c00;\n}\n\n/* Tomorrow Blue */\n.hljs-title,\n.hljs-section {\n\tcolor: #4271ae;\n}\n\n/* Tomorrow Purple */\n.hljs-keyword,\n.hljs-selector-tag {\n\tcolor: #8959a8;\n}\n\n.hljs {\n\tdisplay: block;\n\toverflow-x: auto;\n\tcolor: #4d4d4c;\n\tpadding: 0.5em;\n}\n\n.hljs-emphasis {\n\tfont-style: italic;\n}\n\n.hljs-strong {\n\tfont-weight: bold;\n}\n</style>\n\n<style>\n/*\n * Markdown PDF CSS\n */\n\n body {\n\tfont-family: -apple-system, BlinkMacSystemFont, \"Segoe WPC\", \"Segoe UI\", \"Ubuntu\", \"Droid Sans\", sans-serif, \"Meiryo\";\n\tpadding: 0 12px;\n}\n\npre {\n\tbackground-color: #f8f8f8;\n\tborder: 1px solid #cccccc;\n\tborder-radius: 3px;\n\toverflow-x: auto;\n\twhite-space: pre-wrap;\n\toverflow-wrap: break-word;\n}\n\npre:not(.hljs) {\n\tpadding: 23px;\n\tline-height: 19px;\n}\n\nblockquote {\n\tbackground: rgba(127, 127, 127, 0.1);\n\tborder-color: rgba(0, 122, 204, 0.5);\n}\n\n.emoji {\n\theight: 1.4em;\n}\n\ncode {\n\tfont-size: 14px;\n\tline-height: 19px;\n}\n\n/* for inline code */\n:not(pre):not(.hljs) > code {\n\tcolor: #C9AE75; /* Change the old color so it seems less like an error */\n\tfont-size: inherit;\n}\n\n/* Page Break : use <div class=\"page\"/> to insert page break\n-------------------------------------------------------- */\n.page {\n\tpage-break-after: always;\n}\n\n</style>\n\n<script src=\"https://unpkg.com/mermaid/dist/mermaid.min.js\"></script>\n</head>\n<body>\n  <script>\n    mermaid.initialize({\n      startOnLoad: true,\n      theme: document.body.classList.contains('vscode-dark') || document.body.classList.contains('vscode-high-contrast')\n          ? 'dark'\n          : 'default'\n    });\n  </script>\n<h1 id=\"%E8%81%94%E7%B3%BB%E6%96%B9%E5%BC%8F\">联系方式</h1>\n<ul>\n<li>手机：15810692477</li>\n<li>Email：kongzheng1993@hotmail.com</li>\n<li>QQ/微信号：767141624/evilrat</li>\n</ul>\n<hr>\n<h1 id=\"%E4%B8%AA%E4%BA%BA%E4%BF%A1%E6%81%AF\">个人信息</h1>\n<ul>\n<li>孔征/男/1992</li>\n<li>本科/菏泽学院/计算机与信息工程系</li>\n<li>毕业时间：2016年7月</li>\n<li>技术博客：<a href=\"https://kongzheng1993.github.io\">https://kongzheng1993.github.io</a></li>\n<li>Github: <a href=\"https://github.com/kongzheng1993\">https://github.com/kongzheng1993</a></li>\n<li>微信公众号：evilRat</li>\n</ul>\n<hr>\n<h1 id=\"%E8%BF%91%E5%86%B5%E7%AE%80%E4%BB%8B\">近况简介</h1>\n<p>目前在理想汽车担任<strong>交付准备系统SE（负责人）</strong>，系统相关人员包括开发3人、测试2人、产品1人、业务1人。</p>\n<p>研发过程为敏捷迭代：</p>\n<ul>\n<li>使用飞书（项目、IM、文档、视频会议、OKR、日历）工具进行协作和项目管理</li>\n<li>使用Git进行代码版本控制</li>\n<li>使用Gerrit（CR）、Jenkins（BV）、Sonar（SV）保证代码质量</li>\n<li>使用Jenkins、K8s、Docker、Git实现全流程的CI/CD。</li>\n</ul>\n<p>作为系统负责人，参与需求研发的全流程，包括需求评审、产品评审、排期、技术方案设计、任务分配、功能开发、测试用例评审和bug修复。关注相关服务的健康状态，适时进行重构、优化。保障上线操作无误，至今0回滚，系统常年可用性在99.99%以上。</p>\n<p>此外，作为研发部核心骨干参与发布会等重大项目。</p>\n<h1 id=\"%E5%B7%A5%E4%BD%9C%E7%BB%8F%E9%AA%8C\">工作经验</h1>\n<h2 id=\"%E7%90%86%E6%83%B3%E6%B1%BD%E8%BD%A6-2020%E5%B9%B49%E6%9C%88%E8%87%B3%E4%BB%8A\">理想汽车  （2020年9月至今）</h2>\n<p>企业系统部，负责交付、物流和质量相关系统研发工作。</p>\n<h2 id=\"%E4%BA%9A%E4%BF%A1%E7%A7%91%E6%8A%80-2018%E5%B9%B410%E6%9C%88-2020%E5%B9%B46%E6%9C%88\">亚信科技 （2018年10月-2020年6月）</h2>\n<p>北京移动客服项目、中移在线北京分公司统一接口平台、移动营业厅一体机等项目开发。作为组内主力开发，组内5人，解决开发过程中的难点、重点问题，保证需求按时高质量交付。</p>\n<h2 id=\"%E8%BD%AF%E9%80%9A%E5%8A%A8%E5%8A%9B-2016%E5%B9%B48%E6%9C%88-2018%E5%B9%B410%E6%9C%88\">软通动力 （2016年8月-2018年10月）</h2>\n<p>中国移动在线服务公司北京10086&amp;12580呼叫中心开发运维工作，包括呼叫中心流程开发、数据库开发和接口开发。</p>\n<hr>\n<h1 id=\"%E9%A1%B9%E7%9B%AE%E7%BB%8F%E9%AA%8C\">项目经验</h1>\n<h2 id=\"%E7%90%86%E6%83%B3%E6%B1%BD%E8%BD%A6l7%E5%8F%91%E5%B8%83%E4%BC%9A%E9%A1%B9%E7%9B%AE2022%E5%B9%B410%E6%9C%88--2023%E5%B9%B42%E6%9C%88\">理想汽车L7发布会项目（2022年10月--2023年2月）</h2>\n<p>理想汽车新车发布会是公司级重点项目，是对企业系统的一次大流量考验，是理想汽车的“双11”。本人在项目中参与了服务核心链路梳理，交易系统Code Review和重构，服务扩容、限流、降级功能梳理，应急预案设计，作战手册制定，发布会排练以及最终发布会保障。发布会过程中负责服务的监控和水位播报，按照作战手册完成发布会中的服务降级、限流等操作，监控网关异常流量，配合安全团队封禁恶意IP。最终0失误完成发布会保障工作，呈现了一场完美的发布会，2月8日当晚理想发布会很“苹果”冲上微博热搜。</p>\n<h2 id=\"%E4%BA%A4%E4%BB%98%E5%87%86%E5%A4%87%E7%B3%BB%E7%BB%9F2021%E5%B9%B45%E6%9C%88%E8%87%B3%E4%BB%8A\">交付准备系统（2021年5月至今）</h2>\n<p>交付准备管理系统（PC&amp;APP），车辆清洗、PDI、整备、终检、OTA升级和质量登记等功能，主要是交付中心PDI团队人员和管理者使用。车辆交付周期内节点事件触发系统自动生成响应的工单，PDI人员可以通过PC或者APP操作相关工单或手动创建/取消工单，管理者可以通过系统查看数据、管理团队。</p>\n<ul>\n<li>作为系统负责人，参与需求评审、产品评审、排期、任务分配、功能开发、测试用例评审和bug修复工作</li>\n<li>服务监控、告警跟进处理、代码重构、需求自驱等</li>\n<li>负责理想家APP交付准备系统研发项目。系统上线后，交付中心的pdi时间由原来的半小时以上，降低到13分钟。<strong>本人也因此在2021年Q4得到绩效E（超出预期）</strong></li>\n<li>打通售后服务系统，质损创建维修工单耗时缩短80%</li>\n</ul>\n<h2 id=\"%E6%95%B4%E8%BD%A6%E7%89%A9%E6%B5%81%E7%B3%BB%E7%BB%9F2020%E5%B9%B49%E6%9C%88%E8%87%B3%E4%BB%8A\">整车物流系统（2020年9月至今）</h2>\n<p>车辆下产线到交付交接完成期间的车辆运输和仓储相关的业务系统，事件驱动，实现车辆的自动/手动释放，出入库单、运输单、提交车计划和司机板车的管理，以及车辆运输的质量管理和供应商绩效的管理，系统包括PC端管理系统、APP（车辆维护、远程交付、特殊运输）和车辆交接微信小程序。参与新功能开发和旧有功能的维护和优化。</p>\n<ul>\n<li>车辆维护APP后台的开发和上线，其中对于生成车辆维护工单的逻辑优化，使工单生成的业务节点更准确，避免了重复生成维护工单，APP的使用提高人效50%</li>\n<li>车辆交接小程序中提车计划的重构，规范了板车司机、门卫、仓管和运管的操作，闭环了车辆生产完成到交付完成之间每一次运输的提车和交车流程</li>\n<li>理想汽车远程交付功能开发（PC端+APP端），支持配送车辆到客户指定地点进行交接，简化业务流程，提升用户体验。获得了<strong>2022年中国汽车物流行业创新奖</strong></li>\n</ul>\n<h2 id=\"%E6%95%B4%E8%BD%A6%E4%BA%A4%E4%BB%98%E7%B3%BB%E7%BB%9F2020%E5%B9%B49%E6%9C%88--2021%E5%B9%B46%E6%9C%88\">整车交付系统（2020年9月--2021年6月）</h2>\n<p>用户主要是交付专家和中央管理人员，主要功能包括交付单管理、交付任务管理等。本人的工作是在添加新功能的同时维护已有功能，通过技术手段提高交付人员的效率，降低交付成本。负责开发了交付违约管理、交付pipeline等功能。交付违约管理功能，在客户无法在预约时间提车时，交付专家可以手动或者订单取消、挂起等事件自动触发进入违约流程，创建违约工单群，并将产品专家、零售店长、交付专家、交付店长等订单相关人员拉入群聊，在飞书机器人的引导下，完成发送提醒短信给用户等跟进手段，提高了人效、降低了沟通成本，<strong>客户违约率降低30%</strong>。</p>\n<!-- ## NGTASK任务调度系统（2019年11月-2020年1月）\n\n由于携号转网业务需要同步携转数据，客户要求开发一个任务调度系统，可以通过web页面新增、修改、删除、查询任务。项目框架核心（不含业务代码）我已分享到[github:ngtask](https://github.com/kongzheng1993/ngtask)。独立开发。springboot+quartz+mysql+zookeeper，实现mysql数据导入导出任务，ftp/sftp上传下载任务。任务失败告警功能。\n\n## 中移在线一体机项目 （2019年3月-2019年9月）\n\n中移在线一体机项目是供移动营业厅一体机和pad等移动设备使用的web应用，提供实名制认证、停开机、补卡、开户等业务。使用springboot+vue+mysql。调用接口平台完成客户业务。项目搭建并开发，负责开发了补卡业务流程、包括服务密码验证、人证比对、旧卡校验、补卡、无纸化等流程。随着一体机的上线使用，用户可以通过一体机自助办理业务，减轻了营业厅服务人员的压力，提升了用户满意度。 -->\n<h2 id=\"%E4%B8%AD%E7%A7%BB%E5%9C%A8%E7%BA%BF%E5%8C%97%E4%BA%AC%E7%BB%9F%E4%B8%80%E6%8E%A5%E5%8F%A3%E5%B9%B3%E5%8F%B02018%E5%B9%B410%E6%9C%88--2020%E5%B9%B46%E6%9C%88\">中移在线北京统一接口平台（2018年10月--2020年6月）</h2>\n<p>此项目为中国移动在线公司北京分公司统一接口平台。此系统为中间层，为中移在线北京分公司10086IVR、营业厅一体机、app、微信、门户网站等渠道提供接入转接服务。各渠道过来的请求，由接口平台转接到能力提供方，再将能力响应信息返回给调用方。大部分接口要做一些数据格式的转换和数据内容的映射，以适应各个渠道的调用。此系统为分布式架构（nginx、tomcat、redis、mysql、zookeeper、dubbo），使用spring作为ioc容器，使用jersey提供RESTful接口。在页面可以进行接入接口、转接接口、接口映射、接口编排、接入参数、转接参数、参数映射、接入渠道、渠道权限等的配置。接收请求后，程序会通过调用url获取到通过redis/mysql获取到此接口的相关配置，并根据获取到的参数配置进行参数校验、参数处理、参数映射，调用转接接口获取响应后处理并返回给调用方。根据需求完成各类接口的开发、测试、联调、发布。负责实现了项目的动态数据源和redis集群搭建与集成。</p>\n<ul>\n<li>“移娃”项目中，引入redis实现了用户和“移娃”的会话上下文记录10min，利用redis速度和过期时间的天然优势，完美实现了功能</li>\n<li>优化了接口平台字段名大写蛇形（XXX_YYY）转驼峰（xxxYYY）算法，<strong>500ms优化到20ms</strong>，极大提高了接口RT。<a href=\"https://kongzheng1993.github.io/2020/03/25/kongzheng1993-%E4%B8%80%E6%AC%A1%E8%80%81%E4%BB%A3%E7%A0%81%E4%BC%98%E5%8C%96/\"><strong>查看详情</strong></a></li>\n</ul>\n<!-- ## 北京移动客服系统 （2018年12月-2019年3月）\n\n此系统使用亚信AppFrame（封装了ssh、jquery、html等技术）框架，提供给北京移动客服人员使用，业务比较复杂。\n主要功能：\n\n1. 呼叫中心，集成华为呼叫中心，接听来话，外呼等。\n2. 工单，新建工单、工单派发、认领等功能等。\n3. 服务，提供给其他系统接口。\n4. 客户关系管理，客户黑灰红白名单录入、设置等，客户信息查询、修改等\n5. 后台进程。\n\n在原有基础上新增、修改功能。完成黑灰名单自动填充失效时间、工单流转信息查询功能、向crm提供工单流转信息查询功能接口等需求。认真了解了公司框架，熟练完成前后端开发。 -->\n<hr>\n<h1 id=\"%E4%B8%93%E4%B8%9A%E6%8A%80%E8%83%BD\">专业技能</h1>\n<!-- &#x2B50;：了解，会用\n\n&#x2B50;&#x2B50;：熟悉，框架看过一些源码，中间件知道原理，工具会使用主要功能\n\n&#x2B50;&#x2B50;&#x2B50;：精通，框架看过大部分源码，中间件看过一些源码，工具会使用大部分功能  -->\n<h2 id=\"%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80\">编程语言</h2>\n<ul>\n<li>Java: ⭐⭐⭐</li>\n<li>SQL: ⭐⭐⭐</li>\n<li>JavaScript: ⭐⭐</li>\n<li>HTML: ⭐⭐</li>\n<li>CSS: ⭐⭐</li>\n<li>Python: ⭐</li>\n<li>Shell: ⭐</li>\n</ul>\n<h2 id=\"%E5%B7%A5%E5%85%B7\">工具</h2>\n<ul>\n<li>Maven: ⭐⭐⭐</li>\n<li>Git: ⭐⭐⭐</li>\n<li>SVN: ⭐⭐⭐</li>\n<li>Element UI: ⭐⭐⭐</li>\n</ul>\n<!-- - Ant: &#x2B50; -->\n<!-- - Gradle: &#x2B50; -->\n<h2 id=\"%E6%A1%86%E6%9E%B6\">框架</h2>\n<ul>\n<li>Spring: ⭐⭐⭐</li>\n<li>Spring Cloud: ⭐⭐</li>\n<li>MyBatis: ⭐⭐⭐</li>\n<li>Vue: ⭐⭐</li>\n<li>JUnit: ⭐</li>\n</ul>\n<!-- - ASM: &#x2B50;\n- Netty: &#x2B50;\n- Dubbo: &#x2B50; -->\n<h2 id=\"%E4%B8%AD%E9%97%B4%E4%BB%B6\">中间件</h2>\n<ul>\n<li>MySQL: ⭐⭐</li>\n<li>Oracle: ⭐⭐</li>\n<li>RocketMQ: ⭐</li>\n<li>Zookeeper: ⭐</li>\n<li>Redis: ⭐⭐</li>\n</ul>\n<!-- - Kafka: &#x2B50; -->\n<!-- - Nginx: &#x2B50; -->\n<h2 id=\"%E5%85%B6%E4%BB%96\">其他</h2>\n<ul>\n<li>Docker：⭐</li>\n<li>K8s：⭐</li>\n<li>Jenkins：⭐</li>\n<li>Flink：⭐</li>\n</ul>\n<hr>\n<h1 id=\"%E5%BC%80%E6%BA%90%E4%BD%9C%E5%93%81\">开源作品</h1>\n<h3 id=\"1-ftp%E6%96%87%E4%BB%B6%E4%B8%8B%E8%BD%BD%E5%B7%A5%E5%85%B7-githubdownloadfiles\">1.  ftp文件下载工具 <a href=\"https://github.com/kongzheng1993/downloadFiles\">github:downloadFiles</a></h3>\n<!-- 帮运维同事写的小工具，他手头有个任务，每天一早到工位就要去8台sftp下载录音文件（任务调度平台故障，恢复之前只能手动搞），所以用python帮他做了个小工具。使用paramiko连接sftp、json模块解析配置文件、logging记录日志、zipfile模块压缩文件、threading模拟多线程。最后我还用pyinstaller打包成exe，他写好配置文件，双击就能执行，并且日志会持久化到文件。代码已经分享到[github:downloadFiles](https://github.com/kongzheng1993/downloadFiles)。 -->\n<h3 id=\"2-testivr%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E7%94%9F%E6%88%90%E5%B7%A5%E5%85%B7-githubguigeneratetestivrconfig\">2. testIVR配置文件生成工具 <a href=\"https://github.com/kongzheng1993/GuiGenerateTestIVRConfig\">github:GuiGenerateTestIVRConfig</a></h3>\n<h3 id=\"3-%E4%BD%BF%E7%94%A8nodejszookeeperredis%E5%AE%9E%E7%8E%B0%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0-githubevil-service-discovery\">3. 使用node.js+zookeeper+redis实现服务发现 <a href=\"https://github.com/kongzheng1993/evil-service-discovery\">github:evil-service-discovery</a></h3>\n<h3 id=\"4-springbootquartzmysql%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1%E9%9B%86%E7%BE%A4-githubeviltask\">4. springboot+quartz+mysql定时任务集群 <a href=\"https://github.com/kongzheng1993/Eviltask\">github:EvilTask</a></h3>\n<p><strong>更多请查看我的<a href=\"https://github.com/kongzheng1993\">github</a></strong></p>\n<!-- 来到项目后发现大家使用的调试接口的工具testIVR(模拟ivr流程调用socket和http接口工具) 总是需要手动配置，而且错误率特别高，经常因为一个小问题找半天。在熟悉了testIVR之后，我使用python-tkinter写了一个自动生成testIVR配置文件的工具，在项目组内广泛应用，并得到了领导和客户的好评。\n\n使用python的tkinter库编写gui。通过获取用户在输入控件(Entry)中输入的ivr_id、dtproxy_ip、dtproxy_id和参数配置。编写 cleanparam()函数清洗找出入参，和出参个数。编写dogenerate()函数生成ivr和dtproxy的配置，并循环生成入参、出参配置。使用python的 pyinstaller工具生成exe可执行文件。详情请查看我的[github:GuiGenerateTestIVRConfig](https://github.com/kongzheng1993/GuiGenerateTestIVRConfig) -->\n<h1 id=\"%E8%87%AA%E6%88%91%E8%AF%84%E4%BB%B7\">自我评价</h1>\n<p>有较好的职业素养，对工作积极负责，有创新意识和团队合作精神。热爱技术、热爱编码、热爱学习，喜欢阅读技术书刊、源码，学习能力较强，能快速将学习内容转化为生产力。态度乐观，有较好的沟通能力，为人热情，可以在工作中统合综效，实现共赢。</p>\n<hr>\n<h1 id=\"%E8%87%B4%E8%B0%A2\">致谢</h1>\n<p>感谢您花时间阅读我的简历，期待能有机会和您共事。</p>\n\n</body>\n</html>\n","slug":"kongzheng1993-resume","published":1,"date":"2016-05-20T16:00:00.000Z","updated":"2024-05-19T02:52:24.512Z","_id":"clg0k2art00j4t26f1t9vvfty","title":"","comments":1,"layout":"post","photos":[],"link":"","content":"<!DOCTYPE html>\n<html>\n<head><meta name=\"generator\" content=\"Hexo 3.9.0\">\n<title>2016-05-21-kongzheng1993-resume.md</title>\n<meta http-equiv=\"Content-type\" content=\"text/html;charset=UTF-8\">\n\n<style>\n/* https://github.com/microsoft/vscode/blob/master/extensions/markdown-language-features/media/markdown.css */\n/*---------------------------------------------------------------------------------------------\n *  Copyright (c) Microsoft Corporation. All rights reserved.\n *  Licensed under the MIT License. See License.txt in the project root for license information.\n *--------------------------------------------------------------------------------------------*/\n\nbody {\n\tfont-family: var(--vscode-markdown-font-family, -apple-system, BlinkMacSystemFont, \"Segoe WPC\", \"Segoe UI\", \"Ubuntu\", \"Droid Sans\", sans-serif);\n\tfont-size: var(--vscode-markdown-font-size, 14px);\n\tpadding: 0 26px;\n\tline-height: var(--vscode-markdown-line-height, 22px);\n\tword-wrap: break-word;\n}\n\n#code-csp-warning {\n\tposition: fixed;\n\ttop: 0;\n\tright: 0;\n\tcolor: white;\n\tmargin: 16px;\n\ttext-align: center;\n\tfont-size: 12px;\n\tfont-family: sans-serif;\n\tbackground-color:#444444;\n\tcursor: pointer;\n\tpadding: 6px;\n\tbox-shadow: 1px 1px 1px rgba(0,0,0,.25);\n}\n\n#code-csp-warning:hover {\n\ttext-decoration: none;\n\tbackground-color:#007acc;\n\tbox-shadow: 2px 2px 2px rgba(0,0,0,.25);\n}\n\nbody.scrollBeyondLastLine {\n\tmargin-bottom: calc(100vh - 22px);\n}\n\nbody.showEditorSelection .code-line {\n\tposition: relative;\n}\n\nbody.showEditorSelection .code-active-line:before,\nbody.showEditorSelection .code-line:hover:before {\n\tcontent: \"\";\n\tdisplay: block;\n\tposition: absolute;\n\ttop: 0;\n\tleft: -12px;\n\theight: 100%;\n}\n\nbody.showEditorSelection li.code-active-line:before,\nbody.showEditorSelection li.code-line:hover:before {\n\tleft: -30px;\n}\n\n.vscode-light.showEditorSelection .code-active-line:before {\n\tborder-left: 3px solid rgba(0, 0, 0, 0.15);\n}\n\n.vscode-light.showEditorSelection .code-line:hover:before {\n\tborder-left: 3px solid rgba(0, 0, 0, 0.40);\n}\n\n.vscode-light.showEditorSelection .code-line .code-line:hover:before {\n\tborder-left: none;\n}\n\n.vscode-dark.showEditorSelection .code-active-line:before {\n\tborder-left: 3px solid rgba(255, 255, 255, 0.4);\n}\n\n.vscode-dark.showEditorSelection .code-line:hover:before {\n\tborder-left: 3px solid rgba(255, 255, 255, 0.60);\n}\n\n.vscode-dark.showEditorSelection .code-line .code-line:hover:before {\n\tborder-left: none;\n}\n\n.vscode-high-contrast.showEditorSelection .code-active-line:before {\n\tborder-left: 3px solid rgba(255, 160, 0, 0.7);\n}\n\n.vscode-high-contrast.showEditorSelection .code-line:hover:before {\n\tborder-left: 3px solid rgba(255, 160, 0, 1);\n}\n\n.vscode-high-contrast.showEditorSelection .code-line .code-line:hover:before {\n\tborder-left: none;\n}\n\nimg {\n\tmax-width: 100%;\n\tmax-height: 100%;\n}\n\na {\n\ttext-decoration: none;\n}\n\na:hover {\n\ttext-decoration: underline;\n}\n\na:focus,\ninput:focus,\nselect:focus,\ntextarea:focus {\n\toutline: 1px solid -webkit-focus-ring-color;\n\toutline-offset: -1px;\n}\n\nhr {\n\tborder: 0;\n\theight: 2px;\n\tborder-bottom: 2px solid;\n}\n\nh1 {\n\tpadding-bottom: 0.3em;\n\tline-height: 1.2;\n\tborder-bottom-width: 1px;\n\tborder-bottom-style: solid;\n}\n\nh1, h2, h3 {\n\tfont-weight: normal;\n}\n\ntable {\n\tborder-collapse: collapse;\n}\n\ntable > thead > tr > th {\n\ttext-align: left;\n\tborder-bottom: 1px solid;\n}\n\ntable > thead > tr > th,\ntable > thead > tr > td,\ntable > tbody > tr > th,\ntable > tbody > tr > td {\n\tpadding: 5px 10px;\n}\n\ntable > tbody > tr + tr > td {\n\tborder-top: 1px solid;\n}\n\nblockquote {\n\tmargin: 0 7px 0 5px;\n\tpadding: 0 16px 0 10px;\n\tborder-left-width: 5px;\n\tborder-left-style: solid;\n}\n\ncode {\n\tfont-family: Menlo, Monaco, Consolas, \"Droid Sans Mono\", \"Courier New\", monospace, \"Droid Sans Fallback\";\n\tfont-size: 1em;\n\tline-height: 1.357em;\n}\n\nbody.wordWrap pre {\n\twhite-space: pre-wrap;\n}\n\npre:not(.hljs),\npre.hljs code > div {\n\tpadding: 16px;\n\tborder-radius: 3px;\n\toverflow: auto;\n}\n\npre code {\n\tcolor: var(--vscode-editor-foreground);\n\ttab-size: 4;\n}\n\n/** Theming */\n\n.vscode-light pre {\n\tbackground-color: rgba(220, 220, 220, 0.4);\n}\n\n.vscode-dark pre {\n\tbackground-color: rgba(10, 10, 10, 0.4);\n}\n\n.vscode-high-contrast pre {\n\tbackground-color: rgb(0, 0, 0);\n}\n\n.vscode-high-contrast h1 {\n\tborder-color: rgb(0, 0, 0);\n}\n\n.vscode-light table > thead > tr > th {\n\tborder-color: rgba(0, 0, 0, 0.69);\n}\n\n.vscode-dark table > thead > tr > th {\n\tborder-color: rgba(255, 255, 255, 0.69);\n}\n\n.vscode-light h1,\n.vscode-light hr,\n.vscode-light table > tbody > tr + tr > td {\n\tborder-color: rgba(0, 0, 0, 0.18);\n}\n\n.vscode-dark h1,\n.vscode-dark hr,\n.vscode-dark table > tbody > tr + tr > td {\n\tborder-color: rgba(255, 255, 255, 0.18);\n}\n\n</style>\n\n<style>\n/* Tomorrow Theme */\n/* http://jmblog.github.com/color-themes-for-google-code-highlightjs */\n/* Original theme - https://github.com/chriskempson/tomorrow-theme */\n\n/* Tomorrow Comment */\n.hljs-comment,\n.hljs-quote {\n\tcolor: #8e908c;\n}\n\n/* Tomorrow Red */\n.hljs-variable,\n.hljs-template-variable,\n.hljs-tag,\n.hljs-name,\n.hljs-selector-id,\n.hljs-selector-class,\n.hljs-regexp,\n.hljs-deletion {\n\tcolor: #c82829;\n}\n\n/* Tomorrow Orange */\n.hljs-number,\n.hljs-built_in,\n.hljs-builtin-name,\n.hljs-literal,\n.hljs-type,\n.hljs-params,\n.hljs-meta,\n.hljs-link {\n\tcolor: #f5871f;\n}\n\n/* Tomorrow Yellow */\n.hljs-attribute {\n\tcolor: #eab700;\n}\n\n/* Tomorrow Green */\n.hljs-string,\n.hljs-symbol,\n.hljs-bullet,\n.hljs-addition {\n\tcolor: #718c00;\n}\n\n/* Tomorrow Blue */\n.hljs-title,\n.hljs-section {\n\tcolor: #4271ae;\n}\n\n/* Tomorrow Purple */\n.hljs-keyword,\n.hljs-selector-tag {\n\tcolor: #8959a8;\n}\n\n.hljs {\n\tdisplay: block;\n\toverflow-x: auto;\n\tcolor: #4d4d4c;\n\tpadding: 0.5em;\n}\n\n.hljs-emphasis {\n\tfont-style: italic;\n}\n\n.hljs-strong {\n\tfont-weight: bold;\n}\n</style>\n\n<style>\n/*\n * Markdown PDF CSS\n */\n\n body {\n\tfont-family: -apple-system, BlinkMacSystemFont, \"Segoe WPC\", \"Segoe UI\", \"Ubuntu\", \"Droid Sans\", sans-serif, \"Meiryo\";\n\tpadding: 0 12px;\n}\n\npre {\n\tbackground-color: #f8f8f8;\n\tborder: 1px solid #cccccc;\n\tborder-radius: 3px;\n\toverflow-x: auto;\n\twhite-space: pre-wrap;\n\toverflow-wrap: break-word;\n}\n\npre:not(.hljs) {\n\tpadding: 23px;\n\tline-height: 19px;\n}\n\nblockquote {\n\tbackground: rgba(127, 127, 127, 0.1);\n\tborder-color: rgba(0, 122, 204, 0.5);\n}\n\n.emoji {\n\theight: 1.4em;\n}\n\ncode {\n\tfont-size: 14px;\n\tline-height: 19px;\n}\n\n/* for inline code */\n:not(pre):not(.hljs) > code {\n\tcolor: #C9AE75; /* Change the old color so it seems less like an error */\n\tfont-size: inherit;\n}\n\n/* Page Break : use <div class=\"page\"/> to insert page break\n-------------------------------------------------------- */\n.page {\n\tpage-break-after: always;\n}\n\n</style>\n\n<script src=\"https://unpkg.com/mermaid/dist/mermaid.min.js\"></script>\n</head>\n<body>\n  <script>\n    mermaid.initialize({\n      startOnLoad: true,\n      theme: document.body.classList.contains('vscode-dark') || document.body.classList.contains('vscode-high-contrast')\n          ? 'dark'\n          : 'default'\n    });\n  </script>\n<h1 id=\"%E8%81%94%E7%B3%BB%E6%96%B9%E5%BC%8F\">联系方式</h1>\n<ul>\n<li>手机：15810692477</li>\n<li>Email：kongzheng1993@hotmail.com</li>\n<li>QQ/微信号：767141624/evilrat</li>\n</ul>\n<hr>\n<h1 id=\"%E4%B8%AA%E4%BA%BA%E4%BF%A1%E6%81%AF\">个人信息</h1>\n<ul>\n<li>孔征/男/1992</li>\n<li>本科/菏泽学院/计算机与信息工程系</li>\n<li>毕业时间：2016年7月</li>\n<li>技术博客：<a href=\"https://kongzheng1993.github.io\">https://kongzheng1993.github.io</a></li>\n<li>Github: <a href=\"https://github.com/kongzheng1993\" target=\"_blank\" rel=\"noopener\">https://github.com/kongzheng1993</a></li>\n<li>微信公众号：evilRat</li>\n</ul>\n<hr>\n<h1 id=\"%E8%BF%91%E5%86%B5%E7%AE%80%E4%BB%8B\">近况简介</h1>\n<p>目前在理想汽车担任<strong>交付准备系统SE（负责人）</strong>，系统相关人员包括开发3人、测试2人、产品1人、业务1人。</p>\n<p>研发过程为敏捷迭代：</p>\n<ul>\n<li>使用飞书（项目、IM、文档、视频会议、OKR、日历）工具进行协作和项目管理</li>\n<li>使用Git进行代码版本控制</li>\n<li>使用Gerrit（CR）、Jenkins（BV）、Sonar（SV）保证代码质量</li>\n<li>使用Jenkins、K8s、Docker、Git实现全流程的CI/CD。</li>\n</ul>\n<p>作为系统负责人，参与需求研发的全流程，包括需求评审、产品评审、排期、技术方案设计、任务分配、功能开发、测试用例评审和bug修复。关注相关服务的健康状态，适时进行重构、优化。保障上线操作无误，至今0回滚，系统常年可用性在99.99%以上。</p>\n<p>此外，作为研发部核心骨干参与发布会等重大项目。</p>\n<h1 id=\"%E5%B7%A5%E4%BD%9C%E7%BB%8F%E9%AA%8C\">工作经验</h1>\n<h2 id=\"%E7%90%86%E6%83%B3%E6%B1%BD%E8%BD%A6-2020%E5%B9%B49%E6%9C%88%E8%87%B3%E4%BB%8A\">理想汽车  （2020年9月至今）</h2>\n<p>企业系统部，负责交付、物流和质量相关系统研发工作。</p>\n<h2 id=\"%E4%BA%9A%E4%BF%A1%E7%A7%91%E6%8A%80-2018%E5%B9%B410%E6%9C%88-2020%E5%B9%B46%E6%9C%88\">亚信科技 （2018年10月-2020年6月）</h2>\n<p>北京移动客服项目、中移在线北京分公司统一接口平台、移动营业厅一体机等项目开发。作为组内主力开发，组内5人，解决开发过程中的难点、重点问题，保证需求按时高质量交付。</p>\n<h2 id=\"%E8%BD%AF%E9%80%9A%E5%8A%A8%E5%8A%9B-2016%E5%B9%B48%E6%9C%88-2018%E5%B9%B410%E6%9C%88\">软通动力 （2016年8月-2018年10月）</h2>\n<p>中国移动在线服务公司北京10086&amp;12580呼叫中心开发运维工作，包括呼叫中心流程开发、数据库开发和接口开发。</p>\n<hr>\n<h1 id=\"%E9%A1%B9%E7%9B%AE%E7%BB%8F%E9%AA%8C\">项目经验</h1>\n<h2 id=\"%E7%90%86%E6%83%B3%E6%B1%BD%E8%BD%A6l7%E5%8F%91%E5%B8%83%E4%BC%9A%E9%A1%B9%E7%9B%AE2022%E5%B9%B410%E6%9C%88--2023%E5%B9%B42%E6%9C%88\">理想汽车L7发布会项目（2022年10月--2023年2月）</h2>\n<p>理想汽车新车发布会是公司级重点项目，是对企业系统的一次大流量考验，是理想汽车的“双11”。本人在项目中参与了服务核心链路梳理，交易系统Code Review和重构，服务扩容、限流、降级功能梳理，应急预案设计，作战手册制定，发布会排练以及最终发布会保障。发布会过程中负责服务的监控和水位播报，按照作战手册完成发布会中的服务降级、限流等操作，监控网关异常流量，配合安全团队封禁恶意IP。最终0失误完成发布会保障工作，呈现了一场完美的发布会，2月8日当晚理想发布会很“苹果”冲上微博热搜。</p>\n<h2 id=\"%E4%BA%A4%E4%BB%98%E5%87%86%E5%A4%87%E7%B3%BB%E7%BB%9F2021%E5%B9%B45%E6%9C%88%E8%87%B3%E4%BB%8A\">交付准备系统（2021年5月至今）</h2>\n<p>交付准备管理系统（PC&amp;APP），车辆清洗、PDI、整备、终检、OTA升级和质量登记等功能，主要是交付中心PDI团队人员和管理者使用。车辆交付周期内节点事件触发系统自动生成响应的工单，PDI人员可以通过PC或者APP操作相关工单或手动创建/取消工单，管理者可以通过系统查看数据、管理团队。</p>\n<ul>\n<li>作为系统负责人，参与需求评审、产品评审、排期、任务分配、功能开发、测试用例评审和bug修复工作</li>\n<li>服务监控、告警跟进处理、代码重构、需求自驱等</li>\n<li>负责理想家APP交付准备系统研发项目。系统上线后，交付中心的pdi时间由原来的半小时以上，降低到13分钟。<strong>本人也因此在2021年Q4得到绩效E（超出预期）</strong></li>\n<li>打通售后服务系统，质损创建维修工单耗时缩短80%</li>\n</ul>\n<h2 id=\"%E6%95%B4%E8%BD%A6%E7%89%A9%E6%B5%81%E7%B3%BB%E7%BB%9F2020%E5%B9%B49%E6%9C%88%E8%87%B3%E4%BB%8A\">整车物流系统（2020年9月至今）</h2>\n<p>车辆下产线到交付交接完成期间的车辆运输和仓储相关的业务系统，事件驱动，实现车辆的自动/手动释放，出入库单、运输单、提交车计划和司机板车的管理，以及车辆运输的质量管理和供应商绩效的管理，系统包括PC端管理系统、APP（车辆维护、远程交付、特殊运输）和车辆交接微信小程序。参与新功能开发和旧有功能的维护和优化。</p>\n<ul>\n<li>车辆维护APP后台的开发和上线，其中对于生成车辆维护工单的逻辑优化，使工单生成的业务节点更准确，避免了重复生成维护工单，APP的使用提高人效50%</li>\n<li>车辆交接小程序中提车计划的重构，规范了板车司机、门卫、仓管和运管的操作，闭环了车辆生产完成到交付完成之间每一次运输的提车和交车流程</li>\n<li>理想汽车远程交付功能开发（PC端+APP端），支持配送车辆到客户指定地点进行交接，简化业务流程，提升用户体验。获得了<strong>2022年中国汽车物流行业创新奖</strong></li>\n</ul>\n<h2 id=\"%E6%95%B4%E8%BD%A6%E4%BA%A4%E4%BB%98%E7%B3%BB%E7%BB%9F2020%E5%B9%B49%E6%9C%88--2021%E5%B9%B46%E6%9C%88\">整车交付系统（2020年9月--2021年6月）</h2>\n<p>用户主要是交付专家和中央管理人员，主要功能包括交付单管理、交付任务管理等。本人的工作是在添加新功能的同时维护已有功能，通过技术手段提高交付人员的效率，降低交付成本。负责开发了交付违约管理、交付pipeline等功能。交付违约管理功能，在客户无法在预约时间提车时，交付专家可以手动或者订单取消、挂起等事件自动触发进入违约流程，创建违约工单群，并将产品专家、零售店长、交付专家、交付店长等订单相关人员拉入群聊，在飞书机器人的引导下，完成发送提醒短信给用户等跟进手段，提高了人效、降低了沟通成本，<strong>客户违约率降低30%</strong>。</p>\n<!-- ## NGTASK任务调度系统（2019年11月-2020年1月）\n\n由于携号转网业务需要同步携转数据，客户要求开发一个任务调度系统，可以通过web页面新增、修改、删除、查询任务。项目框架核心（不含业务代码）我已分享到[github:ngtask](https://github.com/kongzheng1993/ngtask)。独立开发。springboot+quartz+mysql+zookeeper，实现mysql数据导入导出任务，ftp/sftp上传下载任务。任务失败告警功能。\n\n## 中移在线一体机项目 （2019年3月-2019年9月）\n\n中移在线一体机项目是供移动营业厅一体机和pad等移动设备使用的web应用，提供实名制认证、停开机、补卡、开户等业务。使用springboot+vue+mysql。调用接口平台完成客户业务。项目搭建并开发，负责开发了补卡业务流程、包括服务密码验证、人证比对、旧卡校验、补卡、无纸化等流程。随着一体机的上线使用，用户可以通过一体机自助办理业务，减轻了营业厅服务人员的压力，提升了用户满意度。 -->\n<h2 id=\"%E4%B8%AD%E7%A7%BB%E5%9C%A8%E7%BA%BF%E5%8C%97%E4%BA%AC%E7%BB%9F%E4%B8%80%E6%8E%A5%E5%8F%A3%E5%B9%B3%E5%8F%B02018%E5%B9%B410%E6%9C%88--2020%E5%B9%B46%E6%9C%88\">中移在线北京统一接口平台（2018年10月--2020年6月）</h2>\n<p>此项目为中国移动在线公司北京分公司统一接口平台。此系统为中间层，为中移在线北京分公司10086IVR、营业厅一体机、app、微信、门户网站等渠道提供接入转接服务。各渠道过来的请求，由接口平台转接到能力提供方，再将能力响应信息返回给调用方。大部分接口要做一些数据格式的转换和数据内容的映射，以适应各个渠道的调用。此系统为分布式架构（nginx、tomcat、redis、mysql、zookeeper、dubbo），使用spring作为ioc容器，使用jersey提供RESTful接口。在页面可以进行接入接口、转接接口、接口映射、接口编排、接入参数、转接参数、参数映射、接入渠道、渠道权限等的配置。接收请求后，程序会通过调用url获取到通过redis/mysql获取到此接口的相关配置，并根据获取到的参数配置进行参数校验、参数处理、参数映射，调用转接接口获取响应后处理并返回给调用方。根据需求完成各类接口的开发、测试、联调、发布。负责实现了项目的动态数据源和redis集群搭建与集成。</p>\n<ul>\n<li>“移娃”项目中，引入redis实现了用户和“移娃”的会话上下文记录10min，利用redis速度和过期时间的天然优势，完美实现了功能</li>\n<li>优化了接口平台字段名大写蛇形（XXX_YYY）转驼峰（xxxYYY）算法，<strong>500ms优化到20ms</strong>，极大提高了接口RT。<a href=\"https://kongzheng1993.github.io/2020/03/25/kongzheng1993-%E4%B8%80%E6%AC%A1%E8%80%81%E4%BB%A3%E7%A0%81%E4%BC%98%E5%8C%96/\"><strong>查看详情</strong></a></li>\n</ul>\n<!-- ## 北京移动客服系统 （2018年12月-2019年3月）\n\n此系统使用亚信AppFrame（封装了ssh、jquery、html等技术）框架，提供给北京移动客服人员使用，业务比较复杂。\n主要功能：\n\n1. 呼叫中心，集成华为呼叫中心，接听来话，外呼等。\n2. 工单，新建工单、工单派发、认领等功能等。\n3. 服务，提供给其他系统接口。\n4. 客户关系管理，客户黑灰红白名单录入、设置等，客户信息查询、修改等\n5. 后台进程。\n\n在原有基础上新增、修改功能。完成黑灰名单自动填充失效时间、工单流转信息查询功能、向crm提供工单流转信息查询功能接口等需求。认真了解了公司框架，熟练完成前后端开发。 -->\n<hr>\n<h1 id=\"%E4%B8%93%E4%B8%9A%E6%8A%80%E8%83%BD\">专业技能</h1>\n<!-- &#x2B50;：了解，会用\n\n&#x2B50;&#x2B50;：熟悉，框架看过一些源码，中间件知道原理，工具会使用主要功能\n\n&#x2B50;&#x2B50;&#x2B50;：精通，框架看过大部分源码，中间件看过一些源码，工具会使用大部分功能  -->\n<h2 id=\"%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80\">编程语言</h2>\n<ul>\n<li>Java: ⭐⭐⭐</li>\n<li>SQL: ⭐⭐⭐</li>\n<li>JavaScript: ⭐⭐</li>\n<li>HTML: ⭐⭐</li>\n<li>CSS: ⭐⭐</li>\n<li>Python: ⭐</li>\n<li>Shell: ⭐</li>\n</ul>\n<h2 id=\"%E5%B7%A5%E5%85%B7\">工具</h2>\n<ul>\n<li>Maven: ⭐⭐⭐</li>\n<li>Git: ⭐⭐⭐</li>\n<li>SVN: ⭐⭐⭐</li>\n<li>Element UI: ⭐⭐⭐</li>\n</ul>\n<!-- - Ant: &#x2B50; -->\n<!-- - Gradle: &#x2B50; -->\n<h2 id=\"%E6%A1%86%E6%9E%B6\">框架</h2>\n<ul>\n<li>Spring: ⭐⭐⭐</li>\n<li>Spring Cloud: ⭐⭐</li>\n<li>MyBatis: ⭐⭐⭐</li>\n<li>Vue: ⭐⭐</li>\n<li>JUnit: ⭐</li>\n</ul>\n<!-- - ASM: &#x2B50;\n- Netty: &#x2B50;\n- Dubbo: &#x2B50; -->\n<h2 id=\"%E4%B8%AD%E9%97%B4%E4%BB%B6\">中间件</h2>\n<ul>\n<li>MySQL: ⭐⭐</li>\n<li>Oracle: ⭐⭐</li>\n<li>RocketMQ: ⭐</li>\n<li>Zookeeper: ⭐</li>\n<li>Redis: ⭐⭐</li>\n</ul>\n<!-- - Kafka: &#x2B50; -->\n<!-- - Nginx: &#x2B50; -->\n<h2 id=\"%E5%85%B6%E4%BB%96\">其他</h2>\n<ul>\n<li>Docker：⭐</li>\n<li>K8s：⭐</li>\n<li>Jenkins：⭐</li>\n<li>Flink：⭐</li>\n</ul>\n<hr>\n<h1 id=\"%E5%BC%80%E6%BA%90%E4%BD%9C%E5%93%81\">开源作品</h1>\n<h3 id=\"1-ftp%E6%96%87%E4%BB%B6%E4%B8%8B%E8%BD%BD%E5%B7%A5%E5%85%B7-githubdownloadfiles\">1.  ftp文件下载工具 <a href=\"https://github.com/kongzheng1993/downloadFiles\" target=\"_blank\" rel=\"noopener\">github:downloadFiles</a></h3>\n<!-- 帮运维同事写的小工具，他手头有个任务，每天一早到工位就要去8台sftp下载录音文件（任务调度平台故障，恢复之前只能手动搞），所以用python帮他做了个小工具。使用paramiko连接sftp、json模块解析配置文件、logging记录日志、zipfile模块压缩文件、threading模拟多线程。最后我还用pyinstaller打包成exe，他写好配置文件，双击就能执行，并且日志会持久化到文件。代码已经分享到[github:downloadFiles](https://github.com/kongzheng1993/downloadFiles)。 -->\n<h3 id=\"2-testivr%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E7%94%9F%E6%88%90%E5%B7%A5%E5%85%B7-githubguigeneratetestivrconfig\">2. testIVR配置文件生成工具 <a href=\"https://github.com/kongzheng1993/GuiGenerateTestIVRConfig\" target=\"_blank\" rel=\"noopener\">github:GuiGenerateTestIVRConfig</a></h3>\n<h3 id=\"3-%E4%BD%BF%E7%94%A8nodejszookeeperredis%E5%AE%9E%E7%8E%B0%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0-githubevil-service-discovery\">3. 使用node.js+zookeeper+redis实现服务发现 <a href=\"https://github.com/kongzheng1993/evil-service-discovery\" target=\"_blank\" rel=\"noopener\">github:evil-service-discovery</a></h3>\n<h3 id=\"4-springbootquartzmysql%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1%E9%9B%86%E7%BE%A4-githubeviltask\">4. springboot+quartz+mysql定时任务集群 <a href=\"https://github.com/kongzheng1993/Eviltask\" target=\"_blank\" rel=\"noopener\">github:EvilTask</a></h3>\n<p><strong>更多请查看我的<a href=\"https://github.com/kongzheng1993\" target=\"_blank\" rel=\"noopener\">github</a></strong></p>\n<!-- 来到项目后发现大家使用的调试接口的工具testIVR(模拟ivr流程调用socket和http接口工具) 总是需要手动配置，而且错误率特别高，经常因为一个小问题找半天。在熟悉了testIVR之后，我使用python-tkinter写了一个自动生成testIVR配置文件的工具，在项目组内广泛应用，并得到了领导和客户的好评。\n\n使用python的tkinter库编写gui。通过获取用户在输入控件(Entry)中输入的ivr_id、dtproxy_ip、dtproxy_id和参数配置。编写 cleanparam()函数清洗找出入参，和出参个数。编写dogenerate()函数生成ivr和dtproxy的配置，并循环生成入参、出参配置。使用python的 pyinstaller工具生成exe可执行文件。详情请查看我的[github:GuiGenerateTestIVRConfig](https://github.com/kongzheng1993/GuiGenerateTestIVRConfig) -->\n<h1 id=\"%E8%87%AA%E6%88%91%E8%AF%84%E4%BB%B7\">自我评价</h1>\n<p>有较好的职业素养，对工作积极负责，有创新意识和团队合作精神。热爱技术、热爱编码、热爱学习，喜欢阅读技术书刊、源码，学习能力较强，能快速将学习内容转化为生产力。态度乐观，有较好的沟通能力，为人热情，可以在工作中统合综效，实现共赢。</p>\n<hr>\n<h1 id=\"%E8%87%B4%E8%B0%A2\">致谢</h1>\n<p>感谢您花时间阅读我的简历，期待能有机会和您共事。</p>\n\n</body>\n</html>\n","site":{"data":{}},"excerpt":"","more":"<!DOCTYPE html>\n<html>\n<head><meta name=\"generator\" content=\"Hexo 3.9.0\">\n<title>2016-05-21-kongzheng1993-resume.md</title>\n<meta http-equiv=\"Content-type\" content=\"text/html;charset=UTF-8\">\n\n<style>\n/* https://github.com/microsoft/vscode/blob/master/extensions/markdown-language-features/media/markdown.css */\n/*---------------------------------------------------------------------------------------------\n *  Copyright (c) Microsoft Corporation. All rights reserved.\n *  Licensed under the MIT License. See License.txt in the project root for license information.\n *--------------------------------------------------------------------------------------------*/\n\nbody {\n\tfont-family: var(--vscode-markdown-font-family, -apple-system, BlinkMacSystemFont, \"Segoe WPC\", \"Segoe UI\", \"Ubuntu\", \"Droid Sans\", sans-serif);\n\tfont-size: var(--vscode-markdown-font-size, 14px);\n\tpadding: 0 26px;\n\tline-height: var(--vscode-markdown-line-height, 22px);\n\tword-wrap: break-word;\n}\n\n#code-csp-warning {\n\tposition: fixed;\n\ttop: 0;\n\tright: 0;\n\tcolor: white;\n\tmargin: 16px;\n\ttext-align: center;\n\tfont-size: 12px;\n\tfont-family: sans-serif;\n\tbackground-color:#444444;\n\tcursor: pointer;\n\tpadding: 6px;\n\tbox-shadow: 1px 1px 1px rgba(0,0,0,.25);\n}\n\n#code-csp-warning:hover {\n\ttext-decoration: none;\n\tbackground-color:#007acc;\n\tbox-shadow: 2px 2px 2px rgba(0,0,0,.25);\n}\n\nbody.scrollBeyondLastLine {\n\tmargin-bottom: calc(100vh - 22px);\n}\n\nbody.showEditorSelection .code-line {\n\tposition: relative;\n}\n\nbody.showEditorSelection .code-active-line:before,\nbody.showEditorSelection .code-line:hover:before {\n\tcontent: \"\";\n\tdisplay: block;\n\tposition: absolute;\n\ttop: 0;\n\tleft: -12px;\n\theight: 100%;\n}\n\nbody.showEditorSelection li.code-active-line:before,\nbody.showEditorSelection li.code-line:hover:before {\n\tleft: -30px;\n}\n\n.vscode-light.showEditorSelection .code-active-line:before {\n\tborder-left: 3px solid rgba(0, 0, 0, 0.15);\n}\n\n.vscode-light.showEditorSelection .code-line:hover:before {\n\tborder-left: 3px solid rgba(0, 0, 0, 0.40);\n}\n\n.vscode-light.showEditorSelection .code-line .code-line:hover:before {\n\tborder-left: none;\n}\n\n.vscode-dark.showEditorSelection .code-active-line:before {\n\tborder-left: 3px solid rgba(255, 255, 255, 0.4);\n}\n\n.vscode-dark.showEditorSelection .code-line:hover:before {\n\tborder-left: 3px solid rgba(255, 255, 255, 0.60);\n}\n\n.vscode-dark.showEditorSelection .code-line .code-line:hover:before {\n\tborder-left: none;\n}\n\n.vscode-high-contrast.showEditorSelection .code-active-line:before {\n\tborder-left: 3px solid rgba(255, 160, 0, 0.7);\n}\n\n.vscode-high-contrast.showEditorSelection .code-line:hover:before {\n\tborder-left: 3px solid rgba(255, 160, 0, 1);\n}\n\n.vscode-high-contrast.showEditorSelection .code-line .code-line:hover:before {\n\tborder-left: none;\n}\n\nimg {\n\tmax-width: 100%;\n\tmax-height: 100%;\n}\n\na {\n\ttext-decoration: none;\n}\n\na:hover {\n\ttext-decoration: underline;\n}\n\na:focus,\ninput:focus,\nselect:focus,\ntextarea:focus {\n\toutline: 1px solid -webkit-focus-ring-color;\n\toutline-offset: -1px;\n}\n\nhr {\n\tborder: 0;\n\theight: 2px;\n\tborder-bottom: 2px solid;\n}\n\nh1 {\n\tpadding-bottom: 0.3em;\n\tline-height: 1.2;\n\tborder-bottom-width: 1px;\n\tborder-bottom-style: solid;\n}\n\nh1, h2, h3 {\n\tfont-weight: normal;\n}\n\ntable {\n\tborder-collapse: collapse;\n}\n\ntable > thead > tr > th {\n\ttext-align: left;\n\tborder-bottom: 1px solid;\n}\n\ntable > thead > tr > th,\ntable > thead > tr > td,\ntable > tbody > tr > th,\ntable > tbody > tr > td {\n\tpadding: 5px 10px;\n}\n\ntable > tbody > tr + tr > td {\n\tborder-top: 1px solid;\n}\n\nblockquote {\n\tmargin: 0 7px 0 5px;\n\tpadding: 0 16px 0 10px;\n\tborder-left-width: 5px;\n\tborder-left-style: solid;\n}\n\ncode {\n\tfont-family: Menlo, Monaco, Consolas, \"Droid Sans Mono\", \"Courier New\", monospace, \"Droid Sans Fallback\";\n\tfont-size: 1em;\n\tline-height: 1.357em;\n}\n\nbody.wordWrap pre {\n\twhite-space: pre-wrap;\n}\n\npre:not(.hljs),\npre.hljs code > div {\n\tpadding: 16px;\n\tborder-radius: 3px;\n\toverflow: auto;\n}\n\npre code {\n\tcolor: var(--vscode-editor-foreground);\n\ttab-size: 4;\n}\n\n/** Theming */\n\n.vscode-light pre {\n\tbackground-color: rgba(220, 220, 220, 0.4);\n}\n\n.vscode-dark pre {\n\tbackground-color: rgba(10, 10, 10, 0.4);\n}\n\n.vscode-high-contrast pre {\n\tbackground-color: rgb(0, 0, 0);\n}\n\n.vscode-high-contrast h1 {\n\tborder-color: rgb(0, 0, 0);\n}\n\n.vscode-light table > thead > tr > th {\n\tborder-color: rgba(0, 0, 0, 0.69);\n}\n\n.vscode-dark table > thead > tr > th {\n\tborder-color: rgba(255, 255, 255, 0.69);\n}\n\n.vscode-light h1,\n.vscode-light hr,\n.vscode-light table > tbody > tr + tr > td {\n\tborder-color: rgba(0, 0, 0, 0.18);\n}\n\n.vscode-dark h1,\n.vscode-dark hr,\n.vscode-dark table > tbody > tr + tr > td {\n\tborder-color: rgba(255, 255, 255, 0.18);\n}\n\n</style>\n\n<style>\n/* Tomorrow Theme */\n/* http://jmblog.github.com/color-themes-for-google-code-highlightjs */\n/* Original theme - https://github.com/chriskempson/tomorrow-theme */\n\n/* Tomorrow Comment */\n.hljs-comment,\n.hljs-quote {\n\tcolor: #8e908c;\n}\n\n/* Tomorrow Red */\n.hljs-variable,\n.hljs-template-variable,\n.hljs-tag,\n.hljs-name,\n.hljs-selector-id,\n.hljs-selector-class,\n.hljs-regexp,\n.hljs-deletion {\n\tcolor: #c82829;\n}\n\n/* Tomorrow Orange */\n.hljs-number,\n.hljs-built_in,\n.hljs-builtin-name,\n.hljs-literal,\n.hljs-type,\n.hljs-params,\n.hljs-meta,\n.hljs-link {\n\tcolor: #f5871f;\n}\n\n/* Tomorrow Yellow */\n.hljs-attribute {\n\tcolor: #eab700;\n}\n\n/* Tomorrow Green */\n.hljs-string,\n.hljs-symbol,\n.hljs-bullet,\n.hljs-addition {\n\tcolor: #718c00;\n}\n\n/* Tomorrow Blue */\n.hljs-title,\n.hljs-section {\n\tcolor: #4271ae;\n}\n\n/* Tomorrow Purple */\n.hljs-keyword,\n.hljs-selector-tag {\n\tcolor: #8959a8;\n}\n\n.hljs {\n\tdisplay: block;\n\toverflow-x: auto;\n\tcolor: #4d4d4c;\n\tpadding: 0.5em;\n}\n\n.hljs-emphasis {\n\tfont-style: italic;\n}\n\n.hljs-strong {\n\tfont-weight: bold;\n}\n</style>\n\n<style>\n/*\n * Markdown PDF CSS\n */\n\n body {\n\tfont-family: -apple-system, BlinkMacSystemFont, \"Segoe WPC\", \"Segoe UI\", \"Ubuntu\", \"Droid Sans\", sans-serif, \"Meiryo\";\n\tpadding: 0 12px;\n}\n\npre {\n\tbackground-color: #f8f8f8;\n\tborder: 1px solid #cccccc;\n\tborder-radius: 3px;\n\toverflow-x: auto;\n\twhite-space: pre-wrap;\n\toverflow-wrap: break-word;\n}\n\npre:not(.hljs) {\n\tpadding: 23px;\n\tline-height: 19px;\n}\n\nblockquote {\n\tbackground: rgba(127, 127, 127, 0.1);\n\tborder-color: rgba(0, 122, 204, 0.5);\n}\n\n.emoji {\n\theight: 1.4em;\n}\n\ncode {\n\tfont-size: 14px;\n\tline-height: 19px;\n}\n\n/* for inline code */\n:not(pre):not(.hljs) > code {\n\tcolor: #C9AE75; /* Change the old color so it seems less like an error */\n\tfont-size: inherit;\n}\n\n/* Page Break : use <div class=\"page\"/> to insert page break\n-------------------------------------------------------- */\n.page {\n\tpage-break-after: always;\n}\n\n</style>\n\n<script src=\"https://unpkg.com/mermaid/dist/mermaid.min.js\"></script>\n</head>\n<body>\n  <script>\n    mermaid.initialize({\n      startOnLoad: true,\n      theme: document.body.classList.contains('vscode-dark') || document.body.classList.contains('vscode-high-contrast')\n          ? 'dark'\n          : 'default'\n    });\n  </script>\n<h1 id=\"%E8%81%94%E7%B3%BB%E6%96%B9%E5%BC%8F\">联系方式</h1>\n<ul>\n<li>手机：15810692477</li>\n<li>Email：kongzheng1993@hotmail.com</li>\n<li>QQ/微信号：767141624/evilrat</li>\n</ul>\n<hr>\n<h1 id=\"%E4%B8%AA%E4%BA%BA%E4%BF%A1%E6%81%AF\">个人信息</h1>\n<ul>\n<li>孔征/男/1992</li>\n<li>本科/菏泽学院/计算机与信息工程系</li>\n<li>毕业时间：2016年7月</li>\n<li>技术博客：<a href=\"https://kongzheng1993.github.io\">https://kongzheng1993.github.io</a></li>\n<li>Github: <a href=\"https://github.com/kongzheng1993\" target=\"_blank\" rel=\"noopener\">https://github.com/kongzheng1993</a></li>\n<li>微信公众号：evilRat</li>\n</ul>\n<hr>\n<h1 id=\"%E8%BF%91%E5%86%B5%E7%AE%80%E4%BB%8B\">近况简介</h1>\n<p>目前在理想汽车担任<strong>交付准备系统SE（负责人）</strong>，系统相关人员包括开发3人、测试2人、产品1人、业务1人。</p>\n<p>研发过程为敏捷迭代：</p>\n<ul>\n<li>使用飞书（项目、IM、文档、视频会议、OKR、日历）工具进行协作和项目管理</li>\n<li>使用Git进行代码版本控制</li>\n<li>使用Gerrit（CR）、Jenkins（BV）、Sonar（SV）保证代码质量</li>\n<li>使用Jenkins、K8s、Docker、Git实现全流程的CI/CD。</li>\n</ul>\n<p>作为系统负责人，参与需求研发的全流程，包括需求评审、产品评审、排期、技术方案设计、任务分配、功能开发、测试用例评审和bug修复。关注相关服务的健康状态，适时进行重构、优化。保障上线操作无误，至今0回滚，系统常年可用性在99.99%以上。</p>\n<p>此外，作为研发部核心骨干参与发布会等重大项目。</p>\n<h1 id=\"%E5%B7%A5%E4%BD%9C%E7%BB%8F%E9%AA%8C\">工作经验</h1>\n<h2 id=\"%E7%90%86%E6%83%B3%E6%B1%BD%E8%BD%A6-2020%E5%B9%B49%E6%9C%88%E8%87%B3%E4%BB%8A\">理想汽车  （2020年9月至今）</h2>\n<p>企业系统部，负责交付、物流和质量相关系统研发工作。</p>\n<h2 id=\"%E4%BA%9A%E4%BF%A1%E7%A7%91%E6%8A%80-2018%E5%B9%B410%E6%9C%88-2020%E5%B9%B46%E6%9C%88\">亚信科技 （2018年10月-2020年6月）</h2>\n<p>北京移动客服项目、中移在线北京分公司统一接口平台、移动营业厅一体机等项目开发。作为组内主力开发，组内5人，解决开发过程中的难点、重点问题，保证需求按时高质量交付。</p>\n<h2 id=\"%E8%BD%AF%E9%80%9A%E5%8A%A8%E5%8A%9B-2016%E5%B9%B48%E6%9C%88-2018%E5%B9%B410%E6%9C%88\">软通动力 （2016年8月-2018年10月）</h2>\n<p>中国移动在线服务公司北京10086&amp;12580呼叫中心开发运维工作，包括呼叫中心流程开发、数据库开发和接口开发。</p>\n<hr>\n<h1 id=\"%E9%A1%B9%E7%9B%AE%E7%BB%8F%E9%AA%8C\">项目经验</h1>\n<h2 id=\"%E7%90%86%E6%83%B3%E6%B1%BD%E8%BD%A6l7%E5%8F%91%E5%B8%83%E4%BC%9A%E9%A1%B9%E7%9B%AE2022%E5%B9%B410%E6%9C%88--2023%E5%B9%B42%E6%9C%88\">理想汽车L7发布会项目（2022年10月--2023年2月）</h2>\n<p>理想汽车新车发布会是公司级重点项目，是对企业系统的一次大流量考验，是理想汽车的“双11”。本人在项目中参与了服务核心链路梳理，交易系统Code Review和重构，服务扩容、限流、降级功能梳理，应急预案设计，作战手册制定，发布会排练以及最终发布会保障。发布会过程中负责服务的监控和水位播报，按照作战手册完成发布会中的服务降级、限流等操作，监控网关异常流量，配合安全团队封禁恶意IP。最终0失误完成发布会保障工作，呈现了一场完美的发布会，2月8日当晚理想发布会很“苹果”冲上微博热搜。</p>\n<h2 id=\"%E4%BA%A4%E4%BB%98%E5%87%86%E5%A4%87%E7%B3%BB%E7%BB%9F2021%E5%B9%B45%E6%9C%88%E8%87%B3%E4%BB%8A\">交付准备系统（2021年5月至今）</h2>\n<p>交付准备管理系统（PC&amp;APP），车辆清洗、PDI、整备、终检、OTA升级和质量登记等功能，主要是交付中心PDI团队人员和管理者使用。车辆交付周期内节点事件触发系统自动生成响应的工单，PDI人员可以通过PC或者APP操作相关工单或手动创建/取消工单，管理者可以通过系统查看数据、管理团队。</p>\n<ul>\n<li>作为系统负责人，参与需求评审、产品评审、排期、任务分配、功能开发、测试用例评审和bug修复工作</li>\n<li>服务监控、告警跟进处理、代码重构、需求自驱等</li>\n<li>负责理想家APP交付准备系统研发项目。系统上线后，交付中心的pdi时间由原来的半小时以上，降低到13分钟。<strong>本人也因此在2021年Q4得到绩效E（超出预期）</strong></li>\n<li>打通售后服务系统，质损创建维修工单耗时缩短80%</li>\n</ul>\n<h2 id=\"%E6%95%B4%E8%BD%A6%E7%89%A9%E6%B5%81%E7%B3%BB%E7%BB%9F2020%E5%B9%B49%E6%9C%88%E8%87%B3%E4%BB%8A\">整车物流系统（2020年9月至今）</h2>\n<p>车辆下产线到交付交接完成期间的车辆运输和仓储相关的业务系统，事件驱动，实现车辆的自动/手动释放，出入库单、运输单、提交车计划和司机板车的管理，以及车辆运输的质量管理和供应商绩效的管理，系统包括PC端管理系统、APP（车辆维护、远程交付、特殊运输）和车辆交接微信小程序。参与新功能开发和旧有功能的维护和优化。</p>\n<ul>\n<li>车辆维护APP后台的开发和上线，其中对于生成车辆维护工单的逻辑优化，使工单生成的业务节点更准确，避免了重复生成维护工单，APP的使用提高人效50%</li>\n<li>车辆交接小程序中提车计划的重构，规范了板车司机、门卫、仓管和运管的操作，闭环了车辆生产完成到交付完成之间每一次运输的提车和交车流程</li>\n<li>理想汽车远程交付功能开发（PC端+APP端），支持配送车辆到客户指定地点进行交接，简化业务流程，提升用户体验。获得了<strong>2022年中国汽车物流行业创新奖</strong></li>\n</ul>\n<h2 id=\"%E6%95%B4%E8%BD%A6%E4%BA%A4%E4%BB%98%E7%B3%BB%E7%BB%9F2020%E5%B9%B49%E6%9C%88--2021%E5%B9%B46%E6%9C%88\">整车交付系统（2020年9月--2021年6月）</h2>\n<p>用户主要是交付专家和中央管理人员，主要功能包括交付单管理、交付任务管理等。本人的工作是在添加新功能的同时维护已有功能，通过技术手段提高交付人员的效率，降低交付成本。负责开发了交付违约管理、交付pipeline等功能。交付违约管理功能，在客户无法在预约时间提车时，交付专家可以手动或者订单取消、挂起等事件自动触发进入违约流程，创建违约工单群，并将产品专家、零售店长、交付专家、交付店长等订单相关人员拉入群聊，在飞书机器人的引导下，完成发送提醒短信给用户等跟进手段，提高了人效、降低了沟通成本，<strong>客户违约率降低30%</strong>。</p>\n<!-- ## NGTASK任务调度系统（2019年11月-2020年1月）\n\n由于携号转网业务需要同步携转数据，客户要求开发一个任务调度系统，可以通过web页面新增、修改、删除、查询任务。项目框架核心（不含业务代码）我已分享到[github:ngtask](https://github.com/kongzheng1993/ngtask)。独立开发。springboot+quartz+mysql+zookeeper，实现mysql数据导入导出任务，ftp/sftp上传下载任务。任务失败告警功能。\n\n## 中移在线一体机项目 （2019年3月-2019年9月）\n\n中移在线一体机项目是供移动营业厅一体机和pad等移动设备使用的web应用，提供实名制认证、停开机、补卡、开户等业务。使用springboot+vue+mysql。调用接口平台完成客户业务。项目搭建并开发，负责开发了补卡业务流程、包括服务密码验证、人证比对、旧卡校验、补卡、无纸化等流程。随着一体机的上线使用，用户可以通过一体机自助办理业务，减轻了营业厅服务人员的压力，提升了用户满意度。 -->\n<h2 id=\"%E4%B8%AD%E7%A7%BB%E5%9C%A8%E7%BA%BF%E5%8C%97%E4%BA%AC%E7%BB%9F%E4%B8%80%E6%8E%A5%E5%8F%A3%E5%B9%B3%E5%8F%B02018%E5%B9%B410%E6%9C%88--2020%E5%B9%B46%E6%9C%88\">中移在线北京统一接口平台（2018年10月--2020年6月）</h2>\n<p>此项目为中国移动在线公司北京分公司统一接口平台。此系统为中间层，为中移在线北京分公司10086IVR、营业厅一体机、app、微信、门户网站等渠道提供接入转接服务。各渠道过来的请求，由接口平台转接到能力提供方，再将能力响应信息返回给调用方。大部分接口要做一些数据格式的转换和数据内容的映射，以适应各个渠道的调用。此系统为分布式架构（nginx、tomcat、redis、mysql、zookeeper、dubbo），使用spring作为ioc容器，使用jersey提供RESTful接口。在页面可以进行接入接口、转接接口、接口映射、接口编排、接入参数、转接参数、参数映射、接入渠道、渠道权限等的配置。接收请求后，程序会通过调用url获取到通过redis/mysql获取到此接口的相关配置，并根据获取到的参数配置进行参数校验、参数处理、参数映射，调用转接接口获取响应后处理并返回给调用方。根据需求完成各类接口的开发、测试、联调、发布。负责实现了项目的动态数据源和redis集群搭建与集成。</p>\n<ul>\n<li>“移娃”项目中，引入redis实现了用户和“移娃”的会话上下文记录10min，利用redis速度和过期时间的天然优势，完美实现了功能</li>\n<li>优化了接口平台字段名大写蛇形（XXX_YYY）转驼峰（xxxYYY）算法，<strong>500ms优化到20ms</strong>，极大提高了接口RT。<a href=\"https://kongzheng1993.github.io/2020/03/25/kongzheng1993-%E4%B8%80%E6%AC%A1%E8%80%81%E4%BB%A3%E7%A0%81%E4%BC%98%E5%8C%96/\"><strong>查看详情</strong></a></li>\n</ul>\n<!-- ## 北京移动客服系统 （2018年12月-2019年3月）\n\n此系统使用亚信AppFrame（封装了ssh、jquery、html等技术）框架，提供给北京移动客服人员使用，业务比较复杂。\n主要功能：\n\n1. 呼叫中心，集成华为呼叫中心，接听来话，外呼等。\n2. 工单，新建工单、工单派发、认领等功能等。\n3. 服务，提供给其他系统接口。\n4. 客户关系管理，客户黑灰红白名单录入、设置等，客户信息查询、修改等\n5. 后台进程。\n\n在原有基础上新增、修改功能。完成黑灰名单自动填充失效时间、工单流转信息查询功能、向crm提供工单流转信息查询功能接口等需求。认真了解了公司框架，熟练完成前后端开发。 -->\n<hr>\n<h1 id=\"%E4%B8%93%E4%B8%9A%E6%8A%80%E8%83%BD\">专业技能</h1>\n<!-- &#x2B50;：了解，会用\n\n&#x2B50;&#x2B50;：熟悉，框架看过一些源码，中间件知道原理，工具会使用主要功能\n\n&#x2B50;&#x2B50;&#x2B50;：精通，框架看过大部分源码，中间件看过一些源码，工具会使用大部分功能  -->\n<h2 id=\"%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80\">编程语言</h2>\n<ul>\n<li>Java: ⭐⭐⭐</li>\n<li>SQL: ⭐⭐⭐</li>\n<li>JavaScript: ⭐⭐</li>\n<li>HTML: ⭐⭐</li>\n<li>CSS: ⭐⭐</li>\n<li>Python: ⭐</li>\n<li>Shell: ⭐</li>\n</ul>\n<h2 id=\"%E5%B7%A5%E5%85%B7\">工具</h2>\n<ul>\n<li>Maven: ⭐⭐⭐</li>\n<li>Git: ⭐⭐⭐</li>\n<li>SVN: ⭐⭐⭐</li>\n<li>Element UI: ⭐⭐⭐</li>\n</ul>\n<!-- - Ant: &#x2B50; -->\n<!-- - Gradle: &#x2B50; -->\n<h2 id=\"%E6%A1%86%E6%9E%B6\">框架</h2>\n<ul>\n<li>Spring: ⭐⭐⭐</li>\n<li>Spring Cloud: ⭐⭐</li>\n<li>MyBatis: ⭐⭐⭐</li>\n<li>Vue: ⭐⭐</li>\n<li>JUnit: ⭐</li>\n</ul>\n<!-- - ASM: &#x2B50;\n- Netty: &#x2B50;\n- Dubbo: &#x2B50; -->\n<h2 id=\"%E4%B8%AD%E9%97%B4%E4%BB%B6\">中间件</h2>\n<ul>\n<li>MySQL: ⭐⭐</li>\n<li>Oracle: ⭐⭐</li>\n<li>RocketMQ: ⭐</li>\n<li>Zookeeper: ⭐</li>\n<li>Redis: ⭐⭐</li>\n</ul>\n<!-- - Kafka: &#x2B50; -->\n<!-- - Nginx: &#x2B50; -->\n<h2 id=\"%E5%85%B6%E4%BB%96\">其他</h2>\n<ul>\n<li>Docker：⭐</li>\n<li>K8s：⭐</li>\n<li>Jenkins：⭐</li>\n<li>Flink：⭐</li>\n</ul>\n<hr>\n<h1 id=\"%E5%BC%80%E6%BA%90%E4%BD%9C%E5%93%81\">开源作品</h1>\n<h3 id=\"1-ftp%E6%96%87%E4%BB%B6%E4%B8%8B%E8%BD%BD%E5%B7%A5%E5%85%B7-githubdownloadfiles\">1.  ftp文件下载工具 <a href=\"https://github.com/kongzheng1993/downloadFiles\" target=\"_blank\" rel=\"noopener\">github:downloadFiles</a></h3>\n<!-- 帮运维同事写的小工具，他手头有个任务，每天一早到工位就要去8台sftp下载录音文件（任务调度平台故障，恢复之前只能手动搞），所以用python帮他做了个小工具。使用paramiko连接sftp、json模块解析配置文件、logging记录日志、zipfile模块压缩文件、threading模拟多线程。最后我还用pyinstaller打包成exe，他写好配置文件，双击就能执行，并且日志会持久化到文件。代码已经分享到[github:downloadFiles](https://github.com/kongzheng1993/downloadFiles)。 -->\n<h3 id=\"2-testivr%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E7%94%9F%E6%88%90%E5%B7%A5%E5%85%B7-githubguigeneratetestivrconfig\">2. testIVR配置文件生成工具 <a href=\"https://github.com/kongzheng1993/GuiGenerateTestIVRConfig\" target=\"_blank\" rel=\"noopener\">github:GuiGenerateTestIVRConfig</a></h3>\n<h3 id=\"3-%E4%BD%BF%E7%94%A8nodejszookeeperredis%E5%AE%9E%E7%8E%B0%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0-githubevil-service-discovery\">3. 使用node.js+zookeeper+redis实现服务发现 <a href=\"https://github.com/kongzheng1993/evil-service-discovery\" target=\"_blank\" rel=\"noopener\">github:evil-service-discovery</a></h3>\n<h3 id=\"4-springbootquartzmysql%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1%E9%9B%86%E7%BE%A4-githubeviltask\">4. springboot+quartz+mysql定时任务集群 <a href=\"https://github.com/kongzheng1993/Eviltask\" target=\"_blank\" rel=\"noopener\">github:EvilTask</a></h3>\n<p><strong>更多请查看我的<a href=\"https://github.com/kongzheng1993\" target=\"_blank\" rel=\"noopener\">github</a></strong></p>\n<!-- 来到项目后发现大家使用的调试接口的工具testIVR(模拟ivr流程调用socket和http接口工具) 总是需要手动配置，而且错误率特别高，经常因为一个小问题找半天。在熟悉了testIVR之后，我使用python-tkinter写了一个自动生成testIVR配置文件的工具，在项目组内广泛应用，并得到了领导和客户的好评。\n\n使用python的tkinter库编写gui。通过获取用户在输入控件(Entry)中输入的ivr_id、dtproxy_ip、dtproxy_id和参数配置。编写 cleanparam()函数清洗找出入参，和出参个数。编写dogenerate()函数生成ivr和dtproxy的配置，并循环生成入参、出参配置。使用python的 pyinstaller工具生成exe可执行文件。详情请查看我的[github:GuiGenerateTestIVRConfig](https://github.com/kongzheng1993/GuiGenerateTestIVRConfig) -->\n<h1 id=\"%E8%87%AA%E6%88%91%E8%AF%84%E4%BB%B7\">自我评价</h1>\n<p>有较好的职业素养，对工作积极负责，有创新意识和团队合作精神。热爱技术、热爱编码、热爱学习，喜欢阅读技术书刊、源码，学习能力较强，能快速将学习内容转化为生产力。态度乐观，有较好的沟通能力，为人热情，可以在工作中统合综效，实现共赢。</p>\n<hr>\n<h1 id=\"%E8%87%B4%E8%B0%A2\">致谢</h1>\n<p>感谢您花时间阅读我的简历，期待能有机会和您共事。</p>\n\n</body>\n</html>\n"},{"title":"SpringMVC消息转换器","excerpt":"","comments":1,"date":"2021-07-01T05:30:10.000Z","_content":"\n今天是建党百年的日子，也是公司六周年。我们发了理想one的车模还有一件polo衫。车模我选的baby blue。\n\n<img src=\"1.jpg\"/>\n\n<img src=\"2.jpg\"/>\n\n<img src=\"3.jpg\"/>\n\n圆规正转！\n\n前几天我们上线了一个给公司app提供接口的api服务，当时ios的开发希望我们能统一处理一下返回报文json中的null，比如字符串为空修改为\"\"，对象为空修改为{}，List为空修改为[]，原因是他不好判空。。然后我们直接实现WebMvcConfigurer，重写了configureMessageConverters，增加了一个处理json的FastJsonHttpMessageConverter，实现了ios开发要求的效果。\n\n```java\n@Configuration\npublic class ApiMvcConfig implements WebMvcConfigurer {\n    /**\n     * 增加对Json的处理\n     * @param converters\n     */\n    @Override\n    public void configureMessageConverters(List<HttpMessageConverter<?>> converters) {\n        //针对字段的处理\n        FastJsonHttpMessageConverter converter = new FastJsonHttpMessageConverter();\n        FastJsonConfig fastJsonConfig = new FastJsonConfig();\n        fastJsonConfig.setSerializerFeatures(SerializerFeature.WriteNullListAsEmpty,// List字段如果为null,输出为[],而非null\n                SerializerFeature.WriteMapNullValue,//加上后，字段为null的也会输出\n                SerializerFeature.WriteNullStringAsEmpty,//字符类型字段如果为null,输出为”“,而非null\n                SerializerFeature.WriteNullBooleanAsFalse,//Boolean字段如果为null,输出为false,而非null\n                //SerializerFeature.WriteNullNumberAsZero, // Number 包装类如果为null，输出为0\n                SerializerFeature.DisableCircularReferenceDetect,\n                SerializerFeature.PrettyFormat  //结果是否格式化,默认为false\n        );\n        //日期格式化\n        fastJsonConfig.setDateFormat(\"yyyy-MM-dd HH:mm:ss\");\n        converter.setFastJsonConfig(fastJsonConfig);\n        converters.add(0, converter);//返回是string的话，默认把这个放在最前，否则ResponseAdvisor 处理字符串返回时会报类型不一致的问题\n    }\n}\n```\n\n\n\n上线后却发现系统没能接入prometheus。在和公司平台云服务部的同学沟通之后，发现我们给prometheus返回的报文全都加上了转译字符，导致prometheus解析不了。。。\n\n下面是有问题的报文：\n\n```shell\n➜  ~ curl -i http://127.0.0.1:11187/dayu/prometheus\nHTTP/1.1 200\nContent-Type: text/plain; version=0.0.4;charset=utf-8\nContent-Length: 19296\nDate: Fri, 02 Jul 2021 08:35:22 GMT\n\n\"# HELP jvm_threads_daemon The current number of live daemon threads\\n# TYPE jvm_threads_daemon gauge\\njvm_threads_daemon{application=\\\"saos-pdi-api\\\",env=\\\"test\\\",namespace=\\\"\\\",pod=\\\"\\\",} 69.0\\n# HELP tomcat_sessions_active_max  \\n# TYPE tomcat_sessions_active_max gauge\\ntomcat_sessions_active_max{application=\\\"saos-pdi-api\\\",env=\\\"test\\\",namespace=\\\"\\\",pod=\\\"\\\",} 5.0\\n# HELP jvm_memory_committed_bytes The amount of memory in bytes that is committed for the Java virtual machine to use\\n# TYPE jvm_memory_committed_bytes gauge\\njvm_memory_committed_bytes{application=\\\"saos-pdi-api\\\",area=\\\"nonheap\\\",env=\\\"test\\\",id=\\\"Code Cache\\\",namespace=\\\"\\\",pod=\\\"\\\",} 2.2740992E7\\njvm_memory_committed_bytes{application=\\\"saos-pdi-api\\\",area=\\\"nonheap\\\",env=\\\"test\\\",id=\\\"Metaspace\\\",namespace=\\\"\\\",pod=\\\"\\\",} 9.728E7\\njvm_memory_committed_bytes{application=\\\"saos-pdi-api\\\",area=\\\"nonheap\\\",env=\\\"test\\\",id=\\\"Compressed Class Space\\\",namespace=\\\"\\\",pod=\\\"\\\",} 1.2894208E7\\njvm_memory_committed_bytes{application=\\\"saos-pdi-api\\\",area=\\\"heap\\\",env=\\\"test\\\",id=\\\"PS Eden Space\\\",namespace=\\\"\\\",pod=\\\"\\\",} 7.99014912E8\\njvm_memory_committed_bytes{application=\\\"saos-pdi-api\\\",area=\\\"heap\\\",env=\\\"test\\\",id=\\\"PS Survivor Space\\\",namespace=\\\"\\\",pod=\\\"\\\",} 2.2020096E7\\njvm_memory_committed_bytes{application=\\\"saos-pdi-api\\\",area=\\\"heap\\\",env=\\\"test\\\",id=\\\"PS Old Gen\\\",namespace=\\\"\\\",pod=\\\"\\\",} 1.9136512E8\\n# HELP tomcat_sessions_expired_total  \\n# TYPE tomcat_sessions_expired_total counter\\ntomcat_sessions_expired_total{application=\\\"saos-pdi-api\\\",env=\\\"test\\\",namespace=\\\"\\\",pod=\\\"\\\",} 0.0\\n# HELP logback_events_total Number of error level events that made it to the logs\\n# TYPE logback_events_total counter\\nlogback_events_total{application=\\\"saos-pdi-api\\\",env=\\\"test\\\",level=\\\"error\\\",namespace=\\\"\\\",pod=\\\"\\\",} 0.0\\nlogback_events_total{application=\\\"saos-pdi-api\\\",env=\\\"test\\\",level=\\\"warn\\\",namespace=\\\"\\\",pod=\\\"\\\",} 5.0\\nlogback_events_total{application=\\\"saos-pdi-api\\\",env=\\\"test\\\",level=\\\"info\\\",namespace=\\\"\\\",pod=\\\"\\\",} 401.0\\nlogback_events_total{application=\\\"saos-pdi-api\\\",env=\\\"test\\\",level=\\\"debug\\\",namespace=\\\"\\\",pod=\\\"\\\",} 60.0\\nlogback_events_total{application=\\\"saos-pdi-api\\\",env=\\\"test\\\",level=\\\"trace\\\",namespace=\\\"\\\",pod=\\\"\\\",} 0.0\\n# HELP jvm_buffer_total_capacity_bytes An estimate of the total capacity of the buffers in this pool\\n# TYPE jvm_buffer_total_capacity_bytes gauge\\njvm_buffer_total_capacity_bytes{application=\\\"saos-pdi-api\\\",env=\\\"test\\\",id=\\\"direct\\\",namespace=\\\"\\\",pod=\\\"\\\",} 170147.0\\njvm_buffer_total_capacity_bytes{application=\\\"saos-pdi-api\\\",env=\\\"test\\\",id=\\\"mapped\\\",namespace=\\\"\\\",pod=\\\"\\\",} 0.0\\n# HELP system_cpu_usage The \\\"recent cpu usage\\\" for the whole system\\n# TYPE system_cpu_usage gauge\\nsystem_cpu_usage{application=\\\"saos-pdi-api\\\",env=\\\"test\\\",namespace=\\\"\\\",pod=\\\"\\\",} 0.03545880166806259\\n# HELP tomcat_threads_config_max  \\n# TYPE tomcat_threads_config_max gauge\\ntomcat_threads_config_max{application=\\\"saos-pdi-api\\\",env=\\\"test\\\",name=\\\"http-nio-11187\\\",namespace=\\\"\\\",pod=\\\"\\\",} 200.0\\n# HELP tomcat_threads_current  \\n# TYPE tomcat_threads_current gauge\\ntomcat_threads_current{application=\\\"saos-pdi-api\\\",env=\\\"test\\\",name=\\\"http-nio-11187\\\",namespace=\\\"\\\",pod=\\\"\\\",} 10.0\\n# HELP tomcat_sessions_rejected_total  \\n# TYPE tomcat_sessions_rejected_total counter\\ntomcat_sessions_rejected_total{application=\\\"saos-pdi-api\\\",env=\\\"test\\\",namespace=\\\"\\\",pod=\\\"\\\",} 0.0\\n# HELP tomcat_global_request_seconds  \\n# TYPE tomcat_global_request_seconds summary\\ntomcat_global_request_seconds_count{application=\\\"saos-pdi-api\\\",env=\\\"test\\\",name=\\\"http-nio-11187\\\",namespace=\\\"\\\",pod=\\\"\\\",} 21.0\\ntomcat_global_request_seconds_sum{application=\\\"saos-pdi-api\\\",env=\\\"test\\\",name=\\\"http-nio-11187\\\",namespace=\\\"\\\",pod=\\\"\\\",} 14.12\\n# HELP jvm_memory_max_bytes The maximum amount of memory in bytes that can be used for memory management\\n# TYPE jvm_memory_max_bytes gauge\\njvm_memory_max_bytes{application=\\\"saos-pdi-api\\\",area=\\\"nonheap\\\",env=\\\"test\\\",id=\\\"Code Cache\\\",namespace=\\\"\\\",pod=\\\"\\\",} 2.5165824E8\\njvm_memory_max_bytes{application=\\\"saos-pdi-api\\\",area=\\\"nonheap\\\",env=\\\"test\\\",id=\\\"Metaspace\\\",namespace=\\\"\\\",pod=\\\"\\\",} -1.0\\njvm_memory_max_bytes{application=\\\"saos-pdi-api\\\",area=\\\"nonheap\\\",env=\\\"test\\\",id=\\\"Compressed Class Space\\\",namespace=\\\"\\\",pod=\\\"\\\",} 1.073741824E9\\njvm_memory_max_bytes{application=\\\"saos-pdi-api\\\",area=\\\"heap\\\",env=\\\"test\\\",id=\\\"PS Eden Space\\\",namespace=\\\"\\\",pod=\\\"\\\",} 1.311244288E9\\njvm_memory_max_bytes{application=\\\"saos-pdi-api\\\",area=\\\"heap\\\",env=\\\"test\\\",id=\\\"PS Survivor Space\\\n...\n```\n\n下面是正常的报文：\n\n```shell\n➜  ~ curl -i http://127.0.0.1:11187/dayu/prometheus\nHTTP/1.1 200\nContent-Type: text/plain; version=0.0.4;charset=utf-8\nContent-Length: 12594\nDate: Fri, 02 Jul 2021 08:39:14 GMT\n\n# HELP tomcat_global_request_max_seconds\n# TYPE tomcat_global_request_max_seconds gauge\ntomcat_global_request_max_seconds{application=\"saos-pdi-api\",env=\"test\",name=\"http-nio-11187\",namespace=\"\",pod=\"\",} 0.0\n# HELP tomcat_global_received_bytes_total\n# TYPE tomcat_global_received_bytes_total counter\ntomcat_global_received_bytes_total{application=\"saos-pdi-api\",env=\"test\",name=\"http-nio-11187\",namespace=\"\",pod=\"\",} 0.0\n# HELP jvm_memory_committed_bytes The amount of memory in bytes that is committed for the Java virtual machine to use\n# TYPE jvm_memory_committed_bytes gauge\njvm_memory_committed_bytes{application=\"saos-pdi-api\",area=\"nonheap\",env=\"test\",id=\"Code Cache\",namespace=\"\",pod=\"\",} 1.9857408E7\njvm_memory_committed_bytes{application=\"saos-pdi-api\",area=\"nonheap\",env=\"test\",id=\"Metaspace\",namespace=\"\",pod=\"\",} 8.7318528E7\njvm_memory_committed_bytes{application=\"saos-pdi-api\",area=\"nonheap\",env=\"test\",id=\"Compressed Class Space\",namespace=\"\",pod=\"\",} 1.1583488E7\njvm_memory_committed_bytes{application=\"saos-pdi-api\",area=\"heap\",env=\"test\",id=\"PS Eden Space\",namespace=\"\",pod=\"\",} 1.120927744E9\njvm_memory_committed_bytes{application=\"saos-pdi-api\",area=\"heap\",env=\"test\",id=\"PS Survivor Space\",namespace=\"\",pod=\"\",} 2.359296E7\njvm_memory_committed_bytes{application=\"saos-pdi-api\",area=\"heap\",env=\"test\",id=\"PS Old Gen\",namespace=\"\",pod=\"\",} 1.86646528E8\n# HELP tomcat_servlet_request_seconds\n# TYPE tomcat_servlet_request_seconds summary\ntomcat_servlet_request_seconds_count{application=\"saos-pdi-api\",env=\"test\",name=\"dispatcherServlet\",namespace=\"\",pod=\"\",} 1.0\ntomcat_servlet_request_seconds_sum{application=\"saos-pdi-api\",env=\"test\",name=\"dispatcherServlet\",namespace=\"\",pod=\"\",} 0.0\n# HELP health\n# TYPE health gauge\nhealth{application=\"saos-pdi-api\",env=\"test\",namespace=\"\",pod=\"\",} 3.0\n# HELP jvm_buffer_memory_used_bytes An estimate of the memory that the Java virtual machine is using for this buffer pool\n# TYPE jvm_buffer_memory_used_bytes gauge\njvm_buffer_memory_used_bytes{application=\"saos-pdi-api\",env=\"test\",id=\"direct\",namespace=\"\",pod=\"\",} 91015.0\njvm_buffer_memory_used_bytes{application=\"saos-pdi-api\",env=\"test\",id=\"mapped\",namespace=\"\",pod=\"\",} 0.0\n# HELP tomcat_threads_current\n# TYPE tomcat_threads_current gauge\ntomcat_threads_current{application=\"saos-pdi-api\",env=\"test\",name=\"http-nio-11187\",namespace=\"\",pod=\"\",} 10.0\n# HELP process_start_time_seconds Start time of the process since unix epoch.\n# TYPE process_start_time_seconds gauge\nprocess_start_time_seconds{application=\"saos-pdi-api\",env=\"test\",namespace=\"\",pod=\"\",} 1.625215112786E9\n# HELP tomcat_threads_config_max\n# TYPE tomcat_threads_config_max gauge\ntomcat_threads_config_max{application=\"saos-pdi-api\",env=\"test\",name=\"http-nio-11187\",namespace=\"\",pod=\"\",} 200.0\n# HELP jvm_gc_memory_promoted_bytes_total Count of positive increases in the size of the old generation memory pool before GC to after GC\n# TYPE jvm_gc_memory_promoted_bytes_total counter\njvm_gc_memory_promoted_bytes_total{application=\"saos-pdi-api\",env=\"test\",namespace=\"\",pod=\"\",} 4.5149664E7\n# HELP jvm_gc_memory_allocated_bytes_total Incremented for an increase in the size of the young generation memory pool after one GC to before the next\n# TYPE jvm_gc_memory_allocated_bytes_total counter\njvm_gc_memory_allocated_bytes_total{application=\"saos-pdi-api\",env=\"test\",namespace=\"\",pod=\"\",} 3.43775952E9\n# HELP tomcat_global_sent_bytes_total\n# TYPE tomcat_global_sent_bytes_total counter\ntomcat_global_sent_bytes_total{application=\"saos-pdi-api\",env=\"test\",name=\"http-nio-11187\",namespace=\"\",pod=\"\",} 0.0\n# HELP jvm_classes_unloaded_total The total number of classes unloaded since the Java virtual machine has started execution\n```\n\n可以看到，Prometheus这个接口的响应报文，并不是一个单纯的json格式，而是text里有json格式的东西。\n\n当时就怀疑是Fastjson是不是有点啥问题[doge]……\n\n果不其然，让我在github上找到一个[issues](https://github.com/alibaba/fastjson/issues/1373)\n\n之前老版本的fastjson是有一个DisableCheckSpecialChar的SerializerFeature的，可以禁止特殊字符的转译，现在标了过期，直接不能用了，默认就给转译。。\n\n使用老版本的fastjson，并加上SerializerFeature.DisableCheckSpecialChar后，是可以的。\n\n但是我们都知道fastjson动不动就爆出漏洞，最新的版本都有点怕，更别说那么老的版本了。\n\n只能再想办法。\n\n我们从头开始想：\n\nhttp响应的报文，是怎么转换的呢？--> HttpMessageConverter\n\n所以这块还得研究透spring的HttpMessageConverter是怎么工作的！\n\n我们都知道请求和响应都是要经过DispatcherServlet类的doDispatch方法。然后获取HandlerAdapter，然后获取对应的Handler，并调用handle方法，中间有对应的请求内容的消息转换器进行请求报文的转换，返回的时候，也会用消息解析器进行报文的转换，最后写入到http的outputStream，完成一次请求的响应。\n\n看我上面增加的自定义的FastJsonHttpMessageConverter，可以看到，我将自定义的HttpMessageConverter放到了第一位，当时考虑是spring有一些默认的消息转换器，对应的json的转换器使用jackson实现的。spring在选择消息转换器的时候，是遍历所有的转换器，找到第一个合适的就使用。所以我必须放到jackson前面，但是放到第一位，也就在string的转换器之前了，暴露给Prometheus的接口是text/plain的，讲道理fastjson不应该处理它，应该留给StringHttpMessageConterver来转换才对啊。\n\n下面的代码是spring默认的消息处理器：\n\n```java\nprotected final void addDefaultHttpMessageConverters(List<HttpMessageConverter<?>> messageConverters) {\n\t\tStringHttpMessageConverter stringHttpMessageConverter = new StringHttpMessageConverter();\n\t\tstringHttpMessageConverter.setWriteAcceptCharset(false);  // see SPR-7316\n\n\t\tmessageConverters.add(new ByteArrayHttpMessageConverter());\n\t\tmessageConverters.add(stringHttpMessageConverter);\n\t\tmessageConverters.add(new ResourceHttpMessageConverter());\n\t\tmessageConverters.add(new ResourceRegionHttpMessageConverter());\n\t\tmessageConverters.add(new SourceHttpMessageConverter<>());\n\t\tmessageConverters.add(new AllEncompassingFormHttpMessageConverter());\n\n\t\tif (romePresent) {\n\t\t\tmessageConverters.add(new AtomFeedHttpMessageConverter());\n\t\t\tmessageConverters.add(new RssChannelHttpMessageConverter());\n\t\t}\n\n\t\tif (jackson2XmlPresent) {\n\t\t\tJackson2ObjectMapperBuilder builder = Jackson2ObjectMapperBuilder.xml();\n\t\t\tif (this.applicationContext != null) {\n\t\t\t\tbuilder.applicationContext(this.applicationContext);\n\t\t\t}\n\t\t\tmessageConverters.add(new MappingJackson2XmlHttpMessageConverter(builder.build()));\n\t\t}\n\t\telse if (jaxb2Present) {\n\t\t\tmessageConverters.add(new Jaxb2RootElementHttpMessageConverter());\n\t\t}\n\n\t\tif (jackson2Present) {\n\t\t\tJackson2ObjectMapperBuilder builder = Jackson2ObjectMapperBuilder.json();\n\t\t\tif (this.applicationContext != null) {\n\t\t\t\tbuilder.applicationContext(this.applicationContext);\n\t\t\t}\n\t\t\tmessageConverters.add(new MappingJackson2HttpMessageConverter(builder.build()));\n\t\t}\n\t\telse if (gsonPresent) {\n\t\t\tmessageConverters.add(new GsonHttpMessageConverter());\n\t\t}\n\t\telse if (jsonbPresent) {\n\t\t\tmessageConverters.add(new JsonbHttpMessageConverter());\n\t\t}\n\n\t\tif (jackson2SmilePresent) {\n\t\t\tJackson2ObjectMapperBuilder builder = Jackson2ObjectMapperBuilder.smile();\n\t\t\tif (this.applicationContext != null) {\n\t\t\t\tbuilder.applicationContext(this.applicationContext);\n\t\t\t}\n\t\t\tmessageConverters.add(new MappingJackson2SmileHttpMessageConverter(builder.build()));\n\t\t}\n\t\tif (jackson2CborPresent) {\n\t\t\tJackson2ObjectMapperBuilder builder = Jackson2ObjectMapperBuilder.cbor();\n\t\t\tif (this.applicationContext != null) {\n\t\t\t\tbuilder.applicationContext(this.applicationContext);\n\t\t\t}\n\t\t\tmessageConverters.add(new MappingJackson2CborHttpMessageConverter(builder.build()));\n\t\t}\n\t}\n```\n\n\n\n可以看到第一位是byte，第二位是String。。。。\n\n试着调整我们自定义消息处理器的位置到后面：\n\n```java\n    public void configureMessageConverters(List<HttpMessageConverter<?>> converters) {\n        //针对字段的处理\n        FastJsonHttpMessageConverter converter = new FastJsonHttpMessageConverter();\n        FastJsonConfig fastJsonConfig = new FastJsonConfig();\n        fastJsonConfig.setSerializerFeatures(SerializerFeature.WriteNullListAsEmpty,// List字段如果为null,输出为[],而非null\n                SerializerFeature.WriteMapNullValue,//加上后，字段为null的也会输出\n                SerializerFeature.WriteNullStringAsEmpty,//字符类型字段如果为null,输出为”“,而非null\n                SerializerFeature.WriteNullBooleanAsFalse,//Boolean字段如果为null,输出为false,而非null\n                //SerializerFeature.WriteNullNumberAsZero, // Number 包装类如果为null，输出为0\n                SerializerFeature.DisableCircularReferenceDetect,\n                SerializerFeature.PrettyFormat  //结果是否格式化,默认为false\n        );\n        //日期格式化\n        fastJsonConfig.setDateFormat(\"yyyy-MM-dd HH:mm:ss\");\n        converter.setFastJsonConfig(fastJsonConfig);\n        converters.add(3,converter);//返回是string的话，默认把这个放在最前，否则ResponseAdvisor 处理字符串返回时会报类型不一致的问题\n    }\n```\n\n这里调整到第四位，可以满足要求。最后也是这样上线解决问题的。\n\n现在还有一个问题，为什么FastJsonHttpMessageConverter要处理text/plain的请求呢？\n\nAbstractMessageConverterMethodProcessor#writeWithMessageConverters中会选择消息转换器，能不能使用是通过消息转换器的canWrite方法来判断的，返回true就会使用这个消息转换器。\n\n```java\nfor (HttpMessageConverter<?> converter : this.messageConverters) {\n\t\t\t\tGenericHttpMessageConverter genericConverter = (converter instanceof GenericHttpMessageConverter ?\n\t\t\t\t\t\t(GenericHttpMessageConverter<?>) converter : null);\n\t\t\t\tif (genericConverter != null ?\n\t\t\t\t\t\t((GenericHttpMessageConverter) converter).canWrite(declaredType, valueType, selectedMediaType) :\n\t\t\t\t\t\tconverter.canWrite(valueType, selectedMediaType)) {\n\t\t\t\t\toutputValue = getAdvice().beforeBodyWrite(outputValue, returnType, selectedMediaType,\n\t\t\t\t\t\t\t(Class<? extends HttpMessageConverter<?>>) converter.getClass(),\n\t\t\t\t\t\t\tinputMessage, outputMessage);\n\t\t\t\t\tif (outputValue != null) {\n\t\t\t\t\t\taddContentDispositionHeader(inputMessage, outputMessage);\n\t\t\t\t\t\tif (genericConverter != null) {\n\t\t\t\t\t\t\tgenericConverter.write(outputValue, declaredType, selectedMediaType, outputMessage);\n\t\t\t\t\t\t}\n\t\t\t\t\t\telse {\n\t\t\t\t\t\t\t((HttpMessageConverter) converter).write(outputValue, selectedMediaType, outputMessage);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\t\t\t\tlogger.debug(\"Written [\" + outputValue + \"] as \\\"\" + selectedMediaType +\n\t\t\t\t\t\t\t\t\t\"\\\" using [\" + converter + \"]\");\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t}\n```\n\nFastJsonHttpMessageConverter的canWrite调用了父类（AbstractHttpMessageConterver）的canWrite方法，这个方法的入参是Class<?> clazz(java.lang.String)和MediaType mediaType(text/plain;version=0.0.4;charset=utf-8)\n\nAbstractHttpMessageConterver的canWrite长这样：\n\n```java\n    public boolean canWrite(Class<?> clazz, @Nullable MediaType mediaType) {\n        return this.supports(clazz) && this.canWrite(mediaType);\n    }\n```\n\nsupports方法直接就是写死的返回true，而canWrite走到最后text/*都会直接返回true，所以就这么愉快的通过了。。。\n\n而人家jackson就实在很多，人家在JacksonHttpMessageConverterConfiguration中创建MappingJackson2HttpMessageConverter的时候，调用AbstractJackson2HttpMessageConverter中的构造器，传入的supportedMediaTypes只有两个关于json的！\n\n```json\n\t/**\n\t * Construct a new {@link MappingJackson2HttpMessageConverter} with a custom {@link ObjectMapper}.\n\t * You can use {@link Jackson2ObjectMapperBuilder} to build it easily.\n\t * @see Jackson2ObjectMapperBuilder#json()\n\t */\n\tpublic MappingJackson2HttpMessageConverter(ObjectMapper objectMapper) {\n\t\tsuper(objectMapper, MediaType.APPLICATION_JSON, new MediaType(\"application\", \"*+json\"));\n\t}\n```\n\n这块确实是挺坑的。。你说fastjson，你好好管你的json就完事了，你搞什么string啊。。\n\n### 总结\n\nSpring根据请求的MediaType选择对应的消息转换器，而我们这里使用的FastJsonHttpMessageConverter，并没有像jackson一样规定supportedMediaTypes，而是AbstractHttpMessageConverter中默认的*/*，导致将text/plain的报文也给转换了，才导致了这次遇到的问题。\n","source":"_posts/2021-07-01-kongzheng1993-springMVC消息转换器.md","raw":"---\ntitle: SpringMVC消息转换器\nexcerpt: 'spring'\ntags: [spring]\ncategories: [spring]\ncomments: true\ndate: 2021-07-01 13:30:10\n---\n\n今天是建党百年的日子，也是公司六周年。我们发了理想one的车模还有一件polo衫。车模我选的baby blue。\n\n<img src=\"1.jpg\"/>\n\n<img src=\"2.jpg\"/>\n\n<img src=\"3.jpg\"/>\n\n圆规正转！\n\n前几天我们上线了一个给公司app提供接口的api服务，当时ios的开发希望我们能统一处理一下返回报文json中的null，比如字符串为空修改为\"\"，对象为空修改为{}，List为空修改为[]，原因是他不好判空。。然后我们直接实现WebMvcConfigurer，重写了configureMessageConverters，增加了一个处理json的FastJsonHttpMessageConverter，实现了ios开发要求的效果。\n\n```java\n@Configuration\npublic class ApiMvcConfig implements WebMvcConfigurer {\n    /**\n     * 增加对Json的处理\n     * @param converters\n     */\n    @Override\n    public void configureMessageConverters(List<HttpMessageConverter<?>> converters) {\n        //针对字段的处理\n        FastJsonHttpMessageConverter converter = new FastJsonHttpMessageConverter();\n        FastJsonConfig fastJsonConfig = new FastJsonConfig();\n        fastJsonConfig.setSerializerFeatures(SerializerFeature.WriteNullListAsEmpty,// List字段如果为null,输出为[],而非null\n                SerializerFeature.WriteMapNullValue,//加上后，字段为null的也会输出\n                SerializerFeature.WriteNullStringAsEmpty,//字符类型字段如果为null,输出为”“,而非null\n                SerializerFeature.WriteNullBooleanAsFalse,//Boolean字段如果为null,输出为false,而非null\n                //SerializerFeature.WriteNullNumberAsZero, // Number 包装类如果为null，输出为0\n                SerializerFeature.DisableCircularReferenceDetect,\n                SerializerFeature.PrettyFormat  //结果是否格式化,默认为false\n        );\n        //日期格式化\n        fastJsonConfig.setDateFormat(\"yyyy-MM-dd HH:mm:ss\");\n        converter.setFastJsonConfig(fastJsonConfig);\n        converters.add(0, converter);//返回是string的话，默认把这个放在最前，否则ResponseAdvisor 处理字符串返回时会报类型不一致的问题\n    }\n}\n```\n\n\n\n上线后却发现系统没能接入prometheus。在和公司平台云服务部的同学沟通之后，发现我们给prometheus返回的报文全都加上了转译字符，导致prometheus解析不了。。。\n\n下面是有问题的报文：\n\n```shell\n➜  ~ curl -i http://127.0.0.1:11187/dayu/prometheus\nHTTP/1.1 200\nContent-Type: text/plain; version=0.0.4;charset=utf-8\nContent-Length: 19296\nDate: Fri, 02 Jul 2021 08:35:22 GMT\n\n\"# HELP jvm_threads_daemon The current number of live daemon threads\\n# TYPE jvm_threads_daemon gauge\\njvm_threads_daemon{application=\\\"saos-pdi-api\\\",env=\\\"test\\\",namespace=\\\"\\\",pod=\\\"\\\",} 69.0\\n# HELP tomcat_sessions_active_max  \\n# TYPE tomcat_sessions_active_max gauge\\ntomcat_sessions_active_max{application=\\\"saos-pdi-api\\\",env=\\\"test\\\",namespace=\\\"\\\",pod=\\\"\\\",} 5.0\\n# HELP jvm_memory_committed_bytes The amount of memory in bytes that is committed for the Java virtual machine to use\\n# TYPE jvm_memory_committed_bytes gauge\\njvm_memory_committed_bytes{application=\\\"saos-pdi-api\\\",area=\\\"nonheap\\\",env=\\\"test\\\",id=\\\"Code Cache\\\",namespace=\\\"\\\",pod=\\\"\\\",} 2.2740992E7\\njvm_memory_committed_bytes{application=\\\"saos-pdi-api\\\",area=\\\"nonheap\\\",env=\\\"test\\\",id=\\\"Metaspace\\\",namespace=\\\"\\\",pod=\\\"\\\",} 9.728E7\\njvm_memory_committed_bytes{application=\\\"saos-pdi-api\\\",area=\\\"nonheap\\\",env=\\\"test\\\",id=\\\"Compressed Class Space\\\",namespace=\\\"\\\",pod=\\\"\\\",} 1.2894208E7\\njvm_memory_committed_bytes{application=\\\"saos-pdi-api\\\",area=\\\"heap\\\",env=\\\"test\\\",id=\\\"PS Eden Space\\\",namespace=\\\"\\\",pod=\\\"\\\",} 7.99014912E8\\njvm_memory_committed_bytes{application=\\\"saos-pdi-api\\\",area=\\\"heap\\\",env=\\\"test\\\",id=\\\"PS Survivor Space\\\",namespace=\\\"\\\",pod=\\\"\\\",} 2.2020096E7\\njvm_memory_committed_bytes{application=\\\"saos-pdi-api\\\",area=\\\"heap\\\",env=\\\"test\\\",id=\\\"PS Old Gen\\\",namespace=\\\"\\\",pod=\\\"\\\",} 1.9136512E8\\n# HELP tomcat_sessions_expired_total  \\n# TYPE tomcat_sessions_expired_total counter\\ntomcat_sessions_expired_total{application=\\\"saos-pdi-api\\\",env=\\\"test\\\",namespace=\\\"\\\",pod=\\\"\\\",} 0.0\\n# HELP logback_events_total Number of error level events that made it to the logs\\n# TYPE logback_events_total counter\\nlogback_events_total{application=\\\"saos-pdi-api\\\",env=\\\"test\\\",level=\\\"error\\\",namespace=\\\"\\\",pod=\\\"\\\",} 0.0\\nlogback_events_total{application=\\\"saos-pdi-api\\\",env=\\\"test\\\",level=\\\"warn\\\",namespace=\\\"\\\",pod=\\\"\\\",} 5.0\\nlogback_events_total{application=\\\"saos-pdi-api\\\",env=\\\"test\\\",level=\\\"info\\\",namespace=\\\"\\\",pod=\\\"\\\",} 401.0\\nlogback_events_total{application=\\\"saos-pdi-api\\\",env=\\\"test\\\",level=\\\"debug\\\",namespace=\\\"\\\",pod=\\\"\\\",} 60.0\\nlogback_events_total{application=\\\"saos-pdi-api\\\",env=\\\"test\\\",level=\\\"trace\\\",namespace=\\\"\\\",pod=\\\"\\\",} 0.0\\n# HELP jvm_buffer_total_capacity_bytes An estimate of the total capacity of the buffers in this pool\\n# TYPE jvm_buffer_total_capacity_bytes gauge\\njvm_buffer_total_capacity_bytes{application=\\\"saos-pdi-api\\\",env=\\\"test\\\",id=\\\"direct\\\",namespace=\\\"\\\",pod=\\\"\\\",} 170147.0\\njvm_buffer_total_capacity_bytes{application=\\\"saos-pdi-api\\\",env=\\\"test\\\",id=\\\"mapped\\\",namespace=\\\"\\\",pod=\\\"\\\",} 0.0\\n# HELP system_cpu_usage The \\\"recent cpu usage\\\" for the whole system\\n# TYPE system_cpu_usage gauge\\nsystem_cpu_usage{application=\\\"saos-pdi-api\\\",env=\\\"test\\\",namespace=\\\"\\\",pod=\\\"\\\",} 0.03545880166806259\\n# HELP tomcat_threads_config_max  \\n# TYPE tomcat_threads_config_max gauge\\ntomcat_threads_config_max{application=\\\"saos-pdi-api\\\",env=\\\"test\\\",name=\\\"http-nio-11187\\\",namespace=\\\"\\\",pod=\\\"\\\",} 200.0\\n# HELP tomcat_threads_current  \\n# TYPE tomcat_threads_current gauge\\ntomcat_threads_current{application=\\\"saos-pdi-api\\\",env=\\\"test\\\",name=\\\"http-nio-11187\\\",namespace=\\\"\\\",pod=\\\"\\\",} 10.0\\n# HELP tomcat_sessions_rejected_total  \\n# TYPE tomcat_sessions_rejected_total counter\\ntomcat_sessions_rejected_total{application=\\\"saos-pdi-api\\\",env=\\\"test\\\",namespace=\\\"\\\",pod=\\\"\\\",} 0.0\\n# HELP tomcat_global_request_seconds  \\n# TYPE tomcat_global_request_seconds summary\\ntomcat_global_request_seconds_count{application=\\\"saos-pdi-api\\\",env=\\\"test\\\",name=\\\"http-nio-11187\\\",namespace=\\\"\\\",pod=\\\"\\\",} 21.0\\ntomcat_global_request_seconds_sum{application=\\\"saos-pdi-api\\\",env=\\\"test\\\",name=\\\"http-nio-11187\\\",namespace=\\\"\\\",pod=\\\"\\\",} 14.12\\n# HELP jvm_memory_max_bytes The maximum amount of memory in bytes that can be used for memory management\\n# TYPE jvm_memory_max_bytes gauge\\njvm_memory_max_bytes{application=\\\"saos-pdi-api\\\",area=\\\"nonheap\\\",env=\\\"test\\\",id=\\\"Code Cache\\\",namespace=\\\"\\\",pod=\\\"\\\",} 2.5165824E8\\njvm_memory_max_bytes{application=\\\"saos-pdi-api\\\",area=\\\"nonheap\\\",env=\\\"test\\\",id=\\\"Metaspace\\\",namespace=\\\"\\\",pod=\\\"\\\",} -1.0\\njvm_memory_max_bytes{application=\\\"saos-pdi-api\\\",area=\\\"nonheap\\\",env=\\\"test\\\",id=\\\"Compressed Class Space\\\",namespace=\\\"\\\",pod=\\\"\\\",} 1.073741824E9\\njvm_memory_max_bytes{application=\\\"saos-pdi-api\\\",area=\\\"heap\\\",env=\\\"test\\\",id=\\\"PS Eden Space\\\",namespace=\\\"\\\",pod=\\\"\\\",} 1.311244288E9\\njvm_memory_max_bytes{application=\\\"saos-pdi-api\\\",area=\\\"heap\\\",env=\\\"test\\\",id=\\\"PS Survivor Space\\\n...\n```\n\n下面是正常的报文：\n\n```shell\n➜  ~ curl -i http://127.0.0.1:11187/dayu/prometheus\nHTTP/1.1 200\nContent-Type: text/plain; version=0.0.4;charset=utf-8\nContent-Length: 12594\nDate: Fri, 02 Jul 2021 08:39:14 GMT\n\n# HELP tomcat_global_request_max_seconds\n# TYPE tomcat_global_request_max_seconds gauge\ntomcat_global_request_max_seconds{application=\"saos-pdi-api\",env=\"test\",name=\"http-nio-11187\",namespace=\"\",pod=\"\",} 0.0\n# HELP tomcat_global_received_bytes_total\n# TYPE tomcat_global_received_bytes_total counter\ntomcat_global_received_bytes_total{application=\"saos-pdi-api\",env=\"test\",name=\"http-nio-11187\",namespace=\"\",pod=\"\",} 0.0\n# HELP jvm_memory_committed_bytes The amount of memory in bytes that is committed for the Java virtual machine to use\n# TYPE jvm_memory_committed_bytes gauge\njvm_memory_committed_bytes{application=\"saos-pdi-api\",area=\"nonheap\",env=\"test\",id=\"Code Cache\",namespace=\"\",pod=\"\",} 1.9857408E7\njvm_memory_committed_bytes{application=\"saos-pdi-api\",area=\"nonheap\",env=\"test\",id=\"Metaspace\",namespace=\"\",pod=\"\",} 8.7318528E7\njvm_memory_committed_bytes{application=\"saos-pdi-api\",area=\"nonheap\",env=\"test\",id=\"Compressed Class Space\",namespace=\"\",pod=\"\",} 1.1583488E7\njvm_memory_committed_bytes{application=\"saos-pdi-api\",area=\"heap\",env=\"test\",id=\"PS Eden Space\",namespace=\"\",pod=\"\",} 1.120927744E9\njvm_memory_committed_bytes{application=\"saos-pdi-api\",area=\"heap\",env=\"test\",id=\"PS Survivor Space\",namespace=\"\",pod=\"\",} 2.359296E7\njvm_memory_committed_bytes{application=\"saos-pdi-api\",area=\"heap\",env=\"test\",id=\"PS Old Gen\",namespace=\"\",pod=\"\",} 1.86646528E8\n# HELP tomcat_servlet_request_seconds\n# TYPE tomcat_servlet_request_seconds summary\ntomcat_servlet_request_seconds_count{application=\"saos-pdi-api\",env=\"test\",name=\"dispatcherServlet\",namespace=\"\",pod=\"\",} 1.0\ntomcat_servlet_request_seconds_sum{application=\"saos-pdi-api\",env=\"test\",name=\"dispatcherServlet\",namespace=\"\",pod=\"\",} 0.0\n# HELP health\n# TYPE health gauge\nhealth{application=\"saos-pdi-api\",env=\"test\",namespace=\"\",pod=\"\",} 3.0\n# HELP jvm_buffer_memory_used_bytes An estimate of the memory that the Java virtual machine is using for this buffer pool\n# TYPE jvm_buffer_memory_used_bytes gauge\njvm_buffer_memory_used_bytes{application=\"saos-pdi-api\",env=\"test\",id=\"direct\",namespace=\"\",pod=\"\",} 91015.0\njvm_buffer_memory_used_bytes{application=\"saos-pdi-api\",env=\"test\",id=\"mapped\",namespace=\"\",pod=\"\",} 0.0\n# HELP tomcat_threads_current\n# TYPE tomcat_threads_current gauge\ntomcat_threads_current{application=\"saos-pdi-api\",env=\"test\",name=\"http-nio-11187\",namespace=\"\",pod=\"\",} 10.0\n# HELP process_start_time_seconds Start time of the process since unix epoch.\n# TYPE process_start_time_seconds gauge\nprocess_start_time_seconds{application=\"saos-pdi-api\",env=\"test\",namespace=\"\",pod=\"\",} 1.625215112786E9\n# HELP tomcat_threads_config_max\n# TYPE tomcat_threads_config_max gauge\ntomcat_threads_config_max{application=\"saos-pdi-api\",env=\"test\",name=\"http-nio-11187\",namespace=\"\",pod=\"\",} 200.0\n# HELP jvm_gc_memory_promoted_bytes_total Count of positive increases in the size of the old generation memory pool before GC to after GC\n# TYPE jvm_gc_memory_promoted_bytes_total counter\njvm_gc_memory_promoted_bytes_total{application=\"saos-pdi-api\",env=\"test\",namespace=\"\",pod=\"\",} 4.5149664E7\n# HELP jvm_gc_memory_allocated_bytes_total Incremented for an increase in the size of the young generation memory pool after one GC to before the next\n# TYPE jvm_gc_memory_allocated_bytes_total counter\njvm_gc_memory_allocated_bytes_total{application=\"saos-pdi-api\",env=\"test\",namespace=\"\",pod=\"\",} 3.43775952E9\n# HELP tomcat_global_sent_bytes_total\n# TYPE tomcat_global_sent_bytes_total counter\ntomcat_global_sent_bytes_total{application=\"saos-pdi-api\",env=\"test\",name=\"http-nio-11187\",namespace=\"\",pod=\"\",} 0.0\n# HELP jvm_classes_unloaded_total The total number of classes unloaded since the Java virtual machine has started execution\n```\n\n可以看到，Prometheus这个接口的响应报文，并不是一个单纯的json格式，而是text里有json格式的东西。\n\n当时就怀疑是Fastjson是不是有点啥问题[doge]……\n\n果不其然，让我在github上找到一个[issues](https://github.com/alibaba/fastjson/issues/1373)\n\n之前老版本的fastjson是有一个DisableCheckSpecialChar的SerializerFeature的，可以禁止特殊字符的转译，现在标了过期，直接不能用了，默认就给转译。。\n\n使用老版本的fastjson，并加上SerializerFeature.DisableCheckSpecialChar后，是可以的。\n\n但是我们都知道fastjson动不动就爆出漏洞，最新的版本都有点怕，更别说那么老的版本了。\n\n只能再想办法。\n\n我们从头开始想：\n\nhttp响应的报文，是怎么转换的呢？--> HttpMessageConverter\n\n所以这块还得研究透spring的HttpMessageConverter是怎么工作的！\n\n我们都知道请求和响应都是要经过DispatcherServlet类的doDispatch方法。然后获取HandlerAdapter，然后获取对应的Handler，并调用handle方法，中间有对应的请求内容的消息转换器进行请求报文的转换，返回的时候，也会用消息解析器进行报文的转换，最后写入到http的outputStream，完成一次请求的响应。\n\n看我上面增加的自定义的FastJsonHttpMessageConverter，可以看到，我将自定义的HttpMessageConverter放到了第一位，当时考虑是spring有一些默认的消息转换器，对应的json的转换器使用jackson实现的。spring在选择消息转换器的时候，是遍历所有的转换器，找到第一个合适的就使用。所以我必须放到jackson前面，但是放到第一位，也就在string的转换器之前了，暴露给Prometheus的接口是text/plain的，讲道理fastjson不应该处理它，应该留给StringHttpMessageConterver来转换才对啊。\n\n下面的代码是spring默认的消息处理器：\n\n```java\nprotected final void addDefaultHttpMessageConverters(List<HttpMessageConverter<?>> messageConverters) {\n\t\tStringHttpMessageConverter stringHttpMessageConverter = new StringHttpMessageConverter();\n\t\tstringHttpMessageConverter.setWriteAcceptCharset(false);  // see SPR-7316\n\n\t\tmessageConverters.add(new ByteArrayHttpMessageConverter());\n\t\tmessageConverters.add(stringHttpMessageConverter);\n\t\tmessageConverters.add(new ResourceHttpMessageConverter());\n\t\tmessageConverters.add(new ResourceRegionHttpMessageConverter());\n\t\tmessageConverters.add(new SourceHttpMessageConverter<>());\n\t\tmessageConverters.add(new AllEncompassingFormHttpMessageConverter());\n\n\t\tif (romePresent) {\n\t\t\tmessageConverters.add(new AtomFeedHttpMessageConverter());\n\t\t\tmessageConverters.add(new RssChannelHttpMessageConverter());\n\t\t}\n\n\t\tif (jackson2XmlPresent) {\n\t\t\tJackson2ObjectMapperBuilder builder = Jackson2ObjectMapperBuilder.xml();\n\t\t\tif (this.applicationContext != null) {\n\t\t\t\tbuilder.applicationContext(this.applicationContext);\n\t\t\t}\n\t\t\tmessageConverters.add(new MappingJackson2XmlHttpMessageConverter(builder.build()));\n\t\t}\n\t\telse if (jaxb2Present) {\n\t\t\tmessageConverters.add(new Jaxb2RootElementHttpMessageConverter());\n\t\t}\n\n\t\tif (jackson2Present) {\n\t\t\tJackson2ObjectMapperBuilder builder = Jackson2ObjectMapperBuilder.json();\n\t\t\tif (this.applicationContext != null) {\n\t\t\t\tbuilder.applicationContext(this.applicationContext);\n\t\t\t}\n\t\t\tmessageConverters.add(new MappingJackson2HttpMessageConverter(builder.build()));\n\t\t}\n\t\telse if (gsonPresent) {\n\t\t\tmessageConverters.add(new GsonHttpMessageConverter());\n\t\t}\n\t\telse if (jsonbPresent) {\n\t\t\tmessageConverters.add(new JsonbHttpMessageConverter());\n\t\t}\n\n\t\tif (jackson2SmilePresent) {\n\t\t\tJackson2ObjectMapperBuilder builder = Jackson2ObjectMapperBuilder.smile();\n\t\t\tif (this.applicationContext != null) {\n\t\t\t\tbuilder.applicationContext(this.applicationContext);\n\t\t\t}\n\t\t\tmessageConverters.add(new MappingJackson2SmileHttpMessageConverter(builder.build()));\n\t\t}\n\t\tif (jackson2CborPresent) {\n\t\t\tJackson2ObjectMapperBuilder builder = Jackson2ObjectMapperBuilder.cbor();\n\t\t\tif (this.applicationContext != null) {\n\t\t\t\tbuilder.applicationContext(this.applicationContext);\n\t\t\t}\n\t\t\tmessageConverters.add(new MappingJackson2CborHttpMessageConverter(builder.build()));\n\t\t}\n\t}\n```\n\n\n\n可以看到第一位是byte，第二位是String。。。。\n\n试着调整我们自定义消息处理器的位置到后面：\n\n```java\n    public void configureMessageConverters(List<HttpMessageConverter<?>> converters) {\n        //针对字段的处理\n        FastJsonHttpMessageConverter converter = new FastJsonHttpMessageConverter();\n        FastJsonConfig fastJsonConfig = new FastJsonConfig();\n        fastJsonConfig.setSerializerFeatures(SerializerFeature.WriteNullListAsEmpty,// List字段如果为null,输出为[],而非null\n                SerializerFeature.WriteMapNullValue,//加上后，字段为null的也会输出\n                SerializerFeature.WriteNullStringAsEmpty,//字符类型字段如果为null,输出为”“,而非null\n                SerializerFeature.WriteNullBooleanAsFalse,//Boolean字段如果为null,输出为false,而非null\n                //SerializerFeature.WriteNullNumberAsZero, // Number 包装类如果为null，输出为0\n                SerializerFeature.DisableCircularReferenceDetect,\n                SerializerFeature.PrettyFormat  //结果是否格式化,默认为false\n        );\n        //日期格式化\n        fastJsonConfig.setDateFormat(\"yyyy-MM-dd HH:mm:ss\");\n        converter.setFastJsonConfig(fastJsonConfig);\n        converters.add(3,converter);//返回是string的话，默认把这个放在最前，否则ResponseAdvisor 处理字符串返回时会报类型不一致的问题\n    }\n```\n\n这里调整到第四位，可以满足要求。最后也是这样上线解决问题的。\n\n现在还有一个问题，为什么FastJsonHttpMessageConverter要处理text/plain的请求呢？\n\nAbstractMessageConverterMethodProcessor#writeWithMessageConverters中会选择消息转换器，能不能使用是通过消息转换器的canWrite方法来判断的，返回true就会使用这个消息转换器。\n\n```java\nfor (HttpMessageConverter<?> converter : this.messageConverters) {\n\t\t\t\tGenericHttpMessageConverter genericConverter = (converter instanceof GenericHttpMessageConverter ?\n\t\t\t\t\t\t(GenericHttpMessageConverter<?>) converter : null);\n\t\t\t\tif (genericConverter != null ?\n\t\t\t\t\t\t((GenericHttpMessageConverter) converter).canWrite(declaredType, valueType, selectedMediaType) :\n\t\t\t\t\t\tconverter.canWrite(valueType, selectedMediaType)) {\n\t\t\t\t\toutputValue = getAdvice().beforeBodyWrite(outputValue, returnType, selectedMediaType,\n\t\t\t\t\t\t\t(Class<? extends HttpMessageConverter<?>>) converter.getClass(),\n\t\t\t\t\t\t\tinputMessage, outputMessage);\n\t\t\t\t\tif (outputValue != null) {\n\t\t\t\t\t\taddContentDispositionHeader(inputMessage, outputMessage);\n\t\t\t\t\t\tif (genericConverter != null) {\n\t\t\t\t\t\t\tgenericConverter.write(outputValue, declaredType, selectedMediaType, outputMessage);\n\t\t\t\t\t\t}\n\t\t\t\t\t\telse {\n\t\t\t\t\t\t\t((HttpMessageConverter) converter).write(outputValue, selectedMediaType, outputMessage);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\t\t\t\tlogger.debug(\"Written [\" + outputValue + \"] as \\\"\" + selectedMediaType +\n\t\t\t\t\t\t\t\t\t\"\\\" using [\" + converter + \"]\");\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t}\n```\n\nFastJsonHttpMessageConverter的canWrite调用了父类（AbstractHttpMessageConterver）的canWrite方法，这个方法的入参是Class<?> clazz(java.lang.String)和MediaType mediaType(text/plain;version=0.0.4;charset=utf-8)\n\nAbstractHttpMessageConterver的canWrite长这样：\n\n```java\n    public boolean canWrite(Class<?> clazz, @Nullable MediaType mediaType) {\n        return this.supports(clazz) && this.canWrite(mediaType);\n    }\n```\n\nsupports方法直接就是写死的返回true，而canWrite走到最后text/*都会直接返回true，所以就这么愉快的通过了。。。\n\n而人家jackson就实在很多，人家在JacksonHttpMessageConverterConfiguration中创建MappingJackson2HttpMessageConverter的时候，调用AbstractJackson2HttpMessageConverter中的构造器，传入的supportedMediaTypes只有两个关于json的！\n\n```json\n\t/**\n\t * Construct a new {@link MappingJackson2HttpMessageConverter} with a custom {@link ObjectMapper}.\n\t * You can use {@link Jackson2ObjectMapperBuilder} to build it easily.\n\t * @see Jackson2ObjectMapperBuilder#json()\n\t */\n\tpublic MappingJackson2HttpMessageConverter(ObjectMapper objectMapper) {\n\t\tsuper(objectMapper, MediaType.APPLICATION_JSON, new MediaType(\"application\", \"*+json\"));\n\t}\n```\n\n这块确实是挺坑的。。你说fastjson，你好好管你的json就完事了，你搞什么string啊。。\n\n### 总结\n\nSpring根据请求的MediaType选择对应的消息转换器，而我们这里使用的FastJsonHttpMessageConverter，并没有像jackson一样规定supportedMediaTypes，而是AbstractHttpMessageConverter中默认的*/*，导致将text/plain的报文也给转换了，才导致了这次遇到的问题。\n","slug":"kongzheng1993-springMVC消息转换器","published":1,"updated":"2023-03-08T07:05:58.810Z","layout":"post","photos":[],"link":"","_id":"clg0k2arv00j5t26f79tb2qp2","content":"<p>今天是建党百年的日子，也是公司六周年。我们发了理想one的车模还有一件polo衫。车模我选的baby blue。</p>\n<img src=\"/2021/07/01/kongzheng1993-springMVC消息转换器/1.jpg\">\n\n<img src=\"/2021/07/01/kongzheng1993-springMVC消息转换器/2.jpg\">\n\n<img src=\"/2021/07/01/kongzheng1993-springMVC消息转换器/3.jpg\">\n\n<p>圆规正转！</p>\n<p>前几天我们上线了一个给公司app提供接口的api服务，当时ios的开发希望我们能统一处理一下返回报文json中的null，比如字符串为空修改为””，对象为空修改为{}，List为空修改为[]，原因是他不好判空。。然后我们直接实现WebMvcConfigurer，重写了configureMessageConverters，增加了一个处理json的FastJsonHttpMessageConverter，实现了ios开发要求的效果。</p>\n<pre><code class=\"java\">@Configuration\npublic class ApiMvcConfig implements WebMvcConfigurer {\n    /**\n     * 增加对Json的处理\n     * @param converters\n     */\n    @Override\n    public void configureMessageConverters(List&lt;HttpMessageConverter&lt;?&gt;&gt; converters) {\n        //针对字段的处理\n        FastJsonHttpMessageConverter converter = new FastJsonHttpMessageConverter();\n        FastJsonConfig fastJsonConfig = new FastJsonConfig();\n        fastJsonConfig.setSerializerFeatures(SerializerFeature.WriteNullListAsEmpty,// List字段如果为null,输出为[],而非null\n                SerializerFeature.WriteMapNullValue,//加上后，字段为null的也会输出\n                SerializerFeature.WriteNullStringAsEmpty,//字符类型字段如果为null,输出为”“,而非null\n                SerializerFeature.WriteNullBooleanAsFalse,//Boolean字段如果为null,输出为false,而非null\n                //SerializerFeature.WriteNullNumberAsZero, // Number 包装类如果为null，输出为0\n                SerializerFeature.DisableCircularReferenceDetect,\n                SerializerFeature.PrettyFormat  //结果是否格式化,默认为false\n        );\n        //日期格式化\n        fastJsonConfig.setDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;);\n        converter.setFastJsonConfig(fastJsonConfig);\n        converters.add(0, converter);//返回是string的话，默认把这个放在最前，否则ResponseAdvisor 处理字符串返回时会报类型不一致的问题\n    }\n}</code></pre>\n<p>上线后却发现系统没能接入prometheus。在和公司平台云服务部的同学沟通之后，发现我们给prometheus返回的报文全都加上了转译字符，导致prometheus解析不了。。。</p>\n<p>下面是有问题的报文：</p>\n<pre><code class=\"shell\">➜  ~ curl -i http://127.0.0.1:11187/dayu/prometheus\nHTTP/1.1 200\nContent-Type: text/plain; version=0.0.4;charset=utf-8\nContent-Length: 19296\nDate: Fri, 02 Jul 2021 08:35:22 GMT\n\n&quot;# HELP jvm_threads_daemon The current number of live daemon threads\\n# TYPE jvm_threads_daemon gauge\\njvm_threads_daemon{application=\\&quot;saos-pdi-api\\&quot;,env=\\&quot;test\\&quot;,namespace=\\&quot;\\&quot;,pod=\\&quot;\\&quot;,} 69.0\\n# HELP tomcat_sessions_active_max  \\n# TYPE tomcat_sessions_active_max gauge\\ntomcat_sessions_active_max{application=\\&quot;saos-pdi-api\\&quot;,env=\\&quot;test\\&quot;,namespace=\\&quot;\\&quot;,pod=\\&quot;\\&quot;,} 5.0\\n# HELP jvm_memory_committed_bytes The amount of memory in bytes that is committed for the Java virtual machine to use\\n# TYPE jvm_memory_committed_bytes gauge\\njvm_memory_committed_bytes{application=\\&quot;saos-pdi-api\\&quot;,area=\\&quot;nonheap\\&quot;,env=\\&quot;test\\&quot;,id=\\&quot;Code Cache\\&quot;,namespace=\\&quot;\\&quot;,pod=\\&quot;\\&quot;,} 2.2740992E7\\njvm_memory_committed_bytes{application=\\&quot;saos-pdi-api\\&quot;,area=\\&quot;nonheap\\&quot;,env=\\&quot;test\\&quot;,id=\\&quot;Metaspace\\&quot;,namespace=\\&quot;\\&quot;,pod=\\&quot;\\&quot;,} 9.728E7\\njvm_memory_committed_bytes{application=\\&quot;saos-pdi-api\\&quot;,area=\\&quot;nonheap\\&quot;,env=\\&quot;test\\&quot;,id=\\&quot;Compressed Class Space\\&quot;,namespace=\\&quot;\\&quot;,pod=\\&quot;\\&quot;,} 1.2894208E7\\njvm_memory_committed_bytes{application=\\&quot;saos-pdi-api\\&quot;,area=\\&quot;heap\\&quot;,env=\\&quot;test\\&quot;,id=\\&quot;PS Eden Space\\&quot;,namespace=\\&quot;\\&quot;,pod=\\&quot;\\&quot;,} 7.99014912E8\\njvm_memory_committed_bytes{application=\\&quot;saos-pdi-api\\&quot;,area=\\&quot;heap\\&quot;,env=\\&quot;test\\&quot;,id=\\&quot;PS Survivor Space\\&quot;,namespace=\\&quot;\\&quot;,pod=\\&quot;\\&quot;,} 2.2020096E7\\njvm_memory_committed_bytes{application=\\&quot;saos-pdi-api\\&quot;,area=\\&quot;heap\\&quot;,env=\\&quot;test\\&quot;,id=\\&quot;PS Old Gen\\&quot;,namespace=\\&quot;\\&quot;,pod=\\&quot;\\&quot;,} 1.9136512E8\\n# HELP tomcat_sessions_expired_total  \\n# TYPE tomcat_sessions_expired_total counter\\ntomcat_sessions_expired_total{application=\\&quot;saos-pdi-api\\&quot;,env=\\&quot;test\\&quot;,namespace=\\&quot;\\&quot;,pod=\\&quot;\\&quot;,} 0.0\\n# HELP logback_events_total Number of error level events that made it to the logs\\n# TYPE logback_events_total counter\\nlogback_events_total{application=\\&quot;saos-pdi-api\\&quot;,env=\\&quot;test\\&quot;,level=\\&quot;error\\&quot;,namespace=\\&quot;\\&quot;,pod=\\&quot;\\&quot;,} 0.0\\nlogback_events_total{application=\\&quot;saos-pdi-api\\&quot;,env=\\&quot;test\\&quot;,level=\\&quot;warn\\&quot;,namespace=\\&quot;\\&quot;,pod=\\&quot;\\&quot;,} 5.0\\nlogback_events_total{application=\\&quot;saos-pdi-api\\&quot;,env=\\&quot;test\\&quot;,level=\\&quot;info\\&quot;,namespace=\\&quot;\\&quot;,pod=\\&quot;\\&quot;,} 401.0\\nlogback_events_total{application=\\&quot;saos-pdi-api\\&quot;,env=\\&quot;test\\&quot;,level=\\&quot;debug\\&quot;,namespace=\\&quot;\\&quot;,pod=\\&quot;\\&quot;,} 60.0\\nlogback_events_total{application=\\&quot;saos-pdi-api\\&quot;,env=\\&quot;test\\&quot;,level=\\&quot;trace\\&quot;,namespace=\\&quot;\\&quot;,pod=\\&quot;\\&quot;,} 0.0\\n# HELP jvm_buffer_total_capacity_bytes An estimate of the total capacity of the buffers in this pool\\n# TYPE jvm_buffer_total_capacity_bytes gauge\\njvm_buffer_total_capacity_bytes{application=\\&quot;saos-pdi-api\\&quot;,env=\\&quot;test\\&quot;,id=\\&quot;direct\\&quot;,namespace=\\&quot;\\&quot;,pod=\\&quot;\\&quot;,} 170147.0\\njvm_buffer_total_capacity_bytes{application=\\&quot;saos-pdi-api\\&quot;,env=\\&quot;test\\&quot;,id=\\&quot;mapped\\&quot;,namespace=\\&quot;\\&quot;,pod=\\&quot;\\&quot;,} 0.0\\n# HELP system_cpu_usage The \\&quot;recent cpu usage\\&quot; for the whole system\\n# TYPE system_cpu_usage gauge\\nsystem_cpu_usage{application=\\&quot;saos-pdi-api\\&quot;,env=\\&quot;test\\&quot;,namespace=\\&quot;\\&quot;,pod=\\&quot;\\&quot;,} 0.03545880166806259\\n# HELP tomcat_threads_config_max  \\n# TYPE tomcat_threads_config_max gauge\\ntomcat_threads_config_max{application=\\&quot;saos-pdi-api\\&quot;,env=\\&quot;test\\&quot;,name=\\&quot;http-nio-11187\\&quot;,namespace=\\&quot;\\&quot;,pod=\\&quot;\\&quot;,} 200.0\\n# HELP tomcat_threads_current  \\n# TYPE tomcat_threads_current gauge\\ntomcat_threads_current{application=\\&quot;saos-pdi-api\\&quot;,env=\\&quot;test\\&quot;,name=\\&quot;http-nio-11187\\&quot;,namespace=\\&quot;\\&quot;,pod=\\&quot;\\&quot;,} 10.0\\n# HELP tomcat_sessions_rejected_total  \\n# TYPE tomcat_sessions_rejected_total counter\\ntomcat_sessions_rejected_total{application=\\&quot;saos-pdi-api\\&quot;,env=\\&quot;test\\&quot;,namespace=\\&quot;\\&quot;,pod=\\&quot;\\&quot;,} 0.0\\n# HELP tomcat_global_request_seconds  \\n# TYPE tomcat_global_request_seconds summary\\ntomcat_global_request_seconds_count{application=\\&quot;saos-pdi-api\\&quot;,env=\\&quot;test\\&quot;,name=\\&quot;http-nio-11187\\&quot;,namespace=\\&quot;\\&quot;,pod=\\&quot;\\&quot;,} 21.0\\ntomcat_global_request_seconds_sum{application=\\&quot;saos-pdi-api\\&quot;,env=\\&quot;test\\&quot;,name=\\&quot;http-nio-11187\\&quot;,namespace=\\&quot;\\&quot;,pod=\\&quot;\\&quot;,} 14.12\\n# HELP jvm_memory_max_bytes The maximum amount of memory in bytes that can be used for memory management\\n# TYPE jvm_memory_max_bytes gauge\\njvm_memory_max_bytes{application=\\&quot;saos-pdi-api\\&quot;,area=\\&quot;nonheap\\&quot;,env=\\&quot;test\\&quot;,id=\\&quot;Code Cache\\&quot;,namespace=\\&quot;\\&quot;,pod=\\&quot;\\&quot;,} 2.5165824E8\\njvm_memory_max_bytes{application=\\&quot;saos-pdi-api\\&quot;,area=\\&quot;nonheap\\&quot;,env=\\&quot;test\\&quot;,id=\\&quot;Metaspace\\&quot;,namespace=\\&quot;\\&quot;,pod=\\&quot;\\&quot;,} -1.0\\njvm_memory_max_bytes{application=\\&quot;saos-pdi-api\\&quot;,area=\\&quot;nonheap\\&quot;,env=\\&quot;test\\&quot;,id=\\&quot;Compressed Class Space\\&quot;,namespace=\\&quot;\\&quot;,pod=\\&quot;\\&quot;,} 1.073741824E9\\njvm_memory_max_bytes{application=\\&quot;saos-pdi-api\\&quot;,area=\\&quot;heap\\&quot;,env=\\&quot;test\\&quot;,id=\\&quot;PS Eden Space\\&quot;,namespace=\\&quot;\\&quot;,pod=\\&quot;\\&quot;,} 1.311244288E9\\njvm_memory_max_bytes{application=\\&quot;saos-pdi-api\\&quot;,area=\\&quot;heap\\&quot;,env=\\&quot;test\\&quot;,id=\\&quot;PS Survivor Space\\\n...</code></pre>\n<p>下面是正常的报文：</p>\n<pre><code class=\"shell\">➜  ~ curl -i http://127.0.0.1:11187/dayu/prometheus\nHTTP/1.1 200\nContent-Type: text/plain; version=0.0.4;charset=utf-8\nContent-Length: 12594\nDate: Fri, 02 Jul 2021 08:39:14 GMT\n\n# HELP tomcat_global_request_max_seconds\n# TYPE tomcat_global_request_max_seconds gauge\ntomcat_global_request_max_seconds{application=&quot;saos-pdi-api&quot;,env=&quot;test&quot;,name=&quot;http-nio-11187&quot;,namespace=&quot;&quot;,pod=&quot;&quot;,} 0.0\n# HELP tomcat_global_received_bytes_total\n# TYPE tomcat_global_received_bytes_total counter\ntomcat_global_received_bytes_total{application=&quot;saos-pdi-api&quot;,env=&quot;test&quot;,name=&quot;http-nio-11187&quot;,namespace=&quot;&quot;,pod=&quot;&quot;,} 0.0\n# HELP jvm_memory_committed_bytes The amount of memory in bytes that is committed for the Java virtual machine to use\n# TYPE jvm_memory_committed_bytes gauge\njvm_memory_committed_bytes{application=&quot;saos-pdi-api&quot;,area=&quot;nonheap&quot;,env=&quot;test&quot;,id=&quot;Code Cache&quot;,namespace=&quot;&quot;,pod=&quot;&quot;,} 1.9857408E7\njvm_memory_committed_bytes{application=&quot;saos-pdi-api&quot;,area=&quot;nonheap&quot;,env=&quot;test&quot;,id=&quot;Metaspace&quot;,namespace=&quot;&quot;,pod=&quot;&quot;,} 8.7318528E7\njvm_memory_committed_bytes{application=&quot;saos-pdi-api&quot;,area=&quot;nonheap&quot;,env=&quot;test&quot;,id=&quot;Compressed Class Space&quot;,namespace=&quot;&quot;,pod=&quot;&quot;,} 1.1583488E7\njvm_memory_committed_bytes{application=&quot;saos-pdi-api&quot;,area=&quot;heap&quot;,env=&quot;test&quot;,id=&quot;PS Eden Space&quot;,namespace=&quot;&quot;,pod=&quot;&quot;,} 1.120927744E9\njvm_memory_committed_bytes{application=&quot;saos-pdi-api&quot;,area=&quot;heap&quot;,env=&quot;test&quot;,id=&quot;PS Survivor Space&quot;,namespace=&quot;&quot;,pod=&quot;&quot;,} 2.359296E7\njvm_memory_committed_bytes{application=&quot;saos-pdi-api&quot;,area=&quot;heap&quot;,env=&quot;test&quot;,id=&quot;PS Old Gen&quot;,namespace=&quot;&quot;,pod=&quot;&quot;,} 1.86646528E8\n# HELP tomcat_servlet_request_seconds\n# TYPE tomcat_servlet_request_seconds summary\ntomcat_servlet_request_seconds_count{application=&quot;saos-pdi-api&quot;,env=&quot;test&quot;,name=&quot;dispatcherServlet&quot;,namespace=&quot;&quot;,pod=&quot;&quot;,} 1.0\ntomcat_servlet_request_seconds_sum{application=&quot;saos-pdi-api&quot;,env=&quot;test&quot;,name=&quot;dispatcherServlet&quot;,namespace=&quot;&quot;,pod=&quot;&quot;,} 0.0\n# HELP health\n# TYPE health gauge\nhealth{application=&quot;saos-pdi-api&quot;,env=&quot;test&quot;,namespace=&quot;&quot;,pod=&quot;&quot;,} 3.0\n# HELP jvm_buffer_memory_used_bytes An estimate of the memory that the Java virtual machine is using for this buffer pool\n# TYPE jvm_buffer_memory_used_bytes gauge\njvm_buffer_memory_used_bytes{application=&quot;saos-pdi-api&quot;,env=&quot;test&quot;,id=&quot;direct&quot;,namespace=&quot;&quot;,pod=&quot;&quot;,} 91015.0\njvm_buffer_memory_used_bytes{application=&quot;saos-pdi-api&quot;,env=&quot;test&quot;,id=&quot;mapped&quot;,namespace=&quot;&quot;,pod=&quot;&quot;,} 0.0\n# HELP tomcat_threads_current\n# TYPE tomcat_threads_current gauge\ntomcat_threads_current{application=&quot;saos-pdi-api&quot;,env=&quot;test&quot;,name=&quot;http-nio-11187&quot;,namespace=&quot;&quot;,pod=&quot;&quot;,} 10.0\n# HELP process_start_time_seconds Start time of the process since unix epoch.\n# TYPE process_start_time_seconds gauge\nprocess_start_time_seconds{application=&quot;saos-pdi-api&quot;,env=&quot;test&quot;,namespace=&quot;&quot;,pod=&quot;&quot;,} 1.625215112786E9\n# HELP tomcat_threads_config_max\n# TYPE tomcat_threads_config_max gauge\ntomcat_threads_config_max{application=&quot;saos-pdi-api&quot;,env=&quot;test&quot;,name=&quot;http-nio-11187&quot;,namespace=&quot;&quot;,pod=&quot;&quot;,} 200.0\n# HELP jvm_gc_memory_promoted_bytes_total Count of positive increases in the size of the old generation memory pool before GC to after GC\n# TYPE jvm_gc_memory_promoted_bytes_total counter\njvm_gc_memory_promoted_bytes_total{application=&quot;saos-pdi-api&quot;,env=&quot;test&quot;,namespace=&quot;&quot;,pod=&quot;&quot;,} 4.5149664E7\n# HELP jvm_gc_memory_allocated_bytes_total Incremented for an increase in the size of the young generation memory pool after one GC to before the next\n# TYPE jvm_gc_memory_allocated_bytes_total counter\njvm_gc_memory_allocated_bytes_total{application=&quot;saos-pdi-api&quot;,env=&quot;test&quot;,namespace=&quot;&quot;,pod=&quot;&quot;,} 3.43775952E9\n# HELP tomcat_global_sent_bytes_total\n# TYPE tomcat_global_sent_bytes_total counter\ntomcat_global_sent_bytes_total{application=&quot;saos-pdi-api&quot;,env=&quot;test&quot;,name=&quot;http-nio-11187&quot;,namespace=&quot;&quot;,pod=&quot;&quot;,} 0.0\n# HELP jvm_classes_unloaded_total The total number of classes unloaded since the Java virtual machine has started execution</code></pre>\n<p>可以看到，Prometheus这个接口的响应报文，并不是一个单纯的json格式，而是text里有json格式的东西。</p>\n<p>当时就怀疑是Fastjson是不是有点啥问题[doge]……</p>\n<p>果不其然，让我在github上找到一个<a href=\"https://github.com/alibaba/fastjson/issues/1373\" target=\"_blank\" rel=\"noopener\">issues</a></p>\n<p>之前老版本的fastjson是有一个DisableCheckSpecialChar的SerializerFeature的，可以禁止特殊字符的转译，现在标了过期，直接不能用了，默认就给转译。。</p>\n<p>使用老版本的fastjson，并加上SerializerFeature.DisableCheckSpecialChar后，是可以的。</p>\n<p>但是我们都知道fastjson动不动就爆出漏洞，最新的版本都有点怕，更别说那么老的版本了。</p>\n<p>只能再想办法。</p>\n<p>我们从头开始想：</p>\n<p>http响应的报文，是怎么转换的呢？–&gt; HttpMessageConverter</p>\n<p>所以这块还得研究透spring的HttpMessageConverter是怎么工作的！</p>\n<p>我们都知道请求和响应都是要经过DispatcherServlet类的doDispatch方法。然后获取HandlerAdapter，然后获取对应的Handler，并调用handle方法，中间有对应的请求内容的消息转换器进行请求报文的转换，返回的时候，也会用消息解析器进行报文的转换，最后写入到http的outputStream，完成一次请求的响应。</p>\n<p>看我上面增加的自定义的FastJsonHttpMessageConverter，可以看到，我将自定义的HttpMessageConverter放到了第一位，当时考虑是spring有一些默认的消息转换器，对应的json的转换器使用jackson实现的。spring在选择消息转换器的时候，是遍历所有的转换器，找到第一个合适的就使用。所以我必须放到jackson前面，但是放到第一位，也就在string的转换器之前了，暴露给Prometheus的接口是text/plain的，讲道理fastjson不应该处理它，应该留给StringHttpMessageConterver来转换才对啊。</p>\n<p>下面的代码是spring默认的消息处理器：</p>\n<pre><code class=\"java\">protected final void addDefaultHttpMessageConverters(List&lt;HttpMessageConverter&lt;?&gt;&gt; messageConverters) {\n        StringHttpMessageConverter stringHttpMessageConverter = new StringHttpMessageConverter();\n        stringHttpMessageConverter.setWriteAcceptCharset(false);  // see SPR-7316\n\n        messageConverters.add(new ByteArrayHttpMessageConverter());\n        messageConverters.add(stringHttpMessageConverter);\n        messageConverters.add(new ResourceHttpMessageConverter());\n        messageConverters.add(new ResourceRegionHttpMessageConverter());\n        messageConverters.add(new SourceHttpMessageConverter&lt;&gt;());\n        messageConverters.add(new AllEncompassingFormHttpMessageConverter());\n\n        if (romePresent) {\n            messageConverters.add(new AtomFeedHttpMessageConverter());\n            messageConverters.add(new RssChannelHttpMessageConverter());\n        }\n\n        if (jackson2XmlPresent) {\n            Jackson2ObjectMapperBuilder builder = Jackson2ObjectMapperBuilder.xml();\n            if (this.applicationContext != null) {\n                builder.applicationContext(this.applicationContext);\n            }\n            messageConverters.add(new MappingJackson2XmlHttpMessageConverter(builder.build()));\n        }\n        else if (jaxb2Present) {\n            messageConverters.add(new Jaxb2RootElementHttpMessageConverter());\n        }\n\n        if (jackson2Present) {\n            Jackson2ObjectMapperBuilder builder = Jackson2ObjectMapperBuilder.json();\n            if (this.applicationContext != null) {\n                builder.applicationContext(this.applicationContext);\n            }\n            messageConverters.add(new MappingJackson2HttpMessageConverter(builder.build()));\n        }\n        else if (gsonPresent) {\n            messageConverters.add(new GsonHttpMessageConverter());\n        }\n        else if (jsonbPresent) {\n            messageConverters.add(new JsonbHttpMessageConverter());\n        }\n\n        if (jackson2SmilePresent) {\n            Jackson2ObjectMapperBuilder builder = Jackson2ObjectMapperBuilder.smile();\n            if (this.applicationContext != null) {\n                builder.applicationContext(this.applicationContext);\n            }\n            messageConverters.add(new MappingJackson2SmileHttpMessageConverter(builder.build()));\n        }\n        if (jackson2CborPresent) {\n            Jackson2ObjectMapperBuilder builder = Jackson2ObjectMapperBuilder.cbor();\n            if (this.applicationContext != null) {\n                builder.applicationContext(this.applicationContext);\n            }\n            messageConverters.add(new MappingJackson2CborHttpMessageConverter(builder.build()));\n        }\n    }</code></pre>\n<p>可以看到第一位是byte，第二位是String。。。。</p>\n<p>试着调整我们自定义消息处理器的位置到后面：</p>\n<pre><code class=\"java\">    public void configureMessageConverters(List&lt;HttpMessageConverter&lt;?&gt;&gt; converters) {\n        //针对字段的处理\n        FastJsonHttpMessageConverter converter = new FastJsonHttpMessageConverter();\n        FastJsonConfig fastJsonConfig = new FastJsonConfig();\n        fastJsonConfig.setSerializerFeatures(SerializerFeature.WriteNullListAsEmpty,// List字段如果为null,输出为[],而非null\n                SerializerFeature.WriteMapNullValue,//加上后，字段为null的也会输出\n                SerializerFeature.WriteNullStringAsEmpty,//字符类型字段如果为null,输出为”“,而非null\n                SerializerFeature.WriteNullBooleanAsFalse,//Boolean字段如果为null,输出为false,而非null\n                //SerializerFeature.WriteNullNumberAsZero, // Number 包装类如果为null，输出为0\n                SerializerFeature.DisableCircularReferenceDetect,\n                SerializerFeature.PrettyFormat  //结果是否格式化,默认为false\n        );\n        //日期格式化\n        fastJsonConfig.setDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;);\n        converter.setFastJsonConfig(fastJsonConfig);\n        converters.add(3,converter);//返回是string的话，默认把这个放在最前，否则ResponseAdvisor 处理字符串返回时会报类型不一致的问题\n    }</code></pre>\n<p>这里调整到第四位，可以满足要求。最后也是这样上线解决问题的。</p>\n<p>现在还有一个问题，为什么FastJsonHttpMessageConverter要处理text/plain的请求呢？</p>\n<p>AbstractMessageConverterMethodProcessor#writeWithMessageConverters中会选择消息转换器，能不能使用是通过消息转换器的canWrite方法来判断的，返回true就会使用这个消息转换器。</p>\n<pre><code class=\"java\">for (HttpMessageConverter&lt;?&gt; converter : this.messageConverters) {\n                GenericHttpMessageConverter genericConverter = (converter instanceof GenericHttpMessageConverter ?\n                        (GenericHttpMessageConverter&lt;?&gt;) converter : null);\n                if (genericConverter != null ?\n                        ((GenericHttpMessageConverter) converter).canWrite(declaredType, valueType, selectedMediaType) :\n                        converter.canWrite(valueType, selectedMediaType)) {\n                    outputValue = getAdvice().beforeBodyWrite(outputValue, returnType, selectedMediaType,\n                            (Class&lt;? extends HttpMessageConverter&lt;?&gt;&gt;) converter.getClass(),\n                            inputMessage, outputMessage);\n                    if (outputValue != null) {\n                        addContentDispositionHeader(inputMessage, outputMessage);\n                        if (genericConverter != null) {\n                            genericConverter.write(outputValue, declaredType, selectedMediaType, outputMessage);\n                        }\n                        else {\n                            ((HttpMessageConverter) converter).write(outputValue, selectedMediaType, outputMessage);\n                        }\n                        if (logger.isDebugEnabled()) {\n                            logger.debug(&quot;Written [&quot; + outputValue + &quot;] as \\&quot;&quot; + selectedMediaType +\n                                    &quot;\\&quot; using [&quot; + converter + &quot;]&quot;);\n                        }\n                    }\n                    return;\n                }\n            }</code></pre>\n<p>FastJsonHttpMessageConverter的canWrite调用了父类（AbstractHttpMessageConterver）的canWrite方法，这个方法的入参是Class&lt;?&gt; clazz(java.lang.String)和MediaType mediaType(text/plain;version=0.0.4;charset=utf-8)</p>\n<p>AbstractHttpMessageConterver的canWrite长这样：</p>\n<pre><code class=\"java\">    public boolean canWrite(Class&lt;?&gt; clazz, @Nullable MediaType mediaType) {\n        return this.supports(clazz) &amp;&amp; this.canWrite(mediaType);\n    }</code></pre>\n<p>supports方法直接就是写死的返回true，而canWrite走到最后text/*都会直接返回true，所以就这么愉快的通过了。。。</p>\n<p>而人家jackson就实在很多，人家在JacksonHttpMessageConverterConfiguration中创建MappingJackson2HttpMessageConverter的时候，调用AbstractJackson2HttpMessageConverter中的构造器，传入的supportedMediaTypes只有两个关于json的！</p>\n<pre><code class=\"json\">    /**\n     * Construct a new {@link MappingJackson2HttpMessageConverter} with a custom {@link ObjectMapper}.\n     * You can use {@link Jackson2ObjectMapperBuilder} to build it easily.\n     * @see Jackson2ObjectMapperBuilder#json()\n     */\n    public MappingJackson2HttpMessageConverter(ObjectMapper objectMapper) {\n        super(objectMapper, MediaType.APPLICATION_JSON, new MediaType(&quot;application&quot;, &quot;*+json&quot;));\n    }</code></pre>\n<p>这块确实是挺坑的。。你说fastjson，你好好管你的json就完事了，你搞什么string啊。。</p>\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3><p>Spring根据请求的MediaType选择对应的消息转换器，而我们这里使用的FastJsonHttpMessageConverter，并没有像jackson一样规定supportedMediaTypes，而是AbstractHttpMessageConverter中默认的<em>/</em>，导致将text/plain的报文也给转换了，才导致了这次遇到的问题。</p>\n","site":{"data":{}},"more":"<p>今天是建党百年的日子，也是公司六周年。我们发了理想one的车模还有一件polo衫。车模我选的baby blue。</p>\n<img src=\"/2021/07/01/kongzheng1993-springMVC消息转换器/1.jpg\">\n\n<img src=\"/2021/07/01/kongzheng1993-springMVC消息转换器/2.jpg\">\n\n<img src=\"/2021/07/01/kongzheng1993-springMVC消息转换器/3.jpg\">\n\n<p>圆规正转！</p>\n<p>前几天我们上线了一个给公司app提供接口的api服务，当时ios的开发希望我们能统一处理一下返回报文json中的null，比如字符串为空修改为””，对象为空修改为{}，List为空修改为[]，原因是他不好判空。。然后我们直接实现WebMvcConfigurer，重写了configureMessageConverters，增加了一个处理json的FastJsonHttpMessageConverter，实现了ios开发要求的效果。</p>\n<pre><code class=\"java\">@Configuration\npublic class ApiMvcConfig implements WebMvcConfigurer {\n    /**\n     * 增加对Json的处理\n     * @param converters\n     */\n    @Override\n    public void configureMessageConverters(List&lt;HttpMessageConverter&lt;?&gt;&gt; converters) {\n        //针对字段的处理\n        FastJsonHttpMessageConverter converter = new FastJsonHttpMessageConverter();\n        FastJsonConfig fastJsonConfig = new FastJsonConfig();\n        fastJsonConfig.setSerializerFeatures(SerializerFeature.WriteNullListAsEmpty,// List字段如果为null,输出为[],而非null\n                SerializerFeature.WriteMapNullValue,//加上后，字段为null的也会输出\n                SerializerFeature.WriteNullStringAsEmpty,//字符类型字段如果为null,输出为”“,而非null\n                SerializerFeature.WriteNullBooleanAsFalse,//Boolean字段如果为null,输出为false,而非null\n                //SerializerFeature.WriteNullNumberAsZero, // Number 包装类如果为null，输出为0\n                SerializerFeature.DisableCircularReferenceDetect,\n                SerializerFeature.PrettyFormat  //结果是否格式化,默认为false\n        );\n        //日期格式化\n        fastJsonConfig.setDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;);\n        converter.setFastJsonConfig(fastJsonConfig);\n        converters.add(0, converter);//返回是string的话，默认把这个放在最前，否则ResponseAdvisor 处理字符串返回时会报类型不一致的问题\n    }\n}</code></pre>\n<p>上线后却发现系统没能接入prometheus。在和公司平台云服务部的同学沟通之后，发现我们给prometheus返回的报文全都加上了转译字符，导致prometheus解析不了。。。</p>\n<p>下面是有问题的报文：</p>\n<pre><code class=\"shell\">➜  ~ curl -i http://127.0.0.1:11187/dayu/prometheus\nHTTP/1.1 200\nContent-Type: text/plain; version=0.0.4;charset=utf-8\nContent-Length: 19296\nDate: Fri, 02 Jul 2021 08:35:22 GMT\n\n&quot;# HELP jvm_threads_daemon The current number of live daemon threads\\n# TYPE jvm_threads_daemon gauge\\njvm_threads_daemon{application=\\&quot;saos-pdi-api\\&quot;,env=\\&quot;test\\&quot;,namespace=\\&quot;\\&quot;,pod=\\&quot;\\&quot;,} 69.0\\n# HELP tomcat_sessions_active_max  \\n# TYPE tomcat_sessions_active_max gauge\\ntomcat_sessions_active_max{application=\\&quot;saos-pdi-api\\&quot;,env=\\&quot;test\\&quot;,namespace=\\&quot;\\&quot;,pod=\\&quot;\\&quot;,} 5.0\\n# HELP jvm_memory_committed_bytes The amount of memory in bytes that is committed for the Java virtual machine to use\\n# TYPE jvm_memory_committed_bytes gauge\\njvm_memory_committed_bytes{application=\\&quot;saos-pdi-api\\&quot;,area=\\&quot;nonheap\\&quot;,env=\\&quot;test\\&quot;,id=\\&quot;Code Cache\\&quot;,namespace=\\&quot;\\&quot;,pod=\\&quot;\\&quot;,} 2.2740992E7\\njvm_memory_committed_bytes{application=\\&quot;saos-pdi-api\\&quot;,area=\\&quot;nonheap\\&quot;,env=\\&quot;test\\&quot;,id=\\&quot;Metaspace\\&quot;,namespace=\\&quot;\\&quot;,pod=\\&quot;\\&quot;,} 9.728E7\\njvm_memory_committed_bytes{application=\\&quot;saos-pdi-api\\&quot;,area=\\&quot;nonheap\\&quot;,env=\\&quot;test\\&quot;,id=\\&quot;Compressed Class Space\\&quot;,namespace=\\&quot;\\&quot;,pod=\\&quot;\\&quot;,} 1.2894208E7\\njvm_memory_committed_bytes{application=\\&quot;saos-pdi-api\\&quot;,area=\\&quot;heap\\&quot;,env=\\&quot;test\\&quot;,id=\\&quot;PS Eden Space\\&quot;,namespace=\\&quot;\\&quot;,pod=\\&quot;\\&quot;,} 7.99014912E8\\njvm_memory_committed_bytes{application=\\&quot;saos-pdi-api\\&quot;,area=\\&quot;heap\\&quot;,env=\\&quot;test\\&quot;,id=\\&quot;PS Survivor Space\\&quot;,namespace=\\&quot;\\&quot;,pod=\\&quot;\\&quot;,} 2.2020096E7\\njvm_memory_committed_bytes{application=\\&quot;saos-pdi-api\\&quot;,area=\\&quot;heap\\&quot;,env=\\&quot;test\\&quot;,id=\\&quot;PS Old Gen\\&quot;,namespace=\\&quot;\\&quot;,pod=\\&quot;\\&quot;,} 1.9136512E8\\n# HELP tomcat_sessions_expired_total  \\n# TYPE tomcat_sessions_expired_total counter\\ntomcat_sessions_expired_total{application=\\&quot;saos-pdi-api\\&quot;,env=\\&quot;test\\&quot;,namespace=\\&quot;\\&quot;,pod=\\&quot;\\&quot;,} 0.0\\n# HELP logback_events_total Number of error level events that made it to the logs\\n# TYPE logback_events_total counter\\nlogback_events_total{application=\\&quot;saos-pdi-api\\&quot;,env=\\&quot;test\\&quot;,level=\\&quot;error\\&quot;,namespace=\\&quot;\\&quot;,pod=\\&quot;\\&quot;,} 0.0\\nlogback_events_total{application=\\&quot;saos-pdi-api\\&quot;,env=\\&quot;test\\&quot;,level=\\&quot;warn\\&quot;,namespace=\\&quot;\\&quot;,pod=\\&quot;\\&quot;,} 5.0\\nlogback_events_total{application=\\&quot;saos-pdi-api\\&quot;,env=\\&quot;test\\&quot;,level=\\&quot;info\\&quot;,namespace=\\&quot;\\&quot;,pod=\\&quot;\\&quot;,} 401.0\\nlogback_events_total{application=\\&quot;saos-pdi-api\\&quot;,env=\\&quot;test\\&quot;,level=\\&quot;debug\\&quot;,namespace=\\&quot;\\&quot;,pod=\\&quot;\\&quot;,} 60.0\\nlogback_events_total{application=\\&quot;saos-pdi-api\\&quot;,env=\\&quot;test\\&quot;,level=\\&quot;trace\\&quot;,namespace=\\&quot;\\&quot;,pod=\\&quot;\\&quot;,} 0.0\\n# HELP jvm_buffer_total_capacity_bytes An estimate of the total capacity of the buffers in this pool\\n# TYPE jvm_buffer_total_capacity_bytes gauge\\njvm_buffer_total_capacity_bytes{application=\\&quot;saos-pdi-api\\&quot;,env=\\&quot;test\\&quot;,id=\\&quot;direct\\&quot;,namespace=\\&quot;\\&quot;,pod=\\&quot;\\&quot;,} 170147.0\\njvm_buffer_total_capacity_bytes{application=\\&quot;saos-pdi-api\\&quot;,env=\\&quot;test\\&quot;,id=\\&quot;mapped\\&quot;,namespace=\\&quot;\\&quot;,pod=\\&quot;\\&quot;,} 0.0\\n# HELP system_cpu_usage The \\&quot;recent cpu usage\\&quot; for the whole system\\n# TYPE system_cpu_usage gauge\\nsystem_cpu_usage{application=\\&quot;saos-pdi-api\\&quot;,env=\\&quot;test\\&quot;,namespace=\\&quot;\\&quot;,pod=\\&quot;\\&quot;,} 0.03545880166806259\\n# HELP tomcat_threads_config_max  \\n# TYPE tomcat_threads_config_max gauge\\ntomcat_threads_config_max{application=\\&quot;saos-pdi-api\\&quot;,env=\\&quot;test\\&quot;,name=\\&quot;http-nio-11187\\&quot;,namespace=\\&quot;\\&quot;,pod=\\&quot;\\&quot;,} 200.0\\n# HELP tomcat_threads_current  \\n# TYPE tomcat_threads_current gauge\\ntomcat_threads_current{application=\\&quot;saos-pdi-api\\&quot;,env=\\&quot;test\\&quot;,name=\\&quot;http-nio-11187\\&quot;,namespace=\\&quot;\\&quot;,pod=\\&quot;\\&quot;,} 10.0\\n# HELP tomcat_sessions_rejected_total  \\n# TYPE tomcat_sessions_rejected_total counter\\ntomcat_sessions_rejected_total{application=\\&quot;saos-pdi-api\\&quot;,env=\\&quot;test\\&quot;,namespace=\\&quot;\\&quot;,pod=\\&quot;\\&quot;,} 0.0\\n# HELP tomcat_global_request_seconds  \\n# TYPE tomcat_global_request_seconds summary\\ntomcat_global_request_seconds_count{application=\\&quot;saos-pdi-api\\&quot;,env=\\&quot;test\\&quot;,name=\\&quot;http-nio-11187\\&quot;,namespace=\\&quot;\\&quot;,pod=\\&quot;\\&quot;,} 21.0\\ntomcat_global_request_seconds_sum{application=\\&quot;saos-pdi-api\\&quot;,env=\\&quot;test\\&quot;,name=\\&quot;http-nio-11187\\&quot;,namespace=\\&quot;\\&quot;,pod=\\&quot;\\&quot;,} 14.12\\n# HELP jvm_memory_max_bytes The maximum amount of memory in bytes that can be used for memory management\\n# TYPE jvm_memory_max_bytes gauge\\njvm_memory_max_bytes{application=\\&quot;saos-pdi-api\\&quot;,area=\\&quot;nonheap\\&quot;,env=\\&quot;test\\&quot;,id=\\&quot;Code Cache\\&quot;,namespace=\\&quot;\\&quot;,pod=\\&quot;\\&quot;,} 2.5165824E8\\njvm_memory_max_bytes{application=\\&quot;saos-pdi-api\\&quot;,area=\\&quot;nonheap\\&quot;,env=\\&quot;test\\&quot;,id=\\&quot;Metaspace\\&quot;,namespace=\\&quot;\\&quot;,pod=\\&quot;\\&quot;,} -1.0\\njvm_memory_max_bytes{application=\\&quot;saos-pdi-api\\&quot;,area=\\&quot;nonheap\\&quot;,env=\\&quot;test\\&quot;,id=\\&quot;Compressed Class Space\\&quot;,namespace=\\&quot;\\&quot;,pod=\\&quot;\\&quot;,} 1.073741824E9\\njvm_memory_max_bytes{application=\\&quot;saos-pdi-api\\&quot;,area=\\&quot;heap\\&quot;,env=\\&quot;test\\&quot;,id=\\&quot;PS Eden Space\\&quot;,namespace=\\&quot;\\&quot;,pod=\\&quot;\\&quot;,} 1.311244288E9\\njvm_memory_max_bytes{application=\\&quot;saos-pdi-api\\&quot;,area=\\&quot;heap\\&quot;,env=\\&quot;test\\&quot;,id=\\&quot;PS Survivor Space\\\n...</code></pre>\n<p>下面是正常的报文：</p>\n<pre><code class=\"shell\">➜  ~ curl -i http://127.0.0.1:11187/dayu/prometheus\nHTTP/1.1 200\nContent-Type: text/plain; version=0.0.4;charset=utf-8\nContent-Length: 12594\nDate: Fri, 02 Jul 2021 08:39:14 GMT\n\n# HELP tomcat_global_request_max_seconds\n# TYPE tomcat_global_request_max_seconds gauge\ntomcat_global_request_max_seconds{application=&quot;saos-pdi-api&quot;,env=&quot;test&quot;,name=&quot;http-nio-11187&quot;,namespace=&quot;&quot;,pod=&quot;&quot;,} 0.0\n# HELP tomcat_global_received_bytes_total\n# TYPE tomcat_global_received_bytes_total counter\ntomcat_global_received_bytes_total{application=&quot;saos-pdi-api&quot;,env=&quot;test&quot;,name=&quot;http-nio-11187&quot;,namespace=&quot;&quot;,pod=&quot;&quot;,} 0.0\n# HELP jvm_memory_committed_bytes The amount of memory in bytes that is committed for the Java virtual machine to use\n# TYPE jvm_memory_committed_bytes gauge\njvm_memory_committed_bytes{application=&quot;saos-pdi-api&quot;,area=&quot;nonheap&quot;,env=&quot;test&quot;,id=&quot;Code Cache&quot;,namespace=&quot;&quot;,pod=&quot;&quot;,} 1.9857408E7\njvm_memory_committed_bytes{application=&quot;saos-pdi-api&quot;,area=&quot;nonheap&quot;,env=&quot;test&quot;,id=&quot;Metaspace&quot;,namespace=&quot;&quot;,pod=&quot;&quot;,} 8.7318528E7\njvm_memory_committed_bytes{application=&quot;saos-pdi-api&quot;,area=&quot;nonheap&quot;,env=&quot;test&quot;,id=&quot;Compressed Class Space&quot;,namespace=&quot;&quot;,pod=&quot;&quot;,} 1.1583488E7\njvm_memory_committed_bytes{application=&quot;saos-pdi-api&quot;,area=&quot;heap&quot;,env=&quot;test&quot;,id=&quot;PS Eden Space&quot;,namespace=&quot;&quot;,pod=&quot;&quot;,} 1.120927744E9\njvm_memory_committed_bytes{application=&quot;saos-pdi-api&quot;,area=&quot;heap&quot;,env=&quot;test&quot;,id=&quot;PS Survivor Space&quot;,namespace=&quot;&quot;,pod=&quot;&quot;,} 2.359296E7\njvm_memory_committed_bytes{application=&quot;saos-pdi-api&quot;,area=&quot;heap&quot;,env=&quot;test&quot;,id=&quot;PS Old Gen&quot;,namespace=&quot;&quot;,pod=&quot;&quot;,} 1.86646528E8\n# HELP tomcat_servlet_request_seconds\n# TYPE tomcat_servlet_request_seconds summary\ntomcat_servlet_request_seconds_count{application=&quot;saos-pdi-api&quot;,env=&quot;test&quot;,name=&quot;dispatcherServlet&quot;,namespace=&quot;&quot;,pod=&quot;&quot;,} 1.0\ntomcat_servlet_request_seconds_sum{application=&quot;saos-pdi-api&quot;,env=&quot;test&quot;,name=&quot;dispatcherServlet&quot;,namespace=&quot;&quot;,pod=&quot;&quot;,} 0.0\n# HELP health\n# TYPE health gauge\nhealth{application=&quot;saos-pdi-api&quot;,env=&quot;test&quot;,namespace=&quot;&quot;,pod=&quot;&quot;,} 3.0\n# HELP jvm_buffer_memory_used_bytes An estimate of the memory that the Java virtual machine is using for this buffer pool\n# TYPE jvm_buffer_memory_used_bytes gauge\njvm_buffer_memory_used_bytes{application=&quot;saos-pdi-api&quot;,env=&quot;test&quot;,id=&quot;direct&quot;,namespace=&quot;&quot;,pod=&quot;&quot;,} 91015.0\njvm_buffer_memory_used_bytes{application=&quot;saos-pdi-api&quot;,env=&quot;test&quot;,id=&quot;mapped&quot;,namespace=&quot;&quot;,pod=&quot;&quot;,} 0.0\n# HELP tomcat_threads_current\n# TYPE tomcat_threads_current gauge\ntomcat_threads_current{application=&quot;saos-pdi-api&quot;,env=&quot;test&quot;,name=&quot;http-nio-11187&quot;,namespace=&quot;&quot;,pod=&quot;&quot;,} 10.0\n# HELP process_start_time_seconds Start time of the process since unix epoch.\n# TYPE process_start_time_seconds gauge\nprocess_start_time_seconds{application=&quot;saos-pdi-api&quot;,env=&quot;test&quot;,namespace=&quot;&quot;,pod=&quot;&quot;,} 1.625215112786E9\n# HELP tomcat_threads_config_max\n# TYPE tomcat_threads_config_max gauge\ntomcat_threads_config_max{application=&quot;saos-pdi-api&quot;,env=&quot;test&quot;,name=&quot;http-nio-11187&quot;,namespace=&quot;&quot;,pod=&quot;&quot;,} 200.0\n# HELP jvm_gc_memory_promoted_bytes_total Count of positive increases in the size of the old generation memory pool before GC to after GC\n# TYPE jvm_gc_memory_promoted_bytes_total counter\njvm_gc_memory_promoted_bytes_total{application=&quot;saos-pdi-api&quot;,env=&quot;test&quot;,namespace=&quot;&quot;,pod=&quot;&quot;,} 4.5149664E7\n# HELP jvm_gc_memory_allocated_bytes_total Incremented for an increase in the size of the young generation memory pool after one GC to before the next\n# TYPE jvm_gc_memory_allocated_bytes_total counter\njvm_gc_memory_allocated_bytes_total{application=&quot;saos-pdi-api&quot;,env=&quot;test&quot;,namespace=&quot;&quot;,pod=&quot;&quot;,} 3.43775952E9\n# HELP tomcat_global_sent_bytes_total\n# TYPE tomcat_global_sent_bytes_total counter\ntomcat_global_sent_bytes_total{application=&quot;saos-pdi-api&quot;,env=&quot;test&quot;,name=&quot;http-nio-11187&quot;,namespace=&quot;&quot;,pod=&quot;&quot;,} 0.0\n# HELP jvm_classes_unloaded_total The total number of classes unloaded since the Java virtual machine has started execution</code></pre>\n<p>可以看到，Prometheus这个接口的响应报文，并不是一个单纯的json格式，而是text里有json格式的东西。</p>\n<p>当时就怀疑是Fastjson是不是有点啥问题[doge]……</p>\n<p>果不其然，让我在github上找到一个<a href=\"https://github.com/alibaba/fastjson/issues/1373\" target=\"_blank\" rel=\"noopener\">issues</a></p>\n<p>之前老版本的fastjson是有一个DisableCheckSpecialChar的SerializerFeature的，可以禁止特殊字符的转译，现在标了过期，直接不能用了，默认就给转译。。</p>\n<p>使用老版本的fastjson，并加上SerializerFeature.DisableCheckSpecialChar后，是可以的。</p>\n<p>但是我们都知道fastjson动不动就爆出漏洞，最新的版本都有点怕，更别说那么老的版本了。</p>\n<p>只能再想办法。</p>\n<p>我们从头开始想：</p>\n<p>http响应的报文，是怎么转换的呢？–&gt; HttpMessageConverter</p>\n<p>所以这块还得研究透spring的HttpMessageConverter是怎么工作的！</p>\n<p>我们都知道请求和响应都是要经过DispatcherServlet类的doDispatch方法。然后获取HandlerAdapter，然后获取对应的Handler，并调用handle方法，中间有对应的请求内容的消息转换器进行请求报文的转换，返回的时候，也会用消息解析器进行报文的转换，最后写入到http的outputStream，完成一次请求的响应。</p>\n<p>看我上面增加的自定义的FastJsonHttpMessageConverter，可以看到，我将自定义的HttpMessageConverter放到了第一位，当时考虑是spring有一些默认的消息转换器，对应的json的转换器使用jackson实现的。spring在选择消息转换器的时候，是遍历所有的转换器，找到第一个合适的就使用。所以我必须放到jackson前面，但是放到第一位，也就在string的转换器之前了，暴露给Prometheus的接口是text/plain的，讲道理fastjson不应该处理它，应该留给StringHttpMessageConterver来转换才对啊。</p>\n<p>下面的代码是spring默认的消息处理器：</p>\n<pre><code class=\"java\">protected final void addDefaultHttpMessageConverters(List&lt;HttpMessageConverter&lt;?&gt;&gt; messageConverters) {\n        StringHttpMessageConverter stringHttpMessageConverter = new StringHttpMessageConverter();\n        stringHttpMessageConverter.setWriteAcceptCharset(false);  // see SPR-7316\n\n        messageConverters.add(new ByteArrayHttpMessageConverter());\n        messageConverters.add(stringHttpMessageConverter);\n        messageConverters.add(new ResourceHttpMessageConverter());\n        messageConverters.add(new ResourceRegionHttpMessageConverter());\n        messageConverters.add(new SourceHttpMessageConverter&lt;&gt;());\n        messageConverters.add(new AllEncompassingFormHttpMessageConverter());\n\n        if (romePresent) {\n            messageConverters.add(new AtomFeedHttpMessageConverter());\n            messageConverters.add(new RssChannelHttpMessageConverter());\n        }\n\n        if (jackson2XmlPresent) {\n            Jackson2ObjectMapperBuilder builder = Jackson2ObjectMapperBuilder.xml();\n            if (this.applicationContext != null) {\n                builder.applicationContext(this.applicationContext);\n            }\n            messageConverters.add(new MappingJackson2XmlHttpMessageConverter(builder.build()));\n        }\n        else if (jaxb2Present) {\n            messageConverters.add(new Jaxb2RootElementHttpMessageConverter());\n        }\n\n        if (jackson2Present) {\n            Jackson2ObjectMapperBuilder builder = Jackson2ObjectMapperBuilder.json();\n            if (this.applicationContext != null) {\n                builder.applicationContext(this.applicationContext);\n            }\n            messageConverters.add(new MappingJackson2HttpMessageConverter(builder.build()));\n        }\n        else if (gsonPresent) {\n            messageConverters.add(new GsonHttpMessageConverter());\n        }\n        else if (jsonbPresent) {\n            messageConverters.add(new JsonbHttpMessageConverter());\n        }\n\n        if (jackson2SmilePresent) {\n            Jackson2ObjectMapperBuilder builder = Jackson2ObjectMapperBuilder.smile();\n            if (this.applicationContext != null) {\n                builder.applicationContext(this.applicationContext);\n            }\n            messageConverters.add(new MappingJackson2SmileHttpMessageConverter(builder.build()));\n        }\n        if (jackson2CborPresent) {\n            Jackson2ObjectMapperBuilder builder = Jackson2ObjectMapperBuilder.cbor();\n            if (this.applicationContext != null) {\n                builder.applicationContext(this.applicationContext);\n            }\n            messageConverters.add(new MappingJackson2CborHttpMessageConverter(builder.build()));\n        }\n    }</code></pre>\n<p>可以看到第一位是byte，第二位是String。。。。</p>\n<p>试着调整我们自定义消息处理器的位置到后面：</p>\n<pre><code class=\"java\">    public void configureMessageConverters(List&lt;HttpMessageConverter&lt;?&gt;&gt; converters) {\n        //针对字段的处理\n        FastJsonHttpMessageConverter converter = new FastJsonHttpMessageConverter();\n        FastJsonConfig fastJsonConfig = new FastJsonConfig();\n        fastJsonConfig.setSerializerFeatures(SerializerFeature.WriteNullListAsEmpty,// List字段如果为null,输出为[],而非null\n                SerializerFeature.WriteMapNullValue,//加上后，字段为null的也会输出\n                SerializerFeature.WriteNullStringAsEmpty,//字符类型字段如果为null,输出为”“,而非null\n                SerializerFeature.WriteNullBooleanAsFalse,//Boolean字段如果为null,输出为false,而非null\n                //SerializerFeature.WriteNullNumberAsZero, // Number 包装类如果为null，输出为0\n                SerializerFeature.DisableCircularReferenceDetect,\n                SerializerFeature.PrettyFormat  //结果是否格式化,默认为false\n        );\n        //日期格式化\n        fastJsonConfig.setDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;);\n        converter.setFastJsonConfig(fastJsonConfig);\n        converters.add(3,converter);//返回是string的话，默认把这个放在最前，否则ResponseAdvisor 处理字符串返回时会报类型不一致的问题\n    }</code></pre>\n<p>这里调整到第四位，可以满足要求。最后也是这样上线解决问题的。</p>\n<p>现在还有一个问题，为什么FastJsonHttpMessageConverter要处理text/plain的请求呢？</p>\n<p>AbstractMessageConverterMethodProcessor#writeWithMessageConverters中会选择消息转换器，能不能使用是通过消息转换器的canWrite方法来判断的，返回true就会使用这个消息转换器。</p>\n<pre><code class=\"java\">for (HttpMessageConverter&lt;?&gt; converter : this.messageConverters) {\n                GenericHttpMessageConverter genericConverter = (converter instanceof GenericHttpMessageConverter ?\n                        (GenericHttpMessageConverter&lt;?&gt;) converter : null);\n                if (genericConverter != null ?\n                        ((GenericHttpMessageConverter) converter).canWrite(declaredType, valueType, selectedMediaType) :\n                        converter.canWrite(valueType, selectedMediaType)) {\n                    outputValue = getAdvice().beforeBodyWrite(outputValue, returnType, selectedMediaType,\n                            (Class&lt;? extends HttpMessageConverter&lt;?&gt;&gt;) converter.getClass(),\n                            inputMessage, outputMessage);\n                    if (outputValue != null) {\n                        addContentDispositionHeader(inputMessage, outputMessage);\n                        if (genericConverter != null) {\n                            genericConverter.write(outputValue, declaredType, selectedMediaType, outputMessage);\n                        }\n                        else {\n                            ((HttpMessageConverter) converter).write(outputValue, selectedMediaType, outputMessage);\n                        }\n                        if (logger.isDebugEnabled()) {\n                            logger.debug(&quot;Written [&quot; + outputValue + &quot;] as \\&quot;&quot; + selectedMediaType +\n                                    &quot;\\&quot; using [&quot; + converter + &quot;]&quot;);\n                        }\n                    }\n                    return;\n                }\n            }</code></pre>\n<p>FastJsonHttpMessageConverter的canWrite调用了父类（AbstractHttpMessageConterver）的canWrite方法，这个方法的入参是Class&lt;?&gt; clazz(java.lang.String)和MediaType mediaType(text/plain;version=0.0.4;charset=utf-8)</p>\n<p>AbstractHttpMessageConterver的canWrite长这样：</p>\n<pre><code class=\"java\">    public boolean canWrite(Class&lt;?&gt; clazz, @Nullable MediaType mediaType) {\n        return this.supports(clazz) &amp;&amp; this.canWrite(mediaType);\n    }</code></pre>\n<p>supports方法直接就是写死的返回true，而canWrite走到最后text/*都会直接返回true，所以就这么愉快的通过了。。。</p>\n<p>而人家jackson就实在很多，人家在JacksonHttpMessageConverterConfiguration中创建MappingJackson2HttpMessageConverter的时候，调用AbstractJackson2HttpMessageConverter中的构造器，传入的supportedMediaTypes只有两个关于json的！</p>\n<pre><code class=\"json\">    /**\n     * Construct a new {@link MappingJackson2HttpMessageConverter} with a custom {@link ObjectMapper}.\n     * You can use {@link Jackson2ObjectMapperBuilder} to build it easily.\n     * @see Jackson2ObjectMapperBuilder#json()\n     */\n    public MappingJackson2HttpMessageConverter(ObjectMapper objectMapper) {\n        super(objectMapper, MediaType.APPLICATION_JSON, new MediaType(&quot;application&quot;, &quot;*+json&quot;));\n    }</code></pre>\n<p>这块确实是挺坑的。。你说fastjson，你好好管你的json就完事了，你搞什么string啊。。</p>\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3><p>Spring根据请求的MediaType选择对应的消息转换器，而我们这里使用的FastJsonHttpMessageConverter，并没有像jackson一样规定supportedMediaTypes，而是AbstractHttpMessageConverter中默认的<em>/</em>，导致将text/plain的报文也给转换了，才导致了这次遇到的问题。</p>\n"},{"title":"泛型","excerpt":"","comments":1,"date":"2021-07-13T05:30:10.000Z","_content":"\n\n\n### 什么是泛型\n\n泛型就是参数化类型：\n\n- 适用于多种数据类型执行相同的代码\n- 泛型中的类型在使用时指定\n- 泛型归根到底就是“模版”\n\n### Java的泛型是假的？\n\nJava的泛型时伪泛型，这是因为Java在编译期间，所有的泛型信息都会被擦掉。Java的泛型基本上都是在编译器这个层次上实现的，在生成的字节码中是不包含泛型中的类型信息的，使用泛型的时候加上类型参数，在编译器编译的时候会去掉，这个过程叫做类型擦除。例如List<Object>和List<String>等类型，在编译后都会变成List\n\n### 为什么要使用泛型\n\n通过泛型**可以定义类型安全的数据结构（类型安全）**，而**无须使用实际的数据类型（可扩展）**。这**能够显著提高性能并得到更高质量的代码（高性能）**，因为您**可以重用数据处理算法，而无须复制类型特定的代码（可重用）**。在概念上，泛型类似于 C++ 模板，但是在实现和功能方面存在明显差异。\n\n1. 编译期类型检查\n2. 强制类型转换\n3. 可读性和灵活性\n\n使用Object实现泛型的存在的问题：\n\n**性能问题：**在使用值类型时，必须boxing & unboxing。装箱和取消装箱都会根据它们自己的权限造成重大的性能损失，但是它还会增加托管堆上的压力，导致更多的垃圾收集工作，而这对于性能而言也不太好。即使是在使用引用类型而不是值类型时，仍然存在性能损失，这是因为必须从 Object 向您要与之交互的实际类型进行强制类型转换，从而造成强制类型转换开销。\n\n　　基于 Object 的解决方案的**第二个问题（通常更为严重）是****类型安全**。因为编译器允许在任何类型和 Object 之间进行强制类型转换，所以您将丢失编译时类型安全。例如，以下代码可以正确编译，但是在运行时将引发无效强制类型转换异常\n\n　　您可以通过提供类型特定的（因而是类型安全的）高性能堆栈来克服上述两个问题。对于整型，可以实现并使用 **IntStack。对于字符串，可以实现 \\**StringStack。\\**\n**\n\n　　***\\*遗憾的是，以这种方式解决性能和类型安全问题，会引起第三个同样严重的问题 — 影响工作效率（无法重用）。编写类型特定的数据结构是一项乏味的、重复性的且易于出错的任务。在修复该数据结构中的缺陷时，您不能只在一个位置修复该缺陷，而必须在实质上是同一数据结构的类型特定的副本所出现的每个位置进行修复。此外，没有办法预知未知的或尚未定义的将来类型的使用情况，因此还必须保持基于 Object 的数据结构。\\****\n\n### 限定通配符和非限定通配符\n\n- 限定通配符：\n  1. `<? extneds T>`，即类型必须为T类型或T的子类\n  2. `<? super T>`，即类型必须为T类型或T的父类\n- 非限定通配符：\n  1. `<T>`，可以用任意类型来替代\n\n### 泛型和Object的区别\n\n使用泛型或者Object作为形参，都可以让方法接受更多类型的对象，让程序变得健壮，代码复用性更高。但是使用Object作为形参，需要进行各种强制类型转换，编译器不会检查类型转换是被否安全，运行时才会暴露出问题。而使用泛型的话，即保证了代码的健壮性，而且还避免了强转的风险。\n\n### 类型擦除引起的问题及解决方法\n\n因为种种原因，Java不能实现真正的泛型，只能使用类型擦除来实现伪泛型，这样虽然不会有类型膨胀问题，但是也引起来许多新问题，所以，SUN对这些问题做出了种种限制，避免我们发生各种错误。\n\n#### 1、先检查再编译以及编译的对象和引用传递问题\n\n**Q**: 既然说类型变量会在编译的时候擦除掉，那为什么我们往 ArrayList 创建的对象中添加整数会报错呢？不是说泛型变量String会在编译的时候变为Object类型吗？为什么不能存别的类型呢？既然类型擦除了，如何保证我们只能使用泛型变量限定的类型呢？\n\n**A**: Java编译器是通过先检查代码中泛型的类型，然后在进行类型擦除，再进行编译。\n\n例如：\n\n```java\npublic static  void main(String[] args) {  \n    ArrayList<String> list = new ArrayList<String>();  \n    list.add(\"123\");  \n    list.add(123);//编译错误  \n}\n```\n\n在上面的程序中，使用`add`方法添加一个整型，在IDE中，直接会报错，说明这就是在编译之前的检查，因为如果是在编译之后检查，类型擦除后，原始类型为`Object`，是应该允许任意引用类型添加的。可实际上却不是这样的，这恰恰说明了关于泛型变量的使用，是会在编译之前检查的。\n\n那么，这个类型检查是针对谁的呢？我们先看看参数化类型和原始类型的兼容。\n\n以 ArrayList举例子，以前的写法:\n\n```java\nArrayList list = new ArrayList();  \n```\n\n现在的写法:\n\n```java\nArrayList<String> list = new ArrayList<String>();\n```\n\n如果是与以前的代码兼容，各种引用传值之间，必然会出现如下的情况：\n\n```java\nArrayList<String> list1 = new ArrayList(); //第一种 情况\nArrayList list2 = new ArrayList<String>(); //第二种 情况\n```\n\n这样是没有错误的，不过会有个编译时警告。\n\n不过在第一种情况，可以实现与完全使用泛型参数一样的效果，第二种则没有效果。\n\n因为类型检查就是编译时完成的，`new ArrayList()`只是在内存中开辟了一个存储空间，可以存储任何类型对象，而**真正设计类型检查的是它的引用**，因为我们是使用它引用`list1`来调用它的方法，比如说调用`add`方法，所以`list1`引用能完成泛型类型的检查。而引用`list2`没有使用泛型，所以不行。\n\n举例子：\n\n```java\npublic class Test {  \n\n    public static void main(String[] args) {  \n\n        ArrayList<String> list1 = new ArrayList();  \n        list1.add(\"1\"); //编译通过  \n        list1.add(1); //编译错误  \n        String str1 = list1.get(0); //返回类型就是String  \n\n        ArrayList list2 = new ArrayList<String>();  \n        list2.add(\"1\"); //编译通过  \n        list2.add(1); //编译通过  \n        Object object = list2.get(0); //返回类型就是Object  \n\n        new ArrayList<String>().add(\"11\"); //编译通过  \n        new ArrayList<String>().add(22); //编译错误  \n\n        String str2 = new ArrayList<String>().get(0); //返回类型就是String  \n    }  \n\n}  \n```\n\n通过上面的例子，我们可以明白，**类型检查就是针对引用的**，谁是一个引用，用这个引用调用泛型方法，就会对这个引用调用的方法进行类型检测，而无关它真正引用的对象。\n\n泛型中参数话类型为什么不考虑继承关系？\n\n在Java中，像下面形式的引用传递是不允许的:\n\n```java\nArrayList<String> list1 = new ArrayList<Object>(); //编译错误  \nArrayList<Object> list2 = new ArrayList<String>(); //编译错误\n```\n\n我们先看第一种情况，将第一种情况拓展成下面的形式：\n\n```java\nArrayList<Object> list1 = new ArrayList<Object>();  \nlist1.add(new Object());  \nlist1.add(new Object());  \nArrayList<String> list2 = list1; //编译错误\n```\n\n实际上，在第4行代码的时候，就会有编译错误。那么，我们先假设它编译没错。那么当我们使用`list2`引用用`get()`方法取值的时候，返回的都是`String`类型的对象（上面提到了，类型检测是根据引用来决定的），可是它里面实际上已经被我们存放了`Object`类型的对象，这样就会有`ClassCastException`了。所以为了避免这种极易出现的错误，Java不允许进行这样的引用传递。（这也是泛型出现的原因，就是为了解决类型转换的问题，我们不能违背它的初衷）。\n\n再看第二种情况，将第二种情况拓展成下面的形式：\n\n```java\nArrayList<String> list1 = new ArrayList<String>();  \nlist1.add(new String());  \nlist1.add(new String());\n\nArrayList<Object> list2 = list1; //编译错误\n```\n\n没错，这样的情况比第一种情况好的多，最起码，在我们用`list2`取值的时候不会出现`ClassCastException`，因为是从`String`转换为`Object`。可是，这样做有什么意义呢，泛型出现的原因，就是为了解决类型转换的问题。我们使用了泛型，到头来，还是要自己强转，违背了泛型设计的初衷。所以java不允许这么干。再说，你如果又用`list2`往里面`add()`新的对象，那么到时候取得时候，我怎么知道我取出来的到底是`String`类型的，还是`Object`类型的呢？\n\n**所以，要格外注意，泛型中的引用传递的问题。**\n\n#### 2、自动类型转换\n\n因为类型擦除的问题，所以所有的泛型类型变量最后都会被替换为原始类型。\n\n既然都被替换为原始类型，那么为什么我们在获取的时候，不需要进行强制类型转换呢？\n\n看下`ArrayList.get()`方法：\n\n```java\npublic E get(int index) {  \n\n    RangeCheck(index);  \n\n    return (E) elementData[index];  \n\n}\n```\n\n可以看到，在`return`之前，会根据泛型变量进行强转。假设泛型类型变量为`Date`，虽然泛型信息会被擦除掉，但是会将`(E) elementData[index]`，编译为`(Date) elementData[index]`。所以我们不用自己进行强转。当存取一个泛型域时也会自动插入强制类型转换。假设`Pair`类的`value`域是`public`的，那么表达式：\n\n```java\nDate date = pair.value;\n```\n\n也会自动地在结果字节码中插入强制类型转换。\n\n#### 3、类型擦除与多态的冲突和解决方法\n\n现在有这样一个泛型类：\n\n```java\nclass Pair<T> {  \n\n    private T value;  \n\n    public T getValue() {  \n        return value;  \n    }  \n\n    public void setValue(T value) {  \n        this.value = value;  \n    }  \n}\n```\n\n然后我们想要一个子类继承它。\n\n```java\nclass DateInter extends Pair<Date> {  \n\n    @Override\n    public void setValue(Date value) {  \n        super.setValue(value);  \n    }  \n\n    @Override\n    public Date getValue() {  \n        return super.getValue();  \n    }  \n}\n```\n\n在这个子类中，我们设定父类的泛型类型为`Pair<Date>`，在子类中，我们覆盖了父类的两个方法，我们的原意是这样的：将父类的泛型类型限定为`Date`，那么父类里面的两个方法的参数都为`Date`类型。\n\n```java\npublic Date getValue() {  \n    return value;  \n}  \n\npublic void setValue(Date value) {  \n    this.value = value;  \n}\n```\n\n所以，我们在子类中重写这两个方法一点问题也没有，实际上，从他们的`@Override`标签中也可以看到，一点问题也没有，实际上是这样的吗？\n\n分析：实际上，类型擦除后，父类的的泛型类型全部变为了原始类型`Object`，所以父类编译之后会变成下面的样子：\n\n```java\nclass Pair {  \n    private Object value;  \n\n    public Object getValue() {  \n        return value;  \n    }  \n\n    public void setValue(Object  value) {  \n        this.value = value;  \n    }  \n}  \n```\n\n再看子类的两个重写的方法的类型：\n\n```java\n@Override  \npublic void setValue(Date value) {  \n    super.setValue(value);  \n}  \n@Override  \npublic Date getValue() {  \n    return super.getValue();  \n}\n```\n\n先来分析`setValue`方法，父类的类型是`Object`，而子类的类型是`Date`，参数类型不一样，这如果实在普通的继承关系中，根本就不会是重写，而是重载。\n\n我们在一个main方法测试一下：\n\n```java\npublic static void main(String[] args) throws ClassNotFoundException {  \n        DateInter dateInter = new DateInter();  \n        dateInter.setValue(new Date());                  \n        dateInter.setValue(new Object()); //编译错误  \n}\n```\n\n如果是重载，那么子类中两个`setValue`方法，一个是参数`Object`类型，一个是`Date`类型，可是我们发现，根本就没有这样的一个子类继承自父类的Object类型参数的方法。所以说，却是是重写了，而不是重载了。\n\n为什么会这样呢？\n\n原因是这样的，我们传入父类的泛型类型是`Date，Pair<Date>`，我们的本意是将泛型类变为如下：\n\n```java\nclass Pair {  \n    private Date value;  \n    public Date getValue() {  \n        return value;  \n    }  \n    public void setValue(Date value) {  \n        this.value = value;  \n    }  \n}\n```\n\n然后再子类中重写参数类型为Date的那两个方法，实现继承中的多态。\n\n可是由于种种原因，虚拟机并不能将泛型类型变为`Date`，只能将类型擦除掉，变为原始类型`Object`。这样，我们的本意是进行重写，实现多态。可是类型擦除后，只能变为了重载。这样，类型擦除就和多态有了冲突。JVM知道你的本意吗？知道！！！可是它能直接实现吗，不能！！！如果真的不能的话，那我们怎么去重写我们想要的`Date`类型参数的方法啊。\n\n于是JVM采用了一个特殊的方法，来完成这项功能，那就是**桥方法**。\n\n首先，我们用`javap -c className`的方式反编译下`DateInter`子类的字节码，结果如下：\n\n```class\nclass com.tao.test.DateInter extends com.tao.test.Pair<java.util.Date> {  \n  com.tao.test.DateInter();  \n    Code:  \n       0: aload_0  \n       1: invokespecial #8                  // Method com/tao/test/Pair.\"<init>\":()V  \n       4: return  \n\n  public void setValue(java.util.Date);  //我们重写的setValue方法  \n    Code:  \n       0: aload_0  \n       1: aload_1  \n       2: invokespecial #16                 // Method com/tao/test/Pair.setValue:(Ljava/lang/Object;)V  \n       5: return  \n\n  public java.util.Date getValue();    //我们重写的getValue方法  \n    Code:  \n       0: aload_0  \n       1: invokespecial #23                 // Method com/tao/test/Pair.getValue:()Ljava/lang/Object;  \n       4: checkcast     #26                 // class java/util/Date  \n       7: areturn  \n\n  public java.lang.Object getValue();     //编译时由编译器生成的桥方法  \n    Code:  \n       0: aload_0  \n       1: invokevirtual #28                 // Method getValue:()Ljava/util/Date 去调用我们重写的getValue方法;  \n       4: areturn  \n\n  public void setValue(java.lang.Object);   //编译时由编译器生成的桥方法  \n    Code:  \n       0: aload_0  \n       1: aload_1  \n       2: checkcast     #26                 // class java/util/Date  \n       5: invokevirtual #30                 // Method setValue:(Ljava/util/Date; 去调用我们重写的setValue方法)V  \n       8: return  \n}\n```\n\n从编译的结果来看，我们本意重写`setValue`和`getValue`方法的子类，竟然有4个方法，其实不用惊奇，最后的两个方法，就是编译器自己生成的桥方法。可以看到桥方法的参数类型都是Object，也就是说，子类中真正覆盖父类两个方法的就是这两个我们看不到的桥方法。而在我们自己定义的`setvalue`和`getValue`方法上面的`@Oveerride`只不过是假象。而桥方法的内部实现，就只是去调用我们自己重写的那两个方法。\n\n所以，**虚拟机巧妙的使用了桥方法，来解决了类型擦除和多态的冲突**。\n\n不过，要提到一点，这里面的`setValue`和`getValue`这两个桥方法的意义又有不同。\n\n`setValue`方法是为了解决类型擦除与多态之间的冲突。\n\n而`getValue`却有普遍的意义，怎么说呢，如果这是一个普通的继承关系：\n\n那么父类的`getValue`方法如下：\n\n```java\npublic Object getValue() {  \n    return value;  \n}\n```\n\n而子类重写的方法是：\n\n```java\npublic Date getValue() {  \n    return super.getValue();  \n}\n```\n\n其实这在普通的类继承中也是普遍存在的重写，这就是协变。\n\n关于协变：。。。。。。\n\n并且，还有一点也许会有疑问，子类中的桥方法`Object getValue()`和`Date getValue()`是同时存在的，可是如果是常规的两个方法，他们的方法签名是一样的，也就是说虚拟机根本不能分别这两个方法。如果是我们自己编写Java代码，这样的代码是无法通过编译器的检查的，但是虚拟机却是允许这样做的，因为虚拟机通过参数类型和返回类型来确定一个方法，所以编译器为了实现泛型的多态允许自己做这个看起来“不合法”的事情，然后交给虚拟器去区别。\n\n#### 4、泛型类型变量不能是基本数据类型\n\n不能用类型参数替换基本类型。就比如，没有`ArrayList<double>`，只有`ArrayList<Double>`。因为当类型擦除后，`ArrayList`的原始类型变为`Object`，但是`Object`类型不能存储`double`值，只能引用`Double`的值。\n\n#### 5、编译时集合的instanceof\n\n```java\nArrayList<String> arrayList = new ArrayList<String>();\n```\n\n因为类型擦除之后，`ArrayList<String>`只剩下原始类型，泛型信息`String`不存在了。\n\n那么，编译时进行类型查询的时候使用下面的方法是错误的\n\n```java\nif( arrayList instanceof ArrayList<String>)\n```\n\n#### 6、泛型在静态方法和静态类中的问题\n\n泛型类中的静态方法和静态变量不可以使用泛型类所声明的泛型类型参数\n\n举例说明：\n\n```java\npublic class Test2<T> {    \n    public static T one;   //编译错误    \n    public static  T show(T one){ //编译错误    \n        return null;    \n    }    \n}\n```\n\n因为泛型类中的泛型参数的实例化是在定义对象的时候指定的，而静态变量和静态方法不需要使用对象来调用。对象都没有创建，如何确定这个泛型参数是何种类型，所以当然是错误的。\n\n但是要注意区分下面的一种情况：\n\n```java\npublic class Test2<T> {    \n\n    public static <T >T show(T one){ //这是正确的    \n        return null;    \n    }    \n}\n```\n\n因为这是一个泛型方法，在泛型方法中使用的T是自己在方法中定义的 T，而不是泛型类中的T。\n","source":"_posts/2021-07-13-kongzheng1993-泛型.md","raw":"---\ntitle: 泛型\nexcerpt: 'Java'\ntags: [Java]\ncategories: [Java]\ncomments: true\ndate: 2021-07-13 13:30:10\n---\n\n\n\n### 什么是泛型\n\n泛型就是参数化类型：\n\n- 适用于多种数据类型执行相同的代码\n- 泛型中的类型在使用时指定\n- 泛型归根到底就是“模版”\n\n### Java的泛型是假的？\n\nJava的泛型时伪泛型，这是因为Java在编译期间，所有的泛型信息都会被擦掉。Java的泛型基本上都是在编译器这个层次上实现的，在生成的字节码中是不包含泛型中的类型信息的，使用泛型的时候加上类型参数，在编译器编译的时候会去掉，这个过程叫做类型擦除。例如List<Object>和List<String>等类型，在编译后都会变成List\n\n### 为什么要使用泛型\n\n通过泛型**可以定义类型安全的数据结构（类型安全）**，而**无须使用实际的数据类型（可扩展）**。这**能够显著提高性能并得到更高质量的代码（高性能）**，因为您**可以重用数据处理算法，而无须复制类型特定的代码（可重用）**。在概念上，泛型类似于 C++ 模板，但是在实现和功能方面存在明显差异。\n\n1. 编译期类型检查\n2. 强制类型转换\n3. 可读性和灵活性\n\n使用Object实现泛型的存在的问题：\n\n**性能问题：**在使用值类型时，必须boxing & unboxing。装箱和取消装箱都会根据它们自己的权限造成重大的性能损失，但是它还会增加托管堆上的压力，导致更多的垃圾收集工作，而这对于性能而言也不太好。即使是在使用引用类型而不是值类型时，仍然存在性能损失，这是因为必须从 Object 向您要与之交互的实际类型进行强制类型转换，从而造成强制类型转换开销。\n\n　　基于 Object 的解决方案的**第二个问题（通常更为严重）是****类型安全**。因为编译器允许在任何类型和 Object 之间进行强制类型转换，所以您将丢失编译时类型安全。例如，以下代码可以正确编译，但是在运行时将引发无效强制类型转换异常\n\n　　您可以通过提供类型特定的（因而是类型安全的）高性能堆栈来克服上述两个问题。对于整型，可以实现并使用 **IntStack。对于字符串，可以实现 \\**StringStack。\\**\n**\n\n　　***\\*遗憾的是，以这种方式解决性能和类型安全问题，会引起第三个同样严重的问题 — 影响工作效率（无法重用）。编写类型特定的数据结构是一项乏味的、重复性的且易于出错的任务。在修复该数据结构中的缺陷时，您不能只在一个位置修复该缺陷，而必须在实质上是同一数据结构的类型特定的副本所出现的每个位置进行修复。此外，没有办法预知未知的或尚未定义的将来类型的使用情况，因此还必须保持基于 Object 的数据结构。\\****\n\n### 限定通配符和非限定通配符\n\n- 限定通配符：\n  1. `<? extneds T>`，即类型必须为T类型或T的子类\n  2. `<? super T>`，即类型必须为T类型或T的父类\n- 非限定通配符：\n  1. `<T>`，可以用任意类型来替代\n\n### 泛型和Object的区别\n\n使用泛型或者Object作为形参，都可以让方法接受更多类型的对象，让程序变得健壮，代码复用性更高。但是使用Object作为形参，需要进行各种强制类型转换，编译器不会检查类型转换是被否安全，运行时才会暴露出问题。而使用泛型的话，即保证了代码的健壮性，而且还避免了强转的风险。\n\n### 类型擦除引起的问题及解决方法\n\n因为种种原因，Java不能实现真正的泛型，只能使用类型擦除来实现伪泛型，这样虽然不会有类型膨胀问题，但是也引起来许多新问题，所以，SUN对这些问题做出了种种限制，避免我们发生各种错误。\n\n#### 1、先检查再编译以及编译的对象和引用传递问题\n\n**Q**: 既然说类型变量会在编译的时候擦除掉，那为什么我们往 ArrayList 创建的对象中添加整数会报错呢？不是说泛型变量String会在编译的时候变为Object类型吗？为什么不能存别的类型呢？既然类型擦除了，如何保证我们只能使用泛型变量限定的类型呢？\n\n**A**: Java编译器是通过先检查代码中泛型的类型，然后在进行类型擦除，再进行编译。\n\n例如：\n\n```java\npublic static  void main(String[] args) {  \n    ArrayList<String> list = new ArrayList<String>();  \n    list.add(\"123\");  \n    list.add(123);//编译错误  \n}\n```\n\n在上面的程序中，使用`add`方法添加一个整型，在IDE中，直接会报错，说明这就是在编译之前的检查，因为如果是在编译之后检查，类型擦除后，原始类型为`Object`，是应该允许任意引用类型添加的。可实际上却不是这样的，这恰恰说明了关于泛型变量的使用，是会在编译之前检查的。\n\n那么，这个类型检查是针对谁的呢？我们先看看参数化类型和原始类型的兼容。\n\n以 ArrayList举例子，以前的写法:\n\n```java\nArrayList list = new ArrayList();  \n```\n\n现在的写法:\n\n```java\nArrayList<String> list = new ArrayList<String>();\n```\n\n如果是与以前的代码兼容，各种引用传值之间，必然会出现如下的情况：\n\n```java\nArrayList<String> list1 = new ArrayList(); //第一种 情况\nArrayList list2 = new ArrayList<String>(); //第二种 情况\n```\n\n这样是没有错误的，不过会有个编译时警告。\n\n不过在第一种情况，可以实现与完全使用泛型参数一样的效果，第二种则没有效果。\n\n因为类型检查就是编译时完成的，`new ArrayList()`只是在内存中开辟了一个存储空间，可以存储任何类型对象，而**真正设计类型检查的是它的引用**，因为我们是使用它引用`list1`来调用它的方法，比如说调用`add`方法，所以`list1`引用能完成泛型类型的检查。而引用`list2`没有使用泛型，所以不行。\n\n举例子：\n\n```java\npublic class Test {  \n\n    public static void main(String[] args) {  \n\n        ArrayList<String> list1 = new ArrayList();  \n        list1.add(\"1\"); //编译通过  \n        list1.add(1); //编译错误  \n        String str1 = list1.get(0); //返回类型就是String  \n\n        ArrayList list2 = new ArrayList<String>();  \n        list2.add(\"1\"); //编译通过  \n        list2.add(1); //编译通过  \n        Object object = list2.get(0); //返回类型就是Object  \n\n        new ArrayList<String>().add(\"11\"); //编译通过  \n        new ArrayList<String>().add(22); //编译错误  \n\n        String str2 = new ArrayList<String>().get(0); //返回类型就是String  \n    }  \n\n}  \n```\n\n通过上面的例子，我们可以明白，**类型检查就是针对引用的**，谁是一个引用，用这个引用调用泛型方法，就会对这个引用调用的方法进行类型检测，而无关它真正引用的对象。\n\n泛型中参数话类型为什么不考虑继承关系？\n\n在Java中，像下面形式的引用传递是不允许的:\n\n```java\nArrayList<String> list1 = new ArrayList<Object>(); //编译错误  \nArrayList<Object> list2 = new ArrayList<String>(); //编译错误\n```\n\n我们先看第一种情况，将第一种情况拓展成下面的形式：\n\n```java\nArrayList<Object> list1 = new ArrayList<Object>();  \nlist1.add(new Object());  \nlist1.add(new Object());  \nArrayList<String> list2 = list1; //编译错误\n```\n\n实际上，在第4行代码的时候，就会有编译错误。那么，我们先假设它编译没错。那么当我们使用`list2`引用用`get()`方法取值的时候，返回的都是`String`类型的对象（上面提到了，类型检测是根据引用来决定的），可是它里面实际上已经被我们存放了`Object`类型的对象，这样就会有`ClassCastException`了。所以为了避免这种极易出现的错误，Java不允许进行这样的引用传递。（这也是泛型出现的原因，就是为了解决类型转换的问题，我们不能违背它的初衷）。\n\n再看第二种情况，将第二种情况拓展成下面的形式：\n\n```java\nArrayList<String> list1 = new ArrayList<String>();  \nlist1.add(new String());  \nlist1.add(new String());\n\nArrayList<Object> list2 = list1; //编译错误\n```\n\n没错，这样的情况比第一种情况好的多，最起码，在我们用`list2`取值的时候不会出现`ClassCastException`，因为是从`String`转换为`Object`。可是，这样做有什么意义呢，泛型出现的原因，就是为了解决类型转换的问题。我们使用了泛型，到头来，还是要自己强转，违背了泛型设计的初衷。所以java不允许这么干。再说，你如果又用`list2`往里面`add()`新的对象，那么到时候取得时候，我怎么知道我取出来的到底是`String`类型的，还是`Object`类型的呢？\n\n**所以，要格外注意，泛型中的引用传递的问题。**\n\n#### 2、自动类型转换\n\n因为类型擦除的问题，所以所有的泛型类型变量最后都会被替换为原始类型。\n\n既然都被替换为原始类型，那么为什么我们在获取的时候，不需要进行强制类型转换呢？\n\n看下`ArrayList.get()`方法：\n\n```java\npublic E get(int index) {  \n\n    RangeCheck(index);  \n\n    return (E) elementData[index];  \n\n}\n```\n\n可以看到，在`return`之前，会根据泛型变量进行强转。假设泛型类型变量为`Date`，虽然泛型信息会被擦除掉，但是会将`(E) elementData[index]`，编译为`(Date) elementData[index]`。所以我们不用自己进行强转。当存取一个泛型域时也会自动插入强制类型转换。假设`Pair`类的`value`域是`public`的，那么表达式：\n\n```java\nDate date = pair.value;\n```\n\n也会自动地在结果字节码中插入强制类型转换。\n\n#### 3、类型擦除与多态的冲突和解决方法\n\n现在有这样一个泛型类：\n\n```java\nclass Pair<T> {  \n\n    private T value;  \n\n    public T getValue() {  \n        return value;  \n    }  \n\n    public void setValue(T value) {  \n        this.value = value;  \n    }  \n}\n```\n\n然后我们想要一个子类继承它。\n\n```java\nclass DateInter extends Pair<Date> {  \n\n    @Override\n    public void setValue(Date value) {  \n        super.setValue(value);  \n    }  \n\n    @Override\n    public Date getValue() {  \n        return super.getValue();  \n    }  \n}\n```\n\n在这个子类中，我们设定父类的泛型类型为`Pair<Date>`，在子类中，我们覆盖了父类的两个方法，我们的原意是这样的：将父类的泛型类型限定为`Date`，那么父类里面的两个方法的参数都为`Date`类型。\n\n```java\npublic Date getValue() {  \n    return value;  \n}  \n\npublic void setValue(Date value) {  \n    this.value = value;  \n}\n```\n\n所以，我们在子类中重写这两个方法一点问题也没有，实际上，从他们的`@Override`标签中也可以看到，一点问题也没有，实际上是这样的吗？\n\n分析：实际上，类型擦除后，父类的的泛型类型全部变为了原始类型`Object`，所以父类编译之后会变成下面的样子：\n\n```java\nclass Pair {  \n    private Object value;  \n\n    public Object getValue() {  \n        return value;  \n    }  \n\n    public void setValue(Object  value) {  \n        this.value = value;  \n    }  \n}  \n```\n\n再看子类的两个重写的方法的类型：\n\n```java\n@Override  \npublic void setValue(Date value) {  \n    super.setValue(value);  \n}  \n@Override  \npublic Date getValue() {  \n    return super.getValue();  \n}\n```\n\n先来分析`setValue`方法，父类的类型是`Object`，而子类的类型是`Date`，参数类型不一样，这如果实在普通的继承关系中，根本就不会是重写，而是重载。\n\n我们在一个main方法测试一下：\n\n```java\npublic static void main(String[] args) throws ClassNotFoundException {  \n        DateInter dateInter = new DateInter();  \n        dateInter.setValue(new Date());                  \n        dateInter.setValue(new Object()); //编译错误  \n}\n```\n\n如果是重载，那么子类中两个`setValue`方法，一个是参数`Object`类型，一个是`Date`类型，可是我们发现，根本就没有这样的一个子类继承自父类的Object类型参数的方法。所以说，却是是重写了，而不是重载了。\n\n为什么会这样呢？\n\n原因是这样的，我们传入父类的泛型类型是`Date，Pair<Date>`，我们的本意是将泛型类变为如下：\n\n```java\nclass Pair {  \n    private Date value;  \n    public Date getValue() {  \n        return value;  \n    }  \n    public void setValue(Date value) {  \n        this.value = value;  \n    }  \n}\n```\n\n然后再子类中重写参数类型为Date的那两个方法，实现继承中的多态。\n\n可是由于种种原因，虚拟机并不能将泛型类型变为`Date`，只能将类型擦除掉，变为原始类型`Object`。这样，我们的本意是进行重写，实现多态。可是类型擦除后，只能变为了重载。这样，类型擦除就和多态有了冲突。JVM知道你的本意吗？知道！！！可是它能直接实现吗，不能！！！如果真的不能的话，那我们怎么去重写我们想要的`Date`类型参数的方法啊。\n\n于是JVM采用了一个特殊的方法，来完成这项功能，那就是**桥方法**。\n\n首先，我们用`javap -c className`的方式反编译下`DateInter`子类的字节码，结果如下：\n\n```class\nclass com.tao.test.DateInter extends com.tao.test.Pair<java.util.Date> {  \n  com.tao.test.DateInter();  \n    Code:  \n       0: aload_0  \n       1: invokespecial #8                  // Method com/tao/test/Pair.\"<init>\":()V  \n       4: return  \n\n  public void setValue(java.util.Date);  //我们重写的setValue方法  \n    Code:  \n       0: aload_0  \n       1: aload_1  \n       2: invokespecial #16                 // Method com/tao/test/Pair.setValue:(Ljava/lang/Object;)V  \n       5: return  \n\n  public java.util.Date getValue();    //我们重写的getValue方法  \n    Code:  \n       0: aload_0  \n       1: invokespecial #23                 // Method com/tao/test/Pair.getValue:()Ljava/lang/Object;  \n       4: checkcast     #26                 // class java/util/Date  \n       7: areturn  \n\n  public java.lang.Object getValue();     //编译时由编译器生成的桥方法  \n    Code:  \n       0: aload_0  \n       1: invokevirtual #28                 // Method getValue:()Ljava/util/Date 去调用我们重写的getValue方法;  \n       4: areturn  \n\n  public void setValue(java.lang.Object);   //编译时由编译器生成的桥方法  \n    Code:  \n       0: aload_0  \n       1: aload_1  \n       2: checkcast     #26                 // class java/util/Date  \n       5: invokevirtual #30                 // Method setValue:(Ljava/util/Date; 去调用我们重写的setValue方法)V  \n       8: return  \n}\n```\n\n从编译的结果来看，我们本意重写`setValue`和`getValue`方法的子类，竟然有4个方法，其实不用惊奇，最后的两个方法，就是编译器自己生成的桥方法。可以看到桥方法的参数类型都是Object，也就是说，子类中真正覆盖父类两个方法的就是这两个我们看不到的桥方法。而在我们自己定义的`setvalue`和`getValue`方法上面的`@Oveerride`只不过是假象。而桥方法的内部实现，就只是去调用我们自己重写的那两个方法。\n\n所以，**虚拟机巧妙的使用了桥方法，来解决了类型擦除和多态的冲突**。\n\n不过，要提到一点，这里面的`setValue`和`getValue`这两个桥方法的意义又有不同。\n\n`setValue`方法是为了解决类型擦除与多态之间的冲突。\n\n而`getValue`却有普遍的意义，怎么说呢，如果这是一个普通的继承关系：\n\n那么父类的`getValue`方法如下：\n\n```java\npublic Object getValue() {  \n    return value;  \n}\n```\n\n而子类重写的方法是：\n\n```java\npublic Date getValue() {  \n    return super.getValue();  \n}\n```\n\n其实这在普通的类继承中也是普遍存在的重写，这就是协变。\n\n关于协变：。。。。。。\n\n并且，还有一点也许会有疑问，子类中的桥方法`Object getValue()`和`Date getValue()`是同时存在的，可是如果是常规的两个方法，他们的方法签名是一样的，也就是说虚拟机根本不能分别这两个方法。如果是我们自己编写Java代码，这样的代码是无法通过编译器的检查的，但是虚拟机却是允许这样做的，因为虚拟机通过参数类型和返回类型来确定一个方法，所以编译器为了实现泛型的多态允许自己做这个看起来“不合法”的事情，然后交给虚拟器去区别。\n\n#### 4、泛型类型变量不能是基本数据类型\n\n不能用类型参数替换基本类型。就比如，没有`ArrayList<double>`，只有`ArrayList<Double>`。因为当类型擦除后，`ArrayList`的原始类型变为`Object`，但是`Object`类型不能存储`double`值，只能引用`Double`的值。\n\n#### 5、编译时集合的instanceof\n\n```java\nArrayList<String> arrayList = new ArrayList<String>();\n```\n\n因为类型擦除之后，`ArrayList<String>`只剩下原始类型，泛型信息`String`不存在了。\n\n那么，编译时进行类型查询的时候使用下面的方法是错误的\n\n```java\nif( arrayList instanceof ArrayList<String>)\n```\n\n#### 6、泛型在静态方法和静态类中的问题\n\n泛型类中的静态方法和静态变量不可以使用泛型类所声明的泛型类型参数\n\n举例说明：\n\n```java\npublic class Test2<T> {    \n    public static T one;   //编译错误    \n    public static  T show(T one){ //编译错误    \n        return null;    \n    }    \n}\n```\n\n因为泛型类中的泛型参数的实例化是在定义对象的时候指定的，而静态变量和静态方法不需要使用对象来调用。对象都没有创建，如何确定这个泛型参数是何种类型，所以当然是错误的。\n\n但是要注意区分下面的一种情况：\n\n```java\npublic class Test2<T> {    \n\n    public static <T >T show(T one){ //这是正确的    \n        return null;    \n    }    \n}\n```\n\n因为这是一个泛型方法，在泛型方法中使用的T是自己在方法中定义的 T，而不是泛型类中的T。\n","slug":"kongzheng1993-泛型","published":1,"updated":"2023-03-08T07:05:58.813Z","layout":"post","photos":[],"link":"","_id":"clg0k2arv00j6t26fsovu8omk","content":"<h3 id=\"什么是泛型\"><a href=\"#什么是泛型\" class=\"headerlink\" title=\"什么是泛型\"></a>什么是泛型</h3><p>泛型就是参数化类型：</p>\n<ul>\n<li>适用于多种数据类型执行相同的代码</li>\n<li>泛型中的类型在使用时指定</li>\n<li>泛型归根到底就是“模版”</li>\n</ul>\n<h3 id=\"Java的泛型是假的？\"><a href=\"#Java的泛型是假的？\" class=\"headerlink\" title=\"Java的泛型是假的？\"></a>Java的泛型是假的？</h3><p>Java的泛型时伪泛型，这是因为Java在编译期间，所有的泛型信息都会被擦掉。Java的泛型基本上都是在编译器这个层次上实现的，在生成的字节码中是不包含泛型中的类型信息的，使用泛型的时候加上类型参数，在编译器编译的时候会去掉，这个过程叫做类型擦除。例如List<object>和List<string>等类型，在编译后都会变成List</string></object></p>\n<h3 id=\"为什么要使用泛型\"><a href=\"#为什么要使用泛型\" class=\"headerlink\" title=\"为什么要使用泛型\"></a>为什么要使用泛型</h3><p>通过泛型<strong>可以定义类型安全的数据结构（类型安全）</strong>，而<strong>无须使用实际的数据类型（可扩展）</strong>。这<strong>能够显著提高性能并得到更高质量的代码（高性能）</strong>，因为您<strong>可以重用数据处理算法，而无须复制类型特定的代码（可重用）</strong>。在概念上，泛型类似于 C++ 模板，但是在实现和功能方面存在明显差异。</p>\n<ol>\n<li>编译期类型检查</li>\n<li>强制类型转换</li>\n<li>可读性和灵活性</li>\n</ol>\n<p>使用Object实现泛型的存在的问题：</p>\n<p><strong>性能问题：</strong>在使用值类型时，必须boxing &amp; unboxing。装箱和取消装箱都会根据它们自己的权限造成重大的性能损失，但是它还会增加托管堆上的压力，导致更多的垃圾收集工作，而这对于性能而言也不太好。即使是在使用引用类型而不是值类型时，仍然存在性能损失，这是因为必须从 Object 向您要与之交互的实际类型进行强制类型转换，从而造成强制类型转换开销。</p>\n<p>　　基于 Object 的解决方案的<strong>第二个问题（通常更为严重）是**</strong>类型安全**。因为编译器允许在任何类型和 Object 之间进行强制类型转换，所以您将丢失编译时类型安全。例如，以下代码可以正确编译，但是在运行时将引发无效强制类型转换异常</p>\n<p>　　您可以通过提供类型特定的（因而是类型安全的）高性能堆栈来克服上述两个问题。对于整型，可以实现并使用 <strong>IntStack。对于字符串，可以实现 \\</strong>StringStack。**\n**</p>\n<p>　　<strong><em>\\</em>遗憾的是，以这种方式解决性能和类型安全问题，会引起第三个同样严重的问题 — 影响工作效率（无法重用）。编写类型特定的数据结构是一项乏味的、重复性的且易于出错的任务。在修复该数据结构中的缺陷时，您不能只在一个位置修复该缺陷，而必须在实质上是同一数据结构的类型特定的副本所出现的每个位置进行修复。此外，没有办法预知未知的或尚未定义的将来类型的使用情况，因此还必须保持基于 Object 的数据结构。**</strong></p>\n<h3 id=\"限定通配符和非限定通配符\"><a href=\"#限定通配符和非限定通配符\" class=\"headerlink\" title=\"限定通配符和非限定通配符\"></a>限定通配符和非限定通配符</h3><ul>\n<li>限定通配符：<ol>\n<li><code>&lt;? extneds T&gt;</code>，即类型必须为T类型或T的子类</li>\n<li><code>&lt;? super T&gt;</code>，即类型必须为T类型或T的父类</li>\n</ol>\n</li>\n<li>非限定通配符：<ol>\n<li><code>&lt;T&gt;</code>，可以用任意类型来替代</li>\n</ol>\n</li>\n</ul>\n<h3 id=\"泛型和Object的区别\"><a href=\"#泛型和Object的区别\" class=\"headerlink\" title=\"泛型和Object的区别\"></a>泛型和Object的区别</h3><p>使用泛型或者Object作为形参，都可以让方法接受更多类型的对象，让程序变得健壮，代码复用性更高。但是使用Object作为形参，需要进行各种强制类型转换，编译器不会检查类型转换是被否安全，运行时才会暴露出问题。而使用泛型的话，即保证了代码的健壮性，而且还避免了强转的风险。</p>\n<h3 id=\"类型擦除引起的问题及解决方法\"><a href=\"#类型擦除引起的问题及解决方法\" class=\"headerlink\" title=\"类型擦除引起的问题及解决方法\"></a>类型擦除引起的问题及解决方法</h3><p>因为种种原因，Java不能实现真正的泛型，只能使用类型擦除来实现伪泛型，这样虽然不会有类型膨胀问题，但是也引起来许多新问题，所以，SUN对这些问题做出了种种限制，避免我们发生各种错误。</p>\n<h4 id=\"1、先检查再编译以及编译的对象和引用传递问题\"><a href=\"#1、先检查再编译以及编译的对象和引用传递问题\" class=\"headerlink\" title=\"1、先检查再编译以及编译的对象和引用传递问题\"></a>1、先检查再编译以及编译的对象和引用传递问题</h4><p><strong>Q</strong>: 既然说类型变量会在编译的时候擦除掉，那为什么我们往 ArrayList 创建的对象中添加整数会报错呢？不是说泛型变量String会在编译的时候变为Object类型吗？为什么不能存别的类型呢？既然类型擦除了，如何保证我们只能使用泛型变量限定的类型呢？</p>\n<p><strong>A</strong>: Java编译器是通过先检查代码中泛型的类型，然后在进行类型擦除，再进行编译。</p>\n<p>例如：</p>\n<pre><code class=\"java\">public static  void main(String[] args) {  \n    ArrayList&lt;String&gt; list = new ArrayList&lt;String&gt;();  \n    list.add(&quot;123&quot;);  \n    list.add(123);//编译错误  \n}</code></pre>\n<p>在上面的程序中，使用<code>add</code>方法添加一个整型，在IDE中，直接会报错，说明这就是在编译之前的检查，因为如果是在编译之后检查，类型擦除后，原始类型为<code>Object</code>，是应该允许任意引用类型添加的。可实际上却不是这样的，这恰恰说明了关于泛型变量的使用，是会在编译之前检查的。</p>\n<p>那么，这个类型检查是针对谁的呢？我们先看看参数化类型和原始类型的兼容。</p>\n<p>以 ArrayList举例子，以前的写法:</p>\n<pre><code class=\"java\">ArrayList list = new ArrayList();  </code></pre>\n<p>现在的写法:</p>\n<pre><code class=\"java\">ArrayList&lt;String&gt; list = new ArrayList&lt;String&gt;();</code></pre>\n<p>如果是与以前的代码兼容，各种引用传值之间，必然会出现如下的情况：</p>\n<pre><code class=\"java\">ArrayList&lt;String&gt; list1 = new ArrayList(); //第一种 情况\nArrayList list2 = new ArrayList&lt;String&gt;(); //第二种 情况</code></pre>\n<p>这样是没有错误的，不过会有个编译时警告。</p>\n<p>不过在第一种情况，可以实现与完全使用泛型参数一样的效果，第二种则没有效果。</p>\n<p>因为类型检查就是编译时完成的，<code>new ArrayList()</code>只是在内存中开辟了一个存储空间，可以存储任何类型对象，而<strong>真正设计类型检查的是它的引用</strong>，因为我们是使用它引用<code>list1</code>来调用它的方法，比如说调用<code>add</code>方法，所以<code>list1</code>引用能完成泛型类型的检查。而引用<code>list2</code>没有使用泛型，所以不行。</p>\n<p>举例子：</p>\n<pre><code class=\"java\">public class Test {  \n\n    public static void main(String[] args) {  \n\n        ArrayList&lt;String&gt; list1 = new ArrayList();  \n        list1.add(&quot;1&quot;); //编译通过  \n        list1.add(1); //编译错误  \n        String str1 = list1.get(0); //返回类型就是String  \n\n        ArrayList list2 = new ArrayList&lt;String&gt;();  \n        list2.add(&quot;1&quot;); //编译通过  \n        list2.add(1); //编译通过  \n        Object object = list2.get(0); //返回类型就是Object  \n\n        new ArrayList&lt;String&gt;().add(&quot;11&quot;); //编译通过  \n        new ArrayList&lt;String&gt;().add(22); //编译错误  \n\n        String str2 = new ArrayList&lt;String&gt;().get(0); //返回类型就是String  \n    }  \n\n}  </code></pre>\n<p>通过上面的例子，我们可以明白，<strong>类型检查就是针对引用的</strong>，谁是一个引用，用这个引用调用泛型方法，就会对这个引用调用的方法进行类型检测，而无关它真正引用的对象。</p>\n<p>泛型中参数话类型为什么不考虑继承关系？</p>\n<p>在Java中，像下面形式的引用传递是不允许的:</p>\n<pre><code class=\"java\">ArrayList&lt;String&gt; list1 = new ArrayList&lt;Object&gt;(); //编译错误  \nArrayList&lt;Object&gt; list2 = new ArrayList&lt;String&gt;(); //编译错误</code></pre>\n<p>我们先看第一种情况，将第一种情况拓展成下面的形式：</p>\n<pre><code class=\"java\">ArrayList&lt;Object&gt; list1 = new ArrayList&lt;Object&gt;();  \nlist1.add(new Object());  \nlist1.add(new Object());  \nArrayList&lt;String&gt; list2 = list1; //编译错误</code></pre>\n<p>实际上，在第4行代码的时候，就会有编译错误。那么，我们先假设它编译没错。那么当我们使用<code>list2</code>引用用<code>get()</code>方法取值的时候，返回的都是<code>String</code>类型的对象（上面提到了，类型检测是根据引用来决定的），可是它里面实际上已经被我们存放了<code>Object</code>类型的对象，这样就会有<code>ClassCastException</code>了。所以为了避免这种极易出现的错误，Java不允许进行这样的引用传递。（这也是泛型出现的原因，就是为了解决类型转换的问题，我们不能违背它的初衷）。</p>\n<p>再看第二种情况，将第二种情况拓展成下面的形式：</p>\n<pre><code class=\"java\">ArrayList&lt;String&gt; list1 = new ArrayList&lt;String&gt;();  \nlist1.add(new String());  \nlist1.add(new String());\n\nArrayList&lt;Object&gt; list2 = list1; //编译错误</code></pre>\n<p>没错，这样的情况比第一种情况好的多，最起码，在我们用<code>list2</code>取值的时候不会出现<code>ClassCastException</code>，因为是从<code>String</code>转换为<code>Object</code>。可是，这样做有什么意义呢，泛型出现的原因，就是为了解决类型转换的问题。我们使用了泛型，到头来，还是要自己强转，违背了泛型设计的初衷。所以java不允许这么干。再说，你如果又用<code>list2</code>往里面<code>add()</code>新的对象，那么到时候取得时候，我怎么知道我取出来的到底是<code>String</code>类型的，还是<code>Object</code>类型的呢？</p>\n<p><strong>所以，要格外注意，泛型中的引用传递的问题。</strong></p>\n<h4 id=\"2、自动类型转换\"><a href=\"#2、自动类型转换\" class=\"headerlink\" title=\"2、自动类型转换\"></a>2、自动类型转换</h4><p>因为类型擦除的问题，所以所有的泛型类型变量最后都会被替换为原始类型。</p>\n<p>既然都被替换为原始类型，那么为什么我们在获取的时候，不需要进行强制类型转换呢？</p>\n<p>看下<code>ArrayList.get()</code>方法：</p>\n<pre><code class=\"java\">public E get(int index) {  \n\n    RangeCheck(index);  \n\n    return (E) elementData[index];  \n\n}</code></pre>\n<p>可以看到，在<code>return</code>之前，会根据泛型变量进行强转。假设泛型类型变量为<code>Date</code>，虽然泛型信息会被擦除掉，但是会将<code>(E) elementData[index]</code>，编译为<code>(Date) elementData[index]</code>。所以我们不用自己进行强转。当存取一个泛型域时也会自动插入强制类型转换。假设<code>Pair</code>类的<code>value</code>域是<code>public</code>的，那么表达式：</p>\n<pre><code class=\"java\">Date date = pair.value;</code></pre>\n<p>也会自动地在结果字节码中插入强制类型转换。</p>\n<h4 id=\"3、类型擦除与多态的冲突和解决方法\"><a href=\"#3、类型擦除与多态的冲突和解决方法\" class=\"headerlink\" title=\"3、类型擦除与多态的冲突和解决方法\"></a>3、类型擦除与多态的冲突和解决方法</h4><p>现在有这样一个泛型类：</p>\n<pre><code class=\"java\">class Pair&lt;T&gt; {  \n\n    private T value;  \n\n    public T getValue() {  \n        return value;  \n    }  \n\n    public void setValue(T value) {  \n        this.value = value;  \n    }  \n}</code></pre>\n<p>然后我们想要一个子类继承它。</p>\n<pre><code class=\"java\">class DateInter extends Pair&lt;Date&gt; {  \n\n    @Override\n    public void setValue(Date value) {  \n        super.setValue(value);  \n    }  \n\n    @Override\n    public Date getValue() {  \n        return super.getValue();  \n    }  \n}</code></pre>\n<p>在这个子类中，我们设定父类的泛型类型为<code>Pair&lt;Date&gt;</code>，在子类中，我们覆盖了父类的两个方法，我们的原意是这样的：将父类的泛型类型限定为<code>Date</code>，那么父类里面的两个方法的参数都为<code>Date</code>类型。</p>\n<pre><code class=\"java\">public Date getValue() {  \n    return value;  \n}  \n\npublic void setValue(Date value) {  \n    this.value = value;  \n}</code></pre>\n<p>所以，我们在子类中重写这两个方法一点问题也没有，实际上，从他们的<code>@Override</code>标签中也可以看到，一点问题也没有，实际上是这样的吗？</p>\n<p>分析：实际上，类型擦除后，父类的的泛型类型全部变为了原始类型<code>Object</code>，所以父类编译之后会变成下面的样子：</p>\n<pre><code class=\"java\">class Pair {  \n    private Object value;  \n\n    public Object getValue() {  \n        return value;  \n    }  \n\n    public void setValue(Object  value) {  \n        this.value = value;  \n    }  \n}  </code></pre>\n<p>再看子类的两个重写的方法的类型：</p>\n<pre><code class=\"java\">@Override  \npublic void setValue(Date value) {  \n    super.setValue(value);  \n}  \n@Override  \npublic Date getValue() {  \n    return super.getValue();  \n}</code></pre>\n<p>先来分析<code>setValue</code>方法，父类的类型是<code>Object</code>，而子类的类型是<code>Date</code>，参数类型不一样，这如果实在普通的继承关系中，根本就不会是重写，而是重载。</p>\n<p>我们在一个main方法测试一下：</p>\n<pre><code class=\"java\">public static void main(String[] args) throws ClassNotFoundException {  \n        DateInter dateInter = new DateInter();  \n        dateInter.setValue(new Date());                  \n        dateInter.setValue(new Object()); //编译错误  \n}</code></pre>\n<p>如果是重载，那么子类中两个<code>setValue</code>方法，一个是参数<code>Object</code>类型，一个是<code>Date</code>类型，可是我们发现，根本就没有这样的一个子类继承自父类的Object类型参数的方法。所以说，却是是重写了，而不是重载了。</p>\n<p>为什么会这样呢？</p>\n<p>原因是这样的，我们传入父类的泛型类型是<code>Date，Pair&lt;Date&gt;</code>，我们的本意是将泛型类变为如下：</p>\n<pre><code class=\"java\">class Pair {  \n    private Date value;  \n    public Date getValue() {  \n        return value;  \n    }  \n    public void setValue(Date value) {  \n        this.value = value;  \n    }  \n}</code></pre>\n<p>然后再子类中重写参数类型为Date的那两个方法，实现继承中的多态。</p>\n<p>可是由于种种原因，虚拟机并不能将泛型类型变为<code>Date</code>，只能将类型擦除掉，变为原始类型<code>Object</code>。这样，我们的本意是进行重写，实现多态。可是类型擦除后，只能变为了重载。这样，类型擦除就和多态有了冲突。JVM知道你的本意吗？知道！！！可是它能直接实现吗，不能！！！如果真的不能的话，那我们怎么去重写我们想要的<code>Date</code>类型参数的方法啊。</p>\n<p>于是JVM采用了一个特殊的方法，来完成这项功能，那就是<strong>桥方法</strong>。</p>\n<p>首先，我们用<code>javap -c className</code>的方式反编译下<code>DateInter</code>子类的字节码，结果如下：</p>\n<pre><code class=\"class\">class com.tao.test.DateInter extends com.tao.test.Pair&lt;java.util.Date&gt; {  \n  com.tao.test.DateInter();  \n    Code:  \n       0: aload_0  \n       1: invokespecial #8                  // Method com/tao/test/Pair.&quot;&lt;init&gt;&quot;:()V  \n       4: return  \n\n  public void setValue(java.util.Date);  //我们重写的setValue方法  \n    Code:  \n       0: aload_0  \n       1: aload_1  \n       2: invokespecial #16                 // Method com/tao/test/Pair.setValue:(Ljava/lang/Object;)V  \n       5: return  \n\n  public java.util.Date getValue();    //我们重写的getValue方法  \n    Code:  \n       0: aload_0  \n       1: invokespecial #23                 // Method com/tao/test/Pair.getValue:()Ljava/lang/Object;  \n       4: checkcast     #26                 // class java/util/Date  \n       7: areturn  \n\n  public java.lang.Object getValue();     //编译时由编译器生成的桥方法  \n    Code:  \n       0: aload_0  \n       1: invokevirtual #28                 // Method getValue:()Ljava/util/Date 去调用我们重写的getValue方法;  \n       4: areturn  \n\n  public void setValue(java.lang.Object);   //编译时由编译器生成的桥方法  \n    Code:  \n       0: aload_0  \n       1: aload_1  \n       2: checkcast     #26                 // class java/util/Date  \n       5: invokevirtual #30                 // Method setValue:(Ljava/util/Date; 去调用我们重写的setValue方法)V  \n       8: return  \n}</code></pre>\n<p>从编译的结果来看，我们本意重写<code>setValue</code>和<code>getValue</code>方法的子类，竟然有4个方法，其实不用惊奇，最后的两个方法，就是编译器自己生成的桥方法。可以看到桥方法的参数类型都是Object，也就是说，子类中真正覆盖父类两个方法的就是这两个我们看不到的桥方法。而在我们自己定义的<code>setvalue</code>和<code>getValue</code>方法上面的<code>@Oveerride</code>只不过是假象。而桥方法的内部实现，就只是去调用我们自己重写的那两个方法。</p>\n<p>所以，<strong>虚拟机巧妙的使用了桥方法，来解决了类型擦除和多态的冲突</strong>。</p>\n<p>不过，要提到一点，这里面的<code>setValue</code>和<code>getValue</code>这两个桥方法的意义又有不同。</p>\n<p><code>setValue</code>方法是为了解决类型擦除与多态之间的冲突。</p>\n<p>而<code>getValue</code>却有普遍的意义，怎么说呢，如果这是一个普通的继承关系：</p>\n<p>那么父类的<code>getValue</code>方法如下：</p>\n<pre><code class=\"java\">public Object getValue() {  \n    return value;  \n}</code></pre>\n<p>而子类重写的方法是：</p>\n<pre><code class=\"java\">public Date getValue() {  \n    return super.getValue();  \n}</code></pre>\n<p>其实这在普通的类继承中也是普遍存在的重写，这就是协变。</p>\n<p>关于协变：。。。。。。</p>\n<p>并且，还有一点也许会有疑问，子类中的桥方法<code>Object getValue()</code>和<code>Date getValue()</code>是同时存在的，可是如果是常规的两个方法，他们的方法签名是一样的，也就是说虚拟机根本不能分别这两个方法。如果是我们自己编写Java代码，这样的代码是无法通过编译器的检查的，但是虚拟机却是允许这样做的，因为虚拟机通过参数类型和返回类型来确定一个方法，所以编译器为了实现泛型的多态允许自己做这个看起来“不合法”的事情，然后交给虚拟器去区别。</p>\n<h4 id=\"4、泛型类型变量不能是基本数据类型\"><a href=\"#4、泛型类型变量不能是基本数据类型\" class=\"headerlink\" title=\"4、泛型类型变量不能是基本数据类型\"></a>4、泛型类型变量不能是基本数据类型</h4><p>不能用类型参数替换基本类型。就比如，没有<code>ArrayList&lt;double&gt;</code>，只有<code>ArrayList&lt;Double&gt;</code>。因为当类型擦除后，<code>ArrayList</code>的原始类型变为<code>Object</code>，但是<code>Object</code>类型不能存储<code>double</code>值，只能引用<code>Double</code>的值。</p>\n<h4 id=\"5、编译时集合的instanceof\"><a href=\"#5、编译时集合的instanceof\" class=\"headerlink\" title=\"5、编译时集合的instanceof\"></a>5、编译时集合的instanceof</h4><pre><code class=\"java\">ArrayList&lt;String&gt; arrayList = new ArrayList&lt;String&gt;();</code></pre>\n<p>因为类型擦除之后，<code>ArrayList&lt;String&gt;</code>只剩下原始类型，泛型信息<code>String</code>不存在了。</p>\n<p>那么，编译时进行类型查询的时候使用下面的方法是错误的</p>\n<pre><code class=\"java\">if( arrayList instanceof ArrayList&lt;String&gt;)</code></pre>\n<h4 id=\"6、泛型在静态方法和静态类中的问题\"><a href=\"#6、泛型在静态方法和静态类中的问题\" class=\"headerlink\" title=\"6、泛型在静态方法和静态类中的问题\"></a>6、泛型在静态方法和静态类中的问题</h4><p>泛型类中的静态方法和静态变量不可以使用泛型类所声明的泛型类型参数</p>\n<p>举例说明：</p>\n<pre><code class=\"java\">public class Test2&lt;T&gt; {    \n    public static T one;   //编译错误    \n    public static  T show(T one){ //编译错误    \n        return null;    \n    }    \n}</code></pre>\n<p>因为泛型类中的泛型参数的实例化是在定义对象的时候指定的，而静态变量和静态方法不需要使用对象来调用。对象都没有创建，如何确定这个泛型参数是何种类型，所以当然是错误的。</p>\n<p>但是要注意区分下面的一种情况：</p>\n<pre><code class=\"java\">public class Test2&lt;T&gt; {    \n\n    public static &lt;T &gt;T show(T one){ //这是正确的    \n        return null;    \n    }    \n}</code></pre>\n<p>因为这是一个泛型方法，在泛型方法中使用的T是自己在方法中定义的 T，而不是泛型类中的T。</p>\n","site":{"data":{}},"more":"<h3 id=\"什么是泛型\"><a href=\"#什么是泛型\" class=\"headerlink\" title=\"什么是泛型\"></a>什么是泛型</h3><p>泛型就是参数化类型：</p>\n<ul>\n<li>适用于多种数据类型执行相同的代码</li>\n<li>泛型中的类型在使用时指定</li>\n<li>泛型归根到底就是“模版”</li>\n</ul>\n<h3 id=\"Java的泛型是假的？\"><a href=\"#Java的泛型是假的？\" class=\"headerlink\" title=\"Java的泛型是假的？\"></a>Java的泛型是假的？</h3><p>Java的泛型时伪泛型，这是因为Java在编译期间，所有的泛型信息都会被擦掉。Java的泛型基本上都是在编译器这个层次上实现的，在生成的字节码中是不包含泛型中的类型信息的，使用泛型的时候加上类型参数，在编译器编译的时候会去掉，这个过程叫做类型擦除。例如List<object>和List<string>等类型，在编译后都会变成List</string></object></p>\n<h3 id=\"为什么要使用泛型\"><a href=\"#为什么要使用泛型\" class=\"headerlink\" title=\"为什么要使用泛型\"></a>为什么要使用泛型</h3><p>通过泛型<strong>可以定义类型安全的数据结构（类型安全）</strong>，而<strong>无须使用实际的数据类型（可扩展）</strong>。这<strong>能够显著提高性能并得到更高质量的代码（高性能）</strong>，因为您<strong>可以重用数据处理算法，而无须复制类型特定的代码（可重用）</strong>。在概念上，泛型类似于 C++ 模板，但是在实现和功能方面存在明显差异。</p>\n<ol>\n<li>编译期类型检查</li>\n<li>强制类型转换</li>\n<li>可读性和灵活性</li>\n</ol>\n<p>使用Object实现泛型的存在的问题：</p>\n<p><strong>性能问题：</strong>在使用值类型时，必须boxing &amp; unboxing。装箱和取消装箱都会根据它们自己的权限造成重大的性能损失，但是它还会增加托管堆上的压力，导致更多的垃圾收集工作，而这对于性能而言也不太好。即使是在使用引用类型而不是值类型时，仍然存在性能损失，这是因为必须从 Object 向您要与之交互的实际类型进行强制类型转换，从而造成强制类型转换开销。</p>\n<p>　　基于 Object 的解决方案的<strong>第二个问题（通常更为严重）是**</strong>类型安全**。因为编译器允许在任何类型和 Object 之间进行强制类型转换，所以您将丢失编译时类型安全。例如，以下代码可以正确编译，但是在运行时将引发无效强制类型转换异常</p>\n<p>　　您可以通过提供类型特定的（因而是类型安全的）高性能堆栈来克服上述两个问题。对于整型，可以实现并使用 <strong>IntStack。对于字符串，可以实现 \\</strong>StringStack。**\n**</p>\n<p>　　<strong><em>\\</em>遗憾的是，以这种方式解决性能和类型安全问题，会引起第三个同样严重的问题 — 影响工作效率（无法重用）。编写类型特定的数据结构是一项乏味的、重复性的且易于出错的任务。在修复该数据结构中的缺陷时，您不能只在一个位置修复该缺陷，而必须在实质上是同一数据结构的类型特定的副本所出现的每个位置进行修复。此外，没有办法预知未知的或尚未定义的将来类型的使用情况，因此还必须保持基于 Object 的数据结构。**</strong></p>\n<h3 id=\"限定通配符和非限定通配符\"><a href=\"#限定通配符和非限定通配符\" class=\"headerlink\" title=\"限定通配符和非限定通配符\"></a>限定通配符和非限定通配符</h3><ul>\n<li>限定通配符：<ol>\n<li><code>&lt;? extneds T&gt;</code>，即类型必须为T类型或T的子类</li>\n<li><code>&lt;? super T&gt;</code>，即类型必须为T类型或T的父类</li>\n</ol>\n</li>\n<li>非限定通配符：<ol>\n<li><code>&lt;T&gt;</code>，可以用任意类型来替代</li>\n</ol>\n</li>\n</ul>\n<h3 id=\"泛型和Object的区别\"><a href=\"#泛型和Object的区别\" class=\"headerlink\" title=\"泛型和Object的区别\"></a>泛型和Object的区别</h3><p>使用泛型或者Object作为形参，都可以让方法接受更多类型的对象，让程序变得健壮，代码复用性更高。但是使用Object作为形参，需要进行各种强制类型转换，编译器不会检查类型转换是被否安全，运行时才会暴露出问题。而使用泛型的话，即保证了代码的健壮性，而且还避免了强转的风险。</p>\n<h3 id=\"类型擦除引起的问题及解决方法\"><a href=\"#类型擦除引起的问题及解决方法\" class=\"headerlink\" title=\"类型擦除引起的问题及解决方法\"></a>类型擦除引起的问题及解决方法</h3><p>因为种种原因，Java不能实现真正的泛型，只能使用类型擦除来实现伪泛型，这样虽然不会有类型膨胀问题，但是也引起来许多新问题，所以，SUN对这些问题做出了种种限制，避免我们发生各种错误。</p>\n<h4 id=\"1、先检查再编译以及编译的对象和引用传递问题\"><a href=\"#1、先检查再编译以及编译的对象和引用传递问题\" class=\"headerlink\" title=\"1、先检查再编译以及编译的对象和引用传递问题\"></a>1、先检查再编译以及编译的对象和引用传递问题</h4><p><strong>Q</strong>: 既然说类型变量会在编译的时候擦除掉，那为什么我们往 ArrayList 创建的对象中添加整数会报错呢？不是说泛型变量String会在编译的时候变为Object类型吗？为什么不能存别的类型呢？既然类型擦除了，如何保证我们只能使用泛型变量限定的类型呢？</p>\n<p><strong>A</strong>: Java编译器是通过先检查代码中泛型的类型，然后在进行类型擦除，再进行编译。</p>\n<p>例如：</p>\n<pre><code class=\"java\">public static  void main(String[] args) {  \n    ArrayList&lt;String&gt; list = new ArrayList&lt;String&gt;();  \n    list.add(&quot;123&quot;);  \n    list.add(123);//编译错误  \n}</code></pre>\n<p>在上面的程序中，使用<code>add</code>方法添加一个整型，在IDE中，直接会报错，说明这就是在编译之前的检查，因为如果是在编译之后检查，类型擦除后，原始类型为<code>Object</code>，是应该允许任意引用类型添加的。可实际上却不是这样的，这恰恰说明了关于泛型变量的使用，是会在编译之前检查的。</p>\n<p>那么，这个类型检查是针对谁的呢？我们先看看参数化类型和原始类型的兼容。</p>\n<p>以 ArrayList举例子，以前的写法:</p>\n<pre><code class=\"java\">ArrayList list = new ArrayList();  </code></pre>\n<p>现在的写法:</p>\n<pre><code class=\"java\">ArrayList&lt;String&gt; list = new ArrayList&lt;String&gt;();</code></pre>\n<p>如果是与以前的代码兼容，各种引用传值之间，必然会出现如下的情况：</p>\n<pre><code class=\"java\">ArrayList&lt;String&gt; list1 = new ArrayList(); //第一种 情况\nArrayList list2 = new ArrayList&lt;String&gt;(); //第二种 情况</code></pre>\n<p>这样是没有错误的，不过会有个编译时警告。</p>\n<p>不过在第一种情况，可以实现与完全使用泛型参数一样的效果，第二种则没有效果。</p>\n<p>因为类型检查就是编译时完成的，<code>new ArrayList()</code>只是在内存中开辟了一个存储空间，可以存储任何类型对象，而<strong>真正设计类型检查的是它的引用</strong>，因为我们是使用它引用<code>list1</code>来调用它的方法，比如说调用<code>add</code>方法，所以<code>list1</code>引用能完成泛型类型的检查。而引用<code>list2</code>没有使用泛型，所以不行。</p>\n<p>举例子：</p>\n<pre><code class=\"java\">public class Test {  \n\n    public static void main(String[] args) {  \n\n        ArrayList&lt;String&gt; list1 = new ArrayList();  \n        list1.add(&quot;1&quot;); //编译通过  \n        list1.add(1); //编译错误  \n        String str1 = list1.get(0); //返回类型就是String  \n\n        ArrayList list2 = new ArrayList&lt;String&gt;();  \n        list2.add(&quot;1&quot;); //编译通过  \n        list2.add(1); //编译通过  \n        Object object = list2.get(0); //返回类型就是Object  \n\n        new ArrayList&lt;String&gt;().add(&quot;11&quot;); //编译通过  \n        new ArrayList&lt;String&gt;().add(22); //编译错误  \n\n        String str2 = new ArrayList&lt;String&gt;().get(0); //返回类型就是String  \n    }  \n\n}  </code></pre>\n<p>通过上面的例子，我们可以明白，<strong>类型检查就是针对引用的</strong>，谁是一个引用，用这个引用调用泛型方法，就会对这个引用调用的方法进行类型检测，而无关它真正引用的对象。</p>\n<p>泛型中参数话类型为什么不考虑继承关系？</p>\n<p>在Java中，像下面形式的引用传递是不允许的:</p>\n<pre><code class=\"java\">ArrayList&lt;String&gt; list1 = new ArrayList&lt;Object&gt;(); //编译错误  \nArrayList&lt;Object&gt; list2 = new ArrayList&lt;String&gt;(); //编译错误</code></pre>\n<p>我们先看第一种情况，将第一种情况拓展成下面的形式：</p>\n<pre><code class=\"java\">ArrayList&lt;Object&gt; list1 = new ArrayList&lt;Object&gt;();  \nlist1.add(new Object());  \nlist1.add(new Object());  \nArrayList&lt;String&gt; list2 = list1; //编译错误</code></pre>\n<p>实际上，在第4行代码的时候，就会有编译错误。那么，我们先假设它编译没错。那么当我们使用<code>list2</code>引用用<code>get()</code>方法取值的时候，返回的都是<code>String</code>类型的对象（上面提到了，类型检测是根据引用来决定的），可是它里面实际上已经被我们存放了<code>Object</code>类型的对象，这样就会有<code>ClassCastException</code>了。所以为了避免这种极易出现的错误，Java不允许进行这样的引用传递。（这也是泛型出现的原因，就是为了解决类型转换的问题，我们不能违背它的初衷）。</p>\n<p>再看第二种情况，将第二种情况拓展成下面的形式：</p>\n<pre><code class=\"java\">ArrayList&lt;String&gt; list1 = new ArrayList&lt;String&gt;();  \nlist1.add(new String());  \nlist1.add(new String());\n\nArrayList&lt;Object&gt; list2 = list1; //编译错误</code></pre>\n<p>没错，这样的情况比第一种情况好的多，最起码，在我们用<code>list2</code>取值的时候不会出现<code>ClassCastException</code>，因为是从<code>String</code>转换为<code>Object</code>。可是，这样做有什么意义呢，泛型出现的原因，就是为了解决类型转换的问题。我们使用了泛型，到头来，还是要自己强转，违背了泛型设计的初衷。所以java不允许这么干。再说，你如果又用<code>list2</code>往里面<code>add()</code>新的对象，那么到时候取得时候，我怎么知道我取出来的到底是<code>String</code>类型的，还是<code>Object</code>类型的呢？</p>\n<p><strong>所以，要格外注意，泛型中的引用传递的问题。</strong></p>\n<h4 id=\"2、自动类型转换\"><a href=\"#2、自动类型转换\" class=\"headerlink\" title=\"2、自动类型转换\"></a>2、自动类型转换</h4><p>因为类型擦除的问题，所以所有的泛型类型变量最后都会被替换为原始类型。</p>\n<p>既然都被替换为原始类型，那么为什么我们在获取的时候，不需要进行强制类型转换呢？</p>\n<p>看下<code>ArrayList.get()</code>方法：</p>\n<pre><code class=\"java\">public E get(int index) {  \n\n    RangeCheck(index);  \n\n    return (E) elementData[index];  \n\n}</code></pre>\n<p>可以看到，在<code>return</code>之前，会根据泛型变量进行强转。假设泛型类型变量为<code>Date</code>，虽然泛型信息会被擦除掉，但是会将<code>(E) elementData[index]</code>，编译为<code>(Date) elementData[index]</code>。所以我们不用自己进行强转。当存取一个泛型域时也会自动插入强制类型转换。假设<code>Pair</code>类的<code>value</code>域是<code>public</code>的，那么表达式：</p>\n<pre><code class=\"java\">Date date = pair.value;</code></pre>\n<p>也会自动地在结果字节码中插入强制类型转换。</p>\n<h4 id=\"3、类型擦除与多态的冲突和解决方法\"><a href=\"#3、类型擦除与多态的冲突和解决方法\" class=\"headerlink\" title=\"3、类型擦除与多态的冲突和解决方法\"></a>3、类型擦除与多态的冲突和解决方法</h4><p>现在有这样一个泛型类：</p>\n<pre><code class=\"java\">class Pair&lt;T&gt; {  \n\n    private T value;  \n\n    public T getValue() {  \n        return value;  \n    }  \n\n    public void setValue(T value) {  \n        this.value = value;  \n    }  \n}</code></pre>\n<p>然后我们想要一个子类继承它。</p>\n<pre><code class=\"java\">class DateInter extends Pair&lt;Date&gt; {  \n\n    @Override\n    public void setValue(Date value) {  \n        super.setValue(value);  \n    }  \n\n    @Override\n    public Date getValue() {  \n        return super.getValue();  \n    }  \n}</code></pre>\n<p>在这个子类中，我们设定父类的泛型类型为<code>Pair&lt;Date&gt;</code>，在子类中，我们覆盖了父类的两个方法，我们的原意是这样的：将父类的泛型类型限定为<code>Date</code>，那么父类里面的两个方法的参数都为<code>Date</code>类型。</p>\n<pre><code class=\"java\">public Date getValue() {  \n    return value;  \n}  \n\npublic void setValue(Date value) {  \n    this.value = value;  \n}</code></pre>\n<p>所以，我们在子类中重写这两个方法一点问题也没有，实际上，从他们的<code>@Override</code>标签中也可以看到，一点问题也没有，实际上是这样的吗？</p>\n<p>分析：实际上，类型擦除后，父类的的泛型类型全部变为了原始类型<code>Object</code>，所以父类编译之后会变成下面的样子：</p>\n<pre><code class=\"java\">class Pair {  \n    private Object value;  \n\n    public Object getValue() {  \n        return value;  \n    }  \n\n    public void setValue(Object  value) {  \n        this.value = value;  \n    }  \n}  </code></pre>\n<p>再看子类的两个重写的方法的类型：</p>\n<pre><code class=\"java\">@Override  \npublic void setValue(Date value) {  \n    super.setValue(value);  \n}  \n@Override  \npublic Date getValue() {  \n    return super.getValue();  \n}</code></pre>\n<p>先来分析<code>setValue</code>方法，父类的类型是<code>Object</code>，而子类的类型是<code>Date</code>，参数类型不一样，这如果实在普通的继承关系中，根本就不会是重写，而是重载。</p>\n<p>我们在一个main方法测试一下：</p>\n<pre><code class=\"java\">public static void main(String[] args) throws ClassNotFoundException {  \n        DateInter dateInter = new DateInter();  \n        dateInter.setValue(new Date());                  \n        dateInter.setValue(new Object()); //编译错误  \n}</code></pre>\n<p>如果是重载，那么子类中两个<code>setValue</code>方法，一个是参数<code>Object</code>类型，一个是<code>Date</code>类型，可是我们发现，根本就没有这样的一个子类继承自父类的Object类型参数的方法。所以说，却是是重写了，而不是重载了。</p>\n<p>为什么会这样呢？</p>\n<p>原因是这样的，我们传入父类的泛型类型是<code>Date，Pair&lt;Date&gt;</code>，我们的本意是将泛型类变为如下：</p>\n<pre><code class=\"java\">class Pair {  \n    private Date value;  \n    public Date getValue() {  \n        return value;  \n    }  \n    public void setValue(Date value) {  \n        this.value = value;  \n    }  \n}</code></pre>\n<p>然后再子类中重写参数类型为Date的那两个方法，实现继承中的多态。</p>\n<p>可是由于种种原因，虚拟机并不能将泛型类型变为<code>Date</code>，只能将类型擦除掉，变为原始类型<code>Object</code>。这样，我们的本意是进行重写，实现多态。可是类型擦除后，只能变为了重载。这样，类型擦除就和多态有了冲突。JVM知道你的本意吗？知道！！！可是它能直接实现吗，不能！！！如果真的不能的话，那我们怎么去重写我们想要的<code>Date</code>类型参数的方法啊。</p>\n<p>于是JVM采用了一个特殊的方法，来完成这项功能，那就是<strong>桥方法</strong>。</p>\n<p>首先，我们用<code>javap -c className</code>的方式反编译下<code>DateInter</code>子类的字节码，结果如下：</p>\n<pre><code class=\"class\">class com.tao.test.DateInter extends com.tao.test.Pair&lt;java.util.Date&gt; {  \n  com.tao.test.DateInter();  \n    Code:  \n       0: aload_0  \n       1: invokespecial #8                  // Method com/tao/test/Pair.&quot;&lt;init&gt;&quot;:()V  \n       4: return  \n\n  public void setValue(java.util.Date);  //我们重写的setValue方法  \n    Code:  \n       0: aload_0  \n       1: aload_1  \n       2: invokespecial #16                 // Method com/tao/test/Pair.setValue:(Ljava/lang/Object;)V  \n       5: return  \n\n  public java.util.Date getValue();    //我们重写的getValue方法  \n    Code:  \n       0: aload_0  \n       1: invokespecial #23                 // Method com/tao/test/Pair.getValue:()Ljava/lang/Object;  \n       4: checkcast     #26                 // class java/util/Date  \n       7: areturn  \n\n  public java.lang.Object getValue();     //编译时由编译器生成的桥方法  \n    Code:  \n       0: aload_0  \n       1: invokevirtual #28                 // Method getValue:()Ljava/util/Date 去调用我们重写的getValue方法;  \n       4: areturn  \n\n  public void setValue(java.lang.Object);   //编译时由编译器生成的桥方法  \n    Code:  \n       0: aload_0  \n       1: aload_1  \n       2: checkcast     #26                 // class java/util/Date  \n       5: invokevirtual #30                 // Method setValue:(Ljava/util/Date; 去调用我们重写的setValue方法)V  \n       8: return  \n}</code></pre>\n<p>从编译的结果来看，我们本意重写<code>setValue</code>和<code>getValue</code>方法的子类，竟然有4个方法，其实不用惊奇，最后的两个方法，就是编译器自己生成的桥方法。可以看到桥方法的参数类型都是Object，也就是说，子类中真正覆盖父类两个方法的就是这两个我们看不到的桥方法。而在我们自己定义的<code>setvalue</code>和<code>getValue</code>方法上面的<code>@Oveerride</code>只不过是假象。而桥方法的内部实现，就只是去调用我们自己重写的那两个方法。</p>\n<p>所以，<strong>虚拟机巧妙的使用了桥方法，来解决了类型擦除和多态的冲突</strong>。</p>\n<p>不过，要提到一点，这里面的<code>setValue</code>和<code>getValue</code>这两个桥方法的意义又有不同。</p>\n<p><code>setValue</code>方法是为了解决类型擦除与多态之间的冲突。</p>\n<p>而<code>getValue</code>却有普遍的意义，怎么说呢，如果这是一个普通的继承关系：</p>\n<p>那么父类的<code>getValue</code>方法如下：</p>\n<pre><code class=\"java\">public Object getValue() {  \n    return value;  \n}</code></pre>\n<p>而子类重写的方法是：</p>\n<pre><code class=\"java\">public Date getValue() {  \n    return super.getValue();  \n}</code></pre>\n<p>其实这在普通的类继承中也是普遍存在的重写，这就是协变。</p>\n<p>关于协变：。。。。。。</p>\n<p>并且，还有一点也许会有疑问，子类中的桥方法<code>Object getValue()</code>和<code>Date getValue()</code>是同时存在的，可是如果是常规的两个方法，他们的方法签名是一样的，也就是说虚拟机根本不能分别这两个方法。如果是我们自己编写Java代码，这样的代码是无法通过编译器的检查的，但是虚拟机却是允许这样做的，因为虚拟机通过参数类型和返回类型来确定一个方法，所以编译器为了实现泛型的多态允许自己做这个看起来“不合法”的事情，然后交给虚拟器去区别。</p>\n<h4 id=\"4、泛型类型变量不能是基本数据类型\"><a href=\"#4、泛型类型变量不能是基本数据类型\" class=\"headerlink\" title=\"4、泛型类型变量不能是基本数据类型\"></a>4、泛型类型变量不能是基本数据类型</h4><p>不能用类型参数替换基本类型。就比如，没有<code>ArrayList&lt;double&gt;</code>，只有<code>ArrayList&lt;Double&gt;</code>。因为当类型擦除后，<code>ArrayList</code>的原始类型变为<code>Object</code>，但是<code>Object</code>类型不能存储<code>double</code>值，只能引用<code>Double</code>的值。</p>\n<h4 id=\"5、编译时集合的instanceof\"><a href=\"#5、编译时集合的instanceof\" class=\"headerlink\" title=\"5、编译时集合的instanceof\"></a>5、编译时集合的instanceof</h4><pre><code class=\"java\">ArrayList&lt;String&gt; arrayList = new ArrayList&lt;String&gt;();</code></pre>\n<p>因为类型擦除之后，<code>ArrayList&lt;String&gt;</code>只剩下原始类型，泛型信息<code>String</code>不存在了。</p>\n<p>那么，编译时进行类型查询的时候使用下面的方法是错误的</p>\n<pre><code class=\"java\">if( arrayList instanceof ArrayList&lt;String&gt;)</code></pre>\n<h4 id=\"6、泛型在静态方法和静态类中的问题\"><a href=\"#6、泛型在静态方法和静态类中的问题\" class=\"headerlink\" title=\"6、泛型在静态方法和静态类中的问题\"></a>6、泛型在静态方法和静态类中的问题</h4><p>泛型类中的静态方法和静态变量不可以使用泛型类所声明的泛型类型参数</p>\n<p>举例说明：</p>\n<pre><code class=\"java\">public class Test2&lt;T&gt; {    \n    public static T one;   //编译错误    \n    public static  T show(T one){ //编译错误    \n        return null;    \n    }    \n}</code></pre>\n<p>因为泛型类中的泛型参数的实例化是在定义对象的时候指定的，而静态变量和静态方法不需要使用对象来调用。对象都没有创建，如何确定这个泛型参数是何种类型，所以当然是错误的。</p>\n<p>但是要注意区分下面的一种情况：</p>\n<pre><code class=\"java\">public class Test2&lt;T&gt; {    \n\n    public static &lt;T &gt;T show(T one){ //这是正确的    \n        return null;    \n    }    \n}</code></pre>\n<p>因为这是一个泛型方法，在泛型方法中使用的T是自己在方法中定义的 T，而不是泛型类中的T。</p>\n"},{"title":"DDD","excerpt":"","comments":1,"date":"2022-03-10T10:30:52.000Z","_content":"\nDDD不是什么新鲜玩意，早在2004年著名建模专家eric evans在其书籍《领域驱动设计—软件核心复杂性应对之道》就提出了。\n\n不过那时候，国内软件业务还没有这么复杂，没有人在意软件设计。\n\n## 杜绝软件退化，两顶帽子\n\n随着软件行业的发展，软件规模越来越大，业务越来越复杂，代码越来越多，越来越乱，屎山就是这么来的……\n\n于是微服务来了，小而专，高内聚。\n\n软件设计质量最高的时候，就是第一版设计。从那之后的每一次需求变更，就开始打乱、破坏之前的设计，随着时间的推迟，维护成本越来越高。\n\n开放-封闭原则：\n- 开放原则：对功能扩展是开放的，当系统需求发生变更时，可以对软件功能进行扩展，使其满足用户新的需求。open for extension\n- 封闭原则：对代码的修改是封闭的，在修改软件的同时，不要影响到系统原有的功能，所以应当在不修改原有代码的基础上实现新功能。close for modification\n\n**软件的本质就是对真实世界的模拟，软件中业务逻辑是否正确的唯一标准就是是否与真实世界一致。**\n\n比如一段电商行业支付相关的代码，一个PayService中有一个payOff方法，初版的需求就是一个简单的根基商品的总价进行支付，但是新需求来了，要求支持各种折扣功能（限时折扣、限量折扣、对某种商品折扣、对某个商品折扣、不折扣）。如果上来就干，可能就是一顿if/else，判断折扣类型计算支付金额。这样的代码，就增加了维护的难度，当更多这样的代码聚集到一起的时候，几百上千行的支付方法，会让开发者难以下手。\n\n如果调整软件的程序结构，由简单的程序结构转变为复杂的程序结构，对应着现实世界的简单需求转变为复杂需求。\n\n要保持软件设计质量不退化，必须在每次需求变更的时候，对原有的程序结构适当的进行调整。\n\n在实现新需求时，要采用两顶帽子的方式：\n1. 在不添加新功能的前提下，重构代码，调整原有程序结构，以适应新功能\n2. 实现新的功能\n\n还是上面的需求，如果不动之前的代码，而是给PayService增加接口，payOff方法实现各不相同。如果后期那种折扣需求变化，就修改哪个实现类；如果后期要增加折扣方式，就增加实现类。\n\n如果每次的灵活设计只能应对一种需求变更，其实作用不大，最后的结果可能是我们期望的变化没有发生，所做的设计都成了摆设，这次设计也就成了过度设计。每次设计应该只为当前的需求设计，使其刚刚满足当前需求。\n\n每次变更，都还原到真实世界中，根据真实世界进行设计。\n\n像图中描述的，将真实世界和软件世界联系起来\n\n<img src=\"entity_model.png\">\n\n- 真实世界有什么事物，软件世界就有什么对象\n- 真实世界的事物有什么行为，软件世界的对象就有什么方法\n- 真实世界的事物间有什么关系，软件世界中对象就有什么关联\n\n软件发展的规律就是逐步由简单软件向复杂软件转变，在这个过程中，需要有两顶帽子，适时的对程序结构进行调整，再实现新需求，只有这样才能保证软件不退化。关于具体两顶帽子怎么做，DDD给了思路：每次变更时，先回到领域模型，基于业务进行领域模型的变更，然后再根据领域模型的变更指导程序的变更。\n\n## 单一指责原则\n\n**单一指责原则：软件系统中的每个元素只完成自己职责范围内的事，而将其他的事交给别人去做，我只是去调用**\n\n一个指责就是软件变化的原因。\n\n什么事高质量的代码？**当用户提出一个需求时，为了实现这个变更而修改软件的成本越低，软件设计的质量就越高**\n怎样才能在每次变更的时候都只修改一个模块就能实现需求呢？需要平时不断的整理代码，将因同一个原因而变更的代码都放到一起，将不同原因而变更的代码放在不同的模块，不同的类中。这样当因为一个原因而修改代码时，需要修改的代码都在同一个模块、同一个类中，修改范围就小了。维护成本降低了，设计质量就提高了。\n\n单一指责原则要求我们在维护软件的过程中不断的整理代码，将软件变化同一个原因的代码放在一起，将软件变化不同原因的代码分开放。\n\n## DDD在数据库设计上的落地\n\n领域模型设计是需求分析人员和设计开发人员共同的产物\n\n    领域对象持久化存储的设计思想：\n    将暂时不用的领域对象从内存中持久化到磁盘中，再次使用这个领域对象时，通过key值到数据库查找到这条记录，将其恢复成领域对象，应用程序继续使用它。以后数据库就没必要用关系型数据库了，可以通过nosql或者大数据平台，数据库的设计也可能不用遵守第三范式了，日后系统大数据转型的时候成本就更低了。\n\nDDD的数据库设计变成了**以领域模型为核心，如何将领域模型转换成数据库设计的过程**\n\n也就是程序中的类转换成数据库的表的过程。\n\n- 在设计过程中，领域模型中，不论对象还是属性，在命名时都采用中文\n- 在数据库设计时，要细化为英文命名，或者汉语拼音首字母，同时要确定字段类型与是否为空等其他属性。\n\n如果将领域模型中的继承关系转换成数据库设计呢？\n1. 如果继承关系的子类不多，并且每个子类的个性化字段不多，则可以用一个表来表示这种继承关系，用一个字段（类型）标识这条记录属于哪个子类，这个字段前面罗列的时父类的字段，这个字段的后面依次罗列各个子类的个性化字段，这样的优点时比较简单，整个继承关系的数据全部保存在这个表里，但是如果子类个性化字段太多，或导致很多字段为空，浪费空间，造成“表稀疏”。\n2. 设计为多个表，父类的字段在每个表中都冗余，每个表的主键相同。如果业务总是将各个子类分开查询，这种设计就很合适，但是如果业务需要同时查询多个子类的数据，这种情况就不合适了。\n3. 如果多种类型需要同时查询，而且各个字表的个性化字段比较多，前两种方法都不合适的时候，可以采用将父类字段作为一个表，各个子类分别有各自的表，主键与父表相同，当分页查询的时候，只查询父类的表，当查看详细信息的时候，再根据主键和类型字段去查询子类的表。\n\n关系型数据库和NoSQL数据库：\n- 我们平常用的还是mysql这种关系型数据库，遵循第三范式，使得数据库能够大幅度降低冗余，但数据库查询需要频繁使用join操作，在高并发场景下性能地下\n- 将需要join的查询在写入数据表前先进行join操作，直接写到一张单表中进行分布式存储，这张表称为“宽表”\n\nNoSQL数据库在设计时的套路就是尽量在单表中存储更多的字段，避免数据查询中的join操作，即使有很多字段是空的，也不会占用字段。\n\n**因为NoSQL一版都是no schema的，而且空字段在序列化是就被过滤掉了，不会持久化到硬盘，也不存在所谓的浪费空间，所以继承关系就直接使用上面第一中方法就可以了。**\n\n\n## 领域模型如何指导程序设计\n\n**服务**：标识的是在领域对象之外的操作和行为，接受用户的请求和执行某些操作。当用户在系统界面操作，会向系统发起请求，“服务”去接收这些请求，然后根据需求去执行相应的方法，也就是操作实体和值对象，在所有的操作完成后，将实体和值对象持久化到数据库中。\n\n\n**实体**：通过一个唯一标识字段来区分真实世界中的每一个个体的领域对象。\n\n**值对象**：代表的是真实世界中那些一成不变的、本质性的事物，这样的领域对象叫做“值对象”。\n\n    可变性是实体的特点，不变性是值对象的本质。\n\n将业务领域模型转换为程序设计思路：\n- 贫血模型\n- 充血模型\n\n贫血模型，就是在软件设计中，有很多POJO对象，它们除了有一堆get/set方法，几乎没有任何业务逻辑。pojo对象去调用对应的service去完成业务逻辑。\n\n充血模型，在领域对象中直接实现业务的逻辑操作。\n\n充血模型保持了领域模型的原貌，可以比较直接地映射成程序的变更，代码修改起来比较直接。保持了对象的封装性，使得领域模型在面临多态、继承能复杂结构时，易于变更。\n\n贫血模型相对充血模型更加简单易行，充血模型对设计和架构能力要求更高。\n\n简单来说：贫血模型的业务逻辑在service中实现，充血模型的业务逻辑在领域对象中实现\n\n取长补短，合理使用：\n**将需要封装的业务逻辑放到领域对象中，按照充血模型去设计；除此之外的其他业务逻辑放到service中，按照贫血模型去设计**\n\n哪些业务逻辑要用充血模型：\n- 在领域模型中出现了类似继承、多态的情况\n- 在软件设计的过程中需要将一些类型或者编码进行转换\n- 希望在软件设计中能更好地表现领域对象之间的关系\n- “聚合”，在真实世界中那些代表整体与部分的事物\n\n\n**聚合**：表达的是真实世界中整体与部分的关系，比如订单与订单明细。一般代码中都会将订单明细对象集合作为订单对象的一个属性，也就是将订单明细聚合到了订单中。使用时就只拿到一个订单对象，订单明细作为订单的属性来使用，对于调用方，感知不到明细对象的存在。当整体不存在时，部分就变的没有意义。整体被称为**聚合根**，是外部访问的唯一入口。增删改的业务可以采用领域驱动设计，只能通过聚合根来访问数据，但是在分析汇总场景下，直接使用sql查询。\n\n**仓库Repository**：领域驱动设计会实现一个仓库（Repository）去完成对数据库的操作。比如创建订单时，把新增订单和新增订单明细两个操作放到同一个事务中，就是将OrderDao#insert和OrderItemDao#insertList放到同一个事务中，供外部调用。\n\n**工厂**：与设计模式中的工厂不同。设计模式中的工厂是将被调用方设计成一个接口下的多个实现，将这些实现放入工厂中，工厂负责通过key找到对应的实现类，创建出来，返回给调用方，从而降低了调用方与被调方的耦合度。而DDD中的工厂是装配创建领域对象，是领域对象生命周期的起点。比如系统要根据ID装载一个订单，订单仓库将任务交给订单工厂，订单工厂分别调用订单DAO、订单明细DAO、用户DAO去进行查询，将订单明细对象和用户对象分别set到订单对象的订单明细和用户属性中，订单工厂将装配好的订单对象返回给订单仓库。\n\nDDD的仓库应该被抽象成一个存放领域对象的地方，一般情况下，我们将数据持久化到数据库，是一种实现。所以为了可以快速装载，或者最近会重复使用同一个领域对象，仓库可以实现缓存的功能，当客户程序需要获取某个领域对象时，可以先到缓存中获取。\n\n通过仓库与工厂，对原有的DAO进行了一层封装，在保存、装载、查询等操作时，加入了聚合、装备等操作，并将这些操作封装起来，对上层的客户程序屏蔽。\n\n**工厂和仓库是聚合的实现。传统DAO的设计是一种贫血设计，而工厂和仓库的设计是一种充血设计。**\n\n\n\n## 如何进行领域驱动设计\n\n业务总是有不同的场景，每种场景下的领域对象也各不相同，领域对象之间会相互联系。正确的设计思路应该是将整个系统划分为许多相对独立的业务场景，在一个一个业务场景中进行领域分析与建模，这样的业务场景被称为“问题子域”。\n\n领域驱动核心的设计思想就是将软件的分析与设计还原到真实世界中，真实世界中的业务与问题叫做“问题域”，业务逻辑与知识叫“业务领域知识”。\n\n比如：\n\n电商网站的问题域：用户如何进行在线购物，购物的流程是怎样的。\n在线订餐系统的问题域：用户如何在线订餐，饭店如何在线接单，系统如何分配骑士配送。\n\n而电商网站又能拆分出用户选购、下单、支付、物流等多个子域，订餐系统也能拆分出用户下单、饭店接单、其实配送等子域。如果一个子域比较复杂，我们还能将一个子域拆封成更多的子域。\n\n一个复杂系统的领域驱动设计，就是以子域为中心，进行领域建模，绘制出一张张的领域模型设计，称之为“限界上下文”（Context Bounds，CB）。\n\nDDD的限界上下文的设计，就体现了高质量软件设计中“单一职责原则“，也就是每个限界上下文中实现的都是软件变化同一个原因的业务。如果用户下单限界上下文有业务变化，还需要对它进行修改就行了，与其他限界上下文无关，这样就缩小了代码修改的范围，维护成本就降低了。\n\n限界上下文之间存在相互关系，这种关系被称为“上下文地图（Context Map）”。\n\n限界上下文之间可能存在的关系：\n- 合作关系（Partnership）：两个上下文紧密合作的关系，一荣俱荣，一损俱损\n- 共享内核（shared kernel）：两个上下文依赖部分共享的模型\n- 客户方-供应方开发（Customer-Supplier Development）：上下文之间有组织的上下游依赖\n- 遵奉者（Conformist）：下游上下文只能盲从上游上下文\n- 防腐层（Anticorruption Layer）：一个上下文通过一些适配和转换与另一个上下文交互\n- 开放主机服务（Open Host Service）：定义一种协议来让其他上下文来对本上下文进行访问\n- 发布语言（Published Language）：通常与OHS一起使用，用于定义开放主机的协议。\n- 大泥球（big ball of mud）：混杂在一起的上下文关系，边界不清晰。\n- 另谋他路（SeparateWay）：两个完全没有任何关系的上下文。\n\n比如用户下单上下文中，存在用户信息的读取，但是用户信息读取不应该在用户下单上下文中实现，因为用户下单业务的变更，不应该影响用户信息读取，所以用户信息的操作应该交给“用户信息管理”上下文，用户下单上下文只需要调用用户信息管理的用户信息读取接口。这个调用关系就是上下文地图的一部分。\n\n**限界上下文内的高内聚**，每个限界上下文内实现的功能，都是软件变化的同一个原因的代码，因为这个原因的变化，才需要修改这个限界上下文。\n\n**限界上下文可以作为拆分微服务的原则，每个限界上下文对应一个微服务。这样在日后的每次需求变更时，可以快速的落到某个微服务中变更，实现了低成本维护和快 速交付**\n\n比如电商系统，根据限界上下文拆分出商品、购物、下单、支付、物流等微服务。\n\n**限界上下文间的低耦合**，限界上下文通过上下文地图相互调用时，通过接口进行调用。通过接口解开调用方与被调用方之间的耦合。\n\n通过微服务来实现“限界上下文”之间的低耦合，比如下单微服务需要调用支付微服务，首先在下单微服务中增加支付接口，在下单微服务中，所有对支付服务的调用都是对其支付接口的调用，接着在其他支付微服务中实现支付，比如现在设计了微信支付微服务和支付宝支付微服务，在系统运行时，需要那种支付方式，就调用哪个支付微服务，这样下单和支付之间的耦合就被解开了。\n\n## 如何解决微服务拆分难题\n\n**微服务做到小而专、高内聚的最佳实践是DDD**\n\n- 从DDD开始需求分析、领域建模，逐渐建立起多个问题子域\n- 将问题子域落实到限界上下文，它们之间的关系形成上下文地图\n- 各子域落实到微服务中贫血模型或充血模型的设计，从而在微服务之间依据上下文地图形成接口\n\n微服务设计最核心的难题是微服务的拆分，讲究小而专的设计，要低耦合、高内聚。\n\n**领域驱动设计解决微服务如何拆分，实现微服务的高内聚于单一职责的问题**\n\n**如何破局需求分析的困境？**\n\n统一语言建模，技术去了解业务，咨询客户，探讨业务。注意捕获专业术语，学会用这些术语沟通。\n\n召开事件风暴会议，在产品经理的引导下，业务和研发一起建模\n\n事件风暴会议，要梳理当前业务中有哪些领域事件，命名时应当采取过去时态。领域事件时已经发生而且需要保存的事件。 \n\n**微服务拆分原则--微服务内高内聚、微服务间低耦合**\n\n- 微服务内高内聚，就是单一职责原则，将代码修改的范围缩小到这个微服务内。\n- 微服务间低耦合，在微服务实现自身业务的过程中，如果需要执行的某些过程不是自己的职责，应当将这些过程交给其他微服务去实现，你只要对它的接口进行调用。\n\n通过DDD进行业务建模，再基于领域模型进行限界上下文划分\n能保证系统的设计，在限界上下文内高内聚，在限界上下文间低耦合。\n\n**领域建模**是将一个系统划分成了多个子域，每个子域都是一个独立的业务场景，每个子域的实现就是“限界上下文”，他们之间的关联关系就是“上下文地图 ”\n\n\n\n\n\n# 领域驱动模型实战\n\n- DP：domain primivate，抽象并封装自检和一些隐性属性的计算逻辑，且这些属性是无状态的。\n- Entity：抽象并封装单对象有状态的逻辑。\n- Domain Service：抽象并封装多对象的有状态逻辑。\n- Repository：抽象并封装外部数据访问的逻辑。\n\n步骤：\n1. 首先对需要处理的业务问题进行总览。UL 统一语言建模\n2. 然后领域驱动对象（Entity）进行划分，明确每个领域驱动对象的包含的信息和职责边界。并进行跨对象，多对象的逻辑组织。\n3. 接着在上层应用中根据业务描述去编排Entity和Domain Service。\n4. 最后再做一些下水道工作，去对下层的数据访问、RPC调用做具体实现。\n\n\n\n\n\n\nhttps://www.bilibili.com/video/BV1PM4y1L7Nh?p=7  10:30\n","source":"_posts/2022-03-10-kongzheng1993-DDD.md","raw":"---\ntitle: DDD\nexcerpt: '架构'\ntags: [架构]\ncategories: [架构]\ncomments: true\ndate: 2022-03-10 18:30:52\n---\n\nDDD不是什么新鲜玩意，早在2004年著名建模专家eric evans在其书籍《领域驱动设计—软件核心复杂性应对之道》就提出了。\n\n不过那时候，国内软件业务还没有这么复杂，没有人在意软件设计。\n\n## 杜绝软件退化，两顶帽子\n\n随着软件行业的发展，软件规模越来越大，业务越来越复杂，代码越来越多，越来越乱，屎山就是这么来的……\n\n于是微服务来了，小而专，高内聚。\n\n软件设计质量最高的时候，就是第一版设计。从那之后的每一次需求变更，就开始打乱、破坏之前的设计，随着时间的推迟，维护成本越来越高。\n\n开放-封闭原则：\n- 开放原则：对功能扩展是开放的，当系统需求发生变更时，可以对软件功能进行扩展，使其满足用户新的需求。open for extension\n- 封闭原则：对代码的修改是封闭的，在修改软件的同时，不要影响到系统原有的功能，所以应当在不修改原有代码的基础上实现新功能。close for modification\n\n**软件的本质就是对真实世界的模拟，软件中业务逻辑是否正确的唯一标准就是是否与真实世界一致。**\n\n比如一段电商行业支付相关的代码，一个PayService中有一个payOff方法，初版的需求就是一个简单的根基商品的总价进行支付，但是新需求来了，要求支持各种折扣功能（限时折扣、限量折扣、对某种商品折扣、对某个商品折扣、不折扣）。如果上来就干，可能就是一顿if/else，判断折扣类型计算支付金额。这样的代码，就增加了维护的难度，当更多这样的代码聚集到一起的时候，几百上千行的支付方法，会让开发者难以下手。\n\n如果调整软件的程序结构，由简单的程序结构转变为复杂的程序结构，对应着现实世界的简单需求转变为复杂需求。\n\n要保持软件设计质量不退化，必须在每次需求变更的时候，对原有的程序结构适当的进行调整。\n\n在实现新需求时，要采用两顶帽子的方式：\n1. 在不添加新功能的前提下，重构代码，调整原有程序结构，以适应新功能\n2. 实现新的功能\n\n还是上面的需求，如果不动之前的代码，而是给PayService增加接口，payOff方法实现各不相同。如果后期那种折扣需求变化，就修改哪个实现类；如果后期要增加折扣方式，就增加实现类。\n\n如果每次的灵活设计只能应对一种需求变更，其实作用不大，最后的结果可能是我们期望的变化没有发生，所做的设计都成了摆设，这次设计也就成了过度设计。每次设计应该只为当前的需求设计，使其刚刚满足当前需求。\n\n每次变更，都还原到真实世界中，根据真实世界进行设计。\n\n像图中描述的，将真实世界和软件世界联系起来\n\n<img src=\"entity_model.png\">\n\n- 真实世界有什么事物，软件世界就有什么对象\n- 真实世界的事物有什么行为，软件世界的对象就有什么方法\n- 真实世界的事物间有什么关系，软件世界中对象就有什么关联\n\n软件发展的规律就是逐步由简单软件向复杂软件转变，在这个过程中，需要有两顶帽子，适时的对程序结构进行调整，再实现新需求，只有这样才能保证软件不退化。关于具体两顶帽子怎么做，DDD给了思路：每次变更时，先回到领域模型，基于业务进行领域模型的变更，然后再根据领域模型的变更指导程序的变更。\n\n## 单一指责原则\n\n**单一指责原则：软件系统中的每个元素只完成自己职责范围内的事，而将其他的事交给别人去做，我只是去调用**\n\n一个指责就是软件变化的原因。\n\n什么事高质量的代码？**当用户提出一个需求时，为了实现这个变更而修改软件的成本越低，软件设计的质量就越高**\n怎样才能在每次变更的时候都只修改一个模块就能实现需求呢？需要平时不断的整理代码，将因同一个原因而变更的代码都放到一起，将不同原因而变更的代码放在不同的模块，不同的类中。这样当因为一个原因而修改代码时，需要修改的代码都在同一个模块、同一个类中，修改范围就小了。维护成本降低了，设计质量就提高了。\n\n单一指责原则要求我们在维护软件的过程中不断的整理代码，将软件变化同一个原因的代码放在一起，将软件变化不同原因的代码分开放。\n\n## DDD在数据库设计上的落地\n\n领域模型设计是需求分析人员和设计开发人员共同的产物\n\n    领域对象持久化存储的设计思想：\n    将暂时不用的领域对象从内存中持久化到磁盘中，再次使用这个领域对象时，通过key值到数据库查找到这条记录，将其恢复成领域对象，应用程序继续使用它。以后数据库就没必要用关系型数据库了，可以通过nosql或者大数据平台，数据库的设计也可能不用遵守第三范式了，日后系统大数据转型的时候成本就更低了。\n\nDDD的数据库设计变成了**以领域模型为核心，如何将领域模型转换成数据库设计的过程**\n\n也就是程序中的类转换成数据库的表的过程。\n\n- 在设计过程中，领域模型中，不论对象还是属性，在命名时都采用中文\n- 在数据库设计时，要细化为英文命名，或者汉语拼音首字母，同时要确定字段类型与是否为空等其他属性。\n\n如果将领域模型中的继承关系转换成数据库设计呢？\n1. 如果继承关系的子类不多，并且每个子类的个性化字段不多，则可以用一个表来表示这种继承关系，用一个字段（类型）标识这条记录属于哪个子类，这个字段前面罗列的时父类的字段，这个字段的后面依次罗列各个子类的个性化字段，这样的优点时比较简单，整个继承关系的数据全部保存在这个表里，但是如果子类个性化字段太多，或导致很多字段为空，浪费空间，造成“表稀疏”。\n2. 设计为多个表，父类的字段在每个表中都冗余，每个表的主键相同。如果业务总是将各个子类分开查询，这种设计就很合适，但是如果业务需要同时查询多个子类的数据，这种情况就不合适了。\n3. 如果多种类型需要同时查询，而且各个字表的个性化字段比较多，前两种方法都不合适的时候，可以采用将父类字段作为一个表，各个子类分别有各自的表，主键与父表相同，当分页查询的时候，只查询父类的表，当查看详细信息的时候，再根据主键和类型字段去查询子类的表。\n\n关系型数据库和NoSQL数据库：\n- 我们平常用的还是mysql这种关系型数据库，遵循第三范式，使得数据库能够大幅度降低冗余，但数据库查询需要频繁使用join操作，在高并发场景下性能地下\n- 将需要join的查询在写入数据表前先进行join操作，直接写到一张单表中进行分布式存储，这张表称为“宽表”\n\nNoSQL数据库在设计时的套路就是尽量在单表中存储更多的字段，避免数据查询中的join操作，即使有很多字段是空的，也不会占用字段。\n\n**因为NoSQL一版都是no schema的，而且空字段在序列化是就被过滤掉了，不会持久化到硬盘，也不存在所谓的浪费空间，所以继承关系就直接使用上面第一中方法就可以了。**\n\n\n## 领域模型如何指导程序设计\n\n**服务**：标识的是在领域对象之外的操作和行为，接受用户的请求和执行某些操作。当用户在系统界面操作，会向系统发起请求，“服务”去接收这些请求，然后根据需求去执行相应的方法，也就是操作实体和值对象，在所有的操作完成后，将实体和值对象持久化到数据库中。\n\n\n**实体**：通过一个唯一标识字段来区分真实世界中的每一个个体的领域对象。\n\n**值对象**：代表的是真实世界中那些一成不变的、本质性的事物，这样的领域对象叫做“值对象”。\n\n    可变性是实体的特点，不变性是值对象的本质。\n\n将业务领域模型转换为程序设计思路：\n- 贫血模型\n- 充血模型\n\n贫血模型，就是在软件设计中，有很多POJO对象，它们除了有一堆get/set方法，几乎没有任何业务逻辑。pojo对象去调用对应的service去完成业务逻辑。\n\n充血模型，在领域对象中直接实现业务的逻辑操作。\n\n充血模型保持了领域模型的原貌，可以比较直接地映射成程序的变更，代码修改起来比较直接。保持了对象的封装性，使得领域模型在面临多态、继承能复杂结构时，易于变更。\n\n贫血模型相对充血模型更加简单易行，充血模型对设计和架构能力要求更高。\n\n简单来说：贫血模型的业务逻辑在service中实现，充血模型的业务逻辑在领域对象中实现\n\n取长补短，合理使用：\n**将需要封装的业务逻辑放到领域对象中，按照充血模型去设计；除此之外的其他业务逻辑放到service中，按照贫血模型去设计**\n\n哪些业务逻辑要用充血模型：\n- 在领域模型中出现了类似继承、多态的情况\n- 在软件设计的过程中需要将一些类型或者编码进行转换\n- 希望在软件设计中能更好地表现领域对象之间的关系\n- “聚合”，在真实世界中那些代表整体与部分的事物\n\n\n**聚合**：表达的是真实世界中整体与部分的关系，比如订单与订单明细。一般代码中都会将订单明细对象集合作为订单对象的一个属性，也就是将订单明细聚合到了订单中。使用时就只拿到一个订单对象，订单明细作为订单的属性来使用，对于调用方，感知不到明细对象的存在。当整体不存在时，部分就变的没有意义。整体被称为**聚合根**，是外部访问的唯一入口。增删改的业务可以采用领域驱动设计，只能通过聚合根来访问数据，但是在分析汇总场景下，直接使用sql查询。\n\n**仓库Repository**：领域驱动设计会实现一个仓库（Repository）去完成对数据库的操作。比如创建订单时，把新增订单和新增订单明细两个操作放到同一个事务中，就是将OrderDao#insert和OrderItemDao#insertList放到同一个事务中，供外部调用。\n\n**工厂**：与设计模式中的工厂不同。设计模式中的工厂是将被调用方设计成一个接口下的多个实现，将这些实现放入工厂中，工厂负责通过key找到对应的实现类，创建出来，返回给调用方，从而降低了调用方与被调方的耦合度。而DDD中的工厂是装配创建领域对象，是领域对象生命周期的起点。比如系统要根据ID装载一个订单，订单仓库将任务交给订单工厂，订单工厂分别调用订单DAO、订单明细DAO、用户DAO去进行查询，将订单明细对象和用户对象分别set到订单对象的订单明细和用户属性中，订单工厂将装配好的订单对象返回给订单仓库。\n\nDDD的仓库应该被抽象成一个存放领域对象的地方，一般情况下，我们将数据持久化到数据库，是一种实现。所以为了可以快速装载，或者最近会重复使用同一个领域对象，仓库可以实现缓存的功能，当客户程序需要获取某个领域对象时，可以先到缓存中获取。\n\n通过仓库与工厂，对原有的DAO进行了一层封装，在保存、装载、查询等操作时，加入了聚合、装备等操作，并将这些操作封装起来，对上层的客户程序屏蔽。\n\n**工厂和仓库是聚合的实现。传统DAO的设计是一种贫血设计，而工厂和仓库的设计是一种充血设计。**\n\n\n\n## 如何进行领域驱动设计\n\n业务总是有不同的场景，每种场景下的领域对象也各不相同，领域对象之间会相互联系。正确的设计思路应该是将整个系统划分为许多相对独立的业务场景，在一个一个业务场景中进行领域分析与建模，这样的业务场景被称为“问题子域”。\n\n领域驱动核心的设计思想就是将软件的分析与设计还原到真实世界中，真实世界中的业务与问题叫做“问题域”，业务逻辑与知识叫“业务领域知识”。\n\n比如：\n\n电商网站的问题域：用户如何进行在线购物，购物的流程是怎样的。\n在线订餐系统的问题域：用户如何在线订餐，饭店如何在线接单，系统如何分配骑士配送。\n\n而电商网站又能拆分出用户选购、下单、支付、物流等多个子域，订餐系统也能拆分出用户下单、饭店接单、其实配送等子域。如果一个子域比较复杂，我们还能将一个子域拆封成更多的子域。\n\n一个复杂系统的领域驱动设计，就是以子域为中心，进行领域建模，绘制出一张张的领域模型设计，称之为“限界上下文”（Context Bounds，CB）。\n\nDDD的限界上下文的设计，就体现了高质量软件设计中“单一职责原则“，也就是每个限界上下文中实现的都是软件变化同一个原因的业务。如果用户下单限界上下文有业务变化，还需要对它进行修改就行了，与其他限界上下文无关，这样就缩小了代码修改的范围，维护成本就降低了。\n\n限界上下文之间存在相互关系，这种关系被称为“上下文地图（Context Map）”。\n\n限界上下文之间可能存在的关系：\n- 合作关系（Partnership）：两个上下文紧密合作的关系，一荣俱荣，一损俱损\n- 共享内核（shared kernel）：两个上下文依赖部分共享的模型\n- 客户方-供应方开发（Customer-Supplier Development）：上下文之间有组织的上下游依赖\n- 遵奉者（Conformist）：下游上下文只能盲从上游上下文\n- 防腐层（Anticorruption Layer）：一个上下文通过一些适配和转换与另一个上下文交互\n- 开放主机服务（Open Host Service）：定义一种协议来让其他上下文来对本上下文进行访问\n- 发布语言（Published Language）：通常与OHS一起使用，用于定义开放主机的协议。\n- 大泥球（big ball of mud）：混杂在一起的上下文关系，边界不清晰。\n- 另谋他路（SeparateWay）：两个完全没有任何关系的上下文。\n\n比如用户下单上下文中，存在用户信息的读取，但是用户信息读取不应该在用户下单上下文中实现，因为用户下单业务的变更，不应该影响用户信息读取，所以用户信息的操作应该交给“用户信息管理”上下文，用户下单上下文只需要调用用户信息管理的用户信息读取接口。这个调用关系就是上下文地图的一部分。\n\n**限界上下文内的高内聚**，每个限界上下文内实现的功能，都是软件变化的同一个原因的代码，因为这个原因的变化，才需要修改这个限界上下文。\n\n**限界上下文可以作为拆分微服务的原则，每个限界上下文对应一个微服务。这样在日后的每次需求变更时，可以快速的落到某个微服务中变更，实现了低成本维护和快 速交付**\n\n比如电商系统，根据限界上下文拆分出商品、购物、下单、支付、物流等微服务。\n\n**限界上下文间的低耦合**，限界上下文通过上下文地图相互调用时，通过接口进行调用。通过接口解开调用方与被调用方之间的耦合。\n\n通过微服务来实现“限界上下文”之间的低耦合，比如下单微服务需要调用支付微服务，首先在下单微服务中增加支付接口，在下单微服务中，所有对支付服务的调用都是对其支付接口的调用，接着在其他支付微服务中实现支付，比如现在设计了微信支付微服务和支付宝支付微服务，在系统运行时，需要那种支付方式，就调用哪个支付微服务，这样下单和支付之间的耦合就被解开了。\n\n## 如何解决微服务拆分难题\n\n**微服务做到小而专、高内聚的最佳实践是DDD**\n\n- 从DDD开始需求分析、领域建模，逐渐建立起多个问题子域\n- 将问题子域落实到限界上下文，它们之间的关系形成上下文地图\n- 各子域落实到微服务中贫血模型或充血模型的设计，从而在微服务之间依据上下文地图形成接口\n\n微服务设计最核心的难题是微服务的拆分，讲究小而专的设计，要低耦合、高内聚。\n\n**领域驱动设计解决微服务如何拆分，实现微服务的高内聚于单一职责的问题**\n\n**如何破局需求分析的困境？**\n\n统一语言建模，技术去了解业务，咨询客户，探讨业务。注意捕获专业术语，学会用这些术语沟通。\n\n召开事件风暴会议，在产品经理的引导下，业务和研发一起建模\n\n事件风暴会议，要梳理当前业务中有哪些领域事件，命名时应当采取过去时态。领域事件时已经发生而且需要保存的事件。 \n\n**微服务拆分原则--微服务内高内聚、微服务间低耦合**\n\n- 微服务内高内聚，就是单一职责原则，将代码修改的范围缩小到这个微服务内。\n- 微服务间低耦合，在微服务实现自身业务的过程中，如果需要执行的某些过程不是自己的职责，应当将这些过程交给其他微服务去实现，你只要对它的接口进行调用。\n\n通过DDD进行业务建模，再基于领域模型进行限界上下文划分\n能保证系统的设计，在限界上下文内高内聚，在限界上下文间低耦合。\n\n**领域建模**是将一个系统划分成了多个子域，每个子域都是一个独立的业务场景，每个子域的实现就是“限界上下文”，他们之间的关联关系就是“上下文地图 ”\n\n\n\n\n\n# 领域驱动模型实战\n\n- DP：domain primivate，抽象并封装自检和一些隐性属性的计算逻辑，且这些属性是无状态的。\n- Entity：抽象并封装单对象有状态的逻辑。\n- Domain Service：抽象并封装多对象的有状态逻辑。\n- Repository：抽象并封装外部数据访问的逻辑。\n\n步骤：\n1. 首先对需要处理的业务问题进行总览。UL 统一语言建模\n2. 然后领域驱动对象（Entity）进行划分，明确每个领域驱动对象的包含的信息和职责边界。并进行跨对象，多对象的逻辑组织。\n3. 接着在上层应用中根据业务描述去编排Entity和Domain Service。\n4. 最后再做一些下水道工作，去对下层的数据访问、RPC调用做具体实现。\n\n\n\n\n\n\nhttps://www.bilibili.com/video/BV1PM4y1L7Nh?p=7  10:30\n","slug":"kongzheng1993-DDD","published":1,"updated":"2023-03-08T07:05:58.824Z","layout":"post","photos":[],"link":"","_id":"clg0k2as300j9t26fq5g7k4yg","content":"<p>DDD不是什么新鲜玩意，早在2004年著名建模专家eric evans在其书籍《领域驱动设计—软件核心复杂性应对之道》就提出了。</p>\n<p>不过那时候，国内软件业务还没有这么复杂，没有人在意软件设计。</p>\n<h2 id=\"杜绝软件退化，两顶帽子\"><a href=\"#杜绝软件退化，两顶帽子\" class=\"headerlink\" title=\"杜绝软件退化，两顶帽子\"></a>杜绝软件退化，两顶帽子</h2><p>随着软件行业的发展，软件规模越来越大，业务越来越复杂，代码越来越多，越来越乱，屎山就是这么来的……</p>\n<p>于是微服务来了，小而专，高内聚。</p>\n<p>软件设计质量最高的时候，就是第一版设计。从那之后的每一次需求变更，就开始打乱、破坏之前的设计，随着时间的推迟，维护成本越来越高。</p>\n<p>开放-封闭原则：</p>\n<ul>\n<li>开放原则：对功能扩展是开放的，当系统需求发生变更时，可以对软件功能进行扩展，使其满足用户新的需求。open for extension</li>\n<li>封闭原则：对代码的修改是封闭的，在修改软件的同时，不要影响到系统原有的功能，所以应当在不修改原有代码的基础上实现新功能。close for modification</li>\n</ul>\n<p><strong>软件的本质就是对真实世界的模拟，软件中业务逻辑是否正确的唯一标准就是是否与真实世界一致。</strong></p>\n<p>比如一段电商行业支付相关的代码，一个PayService中有一个payOff方法，初版的需求就是一个简单的根基商品的总价进行支付，但是新需求来了，要求支持各种折扣功能（限时折扣、限量折扣、对某种商品折扣、对某个商品折扣、不折扣）。如果上来就干，可能就是一顿if/else，判断折扣类型计算支付金额。这样的代码，就增加了维护的难度，当更多这样的代码聚集到一起的时候，几百上千行的支付方法，会让开发者难以下手。</p>\n<p>如果调整软件的程序结构，由简单的程序结构转变为复杂的程序结构，对应着现实世界的简单需求转变为复杂需求。</p>\n<p>要保持软件设计质量不退化，必须在每次需求变更的时候，对原有的程序结构适当的进行调整。</p>\n<p>在实现新需求时，要采用两顶帽子的方式：</p>\n<ol>\n<li>在不添加新功能的前提下，重构代码，调整原有程序结构，以适应新功能</li>\n<li>实现新的功能</li>\n</ol>\n<p>还是上面的需求，如果不动之前的代码，而是给PayService增加接口，payOff方法实现各不相同。如果后期那种折扣需求变化，就修改哪个实现类；如果后期要增加折扣方式，就增加实现类。</p>\n<p>如果每次的灵活设计只能应对一种需求变更，其实作用不大，最后的结果可能是我们期望的变化没有发生，所做的设计都成了摆设，这次设计也就成了过度设计。每次设计应该只为当前的需求设计，使其刚刚满足当前需求。</p>\n<p>每次变更，都还原到真实世界中，根据真实世界进行设计。</p>\n<p>像图中描述的，将真实世界和软件世界联系起来</p>\n<img src=\"/2022/03/10/kongzheng1993-DDD/entity_model.png\">\n\n<ul>\n<li>真实世界有什么事物，软件世界就有什么对象</li>\n<li>真实世界的事物有什么行为，软件世界的对象就有什么方法</li>\n<li>真实世界的事物间有什么关系，软件世界中对象就有什么关联</li>\n</ul>\n<p>软件发展的规律就是逐步由简单软件向复杂软件转变，在这个过程中，需要有两顶帽子，适时的对程序结构进行调整，再实现新需求，只有这样才能保证软件不退化。关于具体两顶帽子怎么做，DDD给了思路：每次变更时，先回到领域模型，基于业务进行领域模型的变更，然后再根据领域模型的变更指导程序的变更。</p>\n<h2 id=\"单一指责原则\"><a href=\"#单一指责原则\" class=\"headerlink\" title=\"单一指责原则\"></a>单一指责原则</h2><p><strong>单一指责原则：软件系统中的每个元素只完成自己职责范围内的事，而将其他的事交给别人去做，我只是去调用</strong></p>\n<p>一个指责就是软件变化的原因。</p>\n<p>什么事高质量的代码？<strong>当用户提出一个需求时，为了实现这个变更而修改软件的成本越低，软件设计的质量就越高</strong><br>怎样才能在每次变更的时候都只修改一个模块就能实现需求呢？需要平时不断的整理代码，将因同一个原因而变更的代码都放到一起，将不同原因而变更的代码放在不同的模块，不同的类中。这样当因为一个原因而修改代码时，需要修改的代码都在同一个模块、同一个类中，修改范围就小了。维护成本降低了，设计质量就提高了。</p>\n<p>单一指责原则要求我们在维护软件的过程中不断的整理代码，将软件变化同一个原因的代码放在一起，将软件变化不同原因的代码分开放。</p>\n<h2 id=\"DDD在数据库设计上的落地\"><a href=\"#DDD在数据库设计上的落地\" class=\"headerlink\" title=\"DDD在数据库设计上的落地\"></a>DDD在数据库设计上的落地</h2><p>领域模型设计是需求分析人员和设计开发人员共同的产物</p>\n<pre><code>领域对象持久化存储的设计思想：\n将暂时不用的领域对象从内存中持久化到磁盘中，再次使用这个领域对象时，通过key值到数据库查找到这条记录，将其恢复成领域对象，应用程序继续使用它。以后数据库就没必要用关系型数据库了，可以通过nosql或者大数据平台，数据库的设计也可能不用遵守第三范式了，日后系统大数据转型的时候成本就更低了。</code></pre><p>DDD的数据库设计变成了<strong>以领域模型为核心，如何将领域模型转换成数据库设计的过程</strong></p>\n<p>也就是程序中的类转换成数据库的表的过程。</p>\n<ul>\n<li>在设计过程中，领域模型中，不论对象还是属性，在命名时都采用中文</li>\n<li>在数据库设计时，要细化为英文命名，或者汉语拼音首字母，同时要确定字段类型与是否为空等其他属性。</li>\n</ul>\n<p>如果将领域模型中的继承关系转换成数据库设计呢？</p>\n<ol>\n<li>如果继承关系的子类不多，并且每个子类的个性化字段不多，则可以用一个表来表示这种继承关系，用一个字段（类型）标识这条记录属于哪个子类，这个字段前面罗列的时父类的字段，这个字段的后面依次罗列各个子类的个性化字段，这样的优点时比较简单，整个继承关系的数据全部保存在这个表里，但是如果子类个性化字段太多，或导致很多字段为空，浪费空间，造成“表稀疏”。</li>\n<li>设计为多个表，父类的字段在每个表中都冗余，每个表的主键相同。如果业务总是将各个子类分开查询，这种设计就很合适，但是如果业务需要同时查询多个子类的数据，这种情况就不合适了。</li>\n<li>如果多种类型需要同时查询，而且各个字表的个性化字段比较多，前两种方法都不合适的时候，可以采用将父类字段作为一个表，各个子类分别有各自的表，主键与父表相同，当分页查询的时候，只查询父类的表，当查看详细信息的时候，再根据主键和类型字段去查询子类的表。</li>\n</ol>\n<p>关系型数据库和NoSQL数据库：</p>\n<ul>\n<li>我们平常用的还是mysql这种关系型数据库，遵循第三范式，使得数据库能够大幅度降低冗余，但数据库查询需要频繁使用join操作，在高并发场景下性能地下</li>\n<li>将需要join的查询在写入数据表前先进行join操作，直接写到一张单表中进行分布式存储，这张表称为“宽表”</li>\n</ul>\n<p>NoSQL数据库在设计时的套路就是尽量在单表中存储更多的字段，避免数据查询中的join操作，即使有很多字段是空的，也不会占用字段。</p>\n<p><strong>因为NoSQL一版都是no schema的，而且空字段在序列化是就被过滤掉了，不会持久化到硬盘，也不存在所谓的浪费空间，所以继承关系就直接使用上面第一中方法就可以了。</strong></p>\n<h2 id=\"领域模型如何指导程序设计\"><a href=\"#领域模型如何指导程序设计\" class=\"headerlink\" title=\"领域模型如何指导程序设计\"></a>领域模型如何指导程序设计</h2><p><strong>服务</strong>：标识的是在领域对象之外的操作和行为，接受用户的请求和执行某些操作。当用户在系统界面操作，会向系统发起请求，“服务”去接收这些请求，然后根据需求去执行相应的方法，也就是操作实体和值对象，在所有的操作完成后，将实体和值对象持久化到数据库中。</p>\n<p><strong>实体</strong>：通过一个唯一标识字段来区分真实世界中的每一个个体的领域对象。</p>\n<p><strong>值对象</strong>：代表的是真实世界中那些一成不变的、本质性的事物，这样的领域对象叫做“值对象”。</p>\n<pre><code>可变性是实体的特点，不变性是值对象的本质。</code></pre><p>将业务领域模型转换为程序设计思路：</p>\n<ul>\n<li>贫血模型</li>\n<li>充血模型</li>\n</ul>\n<p>贫血模型，就是在软件设计中，有很多POJO对象，它们除了有一堆get/set方法，几乎没有任何业务逻辑。pojo对象去调用对应的service去完成业务逻辑。</p>\n<p>充血模型，在领域对象中直接实现业务的逻辑操作。</p>\n<p>充血模型保持了领域模型的原貌，可以比较直接地映射成程序的变更，代码修改起来比较直接。保持了对象的封装性，使得领域模型在面临多态、继承能复杂结构时，易于变更。</p>\n<p>贫血模型相对充血模型更加简单易行，充血模型对设计和架构能力要求更高。</p>\n<p>简单来说：贫血模型的业务逻辑在service中实现，充血模型的业务逻辑在领域对象中实现</p>\n<p>取长补短，合理使用：<br><strong>将需要封装的业务逻辑放到领域对象中，按照充血模型去设计；除此之外的其他业务逻辑放到service中，按照贫血模型去设计</strong></p>\n<p>哪些业务逻辑要用充血模型：</p>\n<ul>\n<li>在领域模型中出现了类似继承、多态的情况</li>\n<li>在软件设计的过程中需要将一些类型或者编码进行转换</li>\n<li>希望在软件设计中能更好地表现领域对象之间的关系</li>\n<li>“聚合”，在真实世界中那些代表整体与部分的事物</li>\n</ul>\n<p><strong>聚合</strong>：表达的是真实世界中整体与部分的关系，比如订单与订单明细。一般代码中都会将订单明细对象集合作为订单对象的一个属性，也就是将订单明细聚合到了订单中。使用时就只拿到一个订单对象，订单明细作为订单的属性来使用，对于调用方，感知不到明细对象的存在。当整体不存在时，部分就变的没有意义。整体被称为<strong>聚合根</strong>，是外部访问的唯一入口。增删改的业务可以采用领域驱动设计，只能通过聚合根来访问数据，但是在分析汇总场景下，直接使用sql查询。</p>\n<p><strong>仓库Repository</strong>：领域驱动设计会实现一个仓库（Repository）去完成对数据库的操作。比如创建订单时，把新增订单和新增订单明细两个操作放到同一个事务中，就是将OrderDao#insert和OrderItemDao#insertList放到同一个事务中，供外部调用。</p>\n<p><strong>工厂</strong>：与设计模式中的工厂不同。设计模式中的工厂是将被调用方设计成一个接口下的多个实现，将这些实现放入工厂中，工厂负责通过key找到对应的实现类，创建出来，返回给调用方，从而降低了调用方与被调方的耦合度。而DDD中的工厂是装配创建领域对象，是领域对象生命周期的起点。比如系统要根据ID装载一个订单，订单仓库将任务交给订单工厂，订单工厂分别调用订单DAO、订单明细DAO、用户DAO去进行查询，将订单明细对象和用户对象分别set到订单对象的订单明细和用户属性中，订单工厂将装配好的订单对象返回给订单仓库。</p>\n<p>DDD的仓库应该被抽象成一个存放领域对象的地方，一般情况下，我们将数据持久化到数据库，是一种实现。所以为了可以快速装载，或者最近会重复使用同一个领域对象，仓库可以实现缓存的功能，当客户程序需要获取某个领域对象时，可以先到缓存中获取。</p>\n<p>通过仓库与工厂，对原有的DAO进行了一层封装，在保存、装载、查询等操作时，加入了聚合、装备等操作，并将这些操作封装起来，对上层的客户程序屏蔽。</p>\n<p><strong>工厂和仓库是聚合的实现。传统DAO的设计是一种贫血设计，而工厂和仓库的设计是一种充血设计。</strong></p>\n<h2 id=\"如何进行领域驱动设计\"><a href=\"#如何进行领域驱动设计\" class=\"headerlink\" title=\"如何进行领域驱动设计\"></a>如何进行领域驱动设计</h2><p>业务总是有不同的场景，每种场景下的领域对象也各不相同，领域对象之间会相互联系。正确的设计思路应该是将整个系统划分为许多相对独立的业务场景，在一个一个业务场景中进行领域分析与建模，这样的业务场景被称为“问题子域”。</p>\n<p>领域驱动核心的设计思想就是将软件的分析与设计还原到真实世界中，真实世界中的业务与问题叫做“问题域”，业务逻辑与知识叫“业务领域知识”。</p>\n<p>比如：</p>\n<p>电商网站的问题域：用户如何进行在线购物，购物的流程是怎样的。<br>在线订餐系统的问题域：用户如何在线订餐，饭店如何在线接单，系统如何分配骑士配送。</p>\n<p>而电商网站又能拆分出用户选购、下单、支付、物流等多个子域，订餐系统也能拆分出用户下单、饭店接单、其实配送等子域。如果一个子域比较复杂，我们还能将一个子域拆封成更多的子域。</p>\n<p>一个复杂系统的领域驱动设计，就是以子域为中心，进行领域建模，绘制出一张张的领域模型设计，称之为“限界上下文”（Context Bounds，CB）。</p>\n<p>DDD的限界上下文的设计，就体现了高质量软件设计中“单一职责原则“，也就是每个限界上下文中实现的都是软件变化同一个原因的业务。如果用户下单限界上下文有业务变化，还需要对它进行修改就行了，与其他限界上下文无关，这样就缩小了代码修改的范围，维护成本就降低了。</p>\n<p>限界上下文之间存在相互关系，这种关系被称为“上下文地图（Context Map）”。</p>\n<p>限界上下文之间可能存在的关系：</p>\n<ul>\n<li>合作关系（Partnership）：两个上下文紧密合作的关系，一荣俱荣，一损俱损</li>\n<li>共享内核（shared kernel）：两个上下文依赖部分共享的模型</li>\n<li>客户方-供应方开发（Customer-Supplier Development）：上下文之间有组织的上下游依赖</li>\n<li>遵奉者（Conformist）：下游上下文只能盲从上游上下文</li>\n<li>防腐层（Anticorruption Layer）：一个上下文通过一些适配和转换与另一个上下文交互</li>\n<li>开放主机服务（Open Host Service）：定义一种协议来让其他上下文来对本上下文进行访问</li>\n<li>发布语言（Published Language）：通常与OHS一起使用，用于定义开放主机的协议。</li>\n<li>大泥球（big ball of mud）：混杂在一起的上下文关系，边界不清晰。</li>\n<li>另谋他路（SeparateWay）：两个完全没有任何关系的上下文。</li>\n</ul>\n<p>比如用户下单上下文中，存在用户信息的读取，但是用户信息读取不应该在用户下单上下文中实现，因为用户下单业务的变更，不应该影响用户信息读取，所以用户信息的操作应该交给“用户信息管理”上下文，用户下单上下文只需要调用用户信息管理的用户信息读取接口。这个调用关系就是上下文地图的一部分。</p>\n<p><strong>限界上下文内的高内聚</strong>，每个限界上下文内实现的功能，都是软件变化的同一个原因的代码，因为这个原因的变化，才需要修改这个限界上下文。</p>\n<p><strong>限界上下文可以作为拆分微服务的原则，每个限界上下文对应一个微服务。这样在日后的每次需求变更时，可以快速的落到某个微服务中变更，实现了低成本维护和快 速交付</strong></p>\n<p>比如电商系统，根据限界上下文拆分出商品、购物、下单、支付、物流等微服务。</p>\n<p><strong>限界上下文间的低耦合</strong>，限界上下文通过上下文地图相互调用时，通过接口进行调用。通过接口解开调用方与被调用方之间的耦合。</p>\n<p>通过微服务来实现“限界上下文”之间的低耦合，比如下单微服务需要调用支付微服务，首先在下单微服务中增加支付接口，在下单微服务中，所有对支付服务的调用都是对其支付接口的调用，接着在其他支付微服务中实现支付，比如现在设计了微信支付微服务和支付宝支付微服务，在系统运行时，需要那种支付方式，就调用哪个支付微服务，这样下单和支付之间的耦合就被解开了。</p>\n<h2 id=\"如何解决微服务拆分难题\"><a href=\"#如何解决微服务拆分难题\" class=\"headerlink\" title=\"如何解决微服务拆分难题\"></a>如何解决微服务拆分难题</h2><p><strong>微服务做到小而专、高内聚的最佳实践是DDD</strong></p>\n<ul>\n<li>从DDD开始需求分析、领域建模，逐渐建立起多个问题子域</li>\n<li>将问题子域落实到限界上下文，它们之间的关系形成上下文地图</li>\n<li>各子域落实到微服务中贫血模型或充血模型的设计，从而在微服务之间依据上下文地图形成接口</li>\n</ul>\n<p>微服务设计最核心的难题是微服务的拆分，讲究小而专的设计，要低耦合、高内聚。</p>\n<p><strong>领域驱动设计解决微服务如何拆分，实现微服务的高内聚于单一职责的问题</strong></p>\n<p><strong>如何破局需求分析的困境？</strong></p>\n<p>统一语言建模，技术去了解业务，咨询客户，探讨业务。注意捕获专业术语，学会用这些术语沟通。</p>\n<p>召开事件风暴会议，在产品经理的引导下，业务和研发一起建模</p>\n<p>事件风暴会议，要梳理当前业务中有哪些领域事件，命名时应当采取过去时态。领域事件时已经发生而且需要保存的事件。 </p>\n<p><strong>微服务拆分原则–微服务内高内聚、微服务间低耦合</strong></p>\n<ul>\n<li>微服务内高内聚，就是单一职责原则，将代码修改的范围缩小到这个微服务内。</li>\n<li>微服务间低耦合，在微服务实现自身业务的过程中，如果需要执行的某些过程不是自己的职责，应当将这些过程交给其他微服务去实现，你只要对它的接口进行调用。</li>\n</ul>\n<p>通过DDD进行业务建模，再基于领域模型进行限界上下文划分<br>能保证系统的设计，在限界上下文内高内聚，在限界上下文间低耦合。</p>\n<p><strong>领域建模</strong>是将一个系统划分成了多个子域，每个子域都是一个独立的业务场景，每个子域的实现就是“限界上下文”，他们之间的关联关系就是“上下文地图 ”</p>\n<h1 id=\"领域驱动模型实战\"><a href=\"#领域驱动模型实战\" class=\"headerlink\" title=\"领域驱动模型实战\"></a>领域驱动模型实战</h1><ul>\n<li>DP：domain primivate，抽象并封装自检和一些隐性属性的计算逻辑，且这些属性是无状态的。</li>\n<li>Entity：抽象并封装单对象有状态的逻辑。</li>\n<li>Domain Service：抽象并封装多对象的有状态逻辑。</li>\n<li>Repository：抽象并封装外部数据访问的逻辑。</li>\n</ul>\n<p>步骤：</p>\n<ol>\n<li>首先对需要处理的业务问题进行总览。UL 统一语言建模</li>\n<li>然后领域驱动对象（Entity）进行划分，明确每个领域驱动对象的包含的信息和职责边界。并进行跨对象，多对象的逻辑组织。</li>\n<li>接着在上层应用中根据业务描述去编排Entity和Domain Service。</li>\n<li>最后再做一些下水道工作，去对下层的数据访问、RPC调用做具体实现。</li>\n</ol>\n<p><a href=\"https://www.bilibili.com/video/BV1PM4y1L7Nh?p=7\" target=\"_blank\" rel=\"noopener\">https://www.bilibili.com/video/BV1PM4y1L7Nh?p=7</a>  10:30</p>\n","site":{"data":{}},"more":"<p>DDD不是什么新鲜玩意，早在2004年著名建模专家eric evans在其书籍《领域驱动设计—软件核心复杂性应对之道》就提出了。</p>\n<p>不过那时候，国内软件业务还没有这么复杂，没有人在意软件设计。</p>\n<h2 id=\"杜绝软件退化，两顶帽子\"><a href=\"#杜绝软件退化，两顶帽子\" class=\"headerlink\" title=\"杜绝软件退化，两顶帽子\"></a>杜绝软件退化，两顶帽子</h2><p>随着软件行业的发展，软件规模越来越大，业务越来越复杂，代码越来越多，越来越乱，屎山就是这么来的……</p>\n<p>于是微服务来了，小而专，高内聚。</p>\n<p>软件设计质量最高的时候，就是第一版设计。从那之后的每一次需求变更，就开始打乱、破坏之前的设计，随着时间的推迟，维护成本越来越高。</p>\n<p>开放-封闭原则：</p>\n<ul>\n<li>开放原则：对功能扩展是开放的，当系统需求发生变更时，可以对软件功能进行扩展，使其满足用户新的需求。open for extension</li>\n<li>封闭原则：对代码的修改是封闭的，在修改软件的同时，不要影响到系统原有的功能，所以应当在不修改原有代码的基础上实现新功能。close for modification</li>\n</ul>\n<p><strong>软件的本质就是对真实世界的模拟，软件中业务逻辑是否正确的唯一标准就是是否与真实世界一致。</strong></p>\n<p>比如一段电商行业支付相关的代码，一个PayService中有一个payOff方法，初版的需求就是一个简单的根基商品的总价进行支付，但是新需求来了，要求支持各种折扣功能（限时折扣、限量折扣、对某种商品折扣、对某个商品折扣、不折扣）。如果上来就干，可能就是一顿if/else，判断折扣类型计算支付金额。这样的代码，就增加了维护的难度，当更多这样的代码聚集到一起的时候，几百上千行的支付方法，会让开发者难以下手。</p>\n<p>如果调整软件的程序结构，由简单的程序结构转变为复杂的程序结构，对应着现实世界的简单需求转变为复杂需求。</p>\n<p>要保持软件设计质量不退化，必须在每次需求变更的时候，对原有的程序结构适当的进行调整。</p>\n<p>在实现新需求时，要采用两顶帽子的方式：</p>\n<ol>\n<li>在不添加新功能的前提下，重构代码，调整原有程序结构，以适应新功能</li>\n<li>实现新的功能</li>\n</ol>\n<p>还是上面的需求，如果不动之前的代码，而是给PayService增加接口，payOff方法实现各不相同。如果后期那种折扣需求变化，就修改哪个实现类；如果后期要增加折扣方式，就增加实现类。</p>\n<p>如果每次的灵活设计只能应对一种需求变更，其实作用不大，最后的结果可能是我们期望的变化没有发生，所做的设计都成了摆设，这次设计也就成了过度设计。每次设计应该只为当前的需求设计，使其刚刚满足当前需求。</p>\n<p>每次变更，都还原到真实世界中，根据真实世界进行设计。</p>\n<p>像图中描述的，将真实世界和软件世界联系起来</p>\n<img src=\"/2022/03/10/kongzheng1993-DDD/entity_model.png\">\n\n<ul>\n<li>真实世界有什么事物，软件世界就有什么对象</li>\n<li>真实世界的事物有什么行为，软件世界的对象就有什么方法</li>\n<li>真实世界的事物间有什么关系，软件世界中对象就有什么关联</li>\n</ul>\n<p>软件发展的规律就是逐步由简单软件向复杂软件转变，在这个过程中，需要有两顶帽子，适时的对程序结构进行调整，再实现新需求，只有这样才能保证软件不退化。关于具体两顶帽子怎么做，DDD给了思路：每次变更时，先回到领域模型，基于业务进行领域模型的变更，然后再根据领域模型的变更指导程序的变更。</p>\n<h2 id=\"单一指责原则\"><a href=\"#单一指责原则\" class=\"headerlink\" title=\"单一指责原则\"></a>单一指责原则</h2><p><strong>单一指责原则：软件系统中的每个元素只完成自己职责范围内的事，而将其他的事交给别人去做，我只是去调用</strong></p>\n<p>一个指责就是软件变化的原因。</p>\n<p>什么事高质量的代码？<strong>当用户提出一个需求时，为了实现这个变更而修改软件的成本越低，软件设计的质量就越高</strong><br>怎样才能在每次变更的时候都只修改一个模块就能实现需求呢？需要平时不断的整理代码，将因同一个原因而变更的代码都放到一起，将不同原因而变更的代码放在不同的模块，不同的类中。这样当因为一个原因而修改代码时，需要修改的代码都在同一个模块、同一个类中，修改范围就小了。维护成本降低了，设计质量就提高了。</p>\n<p>单一指责原则要求我们在维护软件的过程中不断的整理代码，将软件变化同一个原因的代码放在一起，将软件变化不同原因的代码分开放。</p>\n<h2 id=\"DDD在数据库设计上的落地\"><a href=\"#DDD在数据库设计上的落地\" class=\"headerlink\" title=\"DDD在数据库设计上的落地\"></a>DDD在数据库设计上的落地</h2><p>领域模型设计是需求分析人员和设计开发人员共同的产物</p>\n<pre><code>领域对象持久化存储的设计思想：\n将暂时不用的领域对象从内存中持久化到磁盘中，再次使用这个领域对象时，通过key值到数据库查找到这条记录，将其恢复成领域对象，应用程序继续使用它。以后数据库就没必要用关系型数据库了，可以通过nosql或者大数据平台，数据库的设计也可能不用遵守第三范式了，日后系统大数据转型的时候成本就更低了。</code></pre><p>DDD的数据库设计变成了<strong>以领域模型为核心，如何将领域模型转换成数据库设计的过程</strong></p>\n<p>也就是程序中的类转换成数据库的表的过程。</p>\n<ul>\n<li>在设计过程中，领域模型中，不论对象还是属性，在命名时都采用中文</li>\n<li>在数据库设计时，要细化为英文命名，或者汉语拼音首字母，同时要确定字段类型与是否为空等其他属性。</li>\n</ul>\n<p>如果将领域模型中的继承关系转换成数据库设计呢？</p>\n<ol>\n<li>如果继承关系的子类不多，并且每个子类的个性化字段不多，则可以用一个表来表示这种继承关系，用一个字段（类型）标识这条记录属于哪个子类，这个字段前面罗列的时父类的字段，这个字段的后面依次罗列各个子类的个性化字段，这样的优点时比较简单，整个继承关系的数据全部保存在这个表里，但是如果子类个性化字段太多，或导致很多字段为空，浪费空间，造成“表稀疏”。</li>\n<li>设计为多个表，父类的字段在每个表中都冗余，每个表的主键相同。如果业务总是将各个子类分开查询，这种设计就很合适，但是如果业务需要同时查询多个子类的数据，这种情况就不合适了。</li>\n<li>如果多种类型需要同时查询，而且各个字表的个性化字段比较多，前两种方法都不合适的时候，可以采用将父类字段作为一个表，各个子类分别有各自的表，主键与父表相同，当分页查询的时候，只查询父类的表，当查看详细信息的时候，再根据主键和类型字段去查询子类的表。</li>\n</ol>\n<p>关系型数据库和NoSQL数据库：</p>\n<ul>\n<li>我们平常用的还是mysql这种关系型数据库，遵循第三范式，使得数据库能够大幅度降低冗余，但数据库查询需要频繁使用join操作，在高并发场景下性能地下</li>\n<li>将需要join的查询在写入数据表前先进行join操作，直接写到一张单表中进行分布式存储，这张表称为“宽表”</li>\n</ul>\n<p>NoSQL数据库在设计时的套路就是尽量在单表中存储更多的字段，避免数据查询中的join操作，即使有很多字段是空的，也不会占用字段。</p>\n<p><strong>因为NoSQL一版都是no schema的，而且空字段在序列化是就被过滤掉了，不会持久化到硬盘，也不存在所谓的浪费空间，所以继承关系就直接使用上面第一中方法就可以了。</strong></p>\n<h2 id=\"领域模型如何指导程序设计\"><a href=\"#领域模型如何指导程序设计\" class=\"headerlink\" title=\"领域模型如何指导程序设计\"></a>领域模型如何指导程序设计</h2><p><strong>服务</strong>：标识的是在领域对象之外的操作和行为，接受用户的请求和执行某些操作。当用户在系统界面操作，会向系统发起请求，“服务”去接收这些请求，然后根据需求去执行相应的方法，也就是操作实体和值对象，在所有的操作完成后，将实体和值对象持久化到数据库中。</p>\n<p><strong>实体</strong>：通过一个唯一标识字段来区分真实世界中的每一个个体的领域对象。</p>\n<p><strong>值对象</strong>：代表的是真实世界中那些一成不变的、本质性的事物，这样的领域对象叫做“值对象”。</p>\n<pre><code>可变性是实体的特点，不变性是值对象的本质。</code></pre><p>将业务领域模型转换为程序设计思路：</p>\n<ul>\n<li>贫血模型</li>\n<li>充血模型</li>\n</ul>\n<p>贫血模型，就是在软件设计中，有很多POJO对象，它们除了有一堆get/set方法，几乎没有任何业务逻辑。pojo对象去调用对应的service去完成业务逻辑。</p>\n<p>充血模型，在领域对象中直接实现业务的逻辑操作。</p>\n<p>充血模型保持了领域模型的原貌，可以比较直接地映射成程序的变更，代码修改起来比较直接。保持了对象的封装性，使得领域模型在面临多态、继承能复杂结构时，易于变更。</p>\n<p>贫血模型相对充血模型更加简单易行，充血模型对设计和架构能力要求更高。</p>\n<p>简单来说：贫血模型的业务逻辑在service中实现，充血模型的业务逻辑在领域对象中实现</p>\n<p>取长补短，合理使用：<br><strong>将需要封装的业务逻辑放到领域对象中，按照充血模型去设计；除此之外的其他业务逻辑放到service中，按照贫血模型去设计</strong></p>\n<p>哪些业务逻辑要用充血模型：</p>\n<ul>\n<li>在领域模型中出现了类似继承、多态的情况</li>\n<li>在软件设计的过程中需要将一些类型或者编码进行转换</li>\n<li>希望在软件设计中能更好地表现领域对象之间的关系</li>\n<li>“聚合”，在真实世界中那些代表整体与部分的事物</li>\n</ul>\n<p><strong>聚合</strong>：表达的是真实世界中整体与部分的关系，比如订单与订单明细。一般代码中都会将订单明细对象集合作为订单对象的一个属性，也就是将订单明细聚合到了订单中。使用时就只拿到一个订单对象，订单明细作为订单的属性来使用，对于调用方，感知不到明细对象的存在。当整体不存在时，部分就变的没有意义。整体被称为<strong>聚合根</strong>，是外部访问的唯一入口。增删改的业务可以采用领域驱动设计，只能通过聚合根来访问数据，但是在分析汇总场景下，直接使用sql查询。</p>\n<p><strong>仓库Repository</strong>：领域驱动设计会实现一个仓库（Repository）去完成对数据库的操作。比如创建订单时，把新增订单和新增订单明细两个操作放到同一个事务中，就是将OrderDao#insert和OrderItemDao#insertList放到同一个事务中，供外部调用。</p>\n<p><strong>工厂</strong>：与设计模式中的工厂不同。设计模式中的工厂是将被调用方设计成一个接口下的多个实现，将这些实现放入工厂中，工厂负责通过key找到对应的实现类，创建出来，返回给调用方，从而降低了调用方与被调方的耦合度。而DDD中的工厂是装配创建领域对象，是领域对象生命周期的起点。比如系统要根据ID装载一个订单，订单仓库将任务交给订单工厂，订单工厂分别调用订单DAO、订单明细DAO、用户DAO去进行查询，将订单明细对象和用户对象分别set到订单对象的订单明细和用户属性中，订单工厂将装配好的订单对象返回给订单仓库。</p>\n<p>DDD的仓库应该被抽象成一个存放领域对象的地方，一般情况下，我们将数据持久化到数据库，是一种实现。所以为了可以快速装载，或者最近会重复使用同一个领域对象，仓库可以实现缓存的功能，当客户程序需要获取某个领域对象时，可以先到缓存中获取。</p>\n<p>通过仓库与工厂，对原有的DAO进行了一层封装，在保存、装载、查询等操作时，加入了聚合、装备等操作，并将这些操作封装起来，对上层的客户程序屏蔽。</p>\n<p><strong>工厂和仓库是聚合的实现。传统DAO的设计是一种贫血设计，而工厂和仓库的设计是一种充血设计。</strong></p>\n<h2 id=\"如何进行领域驱动设计\"><a href=\"#如何进行领域驱动设计\" class=\"headerlink\" title=\"如何进行领域驱动设计\"></a>如何进行领域驱动设计</h2><p>业务总是有不同的场景，每种场景下的领域对象也各不相同，领域对象之间会相互联系。正确的设计思路应该是将整个系统划分为许多相对独立的业务场景，在一个一个业务场景中进行领域分析与建模，这样的业务场景被称为“问题子域”。</p>\n<p>领域驱动核心的设计思想就是将软件的分析与设计还原到真实世界中，真实世界中的业务与问题叫做“问题域”，业务逻辑与知识叫“业务领域知识”。</p>\n<p>比如：</p>\n<p>电商网站的问题域：用户如何进行在线购物，购物的流程是怎样的。<br>在线订餐系统的问题域：用户如何在线订餐，饭店如何在线接单，系统如何分配骑士配送。</p>\n<p>而电商网站又能拆分出用户选购、下单、支付、物流等多个子域，订餐系统也能拆分出用户下单、饭店接单、其实配送等子域。如果一个子域比较复杂，我们还能将一个子域拆封成更多的子域。</p>\n<p>一个复杂系统的领域驱动设计，就是以子域为中心，进行领域建模，绘制出一张张的领域模型设计，称之为“限界上下文”（Context Bounds，CB）。</p>\n<p>DDD的限界上下文的设计，就体现了高质量软件设计中“单一职责原则“，也就是每个限界上下文中实现的都是软件变化同一个原因的业务。如果用户下单限界上下文有业务变化，还需要对它进行修改就行了，与其他限界上下文无关，这样就缩小了代码修改的范围，维护成本就降低了。</p>\n<p>限界上下文之间存在相互关系，这种关系被称为“上下文地图（Context Map）”。</p>\n<p>限界上下文之间可能存在的关系：</p>\n<ul>\n<li>合作关系（Partnership）：两个上下文紧密合作的关系，一荣俱荣，一损俱损</li>\n<li>共享内核（shared kernel）：两个上下文依赖部分共享的模型</li>\n<li>客户方-供应方开发（Customer-Supplier Development）：上下文之间有组织的上下游依赖</li>\n<li>遵奉者（Conformist）：下游上下文只能盲从上游上下文</li>\n<li>防腐层（Anticorruption Layer）：一个上下文通过一些适配和转换与另一个上下文交互</li>\n<li>开放主机服务（Open Host Service）：定义一种协议来让其他上下文来对本上下文进行访问</li>\n<li>发布语言（Published Language）：通常与OHS一起使用，用于定义开放主机的协议。</li>\n<li>大泥球（big ball of mud）：混杂在一起的上下文关系，边界不清晰。</li>\n<li>另谋他路（SeparateWay）：两个完全没有任何关系的上下文。</li>\n</ul>\n<p>比如用户下单上下文中，存在用户信息的读取，但是用户信息读取不应该在用户下单上下文中实现，因为用户下单业务的变更，不应该影响用户信息读取，所以用户信息的操作应该交给“用户信息管理”上下文，用户下单上下文只需要调用用户信息管理的用户信息读取接口。这个调用关系就是上下文地图的一部分。</p>\n<p><strong>限界上下文内的高内聚</strong>，每个限界上下文内实现的功能，都是软件变化的同一个原因的代码，因为这个原因的变化，才需要修改这个限界上下文。</p>\n<p><strong>限界上下文可以作为拆分微服务的原则，每个限界上下文对应一个微服务。这样在日后的每次需求变更时，可以快速的落到某个微服务中变更，实现了低成本维护和快 速交付</strong></p>\n<p>比如电商系统，根据限界上下文拆分出商品、购物、下单、支付、物流等微服务。</p>\n<p><strong>限界上下文间的低耦合</strong>，限界上下文通过上下文地图相互调用时，通过接口进行调用。通过接口解开调用方与被调用方之间的耦合。</p>\n<p>通过微服务来实现“限界上下文”之间的低耦合，比如下单微服务需要调用支付微服务，首先在下单微服务中增加支付接口，在下单微服务中，所有对支付服务的调用都是对其支付接口的调用，接着在其他支付微服务中实现支付，比如现在设计了微信支付微服务和支付宝支付微服务，在系统运行时，需要那种支付方式，就调用哪个支付微服务，这样下单和支付之间的耦合就被解开了。</p>\n<h2 id=\"如何解决微服务拆分难题\"><a href=\"#如何解决微服务拆分难题\" class=\"headerlink\" title=\"如何解决微服务拆分难题\"></a>如何解决微服务拆分难题</h2><p><strong>微服务做到小而专、高内聚的最佳实践是DDD</strong></p>\n<ul>\n<li>从DDD开始需求分析、领域建模，逐渐建立起多个问题子域</li>\n<li>将问题子域落实到限界上下文，它们之间的关系形成上下文地图</li>\n<li>各子域落实到微服务中贫血模型或充血模型的设计，从而在微服务之间依据上下文地图形成接口</li>\n</ul>\n<p>微服务设计最核心的难题是微服务的拆分，讲究小而专的设计，要低耦合、高内聚。</p>\n<p><strong>领域驱动设计解决微服务如何拆分，实现微服务的高内聚于单一职责的问题</strong></p>\n<p><strong>如何破局需求分析的困境？</strong></p>\n<p>统一语言建模，技术去了解业务，咨询客户，探讨业务。注意捕获专业术语，学会用这些术语沟通。</p>\n<p>召开事件风暴会议，在产品经理的引导下，业务和研发一起建模</p>\n<p>事件风暴会议，要梳理当前业务中有哪些领域事件，命名时应当采取过去时态。领域事件时已经发生而且需要保存的事件。 </p>\n<p><strong>微服务拆分原则–微服务内高内聚、微服务间低耦合</strong></p>\n<ul>\n<li>微服务内高内聚，就是单一职责原则，将代码修改的范围缩小到这个微服务内。</li>\n<li>微服务间低耦合，在微服务实现自身业务的过程中，如果需要执行的某些过程不是自己的职责，应当将这些过程交给其他微服务去实现，你只要对它的接口进行调用。</li>\n</ul>\n<p>通过DDD进行业务建模，再基于领域模型进行限界上下文划分<br>能保证系统的设计，在限界上下文内高内聚，在限界上下文间低耦合。</p>\n<p><strong>领域建模</strong>是将一个系统划分成了多个子域，每个子域都是一个独立的业务场景，每个子域的实现就是“限界上下文”，他们之间的关联关系就是“上下文地图 ”</p>\n<h1 id=\"领域驱动模型实战\"><a href=\"#领域驱动模型实战\" class=\"headerlink\" title=\"领域驱动模型实战\"></a>领域驱动模型实战</h1><ul>\n<li>DP：domain primivate，抽象并封装自检和一些隐性属性的计算逻辑，且这些属性是无状态的。</li>\n<li>Entity：抽象并封装单对象有状态的逻辑。</li>\n<li>Domain Service：抽象并封装多对象的有状态逻辑。</li>\n<li>Repository：抽象并封装外部数据访问的逻辑。</li>\n</ul>\n<p>步骤：</p>\n<ol>\n<li>首先对需要处理的业务问题进行总览。UL 统一语言建模</li>\n<li>然后领域驱动对象（Entity）进行划分，明确每个领域驱动对象的包含的信息和职责边界。并进行跨对象，多对象的逻辑组织。</li>\n<li>接着在上层应用中根据业务描述去编排Entity和Domain Service。</li>\n<li>最后再做一些下水道工作，去对下层的数据访问、RPC调用做具体实现。</li>\n</ol>\n<p><a href=\"https://www.bilibili.com/video/BV1PM4y1L7Nh?p=7\" target=\"_blank\" rel=\"noopener\">https://www.bilibili.com/video/BV1PM4y1L7Nh?p=7</a>  10:30</p>\n"},{"title":"复习知识点","excerpt":"","comments":1,"date":"2022-03-13T10:30:52.000Z","_content":"\n## 操作系统 《现代操作系统：原理与实现》\n\n**操作系统基础概念**\n\n操作系统基础概念中比较重要的知识点：\n\n- 操作系统的作用、特点、分类、发展\n- 操作系统的结构\n- 内核态和用户态、系统调用\n\n**进程和线程（重要）**\n\n1. 进程和线程的基本定义，对比一下两者。\n2. 进程和线程的状态以及各种状态之间的转换。\n3. 进程的通信方式： 进程与进程之前是如何进行通信的。\n4. 进程调度算法： CPU 如何应用不同的调度算法来调度进程。\n\n**内存管理（重要）**\n\n面试官可能会先问一些比较简单的问题比如内存管理的目的、逻辑和物理地址。\n\n比较核心一些的问题还是内存管理机制和内存管理相关的一些概念。\n\n- 内存管理机制 ：像内存管理机制简单分为连续分配管理方式和非连续分配管理方式这两种。非连续分配管理方式比较重要，像分页机制、分段机制、段页式机制都属于非连续分配管理。\n- 内存管理相关概念 ： 快表和多级页表。\n\n除此之外，虚拟内存和请求分页也非常重要，面试中也经常会遇到。\n\n- 虚拟内存 ：虚拟内存介绍、局部性原理、虚拟内存的实现机制\n- 请求分页 ： 页表机制、缺页中断、页面置换算法\n\n最后就是死锁相关的内容了，你需要掌握：\n\n- 死锁的必要条件\n- 死锁预防、避免、检测与解除\n\n**CPU 调度**\n\nCPU 调度这块最重要的就是搞懂几种常见的 CPU 调度算法：\n\n- 先到先服务调度(First-Come First-Served Scheduling，FCFS)\n- 最短作业优先调度(Shortest Job First，SJF)\n- 优先级调度（Priority Scheduling）\n- 轮转法调度(Round Robin，RR)\n- ......\n\n上面这几种调度算法，大家通过名字应该就能猜出个大概意义了。这些调度算法各有优劣，没有银弹，只能根据具体场景选择具体的调度算法。\n\n因此，多级队列调度（Multilevel Queue） 就诞生了。简单来说就是把就绪队列（存放有待执行进程）分成多个独立队列，每个队列都有自己的调度算法。\n\n**Linux 相关（重要）**\n\n另外的话，操作系统这块还需要对 Linux 相关的知识有所了解：\n\n- Linux 常用命令 ：比如说创建文件相关的命令、搜索相关的命令\n- Linux 文件系统 ： 文件系统原理、硬链接与软链接、目录结构\n- 僵尸进程和孤儿进程\n\n\n## 计算机网络 《计算机网络——自顶向下方法》\n\n**网络层**\n\n网络层面试问的也相对较少，主要就是问IPV4，偶尔问一下ARP地址解析协议的的工作原理。\n\n1.首先要记清楚 IPV4 地址是怎么分类的、以及地址的格式。这里经常结合代码题一起问你，我和很多同学都在面试中被面试官要求写一个程序判断给定的字符串是否是 IPV4 地址。\n\n2.IPV4 子网划分面试中不怎么问，笔试题时经常有这个问题。\n\n3.了解 IP 地址和 Mac 地址的区别，了解 ARP 地址解析协议并了解其工作原理。\n\n**传输层**\n\n面试中计算机网络的问题最常出现在这一章中。\n\n1.记清楚 TCP 和 UDP 的区别。\n\n2.TCP三次握手和UDP四次挥手。\n\n这是面试计算机网络最最最常问的问题！！！你计算机网络就算其它的什么也不会，这个问题你必须要记清楚，如果面试官问出你这个问题你都答不上，面试官估计觉得你连敷衍都不想敷衍他了。\n\n当面试官问你三次握手和四次挥手时，你要答出这三个点来。（1）为什么要三次挥手和四次挥手，如果不这样做会有什么影响。（2）三次握手四次挥手的整个流程。（3）有的面试官只要你答出三次握手和四次挥手的大体流程就好了，但是有的面试官会要求你答出三次握手和四次挥手时发送端和接收端分别发了哪些标记。就像下面 Guide哥 画的这张图一样。\n\n![](https://img-blog.csdnimg.cn/20210727212425498.png)\n\n3.TCP协议如何保证可靠传输\n\n把 ARQ 协议、滑动窗口、流量控制、拥塞控制等回答清楚就算到位了。\n\n应用层 ：\n\n（1）另一个最最最常问的问题，”在浏览器中输入 URL 地址到浏览器显示网页这个过程中计算机网络做了什么“。\n\n这个问题无论时考研还是找工作都是常见的，建议把 JavaGuide 中这个问题的总结熟读并全文背诵。\n\n（2）HTTP 1.0 和 HTTP 1.1 的主要区别\n\n这个也要了解一下。\n\n（3）HTTP 和 HTTPS 的区别\n\n这个也是面试常考问题，这个问题展开以后能问的就比较多了。\n\n在回答这个问题时你首先分别介绍一下 HTTP 和 HTTPS 的原理，以及区别。大致就是 HTTP 是通过明文在网络上传输的，HTTPS 是加密的。然后有的面试官问到这也就可以了，有的面试官不讲武德，想搞偷袭，会继续让你讲 HTTPS 建立连接的流程、然后会继续追着你问SSL 的工作流程。建议把这里好好准备一下，面试官一问你就可以展开讲，你就能消耗很多面试时间，这样面试官问其它问题的时间就少了，嘿嘿。\n\n（4）HTTP请求常见的状态码\n\n背几个常用的就好。\n\n（5）DNS域名系统\n\n这里你要可以描述清楚工作原理。也是面试常问问题，当除考研我也重点背过这里。\n\n**网络接口层**\n\n把网卡、网桥、交换机的概念、用途简单了解下就好，一般面试官不会问。\n\n好了，把这些问题搞清楚，应付面试官应该就没什么问题了，赶紧去总结下答案然后好好背吧。如果你时间充分，想系统学一下计算机网络，那你就接着往下看。\n\n\n## 数据结构 可以在下面的算法书中学习\n\n数据结构的种类非常多，不过最常用同时也是面试最常问的数据结构主要就是下面这些：\n\n- **线性数据结构**：\n  - **数组** ：数组（Array） 是一种很常见的数据结构。它由相同类型的元素（element）组成，并且是使用一块连续的内存来存储。\n  - **链表** ：链表（LinkedList） 虽然是一种线性表，但是并不会按线性的顺序存储数据，使用的不是连续的内存空间来存储数据。链表的插入和删除操作的复杂度为 O(1) ，只需要知道目标位置元素的上一个元素即可。但是，在查找一个节点或者访问特定位置的节点的时候复杂度为 O(n) 。\n  - **栈** ：栈 (Stack)只允许在有序的线性数据集合的一端（称为栈顶 top）进行加入数据（push）和移除数据（pop）。因而按照 后进先出（LIFO, Last In First Out） 的原理运作。在栈中，push 和 pop 的操作都发生在栈顶。栈常用一维数组或链表来实现，用数组实现的栈叫作 顺序栈 ，用链表实现的栈叫作 链式栈 。\n  - **队列** ： 队列（Queue）是 先进先出( FIFO，First In, First Out) 的线性表。在具体应用中通常用链表或者数组来实现，用数组实现的队列叫作 顺序队列 ，用链表实现的队列叫作 链式队列 。队列只允许在后端（rear）进行插入操作也就是 入队 enqueue，在前端（front）进行删除操作也就是出队 dequeue。队列的操作方式和堆类似，唯一的区别在于队列只允许新数据在后端进行添加。\n- **图** ：图就是由顶点的有穷非空集合和顶点之间的边组成的集合。通常表示为：**G(V,E)**，其中，G 表示一个图，V 表示顶点的集合，E 表示边的集合。图可以被简单的分为：无向图和有向图，无权图和带权图。\n- **树** : 树就是一种类似现实生活中的树的数据结构（倒置的树）。任何一颗非空树只有一个根节点。常见的树的种类有：平衡树、二叉搜索树、平衡二叉树、红黑树、B 树、LSM 树、字典树（Trie 树）\n- **堆** ：堆是一种满足特定条件的树：堆中的每一个节点值都大于等于（或小于等于）子树中所有节点的值。或者说，任意一个节点的值都大于等于（或小于等于）所有子节点的值。堆分为最大堆和最小堆。\n- **哈希表** ：也叫散列表，是根据关键码值(Key value)而直接进行访问的数据结构，通过 key 就能获取到指定的 value ，速度非常快。\n- **跳表** ：跳表（Skip List）是由 William Pugh 发明的一种查找数据结构，支持对数据的快速查找，插入和删除。跳表的查询，插入和删除操作的期望时间复杂度都为 O(log n)。\n\n**常见问题总结** ：\n\n- **通用常识**：像数据结构的定义，查找、插入、删除元素的时间复杂度，应用场景是每一个数据结构都应该掌握的最基本的点。\n- **线性数据结构** ：\n  - 数组 vs 链表\n  - 栈 vs 队列\n  - 实现一个栈/队列\n  - 翻转链表、返回链表中倒数第 n 个节点、链表合并......\n- **图** ：\n  - 图的常见概念比如顶点的度\n  - 图的遍历算法（广度优先搜索和深度优先搜索）\n  - 拓扑排序\n  - 欧拉回路\n  - 迪杰斯特拉（Dijikstra）算法（最短路径问题）\n- **树** ：\n  - 二叉树的前序遍历、中序遍历、后序遍历\n  - 二叉查找树的出插入、查找、删除\n  - 二叉树的高度计算\n  - 红黑树 vs 二叉查找树\n- **堆** ：\n  - 堆中插入数据\n  - 如何删除堆顶元素\n  - 堆排序\n- **哈希表** ：\n  - 哈希冲突是什么？如何解决？\n  - 键值的映射关系如何维护？哈希函数如何设计？\n- **跳表**：\n  - 为什么 Redis 选择使用跳表而不是红黑树来实现有序集合？\n  - 跳表的查找、插入、删除元素的流程\n  - 跳表插入元素时，如何动态维护索引？\n\n\n## 算法  《算法》 《我的第一本算法书》 《算法导论》 《编程珠玑》\n\n和框架应用类知识不同，算法仅仅通过一周甚至是一个月的突击是完全没办法快速上手的！\n\n想要在算法面试中如鱼得水，就必须持之以恒地坚持刷题-> 总结->再刷题 -> 再总结。\n\n你需要做的就是提前半年甚至是一年来刷 Leetcode，并总结一些常见题目类型的套路！\n\n**那我们应该怎么更高效低刷题呢？** 给几点自己的刷题建议：\n\n- **按照类型来刷** ：一般情况下，一个类型的题目刷 5~10 道左右就够了！\n- **由简入难** ：刷算法是一个循序渐进的过程，如果你不是 ACM 大佬这种级别的人物的话，还是建议先从简单开始刷起，慢慢积累经验。不过，要说明的一点是：很多简单类型的题目甚至还要比中等类型的题目还要难！所以，如果你没办法解决一些简单的算法题，也不要太纠结，不要因此失去信心。\n- **重点关注面试高频题目/题型** ：如果你的时间不是很充足的话，建议可以从高频面试题入手。像 Leetcode 上面就专门把一些最热门的算法面试题给单独整理了出来。\n- **多思考** ：一定不要遇到不会的算法题就直接看别人的答案，这样会让自己形成依赖心理。一定要先思考，一定要多思考！\n- ......\n\n刷题之前，我建议你应该具有基本的算法基础。比如你应该搞清楚常见的算法思想（递归、动态规划、二分查找、贪心、分治、回溯、DFS、BFS、KMP、树的广度和深度优先搜索）；再比如你可能还需要一点点的数学知识（比如位运算、质数）基础。\n\n另外， 网上也有很多算法大佬开源了自己的刷题经验，这些经验都是前辈刷题之后得出的，非常具有参考价值。利用得当的话，可以极大减轻自己的刷题压力。推荐你看看我整理的 [《阿里ACM大佬开源的Leetcode刷题指南》](https://mp.weixin.qq.com/s/7b4JDVA_s27wCLQD7SACXg) 。\n\n## Java并发 《Java 并发实现原理：JDK 源码剖析》\n\n1. 进程和线程的区别。【⭐⭐⭐⭐⭐】这是一个超高频考点，面试回答时别一句一个进程包含很多线程就没了。要答清楚什么是线程什么是进程，线程和进程各自的`运行状态`、线程的`通信方式`和进程的`通信方式`。\n2. 创建线程的方式。【⭐⭐⭐⭐】不仅要把创建线程的方式记熟、记住各种方式的优缺点，还要能写出代码来。有的面试官是会让你写代码创建两个线程然后执行一些操作的，比如两个线程交替输出数字。\n3. 什么是死锁，死锁如何产生，死锁如何避免。【⭐⭐⭐⭐⭐】超高频问题，几乎大厂的一面和二面都会问到。\n4. 并发编程的三大特性（原子性、可见性以及有序性）。【⭐⭐⭐⭐】\n5. `synchronized` 锁升级流程。【⭐⭐⭐⭐⭐】这又是面试八股文的一大考点，锁升级流程记清楚。\n6. `volatile` 关键字。【⭐⭐⭐⭐⭐】对比和 `synchronized` 的区别。\n7. `JMM`（Java Memory Model，Java 内存模型）和 `happens-before` 原则。【⭐⭐⭐⭐⭐】面试中重点！几乎必问。\n8. `ThreadLocal`。【⭐⭐⭐⭐】这也是面试八股文的一个高频考点。我面试到后面不想背这里了，面试过程中就尽可能躲着这个知识点，不提到和这相关的，竟然真的苟过去了。\n9. 线程池。【⭐⭐⭐⭐⭐】超高频考点。需要答出线程池有哪几种，各种线程池的优缺点，线程池的重要参数、线程池的`执行流程`、线程池的饱和策略、如何设置线程池的大小等等。这里也能背十几分钟。\n10. `ReentrantLock` 和 `AQS`。【⭐⭐⭐⭐⭐】其实我在面试的时候对这里不是很熟，我面试的时候尽量不提到这里，也苟过去了。大家如果时间充足的话还是把这块好好理解一下。如果这里理解透彻了，也能在这里和面试官聊很久。\n11. 乐观锁和悲观锁的区别。【⭐⭐⭐⭐⭐】\n12. `CAS` 了解么？原理？什么是 ABA 问题？ABA 问题怎么解决？【⭐⭐⭐⭐⭐】`CAS`（Compare-and-Swap）绝对是面试中的高频中的高频，很多地方都用到了 `CAS` 比如 `ConcurrentHashMap` 采用 `CAS` 和 `synchronized` 来保证并发安全，再比如`java.util.concurrent.atomic`包中的类通过 `volatile+CAS` 重试保证线程安全性。和面试官聊 `CAS` 的时候，你可以结合 `CAS` 的一些实际应用来说。\n13. `Atomic` 原子类【⭐⭐】\n\n\n## Java基础 《Java 编程的逻辑》\n\n1. Java 语言的特点（如果你简历上有提到 C++ 可能还会问你 Java 和 C++ 的区别）。【⭐⭐】\n2. 比较 JVM 和 JDK 以及 JRE 。【⭐⭐⭐】非常非常基础的一个问题！学了 Java 之后还不知这个问题如何回答的小伙伴自觉去面壁吧！\n3. 为什么说 Java 语言“解释与编译并存”。【⭐⭐】\n4. Java 基本类型有哪几种，各占多少位？【⭐⭐】前些年面试常问的一个问题，去年面试过程中只京东问我了\n5. Java 泛型，类型擦除。【⭐⭐⭐】\n6. `==` 和 `equals()` 的区别。【⭐⭐⭐】：这个问题在 2018 年之前几乎是面试必问的问题，但是现在大厂以及比较少问了，现在小厂中厂问的多。\n7. **`hashCode()` 和 `equals()`** 【⭐⭐⭐⭐】：这个问题经常问，面试官经常问为什么重写 `equals()` 时要重写 `hashCode()` 方法？另外，这个问题经常结合着 `HashSet` 问。\n8. **重载和重写的区别。** 【⭐⭐⭐⭐】\n9. 深拷贝和浅拷贝。【⭐】\n10. 面向对象和面向过程的区别。【⭐⭐⭐】\n11. 成员变量与局部变量的区别。【⭐⭐⭐】\n12. 面向对象三大特性是什么。并解释这三大特性。【⭐⭐⭐⭐】\n13. **`String`、`StringBuffer` 和 `StringBuilder` 的区别。** 【⭐⭐⭐⭐】\n14. Java 异常。【⭐⭐⭐】：不会问的特别细。经常的问法是异常可以分为哪几种，然后你答了可检查异常和不可检查异常以后，会让你举例可检查异常有哪些，不可检查有哪些。然后，异常的代码要会写，有一场字节的面试，直接让我写一个把异常捕获了然后抛出去的代码。\n15. 序列化和反序列化【⭐⭐】\n16. 反射【⭐⭐】面试官可能会问你什么是反射，它的优缺点是什么，有哪些应用场景。\n17. `List`、Set`、` `Map` 的区别。【⭐⭐】\n18. **`ArrayList` 和 `LinkedList` 的区别。**【⭐⭐⭐⭐】：答清楚每个分别采用什么数据结构，对比相应的优点和缺点。\n19. 比较 `HashSet`、`LinkedHashSet` 和 `TreeSet` 三者的异同。【⭐⭐⭐】\n20. HashMap 多线程操作导致死循环问题。【⭐⭐⭐】jdk 1.8 后解决了这个问题，但是还是不建议在多线程下使用 `HashMap`,因为多线程下使用 `HashMap` 还是会存在其他问题比如数据丢失。并发环境下推荐使用 `ConcurrentHashMap` 。\n21. HashMap 的长度为什么是 2 的幂次方。【⭐⭐⭐】主要是考虑到了对运算效率的提升。\n22. **`HashMap`、`HashTable`、以及 `ConcurrentHashMap` 的区别。**【⭐⭐⭐⭐⭐】：现在面试的超高频考点。当面试官问到这个问题的时候，展现你背面试八股文能力的机会来了。你可以展开去讲在 Java7 和 Java8 中 `HashMap` 分别采用什么数据结构，为什么 Java8 把之前的`头插法`改成了`尾插法`，怎样实现`扩容`，为什么`负载因子`是 `0.75`，为什么要用`红黑树`等等一系列的东西。\n\n## JVM 《深入理解 Java 虚拟机》\n\n1. 运行时数据区中包含哪些区域？哪些线程共享？哪些线程独享？【⭐⭐⭐⭐⭐】\n2. 说一下方法区和永久代的关系。【⭐⭐⭐】\n3. 讲一下 Java 创建一个对象的过程。【⭐⭐⭐⭐】\n4. 对象的访问定位的两种方式（句柄和直接指针两种方式）。【⭐⭐⭐⭐⭐】\n5. 你了解分代理论吗？讲一下 Minor GC、还有 Full GC。【⭐⭐⭐⭐⭐】\n6. Java 用什么方法确定哪些对象该被清理？ 讲一下可达性分析算法的流程。【⭐⭐⭐⭐】\n7. JDK 中有几种引用类型？分别的特点是什么？【⭐⭐】\n8. 如何回收方法区？【⭐⭐⭐】\n9. 标记清楚、标记复制、标记整理分别是怎样清理垃圾的？各有什么优缺点？【⭐⭐⭐⭐⭐】\n10. JVM 中的安全点和安全区各代表什么？写屏障你了解吗？【⭐⭐⭐⭐】\n11. 并发标记要解决什么问题？并发标记带来了什么问题？如何解决并发扫描时对象消失问题？【⭐⭐⭐⭐】相关阅读：[面试官:你说你熟悉 jvm?那你讲一下并发的可达性分析](https://juejin.cn/post/6844904070788939790) 。\n12. 对于 JVM 的垃圾收集器你有什么了解的？【⭐⭐⭐⭐】有时候面试官会问出这种十分开放性的问题，你需要脑子里过一下你对这个大问题下的哪些知识熟悉哪些不熟悉，不熟悉的点一下就过，熟悉的展开讲。在准备校招时，我的一个是阿里 P7 的学姐，给我做过一次模拟面试，问出这个问题时让我有点懵，那么多东西我不知道从哪开始回答呀，就答得很凌乱。模拟面试完我问她这种问题应该从哪开始回答？ 她说她因为不知道我的掌握情况，所以就先问一个大问题，根据我的回答再追问，以后遇到这种问题主要从自己熟悉得方面切入就可以了。后来的面试还真遇到过好几次这种情况，我就答，垃圾收集器的种类有以下几种 Serial，ParNew...现在用的多的还是 CMS 和 G1，CMS 的垃圾收集流程是 xxx，G1 的垃圾收集流程是 xxx，他们特点是...就这样把话题引到 CMS 和 G1 了，只 CMS 和 G1 这部分和面试官讨论十几分钟完全没问题。\n13. 新生代垃圾收集器有哪些？老年代垃圾收集器有哪些？哪些是单线程垃圾收集器，哪些是多线程垃圾收集器？各有什么特点？各基于哪一种垃圾收集算法？【⭐⭐⭐⭐】\n14. 讲一下 CMS 垃圾收集器的四个步骤。CMS 有什么缺点？【⭐⭐⭐⭐】\n15. G1 垃圾收集器的步骤。有什么缺点？【⭐⭐⭐⭐】\n16. 讲一下内存分配策略？【⭐⭐⭐⭐】\n17. 虚拟机基础故障处理工具有哪些？【⭐⭐⭐】\n18. 什么是字节码？类文件结构的组成了解吗？【⭐⭐⭐⭐】\n19. 类的生命周期？类加载的过程了解么？加载这一步主要做了什么事情？初始化阶段中哪几种情况必须对类初始化？【⭐⭐⭐⭐⭐】\n20. 讲一下双亲委派模型。【⭐⭐⭐⭐⭐】\n\n\n## MySQL 《深入浅出MySQL》\n\n好了，现在正式进入 MySQL 面试八股文的划重点流程。在这里要推荐一本书籍《深入浅出 MySQL 》。\n\n![img](https://img-blog.csdnimg.cn/20210620170853137.png)\n\n- **推荐理由** ：《深入浅出 MySQL》这本书是网易的数据库专家写的，从数据库的基础、开发、优化、管理维护、架构，五个层面讲述了 MySQL（大家面试后端的话管理维护篇就不用看了），内容层层递进。并且每讲解一个小的知识点都会相应的配有实例，更容易读者理解。\n- **学习内容** ：学习内容按照《深入浅出 MySQL》的目录进行介绍。根据章节内容列出的问题我就不附上答案了，大家根据我的问题自己总结下会有更好的学校效果。在补充篇的问题我会给出答案。\n\n**基础篇第2章 SQL 基础**\n\n基础的SQL语句肯定要会，并且要熟练，这是最基础的。\n\n针对本章内容的面试问题：\n\n（1）增删改查这些问题面试官一般不会问的。不过万一问出来，比如“查询用哪个关键字”，你要是不知道你就惨了哈。\n\n（2）ORDER BY、LIMIT、GROUP BY、HAVING 这些关键字分别是做什么用的。\n\n（3）讲一下左链接和右链接的区别。\n\n**基础篇第3章、第4章、第5章**\n\n这三章分别是MySQL的数据类型、运算符、常用函数。简单过一遍，了解就行，这三章在面试中很少会被问到。\n\n**开发篇第7章 表类型（存储引擎）的选择**\n\nInnoDB是面试考察的重点，相关知识都要详细看。另外要拿 InnoDB 对比 MyISAM、MEMORY 去体会 InnoDB 引擎的特点。\n\n针对本章内容的面试问题：\n\nInnoDB 和 MyISM、MEMORY 的区别是什么。\n\n**开发篇第10章 索引的设计和使用**\n\n索引是 MySQL 面试考察的重点，BTree 索引和 Hash 索引要对比着进行学习。\n\n针对本章内容的面试问题：\n\n（1）索引所采用的数据结构，以及为什么要这样设计。\n\n（1）在数据库中创建索引的原则。\n\n（2）BTree 索引和 Hash 索引的适用范围。\n\n**开发篇第11章 视图**\n\n本章做到基本了解，面试过程中问的少。\n\n**开发篇第14章 事务控制和锁定语句**\n\nInnoDB 是行锁，MyISAM、MEMORY 是表锁面试过程中经常会问到。本章的事务控制实例值得好好的体会一下，有利于加深对数据库锁的理解。\n\n**优化篇第18章 SQL优化**\n\n如果你在简历中和开头的自我介绍中强调了你对 MySQL 熟悉，那么你这一章一定要好好看。面试官想考察你在 MySQL 方面的能力是否和你之前说的相符，会倾向于出一道场景问题，让你去设计并优化（当然只是好好看这一章并不能完全解决问题，一会我做一点补充）。\n\n针对本章内容的面试问题：\n\n（1）优化 SQL 语句的步骤有哪些。\n\n（2）哪些场景可以使用索引。\n\n（3）索引在哪些情况会失效。\n\n虽然面试官不会直接问你在优化 SQL 语句时候有哪些技巧？比如怎样优化 Insert 语句，怎样优化 order by语句。但是可以在这一章学一些常用的优化 SQL 语句的技巧，在面试官问一个具体问题时，顺带说一下自己平时会采用这些技巧去优化。\n\n**优化篇第20章 锁问题**\n\n这一章属于第14章的拔高，大家主要看表锁和行锁，页锁被问到的比较少。\n\n针对本章内容的面试问题：\n\n（1）事务四大特性，并解释这四大特性的含义。\n\n（2）并发事务处理会带来哪些问题？\n\n（3）事务隔离级别。\n\n（4）InnoDB 行锁实现方式\n\n（5）你了解 Next-key 锁吗？\n\n（6）如何避免 InnoDB 中的死锁。\n\n（7）数据库多版本并发控制（MVCC 机制）\n\n**优化篇第21章 优化 MySQL Server**\n\n这一章在校招面试中是不会问到的，不过我把这里的相关知识学了去给面试官讲，效果还不错。大家根据自己的情况酌情选择看还是不看哈。\n\n可以和面试官展开聊的知识点：\n\n（1）MySQL 的内存管理及优化。\n\n（2）InnoDB 重做日志的内部机制，这个可以和事务联系起来给面试官讲。\n\n**架构篇第31章 MySQL 复制**\n\n这一章的内容如果你不刻意提到，面试官一般很少主动问。如果大家不打算在 MySQL 这里和面试官多聊，那么这里就可以不看了。如果大家打算在 MySQL 这个环节和面试官展开聊，那么在这里和面试官展开聊是一个不错的选择。\n\n可以和面试官展开聊的知识点：\n\n（1）MySQL 的主从复制原理。\n\n（2）MySQL 的三种复制方式。\n\n（3）MySQL 的异步复制和半同步复制。\n\n（4）如何提高复制的性能。\n\n## Redis 《Redis的设计与实现》\n\n对于没有太多时间准备 Redis 的同学，我在这里给大家准备一些面试常问的八股问题。你在面试大厂时，只要别给面试官对你 Redis 部分太高的期望，你把下面这些问题能回答清楚就算过关了。\n\n1. 什么是 Redis？【⭐⭐】\n2. Redis 除了做缓存，还能做什么？【⭐⭐⭐⭐】\n3. Redis 有哪些数据类型？这些数据类型的应用场景分别是什么？你在项目中用到了吗？【⭐⭐⭐⭐⭐】\n4. Redis6.0 之后为何引入了多线程？【⭐⭐⭐】\n5. Redis 过期数据删除策略讲一下。【⭐⭐⭐】\n6. Redis 的持久化策略了解嘛？分别介绍下 RDB 和 AOF。【⭐⭐⭐⭐】\n7. 什么是缓存穿透？什么是缓存击穿？什么是缓存雪崩？怎么解决（最高频问题）\n8. 设计一个分布式锁？【⭐⭐】\n9. Redis 内存淘汰机制了解么？类似问题：MySQL 里有 2000w 数据，Redis 中只存 20w 的数据，如何保证 Redis 中的数据都是热点数据?【⭐⭐⭐⭐】\n10. Redis 事务你了解嘛？【⭐⭐】\n11. 如何保证 Redis 和 MySQL 的数据一致性？（如果项目同时用到 Redis 和 MySQL，这个问题特别容易被问）【⭐⭐⭐⭐】","source":"_posts/2022-03-10-kongzheng1993-review_point.md","raw":"---\ntitle: 复习知识点\nexcerpt: '面试'\ntags: [面试]\ncategories: [面试]\ncomments: true\ndate: 2022-03-13 18:30:52\n---\n\n## 操作系统 《现代操作系统：原理与实现》\n\n**操作系统基础概念**\n\n操作系统基础概念中比较重要的知识点：\n\n- 操作系统的作用、特点、分类、发展\n- 操作系统的结构\n- 内核态和用户态、系统调用\n\n**进程和线程（重要）**\n\n1. 进程和线程的基本定义，对比一下两者。\n2. 进程和线程的状态以及各种状态之间的转换。\n3. 进程的通信方式： 进程与进程之前是如何进行通信的。\n4. 进程调度算法： CPU 如何应用不同的调度算法来调度进程。\n\n**内存管理（重要）**\n\n面试官可能会先问一些比较简单的问题比如内存管理的目的、逻辑和物理地址。\n\n比较核心一些的问题还是内存管理机制和内存管理相关的一些概念。\n\n- 内存管理机制 ：像内存管理机制简单分为连续分配管理方式和非连续分配管理方式这两种。非连续分配管理方式比较重要，像分页机制、分段机制、段页式机制都属于非连续分配管理。\n- 内存管理相关概念 ： 快表和多级页表。\n\n除此之外，虚拟内存和请求分页也非常重要，面试中也经常会遇到。\n\n- 虚拟内存 ：虚拟内存介绍、局部性原理、虚拟内存的实现机制\n- 请求分页 ： 页表机制、缺页中断、页面置换算法\n\n最后就是死锁相关的内容了，你需要掌握：\n\n- 死锁的必要条件\n- 死锁预防、避免、检测与解除\n\n**CPU 调度**\n\nCPU 调度这块最重要的就是搞懂几种常见的 CPU 调度算法：\n\n- 先到先服务调度(First-Come First-Served Scheduling，FCFS)\n- 最短作业优先调度(Shortest Job First，SJF)\n- 优先级调度（Priority Scheduling）\n- 轮转法调度(Round Robin，RR)\n- ......\n\n上面这几种调度算法，大家通过名字应该就能猜出个大概意义了。这些调度算法各有优劣，没有银弹，只能根据具体场景选择具体的调度算法。\n\n因此，多级队列调度（Multilevel Queue） 就诞生了。简单来说就是把就绪队列（存放有待执行进程）分成多个独立队列，每个队列都有自己的调度算法。\n\n**Linux 相关（重要）**\n\n另外的话，操作系统这块还需要对 Linux 相关的知识有所了解：\n\n- Linux 常用命令 ：比如说创建文件相关的命令、搜索相关的命令\n- Linux 文件系统 ： 文件系统原理、硬链接与软链接、目录结构\n- 僵尸进程和孤儿进程\n\n\n## 计算机网络 《计算机网络——自顶向下方法》\n\n**网络层**\n\n网络层面试问的也相对较少，主要就是问IPV4，偶尔问一下ARP地址解析协议的的工作原理。\n\n1.首先要记清楚 IPV4 地址是怎么分类的、以及地址的格式。这里经常结合代码题一起问你，我和很多同学都在面试中被面试官要求写一个程序判断给定的字符串是否是 IPV4 地址。\n\n2.IPV4 子网划分面试中不怎么问，笔试题时经常有这个问题。\n\n3.了解 IP 地址和 Mac 地址的区别，了解 ARP 地址解析协议并了解其工作原理。\n\n**传输层**\n\n面试中计算机网络的问题最常出现在这一章中。\n\n1.记清楚 TCP 和 UDP 的区别。\n\n2.TCP三次握手和UDP四次挥手。\n\n这是面试计算机网络最最最常问的问题！！！你计算机网络就算其它的什么也不会，这个问题你必须要记清楚，如果面试官问出你这个问题你都答不上，面试官估计觉得你连敷衍都不想敷衍他了。\n\n当面试官问你三次握手和四次挥手时，你要答出这三个点来。（1）为什么要三次挥手和四次挥手，如果不这样做会有什么影响。（2）三次握手四次挥手的整个流程。（3）有的面试官只要你答出三次握手和四次挥手的大体流程就好了，但是有的面试官会要求你答出三次握手和四次挥手时发送端和接收端分别发了哪些标记。就像下面 Guide哥 画的这张图一样。\n\n![](https://img-blog.csdnimg.cn/20210727212425498.png)\n\n3.TCP协议如何保证可靠传输\n\n把 ARQ 协议、滑动窗口、流量控制、拥塞控制等回答清楚就算到位了。\n\n应用层 ：\n\n（1）另一个最最最常问的问题，”在浏览器中输入 URL 地址到浏览器显示网页这个过程中计算机网络做了什么“。\n\n这个问题无论时考研还是找工作都是常见的，建议把 JavaGuide 中这个问题的总结熟读并全文背诵。\n\n（2）HTTP 1.0 和 HTTP 1.1 的主要区别\n\n这个也要了解一下。\n\n（3）HTTP 和 HTTPS 的区别\n\n这个也是面试常考问题，这个问题展开以后能问的就比较多了。\n\n在回答这个问题时你首先分别介绍一下 HTTP 和 HTTPS 的原理，以及区别。大致就是 HTTP 是通过明文在网络上传输的，HTTPS 是加密的。然后有的面试官问到这也就可以了，有的面试官不讲武德，想搞偷袭，会继续让你讲 HTTPS 建立连接的流程、然后会继续追着你问SSL 的工作流程。建议把这里好好准备一下，面试官一问你就可以展开讲，你就能消耗很多面试时间，这样面试官问其它问题的时间就少了，嘿嘿。\n\n（4）HTTP请求常见的状态码\n\n背几个常用的就好。\n\n（5）DNS域名系统\n\n这里你要可以描述清楚工作原理。也是面试常问问题，当除考研我也重点背过这里。\n\n**网络接口层**\n\n把网卡、网桥、交换机的概念、用途简单了解下就好，一般面试官不会问。\n\n好了，把这些问题搞清楚，应付面试官应该就没什么问题了，赶紧去总结下答案然后好好背吧。如果你时间充分，想系统学一下计算机网络，那你就接着往下看。\n\n\n## 数据结构 可以在下面的算法书中学习\n\n数据结构的种类非常多，不过最常用同时也是面试最常问的数据结构主要就是下面这些：\n\n- **线性数据结构**：\n  - **数组** ：数组（Array） 是一种很常见的数据结构。它由相同类型的元素（element）组成，并且是使用一块连续的内存来存储。\n  - **链表** ：链表（LinkedList） 虽然是一种线性表，但是并不会按线性的顺序存储数据，使用的不是连续的内存空间来存储数据。链表的插入和删除操作的复杂度为 O(1) ，只需要知道目标位置元素的上一个元素即可。但是，在查找一个节点或者访问特定位置的节点的时候复杂度为 O(n) 。\n  - **栈** ：栈 (Stack)只允许在有序的线性数据集合的一端（称为栈顶 top）进行加入数据（push）和移除数据（pop）。因而按照 后进先出（LIFO, Last In First Out） 的原理运作。在栈中，push 和 pop 的操作都发生在栈顶。栈常用一维数组或链表来实现，用数组实现的栈叫作 顺序栈 ，用链表实现的栈叫作 链式栈 。\n  - **队列** ： 队列（Queue）是 先进先出( FIFO，First In, First Out) 的线性表。在具体应用中通常用链表或者数组来实现，用数组实现的队列叫作 顺序队列 ，用链表实现的队列叫作 链式队列 。队列只允许在后端（rear）进行插入操作也就是 入队 enqueue，在前端（front）进行删除操作也就是出队 dequeue。队列的操作方式和堆类似，唯一的区别在于队列只允许新数据在后端进行添加。\n- **图** ：图就是由顶点的有穷非空集合和顶点之间的边组成的集合。通常表示为：**G(V,E)**，其中，G 表示一个图，V 表示顶点的集合，E 表示边的集合。图可以被简单的分为：无向图和有向图，无权图和带权图。\n- **树** : 树就是一种类似现实生活中的树的数据结构（倒置的树）。任何一颗非空树只有一个根节点。常见的树的种类有：平衡树、二叉搜索树、平衡二叉树、红黑树、B 树、LSM 树、字典树（Trie 树）\n- **堆** ：堆是一种满足特定条件的树：堆中的每一个节点值都大于等于（或小于等于）子树中所有节点的值。或者说，任意一个节点的值都大于等于（或小于等于）所有子节点的值。堆分为最大堆和最小堆。\n- **哈希表** ：也叫散列表，是根据关键码值(Key value)而直接进行访问的数据结构，通过 key 就能获取到指定的 value ，速度非常快。\n- **跳表** ：跳表（Skip List）是由 William Pugh 发明的一种查找数据结构，支持对数据的快速查找，插入和删除。跳表的查询，插入和删除操作的期望时间复杂度都为 O(log n)。\n\n**常见问题总结** ：\n\n- **通用常识**：像数据结构的定义，查找、插入、删除元素的时间复杂度，应用场景是每一个数据结构都应该掌握的最基本的点。\n- **线性数据结构** ：\n  - 数组 vs 链表\n  - 栈 vs 队列\n  - 实现一个栈/队列\n  - 翻转链表、返回链表中倒数第 n 个节点、链表合并......\n- **图** ：\n  - 图的常见概念比如顶点的度\n  - 图的遍历算法（广度优先搜索和深度优先搜索）\n  - 拓扑排序\n  - 欧拉回路\n  - 迪杰斯特拉（Dijikstra）算法（最短路径问题）\n- **树** ：\n  - 二叉树的前序遍历、中序遍历、后序遍历\n  - 二叉查找树的出插入、查找、删除\n  - 二叉树的高度计算\n  - 红黑树 vs 二叉查找树\n- **堆** ：\n  - 堆中插入数据\n  - 如何删除堆顶元素\n  - 堆排序\n- **哈希表** ：\n  - 哈希冲突是什么？如何解决？\n  - 键值的映射关系如何维护？哈希函数如何设计？\n- **跳表**：\n  - 为什么 Redis 选择使用跳表而不是红黑树来实现有序集合？\n  - 跳表的查找、插入、删除元素的流程\n  - 跳表插入元素时，如何动态维护索引？\n\n\n## 算法  《算法》 《我的第一本算法书》 《算法导论》 《编程珠玑》\n\n和框架应用类知识不同，算法仅仅通过一周甚至是一个月的突击是完全没办法快速上手的！\n\n想要在算法面试中如鱼得水，就必须持之以恒地坚持刷题-> 总结->再刷题 -> 再总结。\n\n你需要做的就是提前半年甚至是一年来刷 Leetcode，并总结一些常见题目类型的套路！\n\n**那我们应该怎么更高效低刷题呢？** 给几点自己的刷题建议：\n\n- **按照类型来刷** ：一般情况下，一个类型的题目刷 5~10 道左右就够了！\n- **由简入难** ：刷算法是一个循序渐进的过程，如果你不是 ACM 大佬这种级别的人物的话，还是建议先从简单开始刷起，慢慢积累经验。不过，要说明的一点是：很多简单类型的题目甚至还要比中等类型的题目还要难！所以，如果你没办法解决一些简单的算法题，也不要太纠结，不要因此失去信心。\n- **重点关注面试高频题目/题型** ：如果你的时间不是很充足的话，建议可以从高频面试题入手。像 Leetcode 上面就专门把一些最热门的算法面试题给单独整理了出来。\n- **多思考** ：一定不要遇到不会的算法题就直接看别人的答案，这样会让自己形成依赖心理。一定要先思考，一定要多思考！\n- ......\n\n刷题之前，我建议你应该具有基本的算法基础。比如你应该搞清楚常见的算法思想（递归、动态规划、二分查找、贪心、分治、回溯、DFS、BFS、KMP、树的广度和深度优先搜索）；再比如你可能还需要一点点的数学知识（比如位运算、质数）基础。\n\n另外， 网上也有很多算法大佬开源了自己的刷题经验，这些经验都是前辈刷题之后得出的，非常具有参考价值。利用得当的话，可以极大减轻自己的刷题压力。推荐你看看我整理的 [《阿里ACM大佬开源的Leetcode刷题指南》](https://mp.weixin.qq.com/s/7b4JDVA_s27wCLQD7SACXg) 。\n\n## Java并发 《Java 并发实现原理：JDK 源码剖析》\n\n1. 进程和线程的区别。【⭐⭐⭐⭐⭐】这是一个超高频考点，面试回答时别一句一个进程包含很多线程就没了。要答清楚什么是线程什么是进程，线程和进程各自的`运行状态`、线程的`通信方式`和进程的`通信方式`。\n2. 创建线程的方式。【⭐⭐⭐⭐】不仅要把创建线程的方式记熟、记住各种方式的优缺点，还要能写出代码来。有的面试官是会让你写代码创建两个线程然后执行一些操作的，比如两个线程交替输出数字。\n3. 什么是死锁，死锁如何产生，死锁如何避免。【⭐⭐⭐⭐⭐】超高频问题，几乎大厂的一面和二面都会问到。\n4. 并发编程的三大特性（原子性、可见性以及有序性）。【⭐⭐⭐⭐】\n5. `synchronized` 锁升级流程。【⭐⭐⭐⭐⭐】这又是面试八股文的一大考点，锁升级流程记清楚。\n6. `volatile` 关键字。【⭐⭐⭐⭐⭐】对比和 `synchronized` 的区别。\n7. `JMM`（Java Memory Model，Java 内存模型）和 `happens-before` 原则。【⭐⭐⭐⭐⭐】面试中重点！几乎必问。\n8. `ThreadLocal`。【⭐⭐⭐⭐】这也是面试八股文的一个高频考点。我面试到后面不想背这里了，面试过程中就尽可能躲着这个知识点，不提到和这相关的，竟然真的苟过去了。\n9. 线程池。【⭐⭐⭐⭐⭐】超高频考点。需要答出线程池有哪几种，各种线程池的优缺点，线程池的重要参数、线程池的`执行流程`、线程池的饱和策略、如何设置线程池的大小等等。这里也能背十几分钟。\n10. `ReentrantLock` 和 `AQS`。【⭐⭐⭐⭐⭐】其实我在面试的时候对这里不是很熟，我面试的时候尽量不提到这里，也苟过去了。大家如果时间充足的话还是把这块好好理解一下。如果这里理解透彻了，也能在这里和面试官聊很久。\n11. 乐观锁和悲观锁的区别。【⭐⭐⭐⭐⭐】\n12. `CAS` 了解么？原理？什么是 ABA 问题？ABA 问题怎么解决？【⭐⭐⭐⭐⭐】`CAS`（Compare-and-Swap）绝对是面试中的高频中的高频，很多地方都用到了 `CAS` 比如 `ConcurrentHashMap` 采用 `CAS` 和 `synchronized` 来保证并发安全，再比如`java.util.concurrent.atomic`包中的类通过 `volatile+CAS` 重试保证线程安全性。和面试官聊 `CAS` 的时候，你可以结合 `CAS` 的一些实际应用来说。\n13. `Atomic` 原子类【⭐⭐】\n\n\n## Java基础 《Java 编程的逻辑》\n\n1. Java 语言的特点（如果你简历上有提到 C++ 可能还会问你 Java 和 C++ 的区别）。【⭐⭐】\n2. 比较 JVM 和 JDK 以及 JRE 。【⭐⭐⭐】非常非常基础的一个问题！学了 Java 之后还不知这个问题如何回答的小伙伴自觉去面壁吧！\n3. 为什么说 Java 语言“解释与编译并存”。【⭐⭐】\n4. Java 基本类型有哪几种，各占多少位？【⭐⭐】前些年面试常问的一个问题，去年面试过程中只京东问我了\n5. Java 泛型，类型擦除。【⭐⭐⭐】\n6. `==` 和 `equals()` 的区别。【⭐⭐⭐】：这个问题在 2018 年之前几乎是面试必问的问题，但是现在大厂以及比较少问了，现在小厂中厂问的多。\n7. **`hashCode()` 和 `equals()`** 【⭐⭐⭐⭐】：这个问题经常问，面试官经常问为什么重写 `equals()` 时要重写 `hashCode()` 方法？另外，这个问题经常结合着 `HashSet` 问。\n8. **重载和重写的区别。** 【⭐⭐⭐⭐】\n9. 深拷贝和浅拷贝。【⭐】\n10. 面向对象和面向过程的区别。【⭐⭐⭐】\n11. 成员变量与局部变量的区别。【⭐⭐⭐】\n12. 面向对象三大特性是什么。并解释这三大特性。【⭐⭐⭐⭐】\n13. **`String`、`StringBuffer` 和 `StringBuilder` 的区别。** 【⭐⭐⭐⭐】\n14. Java 异常。【⭐⭐⭐】：不会问的特别细。经常的问法是异常可以分为哪几种，然后你答了可检查异常和不可检查异常以后，会让你举例可检查异常有哪些，不可检查有哪些。然后，异常的代码要会写，有一场字节的面试，直接让我写一个把异常捕获了然后抛出去的代码。\n15. 序列化和反序列化【⭐⭐】\n16. 反射【⭐⭐】面试官可能会问你什么是反射，它的优缺点是什么，有哪些应用场景。\n17. `List`、Set`、` `Map` 的区别。【⭐⭐】\n18. **`ArrayList` 和 `LinkedList` 的区别。**【⭐⭐⭐⭐】：答清楚每个分别采用什么数据结构，对比相应的优点和缺点。\n19. 比较 `HashSet`、`LinkedHashSet` 和 `TreeSet` 三者的异同。【⭐⭐⭐】\n20. HashMap 多线程操作导致死循环问题。【⭐⭐⭐】jdk 1.8 后解决了这个问题，但是还是不建议在多线程下使用 `HashMap`,因为多线程下使用 `HashMap` 还是会存在其他问题比如数据丢失。并发环境下推荐使用 `ConcurrentHashMap` 。\n21. HashMap 的长度为什么是 2 的幂次方。【⭐⭐⭐】主要是考虑到了对运算效率的提升。\n22. **`HashMap`、`HashTable`、以及 `ConcurrentHashMap` 的区别。**【⭐⭐⭐⭐⭐】：现在面试的超高频考点。当面试官问到这个问题的时候，展现你背面试八股文能力的机会来了。你可以展开去讲在 Java7 和 Java8 中 `HashMap` 分别采用什么数据结构，为什么 Java8 把之前的`头插法`改成了`尾插法`，怎样实现`扩容`，为什么`负载因子`是 `0.75`，为什么要用`红黑树`等等一系列的东西。\n\n## JVM 《深入理解 Java 虚拟机》\n\n1. 运行时数据区中包含哪些区域？哪些线程共享？哪些线程独享？【⭐⭐⭐⭐⭐】\n2. 说一下方法区和永久代的关系。【⭐⭐⭐】\n3. 讲一下 Java 创建一个对象的过程。【⭐⭐⭐⭐】\n4. 对象的访问定位的两种方式（句柄和直接指针两种方式）。【⭐⭐⭐⭐⭐】\n5. 你了解分代理论吗？讲一下 Minor GC、还有 Full GC。【⭐⭐⭐⭐⭐】\n6. Java 用什么方法确定哪些对象该被清理？ 讲一下可达性分析算法的流程。【⭐⭐⭐⭐】\n7. JDK 中有几种引用类型？分别的特点是什么？【⭐⭐】\n8. 如何回收方法区？【⭐⭐⭐】\n9. 标记清楚、标记复制、标记整理分别是怎样清理垃圾的？各有什么优缺点？【⭐⭐⭐⭐⭐】\n10. JVM 中的安全点和安全区各代表什么？写屏障你了解吗？【⭐⭐⭐⭐】\n11. 并发标记要解决什么问题？并发标记带来了什么问题？如何解决并发扫描时对象消失问题？【⭐⭐⭐⭐】相关阅读：[面试官:你说你熟悉 jvm?那你讲一下并发的可达性分析](https://juejin.cn/post/6844904070788939790) 。\n12. 对于 JVM 的垃圾收集器你有什么了解的？【⭐⭐⭐⭐】有时候面试官会问出这种十分开放性的问题，你需要脑子里过一下你对这个大问题下的哪些知识熟悉哪些不熟悉，不熟悉的点一下就过，熟悉的展开讲。在准备校招时，我的一个是阿里 P7 的学姐，给我做过一次模拟面试，问出这个问题时让我有点懵，那么多东西我不知道从哪开始回答呀，就答得很凌乱。模拟面试完我问她这种问题应该从哪开始回答？ 她说她因为不知道我的掌握情况，所以就先问一个大问题，根据我的回答再追问，以后遇到这种问题主要从自己熟悉得方面切入就可以了。后来的面试还真遇到过好几次这种情况，我就答，垃圾收集器的种类有以下几种 Serial，ParNew...现在用的多的还是 CMS 和 G1，CMS 的垃圾收集流程是 xxx，G1 的垃圾收集流程是 xxx，他们特点是...就这样把话题引到 CMS 和 G1 了，只 CMS 和 G1 这部分和面试官讨论十几分钟完全没问题。\n13. 新生代垃圾收集器有哪些？老年代垃圾收集器有哪些？哪些是单线程垃圾收集器，哪些是多线程垃圾收集器？各有什么特点？各基于哪一种垃圾收集算法？【⭐⭐⭐⭐】\n14. 讲一下 CMS 垃圾收集器的四个步骤。CMS 有什么缺点？【⭐⭐⭐⭐】\n15. G1 垃圾收集器的步骤。有什么缺点？【⭐⭐⭐⭐】\n16. 讲一下内存分配策略？【⭐⭐⭐⭐】\n17. 虚拟机基础故障处理工具有哪些？【⭐⭐⭐】\n18. 什么是字节码？类文件结构的组成了解吗？【⭐⭐⭐⭐】\n19. 类的生命周期？类加载的过程了解么？加载这一步主要做了什么事情？初始化阶段中哪几种情况必须对类初始化？【⭐⭐⭐⭐⭐】\n20. 讲一下双亲委派模型。【⭐⭐⭐⭐⭐】\n\n\n## MySQL 《深入浅出MySQL》\n\n好了，现在正式进入 MySQL 面试八股文的划重点流程。在这里要推荐一本书籍《深入浅出 MySQL 》。\n\n![img](https://img-blog.csdnimg.cn/20210620170853137.png)\n\n- **推荐理由** ：《深入浅出 MySQL》这本书是网易的数据库专家写的，从数据库的基础、开发、优化、管理维护、架构，五个层面讲述了 MySQL（大家面试后端的话管理维护篇就不用看了），内容层层递进。并且每讲解一个小的知识点都会相应的配有实例，更容易读者理解。\n- **学习内容** ：学习内容按照《深入浅出 MySQL》的目录进行介绍。根据章节内容列出的问题我就不附上答案了，大家根据我的问题自己总结下会有更好的学校效果。在补充篇的问题我会给出答案。\n\n**基础篇第2章 SQL 基础**\n\n基础的SQL语句肯定要会，并且要熟练，这是最基础的。\n\n针对本章内容的面试问题：\n\n（1）增删改查这些问题面试官一般不会问的。不过万一问出来，比如“查询用哪个关键字”，你要是不知道你就惨了哈。\n\n（2）ORDER BY、LIMIT、GROUP BY、HAVING 这些关键字分别是做什么用的。\n\n（3）讲一下左链接和右链接的区别。\n\n**基础篇第3章、第4章、第5章**\n\n这三章分别是MySQL的数据类型、运算符、常用函数。简单过一遍，了解就行，这三章在面试中很少会被问到。\n\n**开发篇第7章 表类型（存储引擎）的选择**\n\nInnoDB是面试考察的重点，相关知识都要详细看。另外要拿 InnoDB 对比 MyISAM、MEMORY 去体会 InnoDB 引擎的特点。\n\n针对本章内容的面试问题：\n\nInnoDB 和 MyISM、MEMORY 的区别是什么。\n\n**开发篇第10章 索引的设计和使用**\n\n索引是 MySQL 面试考察的重点，BTree 索引和 Hash 索引要对比着进行学习。\n\n针对本章内容的面试问题：\n\n（1）索引所采用的数据结构，以及为什么要这样设计。\n\n（1）在数据库中创建索引的原则。\n\n（2）BTree 索引和 Hash 索引的适用范围。\n\n**开发篇第11章 视图**\n\n本章做到基本了解，面试过程中问的少。\n\n**开发篇第14章 事务控制和锁定语句**\n\nInnoDB 是行锁，MyISAM、MEMORY 是表锁面试过程中经常会问到。本章的事务控制实例值得好好的体会一下，有利于加深对数据库锁的理解。\n\n**优化篇第18章 SQL优化**\n\n如果你在简历中和开头的自我介绍中强调了你对 MySQL 熟悉，那么你这一章一定要好好看。面试官想考察你在 MySQL 方面的能力是否和你之前说的相符，会倾向于出一道场景问题，让你去设计并优化（当然只是好好看这一章并不能完全解决问题，一会我做一点补充）。\n\n针对本章内容的面试问题：\n\n（1）优化 SQL 语句的步骤有哪些。\n\n（2）哪些场景可以使用索引。\n\n（3）索引在哪些情况会失效。\n\n虽然面试官不会直接问你在优化 SQL 语句时候有哪些技巧？比如怎样优化 Insert 语句，怎样优化 order by语句。但是可以在这一章学一些常用的优化 SQL 语句的技巧，在面试官问一个具体问题时，顺带说一下自己平时会采用这些技巧去优化。\n\n**优化篇第20章 锁问题**\n\n这一章属于第14章的拔高，大家主要看表锁和行锁，页锁被问到的比较少。\n\n针对本章内容的面试问题：\n\n（1）事务四大特性，并解释这四大特性的含义。\n\n（2）并发事务处理会带来哪些问题？\n\n（3）事务隔离级别。\n\n（4）InnoDB 行锁实现方式\n\n（5）你了解 Next-key 锁吗？\n\n（6）如何避免 InnoDB 中的死锁。\n\n（7）数据库多版本并发控制（MVCC 机制）\n\n**优化篇第21章 优化 MySQL Server**\n\n这一章在校招面试中是不会问到的，不过我把这里的相关知识学了去给面试官讲，效果还不错。大家根据自己的情况酌情选择看还是不看哈。\n\n可以和面试官展开聊的知识点：\n\n（1）MySQL 的内存管理及优化。\n\n（2）InnoDB 重做日志的内部机制，这个可以和事务联系起来给面试官讲。\n\n**架构篇第31章 MySQL 复制**\n\n这一章的内容如果你不刻意提到，面试官一般很少主动问。如果大家不打算在 MySQL 这里和面试官多聊，那么这里就可以不看了。如果大家打算在 MySQL 这个环节和面试官展开聊，那么在这里和面试官展开聊是一个不错的选择。\n\n可以和面试官展开聊的知识点：\n\n（1）MySQL 的主从复制原理。\n\n（2）MySQL 的三种复制方式。\n\n（3）MySQL 的异步复制和半同步复制。\n\n（4）如何提高复制的性能。\n\n## Redis 《Redis的设计与实现》\n\n对于没有太多时间准备 Redis 的同学，我在这里给大家准备一些面试常问的八股问题。你在面试大厂时，只要别给面试官对你 Redis 部分太高的期望，你把下面这些问题能回答清楚就算过关了。\n\n1. 什么是 Redis？【⭐⭐】\n2. Redis 除了做缓存，还能做什么？【⭐⭐⭐⭐】\n3. Redis 有哪些数据类型？这些数据类型的应用场景分别是什么？你在项目中用到了吗？【⭐⭐⭐⭐⭐】\n4. Redis6.0 之后为何引入了多线程？【⭐⭐⭐】\n5. Redis 过期数据删除策略讲一下。【⭐⭐⭐】\n6. Redis 的持久化策略了解嘛？分别介绍下 RDB 和 AOF。【⭐⭐⭐⭐】\n7. 什么是缓存穿透？什么是缓存击穿？什么是缓存雪崩？怎么解决（最高频问题）\n8. 设计一个分布式锁？【⭐⭐】\n9. Redis 内存淘汰机制了解么？类似问题：MySQL 里有 2000w 数据，Redis 中只存 20w 的数据，如何保证 Redis 中的数据都是热点数据?【⭐⭐⭐⭐】\n10. Redis 事务你了解嘛？【⭐⭐】\n11. 如何保证 Redis 和 MySQL 的数据一致性？（如果项目同时用到 Redis 和 MySQL，这个问题特别容易被问）【⭐⭐⭐⭐】","slug":"kongzheng1993-review_point","published":1,"updated":"2023-03-08T07:05:58.829Z","layout":"post","photos":[],"link":"","_id":"clg0k2asi00jit26fhbnyicb9","content":"<h2 id=\"操作系统-《现代操作系统：原理与实现》\"><a href=\"#操作系统-《现代操作系统：原理与实现》\" class=\"headerlink\" title=\"操作系统 《现代操作系统：原理与实现》\"></a>操作系统 《现代操作系统：原理与实现》</h2><p><strong>操作系统基础概念</strong></p>\n<p>操作系统基础概念中比较重要的知识点：</p>\n<ul>\n<li>操作系统的作用、特点、分类、发展</li>\n<li>操作系统的结构</li>\n<li>内核态和用户态、系统调用</li>\n</ul>\n<p><strong>进程和线程（重要）</strong></p>\n<ol>\n<li>进程和线程的基本定义，对比一下两者。</li>\n<li>进程和线程的状态以及各种状态之间的转换。</li>\n<li>进程的通信方式： 进程与进程之前是如何进行通信的。</li>\n<li>进程调度算法： CPU 如何应用不同的调度算法来调度进程。</li>\n</ol>\n<p><strong>内存管理（重要）</strong></p>\n<p>面试官可能会先问一些比较简单的问题比如内存管理的目的、逻辑和物理地址。</p>\n<p>比较核心一些的问题还是内存管理机制和内存管理相关的一些概念。</p>\n<ul>\n<li>内存管理机制 ：像内存管理机制简单分为连续分配管理方式和非连续分配管理方式这两种。非连续分配管理方式比较重要，像分页机制、分段机制、段页式机制都属于非连续分配管理。</li>\n<li>内存管理相关概念 ： 快表和多级页表。</li>\n</ul>\n<p>除此之外，虚拟内存和请求分页也非常重要，面试中也经常会遇到。</p>\n<ul>\n<li>虚拟内存 ：虚拟内存介绍、局部性原理、虚拟内存的实现机制</li>\n<li>请求分页 ： 页表机制、缺页中断、页面置换算法</li>\n</ul>\n<p>最后就是死锁相关的内容了，你需要掌握：</p>\n<ul>\n<li>死锁的必要条件</li>\n<li>死锁预防、避免、检测与解除</li>\n</ul>\n<p><strong>CPU 调度</strong></p>\n<p>CPU 调度这块最重要的就是搞懂几种常见的 CPU 调度算法：</p>\n<ul>\n<li>先到先服务调度(First-Come First-Served Scheduling，FCFS)</li>\n<li>最短作业优先调度(Shortest Job First，SJF)</li>\n<li>优先级调度（Priority Scheduling）</li>\n<li>轮转法调度(Round Robin，RR)</li>\n<li>……</li>\n</ul>\n<p>上面这几种调度算法，大家通过名字应该就能猜出个大概意义了。这些调度算法各有优劣，没有银弹，只能根据具体场景选择具体的调度算法。</p>\n<p>因此，多级队列调度（Multilevel Queue） 就诞生了。简单来说就是把就绪队列（存放有待执行进程）分成多个独立队列，每个队列都有自己的调度算法。</p>\n<p><strong>Linux 相关（重要）</strong></p>\n<p>另外的话，操作系统这块还需要对 Linux 相关的知识有所了解：</p>\n<ul>\n<li>Linux 常用命令 ：比如说创建文件相关的命令、搜索相关的命令</li>\n<li>Linux 文件系统 ： 文件系统原理、硬链接与软链接、目录结构</li>\n<li>僵尸进程和孤儿进程</li>\n</ul>\n<h2 id=\"计算机网络-《计算机网络——自顶向下方法》\"><a href=\"#计算机网络-《计算机网络——自顶向下方法》\" class=\"headerlink\" title=\"计算机网络 《计算机网络——自顶向下方法》\"></a>计算机网络 《计算机网络——自顶向下方法》</h2><p><strong>网络层</strong></p>\n<p>网络层面试问的也相对较少，主要就是问IPV4，偶尔问一下ARP地址解析协议的的工作原理。</p>\n<p>1.首先要记清楚 IPV4 地址是怎么分类的、以及地址的格式。这里经常结合代码题一起问你，我和很多同学都在面试中被面试官要求写一个程序判断给定的字符串是否是 IPV4 地址。</p>\n<p>2.IPV4 子网划分面试中不怎么问，笔试题时经常有这个问题。</p>\n<p>3.了解 IP 地址和 Mac 地址的区别，了解 ARP 地址解析协议并了解其工作原理。</p>\n<p><strong>传输层</strong></p>\n<p>面试中计算机网络的问题最常出现在这一章中。</p>\n<p>1.记清楚 TCP 和 UDP 的区别。</p>\n<p>2.TCP三次握手和UDP四次挥手。</p>\n<p>这是面试计算机网络最最最常问的问题！！！你计算机网络就算其它的什么也不会，这个问题你必须要记清楚，如果面试官问出你这个问题你都答不上，面试官估计觉得你连敷衍都不想敷衍他了。</p>\n<p>当面试官问你三次握手和四次挥手时，你要答出这三个点来。（1）为什么要三次挥手和四次挥手，如果不这样做会有什么影响。（2）三次握手四次挥手的整个流程。（3）有的面试官只要你答出三次握手和四次挥手的大体流程就好了，但是有的面试官会要求你答出三次握手和四次挥手时发送端和接收端分别发了哪些标记。就像下面 Guide哥 画的这张图一样。</p>\n<p><img src=\"https://img-blog.csdnimg.cn/20210727212425498.png\" alt></p>\n<p>3.TCP协议如何保证可靠传输</p>\n<p>把 ARQ 协议、滑动窗口、流量控制、拥塞控制等回答清楚就算到位了。</p>\n<p>应用层 ：</p>\n<p>（1）另一个最最最常问的问题，”在浏览器中输入 URL 地址到浏览器显示网页这个过程中计算机网络做了什么“。</p>\n<p>这个问题无论时考研还是找工作都是常见的，建议把 JavaGuide 中这个问题的总结熟读并全文背诵。</p>\n<p>（2）HTTP 1.0 和 HTTP 1.1 的主要区别</p>\n<p>这个也要了解一下。</p>\n<p>（3）HTTP 和 HTTPS 的区别</p>\n<p>这个也是面试常考问题，这个问题展开以后能问的就比较多了。</p>\n<p>在回答这个问题时你首先分别介绍一下 HTTP 和 HTTPS 的原理，以及区别。大致就是 HTTP 是通过明文在网络上传输的，HTTPS 是加密的。然后有的面试官问到这也就可以了，有的面试官不讲武德，想搞偷袭，会继续让你讲 HTTPS 建立连接的流程、然后会继续追着你问SSL 的工作流程。建议把这里好好准备一下，面试官一问你就可以展开讲，你就能消耗很多面试时间，这样面试官问其它问题的时间就少了，嘿嘿。</p>\n<p>（4）HTTP请求常见的状态码</p>\n<p>背几个常用的就好。</p>\n<p>（5）DNS域名系统</p>\n<p>这里你要可以描述清楚工作原理。也是面试常问问题，当除考研我也重点背过这里。</p>\n<p><strong>网络接口层</strong></p>\n<p>把网卡、网桥、交换机的概念、用途简单了解下就好，一般面试官不会问。</p>\n<p>好了，把这些问题搞清楚，应付面试官应该就没什么问题了，赶紧去总结下答案然后好好背吧。如果你时间充分，想系统学一下计算机网络，那你就接着往下看。</p>\n<h2 id=\"数据结构-可以在下面的算法书中学习\"><a href=\"#数据结构-可以在下面的算法书中学习\" class=\"headerlink\" title=\"数据结构 可以在下面的算法书中学习\"></a>数据结构 可以在下面的算法书中学习</h2><p>数据结构的种类非常多，不过最常用同时也是面试最常问的数据结构主要就是下面这些：</p>\n<ul>\n<li><strong>线性数据结构</strong>：<ul>\n<li><strong>数组</strong> ：数组（Array） 是一种很常见的数据结构。它由相同类型的元素（element）组成，并且是使用一块连续的内存来存储。</li>\n<li><strong>链表</strong> ：链表（LinkedList） 虽然是一种线性表，但是并不会按线性的顺序存储数据，使用的不是连续的内存空间来存储数据。链表的插入和删除操作的复杂度为 O(1) ，只需要知道目标位置元素的上一个元素即可。但是，在查找一个节点或者访问特定位置的节点的时候复杂度为 O(n) 。</li>\n<li><strong>栈</strong> ：栈 (Stack)只允许在有序的线性数据集合的一端（称为栈顶 top）进行加入数据（push）和移除数据（pop）。因而按照 后进先出（LIFO, Last In First Out） 的原理运作。在栈中，push 和 pop 的操作都发生在栈顶。栈常用一维数组或链表来实现，用数组实现的栈叫作 顺序栈 ，用链表实现的栈叫作 链式栈 。</li>\n<li><strong>队列</strong> ： 队列（Queue）是 先进先出( FIFO，First In, First Out) 的线性表。在具体应用中通常用链表或者数组来实现，用数组实现的队列叫作 顺序队列 ，用链表实现的队列叫作 链式队列 。队列只允许在后端（rear）进行插入操作也就是 入队 enqueue，在前端（front）进行删除操作也就是出队 dequeue。队列的操作方式和堆类似，唯一的区别在于队列只允许新数据在后端进行添加。</li>\n</ul>\n</li>\n<li><strong>图</strong> ：图就是由顶点的有穷非空集合和顶点之间的边组成的集合。通常表示为：<strong>G(V,E)</strong>，其中，G 表示一个图，V 表示顶点的集合，E 表示边的集合。图可以被简单的分为：无向图和有向图，无权图和带权图。</li>\n<li><strong>树</strong> : 树就是一种类似现实生活中的树的数据结构（倒置的树）。任何一颗非空树只有一个根节点。常见的树的种类有：平衡树、二叉搜索树、平衡二叉树、红黑树、B 树、LSM 树、字典树（Trie 树）</li>\n<li><strong>堆</strong> ：堆是一种满足特定条件的树：堆中的每一个节点值都大于等于（或小于等于）子树中所有节点的值。或者说，任意一个节点的值都大于等于（或小于等于）所有子节点的值。堆分为最大堆和最小堆。</li>\n<li><strong>哈希表</strong> ：也叫散列表，是根据关键码值(Key value)而直接进行访问的数据结构，通过 key 就能获取到指定的 value ，速度非常快。</li>\n<li><strong>跳表</strong> ：跳表（Skip List）是由 William Pugh 发明的一种查找数据结构，支持对数据的快速查找，插入和删除。跳表的查询，插入和删除操作的期望时间复杂度都为 O(log n)。</li>\n</ul>\n<p><strong>常见问题总结</strong> ：</p>\n<ul>\n<li><strong>通用常识</strong>：像数据结构的定义，查找、插入、删除元素的时间复杂度，应用场景是每一个数据结构都应该掌握的最基本的点。</li>\n<li><strong>线性数据结构</strong> ：<ul>\n<li>数组 vs 链表</li>\n<li>栈 vs 队列</li>\n<li>实现一个栈/队列</li>\n<li>翻转链表、返回链表中倒数第 n 个节点、链表合并……</li>\n</ul>\n</li>\n<li><strong>图</strong> ：<ul>\n<li>图的常见概念比如顶点的度</li>\n<li>图的遍历算法（广度优先搜索和深度优先搜索）</li>\n<li>拓扑排序</li>\n<li>欧拉回路</li>\n<li>迪杰斯特拉（Dijikstra）算法（最短路径问题）</li>\n</ul>\n</li>\n<li><strong>树</strong> ：<ul>\n<li>二叉树的前序遍历、中序遍历、后序遍历</li>\n<li>二叉查找树的出插入、查找、删除</li>\n<li>二叉树的高度计算</li>\n<li>红黑树 vs 二叉查找树</li>\n</ul>\n</li>\n<li><strong>堆</strong> ：<ul>\n<li>堆中插入数据</li>\n<li>如何删除堆顶元素</li>\n<li>堆排序</li>\n</ul>\n</li>\n<li><strong>哈希表</strong> ：<ul>\n<li>哈希冲突是什么？如何解决？</li>\n<li>键值的映射关系如何维护？哈希函数如何设计？</li>\n</ul>\n</li>\n<li><strong>跳表</strong>：<ul>\n<li>为什么 Redis 选择使用跳表而不是红黑树来实现有序集合？</li>\n<li>跳表的查找、插入、删除元素的流程</li>\n<li>跳表插入元素时，如何动态维护索引？</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"算法-《算法》-《我的第一本算法书》-《算法导论》-《编程珠玑》\"><a href=\"#算法-《算法》-《我的第一本算法书》-《算法导论》-《编程珠玑》\" class=\"headerlink\" title=\"算法  《算法》 《我的第一本算法书》 《算法导论》 《编程珠玑》\"></a>算法  《算法》 《我的第一本算法书》 《算法导论》 《编程珠玑》</h2><p>和框架应用类知识不同，算法仅仅通过一周甚至是一个月的突击是完全没办法快速上手的！</p>\n<p>想要在算法面试中如鱼得水，就必须持之以恒地坚持刷题-&gt; 总结-&gt;再刷题 -&gt; 再总结。</p>\n<p>你需要做的就是提前半年甚至是一年来刷 Leetcode，并总结一些常见题目类型的套路！</p>\n<p><strong>那我们应该怎么更高效低刷题呢？</strong> 给几点自己的刷题建议：</p>\n<ul>\n<li><strong>按照类型来刷</strong> ：一般情况下，一个类型的题目刷 5~10 道左右就够了！</li>\n<li><strong>由简入难</strong> ：刷算法是一个循序渐进的过程，如果你不是 ACM 大佬这种级别的人物的话，还是建议先从简单开始刷起，慢慢积累经验。不过，要说明的一点是：很多简单类型的题目甚至还要比中等类型的题目还要难！所以，如果你没办法解决一些简单的算法题，也不要太纠结，不要因此失去信心。</li>\n<li><strong>重点关注面试高频题目/题型</strong> ：如果你的时间不是很充足的话，建议可以从高频面试题入手。像 Leetcode 上面就专门把一些最热门的算法面试题给单独整理了出来。</li>\n<li><strong>多思考</strong> ：一定不要遇到不会的算法题就直接看别人的答案，这样会让自己形成依赖心理。一定要先思考，一定要多思考！</li>\n<li>……</li>\n</ul>\n<p>刷题之前，我建议你应该具有基本的算法基础。比如你应该搞清楚常见的算法思想（递归、动态规划、二分查找、贪心、分治、回溯、DFS、BFS、KMP、树的广度和深度优先搜索）；再比如你可能还需要一点点的数学知识（比如位运算、质数）基础。</p>\n<p>另外， 网上也有很多算法大佬开源了自己的刷题经验，这些经验都是前辈刷题之后得出的，非常具有参考价值。利用得当的话，可以极大减轻自己的刷题压力。推荐你看看我整理的 <a href=\"https://mp.weixin.qq.com/s/7b4JDVA_s27wCLQD7SACXg\" target=\"_blank\" rel=\"noopener\">《阿里ACM大佬开源的Leetcode刷题指南》</a> 。</p>\n<h2 id=\"Java并发-《Java-并发实现原理：JDK-源码剖析》\"><a href=\"#Java并发-《Java-并发实现原理：JDK-源码剖析》\" class=\"headerlink\" title=\"Java并发 《Java 并发实现原理：JDK 源码剖析》\"></a>Java并发 《Java 并发实现原理：JDK 源码剖析》</h2><ol>\n<li>进程和线程的区别。【⭐⭐⭐⭐⭐】这是一个超高频考点，面试回答时别一句一个进程包含很多线程就没了。要答清楚什么是线程什么是进程，线程和进程各自的<code>运行状态</code>、线程的<code>通信方式</code>和进程的<code>通信方式</code>。</li>\n<li>创建线程的方式。【⭐⭐⭐⭐】不仅要把创建线程的方式记熟、记住各种方式的优缺点，还要能写出代码来。有的面试官是会让你写代码创建两个线程然后执行一些操作的，比如两个线程交替输出数字。</li>\n<li>什么是死锁，死锁如何产生，死锁如何避免。【⭐⭐⭐⭐⭐】超高频问题，几乎大厂的一面和二面都会问到。</li>\n<li>并发编程的三大特性（原子性、可见性以及有序性）。【⭐⭐⭐⭐】</li>\n<li><code>synchronized</code> 锁升级流程。【⭐⭐⭐⭐⭐】这又是面试八股文的一大考点，锁升级流程记清楚。</li>\n<li><code>volatile</code> 关键字。【⭐⭐⭐⭐⭐】对比和 <code>synchronized</code> 的区别。</li>\n<li><code>JMM</code>（Java Memory Model，Java 内存模型）和 <code>happens-before</code> 原则。【⭐⭐⭐⭐⭐】面试中重点！几乎必问。</li>\n<li><code>ThreadLocal</code>。【⭐⭐⭐⭐】这也是面试八股文的一个高频考点。我面试到后面不想背这里了，面试过程中就尽可能躲着这个知识点，不提到和这相关的，竟然真的苟过去了。</li>\n<li>线程池。【⭐⭐⭐⭐⭐】超高频考点。需要答出线程池有哪几种，各种线程池的优缺点，线程池的重要参数、线程池的<code>执行流程</code>、线程池的饱和策略、如何设置线程池的大小等等。这里也能背十几分钟。</li>\n<li><code>ReentrantLock</code> 和 <code>AQS</code>。【⭐⭐⭐⭐⭐】其实我在面试的时候对这里不是很熟，我面试的时候尽量不提到这里，也苟过去了。大家如果时间充足的话还是把这块好好理解一下。如果这里理解透彻了，也能在这里和面试官聊很久。</li>\n<li>乐观锁和悲观锁的区别。【⭐⭐⭐⭐⭐】</li>\n<li><code>CAS</code> 了解么？原理？什么是 ABA 问题？ABA 问题怎么解决？【⭐⭐⭐⭐⭐】<code>CAS</code>（Compare-and-Swap）绝对是面试中的高频中的高频，很多地方都用到了 <code>CAS</code> 比如 <code>ConcurrentHashMap</code> 采用 <code>CAS</code> 和 <code>synchronized</code> 来保证并发安全，再比如<code>java.util.concurrent.atomic</code>包中的类通过 <code>volatile+CAS</code> 重试保证线程安全性。和面试官聊 <code>CAS</code> 的时候，你可以结合 <code>CAS</code> 的一些实际应用来说。</li>\n<li><code>Atomic</code> 原子类【⭐⭐】</li>\n</ol>\n<h2 id=\"Java基础-《Java-编程的逻辑》\"><a href=\"#Java基础-《Java-编程的逻辑》\" class=\"headerlink\" title=\"Java基础 《Java 编程的逻辑》\"></a>Java基础 《Java 编程的逻辑》</h2><ol>\n<li>Java 语言的特点（如果你简历上有提到 C++ 可能还会问你 Java 和 C++ 的区别）。【⭐⭐】</li>\n<li>比较 JVM 和 JDK 以及 JRE 。【⭐⭐⭐】非常非常基础的一个问题！学了 Java 之后还不知这个问题如何回答的小伙伴自觉去面壁吧！</li>\n<li>为什么说 Java 语言“解释与编译并存”。【⭐⭐】</li>\n<li>Java 基本类型有哪几种，各占多少位？【⭐⭐】前些年面试常问的一个问题，去年面试过程中只京东问我了</li>\n<li>Java 泛型，类型擦除。【⭐⭐⭐】</li>\n<li><code>==</code> 和 <code>equals()</code> 的区别。【⭐⭐⭐】：这个问题在 2018 年之前几乎是面试必问的问题，但是现在大厂以及比较少问了，现在小厂中厂问的多。</li>\n<li><strong><code>hashCode()</code> 和 <code>equals()</code></strong> 【⭐⭐⭐⭐】：这个问题经常问，面试官经常问为什么重写 <code>equals()</code> 时要重写 <code>hashCode()</code> 方法？另外，这个问题经常结合着 <code>HashSet</code> 问。</li>\n<li><strong>重载和重写的区别。</strong> 【⭐⭐⭐⭐】</li>\n<li>深拷贝和浅拷贝。【⭐】</li>\n<li>面向对象和面向过程的区别。【⭐⭐⭐】</li>\n<li>成员变量与局部变量的区别。【⭐⭐⭐】</li>\n<li>面向对象三大特性是什么。并解释这三大特性。【⭐⭐⭐⭐】</li>\n<li><strong><code>String</code>、<code>StringBuffer</code> 和 <code>StringBuilder</code> 的区别。</strong> 【⭐⭐⭐⭐】</li>\n<li>Java 异常。【⭐⭐⭐】：不会问的特别细。经常的问法是异常可以分为哪几种，然后你答了可检查异常和不可检查异常以后，会让你举例可检查异常有哪些，不可检查有哪些。然后，异常的代码要会写，有一场字节的面试，直接让我写一个把异常捕获了然后抛出去的代码。</li>\n<li>序列化和反序列化【⭐⭐】</li>\n<li>反射【⭐⭐】面试官可能会问你什么是反射，它的优缺点是什么，有哪些应用场景。</li>\n<li><code>List</code>、Set<code>、</code> <code>Map</code> 的区别。【⭐⭐】</li>\n<li><strong><code>ArrayList</code> 和 <code>LinkedList</code> 的区别。</strong>【⭐⭐⭐⭐】：答清楚每个分别采用什么数据结构，对比相应的优点和缺点。</li>\n<li>比较 <code>HashSet</code>、<code>LinkedHashSet</code> 和 <code>TreeSet</code> 三者的异同。【⭐⭐⭐】</li>\n<li>HashMap 多线程操作导致死循环问题。【⭐⭐⭐】jdk 1.8 后解决了这个问题，但是还是不建议在多线程下使用 <code>HashMap</code>,因为多线程下使用 <code>HashMap</code> 还是会存在其他问题比如数据丢失。并发环境下推荐使用 <code>ConcurrentHashMap</code> 。</li>\n<li>HashMap 的长度为什么是 2 的幂次方。【⭐⭐⭐】主要是考虑到了对运算效率的提升。</li>\n<li><strong><code>HashMap</code>、<code>HashTable</code>、以及 <code>ConcurrentHashMap</code> 的区别。</strong>【⭐⭐⭐⭐⭐】：现在面试的超高频考点。当面试官问到这个问题的时候，展现你背面试八股文能力的机会来了。你可以展开去讲在 Java7 和 Java8 中 <code>HashMap</code> 分别采用什么数据结构，为什么 Java8 把之前的<code>头插法</code>改成了<code>尾插法</code>，怎样实现<code>扩容</code>，为什么<code>负载因子</code>是 <code>0.75</code>，为什么要用<code>红黑树</code>等等一系列的东西。</li>\n</ol>\n<h2 id=\"JVM-《深入理解-Java-虚拟机》\"><a href=\"#JVM-《深入理解-Java-虚拟机》\" class=\"headerlink\" title=\"JVM 《深入理解 Java 虚拟机》\"></a>JVM 《深入理解 Java 虚拟机》</h2><ol>\n<li>运行时数据区中包含哪些区域？哪些线程共享？哪些线程独享？【⭐⭐⭐⭐⭐】</li>\n<li>说一下方法区和永久代的关系。【⭐⭐⭐】</li>\n<li>讲一下 Java 创建一个对象的过程。【⭐⭐⭐⭐】</li>\n<li>对象的访问定位的两种方式（句柄和直接指针两种方式）。【⭐⭐⭐⭐⭐】</li>\n<li>你了解分代理论吗？讲一下 Minor GC、还有 Full GC。【⭐⭐⭐⭐⭐】</li>\n<li>Java 用什么方法确定哪些对象该被清理？ 讲一下可达性分析算法的流程。【⭐⭐⭐⭐】</li>\n<li>JDK 中有几种引用类型？分别的特点是什么？【⭐⭐】</li>\n<li>如何回收方法区？【⭐⭐⭐】</li>\n<li>标记清楚、标记复制、标记整理分别是怎样清理垃圾的？各有什么优缺点？【⭐⭐⭐⭐⭐】</li>\n<li>JVM 中的安全点和安全区各代表什么？写屏障你了解吗？【⭐⭐⭐⭐】</li>\n<li>并发标记要解决什么问题？并发标记带来了什么问题？如何解决并发扫描时对象消失问题？【⭐⭐⭐⭐】相关阅读：<a href=\"https://juejin.cn/post/6844904070788939790\" target=\"_blank\" rel=\"noopener\">面试官:你说你熟悉 jvm?那你讲一下并发的可达性分析</a> 。</li>\n<li>对于 JVM 的垃圾收集器你有什么了解的？【⭐⭐⭐⭐】有时候面试官会问出这种十分开放性的问题，你需要脑子里过一下你对这个大问题下的哪些知识熟悉哪些不熟悉，不熟悉的点一下就过，熟悉的展开讲。在准备校招时，我的一个是阿里 P7 的学姐，给我做过一次模拟面试，问出这个问题时让我有点懵，那么多东西我不知道从哪开始回答呀，就答得很凌乱。模拟面试完我问她这种问题应该从哪开始回答？ 她说她因为不知道我的掌握情况，所以就先问一个大问题，根据我的回答再追问，以后遇到这种问题主要从自己熟悉得方面切入就可以了。后来的面试还真遇到过好几次这种情况，我就答，垃圾收集器的种类有以下几种 Serial，ParNew…现在用的多的还是 CMS 和 G1，CMS 的垃圾收集流程是 xxx，G1 的垃圾收集流程是 xxx，他们特点是…就这样把话题引到 CMS 和 G1 了，只 CMS 和 G1 这部分和面试官讨论十几分钟完全没问题。</li>\n<li>新生代垃圾收集器有哪些？老年代垃圾收集器有哪些？哪些是单线程垃圾收集器，哪些是多线程垃圾收集器？各有什么特点？各基于哪一种垃圾收集算法？【⭐⭐⭐⭐】</li>\n<li>讲一下 CMS 垃圾收集器的四个步骤。CMS 有什么缺点？【⭐⭐⭐⭐】</li>\n<li>G1 垃圾收集器的步骤。有什么缺点？【⭐⭐⭐⭐】</li>\n<li>讲一下内存分配策略？【⭐⭐⭐⭐】</li>\n<li>虚拟机基础故障处理工具有哪些？【⭐⭐⭐】</li>\n<li>什么是字节码？类文件结构的组成了解吗？【⭐⭐⭐⭐】</li>\n<li>类的生命周期？类加载的过程了解么？加载这一步主要做了什么事情？初始化阶段中哪几种情况必须对类初始化？【⭐⭐⭐⭐⭐】</li>\n<li>讲一下双亲委派模型。【⭐⭐⭐⭐⭐】</li>\n</ol>\n<h2 id=\"MySQL-《深入浅出MySQL》\"><a href=\"#MySQL-《深入浅出MySQL》\" class=\"headerlink\" title=\"MySQL 《深入浅出MySQL》\"></a>MySQL 《深入浅出MySQL》</h2><p>好了，现在正式进入 MySQL 面试八股文的划重点流程。在这里要推荐一本书籍《深入浅出 MySQL 》。</p>\n<p><img src=\"https://img-blog.csdnimg.cn/20210620170853137.png\" alt=\"img\"></p>\n<ul>\n<li><strong>推荐理由</strong> ：《深入浅出 MySQL》这本书是网易的数据库专家写的，从数据库的基础、开发、优化、管理维护、架构，五个层面讲述了 MySQL（大家面试后端的话管理维护篇就不用看了），内容层层递进。并且每讲解一个小的知识点都会相应的配有实例，更容易读者理解。</li>\n<li><strong>学习内容</strong> ：学习内容按照《深入浅出 MySQL》的目录进行介绍。根据章节内容列出的问题我就不附上答案了，大家根据我的问题自己总结下会有更好的学校效果。在补充篇的问题我会给出答案。</li>\n</ul>\n<p><strong>基础篇第2章 SQL 基础</strong></p>\n<p>基础的SQL语句肯定要会，并且要熟练，这是最基础的。</p>\n<p>针对本章内容的面试问题：</p>\n<p>（1）增删改查这些问题面试官一般不会问的。不过万一问出来，比如“查询用哪个关键字”，你要是不知道你就惨了哈。</p>\n<p>（2）ORDER BY、LIMIT、GROUP BY、HAVING 这些关键字分别是做什么用的。</p>\n<p>（3）讲一下左链接和右链接的区别。</p>\n<p><strong>基础篇第3章、第4章、第5章</strong></p>\n<p>这三章分别是MySQL的数据类型、运算符、常用函数。简单过一遍，了解就行，这三章在面试中很少会被问到。</p>\n<p><strong>开发篇第7章 表类型（存储引擎）的选择</strong></p>\n<p>InnoDB是面试考察的重点，相关知识都要详细看。另外要拿 InnoDB 对比 MyISAM、MEMORY 去体会 InnoDB 引擎的特点。</p>\n<p>针对本章内容的面试问题：</p>\n<p>InnoDB 和 MyISM、MEMORY 的区别是什么。</p>\n<p><strong>开发篇第10章 索引的设计和使用</strong></p>\n<p>索引是 MySQL 面试考察的重点，BTree 索引和 Hash 索引要对比着进行学习。</p>\n<p>针对本章内容的面试问题：</p>\n<p>（1）索引所采用的数据结构，以及为什么要这样设计。</p>\n<p>（1）在数据库中创建索引的原则。</p>\n<p>（2）BTree 索引和 Hash 索引的适用范围。</p>\n<p><strong>开发篇第11章 视图</strong></p>\n<p>本章做到基本了解，面试过程中问的少。</p>\n<p><strong>开发篇第14章 事务控制和锁定语句</strong></p>\n<p>InnoDB 是行锁，MyISAM、MEMORY 是表锁面试过程中经常会问到。本章的事务控制实例值得好好的体会一下，有利于加深对数据库锁的理解。</p>\n<p><strong>优化篇第18章 SQL优化</strong></p>\n<p>如果你在简历中和开头的自我介绍中强调了你对 MySQL 熟悉，那么你这一章一定要好好看。面试官想考察你在 MySQL 方面的能力是否和你之前说的相符，会倾向于出一道场景问题，让你去设计并优化（当然只是好好看这一章并不能完全解决问题，一会我做一点补充）。</p>\n<p>针对本章内容的面试问题：</p>\n<p>（1）优化 SQL 语句的步骤有哪些。</p>\n<p>（2）哪些场景可以使用索引。</p>\n<p>（3）索引在哪些情况会失效。</p>\n<p>虽然面试官不会直接问你在优化 SQL 语句时候有哪些技巧？比如怎样优化 Insert 语句，怎样优化 order by语句。但是可以在这一章学一些常用的优化 SQL 语句的技巧，在面试官问一个具体问题时，顺带说一下自己平时会采用这些技巧去优化。</p>\n<p><strong>优化篇第20章 锁问题</strong></p>\n<p>这一章属于第14章的拔高，大家主要看表锁和行锁，页锁被问到的比较少。</p>\n<p>针对本章内容的面试问题：</p>\n<p>（1）事务四大特性，并解释这四大特性的含义。</p>\n<p>（2）并发事务处理会带来哪些问题？</p>\n<p>（3）事务隔离级别。</p>\n<p>（4）InnoDB 行锁实现方式</p>\n<p>（5）你了解 Next-key 锁吗？</p>\n<p>（6）如何避免 InnoDB 中的死锁。</p>\n<p>（7）数据库多版本并发控制（MVCC 机制）</p>\n<p><strong>优化篇第21章 优化 MySQL Server</strong></p>\n<p>这一章在校招面试中是不会问到的，不过我把这里的相关知识学了去给面试官讲，效果还不错。大家根据自己的情况酌情选择看还是不看哈。</p>\n<p>可以和面试官展开聊的知识点：</p>\n<p>（1）MySQL 的内存管理及优化。</p>\n<p>（2）InnoDB 重做日志的内部机制，这个可以和事务联系起来给面试官讲。</p>\n<p><strong>架构篇第31章 MySQL 复制</strong></p>\n<p>这一章的内容如果你不刻意提到，面试官一般很少主动问。如果大家不打算在 MySQL 这里和面试官多聊，那么这里就可以不看了。如果大家打算在 MySQL 这个环节和面试官展开聊，那么在这里和面试官展开聊是一个不错的选择。</p>\n<p>可以和面试官展开聊的知识点：</p>\n<p>（1）MySQL 的主从复制原理。</p>\n<p>（2）MySQL 的三种复制方式。</p>\n<p>（3）MySQL 的异步复制和半同步复制。</p>\n<p>（4）如何提高复制的性能。</p>\n<h2 id=\"Redis-《Redis的设计与实现》\"><a href=\"#Redis-《Redis的设计与实现》\" class=\"headerlink\" title=\"Redis 《Redis的设计与实现》\"></a>Redis 《Redis的设计与实现》</h2><p>对于没有太多时间准备 Redis 的同学，我在这里给大家准备一些面试常问的八股问题。你在面试大厂时，只要别给面试官对你 Redis 部分太高的期望，你把下面这些问题能回答清楚就算过关了。</p>\n<ol>\n<li>什么是 Redis？【⭐⭐】</li>\n<li>Redis 除了做缓存，还能做什么？【⭐⭐⭐⭐】</li>\n<li>Redis 有哪些数据类型？这些数据类型的应用场景分别是什么？你在项目中用到了吗？【⭐⭐⭐⭐⭐】</li>\n<li>Redis6.0 之后为何引入了多线程？【⭐⭐⭐】</li>\n<li>Redis 过期数据删除策略讲一下。【⭐⭐⭐】</li>\n<li>Redis 的持久化策略了解嘛？分别介绍下 RDB 和 AOF。【⭐⭐⭐⭐】</li>\n<li>什么是缓存穿透？什么是缓存击穿？什么是缓存雪崩？怎么解决（最高频问题）</li>\n<li>设计一个分布式锁？【⭐⭐】</li>\n<li>Redis 内存淘汰机制了解么？类似问题：MySQL 里有 2000w 数据，Redis 中只存 20w 的数据，如何保证 Redis 中的数据都是热点数据?【⭐⭐⭐⭐】</li>\n<li>Redis 事务你了解嘛？【⭐⭐】</li>\n<li>如何保证 Redis 和 MySQL 的数据一致性？（如果项目同时用到 Redis 和 MySQL，这个问题特别容易被问）【⭐⭐⭐⭐】</li>\n</ol>\n","site":{"data":{}},"more":"<h2 id=\"操作系统-《现代操作系统：原理与实现》\"><a href=\"#操作系统-《现代操作系统：原理与实现》\" class=\"headerlink\" title=\"操作系统 《现代操作系统：原理与实现》\"></a>操作系统 《现代操作系统：原理与实现》</h2><p><strong>操作系统基础概念</strong></p>\n<p>操作系统基础概念中比较重要的知识点：</p>\n<ul>\n<li>操作系统的作用、特点、分类、发展</li>\n<li>操作系统的结构</li>\n<li>内核态和用户态、系统调用</li>\n</ul>\n<p><strong>进程和线程（重要）</strong></p>\n<ol>\n<li>进程和线程的基本定义，对比一下两者。</li>\n<li>进程和线程的状态以及各种状态之间的转换。</li>\n<li>进程的通信方式： 进程与进程之前是如何进行通信的。</li>\n<li>进程调度算法： CPU 如何应用不同的调度算法来调度进程。</li>\n</ol>\n<p><strong>内存管理（重要）</strong></p>\n<p>面试官可能会先问一些比较简单的问题比如内存管理的目的、逻辑和物理地址。</p>\n<p>比较核心一些的问题还是内存管理机制和内存管理相关的一些概念。</p>\n<ul>\n<li>内存管理机制 ：像内存管理机制简单分为连续分配管理方式和非连续分配管理方式这两种。非连续分配管理方式比较重要，像分页机制、分段机制、段页式机制都属于非连续分配管理。</li>\n<li>内存管理相关概念 ： 快表和多级页表。</li>\n</ul>\n<p>除此之外，虚拟内存和请求分页也非常重要，面试中也经常会遇到。</p>\n<ul>\n<li>虚拟内存 ：虚拟内存介绍、局部性原理、虚拟内存的实现机制</li>\n<li>请求分页 ： 页表机制、缺页中断、页面置换算法</li>\n</ul>\n<p>最后就是死锁相关的内容了，你需要掌握：</p>\n<ul>\n<li>死锁的必要条件</li>\n<li>死锁预防、避免、检测与解除</li>\n</ul>\n<p><strong>CPU 调度</strong></p>\n<p>CPU 调度这块最重要的就是搞懂几种常见的 CPU 调度算法：</p>\n<ul>\n<li>先到先服务调度(First-Come First-Served Scheduling，FCFS)</li>\n<li>最短作业优先调度(Shortest Job First，SJF)</li>\n<li>优先级调度（Priority Scheduling）</li>\n<li>轮转法调度(Round Robin，RR)</li>\n<li>……</li>\n</ul>\n<p>上面这几种调度算法，大家通过名字应该就能猜出个大概意义了。这些调度算法各有优劣，没有银弹，只能根据具体场景选择具体的调度算法。</p>\n<p>因此，多级队列调度（Multilevel Queue） 就诞生了。简单来说就是把就绪队列（存放有待执行进程）分成多个独立队列，每个队列都有自己的调度算法。</p>\n<p><strong>Linux 相关（重要）</strong></p>\n<p>另外的话，操作系统这块还需要对 Linux 相关的知识有所了解：</p>\n<ul>\n<li>Linux 常用命令 ：比如说创建文件相关的命令、搜索相关的命令</li>\n<li>Linux 文件系统 ： 文件系统原理、硬链接与软链接、目录结构</li>\n<li>僵尸进程和孤儿进程</li>\n</ul>\n<h2 id=\"计算机网络-《计算机网络——自顶向下方法》\"><a href=\"#计算机网络-《计算机网络——自顶向下方法》\" class=\"headerlink\" title=\"计算机网络 《计算机网络——自顶向下方法》\"></a>计算机网络 《计算机网络——自顶向下方法》</h2><p><strong>网络层</strong></p>\n<p>网络层面试问的也相对较少，主要就是问IPV4，偶尔问一下ARP地址解析协议的的工作原理。</p>\n<p>1.首先要记清楚 IPV4 地址是怎么分类的、以及地址的格式。这里经常结合代码题一起问你，我和很多同学都在面试中被面试官要求写一个程序判断给定的字符串是否是 IPV4 地址。</p>\n<p>2.IPV4 子网划分面试中不怎么问，笔试题时经常有这个问题。</p>\n<p>3.了解 IP 地址和 Mac 地址的区别，了解 ARP 地址解析协议并了解其工作原理。</p>\n<p><strong>传输层</strong></p>\n<p>面试中计算机网络的问题最常出现在这一章中。</p>\n<p>1.记清楚 TCP 和 UDP 的区别。</p>\n<p>2.TCP三次握手和UDP四次挥手。</p>\n<p>这是面试计算机网络最最最常问的问题！！！你计算机网络就算其它的什么也不会，这个问题你必须要记清楚，如果面试官问出你这个问题你都答不上，面试官估计觉得你连敷衍都不想敷衍他了。</p>\n<p>当面试官问你三次握手和四次挥手时，你要答出这三个点来。（1）为什么要三次挥手和四次挥手，如果不这样做会有什么影响。（2）三次握手四次挥手的整个流程。（3）有的面试官只要你答出三次握手和四次挥手的大体流程就好了，但是有的面试官会要求你答出三次握手和四次挥手时发送端和接收端分别发了哪些标记。就像下面 Guide哥 画的这张图一样。</p>\n<p><img src=\"https://img-blog.csdnimg.cn/20210727212425498.png\" alt></p>\n<p>3.TCP协议如何保证可靠传输</p>\n<p>把 ARQ 协议、滑动窗口、流量控制、拥塞控制等回答清楚就算到位了。</p>\n<p>应用层 ：</p>\n<p>（1）另一个最最最常问的问题，”在浏览器中输入 URL 地址到浏览器显示网页这个过程中计算机网络做了什么“。</p>\n<p>这个问题无论时考研还是找工作都是常见的，建议把 JavaGuide 中这个问题的总结熟读并全文背诵。</p>\n<p>（2）HTTP 1.0 和 HTTP 1.1 的主要区别</p>\n<p>这个也要了解一下。</p>\n<p>（3）HTTP 和 HTTPS 的区别</p>\n<p>这个也是面试常考问题，这个问题展开以后能问的就比较多了。</p>\n<p>在回答这个问题时你首先分别介绍一下 HTTP 和 HTTPS 的原理，以及区别。大致就是 HTTP 是通过明文在网络上传输的，HTTPS 是加密的。然后有的面试官问到这也就可以了，有的面试官不讲武德，想搞偷袭，会继续让你讲 HTTPS 建立连接的流程、然后会继续追着你问SSL 的工作流程。建议把这里好好准备一下，面试官一问你就可以展开讲，你就能消耗很多面试时间，这样面试官问其它问题的时间就少了，嘿嘿。</p>\n<p>（4）HTTP请求常见的状态码</p>\n<p>背几个常用的就好。</p>\n<p>（5）DNS域名系统</p>\n<p>这里你要可以描述清楚工作原理。也是面试常问问题，当除考研我也重点背过这里。</p>\n<p><strong>网络接口层</strong></p>\n<p>把网卡、网桥、交换机的概念、用途简单了解下就好，一般面试官不会问。</p>\n<p>好了，把这些问题搞清楚，应付面试官应该就没什么问题了，赶紧去总结下答案然后好好背吧。如果你时间充分，想系统学一下计算机网络，那你就接着往下看。</p>\n<h2 id=\"数据结构-可以在下面的算法书中学习\"><a href=\"#数据结构-可以在下面的算法书中学习\" class=\"headerlink\" title=\"数据结构 可以在下面的算法书中学习\"></a>数据结构 可以在下面的算法书中学习</h2><p>数据结构的种类非常多，不过最常用同时也是面试最常问的数据结构主要就是下面这些：</p>\n<ul>\n<li><strong>线性数据结构</strong>：<ul>\n<li><strong>数组</strong> ：数组（Array） 是一种很常见的数据结构。它由相同类型的元素（element）组成，并且是使用一块连续的内存来存储。</li>\n<li><strong>链表</strong> ：链表（LinkedList） 虽然是一种线性表，但是并不会按线性的顺序存储数据，使用的不是连续的内存空间来存储数据。链表的插入和删除操作的复杂度为 O(1) ，只需要知道目标位置元素的上一个元素即可。但是，在查找一个节点或者访问特定位置的节点的时候复杂度为 O(n) 。</li>\n<li><strong>栈</strong> ：栈 (Stack)只允许在有序的线性数据集合的一端（称为栈顶 top）进行加入数据（push）和移除数据（pop）。因而按照 后进先出（LIFO, Last In First Out） 的原理运作。在栈中，push 和 pop 的操作都发生在栈顶。栈常用一维数组或链表来实现，用数组实现的栈叫作 顺序栈 ，用链表实现的栈叫作 链式栈 。</li>\n<li><strong>队列</strong> ： 队列（Queue）是 先进先出( FIFO，First In, First Out) 的线性表。在具体应用中通常用链表或者数组来实现，用数组实现的队列叫作 顺序队列 ，用链表实现的队列叫作 链式队列 。队列只允许在后端（rear）进行插入操作也就是 入队 enqueue，在前端（front）进行删除操作也就是出队 dequeue。队列的操作方式和堆类似，唯一的区别在于队列只允许新数据在后端进行添加。</li>\n</ul>\n</li>\n<li><strong>图</strong> ：图就是由顶点的有穷非空集合和顶点之间的边组成的集合。通常表示为：<strong>G(V,E)</strong>，其中，G 表示一个图，V 表示顶点的集合，E 表示边的集合。图可以被简单的分为：无向图和有向图，无权图和带权图。</li>\n<li><strong>树</strong> : 树就是一种类似现实生活中的树的数据结构（倒置的树）。任何一颗非空树只有一个根节点。常见的树的种类有：平衡树、二叉搜索树、平衡二叉树、红黑树、B 树、LSM 树、字典树（Trie 树）</li>\n<li><strong>堆</strong> ：堆是一种满足特定条件的树：堆中的每一个节点值都大于等于（或小于等于）子树中所有节点的值。或者说，任意一个节点的值都大于等于（或小于等于）所有子节点的值。堆分为最大堆和最小堆。</li>\n<li><strong>哈希表</strong> ：也叫散列表，是根据关键码值(Key value)而直接进行访问的数据结构，通过 key 就能获取到指定的 value ，速度非常快。</li>\n<li><strong>跳表</strong> ：跳表（Skip List）是由 William Pugh 发明的一种查找数据结构，支持对数据的快速查找，插入和删除。跳表的查询，插入和删除操作的期望时间复杂度都为 O(log n)。</li>\n</ul>\n<p><strong>常见问题总结</strong> ：</p>\n<ul>\n<li><strong>通用常识</strong>：像数据结构的定义，查找、插入、删除元素的时间复杂度，应用场景是每一个数据结构都应该掌握的最基本的点。</li>\n<li><strong>线性数据结构</strong> ：<ul>\n<li>数组 vs 链表</li>\n<li>栈 vs 队列</li>\n<li>实现一个栈/队列</li>\n<li>翻转链表、返回链表中倒数第 n 个节点、链表合并……</li>\n</ul>\n</li>\n<li><strong>图</strong> ：<ul>\n<li>图的常见概念比如顶点的度</li>\n<li>图的遍历算法（广度优先搜索和深度优先搜索）</li>\n<li>拓扑排序</li>\n<li>欧拉回路</li>\n<li>迪杰斯特拉（Dijikstra）算法（最短路径问题）</li>\n</ul>\n</li>\n<li><strong>树</strong> ：<ul>\n<li>二叉树的前序遍历、中序遍历、后序遍历</li>\n<li>二叉查找树的出插入、查找、删除</li>\n<li>二叉树的高度计算</li>\n<li>红黑树 vs 二叉查找树</li>\n</ul>\n</li>\n<li><strong>堆</strong> ：<ul>\n<li>堆中插入数据</li>\n<li>如何删除堆顶元素</li>\n<li>堆排序</li>\n</ul>\n</li>\n<li><strong>哈希表</strong> ：<ul>\n<li>哈希冲突是什么？如何解决？</li>\n<li>键值的映射关系如何维护？哈希函数如何设计？</li>\n</ul>\n</li>\n<li><strong>跳表</strong>：<ul>\n<li>为什么 Redis 选择使用跳表而不是红黑树来实现有序集合？</li>\n<li>跳表的查找、插入、删除元素的流程</li>\n<li>跳表插入元素时，如何动态维护索引？</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"算法-《算法》-《我的第一本算法书》-《算法导论》-《编程珠玑》\"><a href=\"#算法-《算法》-《我的第一本算法书》-《算法导论》-《编程珠玑》\" class=\"headerlink\" title=\"算法  《算法》 《我的第一本算法书》 《算法导论》 《编程珠玑》\"></a>算法  《算法》 《我的第一本算法书》 《算法导论》 《编程珠玑》</h2><p>和框架应用类知识不同，算法仅仅通过一周甚至是一个月的突击是完全没办法快速上手的！</p>\n<p>想要在算法面试中如鱼得水，就必须持之以恒地坚持刷题-&gt; 总结-&gt;再刷题 -&gt; 再总结。</p>\n<p>你需要做的就是提前半年甚至是一年来刷 Leetcode，并总结一些常见题目类型的套路！</p>\n<p><strong>那我们应该怎么更高效低刷题呢？</strong> 给几点自己的刷题建议：</p>\n<ul>\n<li><strong>按照类型来刷</strong> ：一般情况下，一个类型的题目刷 5~10 道左右就够了！</li>\n<li><strong>由简入难</strong> ：刷算法是一个循序渐进的过程，如果你不是 ACM 大佬这种级别的人物的话，还是建议先从简单开始刷起，慢慢积累经验。不过，要说明的一点是：很多简单类型的题目甚至还要比中等类型的题目还要难！所以，如果你没办法解决一些简单的算法题，也不要太纠结，不要因此失去信心。</li>\n<li><strong>重点关注面试高频题目/题型</strong> ：如果你的时间不是很充足的话，建议可以从高频面试题入手。像 Leetcode 上面就专门把一些最热门的算法面试题给单独整理了出来。</li>\n<li><strong>多思考</strong> ：一定不要遇到不会的算法题就直接看别人的答案，这样会让自己形成依赖心理。一定要先思考，一定要多思考！</li>\n<li>……</li>\n</ul>\n<p>刷题之前，我建议你应该具有基本的算法基础。比如你应该搞清楚常见的算法思想（递归、动态规划、二分查找、贪心、分治、回溯、DFS、BFS、KMP、树的广度和深度优先搜索）；再比如你可能还需要一点点的数学知识（比如位运算、质数）基础。</p>\n<p>另外， 网上也有很多算法大佬开源了自己的刷题经验，这些经验都是前辈刷题之后得出的，非常具有参考价值。利用得当的话，可以极大减轻自己的刷题压力。推荐你看看我整理的 <a href=\"https://mp.weixin.qq.com/s/7b4JDVA_s27wCLQD7SACXg\" target=\"_blank\" rel=\"noopener\">《阿里ACM大佬开源的Leetcode刷题指南》</a> 。</p>\n<h2 id=\"Java并发-《Java-并发实现原理：JDK-源码剖析》\"><a href=\"#Java并发-《Java-并发实现原理：JDK-源码剖析》\" class=\"headerlink\" title=\"Java并发 《Java 并发实现原理：JDK 源码剖析》\"></a>Java并发 《Java 并发实现原理：JDK 源码剖析》</h2><ol>\n<li>进程和线程的区别。【⭐⭐⭐⭐⭐】这是一个超高频考点，面试回答时别一句一个进程包含很多线程就没了。要答清楚什么是线程什么是进程，线程和进程各自的<code>运行状态</code>、线程的<code>通信方式</code>和进程的<code>通信方式</code>。</li>\n<li>创建线程的方式。【⭐⭐⭐⭐】不仅要把创建线程的方式记熟、记住各种方式的优缺点，还要能写出代码来。有的面试官是会让你写代码创建两个线程然后执行一些操作的，比如两个线程交替输出数字。</li>\n<li>什么是死锁，死锁如何产生，死锁如何避免。【⭐⭐⭐⭐⭐】超高频问题，几乎大厂的一面和二面都会问到。</li>\n<li>并发编程的三大特性（原子性、可见性以及有序性）。【⭐⭐⭐⭐】</li>\n<li><code>synchronized</code> 锁升级流程。【⭐⭐⭐⭐⭐】这又是面试八股文的一大考点，锁升级流程记清楚。</li>\n<li><code>volatile</code> 关键字。【⭐⭐⭐⭐⭐】对比和 <code>synchronized</code> 的区别。</li>\n<li><code>JMM</code>（Java Memory Model，Java 内存模型）和 <code>happens-before</code> 原则。【⭐⭐⭐⭐⭐】面试中重点！几乎必问。</li>\n<li><code>ThreadLocal</code>。【⭐⭐⭐⭐】这也是面试八股文的一个高频考点。我面试到后面不想背这里了，面试过程中就尽可能躲着这个知识点，不提到和这相关的，竟然真的苟过去了。</li>\n<li>线程池。【⭐⭐⭐⭐⭐】超高频考点。需要答出线程池有哪几种，各种线程池的优缺点，线程池的重要参数、线程池的<code>执行流程</code>、线程池的饱和策略、如何设置线程池的大小等等。这里也能背十几分钟。</li>\n<li><code>ReentrantLock</code> 和 <code>AQS</code>。【⭐⭐⭐⭐⭐】其实我在面试的时候对这里不是很熟，我面试的时候尽量不提到这里，也苟过去了。大家如果时间充足的话还是把这块好好理解一下。如果这里理解透彻了，也能在这里和面试官聊很久。</li>\n<li>乐观锁和悲观锁的区别。【⭐⭐⭐⭐⭐】</li>\n<li><code>CAS</code> 了解么？原理？什么是 ABA 问题？ABA 问题怎么解决？【⭐⭐⭐⭐⭐】<code>CAS</code>（Compare-and-Swap）绝对是面试中的高频中的高频，很多地方都用到了 <code>CAS</code> 比如 <code>ConcurrentHashMap</code> 采用 <code>CAS</code> 和 <code>synchronized</code> 来保证并发安全，再比如<code>java.util.concurrent.atomic</code>包中的类通过 <code>volatile+CAS</code> 重试保证线程安全性。和面试官聊 <code>CAS</code> 的时候，你可以结合 <code>CAS</code> 的一些实际应用来说。</li>\n<li><code>Atomic</code> 原子类【⭐⭐】</li>\n</ol>\n<h2 id=\"Java基础-《Java-编程的逻辑》\"><a href=\"#Java基础-《Java-编程的逻辑》\" class=\"headerlink\" title=\"Java基础 《Java 编程的逻辑》\"></a>Java基础 《Java 编程的逻辑》</h2><ol>\n<li>Java 语言的特点（如果你简历上有提到 C++ 可能还会问你 Java 和 C++ 的区别）。【⭐⭐】</li>\n<li>比较 JVM 和 JDK 以及 JRE 。【⭐⭐⭐】非常非常基础的一个问题！学了 Java 之后还不知这个问题如何回答的小伙伴自觉去面壁吧！</li>\n<li>为什么说 Java 语言“解释与编译并存”。【⭐⭐】</li>\n<li>Java 基本类型有哪几种，各占多少位？【⭐⭐】前些年面试常问的一个问题，去年面试过程中只京东问我了</li>\n<li>Java 泛型，类型擦除。【⭐⭐⭐】</li>\n<li><code>==</code> 和 <code>equals()</code> 的区别。【⭐⭐⭐】：这个问题在 2018 年之前几乎是面试必问的问题，但是现在大厂以及比较少问了，现在小厂中厂问的多。</li>\n<li><strong><code>hashCode()</code> 和 <code>equals()</code></strong> 【⭐⭐⭐⭐】：这个问题经常问，面试官经常问为什么重写 <code>equals()</code> 时要重写 <code>hashCode()</code> 方法？另外，这个问题经常结合着 <code>HashSet</code> 问。</li>\n<li><strong>重载和重写的区别。</strong> 【⭐⭐⭐⭐】</li>\n<li>深拷贝和浅拷贝。【⭐】</li>\n<li>面向对象和面向过程的区别。【⭐⭐⭐】</li>\n<li>成员变量与局部变量的区别。【⭐⭐⭐】</li>\n<li>面向对象三大特性是什么。并解释这三大特性。【⭐⭐⭐⭐】</li>\n<li><strong><code>String</code>、<code>StringBuffer</code> 和 <code>StringBuilder</code> 的区别。</strong> 【⭐⭐⭐⭐】</li>\n<li>Java 异常。【⭐⭐⭐】：不会问的特别细。经常的问法是异常可以分为哪几种，然后你答了可检查异常和不可检查异常以后，会让你举例可检查异常有哪些，不可检查有哪些。然后，异常的代码要会写，有一场字节的面试，直接让我写一个把异常捕获了然后抛出去的代码。</li>\n<li>序列化和反序列化【⭐⭐】</li>\n<li>反射【⭐⭐】面试官可能会问你什么是反射，它的优缺点是什么，有哪些应用场景。</li>\n<li><code>List</code>、Set<code>、</code> <code>Map</code> 的区别。【⭐⭐】</li>\n<li><strong><code>ArrayList</code> 和 <code>LinkedList</code> 的区别。</strong>【⭐⭐⭐⭐】：答清楚每个分别采用什么数据结构，对比相应的优点和缺点。</li>\n<li>比较 <code>HashSet</code>、<code>LinkedHashSet</code> 和 <code>TreeSet</code> 三者的异同。【⭐⭐⭐】</li>\n<li>HashMap 多线程操作导致死循环问题。【⭐⭐⭐】jdk 1.8 后解决了这个问题，但是还是不建议在多线程下使用 <code>HashMap</code>,因为多线程下使用 <code>HashMap</code> 还是会存在其他问题比如数据丢失。并发环境下推荐使用 <code>ConcurrentHashMap</code> 。</li>\n<li>HashMap 的长度为什么是 2 的幂次方。【⭐⭐⭐】主要是考虑到了对运算效率的提升。</li>\n<li><strong><code>HashMap</code>、<code>HashTable</code>、以及 <code>ConcurrentHashMap</code> 的区别。</strong>【⭐⭐⭐⭐⭐】：现在面试的超高频考点。当面试官问到这个问题的时候，展现你背面试八股文能力的机会来了。你可以展开去讲在 Java7 和 Java8 中 <code>HashMap</code> 分别采用什么数据结构，为什么 Java8 把之前的<code>头插法</code>改成了<code>尾插法</code>，怎样实现<code>扩容</code>，为什么<code>负载因子</code>是 <code>0.75</code>，为什么要用<code>红黑树</code>等等一系列的东西。</li>\n</ol>\n<h2 id=\"JVM-《深入理解-Java-虚拟机》\"><a href=\"#JVM-《深入理解-Java-虚拟机》\" class=\"headerlink\" title=\"JVM 《深入理解 Java 虚拟机》\"></a>JVM 《深入理解 Java 虚拟机》</h2><ol>\n<li>运行时数据区中包含哪些区域？哪些线程共享？哪些线程独享？【⭐⭐⭐⭐⭐】</li>\n<li>说一下方法区和永久代的关系。【⭐⭐⭐】</li>\n<li>讲一下 Java 创建一个对象的过程。【⭐⭐⭐⭐】</li>\n<li>对象的访问定位的两种方式（句柄和直接指针两种方式）。【⭐⭐⭐⭐⭐】</li>\n<li>你了解分代理论吗？讲一下 Minor GC、还有 Full GC。【⭐⭐⭐⭐⭐】</li>\n<li>Java 用什么方法确定哪些对象该被清理？ 讲一下可达性分析算法的流程。【⭐⭐⭐⭐】</li>\n<li>JDK 中有几种引用类型？分别的特点是什么？【⭐⭐】</li>\n<li>如何回收方法区？【⭐⭐⭐】</li>\n<li>标记清楚、标记复制、标记整理分别是怎样清理垃圾的？各有什么优缺点？【⭐⭐⭐⭐⭐】</li>\n<li>JVM 中的安全点和安全区各代表什么？写屏障你了解吗？【⭐⭐⭐⭐】</li>\n<li>并发标记要解决什么问题？并发标记带来了什么问题？如何解决并发扫描时对象消失问题？【⭐⭐⭐⭐】相关阅读：<a href=\"https://juejin.cn/post/6844904070788939790\" target=\"_blank\" rel=\"noopener\">面试官:你说你熟悉 jvm?那你讲一下并发的可达性分析</a> 。</li>\n<li>对于 JVM 的垃圾收集器你有什么了解的？【⭐⭐⭐⭐】有时候面试官会问出这种十分开放性的问题，你需要脑子里过一下你对这个大问题下的哪些知识熟悉哪些不熟悉，不熟悉的点一下就过，熟悉的展开讲。在准备校招时，我的一个是阿里 P7 的学姐，给我做过一次模拟面试，问出这个问题时让我有点懵，那么多东西我不知道从哪开始回答呀，就答得很凌乱。模拟面试完我问她这种问题应该从哪开始回答？ 她说她因为不知道我的掌握情况，所以就先问一个大问题，根据我的回答再追问，以后遇到这种问题主要从自己熟悉得方面切入就可以了。后来的面试还真遇到过好几次这种情况，我就答，垃圾收集器的种类有以下几种 Serial，ParNew…现在用的多的还是 CMS 和 G1，CMS 的垃圾收集流程是 xxx，G1 的垃圾收集流程是 xxx，他们特点是…就这样把话题引到 CMS 和 G1 了，只 CMS 和 G1 这部分和面试官讨论十几分钟完全没问题。</li>\n<li>新生代垃圾收集器有哪些？老年代垃圾收集器有哪些？哪些是单线程垃圾收集器，哪些是多线程垃圾收集器？各有什么特点？各基于哪一种垃圾收集算法？【⭐⭐⭐⭐】</li>\n<li>讲一下 CMS 垃圾收集器的四个步骤。CMS 有什么缺点？【⭐⭐⭐⭐】</li>\n<li>G1 垃圾收集器的步骤。有什么缺点？【⭐⭐⭐⭐】</li>\n<li>讲一下内存分配策略？【⭐⭐⭐⭐】</li>\n<li>虚拟机基础故障处理工具有哪些？【⭐⭐⭐】</li>\n<li>什么是字节码？类文件结构的组成了解吗？【⭐⭐⭐⭐】</li>\n<li>类的生命周期？类加载的过程了解么？加载这一步主要做了什么事情？初始化阶段中哪几种情况必须对类初始化？【⭐⭐⭐⭐⭐】</li>\n<li>讲一下双亲委派模型。【⭐⭐⭐⭐⭐】</li>\n</ol>\n<h2 id=\"MySQL-《深入浅出MySQL》\"><a href=\"#MySQL-《深入浅出MySQL》\" class=\"headerlink\" title=\"MySQL 《深入浅出MySQL》\"></a>MySQL 《深入浅出MySQL》</h2><p>好了，现在正式进入 MySQL 面试八股文的划重点流程。在这里要推荐一本书籍《深入浅出 MySQL 》。</p>\n<p><img src=\"https://img-blog.csdnimg.cn/20210620170853137.png\" alt=\"img\"></p>\n<ul>\n<li><strong>推荐理由</strong> ：《深入浅出 MySQL》这本书是网易的数据库专家写的，从数据库的基础、开发、优化、管理维护、架构，五个层面讲述了 MySQL（大家面试后端的话管理维护篇就不用看了），内容层层递进。并且每讲解一个小的知识点都会相应的配有实例，更容易读者理解。</li>\n<li><strong>学习内容</strong> ：学习内容按照《深入浅出 MySQL》的目录进行介绍。根据章节内容列出的问题我就不附上答案了，大家根据我的问题自己总结下会有更好的学校效果。在补充篇的问题我会给出答案。</li>\n</ul>\n<p><strong>基础篇第2章 SQL 基础</strong></p>\n<p>基础的SQL语句肯定要会，并且要熟练，这是最基础的。</p>\n<p>针对本章内容的面试问题：</p>\n<p>（1）增删改查这些问题面试官一般不会问的。不过万一问出来，比如“查询用哪个关键字”，你要是不知道你就惨了哈。</p>\n<p>（2）ORDER BY、LIMIT、GROUP BY、HAVING 这些关键字分别是做什么用的。</p>\n<p>（3）讲一下左链接和右链接的区别。</p>\n<p><strong>基础篇第3章、第4章、第5章</strong></p>\n<p>这三章分别是MySQL的数据类型、运算符、常用函数。简单过一遍，了解就行，这三章在面试中很少会被问到。</p>\n<p><strong>开发篇第7章 表类型（存储引擎）的选择</strong></p>\n<p>InnoDB是面试考察的重点，相关知识都要详细看。另外要拿 InnoDB 对比 MyISAM、MEMORY 去体会 InnoDB 引擎的特点。</p>\n<p>针对本章内容的面试问题：</p>\n<p>InnoDB 和 MyISM、MEMORY 的区别是什么。</p>\n<p><strong>开发篇第10章 索引的设计和使用</strong></p>\n<p>索引是 MySQL 面试考察的重点，BTree 索引和 Hash 索引要对比着进行学习。</p>\n<p>针对本章内容的面试问题：</p>\n<p>（1）索引所采用的数据结构，以及为什么要这样设计。</p>\n<p>（1）在数据库中创建索引的原则。</p>\n<p>（2）BTree 索引和 Hash 索引的适用范围。</p>\n<p><strong>开发篇第11章 视图</strong></p>\n<p>本章做到基本了解，面试过程中问的少。</p>\n<p><strong>开发篇第14章 事务控制和锁定语句</strong></p>\n<p>InnoDB 是行锁，MyISAM、MEMORY 是表锁面试过程中经常会问到。本章的事务控制实例值得好好的体会一下，有利于加深对数据库锁的理解。</p>\n<p><strong>优化篇第18章 SQL优化</strong></p>\n<p>如果你在简历中和开头的自我介绍中强调了你对 MySQL 熟悉，那么你这一章一定要好好看。面试官想考察你在 MySQL 方面的能力是否和你之前说的相符，会倾向于出一道场景问题，让你去设计并优化（当然只是好好看这一章并不能完全解决问题，一会我做一点补充）。</p>\n<p>针对本章内容的面试问题：</p>\n<p>（1）优化 SQL 语句的步骤有哪些。</p>\n<p>（2）哪些场景可以使用索引。</p>\n<p>（3）索引在哪些情况会失效。</p>\n<p>虽然面试官不会直接问你在优化 SQL 语句时候有哪些技巧？比如怎样优化 Insert 语句，怎样优化 order by语句。但是可以在这一章学一些常用的优化 SQL 语句的技巧，在面试官问一个具体问题时，顺带说一下自己平时会采用这些技巧去优化。</p>\n<p><strong>优化篇第20章 锁问题</strong></p>\n<p>这一章属于第14章的拔高，大家主要看表锁和行锁，页锁被问到的比较少。</p>\n<p>针对本章内容的面试问题：</p>\n<p>（1）事务四大特性，并解释这四大特性的含义。</p>\n<p>（2）并发事务处理会带来哪些问题？</p>\n<p>（3）事务隔离级别。</p>\n<p>（4）InnoDB 行锁实现方式</p>\n<p>（5）你了解 Next-key 锁吗？</p>\n<p>（6）如何避免 InnoDB 中的死锁。</p>\n<p>（7）数据库多版本并发控制（MVCC 机制）</p>\n<p><strong>优化篇第21章 优化 MySQL Server</strong></p>\n<p>这一章在校招面试中是不会问到的，不过我把这里的相关知识学了去给面试官讲，效果还不错。大家根据自己的情况酌情选择看还是不看哈。</p>\n<p>可以和面试官展开聊的知识点：</p>\n<p>（1）MySQL 的内存管理及优化。</p>\n<p>（2）InnoDB 重做日志的内部机制，这个可以和事务联系起来给面试官讲。</p>\n<p><strong>架构篇第31章 MySQL 复制</strong></p>\n<p>这一章的内容如果你不刻意提到，面试官一般很少主动问。如果大家不打算在 MySQL 这里和面试官多聊，那么这里就可以不看了。如果大家打算在 MySQL 这个环节和面试官展开聊，那么在这里和面试官展开聊是一个不错的选择。</p>\n<p>可以和面试官展开聊的知识点：</p>\n<p>（1）MySQL 的主从复制原理。</p>\n<p>（2）MySQL 的三种复制方式。</p>\n<p>（3）MySQL 的异步复制和半同步复制。</p>\n<p>（4）如何提高复制的性能。</p>\n<h2 id=\"Redis-《Redis的设计与实现》\"><a href=\"#Redis-《Redis的设计与实现》\" class=\"headerlink\" title=\"Redis 《Redis的设计与实现》\"></a>Redis 《Redis的设计与实现》</h2><p>对于没有太多时间准备 Redis 的同学，我在这里给大家准备一些面试常问的八股问题。你在面试大厂时，只要别给面试官对你 Redis 部分太高的期望，你把下面这些问题能回答清楚就算过关了。</p>\n<ol>\n<li>什么是 Redis？【⭐⭐】</li>\n<li>Redis 除了做缓存，还能做什么？【⭐⭐⭐⭐】</li>\n<li>Redis 有哪些数据类型？这些数据类型的应用场景分别是什么？你在项目中用到了吗？【⭐⭐⭐⭐⭐】</li>\n<li>Redis6.0 之后为何引入了多线程？【⭐⭐⭐】</li>\n<li>Redis 过期数据删除策略讲一下。【⭐⭐⭐】</li>\n<li>Redis 的持久化策略了解嘛？分别介绍下 RDB 和 AOF。【⭐⭐⭐⭐】</li>\n<li>什么是缓存穿透？什么是缓存击穿？什么是缓存雪崩？怎么解决（最高频问题）</li>\n<li>设计一个分布式锁？【⭐⭐】</li>\n<li>Redis 内存淘汰机制了解么？类似问题：MySQL 里有 2000w 数据，Redis 中只存 20w 的数据，如何保证 Redis 中的数据都是热点数据?【⭐⭐⭐⭐】</li>\n<li>Redis 事务你了解嘛？【⭐⭐】</li>\n<li>如何保证 Redis 和 MySQL 的数据一致性？（如果项目同时用到 Redis 和 MySQL，这个问题特别容易被问）【⭐⭐⭐⭐】</li>\n</ol>\n"},{"title":"MySQL技术内幕读书笔记（持续更新）","excerpt":"","comments":1,"date":"2021-01-22T02:30:52.000Z","_content":"\n由于对MySQL的了解不够透彻，虽然用起来没问题，也知道一些常见的知识点，但是一直把它当作一个黑盒来使用，不免有些心里没底，所以下定决心，通过<strong>姜承尧</strong>大佬的书[MySQL技术内幕](https://book.douban.com/subject/24708143/)，认真了解MySQL技术细节。我会将一些我认为重要的知识，记录在这篇博客中，希望看到这篇文章的你，也能有所收获。\n\n# 第一章 MySQL体系结构和存储引擎\n\n## 1. Mysql体系结构\n\n1. 数据库是文件的集合，是依照某种数据模型组织起来并存放于二级存储器中的数据集合；数据库实例是程序，是位于用户与操作系统之间的一层数据管理软件，用户对数据库数据的任何操作，包括数据库定义、数据查询、数据维护、数据库运行控制等都是在数据库实例下进行的，应用程序只有通过数据库实例才能和数据库打交道。\n2. MySQL由以下几个部分组成：\n   - 连接池组件\n   - 管理服务和工具组件\n   - SQL接口组件\n   - 查询分析器组件\n   - 优化器组件\n   - 缓存（cache）组件\n   - 插件式存储引擎\n   - 物理文件\n3. MySQL区别于其他数据库的最重要的一个特点就是它的插件式的表存储引擎。\n4. 存储引擎是基于表的，而不是数据库。\n\n## 2. MySQL存储引擎\n\n1. MySQL是开源的，用户可以基于MySQL预定义的存储引擎接口编写自己的存储引擎。当然也可以通过修改某一存储引擎的源码来得到想要的特性。\n2. InnoDB存储引擎最早是第三方存储引擎，后来被Oracle收购。\n\n### 1. InnoDB存储引擎\n1. InnoDB存储引擎支持事务。其设计目标主要面向在线事务处理（OLTP）的应用。其特点是：行锁设计、支持外键，并支持类似Oracle的非锁定读，即默认读取操作不会产生锁。\n2. 从5.5.8版本开始，InnoDB是MySQL默认的存储引擎。\n3. InnoDB存储引擎将数据放在一个逻辑的表空间中。表空间由InnoDB自身进行管理。从MySQL4.1开始，它可以将每个InnoDB存储引擎的表单独存放到一个独立的ibd文件中。InnoDB支持用裸设备（raw disk）建立表空间。<strong>裸设备：裸设备(raw device)，也叫裸分区（原始分区），是一种没有经过格式化，不被Unix通过文件系统来读取的特殊块设备文件。由应用程序负责对它进行读写操作。不经过文件系统的缓冲。它是不被操作系统直接管理的设备。这种设备少了操作系统这一层，I/O效率更高。不少数据库都能通过使用裸设备作为存储介质来提高I/O效率。</strong>\n4. InnoDB通过使用多版本并发控制（MVCC）来获得高并发性，并实现了SQL的4种隔离级别，默认Repeatable级别。\n5. InnoDB使用一种next-key locking的策略来避免幻读的产生。\n6. InnoDB提供了插入缓存（insert buffer）、二次写（double write）、自适应哈希索引（adaptive hash index）、预读（read ahead）等高性能和高可用功能。\n7. InnoDB表存储数据采用了聚集（clustered）的方式，因此每张表的存储都是按照主键的顺序进行存放。如果没有显式地定义主键，InnoDB会为每一行数据生成一个6字节的ROWID，并以此作为主键。\n\n### 2. MyISAM存储引擎\n1. MyISAM存储引擎不支持事务、锁表设计，支持全文索引，主要面向一些OLAP数据库应用。\n2. MySQL5.5.8之前默认存储引擎是MyISAM（Windows版本除外）。\n3. MyISAM存储引擎的缓冲池只缓存索引文件，而不缓存数据文件。这点和大多数数据库都不同。\n4. MyISAM存储引擎表由MYD和MYI组成，MYD用来存放数据文件，MYI用来存放索引文件。\n5. MySQL5.0之前MyISAM默认支持的表大小是4G，如果需要更大的MyISAM表的话，就要制定MAX_ROWS和AVG_ROW_LENGTH属性。从5.0版本开始，MyISAM默认支持256TB的单表数据，这足够一般应用的需求。\n6. MyISAM存储引擎表，Mysql数据库只缓存其索引文件，数据文件的缓存交给操作系统本身完成，这与LRU算法缓存数据的大部分数据库都不同。MySQL 5.1.23之前，缓存索引的缓冲区最大只能设置为4GB，在之后的版本中，64位系统可以支持大于4GB的索引缓冲区。\n\n### 3. 其他存储引擎\n\n1. NDB： 一个集群存储引擎。数据全部放在内存中（从MySQL 5.1之后，可以将非索引数据放在磁盘上），所以主键查找速度极快，通过添加NDB数据存储节点，可以线性的提高数据库性能，是高可用、高性能的集群系统。复杂的连接操作网络开销很大，因为NDB的连接操作（JOIN）是在数据库层完成的，而不是在存储引擎层完成的。\n2. Memory: 之前被称为HEAP存储引擎。将表中的数据存放在内存中，如果数据库重启或发生崩溃，表中的数据全部消失。非常适合非常适合存储临时数据。默认使用hash哈希索引，而不是B+树索引。只支持表锁，并法性能差，不支持TEXT、BLOB列类型。存储变长字段varchar是按照定长char方式存储的，因此会浪费空间。MySQL数据库使用Memory存储引擎作为临时表来存放查询的中间结果集，如果中间结果集大于Memory存储引擎表的容量设置，又或者中间结果含有TEXT或BLOB字段，则MySQL会把其转换成MyISAM存储引擎表存放到磁盘中，因为MyISAM不缓存数据文件，所以这时产生的临时表的性能对于查询会有损失。\n3. Archive存储引擎： Archive引擎只支持INSERT和SELECT操作，从MySQL5.1开始支持索引。Archive引擎使用zlib算法将数据行（row）进行压缩后存储，压缩比可达到1：10。正如其名，Archive存储引擎非常适合存储归档数据，如日志信息。通过行锁来实现高并发的插入操作。但是不是事务安全的，目的主要是提供高速的插入和压缩。\n4. Federated存储引擎： Federated存储引擎并不存储数据，他只是指向一台远程MySQL数据库服务器上的表。类似SQL Server的链接服务器和Oracle的透明网关。不同的是，Federated只支持MySQL数据库表，不支持异构数据库表。\n5. Maria存储引擎： Maria当初是为了取代原有的MyISAM而设计的，从而成为MySQL默认存储引擎。支持缓存数据和索引文件，应用了行锁设计，提供了MVCC功能，支持事务和非事务安全的选项，以及更好的BLOB字符类型的处理性能。\n\n\n### 4. 其它\n1. 查看当前使用MySQL版本支持的引擎：\n\n```sql\n\nshow engines\\G;\n\n```\n\n## 3. 连接MySQL\n\n### 1. TCP/IP\n\n```bash\n\nmysql -h 192.168.0.101 -u root -p\n\n```\n\n通过TCP/IP连接到数据库实例的时候，MySQL数据库会先检查一张权限视图，用来判断此请求是否允许连接。该视图在MySQL架构下，表名为user。\n\n```sql\n\nuse mysql;\nselect host, user, password from user;\n\n```\n\n### 2. 命名管道和共享内存\n\n如果在MySQL服务器本机连接，可以通过命名管道，但是需要MySQL数据库在配置文件中启用`--enable-named-pipe`选项。在MySQL 4.1之后，还提供了共享内存的连接方式，需要在配置文件中添加`--shared-memory`实现，在连接时，MySQL客户端还需要使用`--protocol=memory`选项。\n\n### 3. UNIX域套接字\n\n在Linux/UNIX环境下，可以使用UNIX域套接字。UNIX域套接字并不是一个网络协议，所以只能在MySQL客户端和数据库实例在一台服务器上时使用。用户可以在配置文件中执行套接字文件的路径。如`--socket=/tmp/mysql.sock`。可以通过命令`show variables like 'socket';`来查找套接字文件。知道了套接字文件的路径后，就可以通过下面的命令连接了：\n\n```bash\n\nmysql -u root -S /tmp/mysql.sock\n\n```\n\n# 第二章 InnoDB存储引擎\n\n## 1. InnoDB存储引擎概述\n\nInnoDB存储引擎是第一个完整支持ACID事务的MySQL存储引擎，其特点是行锁设计、支持MVCC、支持外键、提供一致性非锁定读，同时被设计用来最有效地利用以及使用内存和CPU。\n\n## 2. InnoDB存储引擎的版本\n\n早期InnoDB随MySQL数据库的更新而更新，从MySQL5.1开始，MySQL允许存储引擎开发商以动态方式加载引擎，这样存储引擎可以不受MySQL数据库版本的限制。\n\n## 3. InnoDB体系架构\n\n### 1. 后台线程\n\nInnoDB存储引擎是多线程的模型，后台有多个不同的线程，负责处理不同的任务。\n\n1. Master Thread： 这是一个非常核心的后台线程，主要负责将缓冲池中的数据异步刷新到磁盘，保证数据一致性，包括脏页的刷新、合并插入缓存（INSERT BUFFER）、UNDO页的回收等。\n2. IO Thread： 在InnoDB存储引擎中大量的使用了AIO（Async IO）来处理写IO请求，这样极大地提高了数据库的性能。IO Thread主要负责这些IO请求的回调（call back）处理。InnoDB 1.0之前共有4个IO Thread，分别是write、read、insert buffer和log IO Thread。在Linux平台下，IO Thread的数量不能进行调整，但是在Windows平台下，可以通过参数`innodb_file_io_threads`来增大IO Thread。从InnoDB 1.0.x开始，read thread和write thread分别增大到4个，并且不再使用`innodb_file_io_threads`参数，而是分别使用`innodb_read_io_threads`和`innodb_write_io_threads`参数进行设置。\n\n```sql\n\n#查看innodb引擎版本\nshow variables like 'innodb_version'\\G;\n\n#output\n*************************** 1. row ***************************\nVariable_name: innodb_version\n        Value: 8.0.22\n1 row in set (1.18 sec)\n\n\n#查看innodb读写IO线程\nshow variables like 'innodb_%io_threads'\\G;\n\n#output\n*************************** 1. row ***************************\nVariable_name: innodb_read_io_threads\n        Value: 4\n*************************** 2. row ***************************\nVariable_name: innodb_write_io_threads\n        Value: 4\n2 rows in set (0.00 sec)\n\n\n#查看InnoDB中的IO Threads\nshow engine innodb status\\G;\n\n#output\n...\n--------\nFILE I/O\n--------\nI/O thread 0 state: waiting for completed aio requests (insert buffer thread)\nI/O thread 1 state: waiting for completed aio requests (log thread)\nI/O thread 2 state: waiting for completed aio requests (read thread)\nI/O thread 3 state: waiting for completed aio requests (read thread)\nI/O thread 4 state: waiting for completed aio requests (read thread)\nI/O thread 5 state: waiting for completed aio requests (read thread)\nI/O thread 6 state: waiting for completed aio requests (write thread)\nI/O thread 7 state: waiting for completed aio requests (write thread)\nI/O thread 8 state: waiting for completed aio requests (write thread)\nI/O thread 9 state: waiting for completed aio requests (write thread)\n...\n\n```\n\n3. Purge Thread: 事务被提交后，其所使用的undolog可能不再需要，因此需要Purge Thread来回收已经使用并分配的undo页。在InnoDB1.1之前，purge操作仅在Master Thread中完成。而从InnoDB1.1版本开始，purge操作可以独立到单独的线程中进行，以此来减轻Master Thread的工作，从而提高CPU的使用率以及提升存储引擎的性能。用户可以在配置文件中添加配置来启用独立的Purge Thread（见下面的代码），在InnoDB1.1中，即使将purge线程数设置大于1，启动时也会将其设置为1，从1.2版本开始，InnoDB开始支持多个Purge Thread，这样可以加快undo页的回收，由于Purge Thread需要离散的随机读取undo页，这样也能进一步利用磁盘的随机读取性能。\n\n```conf\n\n[mysqld]\ninnodb_purge_threads=1\n\n```\n\n4. Page Cleaner Thread: InnoDB 1.2.x引入，作用是将之前版本中的脏页的刷新操作都放入到单独的线程中来完成。目的是减轻Master Thread的工作，以及用户查询线程的阻塞，进一步提高InnoDB存储引擎的性能。\n\n### 2. 内存\n\n#### 1. 缓冲池\n\nInnoDB存储引擎是基于磁盘存储的，并将其中的记录按照页的方式进行管理。因此可以将其视为基于磁盘的数据库系统（Disk-base Database）。CPU速度与磁盘速度差距很大，基于磁盘的数据库系统通常采用缓冲池技术来提高数据库的整体性能。\n\n缓冲池就是一块内存区域，通过内存的速度来弥补磁盘速度对数据库性能的影响。\n\n1. 数据库操作时，缓冲池的使用\n   - 当数据库进行读取页当操作当时候，首先将从磁盘读到当页缓存在缓冲池中，这个过程称为将页“FIX”在缓冲池中。下一次读取相同的页的时候，首先判断该页是否在缓冲池中，如果在，称该页在缓冲池中被命中，直接读取该页，否则读取磁盘上的页。\n   - 对于数据库中页的修改操作，首先修改在缓冲池中的页，然后再以一定的频率刷新到磁盘上，这里要注意，页从缓冲池刷新回磁盘的操作并不是在每次页发生更新时触发，而是通过一种成为`Checkpoint`的机制刷新回磁盘。这样也提高了数据库的整体性能。\n\n2. 缓冲池的大小： 缓冲池的大小直接影响着数据库的整体性能\n   1. 系统限制：32位操作系统的限制，最多将该值设置为3G。用户可以打开操作系统的PAE选项来获得32位系统下最大64GB内存的支持。\n   2. 强烈建议采用64位操作系统，让数据库使用更多的内存。\n   3. 对于InnoDB来说，缓冲池配置通过参数`innodb_buffer_pool_size`来设置\n\n3. 缓冲池的类型： 索引页、数据页、undo页、插入缓冲（insert buffer）、自适应哈希索引（adaptive hash index）、InnoDB存储的锁信息（lock info）、数据字典信息（data dictionary）等。从InnoDB 1.0.x开始，允许有多个缓冲池实例。每个页根据哈希值平均分配到不同到缓冲池实例中，增加了数据库的并发处理能力。可以通过参数`innodb_buffer_pool_instances`来进行配置，默认为1。\n\n#### 2. LRU List、Free List和Flush List\n\n1. LRU List\n   - 数据库中的缓冲池是通过LRU（Last Recent Used，最近最少使用）算法来进行管理的。即最频繁使用的页在LRU列表的前端，而最少使用的页在LRU列表的尾端。当缓冲池不能存放新读取到的页时，将首先释放LRU列表中尾端的页。\n   - InnoDB对LRU算法做了一些优化，在LRU列表中加入了midpoint位置。新读取到到页，虽然是最新访问到数据，但是也不会直接放到LRU列表到首部，而是放到midpoint的位置。这个算法在InnoDB存储引擎下称为`midpoint insertion strategy`。在默认配置下，midpoint在LRU列表长度的5/8处，也就是LRU列表尾端的3/8（37%）的位置。midpoint位置可以由参数`innodb_old_blocks_pct`控制。在InnoDB中，把midpoint之后的列表称为old列表，之前的列表称为new列表。可以简单的理解为new列表中的页都是做活跃的热点数据。\n   - 为什么不用最常见的LRU算法（新数据直接放到首部）？这是因为某些SQL结果集可能超大，可能回将整个LRU列表中的数据刷出，导致真正的热点数据也被清除。加入midpoint可以保护热点数据。\n   - InnoDB还有另一个参数`innodb_old_blocks_time`（以毫秒为单位）用于表示页读到mid位置的后需要等待多久才会被加入到LRU列表的热端。页插入到mid位置后的`innodb_old_blocks_time`时间内，可以通过LRU列表访问页，但是无论多少次查询都不会将其移动到new列表，`innodb_old_blocks_time`时间后，如果再次被访问，就会被移动到new列表。\n\n```sql\n\n#为了LRU列表中的热点数据不被刷出啊，可以先设置innodb_old_blocks_time\n\nmysql> SET GLOBAL innodb_old_blocks_time=1000;\nQuery OK, 0 rows affected.\n\n# data or index scan operation\n......\n\nmysql> SET GLOBAL innodb_old_blocks_time=0;\nQuery OK, 0 rows affected.\n\n```\n\n如果用户预估自己活跃的热点数据不止63%，那么再执行SQL语句前可以通过下面的语句来减少热点页被刷出的概率。\n\n```sql\nmysql> SET GLOBAL innodb_old_blocks_pct=20;\nQuery OK, 0 rows affected.\n```\n\n\n2. Free List\n\nLRU列表是用来管理管理已经读取到的页的，但是当数据库刚启动时，LRU列表是空的，即没有任何的页，这时页都存放于Free列表中。当需要从缓冲池中分页时，首先从Free列表中查找到是否可用的空闲页，若有则将该页从Free列表中删除，放入到LRU列表中。否则，根据LRU算法，淘汰LRU列表末尾的页，将该内存空间分配给新的页。\n\n        这里感觉有点难理解，数据库刚启动的时候，缓冲池里是没有缓存数据的，但是相应的内存空间已经开辟了，当我们查询数据后，磁盘返回数据，这时候，缓冲池要缓存数据，LRU列表是空的，要去Free List里取出空闲页，这里的空闲页其实是一个没有存储数据的页的描述（或者说地址），然后将磁盘返回的数据缓存到这个页，并将这个页交由LRU列表管理。也就是FreeList就是记录空闲页描述的双向列表，当LRU列表需要一个新的页的时候，就来找Free列表要，然后新的数据就被缓存了。\n\n- 这里感觉上LRU列表管理已经读取到的页，Free列表管理未使用的页，他们的size的和就应该是缓冲池里所有页的数量了。但是通过`SHOW ENGINE INNODB STATUS`可以看到，free buffers（Free列表页数量）和Database pages（LRU列表中页的数量）之和并不是缓冲池页的总数（Buffer pool size）。这是因为缓冲池中的页可能会被分配给自适应哈希索引、Lock信息、Insert Buffer等页，而这部分页不需要LRU算法进行维护，因此不在LRU列表中。\n- 从InnoDB1.2版本开始，还可以通过`INNODB_BUFFER_POOL_STATUS`来观察缓冲池的运行状态。\n   ```sql\n        select pool_id, hit_rate, pages_made_young, pages_not_made_young from information_schema.INNODB_BUFFER_POOL_STATUS;\n   ```\n- 可以通过`INNODB_BUFFER_PAGE_LRU`来观察每个LRU列表中每个页的具体信息，例如通过下面的语句可以看到缓冲池LRU列表中SPACE为1的表的页类型：\n    ```sql\n        select table_name, space, page_number, page_type from innodb_buffer_page_lru where space = 1;\n    ```\n- InnoDB存储引擎从1.0.x版本开始支持压缩页的功能，即将原本16k的页压缩为1kb、2kb、4kb和8kb。而由于页的大小发生了变化，LRU列表也有了些许的改动。对于非16kb的页，是通过unzip_LRU列表来进行管理的。通过命令`SHOW ENGINE INNODB STATUS\\G;`可以看到LRU列表和unzip_LRU列表的页的数量。LRU中的页包含了unzip_LRU列表中的页。\n- unzip_LRU列表中对不同压缩页大小的页进行分别管理，并通过`伙伴算法`进行内存的分配。以需要从缓冲池中申请页为4kb的大小为例，其过程如下：\n  \n   1. 检查4kb的unzip_LRU列表，检查是否有可用的空闲页；\n   2. 如果有，则直接使用；\n   3. 否则，检查8kb的unzip_LRU列表；\n   4. 如果能够得到空闲页，将页分成2个4KB页，存放到4KB的unzip_LRU列表；\n   5. 如果不能得到空闲页，从LRU列表中申请一个16KB的页，将页分为1个8KB的页、2个4KB的页，分别存放到对应的unzip_LRU列表中。\n\n   可以通过information_schema架构下的表INNODB_BUFFER_PAGE_LRU来观察unzip_LRU列表中的页\n\n   ```sql\n      select table_name, space, page_number, compressed_size from innodb_buffer_page_lru where compressed_size <> 0;\n   ```\n\n   ```\n   伙伴算法，简而言之，就是将内存分成若干块，然后尽可能以最适合的方式满足程序内存需求的一种内存管理算法，伙伴算法的一大优势是它能够完全避免外部碎片的产生。什么是外部碎片以及内部碎片，前面博文slab分配器后面已有介绍。申请时，伙伴算法会给程序分配一个较大的内存空间，即保证所有大块内存都能得到满足。很明显分配比需求还大的内存空间，会产生内部碎片。所以伙伴算法虽然能够完全避免外部碎片的产生，但这恰恰是以产生内部碎片为代价的。\n   ```\n3. Flush List\n- 在LRU列表中的页被修改后，称该页为脏页（dirty page），即缓冲池中的页和磁盘上的页的数据产生了不一致。这时数据库会通过`checkpoint`机制将脏页刷新回磁盘，而Flush列表中的页即为`脏页列表`。需要注意的是，脏页既存在于LRU列表，也存在于Flush列表中。LRU列表用于来管理缓冲池中也的可用性，Flush列表用来管理将页刷回磁盘，二者互不影响。\n- 同LRU列表一样，Flush列表也能通过`SHOW ENGINE INNODB STATUS`来查看，`Modified db pages 24673`就显示了脏页的数量。\n- 查看脏页的数量和类型（table_name为null说明该页属于系统表空间）：\n   ```sql\n      select table_name, space, page_number, page_type \n      from innodb_buffer_page_lru where oldest_modification > 0;\n   ```\n\n### 3. 重做日志缓冲\n\n重做日志缓冲（redo log buffer）。InnoDB存储引擎首先将重做日志信息放入到这个缓冲区，然后按照一定频率将其刷新到重做日志文件。重做日志缓冲不一定要设置的很大，因为一般情况下每一秒会将重做日志缓存刷新到日志文件，因此只需要保证每秒产生的事务量在在这个缓存大小之内即可。该值由配置参数`innodb_log_buffer_size`控制，默认为8M：\n\n```sql\nmysql> show variables like 'innodb_log_buffer_size'\\G;\n*************************** 1. row ***************************\nVariable_name: innodb_log_buffer_size\n        Value: 16777216\n1 row in set (0.00 sec)\n```\n\n重做日志在下面三种情况下会将重做日志缓冲中的内容刷新到外部磁盘的重做日志文件中：\n\n- Master Thread每一秒将重做日志缓冲刷新到重做日志文件；\n- 每个事务提交时会将重做日志缓存刷新到重做日志文件；\n- 当重做日志缓冲池剩余空间小于1/2时，重做日志缓冲会刷新到缓存日志文件。\n\n### 4. 额外的内存池\n\n在InnoDB中，对内存的管理是通过一种称为内存堆（heap）的方式进行的。在对一些数据结构本身的内存进行分配时，需要从额外的内存池中进行申请，当该区域的内存不够时，会从缓冲池中进行申请。这里的数据结构本身是指每个缓冲池中的帧缓存（frame buffer）和对应的缓冲控制对象（buffer control block），这些对象记录了一些诸如LRU、锁、等待等信息，而这些对象的内存需要从额外的内存池中申请。<strong>因此在申请了很大的InnoDB缓冲池时，应该考虑相应的增加这个值</strong>。\n\n## 4. Checkpoint技术\n\nMysql缓冲池的设计就是为了跨越cpu速度与磁盘速度之间鸿沟，也就是页的操作都是首先在缓冲池中完成，操作完成时，缓冲池的数据版本比磁盘新，数据库需要将新版本的页刷新到磁盘。但是刷新到磁盘，瓶颈依然在磁盘IO，而且如果在缓存刷新到磁盘的过程中宕机，缓存中的数据时不能恢复的。所以当前事务数据库都普遍采用了`Write Ahead Log`策略，即当事务提交时，先写重做日志，在修改页。当由于宕机而导致数据丢失时，可以通过重做日志来完成数据的恢复。这也是事务ACID中D（Durability持久性）的要求。\n\n思考一下，缓冲池可以让我们读写数据更快速，重做日志可以保证数据库数据不丢失。有了缓冲池和重做日志，是不是就可以不用将缓冲池中的页刷新到磁盘了？好家伙，直接内存数据库了？毕竟mysql是要持久化的，是要存大量数据的。你一直不落磁盘，先不说内存够不够大，就是重新启动时重新应用重做日志的时间也够受的。所以mysql有个Checkpoint（检查点）技术。\n\n### 1. Checkout技术用于解决以下问题：\n\n- 缩短数据库的恢复时间\n- 缓冲池不够用时，将脏页刷新到磁盘\n- 重做日志不可用时，刷新脏页。\n\n1. 当数据库发生宕机时，数据库不需要重做所有日志，因为Checkpoint之前的页都已经刷新回磁盘了，所以只需要对Checkpoint后的重做日志进行恢复。这样就大大缩短了恢复的时间。\n2. 当缓冲池不够用时，根据LRU算法会溢出最近使用最少的页，若此页为脏页，那么需要强制执行Checkpoint，将脏页刷新到磁盘。\n3. 重做日志出现不可用的情况时因为当前事务数据库系统对重做日志的设计都是循环使用的，并不是无限增大的。重做日志可以被重用的部分是指这些重做日志已经不再需要，即当数据库发生宕机时，数据库恢复操作不需要这部分重做日志。因此这部分就可以被覆盖重用。若此时重做日志还需要使用，那么必须强制产生Checkpoint，将缓冲区中的页至少刷新到当前重做日志的位置。\n\n### 2. LSN（Log Sequece Number）\n\nInnoDB存储引擎是通过LSN来标记版本的。LSN是8字节的数字，单位是字节。每个页有LSN，重做日志中也有LSN，Checkpoint也有LSN。可以通过`SHOW ENGINE INNODB STATUS`来观察：\n\n```sql\nmysql> SHOW ENGINE INNODB STATUS\\G;\n\n......\n---\nLOG\n---\nLog sequence number 92561351052\nLog flushed up to 92561351052\nLast checkpoint at 92561351052\n```\n\n### 3. InnoDB中有两种Checkpoint\n\n#### 1. Sharp Checkpoint\n\nSharp Checkpoint发生在数据库关闭时将所有的脏页刷新回磁盘，这是默认的工作方式，即参数`innodb_fast_shutdown=1`。因为它时将所有的脏页都刷回磁盘，所以不可能在数据库运行时来执行，太影响性能。\n\n#### 2. Fuzzy Checkpoint\n\nInnoDB存储引擎内部使用Fuzzy Checkpoint进行页的刷新，即只刷新一部分脏页，而不是刷新所有的脏页到磁盘。\n\n在InnoDB中可能发生如下几种情况的Fuzzy Checkpoint：\n\n1. Master Thread Checkpoint\n\n   Master Thread Checkpoint以每秒或每十秒的速度从缓冲池的脏页列表中刷新一定比例的页回磁盘，这个过程是异步的，不会阻塞用户查询线程。\n\n2. FLUSH_LRU_LIST Checkporint\n\n   InnoDB存储引擎需要保证LRU列表中需要有差不多100个空闲页可供使用。InnoDB1.1.x版本之前，需要检查LRU是否有足够的可用空间操作发生在用户查询线程，这就会阻塞用户的查询操作。如果没有100个可用的空闲页，那么InnoDB存储引擎会将LRU列表尾端的页移除。如果这些页有脏页，那么就要进行Checkpoint。从MySQL5.6版本，也就是InnoDB1.2.x开始，这个检查被放在了一个单独的Page Cleaner线程中进行，并且用户可以通过参数innodb_lru_scan_depth控制LRU列表中可用页的数量，该值默认为1024。\n\n3. Async/Sync Flush Checkpoint\n\n   这里是在重做日志文件不可用时，需要强制将一些页刷回磁盘，而此时脏页是从脏页列表中选取的。若已经写入到重做日志的LSN极为redo_lsn，将已经刷新回磁盘最新页的LSN记为checkpoint_lsn，则可定义:\n\n   `checkpoint_age = redo_lsn - checkpoint_lsn`\n\n   再定义一下变量：\n\n   `async_water_mark = 75% * total_redo_log_file_size`\n\n   `sync_water_mark = 90% * total_redo_log_file_size`\n\n   如果每个重做日志文件大小为1GB，并且定义了两个重做日志文件，则重做日志文件的总大小为2GB，那么`async_water_mark`=1.5GB，`sync_water_mark`=1.8GB。\n\n   那么：\n\n   - 当checkpoint_age < async_water_mark时，不需要刷新任何脏页到磁盘。\n   - 当async_water_mark < checkpoint_age < sync_water_mark时，触发Async Flush，从Flush列表中刷新足够的脏页回磁盘，是的刷新后满足checkpoint_age<async_water_mark。\n   - checkpoint_age > sync_water_mark这种情况很少发生，除非设置的重做日志文件太小，并且在进行类似LOAD DATA的BULK INSERT操作。此时出发Sync Flush操作，从Flush列表中刷新足够的脏页回磁盘，使得刷新后满足checkpoint_age < async_water_mark。\n\n   可见Async/Sync Flush Checkpoint是为了保证重做日志的循环使用的可用性。InnoDB 1.2.x之前，Async会阻塞发现问题的用户查询线程，而Sync会阻塞所有用户的查询线程。但是后来，这部分的刷新操作同样放入了单独的Page Clener Thread中，不会阻塞用户查询线程。\n\n4. Dirty Page too much Checkpoint\n\n   这种情况就是脏页数量太多，导致InnoDB存储引擎强制进行Checkpoint。目的还是保证缓冲池中有足够可用的页。其可由参数`innodb_max_dirty_pages_pct`来控制。百分比，默认时75（老版本InnoDB是90），表示当缓冲池中脏页的数量占据75%时，强制进行checkpoint，刷新一部分的页到磁盘。\n\n\n## 5. Master Thread工作方式\n\nInnoDB存储引擎的主要工作都是在一个单独的后台线程Master Thread中完成的。\n\n### 1. InnoDB 1.0.x版本之前的Master Thread\n\nMaster Thread具有最高的线程优先级别。其内部由多个循环（loop）组成：主循环（loop）、后台循环（background loop）、刷新循环（flush loop）、暂停循环（suspend loop）。Master Thread会根据数据库运行的状态在loop、background loop、flush loop和suspend loop中进行切换。\n\n绝大多数操作是在这个循环中，其中分为两大部分的操作---每秒钟的操作和每10秒的操作。loop循环是通过thread sleep来实现的，所以所谓的每一秒或者没十秒只是个大概频率，负载很大的情况下可能会有延迟。\n\n每一秒的操作包括：\n\n- 日志缓冲刷新到磁盘，即使这个事务还没有提交（总是）：所以再大的事务提交（commit）的时间也是很短。\n- 合并插入缓冲（可能）：并不是每秒都发生，InnoDB会判断前一秒内发生的IO次数是否小于5次，小于5次，认为压力很小，可以执行合并插入缓冲操作。\n- 至多刷新100个InnoDB的缓冲池中的脏页到磁盘（可能）：InnoDB判断当前缓冲池中脏页的比例（buf_get_modified_ratio_pct）是否超过了配置文件中innodb_max_dirty_pages_pct参数（默认90，代表90%），如果超过了，就要作磁盘同步操作，将100个脏页写入磁盘中。\n- 如果当前没有用户活动，则切换到background loop（可能）\n\n每十秒的操作：\n\n- 刷新100个脏页到磁盘（可能）：InnoDB判断过去10秒内磁盘IO操作是否小于200次，如果是，认为当前有足够的磁盘IO操作能力，则将100个脏页刷新到磁盘\n\n- 合并至多5个插入缓冲（总是）\n\n- 将日志缓冲刷新到磁盘（总是）\n\n- 删除无用的Undo页（总是）：执行full purge操作，删除无用的Undo页，对表进行的update、delete操作，原先的行被标记为删除，但是因为一致性读（consistent read）的关系，要保留这些版本的信息，在full purge过程中，InnoDB会判断当前事务系统中已被删除的行是否可以删除（有时候可能还有查询操作需要读取之前版本的undo信息），如果可以删除，则删除。full purge操作，每次最多尝试回收20个undo页。\n\n- 刷新100个或者10个脏页到磁盘（总是）：InnoDB判断缓冲池中脏页的比例（buf_get_modified_ratio_pct），如果有超过70%的脏页，则刷新100个脏页到磁盘，如果脏页的比例小于70%，则只刷新10%的脏页到磁盘。\n\n  \n\nbackground loop的操作：\n\n- 删除无用的Undo页（总是）\n- 合并20个插入缓冲（总是）\n- 跳回到主循环（总是）\n- 不断刷新100个页直到符合条件（可能，跳转到flush loop中完成）\n\n如果flush loop中也没有什么事情可以作了，InnoDB存储引擎会切换到suspend loop，将Master Thread挂起，等待事件的发生。如果用户启用（enable）了InnoDB存储引擎，却没有使用任何InnoDB存储引擎的表，那么Master Thread总是处于挂起的状态。\n\nMaster Thread伪代码如下：\n\n```c\nvoid master_thread() {\n\tgoto loop;\n    loop:\n    \tfor(int i = 0; i < 10; i++) {\n            thread_sleep(1) // sleep 1 second\n            do log buffer flush to disk\n            if (last_one_second_ios < 5) {\n                do merge at most 5 insert buffer\n            }\n            if (buf_get_mondified_ratio_pct > innodb_max_dirty_pages_pct) {\n                do buffer pool flush 100 dirty page\n            }\n            if (no user activity) {\n                goto background loop\n            }\n        }\n    if (last_ten_second_ios < 200) {\n        do buffer pool flush 100 dirty page\n    }\n    do merge at most 5 insert buffer\n    do log buffer flush to disk\n    do full purge\n    if (buf_get_modified_ratio_pct > 70%) {\n        do buffer pool flush 100 dirty page\n    } else {\n        buffer pool flush 10 dirty page\n    }\n    goto loop\n    background loop:\n    \tdo full purge\n        do merge 20 insert buffer\n        if not idle:\n    \t\tgoto loop\n        else\n            goto flush loop\n    flush loop:\n    \tdo buffer pool flush 100 dirty page\n        if (buf_get_modified_radio_pct > innodb_max_dirty_pages_pct) {\n            goto flush loop\n        }\n    goto suspend loop\n    suspend loop:\n    \tsuspend_thread()\n        waiting event\n        \tgoto loop\n}\n```\n\n### 2. InnoDB 1.2.x版本之前的Master Thread\n\n几个修改：\n\n1. 1.0.x之前的版本其实对IO是有限制的（很多硬编码，比如刷新100个脏页到磁盘），在磁盘技术飞速发展的今天，当固态磁盘（SSD）出现时，这种规定在很大程度上限制了InnoDB存储引擎对磁盘IO的性能，尤其是写入性能。\n从InnoDB1.0.x，InnoDB Plugin提供了参数innodb_io_capacity，用来表示磁盘IO的吞吐量，默认值为200，当用户使用了ssd或者磁盘做了RAID，存储设备拥有了更高的IO速度，就可以将innodb_io_capacity调高，直到符合磁盘IO吞吐量。规则如下：\n\n   - 在合并插入缓存时，合并插入缓存的数量为innodb_io_capacity值的5%\n   - 在从缓冲区刷新脏页时，刷新脏页的数量为innodb_io_capacity\n\n2. `innodb_max_dirty_pages_pct`默认值的问题，在1.0.x版本之前，该值的默认为90，意味着脏页占缓冲池的90%。因为InnoDB存储引擎在每秒刷新缓冲池和flush loop时会判断这个值，如果该值大于`innodb_max_dirty_pages_pct`才刷新100个脏页，如果有很大的内存，或者数据库服务的压力很大，这时刷新脏页的速度反而会降低，同样，数据库在恢复阶段可能需要更多的时间。1.0.x后`innodb_max_diry_pages_pct`默认值变为了75，这样既可以加快刷新脏页的频率，又能保证磁盘IO的负载。\n3. 新增参数`innodb_adaptive_flushing`，自适应刷新，该值影响每秒刷新脏页的数量。原来的规则时：脏页在缓冲池所占比例小于`innodb_max_diry_pages_pct`时，不刷新脏页；大于`innodb_max_diry_pages_pct`时，刷新100个脏页。随着`innodb_adaptive_flushing`的引入，InnoDB存储引擎会通过一个名为`buf_flush_get_desired_flush_rate`的函数来判断需要刷新脏页的最合适的数量。`buf_flush_get_desired_flush_rate`通过判断产生重做日志（redo log）的速度来决定最合适的刷新脏页的数量。因此当脏页的比例小于`innodb_max_diry_pages_pct`时，也会刷新一定数量的脏页。\n4. 之前每次进行full purge操作时，最多回收20个Undo页，从InnoDB1.0.x开始引入了参数`innodb_purge_batch_size`，该参数可以控制每次full purge回收的undu页的数量。该参数的默认值为20，并可以动态的对其进行修改。\n   ```\n      mysql> show variables like 'innodb_purge_batch_size'\\G;\n      Variable_name: innodb_purge_batch_size\n      Value: 20\n      mysql> set global innodb_purge_batch_size=50;\n      Query OK, 0 rows affected (0.00 sec)\n   ```\n\n综上，1.0.x版本开始，Master Thread伪代码如下：\n\n```c\nvoid master_thread() {\n   goto loop;\nloop:\nfor(int i=0; i<10; i++) {\n   thread_sleep(1) //sleep 1 second\n   do log buffer flush to disk\n   if(last_one_second_ios < 5% innodb_io_capacity)\n      do merge 5% innodb_io_capacity insert buffer\n   if(buf_get_modified_ratio_pct > innodb_max_dirty_pages_pct) {\n      do buffer pool flush 100% innodb_io_capacity dirty page\n   } else if enable adaptive flush {\n      do buffer pool flush desired amount dirty page\n   }\n   if(no user activity)\n      goto background loop\n}\nif (last_ten_second_ios < innodb_io_capacity)\n   do buffer pool flush 100% innodb_io_capacity dirty page\ndo merge 5% innodb_io_capacity insert buffer\ndo log buffer flush to disk\ndo full purge\nif(buf_get_modified_ratio_pct > 70%)\n   do buffer pool flush 100% innodb_io_capacity dirty page\nelse\n   do buffer pool flush 10% innodb_io_capacity dirty page\ngoto loop\nbackground loop:\ndo full purge\ndo merge 100% innodb_io_capacity insert buffer\nif not idle:\ngoto loop:\nelse:\n   goto flush loop\nflush loop:\ndo buffer pool flush 100% innodb_io_capacity dirty page\nif(buf_get_modified_ratio_pct > innodb_max_dirty_pages_pct)\n   go to flush loop\n   goto suspend loop\nsuspend loop:\nsuspend_thread()\nwaiting event\ngoto loop;\n}\n```\n\n### 3. InnoDB 1.2.x版本的Master Thread\n\n在InnoDB1.2.x版本中再次对Master Thread进行了优化，由此可以看出Master Thread对性能所起到的关键作用。在1.2.x版本中，Master Thread的伪代码如下：\n```c\nif InnoDB is idle\n   srv_master_do_idle_tasks();\nelse\n   srv_master_do_active_tasks();\n```\n\n其中`srv_master_do_idle_tasks()`就是之前版本中的每10秒的操作，`srv_master_do_active_tasks()`处理的是之前每秒中的操作。同时对于刷新脏页的操作，从Master Thread线程分离到一个单独的Page Cleaner Thread，从而减轻了Master Thread的工作，同时进一步提高了系统的并发性。\n\n## 6. InnoDB关键特性\n\nInnoDB的关键特性包括：\n- 插入缓冲（Insert Buffer）\n- 两次写（Double Write）\n- 自适应哈希索引（Adaptive Hash Index）\n- 异步IO（Async IO）\n- 刷新邻接页（Flush Neighbor Page）","source":"_posts/2021-01-22-kongzheng1993-MySQL技术内幕读书笔记.md","raw":"---\ntitle: MySQL技术内幕读书笔记（持续更新）\nexcerpt: 'MySQL'\ntags: [MySQL]\ncategories: [MySQL]\ncomments: true\ndate: 2021-01-22 10:30:52\n---\n\n由于对MySQL的了解不够透彻，虽然用起来没问题，也知道一些常见的知识点，但是一直把它当作一个黑盒来使用，不免有些心里没底，所以下定决心，通过<strong>姜承尧</strong>大佬的书[MySQL技术内幕](https://book.douban.com/subject/24708143/)，认真了解MySQL技术细节。我会将一些我认为重要的知识，记录在这篇博客中，希望看到这篇文章的你，也能有所收获。\n\n# 第一章 MySQL体系结构和存储引擎\n\n## 1. Mysql体系结构\n\n1. 数据库是文件的集合，是依照某种数据模型组织起来并存放于二级存储器中的数据集合；数据库实例是程序，是位于用户与操作系统之间的一层数据管理软件，用户对数据库数据的任何操作，包括数据库定义、数据查询、数据维护、数据库运行控制等都是在数据库实例下进行的，应用程序只有通过数据库实例才能和数据库打交道。\n2. MySQL由以下几个部分组成：\n   - 连接池组件\n   - 管理服务和工具组件\n   - SQL接口组件\n   - 查询分析器组件\n   - 优化器组件\n   - 缓存（cache）组件\n   - 插件式存储引擎\n   - 物理文件\n3. MySQL区别于其他数据库的最重要的一个特点就是它的插件式的表存储引擎。\n4. 存储引擎是基于表的，而不是数据库。\n\n## 2. MySQL存储引擎\n\n1. MySQL是开源的，用户可以基于MySQL预定义的存储引擎接口编写自己的存储引擎。当然也可以通过修改某一存储引擎的源码来得到想要的特性。\n2. InnoDB存储引擎最早是第三方存储引擎，后来被Oracle收购。\n\n### 1. InnoDB存储引擎\n1. InnoDB存储引擎支持事务。其设计目标主要面向在线事务处理（OLTP）的应用。其特点是：行锁设计、支持外键，并支持类似Oracle的非锁定读，即默认读取操作不会产生锁。\n2. 从5.5.8版本开始，InnoDB是MySQL默认的存储引擎。\n3. InnoDB存储引擎将数据放在一个逻辑的表空间中。表空间由InnoDB自身进行管理。从MySQL4.1开始，它可以将每个InnoDB存储引擎的表单独存放到一个独立的ibd文件中。InnoDB支持用裸设备（raw disk）建立表空间。<strong>裸设备：裸设备(raw device)，也叫裸分区（原始分区），是一种没有经过格式化，不被Unix通过文件系统来读取的特殊块设备文件。由应用程序负责对它进行读写操作。不经过文件系统的缓冲。它是不被操作系统直接管理的设备。这种设备少了操作系统这一层，I/O效率更高。不少数据库都能通过使用裸设备作为存储介质来提高I/O效率。</strong>\n4. InnoDB通过使用多版本并发控制（MVCC）来获得高并发性，并实现了SQL的4种隔离级别，默认Repeatable级别。\n5. InnoDB使用一种next-key locking的策略来避免幻读的产生。\n6. InnoDB提供了插入缓存（insert buffer）、二次写（double write）、自适应哈希索引（adaptive hash index）、预读（read ahead）等高性能和高可用功能。\n7. InnoDB表存储数据采用了聚集（clustered）的方式，因此每张表的存储都是按照主键的顺序进行存放。如果没有显式地定义主键，InnoDB会为每一行数据生成一个6字节的ROWID，并以此作为主键。\n\n### 2. MyISAM存储引擎\n1. MyISAM存储引擎不支持事务、锁表设计，支持全文索引，主要面向一些OLAP数据库应用。\n2. MySQL5.5.8之前默认存储引擎是MyISAM（Windows版本除外）。\n3. MyISAM存储引擎的缓冲池只缓存索引文件，而不缓存数据文件。这点和大多数数据库都不同。\n4. MyISAM存储引擎表由MYD和MYI组成，MYD用来存放数据文件，MYI用来存放索引文件。\n5. MySQL5.0之前MyISAM默认支持的表大小是4G，如果需要更大的MyISAM表的话，就要制定MAX_ROWS和AVG_ROW_LENGTH属性。从5.0版本开始，MyISAM默认支持256TB的单表数据，这足够一般应用的需求。\n6. MyISAM存储引擎表，Mysql数据库只缓存其索引文件，数据文件的缓存交给操作系统本身完成，这与LRU算法缓存数据的大部分数据库都不同。MySQL 5.1.23之前，缓存索引的缓冲区最大只能设置为4GB，在之后的版本中，64位系统可以支持大于4GB的索引缓冲区。\n\n### 3. 其他存储引擎\n\n1. NDB： 一个集群存储引擎。数据全部放在内存中（从MySQL 5.1之后，可以将非索引数据放在磁盘上），所以主键查找速度极快，通过添加NDB数据存储节点，可以线性的提高数据库性能，是高可用、高性能的集群系统。复杂的连接操作网络开销很大，因为NDB的连接操作（JOIN）是在数据库层完成的，而不是在存储引擎层完成的。\n2. Memory: 之前被称为HEAP存储引擎。将表中的数据存放在内存中，如果数据库重启或发生崩溃，表中的数据全部消失。非常适合非常适合存储临时数据。默认使用hash哈希索引，而不是B+树索引。只支持表锁，并法性能差，不支持TEXT、BLOB列类型。存储变长字段varchar是按照定长char方式存储的，因此会浪费空间。MySQL数据库使用Memory存储引擎作为临时表来存放查询的中间结果集，如果中间结果集大于Memory存储引擎表的容量设置，又或者中间结果含有TEXT或BLOB字段，则MySQL会把其转换成MyISAM存储引擎表存放到磁盘中，因为MyISAM不缓存数据文件，所以这时产生的临时表的性能对于查询会有损失。\n3. Archive存储引擎： Archive引擎只支持INSERT和SELECT操作，从MySQL5.1开始支持索引。Archive引擎使用zlib算法将数据行（row）进行压缩后存储，压缩比可达到1：10。正如其名，Archive存储引擎非常适合存储归档数据，如日志信息。通过行锁来实现高并发的插入操作。但是不是事务安全的，目的主要是提供高速的插入和压缩。\n4. Federated存储引擎： Federated存储引擎并不存储数据，他只是指向一台远程MySQL数据库服务器上的表。类似SQL Server的链接服务器和Oracle的透明网关。不同的是，Federated只支持MySQL数据库表，不支持异构数据库表。\n5. Maria存储引擎： Maria当初是为了取代原有的MyISAM而设计的，从而成为MySQL默认存储引擎。支持缓存数据和索引文件，应用了行锁设计，提供了MVCC功能，支持事务和非事务安全的选项，以及更好的BLOB字符类型的处理性能。\n\n\n### 4. 其它\n1. 查看当前使用MySQL版本支持的引擎：\n\n```sql\n\nshow engines\\G;\n\n```\n\n## 3. 连接MySQL\n\n### 1. TCP/IP\n\n```bash\n\nmysql -h 192.168.0.101 -u root -p\n\n```\n\n通过TCP/IP连接到数据库实例的时候，MySQL数据库会先检查一张权限视图，用来判断此请求是否允许连接。该视图在MySQL架构下，表名为user。\n\n```sql\n\nuse mysql;\nselect host, user, password from user;\n\n```\n\n### 2. 命名管道和共享内存\n\n如果在MySQL服务器本机连接，可以通过命名管道，但是需要MySQL数据库在配置文件中启用`--enable-named-pipe`选项。在MySQL 4.1之后，还提供了共享内存的连接方式，需要在配置文件中添加`--shared-memory`实现，在连接时，MySQL客户端还需要使用`--protocol=memory`选项。\n\n### 3. UNIX域套接字\n\n在Linux/UNIX环境下，可以使用UNIX域套接字。UNIX域套接字并不是一个网络协议，所以只能在MySQL客户端和数据库实例在一台服务器上时使用。用户可以在配置文件中执行套接字文件的路径。如`--socket=/tmp/mysql.sock`。可以通过命令`show variables like 'socket';`来查找套接字文件。知道了套接字文件的路径后，就可以通过下面的命令连接了：\n\n```bash\n\nmysql -u root -S /tmp/mysql.sock\n\n```\n\n# 第二章 InnoDB存储引擎\n\n## 1. InnoDB存储引擎概述\n\nInnoDB存储引擎是第一个完整支持ACID事务的MySQL存储引擎，其特点是行锁设计、支持MVCC、支持外键、提供一致性非锁定读，同时被设计用来最有效地利用以及使用内存和CPU。\n\n## 2. InnoDB存储引擎的版本\n\n早期InnoDB随MySQL数据库的更新而更新，从MySQL5.1开始，MySQL允许存储引擎开发商以动态方式加载引擎，这样存储引擎可以不受MySQL数据库版本的限制。\n\n## 3. InnoDB体系架构\n\n### 1. 后台线程\n\nInnoDB存储引擎是多线程的模型，后台有多个不同的线程，负责处理不同的任务。\n\n1. Master Thread： 这是一个非常核心的后台线程，主要负责将缓冲池中的数据异步刷新到磁盘，保证数据一致性，包括脏页的刷新、合并插入缓存（INSERT BUFFER）、UNDO页的回收等。\n2. IO Thread： 在InnoDB存储引擎中大量的使用了AIO（Async IO）来处理写IO请求，这样极大地提高了数据库的性能。IO Thread主要负责这些IO请求的回调（call back）处理。InnoDB 1.0之前共有4个IO Thread，分别是write、read、insert buffer和log IO Thread。在Linux平台下，IO Thread的数量不能进行调整，但是在Windows平台下，可以通过参数`innodb_file_io_threads`来增大IO Thread。从InnoDB 1.0.x开始，read thread和write thread分别增大到4个，并且不再使用`innodb_file_io_threads`参数，而是分别使用`innodb_read_io_threads`和`innodb_write_io_threads`参数进行设置。\n\n```sql\n\n#查看innodb引擎版本\nshow variables like 'innodb_version'\\G;\n\n#output\n*************************** 1. row ***************************\nVariable_name: innodb_version\n        Value: 8.0.22\n1 row in set (1.18 sec)\n\n\n#查看innodb读写IO线程\nshow variables like 'innodb_%io_threads'\\G;\n\n#output\n*************************** 1. row ***************************\nVariable_name: innodb_read_io_threads\n        Value: 4\n*************************** 2. row ***************************\nVariable_name: innodb_write_io_threads\n        Value: 4\n2 rows in set (0.00 sec)\n\n\n#查看InnoDB中的IO Threads\nshow engine innodb status\\G;\n\n#output\n...\n--------\nFILE I/O\n--------\nI/O thread 0 state: waiting for completed aio requests (insert buffer thread)\nI/O thread 1 state: waiting for completed aio requests (log thread)\nI/O thread 2 state: waiting for completed aio requests (read thread)\nI/O thread 3 state: waiting for completed aio requests (read thread)\nI/O thread 4 state: waiting for completed aio requests (read thread)\nI/O thread 5 state: waiting for completed aio requests (read thread)\nI/O thread 6 state: waiting for completed aio requests (write thread)\nI/O thread 7 state: waiting for completed aio requests (write thread)\nI/O thread 8 state: waiting for completed aio requests (write thread)\nI/O thread 9 state: waiting for completed aio requests (write thread)\n...\n\n```\n\n3. Purge Thread: 事务被提交后，其所使用的undolog可能不再需要，因此需要Purge Thread来回收已经使用并分配的undo页。在InnoDB1.1之前，purge操作仅在Master Thread中完成。而从InnoDB1.1版本开始，purge操作可以独立到单独的线程中进行，以此来减轻Master Thread的工作，从而提高CPU的使用率以及提升存储引擎的性能。用户可以在配置文件中添加配置来启用独立的Purge Thread（见下面的代码），在InnoDB1.1中，即使将purge线程数设置大于1，启动时也会将其设置为1，从1.2版本开始，InnoDB开始支持多个Purge Thread，这样可以加快undo页的回收，由于Purge Thread需要离散的随机读取undo页，这样也能进一步利用磁盘的随机读取性能。\n\n```conf\n\n[mysqld]\ninnodb_purge_threads=1\n\n```\n\n4. Page Cleaner Thread: InnoDB 1.2.x引入，作用是将之前版本中的脏页的刷新操作都放入到单独的线程中来完成。目的是减轻Master Thread的工作，以及用户查询线程的阻塞，进一步提高InnoDB存储引擎的性能。\n\n### 2. 内存\n\n#### 1. 缓冲池\n\nInnoDB存储引擎是基于磁盘存储的，并将其中的记录按照页的方式进行管理。因此可以将其视为基于磁盘的数据库系统（Disk-base Database）。CPU速度与磁盘速度差距很大，基于磁盘的数据库系统通常采用缓冲池技术来提高数据库的整体性能。\n\n缓冲池就是一块内存区域，通过内存的速度来弥补磁盘速度对数据库性能的影响。\n\n1. 数据库操作时，缓冲池的使用\n   - 当数据库进行读取页当操作当时候，首先将从磁盘读到当页缓存在缓冲池中，这个过程称为将页“FIX”在缓冲池中。下一次读取相同的页的时候，首先判断该页是否在缓冲池中，如果在，称该页在缓冲池中被命中，直接读取该页，否则读取磁盘上的页。\n   - 对于数据库中页的修改操作，首先修改在缓冲池中的页，然后再以一定的频率刷新到磁盘上，这里要注意，页从缓冲池刷新回磁盘的操作并不是在每次页发生更新时触发，而是通过一种成为`Checkpoint`的机制刷新回磁盘。这样也提高了数据库的整体性能。\n\n2. 缓冲池的大小： 缓冲池的大小直接影响着数据库的整体性能\n   1. 系统限制：32位操作系统的限制，最多将该值设置为3G。用户可以打开操作系统的PAE选项来获得32位系统下最大64GB内存的支持。\n   2. 强烈建议采用64位操作系统，让数据库使用更多的内存。\n   3. 对于InnoDB来说，缓冲池配置通过参数`innodb_buffer_pool_size`来设置\n\n3. 缓冲池的类型： 索引页、数据页、undo页、插入缓冲（insert buffer）、自适应哈希索引（adaptive hash index）、InnoDB存储的锁信息（lock info）、数据字典信息（data dictionary）等。从InnoDB 1.0.x开始，允许有多个缓冲池实例。每个页根据哈希值平均分配到不同到缓冲池实例中，增加了数据库的并发处理能力。可以通过参数`innodb_buffer_pool_instances`来进行配置，默认为1。\n\n#### 2. LRU List、Free List和Flush List\n\n1. LRU List\n   - 数据库中的缓冲池是通过LRU（Last Recent Used，最近最少使用）算法来进行管理的。即最频繁使用的页在LRU列表的前端，而最少使用的页在LRU列表的尾端。当缓冲池不能存放新读取到的页时，将首先释放LRU列表中尾端的页。\n   - InnoDB对LRU算法做了一些优化，在LRU列表中加入了midpoint位置。新读取到到页，虽然是最新访问到数据，但是也不会直接放到LRU列表到首部，而是放到midpoint的位置。这个算法在InnoDB存储引擎下称为`midpoint insertion strategy`。在默认配置下，midpoint在LRU列表长度的5/8处，也就是LRU列表尾端的3/8（37%）的位置。midpoint位置可以由参数`innodb_old_blocks_pct`控制。在InnoDB中，把midpoint之后的列表称为old列表，之前的列表称为new列表。可以简单的理解为new列表中的页都是做活跃的热点数据。\n   - 为什么不用最常见的LRU算法（新数据直接放到首部）？这是因为某些SQL结果集可能超大，可能回将整个LRU列表中的数据刷出，导致真正的热点数据也被清除。加入midpoint可以保护热点数据。\n   - InnoDB还有另一个参数`innodb_old_blocks_time`（以毫秒为单位）用于表示页读到mid位置的后需要等待多久才会被加入到LRU列表的热端。页插入到mid位置后的`innodb_old_blocks_time`时间内，可以通过LRU列表访问页，但是无论多少次查询都不会将其移动到new列表，`innodb_old_blocks_time`时间后，如果再次被访问，就会被移动到new列表。\n\n```sql\n\n#为了LRU列表中的热点数据不被刷出啊，可以先设置innodb_old_blocks_time\n\nmysql> SET GLOBAL innodb_old_blocks_time=1000;\nQuery OK, 0 rows affected.\n\n# data or index scan operation\n......\n\nmysql> SET GLOBAL innodb_old_blocks_time=0;\nQuery OK, 0 rows affected.\n\n```\n\n如果用户预估自己活跃的热点数据不止63%，那么再执行SQL语句前可以通过下面的语句来减少热点页被刷出的概率。\n\n```sql\nmysql> SET GLOBAL innodb_old_blocks_pct=20;\nQuery OK, 0 rows affected.\n```\n\n\n2. Free List\n\nLRU列表是用来管理管理已经读取到的页的，但是当数据库刚启动时，LRU列表是空的，即没有任何的页，这时页都存放于Free列表中。当需要从缓冲池中分页时，首先从Free列表中查找到是否可用的空闲页，若有则将该页从Free列表中删除，放入到LRU列表中。否则，根据LRU算法，淘汰LRU列表末尾的页，将该内存空间分配给新的页。\n\n        这里感觉有点难理解，数据库刚启动的时候，缓冲池里是没有缓存数据的，但是相应的内存空间已经开辟了，当我们查询数据后，磁盘返回数据，这时候，缓冲池要缓存数据，LRU列表是空的，要去Free List里取出空闲页，这里的空闲页其实是一个没有存储数据的页的描述（或者说地址），然后将磁盘返回的数据缓存到这个页，并将这个页交由LRU列表管理。也就是FreeList就是记录空闲页描述的双向列表，当LRU列表需要一个新的页的时候，就来找Free列表要，然后新的数据就被缓存了。\n\n- 这里感觉上LRU列表管理已经读取到的页，Free列表管理未使用的页，他们的size的和就应该是缓冲池里所有页的数量了。但是通过`SHOW ENGINE INNODB STATUS`可以看到，free buffers（Free列表页数量）和Database pages（LRU列表中页的数量）之和并不是缓冲池页的总数（Buffer pool size）。这是因为缓冲池中的页可能会被分配给自适应哈希索引、Lock信息、Insert Buffer等页，而这部分页不需要LRU算法进行维护，因此不在LRU列表中。\n- 从InnoDB1.2版本开始，还可以通过`INNODB_BUFFER_POOL_STATUS`来观察缓冲池的运行状态。\n   ```sql\n        select pool_id, hit_rate, pages_made_young, pages_not_made_young from information_schema.INNODB_BUFFER_POOL_STATUS;\n   ```\n- 可以通过`INNODB_BUFFER_PAGE_LRU`来观察每个LRU列表中每个页的具体信息，例如通过下面的语句可以看到缓冲池LRU列表中SPACE为1的表的页类型：\n    ```sql\n        select table_name, space, page_number, page_type from innodb_buffer_page_lru where space = 1;\n    ```\n- InnoDB存储引擎从1.0.x版本开始支持压缩页的功能，即将原本16k的页压缩为1kb、2kb、4kb和8kb。而由于页的大小发生了变化，LRU列表也有了些许的改动。对于非16kb的页，是通过unzip_LRU列表来进行管理的。通过命令`SHOW ENGINE INNODB STATUS\\G;`可以看到LRU列表和unzip_LRU列表的页的数量。LRU中的页包含了unzip_LRU列表中的页。\n- unzip_LRU列表中对不同压缩页大小的页进行分别管理，并通过`伙伴算法`进行内存的分配。以需要从缓冲池中申请页为4kb的大小为例，其过程如下：\n  \n   1. 检查4kb的unzip_LRU列表，检查是否有可用的空闲页；\n   2. 如果有，则直接使用；\n   3. 否则，检查8kb的unzip_LRU列表；\n   4. 如果能够得到空闲页，将页分成2个4KB页，存放到4KB的unzip_LRU列表；\n   5. 如果不能得到空闲页，从LRU列表中申请一个16KB的页，将页分为1个8KB的页、2个4KB的页，分别存放到对应的unzip_LRU列表中。\n\n   可以通过information_schema架构下的表INNODB_BUFFER_PAGE_LRU来观察unzip_LRU列表中的页\n\n   ```sql\n      select table_name, space, page_number, compressed_size from innodb_buffer_page_lru where compressed_size <> 0;\n   ```\n\n   ```\n   伙伴算法，简而言之，就是将内存分成若干块，然后尽可能以最适合的方式满足程序内存需求的一种内存管理算法，伙伴算法的一大优势是它能够完全避免外部碎片的产生。什么是外部碎片以及内部碎片，前面博文slab分配器后面已有介绍。申请时，伙伴算法会给程序分配一个较大的内存空间，即保证所有大块内存都能得到满足。很明显分配比需求还大的内存空间，会产生内部碎片。所以伙伴算法虽然能够完全避免外部碎片的产生，但这恰恰是以产生内部碎片为代价的。\n   ```\n3. Flush List\n- 在LRU列表中的页被修改后，称该页为脏页（dirty page），即缓冲池中的页和磁盘上的页的数据产生了不一致。这时数据库会通过`checkpoint`机制将脏页刷新回磁盘，而Flush列表中的页即为`脏页列表`。需要注意的是，脏页既存在于LRU列表，也存在于Flush列表中。LRU列表用于来管理缓冲池中也的可用性，Flush列表用来管理将页刷回磁盘，二者互不影响。\n- 同LRU列表一样，Flush列表也能通过`SHOW ENGINE INNODB STATUS`来查看，`Modified db pages 24673`就显示了脏页的数量。\n- 查看脏页的数量和类型（table_name为null说明该页属于系统表空间）：\n   ```sql\n      select table_name, space, page_number, page_type \n      from innodb_buffer_page_lru where oldest_modification > 0;\n   ```\n\n### 3. 重做日志缓冲\n\n重做日志缓冲（redo log buffer）。InnoDB存储引擎首先将重做日志信息放入到这个缓冲区，然后按照一定频率将其刷新到重做日志文件。重做日志缓冲不一定要设置的很大，因为一般情况下每一秒会将重做日志缓存刷新到日志文件，因此只需要保证每秒产生的事务量在在这个缓存大小之内即可。该值由配置参数`innodb_log_buffer_size`控制，默认为8M：\n\n```sql\nmysql> show variables like 'innodb_log_buffer_size'\\G;\n*************************** 1. row ***************************\nVariable_name: innodb_log_buffer_size\n        Value: 16777216\n1 row in set (0.00 sec)\n```\n\n重做日志在下面三种情况下会将重做日志缓冲中的内容刷新到外部磁盘的重做日志文件中：\n\n- Master Thread每一秒将重做日志缓冲刷新到重做日志文件；\n- 每个事务提交时会将重做日志缓存刷新到重做日志文件；\n- 当重做日志缓冲池剩余空间小于1/2时，重做日志缓冲会刷新到缓存日志文件。\n\n### 4. 额外的内存池\n\n在InnoDB中，对内存的管理是通过一种称为内存堆（heap）的方式进行的。在对一些数据结构本身的内存进行分配时，需要从额外的内存池中进行申请，当该区域的内存不够时，会从缓冲池中进行申请。这里的数据结构本身是指每个缓冲池中的帧缓存（frame buffer）和对应的缓冲控制对象（buffer control block），这些对象记录了一些诸如LRU、锁、等待等信息，而这些对象的内存需要从额外的内存池中申请。<strong>因此在申请了很大的InnoDB缓冲池时，应该考虑相应的增加这个值</strong>。\n\n## 4. Checkpoint技术\n\nMysql缓冲池的设计就是为了跨越cpu速度与磁盘速度之间鸿沟，也就是页的操作都是首先在缓冲池中完成，操作完成时，缓冲池的数据版本比磁盘新，数据库需要将新版本的页刷新到磁盘。但是刷新到磁盘，瓶颈依然在磁盘IO，而且如果在缓存刷新到磁盘的过程中宕机，缓存中的数据时不能恢复的。所以当前事务数据库都普遍采用了`Write Ahead Log`策略，即当事务提交时，先写重做日志，在修改页。当由于宕机而导致数据丢失时，可以通过重做日志来完成数据的恢复。这也是事务ACID中D（Durability持久性）的要求。\n\n思考一下，缓冲池可以让我们读写数据更快速，重做日志可以保证数据库数据不丢失。有了缓冲池和重做日志，是不是就可以不用将缓冲池中的页刷新到磁盘了？好家伙，直接内存数据库了？毕竟mysql是要持久化的，是要存大量数据的。你一直不落磁盘，先不说内存够不够大，就是重新启动时重新应用重做日志的时间也够受的。所以mysql有个Checkpoint（检查点）技术。\n\n### 1. Checkout技术用于解决以下问题：\n\n- 缩短数据库的恢复时间\n- 缓冲池不够用时，将脏页刷新到磁盘\n- 重做日志不可用时，刷新脏页。\n\n1. 当数据库发生宕机时，数据库不需要重做所有日志，因为Checkpoint之前的页都已经刷新回磁盘了，所以只需要对Checkpoint后的重做日志进行恢复。这样就大大缩短了恢复的时间。\n2. 当缓冲池不够用时，根据LRU算法会溢出最近使用最少的页，若此页为脏页，那么需要强制执行Checkpoint，将脏页刷新到磁盘。\n3. 重做日志出现不可用的情况时因为当前事务数据库系统对重做日志的设计都是循环使用的，并不是无限增大的。重做日志可以被重用的部分是指这些重做日志已经不再需要，即当数据库发生宕机时，数据库恢复操作不需要这部分重做日志。因此这部分就可以被覆盖重用。若此时重做日志还需要使用，那么必须强制产生Checkpoint，将缓冲区中的页至少刷新到当前重做日志的位置。\n\n### 2. LSN（Log Sequece Number）\n\nInnoDB存储引擎是通过LSN来标记版本的。LSN是8字节的数字，单位是字节。每个页有LSN，重做日志中也有LSN，Checkpoint也有LSN。可以通过`SHOW ENGINE INNODB STATUS`来观察：\n\n```sql\nmysql> SHOW ENGINE INNODB STATUS\\G;\n\n......\n---\nLOG\n---\nLog sequence number 92561351052\nLog flushed up to 92561351052\nLast checkpoint at 92561351052\n```\n\n### 3. InnoDB中有两种Checkpoint\n\n#### 1. Sharp Checkpoint\n\nSharp Checkpoint发生在数据库关闭时将所有的脏页刷新回磁盘，这是默认的工作方式，即参数`innodb_fast_shutdown=1`。因为它时将所有的脏页都刷回磁盘，所以不可能在数据库运行时来执行，太影响性能。\n\n#### 2. Fuzzy Checkpoint\n\nInnoDB存储引擎内部使用Fuzzy Checkpoint进行页的刷新，即只刷新一部分脏页，而不是刷新所有的脏页到磁盘。\n\n在InnoDB中可能发生如下几种情况的Fuzzy Checkpoint：\n\n1. Master Thread Checkpoint\n\n   Master Thread Checkpoint以每秒或每十秒的速度从缓冲池的脏页列表中刷新一定比例的页回磁盘，这个过程是异步的，不会阻塞用户查询线程。\n\n2. FLUSH_LRU_LIST Checkporint\n\n   InnoDB存储引擎需要保证LRU列表中需要有差不多100个空闲页可供使用。InnoDB1.1.x版本之前，需要检查LRU是否有足够的可用空间操作发生在用户查询线程，这就会阻塞用户的查询操作。如果没有100个可用的空闲页，那么InnoDB存储引擎会将LRU列表尾端的页移除。如果这些页有脏页，那么就要进行Checkpoint。从MySQL5.6版本，也就是InnoDB1.2.x开始，这个检查被放在了一个单独的Page Cleaner线程中进行，并且用户可以通过参数innodb_lru_scan_depth控制LRU列表中可用页的数量，该值默认为1024。\n\n3. Async/Sync Flush Checkpoint\n\n   这里是在重做日志文件不可用时，需要强制将一些页刷回磁盘，而此时脏页是从脏页列表中选取的。若已经写入到重做日志的LSN极为redo_lsn，将已经刷新回磁盘最新页的LSN记为checkpoint_lsn，则可定义:\n\n   `checkpoint_age = redo_lsn - checkpoint_lsn`\n\n   再定义一下变量：\n\n   `async_water_mark = 75% * total_redo_log_file_size`\n\n   `sync_water_mark = 90% * total_redo_log_file_size`\n\n   如果每个重做日志文件大小为1GB，并且定义了两个重做日志文件，则重做日志文件的总大小为2GB，那么`async_water_mark`=1.5GB，`sync_water_mark`=1.8GB。\n\n   那么：\n\n   - 当checkpoint_age < async_water_mark时，不需要刷新任何脏页到磁盘。\n   - 当async_water_mark < checkpoint_age < sync_water_mark时，触发Async Flush，从Flush列表中刷新足够的脏页回磁盘，是的刷新后满足checkpoint_age<async_water_mark。\n   - checkpoint_age > sync_water_mark这种情况很少发生，除非设置的重做日志文件太小，并且在进行类似LOAD DATA的BULK INSERT操作。此时出发Sync Flush操作，从Flush列表中刷新足够的脏页回磁盘，使得刷新后满足checkpoint_age < async_water_mark。\n\n   可见Async/Sync Flush Checkpoint是为了保证重做日志的循环使用的可用性。InnoDB 1.2.x之前，Async会阻塞发现问题的用户查询线程，而Sync会阻塞所有用户的查询线程。但是后来，这部分的刷新操作同样放入了单独的Page Clener Thread中，不会阻塞用户查询线程。\n\n4. Dirty Page too much Checkpoint\n\n   这种情况就是脏页数量太多，导致InnoDB存储引擎强制进行Checkpoint。目的还是保证缓冲池中有足够可用的页。其可由参数`innodb_max_dirty_pages_pct`来控制。百分比，默认时75（老版本InnoDB是90），表示当缓冲池中脏页的数量占据75%时，强制进行checkpoint，刷新一部分的页到磁盘。\n\n\n## 5. Master Thread工作方式\n\nInnoDB存储引擎的主要工作都是在一个单独的后台线程Master Thread中完成的。\n\n### 1. InnoDB 1.0.x版本之前的Master Thread\n\nMaster Thread具有最高的线程优先级别。其内部由多个循环（loop）组成：主循环（loop）、后台循环（background loop）、刷新循环（flush loop）、暂停循环（suspend loop）。Master Thread会根据数据库运行的状态在loop、background loop、flush loop和suspend loop中进行切换。\n\n绝大多数操作是在这个循环中，其中分为两大部分的操作---每秒钟的操作和每10秒的操作。loop循环是通过thread sleep来实现的，所以所谓的每一秒或者没十秒只是个大概频率，负载很大的情况下可能会有延迟。\n\n每一秒的操作包括：\n\n- 日志缓冲刷新到磁盘，即使这个事务还没有提交（总是）：所以再大的事务提交（commit）的时间也是很短。\n- 合并插入缓冲（可能）：并不是每秒都发生，InnoDB会判断前一秒内发生的IO次数是否小于5次，小于5次，认为压力很小，可以执行合并插入缓冲操作。\n- 至多刷新100个InnoDB的缓冲池中的脏页到磁盘（可能）：InnoDB判断当前缓冲池中脏页的比例（buf_get_modified_ratio_pct）是否超过了配置文件中innodb_max_dirty_pages_pct参数（默认90，代表90%），如果超过了，就要作磁盘同步操作，将100个脏页写入磁盘中。\n- 如果当前没有用户活动，则切换到background loop（可能）\n\n每十秒的操作：\n\n- 刷新100个脏页到磁盘（可能）：InnoDB判断过去10秒内磁盘IO操作是否小于200次，如果是，认为当前有足够的磁盘IO操作能力，则将100个脏页刷新到磁盘\n\n- 合并至多5个插入缓冲（总是）\n\n- 将日志缓冲刷新到磁盘（总是）\n\n- 删除无用的Undo页（总是）：执行full purge操作，删除无用的Undo页，对表进行的update、delete操作，原先的行被标记为删除，但是因为一致性读（consistent read）的关系，要保留这些版本的信息，在full purge过程中，InnoDB会判断当前事务系统中已被删除的行是否可以删除（有时候可能还有查询操作需要读取之前版本的undo信息），如果可以删除，则删除。full purge操作，每次最多尝试回收20个undo页。\n\n- 刷新100个或者10个脏页到磁盘（总是）：InnoDB判断缓冲池中脏页的比例（buf_get_modified_ratio_pct），如果有超过70%的脏页，则刷新100个脏页到磁盘，如果脏页的比例小于70%，则只刷新10%的脏页到磁盘。\n\n  \n\nbackground loop的操作：\n\n- 删除无用的Undo页（总是）\n- 合并20个插入缓冲（总是）\n- 跳回到主循环（总是）\n- 不断刷新100个页直到符合条件（可能，跳转到flush loop中完成）\n\n如果flush loop中也没有什么事情可以作了，InnoDB存储引擎会切换到suspend loop，将Master Thread挂起，等待事件的发生。如果用户启用（enable）了InnoDB存储引擎，却没有使用任何InnoDB存储引擎的表，那么Master Thread总是处于挂起的状态。\n\nMaster Thread伪代码如下：\n\n```c\nvoid master_thread() {\n\tgoto loop;\n    loop:\n    \tfor(int i = 0; i < 10; i++) {\n            thread_sleep(1) // sleep 1 second\n            do log buffer flush to disk\n            if (last_one_second_ios < 5) {\n                do merge at most 5 insert buffer\n            }\n            if (buf_get_mondified_ratio_pct > innodb_max_dirty_pages_pct) {\n                do buffer pool flush 100 dirty page\n            }\n            if (no user activity) {\n                goto background loop\n            }\n        }\n    if (last_ten_second_ios < 200) {\n        do buffer pool flush 100 dirty page\n    }\n    do merge at most 5 insert buffer\n    do log buffer flush to disk\n    do full purge\n    if (buf_get_modified_ratio_pct > 70%) {\n        do buffer pool flush 100 dirty page\n    } else {\n        buffer pool flush 10 dirty page\n    }\n    goto loop\n    background loop:\n    \tdo full purge\n        do merge 20 insert buffer\n        if not idle:\n    \t\tgoto loop\n        else\n            goto flush loop\n    flush loop:\n    \tdo buffer pool flush 100 dirty page\n        if (buf_get_modified_radio_pct > innodb_max_dirty_pages_pct) {\n            goto flush loop\n        }\n    goto suspend loop\n    suspend loop:\n    \tsuspend_thread()\n        waiting event\n        \tgoto loop\n}\n```\n\n### 2. InnoDB 1.2.x版本之前的Master Thread\n\n几个修改：\n\n1. 1.0.x之前的版本其实对IO是有限制的（很多硬编码，比如刷新100个脏页到磁盘），在磁盘技术飞速发展的今天，当固态磁盘（SSD）出现时，这种规定在很大程度上限制了InnoDB存储引擎对磁盘IO的性能，尤其是写入性能。\n从InnoDB1.0.x，InnoDB Plugin提供了参数innodb_io_capacity，用来表示磁盘IO的吞吐量，默认值为200，当用户使用了ssd或者磁盘做了RAID，存储设备拥有了更高的IO速度，就可以将innodb_io_capacity调高，直到符合磁盘IO吞吐量。规则如下：\n\n   - 在合并插入缓存时，合并插入缓存的数量为innodb_io_capacity值的5%\n   - 在从缓冲区刷新脏页时，刷新脏页的数量为innodb_io_capacity\n\n2. `innodb_max_dirty_pages_pct`默认值的问题，在1.0.x版本之前，该值的默认为90，意味着脏页占缓冲池的90%。因为InnoDB存储引擎在每秒刷新缓冲池和flush loop时会判断这个值，如果该值大于`innodb_max_dirty_pages_pct`才刷新100个脏页，如果有很大的内存，或者数据库服务的压力很大，这时刷新脏页的速度反而会降低，同样，数据库在恢复阶段可能需要更多的时间。1.0.x后`innodb_max_diry_pages_pct`默认值变为了75，这样既可以加快刷新脏页的频率，又能保证磁盘IO的负载。\n3. 新增参数`innodb_adaptive_flushing`，自适应刷新，该值影响每秒刷新脏页的数量。原来的规则时：脏页在缓冲池所占比例小于`innodb_max_diry_pages_pct`时，不刷新脏页；大于`innodb_max_diry_pages_pct`时，刷新100个脏页。随着`innodb_adaptive_flushing`的引入，InnoDB存储引擎会通过一个名为`buf_flush_get_desired_flush_rate`的函数来判断需要刷新脏页的最合适的数量。`buf_flush_get_desired_flush_rate`通过判断产生重做日志（redo log）的速度来决定最合适的刷新脏页的数量。因此当脏页的比例小于`innodb_max_diry_pages_pct`时，也会刷新一定数量的脏页。\n4. 之前每次进行full purge操作时，最多回收20个Undo页，从InnoDB1.0.x开始引入了参数`innodb_purge_batch_size`，该参数可以控制每次full purge回收的undu页的数量。该参数的默认值为20，并可以动态的对其进行修改。\n   ```\n      mysql> show variables like 'innodb_purge_batch_size'\\G;\n      Variable_name: innodb_purge_batch_size\n      Value: 20\n      mysql> set global innodb_purge_batch_size=50;\n      Query OK, 0 rows affected (0.00 sec)\n   ```\n\n综上，1.0.x版本开始，Master Thread伪代码如下：\n\n```c\nvoid master_thread() {\n   goto loop;\nloop:\nfor(int i=0; i<10; i++) {\n   thread_sleep(1) //sleep 1 second\n   do log buffer flush to disk\n   if(last_one_second_ios < 5% innodb_io_capacity)\n      do merge 5% innodb_io_capacity insert buffer\n   if(buf_get_modified_ratio_pct > innodb_max_dirty_pages_pct) {\n      do buffer pool flush 100% innodb_io_capacity dirty page\n   } else if enable adaptive flush {\n      do buffer pool flush desired amount dirty page\n   }\n   if(no user activity)\n      goto background loop\n}\nif (last_ten_second_ios < innodb_io_capacity)\n   do buffer pool flush 100% innodb_io_capacity dirty page\ndo merge 5% innodb_io_capacity insert buffer\ndo log buffer flush to disk\ndo full purge\nif(buf_get_modified_ratio_pct > 70%)\n   do buffer pool flush 100% innodb_io_capacity dirty page\nelse\n   do buffer pool flush 10% innodb_io_capacity dirty page\ngoto loop\nbackground loop:\ndo full purge\ndo merge 100% innodb_io_capacity insert buffer\nif not idle:\ngoto loop:\nelse:\n   goto flush loop\nflush loop:\ndo buffer pool flush 100% innodb_io_capacity dirty page\nif(buf_get_modified_ratio_pct > innodb_max_dirty_pages_pct)\n   go to flush loop\n   goto suspend loop\nsuspend loop:\nsuspend_thread()\nwaiting event\ngoto loop;\n}\n```\n\n### 3. InnoDB 1.2.x版本的Master Thread\n\n在InnoDB1.2.x版本中再次对Master Thread进行了优化，由此可以看出Master Thread对性能所起到的关键作用。在1.2.x版本中，Master Thread的伪代码如下：\n```c\nif InnoDB is idle\n   srv_master_do_idle_tasks();\nelse\n   srv_master_do_active_tasks();\n```\n\n其中`srv_master_do_idle_tasks()`就是之前版本中的每10秒的操作，`srv_master_do_active_tasks()`处理的是之前每秒中的操作。同时对于刷新脏页的操作，从Master Thread线程分离到一个单独的Page Cleaner Thread，从而减轻了Master Thread的工作，同时进一步提高了系统的并发性。\n\n## 6. InnoDB关键特性\n\nInnoDB的关键特性包括：\n- 插入缓冲（Insert Buffer）\n- 两次写（Double Write）\n- 自适应哈希索引（Adaptive Hash Index）\n- 异步IO（Async IO）\n- 刷新邻接页（Flush Neighbor Page）","slug":"kongzheng1993-MySQL技术内幕读书笔记","published":1,"updated":"2023-03-08T07:05:58.808Z","layout":"post","photos":[],"link":"","_id":"clg0k2aui00jnt26f0dgd6e3s","content":"<p>由于对MySQL的了解不够透彻，虽然用起来没问题，也知道一些常见的知识点，但是一直把它当作一个黑盒来使用，不免有些心里没底，所以下定决心，通过<strong>姜承尧</strong>大佬的书<a href=\"https://book.douban.com/subject/24708143/\" target=\"_blank\" rel=\"noopener\">MySQL技术内幕</a>，认真了解MySQL技术细节。我会将一些我认为重要的知识，记录在这篇博客中，希望看到这篇文章的你，也能有所收获。</p>\n<h1 id=\"第一章-MySQL体系结构和存储引擎\"><a href=\"#第一章-MySQL体系结构和存储引擎\" class=\"headerlink\" title=\"第一章 MySQL体系结构和存储引擎\"></a>第一章 MySQL体系结构和存储引擎</h1><h2 id=\"1-Mysql体系结构\"><a href=\"#1-Mysql体系结构\" class=\"headerlink\" title=\"1. Mysql体系结构\"></a>1. Mysql体系结构</h2><ol>\n<li>数据库是文件的集合，是依照某种数据模型组织起来并存放于二级存储器中的数据集合；数据库实例是程序，是位于用户与操作系统之间的一层数据管理软件，用户对数据库数据的任何操作，包括数据库定义、数据查询、数据维护、数据库运行控制等都是在数据库实例下进行的，应用程序只有通过数据库实例才能和数据库打交道。</li>\n<li>MySQL由以下几个部分组成：<ul>\n<li>连接池组件</li>\n<li>管理服务和工具组件</li>\n<li>SQL接口组件</li>\n<li>查询分析器组件</li>\n<li>优化器组件</li>\n<li>缓存（cache）组件</li>\n<li>插件式存储引擎</li>\n<li>物理文件</li>\n</ul>\n</li>\n<li>MySQL区别于其他数据库的最重要的一个特点就是它的插件式的表存储引擎。</li>\n<li>存储引擎是基于表的，而不是数据库。</li>\n</ol>\n<h2 id=\"2-MySQL存储引擎\"><a href=\"#2-MySQL存储引擎\" class=\"headerlink\" title=\"2. MySQL存储引擎\"></a>2. MySQL存储引擎</h2><ol>\n<li>MySQL是开源的，用户可以基于MySQL预定义的存储引擎接口编写自己的存储引擎。当然也可以通过修改某一存储引擎的源码来得到想要的特性。</li>\n<li>InnoDB存储引擎最早是第三方存储引擎，后来被Oracle收购。</li>\n</ol>\n<h3 id=\"1-InnoDB存储引擎\"><a href=\"#1-InnoDB存储引擎\" class=\"headerlink\" title=\"1. InnoDB存储引擎\"></a>1. InnoDB存储引擎</h3><ol>\n<li>InnoDB存储引擎支持事务。其设计目标主要面向在线事务处理（OLTP）的应用。其特点是：行锁设计、支持外键，并支持类似Oracle的非锁定读，即默认读取操作不会产生锁。</li>\n<li>从5.5.8版本开始，InnoDB是MySQL默认的存储引擎。</li>\n<li>InnoDB存储引擎将数据放在一个逻辑的表空间中。表空间由InnoDB自身进行管理。从MySQL4.1开始，它可以将每个InnoDB存储引擎的表单独存放到一个独立的ibd文件中。InnoDB支持用裸设备（raw disk）建立表空间。<strong>裸设备：裸设备(raw device)，也叫裸分区（原始分区），是一种没有经过格式化，不被Unix通过文件系统来读取的特殊块设备文件。由应用程序负责对它进行读写操作。不经过文件系统的缓冲。它是不被操作系统直接管理的设备。这种设备少了操作系统这一层，I/O效率更高。不少数据库都能通过使用裸设备作为存储介质来提高I/O效率。</strong></li>\n<li>InnoDB通过使用多版本并发控制（MVCC）来获得高并发性，并实现了SQL的4种隔离级别，默认Repeatable级别。</li>\n<li>InnoDB使用一种next-key locking的策略来避免幻读的产生。</li>\n<li>InnoDB提供了插入缓存（insert buffer）、二次写（double write）、自适应哈希索引（adaptive hash index）、预读（read ahead）等高性能和高可用功能。</li>\n<li>InnoDB表存储数据采用了聚集（clustered）的方式，因此每张表的存储都是按照主键的顺序进行存放。如果没有显式地定义主键，InnoDB会为每一行数据生成一个6字节的ROWID，并以此作为主键。</li>\n</ol>\n<h3 id=\"2-MyISAM存储引擎\"><a href=\"#2-MyISAM存储引擎\" class=\"headerlink\" title=\"2. MyISAM存储引擎\"></a>2. MyISAM存储引擎</h3><ol>\n<li>MyISAM存储引擎不支持事务、锁表设计，支持全文索引，主要面向一些OLAP数据库应用。</li>\n<li>MySQL5.5.8之前默认存储引擎是MyISAM（Windows版本除外）。</li>\n<li>MyISAM存储引擎的缓冲池只缓存索引文件，而不缓存数据文件。这点和大多数数据库都不同。</li>\n<li>MyISAM存储引擎表由MYD和MYI组成，MYD用来存放数据文件，MYI用来存放索引文件。</li>\n<li>MySQL5.0之前MyISAM默认支持的表大小是4G，如果需要更大的MyISAM表的话，就要制定MAX_ROWS和AVG_ROW_LENGTH属性。从5.0版本开始，MyISAM默认支持256TB的单表数据，这足够一般应用的需求。</li>\n<li>MyISAM存储引擎表，Mysql数据库只缓存其索引文件，数据文件的缓存交给操作系统本身完成，这与LRU算法缓存数据的大部分数据库都不同。MySQL 5.1.23之前，缓存索引的缓冲区最大只能设置为4GB，在之后的版本中，64位系统可以支持大于4GB的索引缓冲区。</li>\n</ol>\n<h3 id=\"3-其他存储引擎\"><a href=\"#3-其他存储引擎\" class=\"headerlink\" title=\"3. 其他存储引擎\"></a>3. 其他存储引擎</h3><ol>\n<li>NDB： 一个集群存储引擎。数据全部放在内存中（从MySQL 5.1之后，可以将非索引数据放在磁盘上），所以主键查找速度极快，通过添加NDB数据存储节点，可以线性的提高数据库性能，是高可用、高性能的集群系统。复杂的连接操作网络开销很大，因为NDB的连接操作（JOIN）是在数据库层完成的，而不是在存储引擎层完成的。</li>\n<li>Memory: 之前被称为HEAP存储引擎。将表中的数据存放在内存中，如果数据库重启或发生崩溃，表中的数据全部消失。非常适合非常适合存储临时数据。默认使用hash哈希索引，而不是B+树索引。只支持表锁，并法性能差，不支持TEXT、BLOB列类型。存储变长字段varchar是按照定长char方式存储的，因此会浪费空间。MySQL数据库使用Memory存储引擎作为临时表来存放查询的中间结果集，如果中间结果集大于Memory存储引擎表的容量设置，又或者中间结果含有TEXT或BLOB字段，则MySQL会把其转换成MyISAM存储引擎表存放到磁盘中，因为MyISAM不缓存数据文件，所以这时产生的临时表的性能对于查询会有损失。</li>\n<li>Archive存储引擎： Archive引擎只支持INSERT和SELECT操作，从MySQL5.1开始支持索引。Archive引擎使用zlib算法将数据行（row）进行压缩后存储，压缩比可达到1：10。正如其名，Archive存储引擎非常适合存储归档数据，如日志信息。通过行锁来实现高并发的插入操作。但是不是事务安全的，目的主要是提供高速的插入和压缩。</li>\n<li>Federated存储引擎： Federated存储引擎并不存储数据，他只是指向一台远程MySQL数据库服务器上的表。类似SQL Server的链接服务器和Oracle的透明网关。不同的是，Federated只支持MySQL数据库表，不支持异构数据库表。</li>\n<li>Maria存储引擎： Maria当初是为了取代原有的MyISAM而设计的，从而成为MySQL默认存储引擎。支持缓存数据和索引文件，应用了行锁设计，提供了MVCC功能，支持事务和非事务安全的选项，以及更好的BLOB字符类型的处理性能。</li>\n</ol>\n<h3 id=\"4-其它\"><a href=\"#4-其它\" class=\"headerlink\" title=\"4. 其它\"></a>4. 其它</h3><ol>\n<li>查看当前使用MySQL版本支持的引擎：</li>\n</ol>\n<pre><code class=\"sql\">\nshow engines\\G;\n</code></pre>\n<h2 id=\"3-连接MySQL\"><a href=\"#3-连接MySQL\" class=\"headerlink\" title=\"3. 连接MySQL\"></a>3. 连接MySQL</h2><h3 id=\"1-TCP-IP\"><a href=\"#1-TCP-IP\" class=\"headerlink\" title=\"1. TCP/IP\"></a>1. TCP/IP</h3><pre><code class=\"bash\">\nmysql -h 192.168.0.101 -u root -p\n</code></pre>\n<p>通过TCP/IP连接到数据库实例的时候，MySQL数据库会先检查一张权限视图，用来判断此请求是否允许连接。该视图在MySQL架构下，表名为user。</p>\n<pre><code class=\"sql\">\nuse mysql;\nselect host, user, password from user;\n</code></pre>\n<h3 id=\"2-命名管道和共享内存\"><a href=\"#2-命名管道和共享内存\" class=\"headerlink\" title=\"2. 命名管道和共享内存\"></a>2. 命名管道和共享内存</h3><p>如果在MySQL服务器本机连接，可以通过命名管道，但是需要MySQL数据库在配置文件中启用<code>--enable-named-pipe</code>选项。在MySQL 4.1之后，还提供了共享内存的连接方式，需要在配置文件中添加<code>--shared-memory</code>实现，在连接时，MySQL客户端还需要使用<code>--protocol=memory</code>选项。</p>\n<h3 id=\"3-UNIX域套接字\"><a href=\"#3-UNIX域套接字\" class=\"headerlink\" title=\"3. UNIX域套接字\"></a>3. UNIX域套接字</h3><p>在Linux/UNIX环境下，可以使用UNIX域套接字。UNIX域套接字并不是一个网络协议，所以只能在MySQL客户端和数据库实例在一台服务器上时使用。用户可以在配置文件中执行套接字文件的路径。如<code>--socket=/tmp/mysql.sock</code>。可以通过命令<code>show variables like &#39;socket&#39;;</code>来查找套接字文件。知道了套接字文件的路径后，就可以通过下面的命令连接了：</p>\n<pre><code class=\"bash\">\nmysql -u root -S /tmp/mysql.sock\n</code></pre>\n<h1 id=\"第二章-InnoDB存储引擎\"><a href=\"#第二章-InnoDB存储引擎\" class=\"headerlink\" title=\"第二章 InnoDB存储引擎\"></a>第二章 InnoDB存储引擎</h1><h2 id=\"1-InnoDB存储引擎概述\"><a href=\"#1-InnoDB存储引擎概述\" class=\"headerlink\" title=\"1. InnoDB存储引擎概述\"></a>1. InnoDB存储引擎概述</h2><p>InnoDB存储引擎是第一个完整支持ACID事务的MySQL存储引擎，其特点是行锁设计、支持MVCC、支持外键、提供一致性非锁定读，同时被设计用来最有效地利用以及使用内存和CPU。</p>\n<h2 id=\"2-InnoDB存储引擎的版本\"><a href=\"#2-InnoDB存储引擎的版本\" class=\"headerlink\" title=\"2. InnoDB存储引擎的版本\"></a>2. InnoDB存储引擎的版本</h2><p>早期InnoDB随MySQL数据库的更新而更新，从MySQL5.1开始，MySQL允许存储引擎开发商以动态方式加载引擎，这样存储引擎可以不受MySQL数据库版本的限制。</p>\n<h2 id=\"3-InnoDB体系架构\"><a href=\"#3-InnoDB体系架构\" class=\"headerlink\" title=\"3. InnoDB体系架构\"></a>3. InnoDB体系架构</h2><h3 id=\"1-后台线程\"><a href=\"#1-后台线程\" class=\"headerlink\" title=\"1. 后台线程\"></a>1. 后台线程</h3><p>InnoDB存储引擎是多线程的模型，后台有多个不同的线程，负责处理不同的任务。</p>\n<ol>\n<li>Master Thread： 这是一个非常核心的后台线程，主要负责将缓冲池中的数据异步刷新到磁盘，保证数据一致性，包括脏页的刷新、合并插入缓存（INSERT BUFFER）、UNDO页的回收等。</li>\n<li>IO Thread： 在InnoDB存储引擎中大量的使用了AIO（Async IO）来处理写IO请求，这样极大地提高了数据库的性能。IO Thread主要负责这些IO请求的回调（call back）处理。InnoDB 1.0之前共有4个IO Thread，分别是write、read、insert buffer和log IO Thread。在Linux平台下，IO Thread的数量不能进行调整，但是在Windows平台下，可以通过参数<code>innodb_file_io_threads</code>来增大IO Thread。从InnoDB 1.0.x开始，read thread和write thread分别增大到4个，并且不再使用<code>innodb_file_io_threads</code>参数，而是分别使用<code>innodb_read_io_threads</code>和<code>innodb_write_io_threads</code>参数进行设置。</li>\n</ol>\n<pre><code class=\"sql\">\n#查看innodb引擎版本\nshow variables like &#39;innodb_version&#39;\\G;\n\n#output\n*************************** 1. row ***************************\nVariable_name: innodb_version\n        Value: 8.0.22\n1 row in set (1.18 sec)\n\n\n#查看innodb读写IO线程\nshow variables like &#39;innodb_%io_threads&#39;\\G;\n\n#output\n*************************** 1. row ***************************\nVariable_name: innodb_read_io_threads\n        Value: 4\n*************************** 2. row ***************************\nVariable_name: innodb_write_io_threads\n        Value: 4\n2 rows in set (0.00 sec)\n\n\n#查看InnoDB中的IO Threads\nshow engine innodb status\\G;\n\n#output\n...\n--------\nFILE I/O\n--------\nI/O thread 0 state: waiting for completed aio requests (insert buffer thread)\nI/O thread 1 state: waiting for completed aio requests (log thread)\nI/O thread 2 state: waiting for completed aio requests (read thread)\nI/O thread 3 state: waiting for completed aio requests (read thread)\nI/O thread 4 state: waiting for completed aio requests (read thread)\nI/O thread 5 state: waiting for completed aio requests (read thread)\nI/O thread 6 state: waiting for completed aio requests (write thread)\nI/O thread 7 state: waiting for completed aio requests (write thread)\nI/O thread 8 state: waiting for completed aio requests (write thread)\nI/O thread 9 state: waiting for completed aio requests (write thread)\n...\n</code></pre>\n<ol start=\"3\">\n<li>Purge Thread: 事务被提交后，其所使用的undolog可能不再需要，因此需要Purge Thread来回收已经使用并分配的undo页。在InnoDB1.1之前，purge操作仅在Master Thread中完成。而从InnoDB1.1版本开始，purge操作可以独立到单独的线程中进行，以此来减轻Master Thread的工作，从而提高CPU的使用率以及提升存储引擎的性能。用户可以在配置文件中添加配置来启用独立的Purge Thread（见下面的代码），在InnoDB1.1中，即使将purge线程数设置大于1，启动时也会将其设置为1，从1.2版本开始，InnoDB开始支持多个Purge Thread，这样可以加快undo页的回收，由于Purge Thread需要离散的随机读取undo页，这样也能进一步利用磁盘的随机读取性能。</li>\n</ol>\n<pre><code class=\"conf\">\n[mysqld]\ninnodb_purge_threads=1\n</code></pre>\n<ol start=\"4\">\n<li>Page Cleaner Thread: InnoDB 1.2.x引入，作用是将之前版本中的脏页的刷新操作都放入到单独的线程中来完成。目的是减轻Master Thread的工作，以及用户查询线程的阻塞，进一步提高InnoDB存储引擎的性能。</li>\n</ol>\n<h3 id=\"2-内存\"><a href=\"#2-内存\" class=\"headerlink\" title=\"2. 内存\"></a>2. 内存</h3><h4 id=\"1-缓冲池\"><a href=\"#1-缓冲池\" class=\"headerlink\" title=\"1. 缓冲池\"></a>1. 缓冲池</h4><p>InnoDB存储引擎是基于磁盘存储的，并将其中的记录按照页的方式进行管理。因此可以将其视为基于磁盘的数据库系统（Disk-base Database）。CPU速度与磁盘速度差距很大，基于磁盘的数据库系统通常采用缓冲池技术来提高数据库的整体性能。</p>\n<p>缓冲池就是一块内存区域，通过内存的速度来弥补磁盘速度对数据库性能的影响。</p>\n<ol>\n<li><p>数据库操作时，缓冲池的使用</p>\n<ul>\n<li>当数据库进行读取页当操作当时候，首先将从磁盘读到当页缓存在缓冲池中，这个过程称为将页“FIX”在缓冲池中。下一次读取相同的页的时候，首先判断该页是否在缓冲池中，如果在，称该页在缓冲池中被命中，直接读取该页，否则读取磁盘上的页。</li>\n<li>对于数据库中页的修改操作，首先修改在缓冲池中的页，然后再以一定的频率刷新到磁盘上，这里要注意，页从缓冲池刷新回磁盘的操作并不是在每次页发生更新时触发，而是通过一种成为<code>Checkpoint</code>的机制刷新回磁盘。这样也提高了数据库的整体性能。</li>\n</ul>\n</li>\n<li><p>缓冲池的大小： 缓冲池的大小直接影响着数据库的整体性能</p>\n<ol>\n<li>系统限制：32位操作系统的限制，最多将该值设置为3G。用户可以打开操作系统的PAE选项来获得32位系统下最大64GB内存的支持。</li>\n<li>强烈建议采用64位操作系统，让数据库使用更多的内存。</li>\n<li>对于InnoDB来说，缓冲池配置通过参数<code>innodb_buffer_pool_size</code>来设置</li>\n</ol>\n</li>\n<li><p>缓冲池的类型： 索引页、数据页、undo页、插入缓冲（insert buffer）、自适应哈希索引（adaptive hash index）、InnoDB存储的锁信息（lock info）、数据字典信息（data dictionary）等。从InnoDB 1.0.x开始，允许有多个缓冲池实例。每个页根据哈希值平均分配到不同到缓冲池实例中，增加了数据库的并发处理能力。可以通过参数<code>innodb_buffer_pool_instances</code>来进行配置，默认为1。</p>\n</li>\n</ol>\n<h4 id=\"2-LRU-List、Free-List和Flush-List\"><a href=\"#2-LRU-List、Free-List和Flush-List\" class=\"headerlink\" title=\"2. LRU List、Free List和Flush List\"></a>2. LRU List、Free List和Flush List</h4><ol>\n<li>LRU List<ul>\n<li>数据库中的缓冲池是通过LRU（Last Recent Used，最近最少使用）算法来进行管理的。即最频繁使用的页在LRU列表的前端，而最少使用的页在LRU列表的尾端。当缓冲池不能存放新读取到的页时，将首先释放LRU列表中尾端的页。</li>\n<li>InnoDB对LRU算法做了一些优化，在LRU列表中加入了midpoint位置。新读取到到页，虽然是最新访问到数据，但是也不会直接放到LRU列表到首部，而是放到midpoint的位置。这个算法在InnoDB存储引擎下称为<code>midpoint insertion strategy</code>。在默认配置下，midpoint在LRU列表长度的5/8处，也就是LRU列表尾端的3/8（37%）的位置。midpoint位置可以由参数<code>innodb_old_blocks_pct</code>控制。在InnoDB中，把midpoint之后的列表称为old列表，之前的列表称为new列表。可以简单的理解为new列表中的页都是做活跃的热点数据。</li>\n<li>为什么不用最常见的LRU算法（新数据直接放到首部）？这是因为某些SQL结果集可能超大，可能回将整个LRU列表中的数据刷出，导致真正的热点数据也被清除。加入midpoint可以保护热点数据。</li>\n<li>InnoDB还有另一个参数<code>innodb_old_blocks_time</code>（以毫秒为单位）用于表示页读到mid位置的后需要等待多久才会被加入到LRU列表的热端。页插入到mid位置后的<code>innodb_old_blocks_time</code>时间内，可以通过LRU列表访问页，但是无论多少次查询都不会将其移动到new列表，<code>innodb_old_blocks_time</code>时间后，如果再次被访问，就会被移动到new列表。</li>\n</ul>\n</li>\n</ol>\n<pre><code class=\"sql\">\n#为了LRU列表中的热点数据不被刷出啊，可以先设置innodb_old_blocks_time\n\nmysql&gt; SET GLOBAL innodb_old_blocks_time=1000;\nQuery OK, 0 rows affected.\n\n# data or index scan operation\n......\n\nmysql&gt; SET GLOBAL innodb_old_blocks_time=0;\nQuery OK, 0 rows affected.\n</code></pre>\n<p>如果用户预估自己活跃的热点数据不止63%，那么再执行SQL语句前可以通过下面的语句来减少热点页被刷出的概率。</p>\n<pre><code class=\"sql\">mysql&gt; SET GLOBAL innodb_old_blocks_pct=20;\nQuery OK, 0 rows affected.</code></pre>\n<ol start=\"2\">\n<li>Free List</li>\n</ol>\n<p>LRU列表是用来管理管理已经读取到的页的，但是当数据库刚启动时，LRU列表是空的，即没有任何的页，这时页都存放于Free列表中。当需要从缓冲池中分页时，首先从Free列表中查找到是否可用的空闲页，若有则将该页从Free列表中删除，放入到LRU列表中。否则，根据LRU算法，淘汰LRU列表末尾的页，将该内存空间分配给新的页。</p>\n<pre><code>    这里感觉有点难理解，数据库刚启动的时候，缓冲池里是没有缓存数据的，但是相应的内存空间已经开辟了，当我们查询数据后，磁盘返回数据，这时候，缓冲池要缓存数据，LRU列表是空的，要去Free List里取出空闲页，这里的空闲页其实是一个没有存储数据的页的描述（或者说地址），然后将磁盘返回的数据缓存到这个页，并将这个页交由LRU列表管理。也就是FreeList就是记录空闲页描述的双向列表，当LRU列表需要一个新的页的时候，就来找Free列表要，然后新的数据就被缓存了。</code></pre><ul>\n<li><p>这里感觉上LRU列表管理已经读取到的页，Free列表管理未使用的页，他们的size的和就应该是缓冲池里所有页的数量了。但是通过<code>SHOW ENGINE INNODB STATUS</code>可以看到，free buffers（Free列表页数量）和Database pages（LRU列表中页的数量）之和并不是缓冲池页的总数（Buffer pool size）。这是因为缓冲池中的页可能会被分配给自适应哈希索引、Lock信息、Insert Buffer等页，而这部分页不需要LRU算法进行维护，因此不在LRU列表中。</p>\n</li>\n<li><p>从InnoDB1.2版本开始，还可以通过<code>INNODB_BUFFER_POOL_STATUS</code>来观察缓冲池的运行状态。</p>\n<pre><code class=\"sql\">      select pool_id, hit_rate, pages_made_young, pages_not_made_young from information_schema.INNODB_BUFFER_POOL_STATUS;</code></pre>\n</li>\n<li><p>可以通过<code>INNODB_BUFFER_PAGE_LRU</code>来观察每个LRU列表中每个页的具体信息，例如通过下面的语句可以看到缓冲池LRU列表中SPACE为1的表的页类型：</p>\n<pre><code class=\"sql\">      select table_name, space, page_number, page_type from innodb_buffer_page_lru where space = 1;</code></pre>\n</li>\n<li><p>InnoDB存储引擎从1.0.x版本开始支持压缩页的功能，即将原本16k的页压缩为1kb、2kb、4kb和8kb。而由于页的大小发生了变化，LRU列表也有了些许的改动。对于非16kb的页，是通过unzip_LRU列表来进行管理的。通过命令<code>SHOW ENGINE INNODB STATUS\\G;</code>可以看到LRU列表和unzip_LRU列表的页的数量。LRU中的页包含了unzip_LRU列表中的页。</p>\n</li>\n<li><p>unzip_LRU列表中对不同压缩页大小的页进行分别管理，并通过<code>伙伴算法</code>进行内存的分配。以需要从缓冲池中申请页为4kb的大小为例，其过程如下：</p>\n<ol>\n<li><p>检查4kb的unzip_LRU列表，检查是否有可用的空闲页；</p>\n</li>\n<li><p>如果有，则直接使用；</p>\n</li>\n<li><p>否则，检查8kb的unzip_LRU列表；</p>\n</li>\n<li><p>如果能够得到空闲页，将页分成2个4KB页，存放到4KB的unzip_LRU列表；</p>\n</li>\n<li><p>如果不能得到空闲页，从LRU列表中申请一个16KB的页，将页分为1个8KB的页、2个4KB的页，分别存放到对应的unzip_LRU列表中。</p>\n<p>可以通过information_schema架构下的表INNODB_BUFFER_PAGE_LRU来观察unzip_LRU列表中的页</p>\n<pre><code class=\"sql\">select table_name, space, page_number, compressed_size from innodb_buffer_page_lru where compressed_size &lt;&gt; 0;</code></pre>\n<pre><code>伙伴算法，简而言之，就是将内存分成若干块，然后尽可能以最适合的方式满足程序内存需求的一种内存管理算法，伙伴算法的一大优势是它能够完全避免外部碎片的产生。什么是外部碎片以及内部碎片，前面博文slab分配器后面已有介绍。申请时，伙伴算法会给程序分配一个较大的内存空间，即保证所有大块内存都能得到满足。很明显分配比需求还大的内存空间，会产生内部碎片。所以伙伴算法虽然能够完全避免外部碎片的产生，但这恰恰是以产生内部碎片为代价的。</code></pre></li>\n</ol>\n</li>\n</ul>\n<ol start=\"3\">\n<li>Flush List</li>\n</ol>\n<ul>\n<li>在LRU列表中的页被修改后，称该页为脏页（dirty page），即缓冲池中的页和磁盘上的页的数据产生了不一致。这时数据库会通过<code>checkpoint</code>机制将脏页刷新回磁盘，而Flush列表中的页即为<code>脏页列表</code>。需要注意的是，脏页既存在于LRU列表，也存在于Flush列表中。LRU列表用于来管理缓冲池中也的可用性，Flush列表用来管理将页刷回磁盘，二者互不影响。</li>\n<li>同LRU列表一样，Flush列表也能通过<code>SHOW ENGINE INNODB STATUS</code>来查看，<code>Modified db pages 24673</code>就显示了脏页的数量。</li>\n<li>查看脏页的数量和类型（table_name为null说明该页属于系统表空间）：<pre><code class=\"sql\">    select table_name, space, page_number, page_type \n    from innodb_buffer_page_lru where oldest_modification &gt; 0;</code></pre>\n</li>\n</ul>\n<h3 id=\"3-重做日志缓冲\"><a href=\"#3-重做日志缓冲\" class=\"headerlink\" title=\"3. 重做日志缓冲\"></a>3. 重做日志缓冲</h3><p>重做日志缓冲（redo log buffer）。InnoDB存储引擎首先将重做日志信息放入到这个缓冲区，然后按照一定频率将其刷新到重做日志文件。重做日志缓冲不一定要设置的很大，因为一般情况下每一秒会将重做日志缓存刷新到日志文件，因此只需要保证每秒产生的事务量在在这个缓存大小之内即可。该值由配置参数<code>innodb_log_buffer_size</code>控制，默认为8M：</p>\n<pre><code class=\"sql\">mysql&gt; show variables like &#39;innodb_log_buffer_size&#39;\\G;\n*************************** 1. row ***************************\nVariable_name: innodb_log_buffer_size\n        Value: 16777216\n1 row in set (0.00 sec)</code></pre>\n<p>重做日志在下面三种情况下会将重做日志缓冲中的内容刷新到外部磁盘的重做日志文件中：</p>\n<ul>\n<li>Master Thread每一秒将重做日志缓冲刷新到重做日志文件；</li>\n<li>每个事务提交时会将重做日志缓存刷新到重做日志文件；</li>\n<li>当重做日志缓冲池剩余空间小于1/2时，重做日志缓冲会刷新到缓存日志文件。</li>\n</ul>\n<h3 id=\"4-额外的内存池\"><a href=\"#4-额外的内存池\" class=\"headerlink\" title=\"4. 额外的内存池\"></a>4. 额外的内存池</h3><p>在InnoDB中，对内存的管理是通过一种称为内存堆（heap）的方式进行的。在对一些数据结构本身的内存进行分配时，需要从额外的内存池中进行申请，当该区域的内存不够时，会从缓冲池中进行申请。这里的数据结构本身是指每个缓冲池中的帧缓存（frame buffer）和对应的缓冲控制对象（buffer control block），这些对象记录了一些诸如LRU、锁、等待等信息，而这些对象的内存需要从额外的内存池中申请。<strong>因此在申请了很大的InnoDB缓冲池时，应该考虑相应的增加这个值</strong>。</p>\n<h2 id=\"4-Checkpoint技术\"><a href=\"#4-Checkpoint技术\" class=\"headerlink\" title=\"4. Checkpoint技术\"></a>4. Checkpoint技术</h2><p>Mysql缓冲池的设计就是为了跨越cpu速度与磁盘速度之间鸿沟，也就是页的操作都是首先在缓冲池中完成，操作完成时，缓冲池的数据版本比磁盘新，数据库需要将新版本的页刷新到磁盘。但是刷新到磁盘，瓶颈依然在磁盘IO，而且如果在缓存刷新到磁盘的过程中宕机，缓存中的数据时不能恢复的。所以当前事务数据库都普遍采用了<code>Write Ahead Log</code>策略，即当事务提交时，先写重做日志，在修改页。当由于宕机而导致数据丢失时，可以通过重做日志来完成数据的恢复。这也是事务ACID中D（Durability持久性）的要求。</p>\n<p>思考一下，缓冲池可以让我们读写数据更快速，重做日志可以保证数据库数据不丢失。有了缓冲池和重做日志，是不是就可以不用将缓冲池中的页刷新到磁盘了？好家伙，直接内存数据库了？毕竟mysql是要持久化的，是要存大量数据的。你一直不落磁盘，先不说内存够不够大，就是重新启动时重新应用重做日志的时间也够受的。所以mysql有个Checkpoint（检查点）技术。</p>\n<h3 id=\"1-Checkout技术用于解决以下问题：\"><a href=\"#1-Checkout技术用于解决以下问题：\" class=\"headerlink\" title=\"1. Checkout技术用于解决以下问题：\"></a>1. Checkout技术用于解决以下问题：</h3><ul>\n<li>缩短数据库的恢复时间</li>\n<li>缓冲池不够用时，将脏页刷新到磁盘</li>\n<li>重做日志不可用时，刷新脏页。</li>\n</ul>\n<ol>\n<li>当数据库发生宕机时，数据库不需要重做所有日志，因为Checkpoint之前的页都已经刷新回磁盘了，所以只需要对Checkpoint后的重做日志进行恢复。这样就大大缩短了恢复的时间。</li>\n<li>当缓冲池不够用时，根据LRU算法会溢出最近使用最少的页，若此页为脏页，那么需要强制执行Checkpoint，将脏页刷新到磁盘。</li>\n<li>重做日志出现不可用的情况时因为当前事务数据库系统对重做日志的设计都是循环使用的，并不是无限增大的。重做日志可以被重用的部分是指这些重做日志已经不再需要，即当数据库发生宕机时，数据库恢复操作不需要这部分重做日志。因此这部分就可以被覆盖重用。若此时重做日志还需要使用，那么必须强制产生Checkpoint，将缓冲区中的页至少刷新到当前重做日志的位置。</li>\n</ol>\n<h3 id=\"2-LSN（Log-Sequece-Number）\"><a href=\"#2-LSN（Log-Sequece-Number）\" class=\"headerlink\" title=\"2. LSN（Log Sequece Number）\"></a>2. LSN（Log Sequece Number）</h3><p>InnoDB存储引擎是通过LSN来标记版本的。LSN是8字节的数字，单位是字节。每个页有LSN，重做日志中也有LSN，Checkpoint也有LSN。可以通过<code>SHOW ENGINE INNODB STATUS</code>来观察：</p>\n<pre><code class=\"sql\">mysql&gt; SHOW ENGINE INNODB STATUS\\G;\n\n......\n---\nLOG\n---\nLog sequence number 92561351052\nLog flushed up to 92561351052\nLast checkpoint at 92561351052</code></pre>\n<h3 id=\"3-InnoDB中有两种Checkpoint\"><a href=\"#3-InnoDB中有两种Checkpoint\" class=\"headerlink\" title=\"3. InnoDB中有两种Checkpoint\"></a>3. InnoDB中有两种Checkpoint</h3><h4 id=\"1-Sharp-Checkpoint\"><a href=\"#1-Sharp-Checkpoint\" class=\"headerlink\" title=\"1. Sharp Checkpoint\"></a>1. Sharp Checkpoint</h4><p>Sharp Checkpoint发生在数据库关闭时将所有的脏页刷新回磁盘，这是默认的工作方式，即参数<code>innodb_fast_shutdown=1</code>。因为它时将所有的脏页都刷回磁盘，所以不可能在数据库运行时来执行，太影响性能。</p>\n<h4 id=\"2-Fuzzy-Checkpoint\"><a href=\"#2-Fuzzy-Checkpoint\" class=\"headerlink\" title=\"2. Fuzzy Checkpoint\"></a>2. Fuzzy Checkpoint</h4><p>InnoDB存储引擎内部使用Fuzzy Checkpoint进行页的刷新，即只刷新一部分脏页，而不是刷新所有的脏页到磁盘。</p>\n<p>在InnoDB中可能发生如下几种情况的Fuzzy Checkpoint：</p>\n<ol>\n<li><p>Master Thread Checkpoint</p>\n<p>Master Thread Checkpoint以每秒或每十秒的速度从缓冲池的脏页列表中刷新一定比例的页回磁盘，这个过程是异步的，不会阻塞用户查询线程。</p>\n</li>\n<li><p>FLUSH_LRU_LIST Checkporint</p>\n<p>InnoDB存储引擎需要保证LRU列表中需要有差不多100个空闲页可供使用。InnoDB1.1.x版本之前，需要检查LRU是否有足够的可用空间操作发生在用户查询线程，这就会阻塞用户的查询操作。如果没有100个可用的空闲页，那么InnoDB存储引擎会将LRU列表尾端的页移除。如果这些页有脏页，那么就要进行Checkpoint。从MySQL5.6版本，也就是InnoDB1.2.x开始，这个检查被放在了一个单独的Page Cleaner线程中进行，并且用户可以通过参数innodb_lru_scan_depth控制LRU列表中可用页的数量，该值默认为1024。</p>\n</li>\n<li><p>Async/Sync Flush Checkpoint</p>\n<p>这里是在重做日志文件不可用时，需要强制将一些页刷回磁盘，而此时脏页是从脏页列表中选取的。若已经写入到重做日志的LSN极为redo_lsn，将已经刷新回磁盘最新页的LSN记为checkpoint_lsn，则可定义:</p>\n<p><code>checkpoint_age = redo_lsn - checkpoint_lsn</code></p>\n<p>再定义一下变量：</p>\n<p><code>async_water_mark = 75% * total_redo_log_file_size</code></p>\n<p><code>sync_water_mark = 90% * total_redo_log_file_size</code></p>\n<p>如果每个重做日志文件大小为1GB，并且定义了两个重做日志文件，则重做日志文件的总大小为2GB，那么<code>async_water_mark</code>=1.5GB，<code>sync_water_mark</code>=1.8GB。</p>\n<p>那么：</p>\n<ul>\n<li>当checkpoint_age &lt; async_water_mark时，不需要刷新任何脏页到磁盘。</li>\n<li>当async_water_mark &lt; checkpoint_age &lt; sync_water_mark时，触发Async Flush，从Flush列表中刷新足够的脏页回磁盘，是的刷新后满足checkpoint_age&lt;async_water_mark。</li>\n<li>checkpoint_age &gt; sync_water_mark这种情况很少发生，除非设置的重做日志文件太小，并且在进行类似LOAD DATA的BULK INSERT操作。此时出发Sync Flush操作，从Flush列表中刷新足够的脏页回磁盘，使得刷新后满足checkpoint_age &lt; async_water_mark。</li>\n</ul>\n<p>可见Async/Sync Flush Checkpoint是为了保证重做日志的循环使用的可用性。InnoDB 1.2.x之前，Async会阻塞发现问题的用户查询线程，而Sync会阻塞所有用户的查询线程。但是后来，这部分的刷新操作同样放入了单独的Page Clener Thread中，不会阻塞用户查询线程。</p>\n</li>\n<li><p>Dirty Page too much Checkpoint</p>\n<p>这种情况就是脏页数量太多，导致InnoDB存储引擎强制进行Checkpoint。目的还是保证缓冲池中有足够可用的页。其可由参数<code>innodb_max_dirty_pages_pct</code>来控制。百分比，默认时75（老版本InnoDB是90），表示当缓冲池中脏页的数量占据75%时，强制进行checkpoint，刷新一部分的页到磁盘。</p>\n</li>\n</ol>\n<h2 id=\"5-Master-Thread工作方式\"><a href=\"#5-Master-Thread工作方式\" class=\"headerlink\" title=\"5. Master Thread工作方式\"></a>5. Master Thread工作方式</h2><p>InnoDB存储引擎的主要工作都是在一个单独的后台线程Master Thread中完成的。</p>\n<h3 id=\"1-InnoDB-1-0-x版本之前的Master-Thread\"><a href=\"#1-InnoDB-1-0-x版本之前的Master-Thread\" class=\"headerlink\" title=\"1. InnoDB 1.0.x版本之前的Master Thread\"></a>1. InnoDB 1.0.x版本之前的Master Thread</h3><p>Master Thread具有最高的线程优先级别。其内部由多个循环（loop）组成：主循环（loop）、后台循环（background loop）、刷新循环（flush loop）、暂停循环（suspend loop）。Master Thread会根据数据库运行的状态在loop、background loop、flush loop和suspend loop中进行切换。</p>\n<p>绝大多数操作是在这个循环中，其中分为两大部分的操作—每秒钟的操作和每10秒的操作。loop循环是通过thread sleep来实现的，所以所谓的每一秒或者没十秒只是个大概频率，负载很大的情况下可能会有延迟。</p>\n<p>每一秒的操作包括：</p>\n<ul>\n<li>日志缓冲刷新到磁盘，即使这个事务还没有提交（总是）：所以再大的事务提交（commit）的时间也是很短。</li>\n<li>合并插入缓冲（可能）：并不是每秒都发生，InnoDB会判断前一秒内发生的IO次数是否小于5次，小于5次，认为压力很小，可以执行合并插入缓冲操作。</li>\n<li>至多刷新100个InnoDB的缓冲池中的脏页到磁盘（可能）：InnoDB判断当前缓冲池中脏页的比例（buf_get_modified_ratio_pct）是否超过了配置文件中innodb_max_dirty_pages_pct参数（默认90，代表90%），如果超过了，就要作磁盘同步操作，将100个脏页写入磁盘中。</li>\n<li>如果当前没有用户活动，则切换到background loop（可能）</li>\n</ul>\n<p>每十秒的操作：</p>\n<ul>\n<li><p>刷新100个脏页到磁盘（可能）：InnoDB判断过去10秒内磁盘IO操作是否小于200次，如果是，认为当前有足够的磁盘IO操作能力，则将100个脏页刷新到磁盘</p>\n</li>\n<li><p>合并至多5个插入缓冲（总是）</p>\n</li>\n<li><p>将日志缓冲刷新到磁盘（总是）</p>\n</li>\n<li><p>删除无用的Undo页（总是）：执行full purge操作，删除无用的Undo页，对表进行的update、delete操作，原先的行被标记为删除，但是因为一致性读（consistent read）的关系，要保留这些版本的信息，在full purge过程中，InnoDB会判断当前事务系统中已被删除的行是否可以删除（有时候可能还有查询操作需要读取之前版本的undo信息），如果可以删除，则删除。full purge操作，每次最多尝试回收20个undo页。</p>\n</li>\n<li><p>刷新100个或者10个脏页到磁盘（总是）：InnoDB判断缓冲池中脏页的比例（buf_get_modified_ratio_pct），如果有超过70%的脏页，则刷新100个脏页到磁盘，如果脏页的比例小于70%，则只刷新10%的脏页到磁盘。</p>\n</li>\n</ul>\n<p>background loop的操作：</p>\n<ul>\n<li>删除无用的Undo页（总是）</li>\n<li>合并20个插入缓冲（总是）</li>\n<li>跳回到主循环（总是）</li>\n<li>不断刷新100个页直到符合条件（可能，跳转到flush loop中完成）</li>\n</ul>\n<p>如果flush loop中也没有什么事情可以作了，InnoDB存储引擎会切换到suspend loop，将Master Thread挂起，等待事件的发生。如果用户启用（enable）了InnoDB存储引擎，却没有使用任何InnoDB存储引擎的表，那么Master Thread总是处于挂起的状态。</p>\n<p>Master Thread伪代码如下：</p>\n<pre><code class=\"c\">void master_thread() {\n    goto loop;\n    loop:\n        for(int i = 0; i &lt; 10; i++) {\n            thread_sleep(1) // sleep 1 second\n            do log buffer flush to disk\n            if (last_one_second_ios &lt; 5) {\n                do merge at most 5 insert buffer\n            }\n            if (buf_get_mondified_ratio_pct &gt; innodb_max_dirty_pages_pct) {\n                do buffer pool flush 100 dirty page\n            }\n            if (no user activity) {\n                goto background loop\n            }\n        }\n    if (last_ten_second_ios &lt; 200) {\n        do buffer pool flush 100 dirty page\n    }\n    do merge at most 5 insert buffer\n    do log buffer flush to disk\n    do full purge\n    if (buf_get_modified_ratio_pct &gt; 70%) {\n        do buffer pool flush 100 dirty page\n    } else {\n        buffer pool flush 10 dirty page\n    }\n    goto loop\n    background loop:\n        do full purge\n        do merge 20 insert buffer\n        if not idle:\n            goto loop\n        else\n            goto flush loop\n    flush loop:\n        do buffer pool flush 100 dirty page\n        if (buf_get_modified_radio_pct &gt; innodb_max_dirty_pages_pct) {\n            goto flush loop\n        }\n    goto suspend loop\n    suspend loop:\n        suspend_thread()\n        waiting event\n            goto loop\n}</code></pre>\n<h3 id=\"2-InnoDB-1-2-x版本之前的Master-Thread\"><a href=\"#2-InnoDB-1-2-x版本之前的Master-Thread\" class=\"headerlink\" title=\"2. InnoDB 1.2.x版本之前的Master Thread\"></a>2. InnoDB 1.2.x版本之前的Master Thread</h3><p>几个修改：</p>\n<ol>\n<li><p>1.0.x之前的版本其实对IO是有限制的（很多硬编码，比如刷新100个脏页到磁盘），在磁盘技术飞速发展的今天，当固态磁盘（SSD）出现时，这种规定在很大程度上限制了InnoDB存储引擎对磁盘IO的性能，尤其是写入性能。<br>从InnoDB1.0.x，InnoDB Plugin提供了参数innodb_io_capacity，用来表示磁盘IO的吞吐量，默认值为200，当用户使用了ssd或者磁盘做了RAID，存储设备拥有了更高的IO速度，就可以将innodb_io_capacity调高，直到符合磁盘IO吞吐量。规则如下：</p>\n<ul>\n<li>在合并插入缓存时，合并插入缓存的数量为innodb_io_capacity值的5%</li>\n<li>在从缓冲区刷新脏页时，刷新脏页的数量为innodb_io_capacity</li>\n</ul>\n</li>\n<li><p><code>innodb_max_dirty_pages_pct</code>默认值的问题，在1.0.x版本之前，该值的默认为90，意味着脏页占缓冲池的90%。因为InnoDB存储引擎在每秒刷新缓冲池和flush loop时会判断这个值，如果该值大于<code>innodb_max_dirty_pages_pct</code>才刷新100个脏页，如果有很大的内存，或者数据库服务的压力很大，这时刷新脏页的速度反而会降低，同样，数据库在恢复阶段可能需要更多的时间。1.0.x后<code>innodb_max_diry_pages_pct</code>默认值变为了75，这样既可以加快刷新脏页的频率，又能保证磁盘IO的负载。</p>\n</li>\n<li><p>新增参数<code>innodb_adaptive_flushing</code>，自适应刷新，该值影响每秒刷新脏页的数量。原来的规则时：脏页在缓冲池所占比例小于<code>innodb_max_diry_pages_pct</code>时，不刷新脏页；大于<code>innodb_max_diry_pages_pct</code>时，刷新100个脏页。随着<code>innodb_adaptive_flushing</code>的引入，InnoDB存储引擎会通过一个名为<code>buf_flush_get_desired_flush_rate</code>的函数来判断需要刷新脏页的最合适的数量。<code>buf_flush_get_desired_flush_rate</code>通过判断产生重做日志（redo log）的速度来决定最合适的刷新脏页的数量。因此当脏页的比例小于<code>innodb_max_diry_pages_pct</code>时，也会刷新一定数量的脏页。</p>\n</li>\n<li><p>之前每次进行full purge操作时，最多回收20个Undo页，从InnoDB1.0.x开始引入了参数<code>innodb_purge_batch_size</code>，该参数可以控制每次full purge回收的undu页的数量。该参数的默认值为20，并可以动态的对其进行修改。</p>\n<pre><code>   mysql&gt; show variables like &#39;innodb_purge_batch_size&#39;\\G;\n   Variable_name: innodb_purge_batch_size\n   Value: 20\n   mysql&gt; set global innodb_purge_batch_size=50;\n   Query OK, 0 rows affected (0.00 sec)</code></pre></li>\n</ol>\n<p>综上，1.0.x版本开始，Master Thread伪代码如下：</p>\n<pre><code class=\"c\">void master_thread() {\n   goto loop;\nloop:\nfor(int i=0; i&lt;10; i++) {\n   thread_sleep(1) //sleep 1 second\n   do log buffer flush to disk\n   if(last_one_second_ios &lt; 5% innodb_io_capacity)\n      do merge 5% innodb_io_capacity insert buffer\n   if(buf_get_modified_ratio_pct &gt; innodb_max_dirty_pages_pct) {\n      do buffer pool flush 100% innodb_io_capacity dirty page\n   } else if enable adaptive flush {\n      do buffer pool flush desired amount dirty page\n   }\n   if(no user activity)\n      goto background loop\n}\nif (last_ten_second_ios &lt; innodb_io_capacity)\n   do buffer pool flush 100% innodb_io_capacity dirty page\ndo merge 5% innodb_io_capacity insert buffer\ndo log buffer flush to disk\ndo full purge\nif(buf_get_modified_ratio_pct &gt; 70%)\n   do buffer pool flush 100% innodb_io_capacity dirty page\nelse\n   do buffer pool flush 10% innodb_io_capacity dirty page\ngoto loop\nbackground loop:\ndo full purge\ndo merge 100% innodb_io_capacity insert buffer\nif not idle:\ngoto loop:\nelse:\n   goto flush loop\nflush loop:\ndo buffer pool flush 100% innodb_io_capacity dirty page\nif(buf_get_modified_ratio_pct &gt; innodb_max_dirty_pages_pct)\n   go to flush loop\n   goto suspend loop\nsuspend loop:\nsuspend_thread()\nwaiting event\ngoto loop;\n}</code></pre>\n<h3 id=\"3-InnoDB-1-2-x版本的Master-Thread\"><a href=\"#3-InnoDB-1-2-x版本的Master-Thread\" class=\"headerlink\" title=\"3. InnoDB 1.2.x版本的Master Thread\"></a>3. InnoDB 1.2.x版本的Master Thread</h3><p>在InnoDB1.2.x版本中再次对Master Thread进行了优化，由此可以看出Master Thread对性能所起到的关键作用。在1.2.x版本中，Master Thread的伪代码如下：</p>\n<pre><code class=\"c\">if InnoDB is idle\n   srv_master_do_idle_tasks();\nelse\n   srv_master_do_active_tasks();</code></pre>\n<p>其中<code>srv_master_do_idle_tasks()</code>就是之前版本中的每10秒的操作，<code>srv_master_do_active_tasks()</code>处理的是之前每秒中的操作。同时对于刷新脏页的操作，从Master Thread线程分离到一个单独的Page Cleaner Thread，从而减轻了Master Thread的工作，同时进一步提高了系统的并发性。</p>\n<h2 id=\"6-InnoDB关键特性\"><a href=\"#6-InnoDB关键特性\" class=\"headerlink\" title=\"6. InnoDB关键特性\"></a>6. InnoDB关键特性</h2><p>InnoDB的关键特性包括：</p>\n<ul>\n<li>插入缓冲（Insert Buffer）</li>\n<li>两次写（Double Write）</li>\n<li>自适应哈希索引（Adaptive Hash Index）</li>\n<li>异步IO（Async IO）</li>\n<li>刷新邻接页（Flush Neighbor Page）</li>\n</ul>\n","site":{"data":{}},"more":"<p>由于对MySQL的了解不够透彻，虽然用起来没问题，也知道一些常见的知识点，但是一直把它当作一个黑盒来使用，不免有些心里没底，所以下定决心，通过<strong>姜承尧</strong>大佬的书<a href=\"https://book.douban.com/subject/24708143/\" target=\"_blank\" rel=\"noopener\">MySQL技术内幕</a>，认真了解MySQL技术细节。我会将一些我认为重要的知识，记录在这篇博客中，希望看到这篇文章的你，也能有所收获。</p>\n<h1 id=\"第一章-MySQL体系结构和存储引擎\"><a href=\"#第一章-MySQL体系结构和存储引擎\" class=\"headerlink\" title=\"第一章 MySQL体系结构和存储引擎\"></a>第一章 MySQL体系结构和存储引擎</h1><h2 id=\"1-Mysql体系结构\"><a href=\"#1-Mysql体系结构\" class=\"headerlink\" title=\"1. Mysql体系结构\"></a>1. Mysql体系结构</h2><ol>\n<li>数据库是文件的集合，是依照某种数据模型组织起来并存放于二级存储器中的数据集合；数据库实例是程序，是位于用户与操作系统之间的一层数据管理软件，用户对数据库数据的任何操作，包括数据库定义、数据查询、数据维护、数据库运行控制等都是在数据库实例下进行的，应用程序只有通过数据库实例才能和数据库打交道。</li>\n<li>MySQL由以下几个部分组成：<ul>\n<li>连接池组件</li>\n<li>管理服务和工具组件</li>\n<li>SQL接口组件</li>\n<li>查询分析器组件</li>\n<li>优化器组件</li>\n<li>缓存（cache）组件</li>\n<li>插件式存储引擎</li>\n<li>物理文件</li>\n</ul>\n</li>\n<li>MySQL区别于其他数据库的最重要的一个特点就是它的插件式的表存储引擎。</li>\n<li>存储引擎是基于表的，而不是数据库。</li>\n</ol>\n<h2 id=\"2-MySQL存储引擎\"><a href=\"#2-MySQL存储引擎\" class=\"headerlink\" title=\"2. MySQL存储引擎\"></a>2. MySQL存储引擎</h2><ol>\n<li>MySQL是开源的，用户可以基于MySQL预定义的存储引擎接口编写自己的存储引擎。当然也可以通过修改某一存储引擎的源码来得到想要的特性。</li>\n<li>InnoDB存储引擎最早是第三方存储引擎，后来被Oracle收购。</li>\n</ol>\n<h3 id=\"1-InnoDB存储引擎\"><a href=\"#1-InnoDB存储引擎\" class=\"headerlink\" title=\"1. InnoDB存储引擎\"></a>1. InnoDB存储引擎</h3><ol>\n<li>InnoDB存储引擎支持事务。其设计目标主要面向在线事务处理（OLTP）的应用。其特点是：行锁设计、支持外键，并支持类似Oracle的非锁定读，即默认读取操作不会产生锁。</li>\n<li>从5.5.8版本开始，InnoDB是MySQL默认的存储引擎。</li>\n<li>InnoDB存储引擎将数据放在一个逻辑的表空间中。表空间由InnoDB自身进行管理。从MySQL4.1开始，它可以将每个InnoDB存储引擎的表单独存放到一个独立的ibd文件中。InnoDB支持用裸设备（raw disk）建立表空间。<strong>裸设备：裸设备(raw device)，也叫裸分区（原始分区），是一种没有经过格式化，不被Unix通过文件系统来读取的特殊块设备文件。由应用程序负责对它进行读写操作。不经过文件系统的缓冲。它是不被操作系统直接管理的设备。这种设备少了操作系统这一层，I/O效率更高。不少数据库都能通过使用裸设备作为存储介质来提高I/O效率。</strong></li>\n<li>InnoDB通过使用多版本并发控制（MVCC）来获得高并发性，并实现了SQL的4种隔离级别，默认Repeatable级别。</li>\n<li>InnoDB使用一种next-key locking的策略来避免幻读的产生。</li>\n<li>InnoDB提供了插入缓存（insert buffer）、二次写（double write）、自适应哈希索引（adaptive hash index）、预读（read ahead）等高性能和高可用功能。</li>\n<li>InnoDB表存储数据采用了聚集（clustered）的方式，因此每张表的存储都是按照主键的顺序进行存放。如果没有显式地定义主键，InnoDB会为每一行数据生成一个6字节的ROWID，并以此作为主键。</li>\n</ol>\n<h3 id=\"2-MyISAM存储引擎\"><a href=\"#2-MyISAM存储引擎\" class=\"headerlink\" title=\"2. MyISAM存储引擎\"></a>2. MyISAM存储引擎</h3><ol>\n<li>MyISAM存储引擎不支持事务、锁表设计，支持全文索引，主要面向一些OLAP数据库应用。</li>\n<li>MySQL5.5.8之前默认存储引擎是MyISAM（Windows版本除外）。</li>\n<li>MyISAM存储引擎的缓冲池只缓存索引文件，而不缓存数据文件。这点和大多数数据库都不同。</li>\n<li>MyISAM存储引擎表由MYD和MYI组成，MYD用来存放数据文件，MYI用来存放索引文件。</li>\n<li>MySQL5.0之前MyISAM默认支持的表大小是4G，如果需要更大的MyISAM表的话，就要制定MAX_ROWS和AVG_ROW_LENGTH属性。从5.0版本开始，MyISAM默认支持256TB的单表数据，这足够一般应用的需求。</li>\n<li>MyISAM存储引擎表，Mysql数据库只缓存其索引文件，数据文件的缓存交给操作系统本身完成，这与LRU算法缓存数据的大部分数据库都不同。MySQL 5.1.23之前，缓存索引的缓冲区最大只能设置为4GB，在之后的版本中，64位系统可以支持大于4GB的索引缓冲区。</li>\n</ol>\n<h3 id=\"3-其他存储引擎\"><a href=\"#3-其他存储引擎\" class=\"headerlink\" title=\"3. 其他存储引擎\"></a>3. 其他存储引擎</h3><ol>\n<li>NDB： 一个集群存储引擎。数据全部放在内存中（从MySQL 5.1之后，可以将非索引数据放在磁盘上），所以主键查找速度极快，通过添加NDB数据存储节点，可以线性的提高数据库性能，是高可用、高性能的集群系统。复杂的连接操作网络开销很大，因为NDB的连接操作（JOIN）是在数据库层完成的，而不是在存储引擎层完成的。</li>\n<li>Memory: 之前被称为HEAP存储引擎。将表中的数据存放在内存中，如果数据库重启或发生崩溃，表中的数据全部消失。非常适合非常适合存储临时数据。默认使用hash哈希索引，而不是B+树索引。只支持表锁，并法性能差，不支持TEXT、BLOB列类型。存储变长字段varchar是按照定长char方式存储的，因此会浪费空间。MySQL数据库使用Memory存储引擎作为临时表来存放查询的中间结果集，如果中间结果集大于Memory存储引擎表的容量设置，又或者中间结果含有TEXT或BLOB字段，则MySQL会把其转换成MyISAM存储引擎表存放到磁盘中，因为MyISAM不缓存数据文件，所以这时产生的临时表的性能对于查询会有损失。</li>\n<li>Archive存储引擎： Archive引擎只支持INSERT和SELECT操作，从MySQL5.1开始支持索引。Archive引擎使用zlib算法将数据行（row）进行压缩后存储，压缩比可达到1：10。正如其名，Archive存储引擎非常适合存储归档数据，如日志信息。通过行锁来实现高并发的插入操作。但是不是事务安全的，目的主要是提供高速的插入和压缩。</li>\n<li>Federated存储引擎： Federated存储引擎并不存储数据，他只是指向一台远程MySQL数据库服务器上的表。类似SQL Server的链接服务器和Oracle的透明网关。不同的是，Federated只支持MySQL数据库表，不支持异构数据库表。</li>\n<li>Maria存储引擎： Maria当初是为了取代原有的MyISAM而设计的，从而成为MySQL默认存储引擎。支持缓存数据和索引文件，应用了行锁设计，提供了MVCC功能，支持事务和非事务安全的选项，以及更好的BLOB字符类型的处理性能。</li>\n</ol>\n<h3 id=\"4-其它\"><a href=\"#4-其它\" class=\"headerlink\" title=\"4. 其它\"></a>4. 其它</h3><ol>\n<li>查看当前使用MySQL版本支持的引擎：</li>\n</ol>\n<pre><code class=\"sql\">\nshow engines\\G;\n</code></pre>\n<h2 id=\"3-连接MySQL\"><a href=\"#3-连接MySQL\" class=\"headerlink\" title=\"3. 连接MySQL\"></a>3. 连接MySQL</h2><h3 id=\"1-TCP-IP\"><a href=\"#1-TCP-IP\" class=\"headerlink\" title=\"1. TCP/IP\"></a>1. TCP/IP</h3><pre><code class=\"bash\">\nmysql -h 192.168.0.101 -u root -p\n</code></pre>\n<p>通过TCP/IP连接到数据库实例的时候，MySQL数据库会先检查一张权限视图，用来判断此请求是否允许连接。该视图在MySQL架构下，表名为user。</p>\n<pre><code class=\"sql\">\nuse mysql;\nselect host, user, password from user;\n</code></pre>\n<h3 id=\"2-命名管道和共享内存\"><a href=\"#2-命名管道和共享内存\" class=\"headerlink\" title=\"2. 命名管道和共享内存\"></a>2. 命名管道和共享内存</h3><p>如果在MySQL服务器本机连接，可以通过命名管道，但是需要MySQL数据库在配置文件中启用<code>--enable-named-pipe</code>选项。在MySQL 4.1之后，还提供了共享内存的连接方式，需要在配置文件中添加<code>--shared-memory</code>实现，在连接时，MySQL客户端还需要使用<code>--protocol=memory</code>选项。</p>\n<h3 id=\"3-UNIX域套接字\"><a href=\"#3-UNIX域套接字\" class=\"headerlink\" title=\"3. UNIX域套接字\"></a>3. UNIX域套接字</h3><p>在Linux/UNIX环境下，可以使用UNIX域套接字。UNIX域套接字并不是一个网络协议，所以只能在MySQL客户端和数据库实例在一台服务器上时使用。用户可以在配置文件中执行套接字文件的路径。如<code>--socket=/tmp/mysql.sock</code>。可以通过命令<code>show variables like &#39;socket&#39;;</code>来查找套接字文件。知道了套接字文件的路径后，就可以通过下面的命令连接了：</p>\n<pre><code class=\"bash\">\nmysql -u root -S /tmp/mysql.sock\n</code></pre>\n<h1 id=\"第二章-InnoDB存储引擎\"><a href=\"#第二章-InnoDB存储引擎\" class=\"headerlink\" title=\"第二章 InnoDB存储引擎\"></a>第二章 InnoDB存储引擎</h1><h2 id=\"1-InnoDB存储引擎概述\"><a href=\"#1-InnoDB存储引擎概述\" class=\"headerlink\" title=\"1. InnoDB存储引擎概述\"></a>1. InnoDB存储引擎概述</h2><p>InnoDB存储引擎是第一个完整支持ACID事务的MySQL存储引擎，其特点是行锁设计、支持MVCC、支持外键、提供一致性非锁定读，同时被设计用来最有效地利用以及使用内存和CPU。</p>\n<h2 id=\"2-InnoDB存储引擎的版本\"><a href=\"#2-InnoDB存储引擎的版本\" class=\"headerlink\" title=\"2. InnoDB存储引擎的版本\"></a>2. InnoDB存储引擎的版本</h2><p>早期InnoDB随MySQL数据库的更新而更新，从MySQL5.1开始，MySQL允许存储引擎开发商以动态方式加载引擎，这样存储引擎可以不受MySQL数据库版本的限制。</p>\n<h2 id=\"3-InnoDB体系架构\"><a href=\"#3-InnoDB体系架构\" class=\"headerlink\" title=\"3. InnoDB体系架构\"></a>3. InnoDB体系架构</h2><h3 id=\"1-后台线程\"><a href=\"#1-后台线程\" class=\"headerlink\" title=\"1. 后台线程\"></a>1. 后台线程</h3><p>InnoDB存储引擎是多线程的模型，后台有多个不同的线程，负责处理不同的任务。</p>\n<ol>\n<li>Master Thread： 这是一个非常核心的后台线程，主要负责将缓冲池中的数据异步刷新到磁盘，保证数据一致性，包括脏页的刷新、合并插入缓存（INSERT BUFFER）、UNDO页的回收等。</li>\n<li>IO Thread： 在InnoDB存储引擎中大量的使用了AIO（Async IO）来处理写IO请求，这样极大地提高了数据库的性能。IO Thread主要负责这些IO请求的回调（call back）处理。InnoDB 1.0之前共有4个IO Thread，分别是write、read、insert buffer和log IO Thread。在Linux平台下，IO Thread的数量不能进行调整，但是在Windows平台下，可以通过参数<code>innodb_file_io_threads</code>来增大IO Thread。从InnoDB 1.0.x开始，read thread和write thread分别增大到4个，并且不再使用<code>innodb_file_io_threads</code>参数，而是分别使用<code>innodb_read_io_threads</code>和<code>innodb_write_io_threads</code>参数进行设置。</li>\n</ol>\n<pre><code class=\"sql\">\n#查看innodb引擎版本\nshow variables like &#39;innodb_version&#39;\\G;\n\n#output\n*************************** 1. row ***************************\nVariable_name: innodb_version\n        Value: 8.0.22\n1 row in set (1.18 sec)\n\n\n#查看innodb读写IO线程\nshow variables like &#39;innodb_%io_threads&#39;\\G;\n\n#output\n*************************** 1. row ***************************\nVariable_name: innodb_read_io_threads\n        Value: 4\n*************************** 2. row ***************************\nVariable_name: innodb_write_io_threads\n        Value: 4\n2 rows in set (0.00 sec)\n\n\n#查看InnoDB中的IO Threads\nshow engine innodb status\\G;\n\n#output\n...\n--------\nFILE I/O\n--------\nI/O thread 0 state: waiting for completed aio requests (insert buffer thread)\nI/O thread 1 state: waiting for completed aio requests (log thread)\nI/O thread 2 state: waiting for completed aio requests (read thread)\nI/O thread 3 state: waiting for completed aio requests (read thread)\nI/O thread 4 state: waiting for completed aio requests (read thread)\nI/O thread 5 state: waiting for completed aio requests (read thread)\nI/O thread 6 state: waiting for completed aio requests (write thread)\nI/O thread 7 state: waiting for completed aio requests (write thread)\nI/O thread 8 state: waiting for completed aio requests (write thread)\nI/O thread 9 state: waiting for completed aio requests (write thread)\n...\n</code></pre>\n<ol start=\"3\">\n<li>Purge Thread: 事务被提交后，其所使用的undolog可能不再需要，因此需要Purge Thread来回收已经使用并分配的undo页。在InnoDB1.1之前，purge操作仅在Master Thread中完成。而从InnoDB1.1版本开始，purge操作可以独立到单独的线程中进行，以此来减轻Master Thread的工作，从而提高CPU的使用率以及提升存储引擎的性能。用户可以在配置文件中添加配置来启用独立的Purge Thread（见下面的代码），在InnoDB1.1中，即使将purge线程数设置大于1，启动时也会将其设置为1，从1.2版本开始，InnoDB开始支持多个Purge Thread，这样可以加快undo页的回收，由于Purge Thread需要离散的随机读取undo页，这样也能进一步利用磁盘的随机读取性能。</li>\n</ol>\n<pre><code class=\"conf\">\n[mysqld]\ninnodb_purge_threads=1\n</code></pre>\n<ol start=\"4\">\n<li>Page Cleaner Thread: InnoDB 1.2.x引入，作用是将之前版本中的脏页的刷新操作都放入到单独的线程中来完成。目的是减轻Master Thread的工作，以及用户查询线程的阻塞，进一步提高InnoDB存储引擎的性能。</li>\n</ol>\n<h3 id=\"2-内存\"><a href=\"#2-内存\" class=\"headerlink\" title=\"2. 内存\"></a>2. 内存</h3><h4 id=\"1-缓冲池\"><a href=\"#1-缓冲池\" class=\"headerlink\" title=\"1. 缓冲池\"></a>1. 缓冲池</h4><p>InnoDB存储引擎是基于磁盘存储的，并将其中的记录按照页的方式进行管理。因此可以将其视为基于磁盘的数据库系统（Disk-base Database）。CPU速度与磁盘速度差距很大，基于磁盘的数据库系统通常采用缓冲池技术来提高数据库的整体性能。</p>\n<p>缓冲池就是一块内存区域，通过内存的速度来弥补磁盘速度对数据库性能的影响。</p>\n<ol>\n<li><p>数据库操作时，缓冲池的使用</p>\n<ul>\n<li>当数据库进行读取页当操作当时候，首先将从磁盘读到当页缓存在缓冲池中，这个过程称为将页“FIX”在缓冲池中。下一次读取相同的页的时候，首先判断该页是否在缓冲池中，如果在，称该页在缓冲池中被命中，直接读取该页，否则读取磁盘上的页。</li>\n<li>对于数据库中页的修改操作，首先修改在缓冲池中的页，然后再以一定的频率刷新到磁盘上，这里要注意，页从缓冲池刷新回磁盘的操作并不是在每次页发生更新时触发，而是通过一种成为<code>Checkpoint</code>的机制刷新回磁盘。这样也提高了数据库的整体性能。</li>\n</ul>\n</li>\n<li><p>缓冲池的大小： 缓冲池的大小直接影响着数据库的整体性能</p>\n<ol>\n<li>系统限制：32位操作系统的限制，最多将该值设置为3G。用户可以打开操作系统的PAE选项来获得32位系统下最大64GB内存的支持。</li>\n<li>强烈建议采用64位操作系统，让数据库使用更多的内存。</li>\n<li>对于InnoDB来说，缓冲池配置通过参数<code>innodb_buffer_pool_size</code>来设置</li>\n</ol>\n</li>\n<li><p>缓冲池的类型： 索引页、数据页、undo页、插入缓冲（insert buffer）、自适应哈希索引（adaptive hash index）、InnoDB存储的锁信息（lock info）、数据字典信息（data dictionary）等。从InnoDB 1.0.x开始，允许有多个缓冲池实例。每个页根据哈希值平均分配到不同到缓冲池实例中，增加了数据库的并发处理能力。可以通过参数<code>innodb_buffer_pool_instances</code>来进行配置，默认为1。</p>\n</li>\n</ol>\n<h4 id=\"2-LRU-List、Free-List和Flush-List\"><a href=\"#2-LRU-List、Free-List和Flush-List\" class=\"headerlink\" title=\"2. LRU List、Free List和Flush List\"></a>2. LRU List、Free List和Flush List</h4><ol>\n<li>LRU List<ul>\n<li>数据库中的缓冲池是通过LRU（Last Recent Used，最近最少使用）算法来进行管理的。即最频繁使用的页在LRU列表的前端，而最少使用的页在LRU列表的尾端。当缓冲池不能存放新读取到的页时，将首先释放LRU列表中尾端的页。</li>\n<li>InnoDB对LRU算法做了一些优化，在LRU列表中加入了midpoint位置。新读取到到页，虽然是最新访问到数据，但是也不会直接放到LRU列表到首部，而是放到midpoint的位置。这个算法在InnoDB存储引擎下称为<code>midpoint insertion strategy</code>。在默认配置下，midpoint在LRU列表长度的5/8处，也就是LRU列表尾端的3/8（37%）的位置。midpoint位置可以由参数<code>innodb_old_blocks_pct</code>控制。在InnoDB中，把midpoint之后的列表称为old列表，之前的列表称为new列表。可以简单的理解为new列表中的页都是做活跃的热点数据。</li>\n<li>为什么不用最常见的LRU算法（新数据直接放到首部）？这是因为某些SQL结果集可能超大，可能回将整个LRU列表中的数据刷出，导致真正的热点数据也被清除。加入midpoint可以保护热点数据。</li>\n<li>InnoDB还有另一个参数<code>innodb_old_blocks_time</code>（以毫秒为单位）用于表示页读到mid位置的后需要等待多久才会被加入到LRU列表的热端。页插入到mid位置后的<code>innodb_old_blocks_time</code>时间内，可以通过LRU列表访问页，但是无论多少次查询都不会将其移动到new列表，<code>innodb_old_blocks_time</code>时间后，如果再次被访问，就会被移动到new列表。</li>\n</ul>\n</li>\n</ol>\n<pre><code class=\"sql\">\n#为了LRU列表中的热点数据不被刷出啊，可以先设置innodb_old_blocks_time\n\nmysql&gt; SET GLOBAL innodb_old_blocks_time=1000;\nQuery OK, 0 rows affected.\n\n# data or index scan operation\n......\n\nmysql&gt; SET GLOBAL innodb_old_blocks_time=0;\nQuery OK, 0 rows affected.\n</code></pre>\n<p>如果用户预估自己活跃的热点数据不止63%，那么再执行SQL语句前可以通过下面的语句来减少热点页被刷出的概率。</p>\n<pre><code class=\"sql\">mysql&gt; SET GLOBAL innodb_old_blocks_pct=20;\nQuery OK, 0 rows affected.</code></pre>\n<ol start=\"2\">\n<li>Free List</li>\n</ol>\n<p>LRU列表是用来管理管理已经读取到的页的，但是当数据库刚启动时，LRU列表是空的，即没有任何的页，这时页都存放于Free列表中。当需要从缓冲池中分页时，首先从Free列表中查找到是否可用的空闲页，若有则将该页从Free列表中删除，放入到LRU列表中。否则，根据LRU算法，淘汰LRU列表末尾的页，将该内存空间分配给新的页。</p>\n<pre><code>    这里感觉有点难理解，数据库刚启动的时候，缓冲池里是没有缓存数据的，但是相应的内存空间已经开辟了，当我们查询数据后，磁盘返回数据，这时候，缓冲池要缓存数据，LRU列表是空的，要去Free List里取出空闲页，这里的空闲页其实是一个没有存储数据的页的描述（或者说地址），然后将磁盘返回的数据缓存到这个页，并将这个页交由LRU列表管理。也就是FreeList就是记录空闲页描述的双向列表，当LRU列表需要一个新的页的时候，就来找Free列表要，然后新的数据就被缓存了。</code></pre><ul>\n<li><p>这里感觉上LRU列表管理已经读取到的页，Free列表管理未使用的页，他们的size的和就应该是缓冲池里所有页的数量了。但是通过<code>SHOW ENGINE INNODB STATUS</code>可以看到，free buffers（Free列表页数量）和Database pages（LRU列表中页的数量）之和并不是缓冲池页的总数（Buffer pool size）。这是因为缓冲池中的页可能会被分配给自适应哈希索引、Lock信息、Insert Buffer等页，而这部分页不需要LRU算法进行维护，因此不在LRU列表中。</p>\n</li>\n<li><p>从InnoDB1.2版本开始，还可以通过<code>INNODB_BUFFER_POOL_STATUS</code>来观察缓冲池的运行状态。</p>\n<pre><code class=\"sql\">      select pool_id, hit_rate, pages_made_young, pages_not_made_young from information_schema.INNODB_BUFFER_POOL_STATUS;</code></pre>\n</li>\n<li><p>可以通过<code>INNODB_BUFFER_PAGE_LRU</code>来观察每个LRU列表中每个页的具体信息，例如通过下面的语句可以看到缓冲池LRU列表中SPACE为1的表的页类型：</p>\n<pre><code class=\"sql\">      select table_name, space, page_number, page_type from innodb_buffer_page_lru where space = 1;</code></pre>\n</li>\n<li><p>InnoDB存储引擎从1.0.x版本开始支持压缩页的功能，即将原本16k的页压缩为1kb、2kb、4kb和8kb。而由于页的大小发生了变化，LRU列表也有了些许的改动。对于非16kb的页，是通过unzip_LRU列表来进行管理的。通过命令<code>SHOW ENGINE INNODB STATUS\\G;</code>可以看到LRU列表和unzip_LRU列表的页的数量。LRU中的页包含了unzip_LRU列表中的页。</p>\n</li>\n<li><p>unzip_LRU列表中对不同压缩页大小的页进行分别管理，并通过<code>伙伴算法</code>进行内存的分配。以需要从缓冲池中申请页为4kb的大小为例，其过程如下：</p>\n<ol>\n<li><p>检查4kb的unzip_LRU列表，检查是否有可用的空闲页；</p>\n</li>\n<li><p>如果有，则直接使用；</p>\n</li>\n<li><p>否则，检查8kb的unzip_LRU列表；</p>\n</li>\n<li><p>如果能够得到空闲页，将页分成2个4KB页，存放到4KB的unzip_LRU列表；</p>\n</li>\n<li><p>如果不能得到空闲页，从LRU列表中申请一个16KB的页，将页分为1个8KB的页、2个4KB的页，分别存放到对应的unzip_LRU列表中。</p>\n<p>可以通过information_schema架构下的表INNODB_BUFFER_PAGE_LRU来观察unzip_LRU列表中的页</p>\n<pre><code class=\"sql\">select table_name, space, page_number, compressed_size from innodb_buffer_page_lru where compressed_size &lt;&gt; 0;</code></pre>\n<pre><code>伙伴算法，简而言之，就是将内存分成若干块，然后尽可能以最适合的方式满足程序内存需求的一种内存管理算法，伙伴算法的一大优势是它能够完全避免外部碎片的产生。什么是外部碎片以及内部碎片，前面博文slab分配器后面已有介绍。申请时，伙伴算法会给程序分配一个较大的内存空间，即保证所有大块内存都能得到满足。很明显分配比需求还大的内存空间，会产生内部碎片。所以伙伴算法虽然能够完全避免外部碎片的产生，但这恰恰是以产生内部碎片为代价的。</code></pre></li>\n</ol>\n</li>\n</ul>\n<ol start=\"3\">\n<li>Flush List</li>\n</ol>\n<ul>\n<li>在LRU列表中的页被修改后，称该页为脏页（dirty page），即缓冲池中的页和磁盘上的页的数据产生了不一致。这时数据库会通过<code>checkpoint</code>机制将脏页刷新回磁盘，而Flush列表中的页即为<code>脏页列表</code>。需要注意的是，脏页既存在于LRU列表，也存在于Flush列表中。LRU列表用于来管理缓冲池中也的可用性，Flush列表用来管理将页刷回磁盘，二者互不影响。</li>\n<li>同LRU列表一样，Flush列表也能通过<code>SHOW ENGINE INNODB STATUS</code>来查看，<code>Modified db pages 24673</code>就显示了脏页的数量。</li>\n<li>查看脏页的数量和类型（table_name为null说明该页属于系统表空间）：<pre><code class=\"sql\">    select table_name, space, page_number, page_type \n    from innodb_buffer_page_lru where oldest_modification &gt; 0;</code></pre>\n</li>\n</ul>\n<h3 id=\"3-重做日志缓冲\"><a href=\"#3-重做日志缓冲\" class=\"headerlink\" title=\"3. 重做日志缓冲\"></a>3. 重做日志缓冲</h3><p>重做日志缓冲（redo log buffer）。InnoDB存储引擎首先将重做日志信息放入到这个缓冲区，然后按照一定频率将其刷新到重做日志文件。重做日志缓冲不一定要设置的很大，因为一般情况下每一秒会将重做日志缓存刷新到日志文件，因此只需要保证每秒产生的事务量在在这个缓存大小之内即可。该值由配置参数<code>innodb_log_buffer_size</code>控制，默认为8M：</p>\n<pre><code class=\"sql\">mysql&gt; show variables like &#39;innodb_log_buffer_size&#39;\\G;\n*************************** 1. row ***************************\nVariable_name: innodb_log_buffer_size\n        Value: 16777216\n1 row in set (0.00 sec)</code></pre>\n<p>重做日志在下面三种情况下会将重做日志缓冲中的内容刷新到外部磁盘的重做日志文件中：</p>\n<ul>\n<li>Master Thread每一秒将重做日志缓冲刷新到重做日志文件；</li>\n<li>每个事务提交时会将重做日志缓存刷新到重做日志文件；</li>\n<li>当重做日志缓冲池剩余空间小于1/2时，重做日志缓冲会刷新到缓存日志文件。</li>\n</ul>\n<h3 id=\"4-额外的内存池\"><a href=\"#4-额外的内存池\" class=\"headerlink\" title=\"4. 额外的内存池\"></a>4. 额外的内存池</h3><p>在InnoDB中，对内存的管理是通过一种称为内存堆（heap）的方式进行的。在对一些数据结构本身的内存进行分配时，需要从额外的内存池中进行申请，当该区域的内存不够时，会从缓冲池中进行申请。这里的数据结构本身是指每个缓冲池中的帧缓存（frame buffer）和对应的缓冲控制对象（buffer control block），这些对象记录了一些诸如LRU、锁、等待等信息，而这些对象的内存需要从额外的内存池中申请。<strong>因此在申请了很大的InnoDB缓冲池时，应该考虑相应的增加这个值</strong>。</p>\n<h2 id=\"4-Checkpoint技术\"><a href=\"#4-Checkpoint技术\" class=\"headerlink\" title=\"4. Checkpoint技术\"></a>4. Checkpoint技术</h2><p>Mysql缓冲池的设计就是为了跨越cpu速度与磁盘速度之间鸿沟，也就是页的操作都是首先在缓冲池中完成，操作完成时，缓冲池的数据版本比磁盘新，数据库需要将新版本的页刷新到磁盘。但是刷新到磁盘，瓶颈依然在磁盘IO，而且如果在缓存刷新到磁盘的过程中宕机，缓存中的数据时不能恢复的。所以当前事务数据库都普遍采用了<code>Write Ahead Log</code>策略，即当事务提交时，先写重做日志，在修改页。当由于宕机而导致数据丢失时，可以通过重做日志来完成数据的恢复。这也是事务ACID中D（Durability持久性）的要求。</p>\n<p>思考一下，缓冲池可以让我们读写数据更快速，重做日志可以保证数据库数据不丢失。有了缓冲池和重做日志，是不是就可以不用将缓冲池中的页刷新到磁盘了？好家伙，直接内存数据库了？毕竟mysql是要持久化的，是要存大量数据的。你一直不落磁盘，先不说内存够不够大，就是重新启动时重新应用重做日志的时间也够受的。所以mysql有个Checkpoint（检查点）技术。</p>\n<h3 id=\"1-Checkout技术用于解决以下问题：\"><a href=\"#1-Checkout技术用于解决以下问题：\" class=\"headerlink\" title=\"1. Checkout技术用于解决以下问题：\"></a>1. Checkout技术用于解决以下问题：</h3><ul>\n<li>缩短数据库的恢复时间</li>\n<li>缓冲池不够用时，将脏页刷新到磁盘</li>\n<li>重做日志不可用时，刷新脏页。</li>\n</ul>\n<ol>\n<li>当数据库发生宕机时，数据库不需要重做所有日志，因为Checkpoint之前的页都已经刷新回磁盘了，所以只需要对Checkpoint后的重做日志进行恢复。这样就大大缩短了恢复的时间。</li>\n<li>当缓冲池不够用时，根据LRU算法会溢出最近使用最少的页，若此页为脏页，那么需要强制执行Checkpoint，将脏页刷新到磁盘。</li>\n<li>重做日志出现不可用的情况时因为当前事务数据库系统对重做日志的设计都是循环使用的，并不是无限增大的。重做日志可以被重用的部分是指这些重做日志已经不再需要，即当数据库发生宕机时，数据库恢复操作不需要这部分重做日志。因此这部分就可以被覆盖重用。若此时重做日志还需要使用，那么必须强制产生Checkpoint，将缓冲区中的页至少刷新到当前重做日志的位置。</li>\n</ol>\n<h3 id=\"2-LSN（Log-Sequece-Number）\"><a href=\"#2-LSN（Log-Sequece-Number）\" class=\"headerlink\" title=\"2. LSN（Log Sequece Number）\"></a>2. LSN（Log Sequece Number）</h3><p>InnoDB存储引擎是通过LSN来标记版本的。LSN是8字节的数字，单位是字节。每个页有LSN，重做日志中也有LSN，Checkpoint也有LSN。可以通过<code>SHOW ENGINE INNODB STATUS</code>来观察：</p>\n<pre><code class=\"sql\">mysql&gt; SHOW ENGINE INNODB STATUS\\G;\n\n......\n---\nLOG\n---\nLog sequence number 92561351052\nLog flushed up to 92561351052\nLast checkpoint at 92561351052</code></pre>\n<h3 id=\"3-InnoDB中有两种Checkpoint\"><a href=\"#3-InnoDB中有两种Checkpoint\" class=\"headerlink\" title=\"3. InnoDB中有两种Checkpoint\"></a>3. InnoDB中有两种Checkpoint</h3><h4 id=\"1-Sharp-Checkpoint\"><a href=\"#1-Sharp-Checkpoint\" class=\"headerlink\" title=\"1. Sharp Checkpoint\"></a>1. Sharp Checkpoint</h4><p>Sharp Checkpoint发生在数据库关闭时将所有的脏页刷新回磁盘，这是默认的工作方式，即参数<code>innodb_fast_shutdown=1</code>。因为它时将所有的脏页都刷回磁盘，所以不可能在数据库运行时来执行，太影响性能。</p>\n<h4 id=\"2-Fuzzy-Checkpoint\"><a href=\"#2-Fuzzy-Checkpoint\" class=\"headerlink\" title=\"2. Fuzzy Checkpoint\"></a>2. Fuzzy Checkpoint</h4><p>InnoDB存储引擎内部使用Fuzzy Checkpoint进行页的刷新，即只刷新一部分脏页，而不是刷新所有的脏页到磁盘。</p>\n<p>在InnoDB中可能发生如下几种情况的Fuzzy Checkpoint：</p>\n<ol>\n<li><p>Master Thread Checkpoint</p>\n<p>Master Thread Checkpoint以每秒或每十秒的速度从缓冲池的脏页列表中刷新一定比例的页回磁盘，这个过程是异步的，不会阻塞用户查询线程。</p>\n</li>\n<li><p>FLUSH_LRU_LIST Checkporint</p>\n<p>InnoDB存储引擎需要保证LRU列表中需要有差不多100个空闲页可供使用。InnoDB1.1.x版本之前，需要检查LRU是否有足够的可用空间操作发生在用户查询线程，这就会阻塞用户的查询操作。如果没有100个可用的空闲页，那么InnoDB存储引擎会将LRU列表尾端的页移除。如果这些页有脏页，那么就要进行Checkpoint。从MySQL5.6版本，也就是InnoDB1.2.x开始，这个检查被放在了一个单独的Page Cleaner线程中进行，并且用户可以通过参数innodb_lru_scan_depth控制LRU列表中可用页的数量，该值默认为1024。</p>\n</li>\n<li><p>Async/Sync Flush Checkpoint</p>\n<p>这里是在重做日志文件不可用时，需要强制将一些页刷回磁盘，而此时脏页是从脏页列表中选取的。若已经写入到重做日志的LSN极为redo_lsn，将已经刷新回磁盘最新页的LSN记为checkpoint_lsn，则可定义:</p>\n<p><code>checkpoint_age = redo_lsn - checkpoint_lsn</code></p>\n<p>再定义一下变量：</p>\n<p><code>async_water_mark = 75% * total_redo_log_file_size</code></p>\n<p><code>sync_water_mark = 90% * total_redo_log_file_size</code></p>\n<p>如果每个重做日志文件大小为1GB，并且定义了两个重做日志文件，则重做日志文件的总大小为2GB，那么<code>async_water_mark</code>=1.5GB，<code>sync_water_mark</code>=1.8GB。</p>\n<p>那么：</p>\n<ul>\n<li>当checkpoint_age &lt; async_water_mark时，不需要刷新任何脏页到磁盘。</li>\n<li>当async_water_mark &lt; checkpoint_age &lt; sync_water_mark时，触发Async Flush，从Flush列表中刷新足够的脏页回磁盘，是的刷新后满足checkpoint_age&lt;async_water_mark。</li>\n<li>checkpoint_age &gt; sync_water_mark这种情况很少发生，除非设置的重做日志文件太小，并且在进行类似LOAD DATA的BULK INSERT操作。此时出发Sync Flush操作，从Flush列表中刷新足够的脏页回磁盘，使得刷新后满足checkpoint_age &lt; async_water_mark。</li>\n</ul>\n<p>可见Async/Sync Flush Checkpoint是为了保证重做日志的循环使用的可用性。InnoDB 1.2.x之前，Async会阻塞发现问题的用户查询线程，而Sync会阻塞所有用户的查询线程。但是后来，这部分的刷新操作同样放入了单独的Page Clener Thread中，不会阻塞用户查询线程。</p>\n</li>\n<li><p>Dirty Page too much Checkpoint</p>\n<p>这种情况就是脏页数量太多，导致InnoDB存储引擎强制进行Checkpoint。目的还是保证缓冲池中有足够可用的页。其可由参数<code>innodb_max_dirty_pages_pct</code>来控制。百分比，默认时75（老版本InnoDB是90），表示当缓冲池中脏页的数量占据75%时，强制进行checkpoint，刷新一部分的页到磁盘。</p>\n</li>\n</ol>\n<h2 id=\"5-Master-Thread工作方式\"><a href=\"#5-Master-Thread工作方式\" class=\"headerlink\" title=\"5. Master Thread工作方式\"></a>5. Master Thread工作方式</h2><p>InnoDB存储引擎的主要工作都是在一个单独的后台线程Master Thread中完成的。</p>\n<h3 id=\"1-InnoDB-1-0-x版本之前的Master-Thread\"><a href=\"#1-InnoDB-1-0-x版本之前的Master-Thread\" class=\"headerlink\" title=\"1. InnoDB 1.0.x版本之前的Master Thread\"></a>1. InnoDB 1.0.x版本之前的Master Thread</h3><p>Master Thread具有最高的线程优先级别。其内部由多个循环（loop）组成：主循环（loop）、后台循环（background loop）、刷新循环（flush loop）、暂停循环（suspend loop）。Master Thread会根据数据库运行的状态在loop、background loop、flush loop和suspend loop中进行切换。</p>\n<p>绝大多数操作是在这个循环中，其中分为两大部分的操作—每秒钟的操作和每10秒的操作。loop循环是通过thread sleep来实现的，所以所谓的每一秒或者没十秒只是个大概频率，负载很大的情况下可能会有延迟。</p>\n<p>每一秒的操作包括：</p>\n<ul>\n<li>日志缓冲刷新到磁盘，即使这个事务还没有提交（总是）：所以再大的事务提交（commit）的时间也是很短。</li>\n<li>合并插入缓冲（可能）：并不是每秒都发生，InnoDB会判断前一秒内发生的IO次数是否小于5次，小于5次，认为压力很小，可以执行合并插入缓冲操作。</li>\n<li>至多刷新100个InnoDB的缓冲池中的脏页到磁盘（可能）：InnoDB判断当前缓冲池中脏页的比例（buf_get_modified_ratio_pct）是否超过了配置文件中innodb_max_dirty_pages_pct参数（默认90，代表90%），如果超过了，就要作磁盘同步操作，将100个脏页写入磁盘中。</li>\n<li>如果当前没有用户活动，则切换到background loop（可能）</li>\n</ul>\n<p>每十秒的操作：</p>\n<ul>\n<li><p>刷新100个脏页到磁盘（可能）：InnoDB判断过去10秒内磁盘IO操作是否小于200次，如果是，认为当前有足够的磁盘IO操作能力，则将100个脏页刷新到磁盘</p>\n</li>\n<li><p>合并至多5个插入缓冲（总是）</p>\n</li>\n<li><p>将日志缓冲刷新到磁盘（总是）</p>\n</li>\n<li><p>删除无用的Undo页（总是）：执行full purge操作，删除无用的Undo页，对表进行的update、delete操作，原先的行被标记为删除，但是因为一致性读（consistent read）的关系，要保留这些版本的信息，在full purge过程中，InnoDB会判断当前事务系统中已被删除的行是否可以删除（有时候可能还有查询操作需要读取之前版本的undo信息），如果可以删除，则删除。full purge操作，每次最多尝试回收20个undo页。</p>\n</li>\n<li><p>刷新100个或者10个脏页到磁盘（总是）：InnoDB判断缓冲池中脏页的比例（buf_get_modified_ratio_pct），如果有超过70%的脏页，则刷新100个脏页到磁盘，如果脏页的比例小于70%，则只刷新10%的脏页到磁盘。</p>\n</li>\n</ul>\n<p>background loop的操作：</p>\n<ul>\n<li>删除无用的Undo页（总是）</li>\n<li>合并20个插入缓冲（总是）</li>\n<li>跳回到主循环（总是）</li>\n<li>不断刷新100个页直到符合条件（可能，跳转到flush loop中完成）</li>\n</ul>\n<p>如果flush loop中也没有什么事情可以作了，InnoDB存储引擎会切换到suspend loop，将Master Thread挂起，等待事件的发生。如果用户启用（enable）了InnoDB存储引擎，却没有使用任何InnoDB存储引擎的表，那么Master Thread总是处于挂起的状态。</p>\n<p>Master Thread伪代码如下：</p>\n<pre><code class=\"c\">void master_thread() {\n    goto loop;\n    loop:\n        for(int i = 0; i &lt; 10; i++) {\n            thread_sleep(1) // sleep 1 second\n            do log buffer flush to disk\n            if (last_one_second_ios &lt; 5) {\n                do merge at most 5 insert buffer\n            }\n            if (buf_get_mondified_ratio_pct &gt; innodb_max_dirty_pages_pct) {\n                do buffer pool flush 100 dirty page\n            }\n            if (no user activity) {\n                goto background loop\n            }\n        }\n    if (last_ten_second_ios &lt; 200) {\n        do buffer pool flush 100 dirty page\n    }\n    do merge at most 5 insert buffer\n    do log buffer flush to disk\n    do full purge\n    if (buf_get_modified_ratio_pct &gt; 70%) {\n        do buffer pool flush 100 dirty page\n    } else {\n        buffer pool flush 10 dirty page\n    }\n    goto loop\n    background loop:\n        do full purge\n        do merge 20 insert buffer\n        if not idle:\n            goto loop\n        else\n            goto flush loop\n    flush loop:\n        do buffer pool flush 100 dirty page\n        if (buf_get_modified_radio_pct &gt; innodb_max_dirty_pages_pct) {\n            goto flush loop\n        }\n    goto suspend loop\n    suspend loop:\n        suspend_thread()\n        waiting event\n            goto loop\n}</code></pre>\n<h3 id=\"2-InnoDB-1-2-x版本之前的Master-Thread\"><a href=\"#2-InnoDB-1-2-x版本之前的Master-Thread\" class=\"headerlink\" title=\"2. InnoDB 1.2.x版本之前的Master Thread\"></a>2. InnoDB 1.2.x版本之前的Master Thread</h3><p>几个修改：</p>\n<ol>\n<li><p>1.0.x之前的版本其实对IO是有限制的（很多硬编码，比如刷新100个脏页到磁盘），在磁盘技术飞速发展的今天，当固态磁盘（SSD）出现时，这种规定在很大程度上限制了InnoDB存储引擎对磁盘IO的性能，尤其是写入性能。<br>从InnoDB1.0.x，InnoDB Plugin提供了参数innodb_io_capacity，用来表示磁盘IO的吞吐量，默认值为200，当用户使用了ssd或者磁盘做了RAID，存储设备拥有了更高的IO速度，就可以将innodb_io_capacity调高，直到符合磁盘IO吞吐量。规则如下：</p>\n<ul>\n<li>在合并插入缓存时，合并插入缓存的数量为innodb_io_capacity值的5%</li>\n<li>在从缓冲区刷新脏页时，刷新脏页的数量为innodb_io_capacity</li>\n</ul>\n</li>\n<li><p><code>innodb_max_dirty_pages_pct</code>默认值的问题，在1.0.x版本之前，该值的默认为90，意味着脏页占缓冲池的90%。因为InnoDB存储引擎在每秒刷新缓冲池和flush loop时会判断这个值，如果该值大于<code>innodb_max_dirty_pages_pct</code>才刷新100个脏页，如果有很大的内存，或者数据库服务的压力很大，这时刷新脏页的速度反而会降低，同样，数据库在恢复阶段可能需要更多的时间。1.0.x后<code>innodb_max_diry_pages_pct</code>默认值变为了75，这样既可以加快刷新脏页的频率，又能保证磁盘IO的负载。</p>\n</li>\n<li><p>新增参数<code>innodb_adaptive_flushing</code>，自适应刷新，该值影响每秒刷新脏页的数量。原来的规则时：脏页在缓冲池所占比例小于<code>innodb_max_diry_pages_pct</code>时，不刷新脏页；大于<code>innodb_max_diry_pages_pct</code>时，刷新100个脏页。随着<code>innodb_adaptive_flushing</code>的引入，InnoDB存储引擎会通过一个名为<code>buf_flush_get_desired_flush_rate</code>的函数来判断需要刷新脏页的最合适的数量。<code>buf_flush_get_desired_flush_rate</code>通过判断产生重做日志（redo log）的速度来决定最合适的刷新脏页的数量。因此当脏页的比例小于<code>innodb_max_diry_pages_pct</code>时，也会刷新一定数量的脏页。</p>\n</li>\n<li><p>之前每次进行full purge操作时，最多回收20个Undo页，从InnoDB1.0.x开始引入了参数<code>innodb_purge_batch_size</code>，该参数可以控制每次full purge回收的undu页的数量。该参数的默认值为20，并可以动态的对其进行修改。</p>\n<pre><code>   mysql&gt; show variables like &#39;innodb_purge_batch_size&#39;\\G;\n   Variable_name: innodb_purge_batch_size\n   Value: 20\n   mysql&gt; set global innodb_purge_batch_size=50;\n   Query OK, 0 rows affected (0.00 sec)</code></pre></li>\n</ol>\n<p>综上，1.0.x版本开始，Master Thread伪代码如下：</p>\n<pre><code class=\"c\">void master_thread() {\n   goto loop;\nloop:\nfor(int i=0; i&lt;10; i++) {\n   thread_sleep(1) //sleep 1 second\n   do log buffer flush to disk\n   if(last_one_second_ios &lt; 5% innodb_io_capacity)\n      do merge 5% innodb_io_capacity insert buffer\n   if(buf_get_modified_ratio_pct &gt; innodb_max_dirty_pages_pct) {\n      do buffer pool flush 100% innodb_io_capacity dirty page\n   } else if enable adaptive flush {\n      do buffer pool flush desired amount dirty page\n   }\n   if(no user activity)\n      goto background loop\n}\nif (last_ten_second_ios &lt; innodb_io_capacity)\n   do buffer pool flush 100% innodb_io_capacity dirty page\ndo merge 5% innodb_io_capacity insert buffer\ndo log buffer flush to disk\ndo full purge\nif(buf_get_modified_ratio_pct &gt; 70%)\n   do buffer pool flush 100% innodb_io_capacity dirty page\nelse\n   do buffer pool flush 10% innodb_io_capacity dirty page\ngoto loop\nbackground loop:\ndo full purge\ndo merge 100% innodb_io_capacity insert buffer\nif not idle:\ngoto loop:\nelse:\n   goto flush loop\nflush loop:\ndo buffer pool flush 100% innodb_io_capacity dirty page\nif(buf_get_modified_ratio_pct &gt; innodb_max_dirty_pages_pct)\n   go to flush loop\n   goto suspend loop\nsuspend loop:\nsuspend_thread()\nwaiting event\ngoto loop;\n}</code></pre>\n<h3 id=\"3-InnoDB-1-2-x版本的Master-Thread\"><a href=\"#3-InnoDB-1-2-x版本的Master-Thread\" class=\"headerlink\" title=\"3. InnoDB 1.2.x版本的Master Thread\"></a>3. InnoDB 1.2.x版本的Master Thread</h3><p>在InnoDB1.2.x版本中再次对Master Thread进行了优化，由此可以看出Master Thread对性能所起到的关键作用。在1.2.x版本中，Master Thread的伪代码如下：</p>\n<pre><code class=\"c\">if InnoDB is idle\n   srv_master_do_idle_tasks();\nelse\n   srv_master_do_active_tasks();</code></pre>\n<p>其中<code>srv_master_do_idle_tasks()</code>就是之前版本中的每10秒的操作，<code>srv_master_do_active_tasks()</code>处理的是之前每秒中的操作。同时对于刷新脏页的操作，从Master Thread线程分离到一个单独的Page Cleaner Thread，从而减轻了Master Thread的工作，同时进一步提高了系统的并发性。</p>\n<h2 id=\"6-InnoDB关键特性\"><a href=\"#6-InnoDB关键特性\" class=\"headerlink\" title=\"6. InnoDB关键特性\"></a>6. InnoDB关键特性</h2><p>InnoDB的关键特性包括：</p>\n<ul>\n<li>插入缓冲（Insert Buffer）</li>\n<li>两次写（Double Write）</li>\n<li>自适应哈希索引（Adaptive Hash Index）</li>\n<li>异步IO（Async IO）</li>\n<li>刷新邻接页（Flush Neighbor Page）</li>\n</ul>\n"},{"title":"Java Retry","excerpt":"","comments":1,"date":"2021-03-29T11:30:52.000Z","_content":"\nSpring Retry是Spring提供的声明式重试框架。于2.2.0之后从Spring Batch中独立出来。之前用到了spring retry，本来想自己整理下，没想到在网上找到更好的总结，不仅总结了spring retry，而且还是从最简单的while循环的方式开始，到spring retry，再到guava retry，最后自己还搞了一个集二者大成的重试框架。本想搞个链接放在这里，但是怕回头作者博客迁移找不到了。。\n\n以下为原文：[java retry(重试) spring retry, guava retrying 详解](https://blog.51cto.com/9250070/2156431)\n\n\n## 系列说明\njava retry 的一步步实现机制。\n\n## 情景导入\n\n### 简单的需求\n\n产品经理：实现一个按条件，查询用户信息的服务。\n\n小明：好的。没问题。\n\n代码: \n- UserService.java\n\n```java\npublic interface UserService {\n\n    /**\n     * 根据条件查询用户信息\n     * @param condition 条件\n     * @return User 信息\n     */\n    User queryUser(QueryUserCondition condition);\n\n}\n```\n\n- UserServiceImpl.java\n\n```java\npublic class UserServiceImpl implements UserService {\n\n    private OutService outService;\n\n    public UserServiceImpl(OutService outService) {\n        this.outService = outService;\n    }\n\n    @Override\n    public User queryUser(QueryUserCondition condition) {\n        outService.remoteCall();\n        return new User();\n    }\n\n}\n```\n\n项目经理：这个服务有时候会失败，你看下。\n\n小明：OutService 在是一个 RPC 的外部服务，但是有时候不稳定。\n\n项目经理：如果调用失败了，你可以调用的时候重试几次。你去看下重试相关的东西\n\n### 重试\n#### 重试作用\n对于重试是有场景限制的，不是什么场景都适合重试，比如参数校验不合法、写操作等（要考虑写是否幂等）都不适合重试。\n\n远程调用超时、网络突然中断可以重试。在微服务治理框架中，通常都有自己的重试与超时配置，比如dubbo可以设置retries=1，timeout=500调用失败只重试1次，超过500ms调用仍未返回则调用失败。\n\n比如外部 RPC 调用，或者数据入库等操作，如果一次操作失败，可以进行多次重试，提高调用成功的可能性。\n\n### V1.0 支持重试版本\n思考\n\n小明：我手头还有其他任务，这个也挺简单的。5 分钟时间搞定他。\n\n实现\n\n- UserServiceRetryImpl.java\n\n```java\npublic class UserServiceRetryImpl implements UserService {\n\n    @Override\n    public User queryUser(QueryUserCondition condition) {\n        int times = 0;\n        OutService outService = new AlwaysFailOutServiceImpl();\n\n        while (times < RetryConstant.MAX_TIMES) {\n            try {\n                outService.remoteCall();\n                return new User();\n            } catch (Exception e) {\n                times++;\n\n                if(times >= RetryConstant.MAX_TIMES) {\n                    throw new RuntimeException(e);\n                }\n            }\n        }\n\n        return null;\n    }\n\n}\n```\n\n### V1.1 代理模式版本\n易于维护\n\n项目经理：你的代码我看了，功能虽然实现了，但是尽量写的易于维护一点。\n\n小明：好的。(心想，是说要写点注释什么的？)\n\n代理模式\n\n为其他对象提供一种代理以控制对这个对象的访问。\n\n在某些情况下，一个对象不适合或者不能直接引用另一个对象，而代理对象可以在客户端和目标对象之间起到中介作用。\n\n其特征是代理与委托类有同样的接口。\n\n实现\n\n小明想到以前看过的代理模式，心想用这种方式，原来的代码改动量较少，以后想改起来也方便些。\n\n- UserServiceProxyImpl.java\n\n```java\npublic class UserServiceProxyImpl implements UserService {\n\n    private UserService userService = new UserServiceImpl();\n\n    @Override\n    public User queryUser(QueryUserCondition condition) {\n        int times = 0;\n\n        while (times < RetryConstant.MAX_TIMES) {\n            try {\n                return userService.queryUser(condition);\n            } catch (Exception e) {\n                times++;\n\n                if(times >= RetryConstant.MAX_TIMES) {\n                    throw new RuntimeException(e);\n                }\n            }\n        }\n        return null;\n    }\n\n}\n```\n\n### V1.2 动态代理模式\n\n方便拓展\n\n项目经理：小明啊，这里还有个方法也是同样的问题。你也给加上重试吧。\n\n小明：好的。\n\n小明心想，我在写一个代理，但是转念冷静了下来，如果还有个服务也要重试怎么办呢？\n\n- RoleService.java\n\n```java\npublic interface RoleService {\n\n    /**\n     * 查询\n     * @param user 用户信息\n     * @return 是否拥有权限\n     */\n    boolean hasPrivilege(User user);\n\n}\n```\n代码实现\n\n- DynamicProxy.java\n\n```java\npublic class DynamicProxy implements InvocationHandler {\n\n    private final Object subject;\n\n    public DynamicProxy(Object subject) {\n        this.subject = subject;\n    }\n\n    @Override\n    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {\n        int times = 0;\n\n        while (times < RetryConstant.MAX_TIMES) {\n            try {\n                // 当代理对象调用真实对象的方法时，其会自动的跳转到代理对象关联的handler对象的invoke方法来进行调用\n                return method.invoke(subject, args);\n            } catch (Exception e) {\n                times++;\n\n                if (times >= RetryConstant.MAX_TIMES) {\n                    throw new RuntimeException(e);\n                }\n            }\n        }\n\n        return null;\n    }\n\n    /**\n     * 获取动态代理\n     *\n     * @param realSubject 代理对象\n     */\n    public static Object getProxy(Object realSubject) {\n        //    我们要代理哪个真实对象，就将该对象传进去，最后是通过该真实对象来调用其方法的\n        InvocationHandler handler = new DynamicProxy(realSubject);\n        return Proxy.newProxyInstance(handler.getClass().getClassLoader(),\n                realSubject.getClass().getInterfaces(), handler);\n    }\n\n}\n```\n\n测试代码\n```java\n@Test\npublic void failUserServiceTest() {\n        UserService realService = new UserServiceImpl();\n        UserService proxyService = (UserService) DynamicProxy.getProxy(realService);\n\n        User user = proxyService.queryUser(new QueryUserCondition());\n        LOGGER.info(\"failUserServiceTest: \" + user);\n}\n\n@Test\npublic void roleServiceTest() {\n        RoleService realService = new RoleServiceImpl();\n        RoleService proxyService = (RoleService) DynamicProxy.getProxy(realService);\n\n        boolean hasPrivilege = proxyService.hasPrivilege(new User());\n        LOGGER.info(\"roleServiceTest: \" + hasPrivilege);\n}\n```\n### V1.3 动态代理模式增强\n\n对话\n\n项目经理：小明，你动态代理的方式是挺会偷懒的，可是我们有的类没有接口。这个问题你要解决一下。\n\n小明：好的。(谁？写服务竟然不定义接口)\n\n- ResourceServiceImpl.java\n\n```java\npublic class ResourceServiceImpl {\n\n    /**\n     * 校验资源信息\n     * @param user 入参\n     * @return 是否校验通过\n     */\n    public boolean checkResource(User user) {\n        OutService outService = new AlwaysFailOutServiceImpl();\n        outService.remoteCall();\n        return true;\n    }\n\n}\n```\n\n字节码技术\n\n小明看了下网上的资料，解决的办法还是有的。\n\nCGLIB\n\nCGLIB 是一个功能强大、高性能和高质量的代码生成库，用于扩展JAVA类并在运行时实现接口。\n\njavassist\n\njavassist (Java编程助手)使Java字节码操作变得简单。\n它是Java中编辑字节码的类库;它允许Java程序在运行时定义新类，并在JVM加载类文件时修改类文件。\n与其他类似的字节码编辑器不同，Javassist提供了两个级别的API:源级和字节码级。\n如果用户使用源代码级API，他们可以编辑类文件，而不需要了解Java字节码的规范。\n整个API只使用Java语言的词汇表进行设计。您甚至可以以源文本的形式指定插入的字节码;Javassist动态编译它。\n另一方面，字节码级API允许用户直接编辑类文件作为其他编辑器。\n\nASM\n\nASM 是一个通用的Java字节码操作和分析框架。\n它可以用来修改现有的类或动态地生成类，直接以二进制形式。\nASM提供了一些通用的字节码转换和分析算法，可以从这些算法中构建自定义复杂的转换和代码分析工具。\nASM提供与其他Java字节码框架类似的功能，但主要关注性能。\n因为它的设计和实现都尽可能地小和快，所以非常适合在动态系统中使用(当然也可以以静态的方式使用，例如在编译器中)。\n\n实现\n\n小明看了下，就选择使用 CGLIB。\n\n- CglibProxy.java\n\n```java\npublic class CglibProxy implements MethodInterceptor {\n\n    @Override\n    public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable {\n        int times = 0;\n\n        while (times < RetryConstant.MAX_TIMES) {\n            try {\n                //通过代理子类调用父类的方法\n                return methodProxy.invokeSuper(o, objects);\n            } catch (Exception e) {\n                times++;\n\n                if (times >= RetryConstant.MAX_TIMES) {\n                    throw new RuntimeException(e);\n                }\n            }\n        }\n\n        return null;\n    }\n\n    /**\n     * 获取代理类\n     * @param clazz 类信息\n     * @return 代理类结果\n     */\n    public Object getProxy(Class clazz){\n        Enhancer enhancer = new Enhancer();\n        //目标对象类\n        enhancer.setSuperclass(clazz);\n        enhancer.setCallback(this);\n        //通过字节码技术创建目标对象类的子类实例作为代理\n        return enhancer.create();\n    }\n\n}\n```\n测试\n\n```java\n@Test\npublic void failUserServiceTest() {\n   UserService proxyService = (UserService) new CglibProxy().getProxy(UserServiceImpl.class);\n\n   User user = proxyService.queryUser(new QueryUserCondition());\n   LOGGER.info(\"failUserServiceTest: \" + user);\n}\n\n@Test\npublic void resourceServiceTest() {\n   ResourceServiceImpl proxyService = (ResourceServiceImpl) new CglibProxy().getProxy(ResourceServiceImpl.class);\n   boolean result = proxyService.checkResource(new User());\n   LOGGER.info(\"resourceServiceTest: \" + result);\n}\n```\n\n### V2.0 AOP 实现\n\n对话\n\n项目经理：小明啊，最近我在想一个问题。不同的服务，重试的时候次数应该是不同的。因为服务对稳定性的要求各不相同啊。\n\n小明：好的。(心想，重试都搞了一周了，今天都周五了。)\n\n下班之前，小明一直在想这个问题。刚好周末，花点时间写个重试小工具吧。\n\n设计思路\n\n技术支持\n\nspring\n\njava 注解\n\n注解定义\n注解可在方法上使用，定义需要重试的次数\n\n注解解析\n拦截指定需要重试的方法，解析对应的重试次数，然后进行对应次数的重试。\n\n实现\n\n- Retryable.java\n```java\n@Target({ElementType.METHOD})\n@Retention(RetentionPolicy.RUNTIME)\n@Documented\npublic @interface Retryable {\n\n    /**\n     * Exception type that are retryable.\n     * @return exception type to retry\n     */\n    Class<? extends Throwable> value() default RuntimeException.class;\n\n    /**\n     * 包含第一次失败\n     * @return the maximum number of attempts (including the first failure), defaults to 3\n     */\n    int maxAttempts() default 3;\n\n}\n```\n\n- RetryAspect.java\n\n```java\n@Aspect\n@Component\npublic class RetryAspect {\n\n    @Pointcut(\"execution(public * com.github.houbb.retry.aop..*.*(..)) &&\" +\n                      \"@annotation(com.github.houbb.retry.aop.annotation.Retryable)\")\n    public void myPointcut() {\n    }\n\n    @Around(\"myPointcut()\")\n    public Object around(ProceedingJoinPoint point) throws Throwable {\n        Method method = getCurrentMethod(point);\n        Retryable retryable = method.getAnnotation(Retryable.class);\n\n        //1. 最大次数判断\n        int maxAttempts = retryable.maxAttempts();\n        if (maxAttempts <= 1) {\n            return point.proceed();\n        }\n\n        //2. 异常处理\n        int times = 0;\n        final Class<? extends Throwable> exceptionClass = retryable.value();\n        while (times < maxAttempts) {\n            try {\n                return point.proceed();\n            } catch (Throwable e) {\n                times++;\n\n                // 超过最大重试次数 or 不属于当前处理异常\n                if (times >= maxAttempts ||\n                        !e.getClass().isAssignableFrom(exceptionClass)) {\n                    throw new Throwable(e);\n                }\n            }\n        }\n\n        return null;\n    }\n\n    private Method getCurrentMethod(ProceedingJoinPoint point) {\n        try {\n            Signature sig = point.getSignature();\n            MethodSignature msig = (MethodSignature) sig;\n            Object target = point.getTarget();\n            return target.getClass().getMethod(msig.getName(), msig.getParameterTypes());\n        } catch (NoSuchMethodException e) {\n            throw new RuntimeException(e);\n        }\n    }\n\n}\n```\n\n方法的使用\n\nfiveTimes()\n当前方法一共重试 5 次。\n重试条件：服务抛出 AopRuntimeExption\n\n```java\n@Override\n@Retryable(maxAttempts = 5, value = AopRuntimeExption.class)\npublic void fiveTimes() {\n    LOGGER.info(\"fiveTimes called!\");\n    throw new AopRuntimeExption();\n}\n```\n\n测试日志\n```console\n2018-08-08 15:49:33.814  INFO  [main] com.github.houbb.retry.aop.service.impl.UserServiceImpl:66 - fiveTimes called!\n2018-08-08 15:49:33.815  INFO  [main] com.github.houbb.retry.aop.service.impl.UserServiceImpl:66 - fiveTimes called!\n2018-08-08 15:49:33.815  INFO  [main] com.github.houbb.retry.aop.service.impl.UserServiceImpl:66 - fiveTimes called!\n2018-08-08 15:49:33.815  INFO  [main] com.github.houbb.retry.aop.service.impl.UserServiceImpl:66 - fiveTimes called!\n2018-08-08 15:49:33.815  INFO  [main] com.github.houbb.retry.aop.service.impl.UserServiceImpl:66 - fiveTimes called!\n\njava.lang.reflect.UndeclaredThrowableException\n...\n```\n### V3.0 spring-retry 版本\n对话\n\n周一来到公司，项目经理又和小明谈了起来。\n\n项目经理：重试次数是满足了，但是重试其实应该讲究策略。比如调用外部，第一次失败，可以等待 5S 在次调用，如果又失败了，可以等待 10S 再调用。。。\n\n小明：了解。\n\n思考\n\n可是今天周一，还有其他很多事情要做。\n\n小明在想，没时间写这个呀。看看网上有没有现成的。\n\nspring-retry\n\nSpring Retry 为 Spring 应用程序提供了声明性重试支持。 它用于Spring批处理、Spring集成、Apache Hadoop(等等)的Spring。\n\n在分布式系统中，为了保证数据分布式事务的强一致性，大家在调用RPC接口或者发送MQ时，针对可能会出现网络抖动请求超时情况采取一下重试操作。 大家用的最多的重试方式就是MQ了，但是如果你的项目中没有引入MQ，那就不方便了。\n\n还有一种方式，是开发者自己编写重试机制，但是大多不够优雅。\n\n注解式使用\nRemoteService.java\n重试条件：遇到 RuntimeException\n\n重试次数：3\n\n重试策略：重试的时候等待 5S, 后面时间依次变为原来的 2 倍数。\n\n熔断机制：全部重试失败，则调用 recover() 方法。\n\n```java\n@Service\npublic class RemoteService {\n\n    private static final Logger LOGGER = LoggerFactory.getLogger(RemoteService.class);\n\n    /**\n     * 调用方法\n     */\n    @Retryable(value = RuntimeException.class,\n               maxAttempts = 3,\n               backoff = @Backoff(delay = 5000L, multiplier = 2))\n    public void call() {\n        LOGGER.info(\"Call something...\");\n        throw new RuntimeException(\"RPC调用异常\");\n    }\n\n    /**\n     * recover 机制\n     * @param e 异常\n     */\n    @Recover\n    public void recover(RuntimeException e) {\n        LOGGER.info(\"Start do recover things....\");\n        LOGGER.warn(\"We meet ex: \", e);\n    }\n\n}\n```\n测试\n```java\n@RunWith(SpringRunner.class)\n@SpringBootTest(webEnvironment = SpringBootTest.WebEnvironment.NONE)\npublic class RemoteServiceTest {\n\n    @Autowired\n    private RemoteService remoteService;\n\n    @Test\n    public void test() {\n        remoteService.call();\n    }\n\n}\n```\n日志\n```\n2018-08-08 16:03:26.409  INFO 1433 --- [           main] c.g.h.r.spring.service.RemoteService     : Call something...\n2018-08-08 16:03:31.414  INFO 1433 --- [           main] c.g.h.r.spring.service.RemoteService     : Call something...\n2018-08-08 16:03:41.416  INFO 1433 --- [           main] c.g.h.r.spring.service.RemoteService     : Call something...\n2018-08-08 16:03:41.418  INFO 1433 --- [           main] c.g.h.r.spring.service.RemoteService     : Start do recover things....\n2018-08-08 16:03:41.425  WARN 1433 --- [           main] c.g.h.r.spring.service.RemoteService     : We meet ex: \n\njava.lang.RuntimeException: RPC调用异常\n    at com.github.houbb.retry.spring.service.RemoteService.call(RemoteService.java:38) ~[classes/:na]\n...\n```\n\n三次调用的时间点：\n\n2018-08-08 16:03:26.409 \n\n2018-08-08 16:03:31.414\n\n2018-08-08 16:03:41.416\n\n缺陷\n\nspring-retry 工具虽能优雅实现重试，但是存在两个不友好设计：\n\n一个是重试实体限定为 Throwable 子类，说明重试针对的是可捕捉的功能异常为设计前提的，但是我们希望依赖某个数据对象实体作为重试实体，但sping-retry框架必须强制转换为Throwable子类。\n\n另一个就是重试根源的断言对象使用的是 doWithRetry 的 Exception 异常实例，不符合正常内部断言的返回设计。\n\nSpring Retry 提倡以注解的方式对方法进行重试，重试逻辑是同步执行的，重试的“失败”针对的是Throwable，\n如果你要以返回值的某个状态来判定是否需要重试，可能只能通过自己判断返回值然后显式抛出异常了。\n\n@Recover 注解在使用时无法指定方法，如果一个类中多个重试方法，就会很麻烦。\n\n注解介绍\n\n- @EnableRetry\n\n表示是否开始重试。\n\n|序号|属性|类型|默认值|说明|\n|----|----|----|----|----|\n|1|proxyTargetClass|boolean|false|指示是否要创建基于子类的(CGLIB)代理，而不是创建标准的基于Java接口的代理。\n\n- @Retryable\n\n标注此注解的方法在发生异常时会进行重试\n\n|序号|属性|类型|默认值|说明|\n|----|----|----|----|----|\n|1|interceptor|String|\"\"|将interceptor的bean名称应用到retryable()|\n|2|value|Class[]|{}|可重试的异常类型。|\n|3|label|String|\"\"|统计报告的唯一标签。如果没有提供，调用者可以选择忽略它，或者提供默认值。|\n|4|maxAttempts|int|3|尝试的最大次数(包括第一次失败)，默认为3次。|\n|5|backoff|@Backoff|@Backoff()|指定用于重试此操作的backoff属性。默认为空|\n\n- @Backoff\n\n|序号|属性|类型|默认值|说明|\n|----|----|----|----|----|\n|1|delay|long|0|如果不设置则默认使用1000milliseconds重试等待|\n|2|maxDelay|long|0|最大重试等待时间|\n|3|multiplier|long|0|用于计算下一个延迟延迟的乘数(大于0生效)|\n|4|random|boolean|false|随机重试等待时间|\n\n- @Recover\n\n用于恢复处理程序的方法调用的注释。一个合适的复苏handler有一个类型为可投掷(或可投掷的子类型)的第一个参数和返回与`@Retryable`方法相同的类型的值。可抛出的第一个参数是可选的(但是没有它的方法只会被调用)。从失败方法的参数列表按顺序填充后续的参数。\n\n### 方法式使用\n\n注解式只是让我们使用更加便捷，但是如果要更高的灵活性。可以使用各种提供的方法。\n\n- SimpleDemo.java\n\n```java\npublic class SimpleDemo {\n\n    private static final Logger LOGGER = LoggerFactory.getLogger(SimpleDemo.class);\n\n    public static void main(String[] args) throws Exception {\n        RetryTemplate template = new RetryTemplate();\n\n        // 策略\n        SimpleRetryPolicy policy = new SimpleRetryPolicy();\n        policy.setMaxAttempts(2);\n        template.setRetryPolicy(policy);\n\n        String result = template.execute(\n                new RetryCallback<String, Exception>() {\n                    @Override\n                    public String doWithRetry(RetryContext arg0) {\n                        throw new NullPointerException();\n                    }\n                }\n                ,\n                new RecoveryCallback<String>() {\n                    @Override\n                    public String recover(RetryContext context) {\n                        return \"recovery callback\";\n                    }\n                }\n        );\n\n        LOGGER.info(\"result: {}\", result);\n    }\n\n}\n```\n\n执行日志\n\n```console\n16:30:52.578 [main] DEBUG org.springframework.retry.support.RetryTemplate - Retry: count=0\n16:30:52.591 [main] DEBUG org.springframework.retry.support.RetryTemplate - Checking for rethrow: count=1\n16:30:52.591 [main] DEBUG org.springframework.retry.support.RetryTemplate - Retry: count=1\n16:30:52.591 [main] DEBUG org.springframework.retry.support.RetryTemplate - Checking for rethrow: count=2\n16:30:52.591 [main] DEBUG org.springframework.retry.support.RetryTemplate - Retry failed last attempt: count=2\n16:30:52.592 [main] INFO com.github.houbb.retry.spring.commonway.SimpleDemo - result: recovery callback\n```\n\n### spring-retry 结构\n\n概览\n\n- RetryCallback: 封装你需要重试的业务逻辑（上文中的doSth）\n\n- RecoverCallback：封装在多次重试都失败后你需要执行的业务逻辑(上文中的doSthWhenStillFail)\n\n- RetryContext: 重试语境下的上下文，可用于在多次Retry或者Retry 和Recover之间传递参数或状态（在多次doSth或者doSth与doSthWhenStillFail之间传递参数）\n\n- RetryOperations : 定义了“重试”的基本框架（模板），要求传入RetryCallback，可选传入RecoveryCallback；\n\n- RetryListener：典型的“监听者”，在重试的不同阶段通知“监听者”（例如doSth，wait等阶段时通知）\n\n- RetryPolicy : 重试的策略或条件，可以简单的进行多次重试，可以是指定超时时间进行重试（上文中的someCondition）\n\n- BackOffPolicy: 重试的回退策略，在业务逻辑执行发生异常时。如果需要重试，我们可能需要等一段时间(可能服务器过于繁忙，如果一直不间隔重试可能拖垮服务器)，当然这段时间可以是 0，也可以是固定的，可以是随机的（参见tcp的拥塞控制算法中的回退策略）。回退策略在上文中体现为wait()；\n\n- RetryTemplate: RetryOperations的具体实现，组合了RetryListener[]，BackOffPolicy，RetryPolicy。\n重试策略\n- NeverRetryPolicy：只允许调用RetryCallback一次，不允许重试\n\n- AlwaysRetryPolicy：允许无限重试，直到成功，此方式逻辑不当会导致死循环\n\n- SimpleRetryPolicy：固定次数重试策略，默认重试最大次数为3次，RetryTemplate默认使用的策略\n\n- TimeoutRetryPolicy：超时时间重试策略，默认超时时间为1秒，在指定的超时时间内允许重试\n\n- ExceptionClassifierRetryPolicy：设置不同异常的重试策略，类似组合重试策略，区别在于这里只区分不同异常的重试\n\n- CircuitBreakerRetryPolicy：有熔断功能的重试策略，需设置3个参数openTimeout、resetTimeout和delegate\n\n- CompositeRetryPolicy：组合重试策略，有两种组合方式，乐观组合重试策略是指只要有一个策略允许重试即可以，悲观组合重试策略是指只要有一个策略不允许重试即可以，但不管哪种组合方式，组合中的每一个策略都会执行重试回退策略。重试回退策略，指的是每次重试是立即重试还是等待一段时间后重试。默认情况下是立即重试，如果需要配置等待一段时间后重试则需要指定回退策略BackoffRetryPolicy。\n\n- NoBackOffPolicy：无退避算法策略，每次重试时立即重试\n\n- FixedBackOffPolicy：固定时间的退避策略，需设置参数sleeper和backOffPeriod，sleeper指定等待策略，默认是Thread.sleep，即线程休眠，backOffPeriod指定休眠时间，默认1秒\n\n- UniformRandomBackOffPolicy：随机时间退避策略，需设置sleeper、minBackOffPeriod和maxBackOffPeriod，该策略在[minBackOffPeriod,maxBackOffPeriod之间取一个随机休眠时间，minBackOffPeriod默认500毫秒，maxBackOffPeriod默认1500毫秒\n\n- ExponentialBackOffPolicy：指数退避策略，需设置参数sleeper、initialInterval、maxInterval和multiplier，initialInterval指定初始休眠时间，默认100毫秒，maxInterval指定最大休眠时间，默认30秒，multiplier指定乘数，即下一次休眠时间为当前休眠时间*multiplier\n\n- ExponentialRandomBackOffPolicy：随机指数退避策略，引入随机乘数可以实现随机乘数回退\n\n### guava-retrying\n\n谈话\n\n小华：我们系统也要用到重试\n\n项目经理：小明前段时间用了 spring-retry，分享下应该还不错\n\n小明：spring-retry 基本功能都有，但是必须是基于异常来进行控制。如果你要以返回值的某个状态来判定是否需要重试，可能只能通过自己判断返回值然后显式抛出异常了。\n\n小华：我们项目中想根据对象的属性来进行重试。你可以看下 guava-retry，我很久以前用过，感觉还不错。\n\n小明：好的。\n\n#### guava-retrying\n\nguava-retrying 模块提供了一种通用方法， 可以使用Guava谓词匹配增强的特定停止、重试和异常处理功能来重试任意Java代码。\n\n优势\n\nguava retryer工具与spring-retry类似，都是通过定义重试者角色来包装正常逻辑重试，但是Guava retryer有更优的策略定义，在支持重试次数和重试频度控制基础上，能够兼容支持多个异常或者自定义实体对象的重试源定义，让重试功能有更多的灵活性。\n\nGuava Retryer也是线程安全的，入口调用逻辑采用的是 java.util.concurrent.Callable 的 call() 方法\n\n代码例子\n\n入门案例\n\n遇到异常之后，重试 3 次停止\n\n- HelloDemo.java\n\n```java\npublic static void main(String[] args) {\n    Callable<Boolean> callable = new Callable<Boolean>() {\n        @Override\n        public Boolean call() throws Exception {\n            // do something useful here\n            LOGGER.info(\"call...\");\n            throw new RuntimeException();\n        }\n    };\n\n    Retryer<Boolean> retryer = RetryerBuilder.<Boolean>newBuilder()\n            .retryIfResult(Predicates.isNull())\n            .retryIfExceptionOfType(IOException.class)\n            .retryIfRuntimeException()\n            .withStopStrategy(StopStrategies.stopAfterAttempt(3))\n            .build();\n    try {\n        retryer.call(callable);\n    } catch (RetryException | ExecutionException e) {\n        e.printStackTrace();\n    }\n\n}\n```\n\n日志\n\n```console\n2018-08-08 17:21:12.442  INFO  [main] com.github.houbb.retry.guava.HelloDemo:41 - call...\ncom.github.rholder.retry.RetryException: Retrying failed to complete successfully after 3 attempts.\n2018-08-08 17:21:12.443  INFO  [main] com.github.houbb.retry.guava.HelloDemo:41 - call...\n2018-08-08 17:21:12.444  INFO  [main] com.github.houbb.retry.guava.HelloDemo:41 - call...\n    at com.github.rholder.retry.Retryer.call(Retryer.java:174)\n    at com.github.houbb.retry.guava.HelloDemo.main(HelloDemo.java:53)\nCaused by: java.lang.RuntimeException\n    at com.github.houbb.retry.guava.HelloDemo$1.call(HelloDemo.java:42)\n    at com.github.houbb.retry.guava.HelloDemo$1.call(HelloDemo.java:37)\n    at com.github.rholder.retry.AttemptTimeLimiters$NoAttemptTimeLimit.call(AttemptTimeLimiters.java:78)\n    at com.github.rholder.retry.Retryer.call(Retryer.java:160)\n    ... 1 more\n```\n\n重试策略\n\nExponentialBackoff.java\n\n重试次数：3\n\n重试策略：固定等待 3S\n\n```java\nRetryer<Boolean> retryer = RetryerBuilder.<Boolean>newBuilder()\n                .retryIfResult(Predicates.isNull())\n                .retryIfExceptionOfType(IOException.class)\n                .retryIfRuntimeException()\n                .withWaitStrategy(WaitStrategies.fixedWait(3, TimeUnit.SECONDS))\n                .withStopStrategy(StopStrategies.stopAfterAttempt(3))\n                .build();\n        try {\n            retryer.call(callable);\n        } catch (RetryException | ExecutionException e) {\n            e.printStackTrace();\n        }\n```\n\n日志\n\n```console\n2018-08-08 17:20:41.653  INFO  [main] com.github.houbb.retry.guava.ExponentialBackoff:43 - call...\n2018-08-08 17:20:44.659  INFO  [main] com.github.houbb.retry.guava.ExponentialBackoff:43 - call...\n2018-08-08 17:20:47.664  INFO  [main] com.github.houbb.retry.guava.ExponentialBackoff:43 - call...\ncom.github.rholder.retry.RetryException: Retrying failed to complete successfully after 3 attempts.\n    at com.github.rholder.retry.Retryer.call(Retryer.java:174)\n    at com.github.houbb.retry.guava.ExponentialBackoff.main(ExponentialBackoff.java:56)\nCaused by: java.lang.RuntimeException\n    at com.github.houbb.retry.guava.ExponentialBackoff$1.call(ExponentialBackoff.java:44)\n    at com.github.houbb.retry.guava.ExponentialBackoff$1.call(ExponentialBackoff.java:39)\n    at com.github.rholder.retry.AttemptTimeLimiters$NoAttemptTimeLimit.call(AttemptTimeLimiters.java:78)\n    at com.github.rholder.retry.Retryer.call(Retryer.java:160)\n    ... 1 more\n```\n\n#### guava-retrying 简介\n\n- RetryerBuilder RetryerBuilder 是一个 factory 创建者，可以定制设置重试源且可以支持多个重试源，可以配置重试次数或重试超时时间，以及可以配置等待时间间隔，创建重试者 Retryer 实例。RetryerBuilder 的重试源支持 Exception 异常对象和自定义断言对象，通过retryIfException 和 retryIfResult 设置，同时支持多个且能兼容。\n\n- retryIfException retryIfException，抛出 runtime 异常、checked 异常时都会重试，但是抛出 error 不会重试。\n\n- retryIfRuntimeException retryIfRuntimeException 只会在抛 runtime 异常的时候才重试，checked 异常和error 都不重试。\n\n- retryIfExceptionOfType retryIfExceptionOfType 允许我们只在发生特定异常的时候才重试，比如NullPointerException 和 IllegalStateException 都属于 runtime 异常，也包括自定义的error。\n\n如：　　\n\n```java\nretryIfExceptionOfType(Error.class)// 只在抛出error重试\n```\n当然我们还可以在只有出现指定的异常的时候才重试，如：　\n\n```java　\n.retryIfExceptionOfType(IllegalStateException.class)\n.retryIfExceptionOfType(NullPointerException.class)\n```\n\n或者通过Predicate实现\n\n```java\n.retryIfException(Predicates.or(Predicates.instanceOf(NullPointerException.class),\nPredicates.instanceOf(IllegalStateException.class))) \n```\n\n- retryIfResult retryIfResult 可以指定你的 Callable 方法在返回值的时候进行重试，如　　\n\n```java\n// 返回false重试  \n.retryIfResult(Predicates.equalTo(false))   \n\n//以_error结尾才重试  \n.retryIfResult(Predicates.containsPattern(\"_error$\"))  \n```\n\n- RetryListener 当发生重试之后，假如我们需要做一些额外的处理动作，比如log一下异常，那么可以使用RetryListener。每次重试之后，guava-retrying 会自动回调我们注册的监听。可以注册多个RetryListener，会按照注册顺序依次调用。 　\n\n```java\n.withRetryListener(new RetryListener {      \n @Override    \n   public <T> void onRetry(Attempt<T> attempt) {  \n               logger.error(\"第【{}】次调用失败\" , attempt.getAttemptNumber());  \n          } \n }\n) \n```\n主要接口\n\n|序号|接口|描述|备注|\n|--|--|--|--|\n|1|Attempt|一次执行任务|\n|2|AttemptTimeLimiter|单次任务执行时间限制|如果单次任务执行超时，则终止执行当前任务|\n|3|BlockStrategies|任务阻塞策略|通俗的讲就是当前任务执行完，下次任务还没开始这段时间做什么），默认策略为：BlockStrategies.THREAD_SLEEP_STRATEGY|\n|4|RetryException|重试异常|\n|5|RetryListener|自定义重试监听器|可以用于异步记录错误日志|\n|6|StopStrategy|停止重试策略|\n|7|WaitStrategy|等待时长策略|（控制时间间隔），返回结果为下次执行时长|\n|8|Attempt|一次执行任务|\n|9|Attempt|一次执行任务|\n\nStopStrategy\n\n提供三种：\n\n- StopAfterDelayStrategy 设定一个最长允许的执行时间；比如设定最长执行10s，无论任务执行次数，只要重试的时候超出了最长时间，则任务终止，并返回重试异常RetryException；\n\n- NeverStopStrategy 不停止，用于需要一直轮训知道返回期望结果的情况；\n\n- StopAfterAttemptStrategy 设定最大重试次数，如果超出最大重试次数则停止重试，并返回重试异常；\n\nWaitStrategy\n\n- FixedWaitStrategy 固定等待时长策略；\n\n- RandomWaitStrategy 随机等待时长策略（可以提供一个最小和最大时长，等待时长为其区间随机值）\n\n- IncrementingWaitStrategy 递增等待时长策略（提供一个初始值和步长，等待时间随重试次数增加而增加）\n\n- ExponentialWaitStrategy 指数等待时长策略；\n\n- FibonacciWaitStrategy Fibonacci 等待时长策略；\n\n- ExceptionWaitStrategy 异常时长等待策略；\n\n- CompositeWaitStrategy 复合时长等待策略；\n\n#### 总结\n\n1. 优雅重试共性和原理\n\n正常和重试优雅解耦，重试断言条件实例或逻辑异常实例是两者沟通的媒介。\n\n约定重试间隔，差异性重试策略，设置重试超时时间，进一步保证重试有效性以及重试流程稳定性。\n\n都使用了命令设计模式，通过委托重试对象完成相应的逻辑操作，同时内部封装实现重试逻辑。\n\nspring-retry 和 guava-retry 工具都是线程安全的重试，能够支持并发业务场景的重试逻辑正确性。\n\n2. 优雅重试适用场景\n\n功能逻辑中存在不稳定依赖场景，需要使用重试获取预期结果或者尝试重新执行逻辑不立即结束。比如远程接口访问，数据加载访问，数据上传校验等等。\n\n对于异常场景存在需要重试场景，同时希望把正常逻辑和重试逻辑解耦。\n\n对于需要基于数据媒介交互，希望通过重试轮询检测执行逻辑场景也可以考虑重试方案。\n\n谈话\n\n项目经理：我觉得 guava-retry 挺好的，就是不够方便。小明啊，你给封装个基于注解的吧。\n\n小明：……\n\n更好的实现:\n\n[java重试框架——sisyphus](https://github.com/houbb/sisyphus)","source":"_posts/2021-03-29-kongzheng1993-JavaRetry.md","raw":"---\ntitle: Java Retry\nexcerpt: 'Spring'\ntags: [Spring]\ncategories: [Spring]\ncomments: true\ndate: 2021-03-29 19:30:52\n---\n\nSpring Retry是Spring提供的声明式重试框架。于2.2.0之后从Spring Batch中独立出来。之前用到了spring retry，本来想自己整理下，没想到在网上找到更好的总结，不仅总结了spring retry，而且还是从最简单的while循环的方式开始，到spring retry，再到guava retry，最后自己还搞了一个集二者大成的重试框架。本想搞个链接放在这里，但是怕回头作者博客迁移找不到了。。\n\n以下为原文：[java retry(重试) spring retry, guava retrying 详解](https://blog.51cto.com/9250070/2156431)\n\n\n## 系列说明\njava retry 的一步步实现机制。\n\n## 情景导入\n\n### 简单的需求\n\n产品经理：实现一个按条件，查询用户信息的服务。\n\n小明：好的。没问题。\n\n代码: \n- UserService.java\n\n```java\npublic interface UserService {\n\n    /**\n     * 根据条件查询用户信息\n     * @param condition 条件\n     * @return User 信息\n     */\n    User queryUser(QueryUserCondition condition);\n\n}\n```\n\n- UserServiceImpl.java\n\n```java\npublic class UserServiceImpl implements UserService {\n\n    private OutService outService;\n\n    public UserServiceImpl(OutService outService) {\n        this.outService = outService;\n    }\n\n    @Override\n    public User queryUser(QueryUserCondition condition) {\n        outService.remoteCall();\n        return new User();\n    }\n\n}\n```\n\n项目经理：这个服务有时候会失败，你看下。\n\n小明：OutService 在是一个 RPC 的外部服务，但是有时候不稳定。\n\n项目经理：如果调用失败了，你可以调用的时候重试几次。你去看下重试相关的东西\n\n### 重试\n#### 重试作用\n对于重试是有场景限制的，不是什么场景都适合重试，比如参数校验不合法、写操作等（要考虑写是否幂等）都不适合重试。\n\n远程调用超时、网络突然中断可以重试。在微服务治理框架中，通常都有自己的重试与超时配置，比如dubbo可以设置retries=1，timeout=500调用失败只重试1次，超过500ms调用仍未返回则调用失败。\n\n比如外部 RPC 调用，或者数据入库等操作，如果一次操作失败，可以进行多次重试，提高调用成功的可能性。\n\n### V1.0 支持重试版本\n思考\n\n小明：我手头还有其他任务，这个也挺简单的。5 分钟时间搞定他。\n\n实现\n\n- UserServiceRetryImpl.java\n\n```java\npublic class UserServiceRetryImpl implements UserService {\n\n    @Override\n    public User queryUser(QueryUserCondition condition) {\n        int times = 0;\n        OutService outService = new AlwaysFailOutServiceImpl();\n\n        while (times < RetryConstant.MAX_TIMES) {\n            try {\n                outService.remoteCall();\n                return new User();\n            } catch (Exception e) {\n                times++;\n\n                if(times >= RetryConstant.MAX_TIMES) {\n                    throw new RuntimeException(e);\n                }\n            }\n        }\n\n        return null;\n    }\n\n}\n```\n\n### V1.1 代理模式版本\n易于维护\n\n项目经理：你的代码我看了，功能虽然实现了，但是尽量写的易于维护一点。\n\n小明：好的。(心想，是说要写点注释什么的？)\n\n代理模式\n\n为其他对象提供一种代理以控制对这个对象的访问。\n\n在某些情况下，一个对象不适合或者不能直接引用另一个对象，而代理对象可以在客户端和目标对象之间起到中介作用。\n\n其特征是代理与委托类有同样的接口。\n\n实现\n\n小明想到以前看过的代理模式，心想用这种方式，原来的代码改动量较少，以后想改起来也方便些。\n\n- UserServiceProxyImpl.java\n\n```java\npublic class UserServiceProxyImpl implements UserService {\n\n    private UserService userService = new UserServiceImpl();\n\n    @Override\n    public User queryUser(QueryUserCondition condition) {\n        int times = 0;\n\n        while (times < RetryConstant.MAX_TIMES) {\n            try {\n                return userService.queryUser(condition);\n            } catch (Exception e) {\n                times++;\n\n                if(times >= RetryConstant.MAX_TIMES) {\n                    throw new RuntimeException(e);\n                }\n            }\n        }\n        return null;\n    }\n\n}\n```\n\n### V1.2 动态代理模式\n\n方便拓展\n\n项目经理：小明啊，这里还有个方法也是同样的问题。你也给加上重试吧。\n\n小明：好的。\n\n小明心想，我在写一个代理，但是转念冷静了下来，如果还有个服务也要重试怎么办呢？\n\n- RoleService.java\n\n```java\npublic interface RoleService {\n\n    /**\n     * 查询\n     * @param user 用户信息\n     * @return 是否拥有权限\n     */\n    boolean hasPrivilege(User user);\n\n}\n```\n代码实现\n\n- DynamicProxy.java\n\n```java\npublic class DynamicProxy implements InvocationHandler {\n\n    private final Object subject;\n\n    public DynamicProxy(Object subject) {\n        this.subject = subject;\n    }\n\n    @Override\n    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {\n        int times = 0;\n\n        while (times < RetryConstant.MAX_TIMES) {\n            try {\n                // 当代理对象调用真实对象的方法时，其会自动的跳转到代理对象关联的handler对象的invoke方法来进行调用\n                return method.invoke(subject, args);\n            } catch (Exception e) {\n                times++;\n\n                if (times >= RetryConstant.MAX_TIMES) {\n                    throw new RuntimeException(e);\n                }\n            }\n        }\n\n        return null;\n    }\n\n    /**\n     * 获取动态代理\n     *\n     * @param realSubject 代理对象\n     */\n    public static Object getProxy(Object realSubject) {\n        //    我们要代理哪个真实对象，就将该对象传进去，最后是通过该真实对象来调用其方法的\n        InvocationHandler handler = new DynamicProxy(realSubject);\n        return Proxy.newProxyInstance(handler.getClass().getClassLoader(),\n                realSubject.getClass().getInterfaces(), handler);\n    }\n\n}\n```\n\n测试代码\n```java\n@Test\npublic void failUserServiceTest() {\n        UserService realService = new UserServiceImpl();\n        UserService proxyService = (UserService) DynamicProxy.getProxy(realService);\n\n        User user = proxyService.queryUser(new QueryUserCondition());\n        LOGGER.info(\"failUserServiceTest: \" + user);\n}\n\n@Test\npublic void roleServiceTest() {\n        RoleService realService = new RoleServiceImpl();\n        RoleService proxyService = (RoleService) DynamicProxy.getProxy(realService);\n\n        boolean hasPrivilege = proxyService.hasPrivilege(new User());\n        LOGGER.info(\"roleServiceTest: \" + hasPrivilege);\n}\n```\n### V1.3 动态代理模式增强\n\n对话\n\n项目经理：小明，你动态代理的方式是挺会偷懒的，可是我们有的类没有接口。这个问题你要解决一下。\n\n小明：好的。(谁？写服务竟然不定义接口)\n\n- ResourceServiceImpl.java\n\n```java\npublic class ResourceServiceImpl {\n\n    /**\n     * 校验资源信息\n     * @param user 入参\n     * @return 是否校验通过\n     */\n    public boolean checkResource(User user) {\n        OutService outService = new AlwaysFailOutServiceImpl();\n        outService.remoteCall();\n        return true;\n    }\n\n}\n```\n\n字节码技术\n\n小明看了下网上的资料，解决的办法还是有的。\n\nCGLIB\n\nCGLIB 是一个功能强大、高性能和高质量的代码生成库，用于扩展JAVA类并在运行时实现接口。\n\njavassist\n\njavassist (Java编程助手)使Java字节码操作变得简单。\n它是Java中编辑字节码的类库;它允许Java程序在运行时定义新类，并在JVM加载类文件时修改类文件。\n与其他类似的字节码编辑器不同，Javassist提供了两个级别的API:源级和字节码级。\n如果用户使用源代码级API，他们可以编辑类文件，而不需要了解Java字节码的规范。\n整个API只使用Java语言的词汇表进行设计。您甚至可以以源文本的形式指定插入的字节码;Javassist动态编译它。\n另一方面，字节码级API允许用户直接编辑类文件作为其他编辑器。\n\nASM\n\nASM 是一个通用的Java字节码操作和分析框架。\n它可以用来修改现有的类或动态地生成类，直接以二进制形式。\nASM提供了一些通用的字节码转换和分析算法，可以从这些算法中构建自定义复杂的转换和代码分析工具。\nASM提供与其他Java字节码框架类似的功能，但主要关注性能。\n因为它的设计和实现都尽可能地小和快，所以非常适合在动态系统中使用(当然也可以以静态的方式使用，例如在编译器中)。\n\n实现\n\n小明看了下，就选择使用 CGLIB。\n\n- CglibProxy.java\n\n```java\npublic class CglibProxy implements MethodInterceptor {\n\n    @Override\n    public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable {\n        int times = 0;\n\n        while (times < RetryConstant.MAX_TIMES) {\n            try {\n                //通过代理子类调用父类的方法\n                return methodProxy.invokeSuper(o, objects);\n            } catch (Exception e) {\n                times++;\n\n                if (times >= RetryConstant.MAX_TIMES) {\n                    throw new RuntimeException(e);\n                }\n            }\n        }\n\n        return null;\n    }\n\n    /**\n     * 获取代理类\n     * @param clazz 类信息\n     * @return 代理类结果\n     */\n    public Object getProxy(Class clazz){\n        Enhancer enhancer = new Enhancer();\n        //目标对象类\n        enhancer.setSuperclass(clazz);\n        enhancer.setCallback(this);\n        //通过字节码技术创建目标对象类的子类实例作为代理\n        return enhancer.create();\n    }\n\n}\n```\n测试\n\n```java\n@Test\npublic void failUserServiceTest() {\n   UserService proxyService = (UserService) new CglibProxy().getProxy(UserServiceImpl.class);\n\n   User user = proxyService.queryUser(new QueryUserCondition());\n   LOGGER.info(\"failUserServiceTest: \" + user);\n}\n\n@Test\npublic void resourceServiceTest() {\n   ResourceServiceImpl proxyService = (ResourceServiceImpl) new CglibProxy().getProxy(ResourceServiceImpl.class);\n   boolean result = proxyService.checkResource(new User());\n   LOGGER.info(\"resourceServiceTest: \" + result);\n}\n```\n\n### V2.0 AOP 实现\n\n对话\n\n项目经理：小明啊，最近我在想一个问题。不同的服务，重试的时候次数应该是不同的。因为服务对稳定性的要求各不相同啊。\n\n小明：好的。(心想，重试都搞了一周了，今天都周五了。)\n\n下班之前，小明一直在想这个问题。刚好周末，花点时间写个重试小工具吧。\n\n设计思路\n\n技术支持\n\nspring\n\njava 注解\n\n注解定义\n注解可在方法上使用，定义需要重试的次数\n\n注解解析\n拦截指定需要重试的方法，解析对应的重试次数，然后进行对应次数的重试。\n\n实现\n\n- Retryable.java\n```java\n@Target({ElementType.METHOD})\n@Retention(RetentionPolicy.RUNTIME)\n@Documented\npublic @interface Retryable {\n\n    /**\n     * Exception type that are retryable.\n     * @return exception type to retry\n     */\n    Class<? extends Throwable> value() default RuntimeException.class;\n\n    /**\n     * 包含第一次失败\n     * @return the maximum number of attempts (including the first failure), defaults to 3\n     */\n    int maxAttempts() default 3;\n\n}\n```\n\n- RetryAspect.java\n\n```java\n@Aspect\n@Component\npublic class RetryAspect {\n\n    @Pointcut(\"execution(public * com.github.houbb.retry.aop..*.*(..)) &&\" +\n                      \"@annotation(com.github.houbb.retry.aop.annotation.Retryable)\")\n    public void myPointcut() {\n    }\n\n    @Around(\"myPointcut()\")\n    public Object around(ProceedingJoinPoint point) throws Throwable {\n        Method method = getCurrentMethod(point);\n        Retryable retryable = method.getAnnotation(Retryable.class);\n\n        //1. 最大次数判断\n        int maxAttempts = retryable.maxAttempts();\n        if (maxAttempts <= 1) {\n            return point.proceed();\n        }\n\n        //2. 异常处理\n        int times = 0;\n        final Class<? extends Throwable> exceptionClass = retryable.value();\n        while (times < maxAttempts) {\n            try {\n                return point.proceed();\n            } catch (Throwable e) {\n                times++;\n\n                // 超过最大重试次数 or 不属于当前处理异常\n                if (times >= maxAttempts ||\n                        !e.getClass().isAssignableFrom(exceptionClass)) {\n                    throw new Throwable(e);\n                }\n            }\n        }\n\n        return null;\n    }\n\n    private Method getCurrentMethod(ProceedingJoinPoint point) {\n        try {\n            Signature sig = point.getSignature();\n            MethodSignature msig = (MethodSignature) sig;\n            Object target = point.getTarget();\n            return target.getClass().getMethod(msig.getName(), msig.getParameterTypes());\n        } catch (NoSuchMethodException e) {\n            throw new RuntimeException(e);\n        }\n    }\n\n}\n```\n\n方法的使用\n\nfiveTimes()\n当前方法一共重试 5 次。\n重试条件：服务抛出 AopRuntimeExption\n\n```java\n@Override\n@Retryable(maxAttempts = 5, value = AopRuntimeExption.class)\npublic void fiveTimes() {\n    LOGGER.info(\"fiveTimes called!\");\n    throw new AopRuntimeExption();\n}\n```\n\n测试日志\n```console\n2018-08-08 15:49:33.814  INFO  [main] com.github.houbb.retry.aop.service.impl.UserServiceImpl:66 - fiveTimes called!\n2018-08-08 15:49:33.815  INFO  [main] com.github.houbb.retry.aop.service.impl.UserServiceImpl:66 - fiveTimes called!\n2018-08-08 15:49:33.815  INFO  [main] com.github.houbb.retry.aop.service.impl.UserServiceImpl:66 - fiveTimes called!\n2018-08-08 15:49:33.815  INFO  [main] com.github.houbb.retry.aop.service.impl.UserServiceImpl:66 - fiveTimes called!\n2018-08-08 15:49:33.815  INFO  [main] com.github.houbb.retry.aop.service.impl.UserServiceImpl:66 - fiveTimes called!\n\njava.lang.reflect.UndeclaredThrowableException\n...\n```\n### V3.0 spring-retry 版本\n对话\n\n周一来到公司，项目经理又和小明谈了起来。\n\n项目经理：重试次数是满足了，但是重试其实应该讲究策略。比如调用外部，第一次失败，可以等待 5S 在次调用，如果又失败了，可以等待 10S 再调用。。。\n\n小明：了解。\n\n思考\n\n可是今天周一，还有其他很多事情要做。\n\n小明在想，没时间写这个呀。看看网上有没有现成的。\n\nspring-retry\n\nSpring Retry 为 Spring 应用程序提供了声明性重试支持。 它用于Spring批处理、Spring集成、Apache Hadoop(等等)的Spring。\n\n在分布式系统中，为了保证数据分布式事务的强一致性，大家在调用RPC接口或者发送MQ时，针对可能会出现网络抖动请求超时情况采取一下重试操作。 大家用的最多的重试方式就是MQ了，但是如果你的项目中没有引入MQ，那就不方便了。\n\n还有一种方式，是开发者自己编写重试机制，但是大多不够优雅。\n\n注解式使用\nRemoteService.java\n重试条件：遇到 RuntimeException\n\n重试次数：3\n\n重试策略：重试的时候等待 5S, 后面时间依次变为原来的 2 倍数。\n\n熔断机制：全部重试失败，则调用 recover() 方法。\n\n```java\n@Service\npublic class RemoteService {\n\n    private static final Logger LOGGER = LoggerFactory.getLogger(RemoteService.class);\n\n    /**\n     * 调用方法\n     */\n    @Retryable(value = RuntimeException.class,\n               maxAttempts = 3,\n               backoff = @Backoff(delay = 5000L, multiplier = 2))\n    public void call() {\n        LOGGER.info(\"Call something...\");\n        throw new RuntimeException(\"RPC调用异常\");\n    }\n\n    /**\n     * recover 机制\n     * @param e 异常\n     */\n    @Recover\n    public void recover(RuntimeException e) {\n        LOGGER.info(\"Start do recover things....\");\n        LOGGER.warn(\"We meet ex: \", e);\n    }\n\n}\n```\n测试\n```java\n@RunWith(SpringRunner.class)\n@SpringBootTest(webEnvironment = SpringBootTest.WebEnvironment.NONE)\npublic class RemoteServiceTest {\n\n    @Autowired\n    private RemoteService remoteService;\n\n    @Test\n    public void test() {\n        remoteService.call();\n    }\n\n}\n```\n日志\n```\n2018-08-08 16:03:26.409  INFO 1433 --- [           main] c.g.h.r.spring.service.RemoteService     : Call something...\n2018-08-08 16:03:31.414  INFO 1433 --- [           main] c.g.h.r.spring.service.RemoteService     : Call something...\n2018-08-08 16:03:41.416  INFO 1433 --- [           main] c.g.h.r.spring.service.RemoteService     : Call something...\n2018-08-08 16:03:41.418  INFO 1433 --- [           main] c.g.h.r.spring.service.RemoteService     : Start do recover things....\n2018-08-08 16:03:41.425  WARN 1433 --- [           main] c.g.h.r.spring.service.RemoteService     : We meet ex: \n\njava.lang.RuntimeException: RPC调用异常\n    at com.github.houbb.retry.spring.service.RemoteService.call(RemoteService.java:38) ~[classes/:na]\n...\n```\n\n三次调用的时间点：\n\n2018-08-08 16:03:26.409 \n\n2018-08-08 16:03:31.414\n\n2018-08-08 16:03:41.416\n\n缺陷\n\nspring-retry 工具虽能优雅实现重试，但是存在两个不友好设计：\n\n一个是重试实体限定为 Throwable 子类，说明重试针对的是可捕捉的功能异常为设计前提的，但是我们希望依赖某个数据对象实体作为重试实体，但sping-retry框架必须强制转换为Throwable子类。\n\n另一个就是重试根源的断言对象使用的是 doWithRetry 的 Exception 异常实例，不符合正常内部断言的返回设计。\n\nSpring Retry 提倡以注解的方式对方法进行重试，重试逻辑是同步执行的，重试的“失败”针对的是Throwable，\n如果你要以返回值的某个状态来判定是否需要重试，可能只能通过自己判断返回值然后显式抛出异常了。\n\n@Recover 注解在使用时无法指定方法，如果一个类中多个重试方法，就会很麻烦。\n\n注解介绍\n\n- @EnableRetry\n\n表示是否开始重试。\n\n|序号|属性|类型|默认值|说明|\n|----|----|----|----|----|\n|1|proxyTargetClass|boolean|false|指示是否要创建基于子类的(CGLIB)代理，而不是创建标准的基于Java接口的代理。\n\n- @Retryable\n\n标注此注解的方法在发生异常时会进行重试\n\n|序号|属性|类型|默认值|说明|\n|----|----|----|----|----|\n|1|interceptor|String|\"\"|将interceptor的bean名称应用到retryable()|\n|2|value|Class[]|{}|可重试的异常类型。|\n|3|label|String|\"\"|统计报告的唯一标签。如果没有提供，调用者可以选择忽略它，或者提供默认值。|\n|4|maxAttempts|int|3|尝试的最大次数(包括第一次失败)，默认为3次。|\n|5|backoff|@Backoff|@Backoff()|指定用于重试此操作的backoff属性。默认为空|\n\n- @Backoff\n\n|序号|属性|类型|默认值|说明|\n|----|----|----|----|----|\n|1|delay|long|0|如果不设置则默认使用1000milliseconds重试等待|\n|2|maxDelay|long|0|最大重试等待时间|\n|3|multiplier|long|0|用于计算下一个延迟延迟的乘数(大于0生效)|\n|4|random|boolean|false|随机重试等待时间|\n\n- @Recover\n\n用于恢复处理程序的方法调用的注释。一个合适的复苏handler有一个类型为可投掷(或可投掷的子类型)的第一个参数和返回与`@Retryable`方法相同的类型的值。可抛出的第一个参数是可选的(但是没有它的方法只会被调用)。从失败方法的参数列表按顺序填充后续的参数。\n\n### 方法式使用\n\n注解式只是让我们使用更加便捷，但是如果要更高的灵活性。可以使用各种提供的方法。\n\n- SimpleDemo.java\n\n```java\npublic class SimpleDemo {\n\n    private static final Logger LOGGER = LoggerFactory.getLogger(SimpleDemo.class);\n\n    public static void main(String[] args) throws Exception {\n        RetryTemplate template = new RetryTemplate();\n\n        // 策略\n        SimpleRetryPolicy policy = new SimpleRetryPolicy();\n        policy.setMaxAttempts(2);\n        template.setRetryPolicy(policy);\n\n        String result = template.execute(\n                new RetryCallback<String, Exception>() {\n                    @Override\n                    public String doWithRetry(RetryContext arg0) {\n                        throw new NullPointerException();\n                    }\n                }\n                ,\n                new RecoveryCallback<String>() {\n                    @Override\n                    public String recover(RetryContext context) {\n                        return \"recovery callback\";\n                    }\n                }\n        );\n\n        LOGGER.info(\"result: {}\", result);\n    }\n\n}\n```\n\n执行日志\n\n```console\n16:30:52.578 [main] DEBUG org.springframework.retry.support.RetryTemplate - Retry: count=0\n16:30:52.591 [main] DEBUG org.springframework.retry.support.RetryTemplate - Checking for rethrow: count=1\n16:30:52.591 [main] DEBUG org.springframework.retry.support.RetryTemplate - Retry: count=1\n16:30:52.591 [main] DEBUG org.springframework.retry.support.RetryTemplate - Checking for rethrow: count=2\n16:30:52.591 [main] DEBUG org.springframework.retry.support.RetryTemplate - Retry failed last attempt: count=2\n16:30:52.592 [main] INFO com.github.houbb.retry.spring.commonway.SimpleDemo - result: recovery callback\n```\n\n### spring-retry 结构\n\n概览\n\n- RetryCallback: 封装你需要重试的业务逻辑（上文中的doSth）\n\n- RecoverCallback：封装在多次重试都失败后你需要执行的业务逻辑(上文中的doSthWhenStillFail)\n\n- RetryContext: 重试语境下的上下文，可用于在多次Retry或者Retry 和Recover之间传递参数或状态（在多次doSth或者doSth与doSthWhenStillFail之间传递参数）\n\n- RetryOperations : 定义了“重试”的基本框架（模板），要求传入RetryCallback，可选传入RecoveryCallback；\n\n- RetryListener：典型的“监听者”，在重试的不同阶段通知“监听者”（例如doSth，wait等阶段时通知）\n\n- RetryPolicy : 重试的策略或条件，可以简单的进行多次重试，可以是指定超时时间进行重试（上文中的someCondition）\n\n- BackOffPolicy: 重试的回退策略，在业务逻辑执行发生异常时。如果需要重试，我们可能需要等一段时间(可能服务器过于繁忙，如果一直不间隔重试可能拖垮服务器)，当然这段时间可以是 0，也可以是固定的，可以是随机的（参见tcp的拥塞控制算法中的回退策略）。回退策略在上文中体现为wait()；\n\n- RetryTemplate: RetryOperations的具体实现，组合了RetryListener[]，BackOffPolicy，RetryPolicy。\n重试策略\n- NeverRetryPolicy：只允许调用RetryCallback一次，不允许重试\n\n- AlwaysRetryPolicy：允许无限重试，直到成功，此方式逻辑不当会导致死循环\n\n- SimpleRetryPolicy：固定次数重试策略，默认重试最大次数为3次，RetryTemplate默认使用的策略\n\n- TimeoutRetryPolicy：超时时间重试策略，默认超时时间为1秒，在指定的超时时间内允许重试\n\n- ExceptionClassifierRetryPolicy：设置不同异常的重试策略，类似组合重试策略，区别在于这里只区分不同异常的重试\n\n- CircuitBreakerRetryPolicy：有熔断功能的重试策略，需设置3个参数openTimeout、resetTimeout和delegate\n\n- CompositeRetryPolicy：组合重试策略，有两种组合方式，乐观组合重试策略是指只要有一个策略允许重试即可以，悲观组合重试策略是指只要有一个策略不允许重试即可以，但不管哪种组合方式，组合中的每一个策略都会执行重试回退策略。重试回退策略，指的是每次重试是立即重试还是等待一段时间后重试。默认情况下是立即重试，如果需要配置等待一段时间后重试则需要指定回退策略BackoffRetryPolicy。\n\n- NoBackOffPolicy：无退避算法策略，每次重试时立即重试\n\n- FixedBackOffPolicy：固定时间的退避策略，需设置参数sleeper和backOffPeriod，sleeper指定等待策略，默认是Thread.sleep，即线程休眠，backOffPeriod指定休眠时间，默认1秒\n\n- UniformRandomBackOffPolicy：随机时间退避策略，需设置sleeper、minBackOffPeriod和maxBackOffPeriod，该策略在[minBackOffPeriod,maxBackOffPeriod之间取一个随机休眠时间，minBackOffPeriod默认500毫秒，maxBackOffPeriod默认1500毫秒\n\n- ExponentialBackOffPolicy：指数退避策略，需设置参数sleeper、initialInterval、maxInterval和multiplier，initialInterval指定初始休眠时间，默认100毫秒，maxInterval指定最大休眠时间，默认30秒，multiplier指定乘数，即下一次休眠时间为当前休眠时间*multiplier\n\n- ExponentialRandomBackOffPolicy：随机指数退避策略，引入随机乘数可以实现随机乘数回退\n\n### guava-retrying\n\n谈话\n\n小华：我们系统也要用到重试\n\n项目经理：小明前段时间用了 spring-retry，分享下应该还不错\n\n小明：spring-retry 基本功能都有，但是必须是基于异常来进行控制。如果你要以返回值的某个状态来判定是否需要重试，可能只能通过自己判断返回值然后显式抛出异常了。\n\n小华：我们项目中想根据对象的属性来进行重试。你可以看下 guava-retry，我很久以前用过，感觉还不错。\n\n小明：好的。\n\n#### guava-retrying\n\nguava-retrying 模块提供了一种通用方法， 可以使用Guava谓词匹配增强的特定停止、重试和异常处理功能来重试任意Java代码。\n\n优势\n\nguava retryer工具与spring-retry类似，都是通过定义重试者角色来包装正常逻辑重试，但是Guava retryer有更优的策略定义，在支持重试次数和重试频度控制基础上，能够兼容支持多个异常或者自定义实体对象的重试源定义，让重试功能有更多的灵活性。\n\nGuava Retryer也是线程安全的，入口调用逻辑采用的是 java.util.concurrent.Callable 的 call() 方法\n\n代码例子\n\n入门案例\n\n遇到异常之后，重试 3 次停止\n\n- HelloDemo.java\n\n```java\npublic static void main(String[] args) {\n    Callable<Boolean> callable = new Callable<Boolean>() {\n        @Override\n        public Boolean call() throws Exception {\n            // do something useful here\n            LOGGER.info(\"call...\");\n            throw new RuntimeException();\n        }\n    };\n\n    Retryer<Boolean> retryer = RetryerBuilder.<Boolean>newBuilder()\n            .retryIfResult(Predicates.isNull())\n            .retryIfExceptionOfType(IOException.class)\n            .retryIfRuntimeException()\n            .withStopStrategy(StopStrategies.stopAfterAttempt(3))\n            .build();\n    try {\n        retryer.call(callable);\n    } catch (RetryException | ExecutionException e) {\n        e.printStackTrace();\n    }\n\n}\n```\n\n日志\n\n```console\n2018-08-08 17:21:12.442  INFO  [main] com.github.houbb.retry.guava.HelloDemo:41 - call...\ncom.github.rholder.retry.RetryException: Retrying failed to complete successfully after 3 attempts.\n2018-08-08 17:21:12.443  INFO  [main] com.github.houbb.retry.guava.HelloDemo:41 - call...\n2018-08-08 17:21:12.444  INFO  [main] com.github.houbb.retry.guava.HelloDemo:41 - call...\n    at com.github.rholder.retry.Retryer.call(Retryer.java:174)\n    at com.github.houbb.retry.guava.HelloDemo.main(HelloDemo.java:53)\nCaused by: java.lang.RuntimeException\n    at com.github.houbb.retry.guava.HelloDemo$1.call(HelloDemo.java:42)\n    at com.github.houbb.retry.guava.HelloDemo$1.call(HelloDemo.java:37)\n    at com.github.rholder.retry.AttemptTimeLimiters$NoAttemptTimeLimit.call(AttemptTimeLimiters.java:78)\n    at com.github.rholder.retry.Retryer.call(Retryer.java:160)\n    ... 1 more\n```\n\n重试策略\n\nExponentialBackoff.java\n\n重试次数：3\n\n重试策略：固定等待 3S\n\n```java\nRetryer<Boolean> retryer = RetryerBuilder.<Boolean>newBuilder()\n                .retryIfResult(Predicates.isNull())\n                .retryIfExceptionOfType(IOException.class)\n                .retryIfRuntimeException()\n                .withWaitStrategy(WaitStrategies.fixedWait(3, TimeUnit.SECONDS))\n                .withStopStrategy(StopStrategies.stopAfterAttempt(3))\n                .build();\n        try {\n            retryer.call(callable);\n        } catch (RetryException | ExecutionException e) {\n            e.printStackTrace();\n        }\n```\n\n日志\n\n```console\n2018-08-08 17:20:41.653  INFO  [main] com.github.houbb.retry.guava.ExponentialBackoff:43 - call...\n2018-08-08 17:20:44.659  INFO  [main] com.github.houbb.retry.guava.ExponentialBackoff:43 - call...\n2018-08-08 17:20:47.664  INFO  [main] com.github.houbb.retry.guava.ExponentialBackoff:43 - call...\ncom.github.rholder.retry.RetryException: Retrying failed to complete successfully after 3 attempts.\n    at com.github.rholder.retry.Retryer.call(Retryer.java:174)\n    at com.github.houbb.retry.guava.ExponentialBackoff.main(ExponentialBackoff.java:56)\nCaused by: java.lang.RuntimeException\n    at com.github.houbb.retry.guava.ExponentialBackoff$1.call(ExponentialBackoff.java:44)\n    at com.github.houbb.retry.guava.ExponentialBackoff$1.call(ExponentialBackoff.java:39)\n    at com.github.rholder.retry.AttemptTimeLimiters$NoAttemptTimeLimit.call(AttemptTimeLimiters.java:78)\n    at com.github.rholder.retry.Retryer.call(Retryer.java:160)\n    ... 1 more\n```\n\n#### guava-retrying 简介\n\n- RetryerBuilder RetryerBuilder 是一个 factory 创建者，可以定制设置重试源且可以支持多个重试源，可以配置重试次数或重试超时时间，以及可以配置等待时间间隔，创建重试者 Retryer 实例。RetryerBuilder 的重试源支持 Exception 异常对象和自定义断言对象，通过retryIfException 和 retryIfResult 设置，同时支持多个且能兼容。\n\n- retryIfException retryIfException，抛出 runtime 异常、checked 异常时都会重试，但是抛出 error 不会重试。\n\n- retryIfRuntimeException retryIfRuntimeException 只会在抛 runtime 异常的时候才重试，checked 异常和error 都不重试。\n\n- retryIfExceptionOfType retryIfExceptionOfType 允许我们只在发生特定异常的时候才重试，比如NullPointerException 和 IllegalStateException 都属于 runtime 异常，也包括自定义的error。\n\n如：　　\n\n```java\nretryIfExceptionOfType(Error.class)// 只在抛出error重试\n```\n当然我们还可以在只有出现指定的异常的时候才重试，如：　\n\n```java　\n.retryIfExceptionOfType(IllegalStateException.class)\n.retryIfExceptionOfType(NullPointerException.class)\n```\n\n或者通过Predicate实现\n\n```java\n.retryIfException(Predicates.or(Predicates.instanceOf(NullPointerException.class),\nPredicates.instanceOf(IllegalStateException.class))) \n```\n\n- retryIfResult retryIfResult 可以指定你的 Callable 方法在返回值的时候进行重试，如　　\n\n```java\n// 返回false重试  \n.retryIfResult(Predicates.equalTo(false))   \n\n//以_error结尾才重试  \n.retryIfResult(Predicates.containsPattern(\"_error$\"))  \n```\n\n- RetryListener 当发生重试之后，假如我们需要做一些额外的处理动作，比如log一下异常，那么可以使用RetryListener。每次重试之后，guava-retrying 会自动回调我们注册的监听。可以注册多个RetryListener，会按照注册顺序依次调用。 　\n\n```java\n.withRetryListener(new RetryListener {      \n @Override    \n   public <T> void onRetry(Attempt<T> attempt) {  \n               logger.error(\"第【{}】次调用失败\" , attempt.getAttemptNumber());  \n          } \n }\n) \n```\n主要接口\n\n|序号|接口|描述|备注|\n|--|--|--|--|\n|1|Attempt|一次执行任务|\n|2|AttemptTimeLimiter|单次任务执行时间限制|如果单次任务执行超时，则终止执行当前任务|\n|3|BlockStrategies|任务阻塞策略|通俗的讲就是当前任务执行完，下次任务还没开始这段时间做什么），默认策略为：BlockStrategies.THREAD_SLEEP_STRATEGY|\n|4|RetryException|重试异常|\n|5|RetryListener|自定义重试监听器|可以用于异步记录错误日志|\n|6|StopStrategy|停止重试策略|\n|7|WaitStrategy|等待时长策略|（控制时间间隔），返回结果为下次执行时长|\n|8|Attempt|一次执行任务|\n|9|Attempt|一次执行任务|\n\nStopStrategy\n\n提供三种：\n\n- StopAfterDelayStrategy 设定一个最长允许的执行时间；比如设定最长执行10s，无论任务执行次数，只要重试的时候超出了最长时间，则任务终止，并返回重试异常RetryException；\n\n- NeverStopStrategy 不停止，用于需要一直轮训知道返回期望结果的情况；\n\n- StopAfterAttemptStrategy 设定最大重试次数，如果超出最大重试次数则停止重试，并返回重试异常；\n\nWaitStrategy\n\n- FixedWaitStrategy 固定等待时长策略；\n\n- RandomWaitStrategy 随机等待时长策略（可以提供一个最小和最大时长，等待时长为其区间随机值）\n\n- IncrementingWaitStrategy 递增等待时长策略（提供一个初始值和步长，等待时间随重试次数增加而增加）\n\n- ExponentialWaitStrategy 指数等待时长策略；\n\n- FibonacciWaitStrategy Fibonacci 等待时长策略；\n\n- ExceptionWaitStrategy 异常时长等待策略；\n\n- CompositeWaitStrategy 复合时长等待策略；\n\n#### 总结\n\n1. 优雅重试共性和原理\n\n正常和重试优雅解耦，重试断言条件实例或逻辑异常实例是两者沟通的媒介。\n\n约定重试间隔，差异性重试策略，设置重试超时时间，进一步保证重试有效性以及重试流程稳定性。\n\n都使用了命令设计模式，通过委托重试对象完成相应的逻辑操作，同时内部封装实现重试逻辑。\n\nspring-retry 和 guava-retry 工具都是线程安全的重试，能够支持并发业务场景的重试逻辑正确性。\n\n2. 优雅重试适用场景\n\n功能逻辑中存在不稳定依赖场景，需要使用重试获取预期结果或者尝试重新执行逻辑不立即结束。比如远程接口访问，数据加载访问，数据上传校验等等。\n\n对于异常场景存在需要重试场景，同时希望把正常逻辑和重试逻辑解耦。\n\n对于需要基于数据媒介交互，希望通过重试轮询检测执行逻辑场景也可以考虑重试方案。\n\n谈话\n\n项目经理：我觉得 guava-retry 挺好的，就是不够方便。小明啊，你给封装个基于注解的吧。\n\n小明：……\n\n更好的实现:\n\n[java重试框架——sisyphus](https://github.com/houbb/sisyphus)","slug":"kongzheng1993-JavaRetry","published":1,"updated":"2023-03-08T07:05:58.809Z","layout":"post","photos":[],"link":"","_id":"clg0k2auo00jot26fsllxnm0z","content":"<p>Spring Retry是Spring提供的声明式重试框架。于2.2.0之后从Spring Batch中独立出来。之前用到了spring retry，本来想自己整理下，没想到在网上找到更好的总结，不仅总结了spring retry，而且还是从最简单的while循环的方式开始，到spring retry，再到guava retry，最后自己还搞了一个集二者大成的重试框架。本想搞个链接放在这里，但是怕回头作者博客迁移找不到了。。</p>\n<p>以下为原文：<a href=\"https://blog.51cto.com/9250070/2156431\" target=\"_blank\" rel=\"noopener\">java retry(重试) spring retry, guava retrying 详解</a></p>\n<h2 id=\"系列说明\"><a href=\"#系列说明\" class=\"headerlink\" title=\"系列说明\"></a>系列说明</h2><p>java retry 的一步步实现机制。</p>\n<h2 id=\"情景导入\"><a href=\"#情景导入\" class=\"headerlink\" title=\"情景导入\"></a>情景导入</h2><h3 id=\"简单的需求\"><a href=\"#简单的需求\" class=\"headerlink\" title=\"简单的需求\"></a>简单的需求</h3><p>产品经理：实现一个按条件，查询用户信息的服务。</p>\n<p>小明：好的。没问题。</p>\n<p>代码: </p>\n<ul>\n<li>UserService.java</li>\n</ul>\n<pre><code class=\"java\">public interface UserService {\n\n    /**\n     * 根据条件查询用户信息\n     * @param condition 条件\n     * @return User 信息\n     */\n    User queryUser(QueryUserCondition condition);\n\n}</code></pre>\n<ul>\n<li>UserServiceImpl.java</li>\n</ul>\n<pre><code class=\"java\">public class UserServiceImpl implements UserService {\n\n    private OutService outService;\n\n    public UserServiceImpl(OutService outService) {\n        this.outService = outService;\n    }\n\n    @Override\n    public User queryUser(QueryUserCondition condition) {\n        outService.remoteCall();\n        return new User();\n    }\n\n}</code></pre>\n<p>项目经理：这个服务有时候会失败，你看下。</p>\n<p>小明：OutService 在是一个 RPC 的外部服务，但是有时候不稳定。</p>\n<p>项目经理：如果调用失败了，你可以调用的时候重试几次。你去看下重试相关的东西</p>\n<h3 id=\"重试\"><a href=\"#重试\" class=\"headerlink\" title=\"重试\"></a>重试</h3><h4 id=\"重试作用\"><a href=\"#重试作用\" class=\"headerlink\" title=\"重试作用\"></a>重试作用</h4><p>对于重试是有场景限制的，不是什么场景都适合重试，比如参数校验不合法、写操作等（要考虑写是否幂等）都不适合重试。</p>\n<p>远程调用超时、网络突然中断可以重试。在微服务治理框架中，通常都有自己的重试与超时配置，比如dubbo可以设置retries=1，timeout=500调用失败只重试1次，超过500ms调用仍未返回则调用失败。</p>\n<p>比如外部 RPC 调用，或者数据入库等操作，如果一次操作失败，可以进行多次重试，提高调用成功的可能性。</p>\n<h3 id=\"V1-0-支持重试版本\"><a href=\"#V1-0-支持重试版本\" class=\"headerlink\" title=\"V1.0 支持重试版本\"></a>V1.0 支持重试版本</h3><p>思考</p>\n<p>小明：我手头还有其他任务，这个也挺简单的。5 分钟时间搞定他。</p>\n<p>实现</p>\n<ul>\n<li>UserServiceRetryImpl.java</li>\n</ul>\n<pre><code class=\"java\">public class UserServiceRetryImpl implements UserService {\n\n    @Override\n    public User queryUser(QueryUserCondition condition) {\n        int times = 0;\n        OutService outService = new AlwaysFailOutServiceImpl();\n\n        while (times &lt; RetryConstant.MAX_TIMES) {\n            try {\n                outService.remoteCall();\n                return new User();\n            } catch (Exception e) {\n                times++;\n\n                if(times &gt;= RetryConstant.MAX_TIMES) {\n                    throw new RuntimeException(e);\n                }\n            }\n        }\n\n        return null;\n    }\n\n}</code></pre>\n<h3 id=\"V1-1-代理模式版本\"><a href=\"#V1-1-代理模式版本\" class=\"headerlink\" title=\"V1.1 代理模式版本\"></a>V1.1 代理模式版本</h3><p>易于维护</p>\n<p>项目经理：你的代码我看了，功能虽然实现了，但是尽量写的易于维护一点。</p>\n<p>小明：好的。(心想，是说要写点注释什么的？)</p>\n<p>代理模式</p>\n<p>为其他对象提供一种代理以控制对这个对象的访问。</p>\n<p>在某些情况下，一个对象不适合或者不能直接引用另一个对象，而代理对象可以在客户端和目标对象之间起到中介作用。</p>\n<p>其特征是代理与委托类有同样的接口。</p>\n<p>实现</p>\n<p>小明想到以前看过的代理模式，心想用这种方式，原来的代码改动量较少，以后想改起来也方便些。</p>\n<ul>\n<li>UserServiceProxyImpl.java</li>\n</ul>\n<pre><code class=\"java\">public class UserServiceProxyImpl implements UserService {\n\n    private UserService userService = new UserServiceImpl();\n\n    @Override\n    public User queryUser(QueryUserCondition condition) {\n        int times = 0;\n\n        while (times &lt; RetryConstant.MAX_TIMES) {\n            try {\n                return userService.queryUser(condition);\n            } catch (Exception e) {\n                times++;\n\n                if(times &gt;= RetryConstant.MAX_TIMES) {\n                    throw new RuntimeException(e);\n                }\n            }\n        }\n        return null;\n    }\n\n}</code></pre>\n<h3 id=\"V1-2-动态代理模式\"><a href=\"#V1-2-动态代理模式\" class=\"headerlink\" title=\"V1.2 动态代理模式\"></a>V1.2 动态代理模式</h3><p>方便拓展</p>\n<p>项目经理：小明啊，这里还有个方法也是同样的问题。你也给加上重试吧。</p>\n<p>小明：好的。</p>\n<p>小明心想，我在写一个代理，但是转念冷静了下来，如果还有个服务也要重试怎么办呢？</p>\n<ul>\n<li>RoleService.java</li>\n</ul>\n<pre><code class=\"java\">public interface RoleService {\n\n    /**\n     * 查询\n     * @param user 用户信息\n     * @return 是否拥有权限\n     */\n    boolean hasPrivilege(User user);\n\n}</code></pre>\n<p>代码实现</p>\n<ul>\n<li>DynamicProxy.java</li>\n</ul>\n<pre><code class=\"java\">public class DynamicProxy implements InvocationHandler {\n\n    private final Object subject;\n\n    public DynamicProxy(Object subject) {\n        this.subject = subject;\n    }\n\n    @Override\n    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {\n        int times = 0;\n\n        while (times &lt; RetryConstant.MAX_TIMES) {\n            try {\n                // 当代理对象调用真实对象的方法时，其会自动的跳转到代理对象关联的handler对象的invoke方法来进行调用\n                return method.invoke(subject, args);\n            } catch (Exception e) {\n                times++;\n\n                if (times &gt;= RetryConstant.MAX_TIMES) {\n                    throw new RuntimeException(e);\n                }\n            }\n        }\n\n        return null;\n    }\n\n    /**\n     * 获取动态代理\n     *\n     * @param realSubject 代理对象\n     */\n    public static Object getProxy(Object realSubject) {\n        //    我们要代理哪个真实对象，就将该对象传进去，最后是通过该真实对象来调用其方法的\n        InvocationHandler handler = new DynamicProxy(realSubject);\n        return Proxy.newProxyInstance(handler.getClass().getClassLoader(),\n                realSubject.getClass().getInterfaces(), handler);\n    }\n\n}</code></pre>\n<p>测试代码</p>\n<pre><code class=\"java\">@Test\npublic void failUserServiceTest() {\n        UserService realService = new UserServiceImpl();\n        UserService proxyService = (UserService) DynamicProxy.getProxy(realService);\n\n        User user = proxyService.queryUser(new QueryUserCondition());\n        LOGGER.info(&quot;failUserServiceTest: &quot; + user);\n}\n\n@Test\npublic void roleServiceTest() {\n        RoleService realService = new RoleServiceImpl();\n        RoleService proxyService = (RoleService) DynamicProxy.getProxy(realService);\n\n        boolean hasPrivilege = proxyService.hasPrivilege(new User());\n        LOGGER.info(&quot;roleServiceTest: &quot; + hasPrivilege);\n}</code></pre>\n<h3 id=\"V1-3-动态代理模式增强\"><a href=\"#V1-3-动态代理模式增强\" class=\"headerlink\" title=\"V1.3 动态代理模式增强\"></a>V1.3 动态代理模式增强</h3><p>对话</p>\n<p>项目经理：小明，你动态代理的方式是挺会偷懒的，可是我们有的类没有接口。这个问题你要解决一下。</p>\n<p>小明：好的。(谁？写服务竟然不定义接口)</p>\n<ul>\n<li>ResourceServiceImpl.java</li>\n</ul>\n<pre><code class=\"java\">public class ResourceServiceImpl {\n\n    /**\n     * 校验资源信息\n     * @param user 入参\n     * @return 是否校验通过\n     */\n    public boolean checkResource(User user) {\n        OutService outService = new AlwaysFailOutServiceImpl();\n        outService.remoteCall();\n        return true;\n    }\n\n}</code></pre>\n<p>字节码技术</p>\n<p>小明看了下网上的资料，解决的办法还是有的。</p>\n<p>CGLIB</p>\n<p>CGLIB 是一个功能强大、高性能和高质量的代码生成库，用于扩展JAVA类并在运行时实现接口。</p>\n<p>javassist</p>\n<p>javassist (Java编程助手)使Java字节码操作变得简单。<br>它是Java中编辑字节码的类库;它允许Java程序在运行时定义新类，并在JVM加载类文件时修改类文件。<br>与其他类似的字节码编辑器不同，Javassist提供了两个级别的API:源级和字节码级。<br>如果用户使用源代码级API，他们可以编辑类文件，而不需要了解Java字节码的规范。<br>整个API只使用Java语言的词汇表进行设计。您甚至可以以源文本的形式指定插入的字节码;Javassist动态编译它。<br>另一方面，字节码级API允许用户直接编辑类文件作为其他编辑器。</p>\n<p>ASM</p>\n<p>ASM 是一个通用的Java字节码操作和分析框架。<br>它可以用来修改现有的类或动态地生成类，直接以二进制形式。<br>ASM提供了一些通用的字节码转换和分析算法，可以从这些算法中构建自定义复杂的转换和代码分析工具。<br>ASM提供与其他Java字节码框架类似的功能，但主要关注性能。<br>因为它的设计和实现都尽可能地小和快，所以非常适合在动态系统中使用(当然也可以以静态的方式使用，例如在编译器中)。</p>\n<p>实现</p>\n<p>小明看了下，就选择使用 CGLIB。</p>\n<ul>\n<li>CglibProxy.java</li>\n</ul>\n<pre><code class=\"java\">public class CglibProxy implements MethodInterceptor {\n\n    @Override\n    public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable {\n        int times = 0;\n\n        while (times &lt; RetryConstant.MAX_TIMES) {\n            try {\n                //通过代理子类调用父类的方法\n                return methodProxy.invokeSuper(o, objects);\n            } catch (Exception e) {\n                times++;\n\n                if (times &gt;= RetryConstant.MAX_TIMES) {\n                    throw new RuntimeException(e);\n                }\n            }\n        }\n\n        return null;\n    }\n\n    /**\n     * 获取代理类\n     * @param clazz 类信息\n     * @return 代理类结果\n     */\n    public Object getProxy(Class clazz){\n        Enhancer enhancer = new Enhancer();\n        //目标对象类\n        enhancer.setSuperclass(clazz);\n        enhancer.setCallback(this);\n        //通过字节码技术创建目标对象类的子类实例作为代理\n        return enhancer.create();\n    }\n\n}</code></pre>\n<p>测试</p>\n<pre><code class=\"java\">@Test\npublic void failUserServiceTest() {\n   UserService proxyService = (UserService) new CglibProxy().getProxy(UserServiceImpl.class);\n\n   User user = proxyService.queryUser(new QueryUserCondition());\n   LOGGER.info(&quot;failUserServiceTest: &quot; + user);\n}\n\n@Test\npublic void resourceServiceTest() {\n   ResourceServiceImpl proxyService = (ResourceServiceImpl) new CglibProxy().getProxy(ResourceServiceImpl.class);\n   boolean result = proxyService.checkResource(new User());\n   LOGGER.info(&quot;resourceServiceTest: &quot; + result);\n}</code></pre>\n<h3 id=\"V2-0-AOP-实现\"><a href=\"#V2-0-AOP-实现\" class=\"headerlink\" title=\"V2.0 AOP 实现\"></a>V2.0 AOP 实现</h3><p>对话</p>\n<p>项目经理：小明啊，最近我在想一个问题。不同的服务，重试的时候次数应该是不同的。因为服务对稳定性的要求各不相同啊。</p>\n<p>小明：好的。(心想，重试都搞了一周了，今天都周五了。)</p>\n<p>下班之前，小明一直在想这个问题。刚好周末，花点时间写个重试小工具吧。</p>\n<p>设计思路</p>\n<p>技术支持</p>\n<p>spring</p>\n<p>java 注解</p>\n<p>注解定义<br>注解可在方法上使用，定义需要重试的次数</p>\n<p>注解解析<br>拦截指定需要重试的方法，解析对应的重试次数，然后进行对应次数的重试。</p>\n<p>实现</p>\n<ul>\n<li><p>Retryable.java</p>\n<pre><code class=\"java\">@Target({ElementType.METHOD})\n@Retention(RetentionPolicy.RUNTIME)\n@Documented\npublic @interface Retryable {\n\n  /**\n   * Exception type that are retryable.\n   * @return exception type to retry\n   */\n  Class&lt;? extends Throwable&gt; value() default RuntimeException.class;\n\n  /**\n   * 包含第一次失败\n   * @return the maximum number of attempts (including the first failure), defaults to 3\n   */\n  int maxAttempts() default 3;\n</code></pre>\n</li>\n</ul>\n<p>}</p>\n<pre><code>\n- RetryAspect.java\n\n```java\n@Aspect\n@Component\npublic class RetryAspect {\n\n    @Pointcut(&quot;execution(public * com.github.houbb.retry.aop..*.*(..)) &amp;&amp;&quot; +\n                      &quot;@annotation(com.github.houbb.retry.aop.annotation.Retryable)&quot;)\n    public void myPointcut() {\n    }\n\n    @Around(&quot;myPointcut()&quot;)\n    public Object around(ProceedingJoinPoint point) throws Throwable {\n        Method method = getCurrentMethod(point);\n        Retryable retryable = method.getAnnotation(Retryable.class);\n\n        //1. 最大次数判断\n        int maxAttempts = retryable.maxAttempts();\n        if (maxAttempts &lt;= 1) {\n            return point.proceed();\n        }\n\n        //2. 异常处理\n        int times = 0;\n        final Class&lt;? extends Throwable&gt; exceptionClass = retryable.value();\n        while (times &lt; maxAttempts) {\n            try {\n                return point.proceed();\n            } catch (Throwable e) {\n                times++;\n\n                // 超过最大重试次数 or 不属于当前处理异常\n                if (times &gt;= maxAttempts ||\n                        !e.getClass().isAssignableFrom(exceptionClass)) {\n                    throw new Throwable(e);\n                }\n            }\n        }\n\n        return null;\n    }\n\n    private Method getCurrentMethod(ProceedingJoinPoint point) {\n        try {\n            Signature sig = point.getSignature();\n            MethodSignature msig = (MethodSignature) sig;\n            Object target = point.getTarget();\n            return target.getClass().getMethod(msig.getName(), msig.getParameterTypes());\n        } catch (NoSuchMethodException e) {\n            throw new RuntimeException(e);\n        }\n    }\n\n}</code></pre><p>方法的使用</p>\n<p>fiveTimes()<br>当前方法一共重试 5 次。<br>重试条件：服务抛出 AopRuntimeExption</p>\n<pre><code class=\"java\">@Override\n@Retryable(maxAttempts = 5, value = AopRuntimeExption.class)\npublic void fiveTimes() {\n    LOGGER.info(&quot;fiveTimes called!&quot;);\n    throw new AopRuntimeExption();\n}</code></pre>\n<p>测试日志</p>\n<pre><code class=\"console\">2018-08-08 15:49:33.814  INFO  [main] com.github.houbb.retry.aop.service.impl.UserServiceImpl:66 - fiveTimes called!\n2018-08-08 15:49:33.815  INFO  [main] com.github.houbb.retry.aop.service.impl.UserServiceImpl:66 - fiveTimes called!\n2018-08-08 15:49:33.815  INFO  [main] com.github.houbb.retry.aop.service.impl.UserServiceImpl:66 - fiveTimes called!\n2018-08-08 15:49:33.815  INFO  [main] com.github.houbb.retry.aop.service.impl.UserServiceImpl:66 - fiveTimes called!\n2018-08-08 15:49:33.815  INFO  [main] com.github.houbb.retry.aop.service.impl.UserServiceImpl:66 - fiveTimes called!\n\njava.lang.reflect.UndeclaredThrowableException\n...</code></pre>\n<h3 id=\"V3-0-spring-retry-版本\"><a href=\"#V3-0-spring-retry-版本\" class=\"headerlink\" title=\"V3.0 spring-retry 版本\"></a>V3.0 spring-retry 版本</h3><p>对话</p>\n<p>周一来到公司，项目经理又和小明谈了起来。</p>\n<p>项目经理：重试次数是满足了，但是重试其实应该讲究策略。比如调用外部，第一次失败，可以等待 5S 在次调用，如果又失败了，可以等待 10S 再调用。。。</p>\n<p>小明：了解。</p>\n<p>思考</p>\n<p>可是今天周一，还有其他很多事情要做。</p>\n<p>小明在想，没时间写这个呀。看看网上有没有现成的。</p>\n<p>spring-retry</p>\n<p>Spring Retry 为 Spring 应用程序提供了声明性重试支持。 它用于Spring批处理、Spring集成、Apache Hadoop(等等)的Spring。</p>\n<p>在分布式系统中，为了保证数据分布式事务的强一致性，大家在调用RPC接口或者发送MQ时，针对可能会出现网络抖动请求超时情况采取一下重试操作。 大家用的最多的重试方式就是MQ了，但是如果你的项目中没有引入MQ，那就不方便了。</p>\n<p>还有一种方式，是开发者自己编写重试机制，但是大多不够优雅。</p>\n<p>注解式使用<br>RemoteService.java<br>重试条件：遇到 RuntimeException</p>\n<p>重试次数：3</p>\n<p>重试策略：重试的时候等待 5S, 后面时间依次变为原来的 2 倍数。</p>\n<p>熔断机制：全部重试失败，则调用 recover() 方法。</p>\n<pre><code class=\"java\">@Service\npublic class RemoteService {\n\n    private static final Logger LOGGER = LoggerFactory.getLogger(RemoteService.class);\n\n    /**\n     * 调用方法\n     */\n    @Retryable(value = RuntimeException.class,\n               maxAttempts = 3,\n               backoff = @Backoff(delay = 5000L, multiplier = 2))\n    public void call() {\n        LOGGER.info(&quot;Call something...&quot;);\n        throw new RuntimeException(&quot;RPC调用异常&quot;);\n    }\n\n    /**\n     * recover 机制\n     * @param e 异常\n     */\n    @Recover\n    public void recover(RuntimeException e) {\n        LOGGER.info(&quot;Start do recover things....&quot;);\n        LOGGER.warn(&quot;We meet ex: &quot;, e);\n    }\n\n}</code></pre>\n<p>测试</p>\n<pre><code class=\"java\">@RunWith(SpringRunner.class)\n@SpringBootTest(webEnvironment = SpringBootTest.WebEnvironment.NONE)\npublic class RemoteServiceTest {\n\n    @Autowired\n    private RemoteService remoteService;\n\n    @Test\n    public void test() {\n        remoteService.call();\n    }\n\n}</code></pre>\n<p>日志</p>\n<pre><code>2018-08-08 16:03:26.409  INFO 1433 --- [           main] c.g.h.r.spring.service.RemoteService     : Call something...\n2018-08-08 16:03:31.414  INFO 1433 --- [           main] c.g.h.r.spring.service.RemoteService     : Call something...\n2018-08-08 16:03:41.416  INFO 1433 --- [           main] c.g.h.r.spring.service.RemoteService     : Call something...\n2018-08-08 16:03:41.418  INFO 1433 --- [           main] c.g.h.r.spring.service.RemoteService     : Start do recover things....\n2018-08-08 16:03:41.425  WARN 1433 --- [           main] c.g.h.r.spring.service.RemoteService     : We meet ex: \n\njava.lang.RuntimeException: RPC调用异常\n    at com.github.houbb.retry.spring.service.RemoteService.call(RemoteService.java:38) ~[classes/:na]\n...</code></pre><p>三次调用的时间点：</p>\n<p>2018-08-08 16:03:26.409 </p>\n<p>2018-08-08 16:03:31.414</p>\n<p>2018-08-08 16:03:41.416</p>\n<p>缺陷</p>\n<p>spring-retry 工具虽能优雅实现重试，但是存在两个不友好设计：</p>\n<p>一个是重试实体限定为 Throwable 子类，说明重试针对的是可捕捉的功能异常为设计前提的，但是我们希望依赖某个数据对象实体作为重试实体，但sping-retry框架必须强制转换为Throwable子类。</p>\n<p>另一个就是重试根源的断言对象使用的是 doWithRetry 的 Exception 异常实例，不符合正常内部断言的返回设计。</p>\n<p>Spring Retry 提倡以注解的方式对方法进行重试，重试逻辑是同步执行的，重试的“失败”针对的是Throwable，<br>如果你要以返回值的某个状态来判定是否需要重试，可能只能通过自己判断返回值然后显式抛出异常了。</p>\n<p>@Recover 注解在使用时无法指定方法，如果一个类中多个重试方法，就会很麻烦。</p>\n<p>注解介绍</p>\n<ul>\n<li>@EnableRetry</li>\n</ul>\n<p>表示是否开始重试。</p>\n<table>\n<thead>\n<tr>\n<th>序号</th>\n<th>属性</th>\n<th>类型</th>\n<th>默认值</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>1</td>\n<td>proxyTargetClass</td>\n<td>boolean</td>\n<td>false</td>\n<td>指示是否要创建基于子类的(CGLIB)代理，而不是创建标准的基于Java接口的代理。</td>\n</tr>\n</tbody></table>\n<ul>\n<li>@Retryable</li>\n</ul>\n<p>标注此注解的方法在发生异常时会进行重试</p>\n<table>\n<thead>\n<tr>\n<th>序号</th>\n<th>属性</th>\n<th>类型</th>\n<th>默认值</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>1</td>\n<td>interceptor</td>\n<td>String</td>\n<td>“”</td>\n<td>将interceptor的bean名称应用到retryable()</td>\n</tr>\n<tr>\n<td>2</td>\n<td>value</td>\n<td>Class[]</td>\n<td>{}</td>\n<td>可重试的异常类型。</td>\n</tr>\n<tr>\n<td>3</td>\n<td>label</td>\n<td>String</td>\n<td>“”</td>\n<td>统计报告的唯一标签。如果没有提供，调用者可以选择忽略它，或者提供默认值。</td>\n</tr>\n<tr>\n<td>4</td>\n<td>maxAttempts</td>\n<td>int</td>\n<td>3</td>\n<td>尝试的最大次数(包括第一次失败)，默认为3次。</td>\n</tr>\n<tr>\n<td>5</td>\n<td>backoff</td>\n<td>@Backoff</td>\n<td>@Backoff()</td>\n<td>指定用于重试此操作的backoff属性。默认为空</td>\n</tr>\n</tbody></table>\n<ul>\n<li>@Backoff</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>序号</th>\n<th>属性</th>\n<th>类型</th>\n<th>默认值</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>1</td>\n<td>delay</td>\n<td>long</td>\n<td>0</td>\n<td>如果不设置则默认使用1000milliseconds重试等待</td>\n</tr>\n<tr>\n<td>2</td>\n<td>maxDelay</td>\n<td>long</td>\n<td>0</td>\n<td>最大重试等待时间</td>\n</tr>\n<tr>\n<td>3</td>\n<td>multiplier</td>\n<td>long</td>\n<td>0</td>\n<td>用于计算下一个延迟延迟的乘数(大于0生效)</td>\n</tr>\n<tr>\n<td>4</td>\n<td>random</td>\n<td>boolean</td>\n<td>false</td>\n<td>随机重试等待时间</td>\n</tr>\n</tbody></table>\n<ul>\n<li>@Recover</li>\n</ul>\n<p>用于恢复处理程序的方法调用的注释。一个合适的复苏handler有一个类型为可投掷(或可投掷的子类型)的第一个参数和返回与<code>@Retryable</code>方法相同的类型的值。可抛出的第一个参数是可选的(但是没有它的方法只会被调用)。从失败方法的参数列表按顺序填充后续的参数。</p>\n<h3 id=\"方法式使用\"><a href=\"#方法式使用\" class=\"headerlink\" title=\"方法式使用\"></a>方法式使用</h3><p>注解式只是让我们使用更加便捷，但是如果要更高的灵活性。可以使用各种提供的方法。</p>\n<ul>\n<li>SimpleDemo.java</li>\n</ul>\n<pre><code class=\"java\">public class SimpleDemo {\n\n    private static final Logger LOGGER = LoggerFactory.getLogger(SimpleDemo.class);\n\n    public static void main(String[] args) throws Exception {\n        RetryTemplate template = new RetryTemplate();\n\n        // 策略\n        SimpleRetryPolicy policy = new SimpleRetryPolicy();\n        policy.setMaxAttempts(2);\n        template.setRetryPolicy(policy);\n\n        String result = template.execute(\n                new RetryCallback&lt;String, Exception&gt;() {\n                    @Override\n                    public String doWithRetry(RetryContext arg0) {\n                        throw new NullPointerException();\n                    }\n                }\n                ,\n                new RecoveryCallback&lt;String&gt;() {\n                    @Override\n                    public String recover(RetryContext context) {\n                        return &quot;recovery callback&quot;;\n                    }\n                }\n        );\n\n        LOGGER.info(&quot;result: {}&quot;, result);\n    }\n\n}</code></pre>\n<p>执行日志</p>\n<pre><code class=\"console\">16:30:52.578 [main] DEBUG org.springframework.retry.support.RetryTemplate - Retry: count=0\n16:30:52.591 [main] DEBUG org.springframework.retry.support.RetryTemplate - Checking for rethrow: count=1\n16:30:52.591 [main] DEBUG org.springframework.retry.support.RetryTemplate - Retry: count=1\n16:30:52.591 [main] DEBUG org.springframework.retry.support.RetryTemplate - Checking for rethrow: count=2\n16:30:52.591 [main] DEBUG org.springframework.retry.support.RetryTemplate - Retry failed last attempt: count=2\n16:30:52.592 [main] INFO com.github.houbb.retry.spring.commonway.SimpleDemo - result: recovery callback</code></pre>\n<h3 id=\"spring-retry-结构\"><a href=\"#spring-retry-结构\" class=\"headerlink\" title=\"spring-retry 结构\"></a>spring-retry 结构</h3><p>概览</p>\n<ul>\n<li><p>RetryCallback: 封装你需要重试的业务逻辑（上文中的doSth）</p>\n</li>\n<li><p>RecoverCallback：封装在多次重试都失败后你需要执行的业务逻辑(上文中的doSthWhenStillFail)</p>\n</li>\n<li><p>RetryContext: 重试语境下的上下文，可用于在多次Retry或者Retry 和Recover之间传递参数或状态（在多次doSth或者doSth与doSthWhenStillFail之间传递参数）</p>\n</li>\n<li><p>RetryOperations : 定义了“重试”的基本框架（模板），要求传入RetryCallback，可选传入RecoveryCallback；</p>\n</li>\n<li><p>RetryListener：典型的“监听者”，在重试的不同阶段通知“监听者”（例如doSth，wait等阶段时通知）</p>\n</li>\n<li><p>RetryPolicy : 重试的策略或条件，可以简单的进行多次重试，可以是指定超时时间进行重试（上文中的someCondition）</p>\n</li>\n<li><p>BackOffPolicy: 重试的回退策略，在业务逻辑执行发生异常时。如果需要重试，我们可能需要等一段时间(可能服务器过于繁忙，如果一直不间隔重试可能拖垮服务器)，当然这段时间可以是 0，也可以是固定的，可以是随机的（参见tcp的拥塞控制算法中的回退策略）。回退策略在上文中体现为wait()；</p>\n</li>\n<li><p>RetryTemplate: RetryOperations的具体实现，组合了RetryListener[]，BackOffPolicy，RetryPolicy。<br>重试策略</p>\n</li>\n<li><p>NeverRetryPolicy：只允许调用RetryCallback一次，不允许重试</p>\n</li>\n<li><p>AlwaysRetryPolicy：允许无限重试，直到成功，此方式逻辑不当会导致死循环</p>\n</li>\n<li><p>SimpleRetryPolicy：固定次数重试策略，默认重试最大次数为3次，RetryTemplate默认使用的策略</p>\n</li>\n<li><p>TimeoutRetryPolicy：超时时间重试策略，默认超时时间为1秒，在指定的超时时间内允许重试</p>\n</li>\n<li><p>ExceptionClassifierRetryPolicy：设置不同异常的重试策略，类似组合重试策略，区别在于这里只区分不同异常的重试</p>\n</li>\n<li><p>CircuitBreakerRetryPolicy：有熔断功能的重试策略，需设置3个参数openTimeout、resetTimeout和delegate</p>\n</li>\n<li><p>CompositeRetryPolicy：组合重试策略，有两种组合方式，乐观组合重试策略是指只要有一个策略允许重试即可以，悲观组合重试策略是指只要有一个策略不允许重试即可以，但不管哪种组合方式，组合中的每一个策略都会执行重试回退策略。重试回退策略，指的是每次重试是立即重试还是等待一段时间后重试。默认情况下是立即重试，如果需要配置等待一段时间后重试则需要指定回退策略BackoffRetryPolicy。</p>\n</li>\n<li><p>NoBackOffPolicy：无退避算法策略，每次重试时立即重试</p>\n</li>\n<li><p>FixedBackOffPolicy：固定时间的退避策略，需设置参数sleeper和backOffPeriod，sleeper指定等待策略，默认是Thread.sleep，即线程休眠，backOffPeriod指定休眠时间，默认1秒</p>\n</li>\n<li><p>UniformRandomBackOffPolicy：随机时间退避策略，需设置sleeper、minBackOffPeriod和maxBackOffPeriod，该策略在[minBackOffPeriod,maxBackOffPeriod之间取一个随机休眠时间，minBackOffPeriod默认500毫秒，maxBackOffPeriod默认1500毫秒</p>\n</li>\n<li><p>ExponentialBackOffPolicy：指数退避策略，需设置参数sleeper、initialInterval、maxInterval和multiplier，initialInterval指定初始休眠时间，默认100毫秒，maxInterval指定最大休眠时间，默认30秒，multiplier指定乘数，即下一次休眠时间为当前休眠时间*multiplier</p>\n</li>\n<li><p>ExponentialRandomBackOffPolicy：随机指数退避策略，引入随机乘数可以实现随机乘数回退</p>\n</li>\n</ul>\n<h3 id=\"guava-retrying\"><a href=\"#guava-retrying\" class=\"headerlink\" title=\"guava-retrying\"></a>guava-retrying</h3><p>谈话</p>\n<p>小华：我们系统也要用到重试</p>\n<p>项目经理：小明前段时间用了 spring-retry，分享下应该还不错</p>\n<p>小明：spring-retry 基本功能都有，但是必须是基于异常来进行控制。如果你要以返回值的某个状态来判定是否需要重试，可能只能通过自己判断返回值然后显式抛出异常了。</p>\n<p>小华：我们项目中想根据对象的属性来进行重试。你可以看下 guava-retry，我很久以前用过，感觉还不错。</p>\n<p>小明：好的。</p>\n<h4 id=\"guava-retrying-1\"><a href=\"#guava-retrying-1\" class=\"headerlink\" title=\"guava-retrying\"></a>guava-retrying</h4><p>guava-retrying 模块提供了一种通用方法， 可以使用Guava谓词匹配增强的特定停止、重试和异常处理功能来重试任意Java代码。</p>\n<p>优势</p>\n<p>guava retryer工具与spring-retry类似，都是通过定义重试者角色来包装正常逻辑重试，但是Guava retryer有更优的策略定义，在支持重试次数和重试频度控制基础上，能够兼容支持多个异常或者自定义实体对象的重试源定义，让重试功能有更多的灵活性。</p>\n<p>Guava Retryer也是线程安全的，入口调用逻辑采用的是 java.util.concurrent.Callable 的 call() 方法</p>\n<p>代码例子</p>\n<p>入门案例</p>\n<p>遇到异常之后，重试 3 次停止</p>\n<ul>\n<li>HelloDemo.java</li>\n</ul>\n<pre><code class=\"java\">public static void main(String[] args) {\n    Callable&lt;Boolean&gt; callable = new Callable&lt;Boolean&gt;() {\n        @Override\n        public Boolean call() throws Exception {\n            // do something useful here\n            LOGGER.info(&quot;call...&quot;);\n            throw new RuntimeException();\n        }\n    };\n\n    Retryer&lt;Boolean&gt; retryer = RetryerBuilder.&lt;Boolean&gt;newBuilder()\n            .retryIfResult(Predicates.isNull())\n            .retryIfExceptionOfType(IOException.class)\n            .retryIfRuntimeException()\n            .withStopStrategy(StopStrategies.stopAfterAttempt(3))\n            .build();\n    try {\n        retryer.call(callable);\n    } catch (RetryException | ExecutionException e) {\n        e.printStackTrace();\n    }\n\n}</code></pre>\n<p>日志</p>\n<pre><code class=\"console\">2018-08-08 17:21:12.442  INFO  [main] com.github.houbb.retry.guava.HelloDemo:41 - call...\ncom.github.rholder.retry.RetryException: Retrying failed to complete successfully after 3 attempts.\n2018-08-08 17:21:12.443  INFO  [main] com.github.houbb.retry.guava.HelloDemo:41 - call...\n2018-08-08 17:21:12.444  INFO  [main] com.github.houbb.retry.guava.HelloDemo:41 - call...\n    at com.github.rholder.retry.Retryer.call(Retryer.java:174)\n    at com.github.houbb.retry.guava.HelloDemo.main(HelloDemo.java:53)\nCaused by: java.lang.RuntimeException\n    at com.github.houbb.retry.guava.HelloDemo$1.call(HelloDemo.java:42)\n    at com.github.houbb.retry.guava.HelloDemo$1.call(HelloDemo.java:37)\n    at com.github.rholder.retry.AttemptTimeLimiters$NoAttemptTimeLimit.call(AttemptTimeLimiters.java:78)\n    at com.github.rholder.retry.Retryer.call(Retryer.java:160)\n    ... 1 more</code></pre>\n<p>重试策略</p>\n<p>ExponentialBackoff.java</p>\n<p>重试次数：3</p>\n<p>重试策略：固定等待 3S</p>\n<pre><code class=\"java\">Retryer&lt;Boolean&gt; retryer = RetryerBuilder.&lt;Boolean&gt;newBuilder()\n                .retryIfResult(Predicates.isNull())\n                .retryIfExceptionOfType(IOException.class)\n                .retryIfRuntimeException()\n                .withWaitStrategy(WaitStrategies.fixedWait(3, TimeUnit.SECONDS))\n                .withStopStrategy(StopStrategies.stopAfterAttempt(3))\n                .build();\n        try {\n            retryer.call(callable);\n        } catch (RetryException | ExecutionException e) {\n            e.printStackTrace();\n        }</code></pre>\n<p>日志</p>\n<pre><code class=\"console\">2018-08-08 17:20:41.653  INFO  [main] com.github.houbb.retry.guava.ExponentialBackoff:43 - call...\n2018-08-08 17:20:44.659  INFO  [main] com.github.houbb.retry.guava.ExponentialBackoff:43 - call...\n2018-08-08 17:20:47.664  INFO  [main] com.github.houbb.retry.guava.ExponentialBackoff:43 - call...\ncom.github.rholder.retry.RetryException: Retrying failed to complete successfully after 3 attempts.\n    at com.github.rholder.retry.Retryer.call(Retryer.java:174)\n    at com.github.houbb.retry.guava.ExponentialBackoff.main(ExponentialBackoff.java:56)\nCaused by: java.lang.RuntimeException\n    at com.github.houbb.retry.guava.ExponentialBackoff$1.call(ExponentialBackoff.java:44)\n    at com.github.houbb.retry.guava.ExponentialBackoff$1.call(ExponentialBackoff.java:39)\n    at com.github.rholder.retry.AttemptTimeLimiters$NoAttemptTimeLimit.call(AttemptTimeLimiters.java:78)\n    at com.github.rholder.retry.Retryer.call(Retryer.java:160)\n    ... 1 more</code></pre>\n<h4 id=\"guava-retrying-简介\"><a href=\"#guava-retrying-简介\" class=\"headerlink\" title=\"guava-retrying 简介\"></a>guava-retrying 简介</h4><ul>\n<li><p>RetryerBuilder RetryerBuilder 是一个 factory 创建者，可以定制设置重试源且可以支持多个重试源，可以配置重试次数或重试超时时间，以及可以配置等待时间间隔，创建重试者 Retryer 实例。RetryerBuilder 的重试源支持 Exception 异常对象和自定义断言对象，通过retryIfException 和 retryIfResult 设置，同时支持多个且能兼容。</p>\n</li>\n<li><p>retryIfException retryIfException，抛出 runtime 异常、checked 异常时都会重试，但是抛出 error 不会重试。</p>\n</li>\n<li><p>retryIfRuntimeException retryIfRuntimeException 只会在抛 runtime 异常的时候才重试，checked 异常和error 都不重试。</p>\n</li>\n<li><p>retryIfExceptionOfType retryIfExceptionOfType 允许我们只在发生特定异常的时候才重试，比如NullPointerException 和 IllegalStateException 都属于 runtime 异常，也包括自定义的error。</p>\n</li>\n</ul>\n<p>如：　　</p>\n<pre><code class=\"java\">retryIfExceptionOfType(Error.class)// 只在抛出error重试</code></pre>\n<p>当然我们还可以在只有出现指定的异常的时候才重试，如：　</p>\n<pre><code class=\"java\">.retryIfExceptionOfType(IllegalStateException.class)\n.retryIfExceptionOfType(NullPointerException.class)</code></pre>\n<p>或者通过Predicate实现</p>\n<pre><code class=\"java\">.retryIfException(Predicates.or(Predicates.instanceOf(NullPointerException.class),\nPredicates.instanceOf(IllegalStateException.class))) </code></pre>\n<ul>\n<li>retryIfResult retryIfResult 可以指定你的 Callable 方法在返回值的时候进行重试，如　　</li>\n</ul>\n<pre><code class=\"java\">// 返回false重试  \n.retryIfResult(Predicates.equalTo(false))   \n\n//以_error结尾才重试  \n.retryIfResult(Predicates.containsPattern(&quot;_error$&quot;))  </code></pre>\n<ul>\n<li>RetryListener 当发生重试之后，假如我们需要做一些额外的处理动作，比如log一下异常，那么可以使用RetryListener。每次重试之后，guava-retrying 会自动回调我们注册的监听。可以注册多个RetryListener，会按照注册顺序依次调用。 　</li>\n</ul>\n<pre><code class=\"java\">.withRetryListener(new RetryListener {      \n @Override    \n   public &lt;T&gt; void onRetry(Attempt&lt;T&gt; attempt) {  \n               logger.error(&quot;第【{}】次调用失败&quot; , attempt.getAttemptNumber());  \n          } \n }\n) </code></pre>\n<p>主要接口</p>\n<table>\n<thead>\n<tr>\n<th>序号</th>\n<th>接口</th>\n<th>描述</th>\n<th>备注</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>1</td>\n<td>Attempt</td>\n<td>一次执行任务</td>\n<td></td>\n</tr>\n<tr>\n<td>2</td>\n<td>AttemptTimeLimiter</td>\n<td>单次任务执行时间限制</td>\n<td>如果单次任务执行超时，则终止执行当前任务</td>\n</tr>\n<tr>\n<td>3</td>\n<td>BlockStrategies</td>\n<td>任务阻塞策略</td>\n<td>通俗的讲就是当前任务执行完，下次任务还没开始这段时间做什么），默认策略为：BlockStrategies.THREAD_SLEEP_STRATEGY</td>\n</tr>\n<tr>\n<td>4</td>\n<td>RetryException</td>\n<td>重试异常</td>\n<td></td>\n</tr>\n<tr>\n<td>5</td>\n<td>RetryListener</td>\n<td>自定义重试监听器</td>\n<td>可以用于异步记录错误日志</td>\n</tr>\n<tr>\n<td>6</td>\n<td>StopStrategy</td>\n<td>停止重试策略</td>\n<td></td>\n</tr>\n<tr>\n<td>7</td>\n<td>WaitStrategy</td>\n<td>等待时长策略</td>\n<td>（控制时间间隔），返回结果为下次执行时长</td>\n</tr>\n<tr>\n<td>8</td>\n<td>Attempt</td>\n<td>一次执行任务</td>\n<td></td>\n</tr>\n<tr>\n<td>9</td>\n<td>Attempt</td>\n<td>一次执行任务</td>\n<td></td>\n</tr>\n</tbody></table>\n<p>StopStrategy</p>\n<p>提供三种：</p>\n<ul>\n<li><p>StopAfterDelayStrategy 设定一个最长允许的执行时间；比如设定最长执行10s，无论任务执行次数，只要重试的时候超出了最长时间，则任务终止，并返回重试异常RetryException；</p>\n</li>\n<li><p>NeverStopStrategy 不停止，用于需要一直轮训知道返回期望结果的情况；</p>\n</li>\n<li><p>StopAfterAttemptStrategy 设定最大重试次数，如果超出最大重试次数则停止重试，并返回重试异常；</p>\n</li>\n</ul>\n<p>WaitStrategy</p>\n<ul>\n<li><p>FixedWaitStrategy 固定等待时长策略；</p>\n</li>\n<li><p>RandomWaitStrategy 随机等待时长策略（可以提供一个最小和最大时长，等待时长为其区间随机值）</p>\n</li>\n<li><p>IncrementingWaitStrategy 递增等待时长策略（提供一个初始值和步长，等待时间随重试次数增加而增加）</p>\n</li>\n<li><p>ExponentialWaitStrategy 指数等待时长策略；</p>\n</li>\n<li><p>FibonacciWaitStrategy Fibonacci 等待时长策略；</p>\n</li>\n<li><p>ExceptionWaitStrategy 异常时长等待策略；</p>\n</li>\n<li><p>CompositeWaitStrategy 复合时长等待策略；</p>\n</li>\n</ul>\n<h4 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h4><ol>\n<li>优雅重试共性和原理</li>\n</ol>\n<p>正常和重试优雅解耦，重试断言条件实例或逻辑异常实例是两者沟通的媒介。</p>\n<p>约定重试间隔，差异性重试策略，设置重试超时时间，进一步保证重试有效性以及重试流程稳定性。</p>\n<p>都使用了命令设计模式，通过委托重试对象完成相应的逻辑操作，同时内部封装实现重试逻辑。</p>\n<p>spring-retry 和 guava-retry 工具都是线程安全的重试，能够支持并发业务场景的重试逻辑正确性。</p>\n<ol start=\"2\">\n<li>优雅重试适用场景</li>\n</ol>\n<p>功能逻辑中存在不稳定依赖场景，需要使用重试获取预期结果或者尝试重新执行逻辑不立即结束。比如远程接口访问，数据加载访问，数据上传校验等等。</p>\n<p>对于异常场景存在需要重试场景，同时希望把正常逻辑和重试逻辑解耦。</p>\n<p>对于需要基于数据媒介交互，希望通过重试轮询检测执行逻辑场景也可以考虑重试方案。</p>\n<p>谈话</p>\n<p>项目经理：我觉得 guava-retry 挺好的，就是不够方便。小明啊，你给封装个基于注解的吧。</p>\n<p>小明：……</p>\n<p>更好的实现:</p>\n<p><a href=\"https://github.com/houbb/sisyphus\" target=\"_blank\" rel=\"noopener\">java重试框架——sisyphus</a></p>\n","site":{"data":{}},"more":"<p>Spring Retry是Spring提供的声明式重试框架。于2.2.0之后从Spring Batch中独立出来。之前用到了spring retry，本来想自己整理下，没想到在网上找到更好的总结，不仅总结了spring retry，而且还是从最简单的while循环的方式开始，到spring retry，再到guava retry，最后自己还搞了一个集二者大成的重试框架。本想搞个链接放在这里，但是怕回头作者博客迁移找不到了。。</p>\n<p>以下为原文：<a href=\"https://blog.51cto.com/9250070/2156431\" target=\"_blank\" rel=\"noopener\">java retry(重试) spring retry, guava retrying 详解</a></p>\n<h2 id=\"系列说明\"><a href=\"#系列说明\" class=\"headerlink\" title=\"系列说明\"></a>系列说明</h2><p>java retry 的一步步实现机制。</p>\n<h2 id=\"情景导入\"><a href=\"#情景导入\" class=\"headerlink\" title=\"情景导入\"></a>情景导入</h2><h3 id=\"简单的需求\"><a href=\"#简单的需求\" class=\"headerlink\" title=\"简单的需求\"></a>简单的需求</h3><p>产品经理：实现一个按条件，查询用户信息的服务。</p>\n<p>小明：好的。没问题。</p>\n<p>代码: </p>\n<ul>\n<li>UserService.java</li>\n</ul>\n<pre><code class=\"java\">public interface UserService {\n\n    /**\n     * 根据条件查询用户信息\n     * @param condition 条件\n     * @return User 信息\n     */\n    User queryUser(QueryUserCondition condition);\n\n}</code></pre>\n<ul>\n<li>UserServiceImpl.java</li>\n</ul>\n<pre><code class=\"java\">public class UserServiceImpl implements UserService {\n\n    private OutService outService;\n\n    public UserServiceImpl(OutService outService) {\n        this.outService = outService;\n    }\n\n    @Override\n    public User queryUser(QueryUserCondition condition) {\n        outService.remoteCall();\n        return new User();\n    }\n\n}</code></pre>\n<p>项目经理：这个服务有时候会失败，你看下。</p>\n<p>小明：OutService 在是一个 RPC 的外部服务，但是有时候不稳定。</p>\n<p>项目经理：如果调用失败了，你可以调用的时候重试几次。你去看下重试相关的东西</p>\n<h3 id=\"重试\"><a href=\"#重试\" class=\"headerlink\" title=\"重试\"></a>重试</h3><h4 id=\"重试作用\"><a href=\"#重试作用\" class=\"headerlink\" title=\"重试作用\"></a>重试作用</h4><p>对于重试是有场景限制的，不是什么场景都适合重试，比如参数校验不合法、写操作等（要考虑写是否幂等）都不适合重试。</p>\n<p>远程调用超时、网络突然中断可以重试。在微服务治理框架中，通常都有自己的重试与超时配置，比如dubbo可以设置retries=1，timeout=500调用失败只重试1次，超过500ms调用仍未返回则调用失败。</p>\n<p>比如外部 RPC 调用，或者数据入库等操作，如果一次操作失败，可以进行多次重试，提高调用成功的可能性。</p>\n<h3 id=\"V1-0-支持重试版本\"><a href=\"#V1-0-支持重试版本\" class=\"headerlink\" title=\"V1.0 支持重试版本\"></a>V1.0 支持重试版本</h3><p>思考</p>\n<p>小明：我手头还有其他任务，这个也挺简单的。5 分钟时间搞定他。</p>\n<p>实现</p>\n<ul>\n<li>UserServiceRetryImpl.java</li>\n</ul>\n<pre><code class=\"java\">public class UserServiceRetryImpl implements UserService {\n\n    @Override\n    public User queryUser(QueryUserCondition condition) {\n        int times = 0;\n        OutService outService = new AlwaysFailOutServiceImpl();\n\n        while (times &lt; RetryConstant.MAX_TIMES) {\n            try {\n                outService.remoteCall();\n                return new User();\n            } catch (Exception e) {\n                times++;\n\n                if(times &gt;= RetryConstant.MAX_TIMES) {\n                    throw new RuntimeException(e);\n                }\n            }\n        }\n\n        return null;\n    }\n\n}</code></pre>\n<h3 id=\"V1-1-代理模式版本\"><a href=\"#V1-1-代理模式版本\" class=\"headerlink\" title=\"V1.1 代理模式版本\"></a>V1.1 代理模式版本</h3><p>易于维护</p>\n<p>项目经理：你的代码我看了，功能虽然实现了，但是尽量写的易于维护一点。</p>\n<p>小明：好的。(心想，是说要写点注释什么的？)</p>\n<p>代理模式</p>\n<p>为其他对象提供一种代理以控制对这个对象的访问。</p>\n<p>在某些情况下，一个对象不适合或者不能直接引用另一个对象，而代理对象可以在客户端和目标对象之间起到中介作用。</p>\n<p>其特征是代理与委托类有同样的接口。</p>\n<p>实现</p>\n<p>小明想到以前看过的代理模式，心想用这种方式，原来的代码改动量较少，以后想改起来也方便些。</p>\n<ul>\n<li>UserServiceProxyImpl.java</li>\n</ul>\n<pre><code class=\"java\">public class UserServiceProxyImpl implements UserService {\n\n    private UserService userService = new UserServiceImpl();\n\n    @Override\n    public User queryUser(QueryUserCondition condition) {\n        int times = 0;\n\n        while (times &lt; RetryConstant.MAX_TIMES) {\n            try {\n                return userService.queryUser(condition);\n            } catch (Exception e) {\n                times++;\n\n                if(times &gt;= RetryConstant.MAX_TIMES) {\n                    throw new RuntimeException(e);\n                }\n            }\n        }\n        return null;\n    }\n\n}</code></pre>\n<h3 id=\"V1-2-动态代理模式\"><a href=\"#V1-2-动态代理模式\" class=\"headerlink\" title=\"V1.2 动态代理模式\"></a>V1.2 动态代理模式</h3><p>方便拓展</p>\n<p>项目经理：小明啊，这里还有个方法也是同样的问题。你也给加上重试吧。</p>\n<p>小明：好的。</p>\n<p>小明心想，我在写一个代理，但是转念冷静了下来，如果还有个服务也要重试怎么办呢？</p>\n<ul>\n<li>RoleService.java</li>\n</ul>\n<pre><code class=\"java\">public interface RoleService {\n\n    /**\n     * 查询\n     * @param user 用户信息\n     * @return 是否拥有权限\n     */\n    boolean hasPrivilege(User user);\n\n}</code></pre>\n<p>代码实现</p>\n<ul>\n<li>DynamicProxy.java</li>\n</ul>\n<pre><code class=\"java\">public class DynamicProxy implements InvocationHandler {\n\n    private final Object subject;\n\n    public DynamicProxy(Object subject) {\n        this.subject = subject;\n    }\n\n    @Override\n    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {\n        int times = 0;\n\n        while (times &lt; RetryConstant.MAX_TIMES) {\n            try {\n                // 当代理对象调用真实对象的方法时，其会自动的跳转到代理对象关联的handler对象的invoke方法来进行调用\n                return method.invoke(subject, args);\n            } catch (Exception e) {\n                times++;\n\n                if (times &gt;= RetryConstant.MAX_TIMES) {\n                    throw new RuntimeException(e);\n                }\n            }\n        }\n\n        return null;\n    }\n\n    /**\n     * 获取动态代理\n     *\n     * @param realSubject 代理对象\n     */\n    public static Object getProxy(Object realSubject) {\n        //    我们要代理哪个真实对象，就将该对象传进去，最后是通过该真实对象来调用其方法的\n        InvocationHandler handler = new DynamicProxy(realSubject);\n        return Proxy.newProxyInstance(handler.getClass().getClassLoader(),\n                realSubject.getClass().getInterfaces(), handler);\n    }\n\n}</code></pre>\n<p>测试代码</p>\n<pre><code class=\"java\">@Test\npublic void failUserServiceTest() {\n        UserService realService = new UserServiceImpl();\n        UserService proxyService = (UserService) DynamicProxy.getProxy(realService);\n\n        User user = proxyService.queryUser(new QueryUserCondition());\n        LOGGER.info(&quot;failUserServiceTest: &quot; + user);\n}\n\n@Test\npublic void roleServiceTest() {\n        RoleService realService = new RoleServiceImpl();\n        RoleService proxyService = (RoleService) DynamicProxy.getProxy(realService);\n\n        boolean hasPrivilege = proxyService.hasPrivilege(new User());\n        LOGGER.info(&quot;roleServiceTest: &quot; + hasPrivilege);\n}</code></pre>\n<h3 id=\"V1-3-动态代理模式增强\"><a href=\"#V1-3-动态代理模式增强\" class=\"headerlink\" title=\"V1.3 动态代理模式增强\"></a>V1.3 动态代理模式增强</h3><p>对话</p>\n<p>项目经理：小明，你动态代理的方式是挺会偷懒的，可是我们有的类没有接口。这个问题你要解决一下。</p>\n<p>小明：好的。(谁？写服务竟然不定义接口)</p>\n<ul>\n<li>ResourceServiceImpl.java</li>\n</ul>\n<pre><code class=\"java\">public class ResourceServiceImpl {\n\n    /**\n     * 校验资源信息\n     * @param user 入参\n     * @return 是否校验通过\n     */\n    public boolean checkResource(User user) {\n        OutService outService = new AlwaysFailOutServiceImpl();\n        outService.remoteCall();\n        return true;\n    }\n\n}</code></pre>\n<p>字节码技术</p>\n<p>小明看了下网上的资料，解决的办法还是有的。</p>\n<p>CGLIB</p>\n<p>CGLIB 是一个功能强大、高性能和高质量的代码生成库，用于扩展JAVA类并在运行时实现接口。</p>\n<p>javassist</p>\n<p>javassist (Java编程助手)使Java字节码操作变得简单。<br>它是Java中编辑字节码的类库;它允许Java程序在运行时定义新类，并在JVM加载类文件时修改类文件。<br>与其他类似的字节码编辑器不同，Javassist提供了两个级别的API:源级和字节码级。<br>如果用户使用源代码级API，他们可以编辑类文件，而不需要了解Java字节码的规范。<br>整个API只使用Java语言的词汇表进行设计。您甚至可以以源文本的形式指定插入的字节码;Javassist动态编译它。<br>另一方面，字节码级API允许用户直接编辑类文件作为其他编辑器。</p>\n<p>ASM</p>\n<p>ASM 是一个通用的Java字节码操作和分析框架。<br>它可以用来修改现有的类或动态地生成类，直接以二进制形式。<br>ASM提供了一些通用的字节码转换和分析算法，可以从这些算法中构建自定义复杂的转换和代码分析工具。<br>ASM提供与其他Java字节码框架类似的功能，但主要关注性能。<br>因为它的设计和实现都尽可能地小和快，所以非常适合在动态系统中使用(当然也可以以静态的方式使用，例如在编译器中)。</p>\n<p>实现</p>\n<p>小明看了下，就选择使用 CGLIB。</p>\n<ul>\n<li>CglibProxy.java</li>\n</ul>\n<pre><code class=\"java\">public class CglibProxy implements MethodInterceptor {\n\n    @Override\n    public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable {\n        int times = 0;\n\n        while (times &lt; RetryConstant.MAX_TIMES) {\n            try {\n                //通过代理子类调用父类的方法\n                return methodProxy.invokeSuper(o, objects);\n            } catch (Exception e) {\n                times++;\n\n                if (times &gt;= RetryConstant.MAX_TIMES) {\n                    throw new RuntimeException(e);\n                }\n            }\n        }\n\n        return null;\n    }\n\n    /**\n     * 获取代理类\n     * @param clazz 类信息\n     * @return 代理类结果\n     */\n    public Object getProxy(Class clazz){\n        Enhancer enhancer = new Enhancer();\n        //目标对象类\n        enhancer.setSuperclass(clazz);\n        enhancer.setCallback(this);\n        //通过字节码技术创建目标对象类的子类实例作为代理\n        return enhancer.create();\n    }\n\n}</code></pre>\n<p>测试</p>\n<pre><code class=\"java\">@Test\npublic void failUserServiceTest() {\n   UserService proxyService = (UserService) new CglibProxy().getProxy(UserServiceImpl.class);\n\n   User user = proxyService.queryUser(new QueryUserCondition());\n   LOGGER.info(&quot;failUserServiceTest: &quot; + user);\n}\n\n@Test\npublic void resourceServiceTest() {\n   ResourceServiceImpl proxyService = (ResourceServiceImpl) new CglibProxy().getProxy(ResourceServiceImpl.class);\n   boolean result = proxyService.checkResource(new User());\n   LOGGER.info(&quot;resourceServiceTest: &quot; + result);\n}</code></pre>\n<h3 id=\"V2-0-AOP-实现\"><a href=\"#V2-0-AOP-实现\" class=\"headerlink\" title=\"V2.0 AOP 实现\"></a>V2.0 AOP 实现</h3><p>对话</p>\n<p>项目经理：小明啊，最近我在想一个问题。不同的服务，重试的时候次数应该是不同的。因为服务对稳定性的要求各不相同啊。</p>\n<p>小明：好的。(心想，重试都搞了一周了，今天都周五了。)</p>\n<p>下班之前，小明一直在想这个问题。刚好周末，花点时间写个重试小工具吧。</p>\n<p>设计思路</p>\n<p>技术支持</p>\n<p>spring</p>\n<p>java 注解</p>\n<p>注解定义<br>注解可在方法上使用，定义需要重试的次数</p>\n<p>注解解析<br>拦截指定需要重试的方法，解析对应的重试次数，然后进行对应次数的重试。</p>\n<p>实现</p>\n<ul>\n<li><p>Retryable.java</p>\n<pre><code class=\"java\">@Target({ElementType.METHOD})\n@Retention(RetentionPolicy.RUNTIME)\n@Documented\npublic @interface Retryable {\n\n  /**\n   * Exception type that are retryable.\n   * @return exception type to retry\n   */\n  Class&lt;? extends Throwable&gt; value() default RuntimeException.class;\n\n  /**\n   * 包含第一次失败\n   * @return the maximum number of attempts (including the first failure), defaults to 3\n   */\n  int maxAttempts() default 3;\n</code></pre>\n</li>\n</ul>\n<p>}</p>\n<pre><code>\n- RetryAspect.java\n\n```java\n@Aspect\n@Component\npublic class RetryAspect {\n\n    @Pointcut(&quot;execution(public * com.github.houbb.retry.aop..*.*(..)) &amp;&amp;&quot; +\n                      &quot;@annotation(com.github.houbb.retry.aop.annotation.Retryable)&quot;)\n    public void myPointcut() {\n    }\n\n    @Around(&quot;myPointcut()&quot;)\n    public Object around(ProceedingJoinPoint point) throws Throwable {\n        Method method = getCurrentMethod(point);\n        Retryable retryable = method.getAnnotation(Retryable.class);\n\n        //1. 最大次数判断\n        int maxAttempts = retryable.maxAttempts();\n        if (maxAttempts &lt;= 1) {\n            return point.proceed();\n        }\n\n        //2. 异常处理\n        int times = 0;\n        final Class&lt;? extends Throwable&gt; exceptionClass = retryable.value();\n        while (times &lt; maxAttempts) {\n            try {\n                return point.proceed();\n            } catch (Throwable e) {\n                times++;\n\n                // 超过最大重试次数 or 不属于当前处理异常\n                if (times &gt;= maxAttempts ||\n                        !e.getClass().isAssignableFrom(exceptionClass)) {\n                    throw new Throwable(e);\n                }\n            }\n        }\n\n        return null;\n    }\n\n    private Method getCurrentMethod(ProceedingJoinPoint point) {\n        try {\n            Signature sig = point.getSignature();\n            MethodSignature msig = (MethodSignature) sig;\n            Object target = point.getTarget();\n            return target.getClass().getMethod(msig.getName(), msig.getParameterTypes());\n        } catch (NoSuchMethodException e) {\n            throw new RuntimeException(e);\n        }\n    }\n\n}</code></pre><p>方法的使用</p>\n<p>fiveTimes()<br>当前方法一共重试 5 次。<br>重试条件：服务抛出 AopRuntimeExption</p>\n<pre><code class=\"java\">@Override\n@Retryable(maxAttempts = 5, value = AopRuntimeExption.class)\npublic void fiveTimes() {\n    LOGGER.info(&quot;fiveTimes called!&quot;);\n    throw new AopRuntimeExption();\n}</code></pre>\n<p>测试日志</p>\n<pre><code class=\"console\">2018-08-08 15:49:33.814  INFO  [main] com.github.houbb.retry.aop.service.impl.UserServiceImpl:66 - fiveTimes called!\n2018-08-08 15:49:33.815  INFO  [main] com.github.houbb.retry.aop.service.impl.UserServiceImpl:66 - fiveTimes called!\n2018-08-08 15:49:33.815  INFO  [main] com.github.houbb.retry.aop.service.impl.UserServiceImpl:66 - fiveTimes called!\n2018-08-08 15:49:33.815  INFO  [main] com.github.houbb.retry.aop.service.impl.UserServiceImpl:66 - fiveTimes called!\n2018-08-08 15:49:33.815  INFO  [main] com.github.houbb.retry.aop.service.impl.UserServiceImpl:66 - fiveTimes called!\n\njava.lang.reflect.UndeclaredThrowableException\n...</code></pre>\n<h3 id=\"V3-0-spring-retry-版本\"><a href=\"#V3-0-spring-retry-版本\" class=\"headerlink\" title=\"V3.0 spring-retry 版本\"></a>V3.0 spring-retry 版本</h3><p>对话</p>\n<p>周一来到公司，项目经理又和小明谈了起来。</p>\n<p>项目经理：重试次数是满足了，但是重试其实应该讲究策略。比如调用外部，第一次失败，可以等待 5S 在次调用，如果又失败了，可以等待 10S 再调用。。。</p>\n<p>小明：了解。</p>\n<p>思考</p>\n<p>可是今天周一，还有其他很多事情要做。</p>\n<p>小明在想，没时间写这个呀。看看网上有没有现成的。</p>\n<p>spring-retry</p>\n<p>Spring Retry 为 Spring 应用程序提供了声明性重试支持。 它用于Spring批处理、Spring集成、Apache Hadoop(等等)的Spring。</p>\n<p>在分布式系统中，为了保证数据分布式事务的强一致性，大家在调用RPC接口或者发送MQ时，针对可能会出现网络抖动请求超时情况采取一下重试操作。 大家用的最多的重试方式就是MQ了，但是如果你的项目中没有引入MQ，那就不方便了。</p>\n<p>还有一种方式，是开发者自己编写重试机制，但是大多不够优雅。</p>\n<p>注解式使用<br>RemoteService.java<br>重试条件：遇到 RuntimeException</p>\n<p>重试次数：3</p>\n<p>重试策略：重试的时候等待 5S, 后面时间依次变为原来的 2 倍数。</p>\n<p>熔断机制：全部重试失败，则调用 recover() 方法。</p>\n<pre><code class=\"java\">@Service\npublic class RemoteService {\n\n    private static final Logger LOGGER = LoggerFactory.getLogger(RemoteService.class);\n\n    /**\n     * 调用方法\n     */\n    @Retryable(value = RuntimeException.class,\n               maxAttempts = 3,\n               backoff = @Backoff(delay = 5000L, multiplier = 2))\n    public void call() {\n        LOGGER.info(&quot;Call something...&quot;);\n        throw new RuntimeException(&quot;RPC调用异常&quot;);\n    }\n\n    /**\n     * recover 机制\n     * @param e 异常\n     */\n    @Recover\n    public void recover(RuntimeException e) {\n        LOGGER.info(&quot;Start do recover things....&quot;);\n        LOGGER.warn(&quot;We meet ex: &quot;, e);\n    }\n\n}</code></pre>\n<p>测试</p>\n<pre><code class=\"java\">@RunWith(SpringRunner.class)\n@SpringBootTest(webEnvironment = SpringBootTest.WebEnvironment.NONE)\npublic class RemoteServiceTest {\n\n    @Autowired\n    private RemoteService remoteService;\n\n    @Test\n    public void test() {\n        remoteService.call();\n    }\n\n}</code></pre>\n<p>日志</p>\n<pre><code>2018-08-08 16:03:26.409  INFO 1433 --- [           main] c.g.h.r.spring.service.RemoteService     : Call something...\n2018-08-08 16:03:31.414  INFO 1433 --- [           main] c.g.h.r.spring.service.RemoteService     : Call something...\n2018-08-08 16:03:41.416  INFO 1433 --- [           main] c.g.h.r.spring.service.RemoteService     : Call something...\n2018-08-08 16:03:41.418  INFO 1433 --- [           main] c.g.h.r.spring.service.RemoteService     : Start do recover things....\n2018-08-08 16:03:41.425  WARN 1433 --- [           main] c.g.h.r.spring.service.RemoteService     : We meet ex: \n\njava.lang.RuntimeException: RPC调用异常\n    at com.github.houbb.retry.spring.service.RemoteService.call(RemoteService.java:38) ~[classes/:na]\n...</code></pre><p>三次调用的时间点：</p>\n<p>2018-08-08 16:03:26.409 </p>\n<p>2018-08-08 16:03:31.414</p>\n<p>2018-08-08 16:03:41.416</p>\n<p>缺陷</p>\n<p>spring-retry 工具虽能优雅实现重试，但是存在两个不友好设计：</p>\n<p>一个是重试实体限定为 Throwable 子类，说明重试针对的是可捕捉的功能异常为设计前提的，但是我们希望依赖某个数据对象实体作为重试实体，但sping-retry框架必须强制转换为Throwable子类。</p>\n<p>另一个就是重试根源的断言对象使用的是 doWithRetry 的 Exception 异常实例，不符合正常内部断言的返回设计。</p>\n<p>Spring Retry 提倡以注解的方式对方法进行重试，重试逻辑是同步执行的，重试的“失败”针对的是Throwable，<br>如果你要以返回值的某个状态来判定是否需要重试，可能只能通过自己判断返回值然后显式抛出异常了。</p>\n<p>@Recover 注解在使用时无法指定方法，如果一个类中多个重试方法，就会很麻烦。</p>\n<p>注解介绍</p>\n<ul>\n<li>@EnableRetry</li>\n</ul>\n<p>表示是否开始重试。</p>\n<table>\n<thead>\n<tr>\n<th>序号</th>\n<th>属性</th>\n<th>类型</th>\n<th>默认值</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>1</td>\n<td>proxyTargetClass</td>\n<td>boolean</td>\n<td>false</td>\n<td>指示是否要创建基于子类的(CGLIB)代理，而不是创建标准的基于Java接口的代理。</td>\n</tr>\n</tbody></table>\n<ul>\n<li>@Retryable</li>\n</ul>\n<p>标注此注解的方法在发生异常时会进行重试</p>\n<table>\n<thead>\n<tr>\n<th>序号</th>\n<th>属性</th>\n<th>类型</th>\n<th>默认值</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>1</td>\n<td>interceptor</td>\n<td>String</td>\n<td>“”</td>\n<td>将interceptor的bean名称应用到retryable()</td>\n</tr>\n<tr>\n<td>2</td>\n<td>value</td>\n<td>Class[]</td>\n<td>{}</td>\n<td>可重试的异常类型。</td>\n</tr>\n<tr>\n<td>3</td>\n<td>label</td>\n<td>String</td>\n<td>“”</td>\n<td>统计报告的唯一标签。如果没有提供，调用者可以选择忽略它，或者提供默认值。</td>\n</tr>\n<tr>\n<td>4</td>\n<td>maxAttempts</td>\n<td>int</td>\n<td>3</td>\n<td>尝试的最大次数(包括第一次失败)，默认为3次。</td>\n</tr>\n<tr>\n<td>5</td>\n<td>backoff</td>\n<td>@Backoff</td>\n<td>@Backoff()</td>\n<td>指定用于重试此操作的backoff属性。默认为空</td>\n</tr>\n</tbody></table>\n<ul>\n<li>@Backoff</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>序号</th>\n<th>属性</th>\n<th>类型</th>\n<th>默认值</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>1</td>\n<td>delay</td>\n<td>long</td>\n<td>0</td>\n<td>如果不设置则默认使用1000milliseconds重试等待</td>\n</tr>\n<tr>\n<td>2</td>\n<td>maxDelay</td>\n<td>long</td>\n<td>0</td>\n<td>最大重试等待时间</td>\n</tr>\n<tr>\n<td>3</td>\n<td>multiplier</td>\n<td>long</td>\n<td>0</td>\n<td>用于计算下一个延迟延迟的乘数(大于0生效)</td>\n</tr>\n<tr>\n<td>4</td>\n<td>random</td>\n<td>boolean</td>\n<td>false</td>\n<td>随机重试等待时间</td>\n</tr>\n</tbody></table>\n<ul>\n<li>@Recover</li>\n</ul>\n<p>用于恢复处理程序的方法调用的注释。一个合适的复苏handler有一个类型为可投掷(或可投掷的子类型)的第一个参数和返回与<code>@Retryable</code>方法相同的类型的值。可抛出的第一个参数是可选的(但是没有它的方法只会被调用)。从失败方法的参数列表按顺序填充后续的参数。</p>\n<h3 id=\"方法式使用\"><a href=\"#方法式使用\" class=\"headerlink\" title=\"方法式使用\"></a>方法式使用</h3><p>注解式只是让我们使用更加便捷，但是如果要更高的灵活性。可以使用各种提供的方法。</p>\n<ul>\n<li>SimpleDemo.java</li>\n</ul>\n<pre><code class=\"java\">public class SimpleDemo {\n\n    private static final Logger LOGGER = LoggerFactory.getLogger(SimpleDemo.class);\n\n    public static void main(String[] args) throws Exception {\n        RetryTemplate template = new RetryTemplate();\n\n        // 策略\n        SimpleRetryPolicy policy = new SimpleRetryPolicy();\n        policy.setMaxAttempts(2);\n        template.setRetryPolicy(policy);\n\n        String result = template.execute(\n                new RetryCallback&lt;String, Exception&gt;() {\n                    @Override\n                    public String doWithRetry(RetryContext arg0) {\n                        throw new NullPointerException();\n                    }\n                }\n                ,\n                new RecoveryCallback&lt;String&gt;() {\n                    @Override\n                    public String recover(RetryContext context) {\n                        return &quot;recovery callback&quot;;\n                    }\n                }\n        );\n\n        LOGGER.info(&quot;result: {}&quot;, result);\n    }\n\n}</code></pre>\n<p>执行日志</p>\n<pre><code class=\"console\">16:30:52.578 [main] DEBUG org.springframework.retry.support.RetryTemplate - Retry: count=0\n16:30:52.591 [main] DEBUG org.springframework.retry.support.RetryTemplate - Checking for rethrow: count=1\n16:30:52.591 [main] DEBUG org.springframework.retry.support.RetryTemplate - Retry: count=1\n16:30:52.591 [main] DEBUG org.springframework.retry.support.RetryTemplate - Checking for rethrow: count=2\n16:30:52.591 [main] DEBUG org.springframework.retry.support.RetryTemplate - Retry failed last attempt: count=2\n16:30:52.592 [main] INFO com.github.houbb.retry.spring.commonway.SimpleDemo - result: recovery callback</code></pre>\n<h3 id=\"spring-retry-结构\"><a href=\"#spring-retry-结构\" class=\"headerlink\" title=\"spring-retry 结构\"></a>spring-retry 结构</h3><p>概览</p>\n<ul>\n<li><p>RetryCallback: 封装你需要重试的业务逻辑（上文中的doSth）</p>\n</li>\n<li><p>RecoverCallback：封装在多次重试都失败后你需要执行的业务逻辑(上文中的doSthWhenStillFail)</p>\n</li>\n<li><p>RetryContext: 重试语境下的上下文，可用于在多次Retry或者Retry 和Recover之间传递参数或状态（在多次doSth或者doSth与doSthWhenStillFail之间传递参数）</p>\n</li>\n<li><p>RetryOperations : 定义了“重试”的基本框架（模板），要求传入RetryCallback，可选传入RecoveryCallback；</p>\n</li>\n<li><p>RetryListener：典型的“监听者”，在重试的不同阶段通知“监听者”（例如doSth，wait等阶段时通知）</p>\n</li>\n<li><p>RetryPolicy : 重试的策略或条件，可以简单的进行多次重试，可以是指定超时时间进行重试（上文中的someCondition）</p>\n</li>\n<li><p>BackOffPolicy: 重试的回退策略，在业务逻辑执行发生异常时。如果需要重试，我们可能需要等一段时间(可能服务器过于繁忙，如果一直不间隔重试可能拖垮服务器)，当然这段时间可以是 0，也可以是固定的，可以是随机的（参见tcp的拥塞控制算法中的回退策略）。回退策略在上文中体现为wait()；</p>\n</li>\n<li><p>RetryTemplate: RetryOperations的具体实现，组合了RetryListener[]，BackOffPolicy，RetryPolicy。<br>重试策略</p>\n</li>\n<li><p>NeverRetryPolicy：只允许调用RetryCallback一次，不允许重试</p>\n</li>\n<li><p>AlwaysRetryPolicy：允许无限重试，直到成功，此方式逻辑不当会导致死循环</p>\n</li>\n<li><p>SimpleRetryPolicy：固定次数重试策略，默认重试最大次数为3次，RetryTemplate默认使用的策略</p>\n</li>\n<li><p>TimeoutRetryPolicy：超时时间重试策略，默认超时时间为1秒，在指定的超时时间内允许重试</p>\n</li>\n<li><p>ExceptionClassifierRetryPolicy：设置不同异常的重试策略，类似组合重试策略，区别在于这里只区分不同异常的重试</p>\n</li>\n<li><p>CircuitBreakerRetryPolicy：有熔断功能的重试策略，需设置3个参数openTimeout、resetTimeout和delegate</p>\n</li>\n<li><p>CompositeRetryPolicy：组合重试策略，有两种组合方式，乐观组合重试策略是指只要有一个策略允许重试即可以，悲观组合重试策略是指只要有一个策略不允许重试即可以，但不管哪种组合方式，组合中的每一个策略都会执行重试回退策略。重试回退策略，指的是每次重试是立即重试还是等待一段时间后重试。默认情况下是立即重试，如果需要配置等待一段时间后重试则需要指定回退策略BackoffRetryPolicy。</p>\n</li>\n<li><p>NoBackOffPolicy：无退避算法策略，每次重试时立即重试</p>\n</li>\n<li><p>FixedBackOffPolicy：固定时间的退避策略，需设置参数sleeper和backOffPeriod，sleeper指定等待策略，默认是Thread.sleep，即线程休眠，backOffPeriod指定休眠时间，默认1秒</p>\n</li>\n<li><p>UniformRandomBackOffPolicy：随机时间退避策略，需设置sleeper、minBackOffPeriod和maxBackOffPeriod，该策略在[minBackOffPeriod,maxBackOffPeriod之间取一个随机休眠时间，minBackOffPeriod默认500毫秒，maxBackOffPeriod默认1500毫秒</p>\n</li>\n<li><p>ExponentialBackOffPolicy：指数退避策略，需设置参数sleeper、initialInterval、maxInterval和multiplier，initialInterval指定初始休眠时间，默认100毫秒，maxInterval指定最大休眠时间，默认30秒，multiplier指定乘数，即下一次休眠时间为当前休眠时间*multiplier</p>\n</li>\n<li><p>ExponentialRandomBackOffPolicy：随机指数退避策略，引入随机乘数可以实现随机乘数回退</p>\n</li>\n</ul>\n<h3 id=\"guava-retrying\"><a href=\"#guava-retrying\" class=\"headerlink\" title=\"guava-retrying\"></a>guava-retrying</h3><p>谈话</p>\n<p>小华：我们系统也要用到重试</p>\n<p>项目经理：小明前段时间用了 spring-retry，分享下应该还不错</p>\n<p>小明：spring-retry 基本功能都有，但是必须是基于异常来进行控制。如果你要以返回值的某个状态来判定是否需要重试，可能只能通过自己判断返回值然后显式抛出异常了。</p>\n<p>小华：我们项目中想根据对象的属性来进行重试。你可以看下 guava-retry，我很久以前用过，感觉还不错。</p>\n<p>小明：好的。</p>\n<h4 id=\"guava-retrying-1\"><a href=\"#guava-retrying-1\" class=\"headerlink\" title=\"guava-retrying\"></a>guava-retrying</h4><p>guava-retrying 模块提供了一种通用方法， 可以使用Guava谓词匹配增强的特定停止、重试和异常处理功能来重试任意Java代码。</p>\n<p>优势</p>\n<p>guava retryer工具与spring-retry类似，都是通过定义重试者角色来包装正常逻辑重试，但是Guava retryer有更优的策略定义，在支持重试次数和重试频度控制基础上，能够兼容支持多个异常或者自定义实体对象的重试源定义，让重试功能有更多的灵活性。</p>\n<p>Guava Retryer也是线程安全的，入口调用逻辑采用的是 java.util.concurrent.Callable 的 call() 方法</p>\n<p>代码例子</p>\n<p>入门案例</p>\n<p>遇到异常之后，重试 3 次停止</p>\n<ul>\n<li>HelloDemo.java</li>\n</ul>\n<pre><code class=\"java\">public static void main(String[] args) {\n    Callable&lt;Boolean&gt; callable = new Callable&lt;Boolean&gt;() {\n        @Override\n        public Boolean call() throws Exception {\n            // do something useful here\n            LOGGER.info(&quot;call...&quot;);\n            throw new RuntimeException();\n        }\n    };\n\n    Retryer&lt;Boolean&gt; retryer = RetryerBuilder.&lt;Boolean&gt;newBuilder()\n            .retryIfResult(Predicates.isNull())\n            .retryIfExceptionOfType(IOException.class)\n            .retryIfRuntimeException()\n            .withStopStrategy(StopStrategies.stopAfterAttempt(3))\n            .build();\n    try {\n        retryer.call(callable);\n    } catch (RetryException | ExecutionException e) {\n        e.printStackTrace();\n    }\n\n}</code></pre>\n<p>日志</p>\n<pre><code class=\"console\">2018-08-08 17:21:12.442  INFO  [main] com.github.houbb.retry.guava.HelloDemo:41 - call...\ncom.github.rholder.retry.RetryException: Retrying failed to complete successfully after 3 attempts.\n2018-08-08 17:21:12.443  INFO  [main] com.github.houbb.retry.guava.HelloDemo:41 - call...\n2018-08-08 17:21:12.444  INFO  [main] com.github.houbb.retry.guava.HelloDemo:41 - call...\n    at com.github.rholder.retry.Retryer.call(Retryer.java:174)\n    at com.github.houbb.retry.guava.HelloDemo.main(HelloDemo.java:53)\nCaused by: java.lang.RuntimeException\n    at com.github.houbb.retry.guava.HelloDemo$1.call(HelloDemo.java:42)\n    at com.github.houbb.retry.guava.HelloDemo$1.call(HelloDemo.java:37)\n    at com.github.rholder.retry.AttemptTimeLimiters$NoAttemptTimeLimit.call(AttemptTimeLimiters.java:78)\n    at com.github.rholder.retry.Retryer.call(Retryer.java:160)\n    ... 1 more</code></pre>\n<p>重试策略</p>\n<p>ExponentialBackoff.java</p>\n<p>重试次数：3</p>\n<p>重试策略：固定等待 3S</p>\n<pre><code class=\"java\">Retryer&lt;Boolean&gt; retryer = RetryerBuilder.&lt;Boolean&gt;newBuilder()\n                .retryIfResult(Predicates.isNull())\n                .retryIfExceptionOfType(IOException.class)\n                .retryIfRuntimeException()\n                .withWaitStrategy(WaitStrategies.fixedWait(3, TimeUnit.SECONDS))\n                .withStopStrategy(StopStrategies.stopAfterAttempt(3))\n                .build();\n        try {\n            retryer.call(callable);\n        } catch (RetryException | ExecutionException e) {\n            e.printStackTrace();\n        }</code></pre>\n<p>日志</p>\n<pre><code class=\"console\">2018-08-08 17:20:41.653  INFO  [main] com.github.houbb.retry.guava.ExponentialBackoff:43 - call...\n2018-08-08 17:20:44.659  INFO  [main] com.github.houbb.retry.guava.ExponentialBackoff:43 - call...\n2018-08-08 17:20:47.664  INFO  [main] com.github.houbb.retry.guava.ExponentialBackoff:43 - call...\ncom.github.rholder.retry.RetryException: Retrying failed to complete successfully after 3 attempts.\n    at com.github.rholder.retry.Retryer.call(Retryer.java:174)\n    at com.github.houbb.retry.guava.ExponentialBackoff.main(ExponentialBackoff.java:56)\nCaused by: java.lang.RuntimeException\n    at com.github.houbb.retry.guava.ExponentialBackoff$1.call(ExponentialBackoff.java:44)\n    at com.github.houbb.retry.guava.ExponentialBackoff$1.call(ExponentialBackoff.java:39)\n    at com.github.rholder.retry.AttemptTimeLimiters$NoAttemptTimeLimit.call(AttemptTimeLimiters.java:78)\n    at com.github.rholder.retry.Retryer.call(Retryer.java:160)\n    ... 1 more</code></pre>\n<h4 id=\"guava-retrying-简介\"><a href=\"#guava-retrying-简介\" class=\"headerlink\" title=\"guava-retrying 简介\"></a>guava-retrying 简介</h4><ul>\n<li><p>RetryerBuilder RetryerBuilder 是一个 factory 创建者，可以定制设置重试源且可以支持多个重试源，可以配置重试次数或重试超时时间，以及可以配置等待时间间隔，创建重试者 Retryer 实例。RetryerBuilder 的重试源支持 Exception 异常对象和自定义断言对象，通过retryIfException 和 retryIfResult 设置，同时支持多个且能兼容。</p>\n</li>\n<li><p>retryIfException retryIfException，抛出 runtime 异常、checked 异常时都会重试，但是抛出 error 不会重试。</p>\n</li>\n<li><p>retryIfRuntimeException retryIfRuntimeException 只会在抛 runtime 异常的时候才重试，checked 异常和error 都不重试。</p>\n</li>\n<li><p>retryIfExceptionOfType retryIfExceptionOfType 允许我们只在发生特定异常的时候才重试，比如NullPointerException 和 IllegalStateException 都属于 runtime 异常，也包括自定义的error。</p>\n</li>\n</ul>\n<p>如：　　</p>\n<pre><code class=\"java\">retryIfExceptionOfType(Error.class)// 只在抛出error重试</code></pre>\n<p>当然我们还可以在只有出现指定的异常的时候才重试，如：　</p>\n<pre><code class=\"java\">.retryIfExceptionOfType(IllegalStateException.class)\n.retryIfExceptionOfType(NullPointerException.class)</code></pre>\n<p>或者通过Predicate实现</p>\n<pre><code class=\"java\">.retryIfException(Predicates.or(Predicates.instanceOf(NullPointerException.class),\nPredicates.instanceOf(IllegalStateException.class))) </code></pre>\n<ul>\n<li>retryIfResult retryIfResult 可以指定你的 Callable 方法在返回值的时候进行重试，如　　</li>\n</ul>\n<pre><code class=\"java\">// 返回false重试  \n.retryIfResult(Predicates.equalTo(false))   \n\n//以_error结尾才重试  \n.retryIfResult(Predicates.containsPattern(&quot;_error$&quot;))  </code></pre>\n<ul>\n<li>RetryListener 当发生重试之后，假如我们需要做一些额外的处理动作，比如log一下异常，那么可以使用RetryListener。每次重试之后，guava-retrying 会自动回调我们注册的监听。可以注册多个RetryListener，会按照注册顺序依次调用。 　</li>\n</ul>\n<pre><code class=\"java\">.withRetryListener(new RetryListener {      \n @Override    \n   public &lt;T&gt; void onRetry(Attempt&lt;T&gt; attempt) {  \n               logger.error(&quot;第【{}】次调用失败&quot; , attempt.getAttemptNumber());  \n          } \n }\n) </code></pre>\n<p>主要接口</p>\n<table>\n<thead>\n<tr>\n<th>序号</th>\n<th>接口</th>\n<th>描述</th>\n<th>备注</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>1</td>\n<td>Attempt</td>\n<td>一次执行任务</td>\n<td></td>\n</tr>\n<tr>\n<td>2</td>\n<td>AttemptTimeLimiter</td>\n<td>单次任务执行时间限制</td>\n<td>如果单次任务执行超时，则终止执行当前任务</td>\n</tr>\n<tr>\n<td>3</td>\n<td>BlockStrategies</td>\n<td>任务阻塞策略</td>\n<td>通俗的讲就是当前任务执行完，下次任务还没开始这段时间做什么），默认策略为：BlockStrategies.THREAD_SLEEP_STRATEGY</td>\n</tr>\n<tr>\n<td>4</td>\n<td>RetryException</td>\n<td>重试异常</td>\n<td></td>\n</tr>\n<tr>\n<td>5</td>\n<td>RetryListener</td>\n<td>自定义重试监听器</td>\n<td>可以用于异步记录错误日志</td>\n</tr>\n<tr>\n<td>6</td>\n<td>StopStrategy</td>\n<td>停止重试策略</td>\n<td></td>\n</tr>\n<tr>\n<td>7</td>\n<td>WaitStrategy</td>\n<td>等待时长策略</td>\n<td>（控制时间间隔），返回结果为下次执行时长</td>\n</tr>\n<tr>\n<td>8</td>\n<td>Attempt</td>\n<td>一次执行任务</td>\n<td></td>\n</tr>\n<tr>\n<td>9</td>\n<td>Attempt</td>\n<td>一次执行任务</td>\n<td></td>\n</tr>\n</tbody></table>\n<p>StopStrategy</p>\n<p>提供三种：</p>\n<ul>\n<li><p>StopAfterDelayStrategy 设定一个最长允许的执行时间；比如设定最长执行10s，无论任务执行次数，只要重试的时候超出了最长时间，则任务终止，并返回重试异常RetryException；</p>\n</li>\n<li><p>NeverStopStrategy 不停止，用于需要一直轮训知道返回期望结果的情况；</p>\n</li>\n<li><p>StopAfterAttemptStrategy 设定最大重试次数，如果超出最大重试次数则停止重试，并返回重试异常；</p>\n</li>\n</ul>\n<p>WaitStrategy</p>\n<ul>\n<li><p>FixedWaitStrategy 固定等待时长策略；</p>\n</li>\n<li><p>RandomWaitStrategy 随机等待时长策略（可以提供一个最小和最大时长，等待时长为其区间随机值）</p>\n</li>\n<li><p>IncrementingWaitStrategy 递增等待时长策略（提供一个初始值和步长，等待时间随重试次数增加而增加）</p>\n</li>\n<li><p>ExponentialWaitStrategy 指数等待时长策略；</p>\n</li>\n<li><p>FibonacciWaitStrategy Fibonacci 等待时长策略；</p>\n</li>\n<li><p>ExceptionWaitStrategy 异常时长等待策略；</p>\n</li>\n<li><p>CompositeWaitStrategy 复合时长等待策略；</p>\n</li>\n</ul>\n<h4 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h4><ol>\n<li>优雅重试共性和原理</li>\n</ol>\n<p>正常和重试优雅解耦，重试断言条件实例或逻辑异常实例是两者沟通的媒介。</p>\n<p>约定重试间隔，差异性重试策略，设置重试超时时间，进一步保证重试有效性以及重试流程稳定性。</p>\n<p>都使用了命令设计模式，通过委托重试对象完成相应的逻辑操作，同时内部封装实现重试逻辑。</p>\n<p>spring-retry 和 guava-retry 工具都是线程安全的重试，能够支持并发业务场景的重试逻辑正确性。</p>\n<ol start=\"2\">\n<li>优雅重试适用场景</li>\n</ol>\n<p>功能逻辑中存在不稳定依赖场景，需要使用重试获取预期结果或者尝试重新执行逻辑不立即结束。比如远程接口访问，数据加载访问，数据上传校验等等。</p>\n<p>对于异常场景存在需要重试场景，同时希望把正常逻辑和重试逻辑解耦。</p>\n<p>对于需要基于数据媒介交互，希望通过重试轮询检测执行逻辑场景也可以考虑重试方案。</p>\n<p>谈话</p>\n<p>项目经理：我觉得 guava-retry 挺好的，就是不够方便。小明啊，你给封装个基于注解的吧。</p>\n<p>小明：……</p>\n<p>更好的实现:</p>\n<p><a href=\"https://github.com/houbb/sisyphus\" target=\"_blank\" rel=\"noopener\">java重试框架——sisyphus</a></p>\n"},{"layout":"post","title":"java多线程总结","date":"2018-06-07T16:00:00.000Z","excerpt":"","comments":1,"_content":"\n以下文字摘自[JavaGuide](https://github.com/Snailclimb/JavaGuide)\n\n<!-- TOC -->\n\n- [Java 并发基础常见面试题总结](#java-并发基础常见面试题总结)\n    - [1. 什么是线程和进程?](#1-什么是线程和进程)\n        - [1.1. 何为进程?](#11-何为进程)\n        - [1.2. 何为线程?](#12-何为线程)\n    - [2. 请简要描述线程与进程的关系,区别及优缺点？](#2-请简要描述线程与进程的关系区别及优缺点)\n        - [2.1. 图解进程和线程的关系](#21-图解进程和线程的关系)\n        - [2.2. 程序计数器为什么是私有的?](#22-程序计数器为什么是私有的)\n        - [2.3. 虚拟机栈和本地方法栈为什么是私有的?](#23-虚拟机栈和本地方法栈为什么是私有的)\n        - [2.4. 一句话简单了解堆和方法区](#24-一句话简单了解堆和方法区)\n    - [3. 说说并发与并行的区别?](#3-说说并发与并行的区别)\n    - [4. 为什么要使用多线程呢?](#4-为什么要使用多线程呢)\n    - [5. 使用多线程可能带来什么问题?](#5-使用多线程可能带来什么问题)\n    - [6. 说说线程的生命周期和状态?](#6-说说线程的生命周期和状态)\n    - [7. 什么是上下文切换?](#7-什么是上下文切换)\n    - [8. 什么是线程死锁?如何避免死锁?](#8-什么是线程死锁如何避免死锁)\n        - [8.1. 认识线程死锁](#81-认识线程死锁)\n        - [8.2. 如何避免线程死锁?](#82-如何避免线程死锁)\n    - [9. 说说 sleep() 方法和 wait() 方法区别和共同点?](#9-说说-sleep-方法和-wait-方法区别和共同点)\n    - [10. 为什么我们调用 start() 方法时会执行 run() 方法，为什么我们不能直接调用 run() 方法？](#10-为什么我们调用-start-方法时会执行-run-方法为什么我们不能直接调用-run-方法)\n\n<!-- /TOC -->\n\n# Java 并发基础常见面试题总结\n\n## 1. 什么是线程和进程?\n\n### 1.1. 何为进程?\n\n进程是程序的一次执行过程，是系统运行程序的基本单位，因此进程是动态的。系统运行一个程序即是一个进程从创建，运行到消亡的过程。\n\n在 Java 中，当我们启动 main 函数时其实就是启动了一个 JVM 的进程，而 main 函数所在的线程就是这个进程中的一个线程，也称主线程。\n\n如下图所示，在 windows 中通过查看任务管理器的方式，我们就可以清楚看到 window 当前运行的进程（.exe 文件的运行）。\n\n![进程示例图片-Windows](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/进程示例图片-Windows.png)\n\n### 1.2. 何为线程?\n\n线程与进程相似，但线程是一个比进程更小的执行单位。一个进程在其执行的过程中可以产生多个线程。与进程不同的是同类的多个线程共享进程的**堆**和**方法区**资源，但每个线程有自己的**程序计数器**、**虚拟机栈**和**本地方法栈**，所以系统在产生一个线程，或是在各个线程之间作切换工作时，负担要比进程小得多，也正因为如此，线程也被称为轻量级进程。\n\nJava 程序天生就是多线程程序，我们可以通过 JMX 来看一下一个普通的 Java 程序有哪些线程，代码如下。\n\n```java\npublic class MultiThread {\n\tpublic static void main(String[] args) {\n\t\t// 获取 Java 线程管理 MXBean\n\tThreadMXBean threadMXBean = ManagementFactory.getThreadMXBean();\n\t\t// 不需要获取同步的 monitor 和 synchronizer 信息，仅获取线程和线程堆栈信息\n\t\tThreadInfo[] threadInfos = threadMXBean.dumpAllThreads(false, false);\n\t\t// 遍历线程信息，仅打印线程 ID 和线程名称信息\n\t\tfor (ThreadInfo threadInfo : threadInfos) {\n\t\t\tSystem.out.println(\"[\" + threadInfo.getThreadId() + \"] \" + threadInfo.getThreadName());\n\t\t}\n\t}\n}\n```\n\n上述程序输出如下（输出内容可能不同，不用太纠结下面每个线程的作用，只用知道 main 线程执行 main 方法即可）：\n\n```\n[5] Attach Listener //添加事件\n[4] Signal Dispatcher // 分发处理给 JVM 信号的线程\n[3] Finalizer //调用对象 finalize 方法的线程\n[2] Reference Handler //清除 reference 线程\n[1] main //main 线程,程序入口\n```\n\n从上面的输出内容可以看出：**一个 Java 程序的运行是 main 线程和多个其他线程同时运行**。\n\n## 2. 请简要描述线程与进程的关系,区别及优缺点？\n\n**从 JVM 角度说进程和线程之间的关系**\n\n### 2.1. 图解进程和线程的关系\n\n下图是 Java 内存区域，通过下图我们从 JVM 的角度来说一下线程和进程之间的关系。如果你对 Java 内存区域 (运行时数据区) 这部分知识不太了解的话可以阅读一下这篇文章：[《可能是把 Java 内存区域讲的最清楚的一篇文章》](https://github.com/Snailclimb/JavaGuide/blob/3965c02cc0f294b0bd3580df4868d5e396959e2e/Java%E7%9B%B8%E5%85%B3/%E5%8F%AF%E8%83%BD%E6%98%AF%E6%8A%8AJava%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F%E8%AE%B2%E7%9A%84%E6%9C%80%E6%B8%85%E6%A5%9A%E7%9A%84%E4%B8%80%E7%AF%87%E6%96%87%E7%AB%A0.md \"《可能是把 Java 内存区域讲的最清楚的一篇文章》\")\n\n<div align=\"center\">  \n<img src=\"https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-3/JVM运行时数据区域.png\" width=\"600px\"/>\n</div>\n\n从上图可以看出：一个进程中可以有多个线程，多个线程共享进程的**堆**和**方法区 (JDK1.8 之后的元空间)**资源，但是每个线程有自己的**程序计数器**、**虚拟机栈** 和 **本地方法栈**。\n\n**总结：** 线程 是 进程 划分成的更小的运行单位。线程和进程最大的不同在于基本上各进程是独立的，而各线程则不一定，因为同一进程中的线程极有可能会相互影响。线程执行开销小，但不利于资源的管理和保护；而进程正相反\n\n下面是该知识点的扩展内容！\n\n下面来思考这样一个问题：为什么**程序计数器**、**虚拟机栈**和**本地方法栈**是线程私有的呢？为什么堆和方法区是线程共享的呢？\n\n### 2.2. 程序计数器为什么是私有的?\n\n程序计数器主要有下面两个作用：\n\n1. 字节码解释器通过改变程序计数器来依次读取指令，从而实现代码的流程控制，如：顺序执行、选择、循环、异常处理。\n2. 在多线程的情况下，程序计数器用于记录当前线程执行的位置，从而当线程被切换回来的时候能够知道该线程上次运行到哪儿了。\n\n需要注意的是，如果执行的是 native 方法，那么程序计数器记录的是 undefined 地址，只有执行的是 Java 代码时程序计数器记录的才是下一条指令的地址。\n\n所以，程序计数器私有主要是为了**线程切换后能恢复到正确的执行位置**。\n\n### 2.3. 虚拟机栈和本地方法栈为什么是私有的?\n\n- **虚拟机栈：** 每个 Java 方法在执行的同时会创建一个栈帧用于存储局部变量表、操作数栈、常量池引用等信息。从方法调用直至执行完成的过程，就对应着一个栈帧在 Java 虚拟机栈中入栈和出栈的过程。\n- **本地方法栈：** 和虚拟机栈所发挥的作用非常相似，区别是： **虚拟机栈为虚拟机执行 Java 方法 （也就是字节码）服务，而本地方法栈则为虚拟机使用到的 Native 方法服务。** 在 HotSpot 虚拟机中和 Java 虚拟机栈合二为一。\n\n所以，为了**保证线程中的局部变量不被别的线程访问到**，虚拟机栈和本地方法栈是线程私有的。\n\n### 2.4. 一句话简单了解堆和方法区\n\n堆和方法区是所有线程共享的资源，其中堆是进程中最大的一块内存，主要用于存放新创建的对象 (所有对象都在这里分配内存)，方法区主要用于存放已被加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。\n\n## 3. 说说并发与并行的区别?\n\n- **并发：** 同一时间段，多个任务都在执行 (单位时间内不一定同时执行)；\n- **并行：** 单位时间内，多个任务同时执行。\n\n## 4. 为什么要使用多线程呢?\n\n先从总体上来说：\n\n- **从计算机底层来说：** 线程可以比作是轻量级的进程，是程序执行的最小单位,线程间的切换和调度的成本远远小于进程。另外，多核 CPU 时代意味着多个线程可以同时运行，这减少了线程上下文切换的开销。\n- **从当代互联网发展趋势来说：** 现在的系统动不动就要求百万级甚至千万级的并发量，而多线程并发编程正是开发高并发系统的基础，利用好多线程机制可以大大提高系统整体的并发能力以及性能。\n\n再深入到计算机底层来探讨：\n\n- **单核时代：** 在单核时代多线程主要是为了提高 CPU 和 IO 设备的综合利用率。举个例子：当只有一个线程的时候会导致 CPU 计算时，IO 设备空闲；进行 IO 操作时，CPU 空闲。我们可以简单地说这两者的利用率目前都是 50%左右。但是当有两个线程的时候就不一样了，当一个线程执行 CPU 计算时，另外一个线程可以进行 IO 操作，这样两个的利用率就可以在理想情况下达到 100%了。\n- **多核时代:** 多核时代多线程主要是为了提高 CPU 利用率。举个例子：假如我们要计算一个复杂的任务，我们只用一个线程的话，CPU 只会一个 CPU 核心被利用到，而创建多个线程就可以让多个 CPU 核心被利用到，这样就提高了 CPU 的利用率。\n\n## 5. 使用多线程可能带来什么问题?\n\n并发编程的目的就是为了能提高程序的执行效率提高程序运行速度，但是并发编程并不总是能提高程序运行速度的，而且并发编程可能会遇到很多问题，比如：内存泄漏、死锁、线程不安全等等。\n\n## 6. 说说线程的生命周期和状态?\n\nJava 线程在运行的生命周期中的指定时刻只可能处于下面 6 种不同状态的其中一个状态（图源《Java 并发编程艺术》4.1.4 节）。\n\n![Java 线程的状态 ](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/19-1-29/Java%E7%BA%BF%E7%A8%8B%E7%9A%84%E7%8A%B6%E6%80%81.png)\n\n线程在生命周期中并不是固定处于某一个状态而是随着代码的执行在不同状态之间切换。Java 线程状态变迁如下图所示（图源《Java 并发编程艺术》4.1.4 节）：\n\n![Java 线程状态变迁 ](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/19-1-29/Java+%E7%BA%BF%E7%A8%8B%E7%8A%B6%E6%80%81%E5%8F%98%E8%BF%81.png)\n\n由上图可以看出：线程创建之后它将处于 **NEW（新建）** 状态，调用 `start()` 方法后开始运行，线程这时候处于 **READY（可运行）** 状态。可运行状态的线程获得了 CPU 时间片（timeslice）后就处于 **RUNNING（运行）** 状态。\n\n> 操作系统隐藏 Java 虚拟机（JVM）中的 RUNNABLE 和 RUNNING 状态，它只能看到 RUNNABLE 状态（图源：[HowToDoInJava](https://howtodoinjava.com/ \"HowToDoInJava\")：[Java Thread Life Cycle and Thread States](https://howtodoinjava.com/java/multi-threading/java-thread-life-cycle-and-thread-states/ \"Java Thread Life Cycle and Thread States\")），所以 Java 系统一般将这两个状态统称为 **RUNNABLE（运行中）** 状态 。\n\n![RUNNABLE-VS-RUNNING](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-3/RUNNABLE-VS-RUNNING.png)\n\n当线程执行 `wait()`方法之后，线程进入 **WAITING（等待）** 状态。进入等待状态的线程需要依靠其他线程的通知才能够返回到运行状态，而 **TIME_WAITING(超时等待)** 状态相当于在等待状态的基础上增加了超时限制，比如通过 `sleep（long millis）`方法或 `wait（long millis）`方法可以将 Java 线程置于 TIMED WAITING 状态。当超时时间到达后 Java 线程将会返回到 RUNNABLE 状态。当线程调用同步方法时，在没有获取到锁的情况下，线程将会进入到 **BLOCKED（阻塞）** 状态。线程在执行 Runnable 的`run()`方法之后将会进入到 **TERMINATED（终止）** 状态。\n\n## 7. 什么是上下文切换?\n\n多线程编程中一般线程的个数都大于 CPU 核心的个数，而一个 CPU 核心在任意时刻只能被一个线程使用，为了让这些线程都能得到有效执行，CPU 采取的策略是为每个线程分配时间片并轮转的形式。当一个线程的时间片用完的时候就会重新处于就绪状态让给其他线程使用，这个过程就属于一次上下文切换。\n\n概括来说就是：当前任务在执行完 CPU 时间片切换到另一个任务之前会先保存自己的状态，以便下次再切换回这个任务时，可以再加载这个任务的状态。**任务从保存到再加载的过程就是一次上下文切换**。\n\n上下文切换通常是计算密集型的。也就是说，它需要相当可观的处理器时间，在每秒几十上百次的切换中，每次切换都需要纳秒量级的时间。所以，上下文切换对系统来说意味着消耗大量的 CPU 时间，事实上，可能是操作系统中时间消耗最大的操作。\n\nLinux 相比与其他操作系统（包括其他类 Unix 系统）有很多的优点，其中有一项就是，其上下文切换和模式切换的时间消耗非常少。\n\n## 8. 什么是线程死锁?如何避免死锁?\n\n### 8.1. 认识线程死锁\n\n线程死锁描述的是这样一种情况：多个线程同时被阻塞，它们中的一个或者全部都在等待某个资源被释放。由于线程被无限期地阻塞，因此程序不可能正常终止。\n\n如下图所示，线程 A 持有资源 2，线程 B 持有资源 1，他们同时都想申请对方的资源，所以这两个线程就会互相等待而进入死锁状态。\n\n![线程死锁示意图 ](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-4/2019-4%E6%AD%BB%E9%94%811.png)\n\n下面通过一个例子来说明线程死锁,代码模拟了上图的死锁的情况 (代码来源于《并发编程之美》)：\n\n```java\npublic class DeadLockDemo {\n    private static Object resource1 = new Object();//资源 1\n    private static Object resource2 = new Object();//资源 2\n\n    public static void main(String[] args) {\n        new Thread(() -> {\n            synchronized (resource1) {\n                System.out.println(Thread.currentThread() + \"get resource1\");\n                try {\n                    Thread.sleep(1000);\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n                System.out.println(Thread.currentThread() + \"waiting get resource2\");\n                synchronized (resource2) {\n                    System.out.println(Thread.currentThread() + \"get resource2\");\n                }\n            }\n        }, \"线程 1\").start();\n\n        new Thread(() -> {\n            synchronized (resource2) {\n                System.out.println(Thread.currentThread() + \"get resource2\");\n                try {\n                    Thread.sleep(1000);\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n                System.out.println(Thread.currentThread() + \"waiting get resource1\");\n                synchronized (resource1) {\n                    System.out.println(Thread.currentThread() + \"get resource1\");\n                }\n            }\n        }, \"线程 2\").start();\n    }\n}\n```\n\nOutput\n\n```\nThread[线程 1,5,main]get resource1\nThread[线程 2,5,main]get resource2\nThread[线程 1,5,main]waiting get resource2\nThread[线程 2,5,main]waiting get resource1\n```\n\n线程 A 通过 synchronized (resource1) 获得 resource1 的监视器锁，然后通过`Thread.sleep(1000);`让线程 A 休眠 1s 为的是让线程 B 得到执行然后获取到 resource2 的监视器锁。线程 A 和线程 B 休眠结束了都开始企图请求获取对方的资源，然后这两个线程就会陷入互相等待的状态，这也就产生了死锁。上面的例子符合产生死锁的四个必要条件。\n\n学过操作系统的朋友都知道产生死锁必须具备以下四个条件：\n\n1. 互斥条件：该资源任意一个时刻只由一个线程占用。\n2. 请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。\n3. 不剥夺条件:线程已获得的资源在末使用完之前不能被其他线程强行剥夺，只有自己使用完毕后才释放资源。\n4. 循环等待条件:若干进程之间形成一种头尾相接的循环等待资源关系。\n\n### 8.2. 如何避免线程死锁?\n\n我上面说了产生死锁的四个必要条件，为了避免死锁，我们只要破坏产生死锁的四个条件中的其中一个就可以了。现在我们来挨个分析一下：\n\n1. **破坏互斥条件** ：这个条件我们没有办法破坏，因为我们用锁本来就是想让他们互斥的（临界资源需要互斥访问）。\n2. **破坏请求与保持条件**  ：一次性申请所有的资源。\n3. **破坏不剥夺条件** ：占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源。\n4. **破坏循环等待条件** ：靠按序申请资源来预防。按某一顺序申请资源，释放资源则反序释放。破坏循环等待条件。\n\n我们对线程 2 的代码修改成下面这样就不会产生死锁了。\n\n```java\n        new Thread(() -> {\n            synchronized (resource1) {\n                System.out.println(Thread.currentThread() + \"get resource1\");\n                try {\n                    Thread.sleep(1000);\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n                System.out.println(Thread.currentThread() + \"waiting get resource2\");\n                synchronized (resource2) {\n                    System.out.println(Thread.currentThread() + \"get resource2\");\n                }\n            }\n        }, \"线程 2\").start();\n```\n\nOutput\n\n```\nThread[线程 1,5,main]get resource1\nThread[线程 1,5,main]waiting get resource2\nThread[线程 1,5,main]get resource2\nThread[线程 2,5,main]get resource1\nThread[线程 2,5,main]waiting get resource2\nThread[线程 2,5,main]get resource2\n\nProcess finished with exit code 0\n```\n\n我们分析一下上面的代码为什么避免了死锁的发生?\n\n线程 1 首先获得到 resource1 的监视器锁,这时候线程 2 就获取不到了。然后线程 1 再去获取 resource2 的监视器锁，可以获取到。然后线程 1 释放了对 resource1、resource2 的监视器锁的占用，线程 2 获取到就可以执行了。这样就破坏了破坏循环等待条件，因此避免了死锁。\n\n## 9. 说说 sleep() 方法和 wait() 方法区别和共同点?\n\n- 两者最主要的区别在于：**sleep 方法没有释放锁，而 wait 方法释放了锁** 。\n- 两者都可以暂停线程的执行。\n- Wait 通常被用于线程间交互/通信，sleep 通常被用于暂停执行。\n- wait() 方法被调用后，线程不会自动苏醒，需要别的线程调用同一个对象上的 notify() 或者 notifyAll() 方法。sleep() 方法执行完成后，线程会自动苏醒。或者可以使用 wait(long timeout)超时后线程会自动苏醒。\n\n## 10. 为什么我们调用 start() 方法时会执行 run() 方法，为什么我们不能直接调用 run() 方法？\n\n这是另一个非常经典的 java 多线程面试问题，而且在面试中会经常被问到。很简单，但是很多人都会答不上来！\n\nnew 一个 Thread，线程进入了新建状态;调用 start() 方法，会启动一个线程并使线程进入了就绪状态，当分配到时间片后就可以开始运行了。 start() 会执行线程的相应准备工作，然后自动执行 run() 方法的内容，这是真正的多线程工作。 而直接执行 run() 方法，会把 run 方法当成一个 main 线程下的普通方法去执行，并不会在某个线程中执行它，所以这并不是多线程工作。\n\n**总结： 调用 start 方法方可启动线程并使线程进入就绪状态，而 run 方法只是 thread 的一个普通方法调用，还是在主线程里执行。**\n\n\n\n\n\n<!-- TOC -->\n\n- [Java 并发进阶常见面试题总结](#java-并发进阶常见面试题总结)\n    - [1. synchronized 关键字](#1-synchronized-关键字)\n        - [1.1. 说一说自己对于 synchronized 关键字的了解](#11-说一说自己对于-synchronized-关键字的了解)\n        - [1.2. 说说自己是怎么使用 synchronized 关键字，在项目中用到了吗](#12-说说自己是怎么使用-synchronized-关键字在项目中用到了吗)\n        - [1.3. 讲一下 synchronized 关键字的底层原理](#13-讲一下-synchronized-关键字的底层原理)\n        - [1.4. 说说 JDK1.6 之后的synchronized 关键字底层做了哪些优化，可以详细介绍一下这些优化吗](#14-说说-jdk16-之后的synchronized-关键字底层做了哪些优化可以详细介绍一下这些优化吗)\n        - [1.5. 谈谈 synchronized和ReentrantLock 的区别](#15-谈谈-synchronized和reentrantlock-的区别)\n    - [2. volatile关键字](#2-volatile关键字)\n        - [2.1. 讲一下Java内存模型](#21-讲一下java内存模型)\n        - [2.2. 说说 synchronized 关键字和 volatile 关键字的区别](#22-说说-synchronized-关键字和-volatile-关键字的区别)\n    - [3. ThreadLocal](#3-threadlocal)\n        - [3.1. ThreadLocal简介](#31-threadlocal简介)\n        - [3.2. ThreadLocal示例](#32-threadlocal示例)\n        - [3.3. ThreadLocal原理](#33-threadlocal原理)\n        - [3.4. ThreadLocal 内存泄露问题](#34-threadlocal-内存泄露问题)\n    - [4. 线程池](#4-线程池)\n        - [4.1. 为什么要用线程池？](#41-为什么要用线程池)\n        - [4.2. 实现Runnable接口和Callable接口的区别](#42-实现runnable接口和callable接口的区别)\n        - [4.3. 执行execute()方法和submit()方法的区别是什么呢？](#43-执行execute方法和submit方法的区别是什么呢)\n        - [4.4. 如何创建线程池](#44-如何创建线程池)\n    - [5. Atomic 原子类](#5-atomic-原子类)\n        - [5.1. 介绍一下Atomic 原子类](#51-介绍一下atomic-原子类)\n        - [5.2. JUC 包中的原子类是哪4类?](#52-juc-包中的原子类是哪4类)\n        - [5.3. 讲讲 AtomicInteger 的使用](#53-讲讲-atomicinteger-的使用)\n        - [5.4. 能不能给我简单介绍一下 AtomicInteger 类的原理](#54-能不能给我简单介绍一下-atomicinteger-类的原理)\n    - [6. AQS](#6-aqs)\n        - [6.1. AQS 介绍](#61-aqs-介绍)\n        - [6.2. AQS 原理分析](#62-aqs-原理分析)\n            - [6.2.1. AQS 原理概览](#621-aqs-原理概览)\n            - [6.2.2. AQS 对资源的共享方式](#622-aqs-对资源的共享方式)\n            - [6.2.3. AQS底层使用了模板方法模式](#623-aqs底层使用了模板方法模式)\n        - [6.3. AQS 组件总结](#63-aqs-组件总结)\n    - [7 Reference](#7-reference)\n\n<!-- /TOC -->\n\n# Java 并发进阶常见面试题总结\n\n## 1. synchronized 关键字\n\n### 1.1. 说一说自己对于 synchronized 关键字的了解\n\nsynchronized关键字解决的是多个线程之间访问资源的同步性，synchronized关键字可以保证被它修饰的方法或者代码块在任意时刻只能有一个线程执行。\n\n另外，在 Java 早期版本中，synchronized属于重量级锁，效率低下，因为监视器锁（monitor）是依赖于底层的操作系统的 Mutex Lock 来实现的，Java 的线程是映射到操作系统的原生线程之上的。如果要挂起或者唤醒一个线程，都需要操作系统帮忙完成，而操作系统实现线程之间的切换时需要从用户态转换到内核态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高，这也是为什么早期的 synchronized 效率低的原因。庆幸的是在 Java 6 之后 Java 官方对从 JVM 层面对synchronized 较大优化，所以现在的 synchronized 锁效率也优化得很不错了。JDK1.6对锁的实现引入了大量的优化，如自旋锁、适应性自旋锁、锁消除、锁粗化、偏向锁、轻量级锁等技术来减少锁操作的开销。\n\n\n### 1.2. 说说自己是怎么使用 synchronized 关键字，在项目中用到了吗\n\n**synchronized关键字最主要的三种使用方式：**\n\n- **修饰实例方法:** 作用于当前对象实例加锁，进入同步代码前要获得当前对象实例的锁\n- **修饰静态方法:** 也就是给当前类加锁，会作用于类的所有对象实例，因为静态成员不属于任何一个实例对象，是类成员（ static 表明这是该类的一个静态资源，不管new了多少个对象，只有一份）。所以如果一个线程 A 调用一个实例对象的非静态 synchronized 方法，而线程 B 需要调用这个实例对象所属类的静态 synchronized 方法，是允许的，不会发生互斥现象，**因为访问静态 synchronized 方法占用的锁是当前类的锁，而访问非静态 synchronized 方法占用的锁是当前实例对象锁**。\n- **修饰代码块:** 指定加锁对象，对给定对象加锁，进入同步代码库前要获得给定对象的锁。\n\n**总结：** synchronized 关键字加到 static 静态方法和 synchronized(class)代码块上都是是给 Class 类上锁。synchronized 关键字加到实例方法上是给对象实例上锁。尽量不要使用 synchronized(String a) 因为JVM中，字符串常量池具有缓存功能！\n\n下面我以一个常见的面试题为例讲解一下 synchronized 关键字的具体使用。\n\n面试中面试官经常会说：“单例模式了解吗？来给我手写一下！给我解释一下双重检验锁方式实现单例模式的原理呗！”\n\n**双重校验锁实现对象单例（线程安全）**\n\n```java\npublic class Singleton {\n\n    private volatile static Singleton uniqueInstance;\n\n    private Singleton() {\n    }\n\n    public static Singleton getUniqueInstance() {\n       //先判断对象是否已经实例过，没有实例化过才进入加锁代码\n        if (uniqueInstance == null) {\n            //类对象加锁\n            synchronized (Singleton.class) {\n                if (uniqueInstance == null) {\n                    uniqueInstance = new Singleton();\n                }\n            }\n        }\n        return uniqueInstance;\n    }\n}\n```\n另外，需要注意 uniqueInstance 采用 volatile 关键字修饰也是很有必要。\n\nuniqueInstance 采用 volatile 关键字修饰也是很有必要的， uniqueInstance = new Singleton(); 这段代码其实是分为三步执行：\n\n1. 为 uniqueInstance 分配内存空间\n2. 初始化 uniqueInstance\n3. 将 uniqueInstance 指向分配的内存地址\n\n但是由于 JVM 具有指令重排的特性，执行顺序有可能变成 1->3->2。指令重排在单线程环境下不会出现问题，但是在多线程环境下会导致一个线程获得还没有初始化的实例。例如，线程 T1 执行了 1 和 3，此时 T2 调用 getUniqueInstance() 后发现 uniqueInstance 不为空，因此返回 uniqueInstance，但此时 uniqueInstance 还未被初始化。\n\n使用 volatile 可以禁止 JVM 的指令重排，保证在多线程环境下也能正常运行。\n\n### 1.3. 讲一下 synchronized 关键字的底层原理\n\n**synchronized 关键字底层原理属于 JVM 层面。**\n\n**① synchronized 同步语句块的情况**\n\n```java\npublic class SynchronizedDemo {\n\tpublic void method() {\n\t\tsynchronized (this) {\n\t\t\tSystem.out.println(\"synchronized 代码块\");\n\t\t}\n\t}\n}\n\n```\n\n通过 JDK 自带的 javap 命令查看 SynchronizedDemo 类的相关字节码信息：首先切换到类的对应目录执行 `javac SynchronizedDemo.java` 命令生成编译后的 .class 文件，然后执行`javap -c -s -v -l SynchronizedDemo.class`。\n\n![synchronized关键字原理](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/synchronized关键字原理.png)\n\n从上面我们可以看出：\n\n**synchronized 同步语句块的实现使用的是 monitorenter 和 monitorexit 指令，其中 monitorenter 指令指向同步代码块的开始位置，monitorexit 指令则指明同步代码块的结束位置。** 当执行 monitorenter 指令时，线程试图获取锁也就是获取 monitor(monitor对象存在于每个Java对象的对象头中，synchronized 锁便是通过这种方式获取锁的，也是为什么Java中任意对象可以作为锁的原因) 的持有权。当计数器为0则可以成功获取，获取后将锁计数器设为1也就是加1。相应的在执行 monitorexit 指令后，将锁计数器设为0，表明锁被释放。如果获取对象锁失败，那当前线程就要阻塞等待，直到锁被另外一个线程释放为止。\n\n**② synchronized 修饰方法的的情况**\n\n```java\npublic class SynchronizedDemo2 {\n\tpublic synchronized void method() {\n\t\tSystem.out.println(\"synchronized 方法\");\n\t}\n}\n\n```\n\n![synchronized关键字原理](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/synchronized关键字原理2.png)\n\nsynchronized 修饰的方法并没有 monitorenter 指令和 monitorexit 指令，取得代之的确实是 ACC_SYNCHRONIZED 标识，该标识指明了该方法是一个同步方法，JVM 通过该 ACC_SYNCHRONIZED 访问标志来辨别一个方法是否声明为同步方法，从而执行相应的同步调用。\n\n\n### 1.4. 说说 JDK1.6 之后的synchronized 关键字底层做了哪些优化，可以详细介绍一下这些优化吗\n\nJDK1.6 对锁的实现引入了大量的优化，如偏向锁、轻量级锁、自旋锁、适应性自旋锁、锁消除、锁粗化等技术来减少锁操作的开销。\n\n锁主要存在四种状态，依次是：无锁状态、偏向锁状态、轻量级锁状态、重量级锁状态，他们会随着竞争的激烈而逐渐升级。注意锁可以升级不可降级，这种策略是为了提高获得锁和释放锁的效率。\n\n关于这几种优化的详细信息可以查看笔主的这篇文章：<https://gitee.com/SnailClimb/JavaGuide/blob/master/docs/java/Multithread/synchronized.md>\n\n### 1.5. 谈谈 synchronized和ReentrantLock 的区别\n\n\n**① 两者都是可重入锁**\n\n两者都是可重入锁。“可重入锁”概念是：自己可以再次获取自己的内部锁。比如一个线程获得了某个对象的锁，此时这个对象锁还没有释放，当其再次想要获取这个对象的锁的时候还是可以获取的，如果不可锁重入的话，就会造成死锁。同一个线程每次获取锁，锁的计数器都自增1，所以要等到锁的计数器下降为0时才能释放锁。\n\n**② synchronized 依赖于 JVM 而 ReentrantLock 依赖于 API**\n\nsynchronized 是依赖于 JVM 实现的，前面我们也讲到了 虚拟机团队在 JDK1.6 为 synchronized 关键字进行了很多优化，但是这些优化都是在虚拟机层面实现的，并没有直接暴露给我们。ReentrantLock 是 JDK 层面实现的（也就是 API 层面，需要 lock() 和 unlock() 方法配合 try/finally 语句块来完成），所以我们可以通过查看它的源代码，来看它是如何实现的。\n\n**③ ReentrantLock 比 synchronized 增加了一些高级功能**\n\n相比synchronized，ReentrantLock增加了一些高级功能。主要来说主要有三点：**①等待可中断；②可实现公平锁；③可实现选择性通知（锁可以绑定多个条件）**\n\n- **ReentrantLock提供了一种能够中断等待锁的线程的机制**，通过lock.lockInterruptibly()来实现这个机制。也就是说正在等待的线程可以选择放弃等待，改为处理其他事情。\n- **ReentrantLock可以指定是公平锁还是非公平锁。而synchronized只能是非公平锁。所谓的公平锁就是先等待的线程先获得锁。** ReentrantLock默认情况是非公平的，可以通过 ReentrantLock类的`ReentrantLock(boolean fair)`构造方法来制定是否是公平的。\n- synchronized关键字与wait()和notify()/notifyAll()方法相结合可以实现等待/通知机制，ReentrantLock类当然也可以实现，但是需要借助于Condition接口与newCondition() 方法。Condition是JDK1.5之后才有的，它具有很好的灵活性，比如可以实现多路通知功能也就是在一个Lock对象中可以创建多个Condition实例（即对象监视器），**线程对象可以注册在指定的Condition中，从而可以有选择性的进行线程通知，在调度线程上更加灵活。 在使用notify()/notifyAll()方法进行通知时，被通知的线程是由 JVM 选择的，用ReentrantLock类结合Condition实例可以实现“选择性通知”** ，这个功能非常重要，而且是Condition接口默认提供的。而synchronized关键字就相当于整个Lock对象中只有一个Condition实例，所有的线程都注册在它一个身上。如果执行notifyAll()方法的话就会通知所有处于等待状态的线程这样会造成很大的效率问题，而Condition实例的signalAll()方法 只会唤醒注册在该Condition实例中的所有等待线程。\n\n如果你想使用上述功能，那么选择ReentrantLock是一个不错的选择。\n\n**④ 性能已不是选择标准**\n\n## 2. volatile关键字\n\n### 2.1. 讲一下Java内存模型\n\n\n在 JDK1.2 之前，Java的内存模型实现总是从**主存**（即共享内存）读取变量，是不需要进行特别的注意的。而在当前的 Java 内存模型下，线程可以把变量保存**本地内存**（比如机器的寄存器）中，而不是直接在主存中进行读写。这就可能造成一个线程在主存中修改了一个变量的值，而另外一个线程还继续使用它在寄存器中的变量值的拷贝，造成**数据的不一致**。\n\n![数据不一致](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/数据不一致.png)\n\n要解决这个问题，就需要把变量声明为**volatile**，这就指示 JVM，这个变量是不稳定的，每次使用它都到主存中进行读取。\n\n说白了， **volatile** 关键字的主要作用就是保证变量的可见性然后还有一个作用是防止指令重排序。\n\n![volatile关键字的可见性](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/volatile关键字的可见性.png)\n\n### 2.2 并发编程的三个重要特性\n\n1. **原子性** : 一个的操作或者多次操作，要么所有的操作全部都得到执行并且不会收到任何因素的干扰而中断，要么所有的操作都执行，要么都不执行。`synchronized ` 可以保证代码片段的原子性。\n2. **可见性**  ：当一个变量对共享变量进行了修改，那么另外的线程都是立即可以看到修改后的最新值。`volatile` 关键字可以保证共享变量的可见性。\n3. **有序性** ：代码在执行的过程中的先后顺序，Java 在编译器以及运行期间的优化，代码的执行顺序未必就是编写代码时候的顺序。`volatile` 关键字可以禁止指令进行重排序优化。\n\n### 2.3. 说说 synchronized 关键字和 volatile 关键字的区别\n\n`synchronized` 关键字和 `volatile` 关键字是两个互补的存在，而不是对立的存在：\n\n- **volatile关键字**是线程同步的**轻量级实现**，所以**volatile性能肯定比synchronized关键字要好**。但是**volatile关键字只能用于变量而synchronized关键字可以修饰方法以及代码块**。synchronized关键字在JavaSE1.6之后进行了主要包括为了减少获得锁和释放锁带来的性能消耗而引入的偏向锁和轻量级锁以及其它各种优化之后执行效率有了显著提升，**实际开发中使用 synchronized 关键字的场景还是更多一些**。\n- **多线程访问volatile关键字不会发生阻塞，而synchronized关键字可能会发生阻塞**\n- **volatile关键字能保证数据的可见性，但不能保证数据的原子性。synchronized关键字两者都能保证。**\n- **volatile关键字主要用于解决变量在多个线程之间的可见性，而 synchronized关键字解决的是多个线程之间访问资源的同步性。**\n\n## 3. ThreadLocal\n\n### 3.1. ThreadLocal简介\n\n通常情况下，我们创建的变量是可以被任何一个线程访问并修改的。**如果想实现每一个线程都有自己的专属本地变量该如何解决呢？** JDK中提供的`ThreadLocal`类正是为了解决这样的问题。 **`ThreadLocal`类主要解决的就是让每个线程绑定自己的值，可以将`ThreadLocal`类形象的比喻成存放数据的盒子，盒子中可以存储每个线程的私有数据。**\n\n**如果你创建了一个`ThreadLocal`变量，那么访问这个变量的每个线程都会有这个变量的本地副本，这也是`ThreadLocal`变量名的由来。他们可以使用 `get（）` 和 `set（）` 方法来获取默认值或将其值更改为当前线程所存的副本的值，从而避免了线程安全问题。**\n\n再举个简单的例子： \n\n比如有两个人去宝屋收集宝物，这两个共用一个袋子的话肯定会产生争执，但是给他们两个人每个人分配一个袋子的话就不会出现这样的问题。如果把这两个人比作线程的话，那么ThreadLocal就是用来避免这两个线程竞争的。\n\n### 3.2. ThreadLocal示例\n\n相信看了上面的解释，大家已经搞懂 ThreadLocal 类是个什么东西了。\n\n```java\nimport java.text.SimpleDateFormat;\nimport java.util.Random;\n\npublic class ThreadLocalExample implements Runnable{\n\n     // SimpleDateFormat 不是线程安全的，所以每个线程都要有自己独立的副本\n    private static final ThreadLocal<SimpleDateFormat> formatter = ThreadLocal.withInitial(() -> new SimpleDateFormat(\"yyyyMMdd HHmm\"));\n\n    public static void main(String[] args) throws InterruptedException {\n        ThreadLocalExample obj = new ThreadLocalExample();\n        for(int i=0 ; i<10; i++){\n            Thread t = new Thread(obj, \"\"+i);\n            Thread.sleep(new Random().nextInt(1000));\n            t.start();\n        }\n    }\n\n    @Override\n    public void run() {\n        System.out.println(\"Thread Name= \"+Thread.currentThread().getName()+\" default Formatter = \"+formatter.get().toPattern());\n        try {\n            Thread.sleep(new Random().nextInt(1000));\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n        //formatter pattern is changed here by thread, but it won't reflect to other threads\n        formatter.set(new SimpleDateFormat());\n\n        System.out.println(\"Thread Name= \"+Thread.currentThread().getName()+\" formatter = \"+formatter.get().toPattern());\n    }\n\n}\n\n```\n\nOutput:\n\n```\nThread Name= 0 default Formatter = yyyyMMdd HHmm\nThread Name= 0 formatter = yy-M-d ah:mm\nThread Name= 1 default Formatter = yyyyMMdd HHmm\nThread Name= 2 default Formatter = yyyyMMdd HHmm\nThread Name= 1 formatter = yy-M-d ah:mm\nThread Name= 3 default Formatter = yyyyMMdd HHmm\nThread Name= 2 formatter = yy-M-d ah:mm\nThread Name= 4 default Formatter = yyyyMMdd HHmm\nThread Name= 3 formatter = yy-M-d ah:mm\nThread Name= 4 formatter = yy-M-d ah:mm\nThread Name= 5 default Formatter = yyyyMMdd HHmm\nThread Name= 5 formatter = yy-M-d ah:mm\nThread Name= 6 default Formatter = yyyyMMdd HHmm\nThread Name= 6 formatter = yy-M-d ah:mm\nThread Name= 7 default Formatter = yyyyMMdd HHmm\nThread Name= 7 formatter = yy-M-d ah:mm\nThread Name= 8 default Formatter = yyyyMMdd HHmm\nThread Name= 9 default Formatter = yyyyMMdd HHmm\nThread Name= 8 formatter = yy-M-d ah:mm\nThread Name= 9 formatter = yy-M-d ah:mm\n```\n\n从输出中可以看出，Thread-0已经改变了formatter的值，但仍然是thread-2默认格式化程序与初始化值相同，其他线程也一样。\n\n上面有一段代码用到了创建 `ThreadLocal` 变量的那段代码用到了 Java8 的知识，它等于下面这段代码，如果你写了下面这段代码的话，IDEA会提示你转换为Java8的格式(IDEA真的不错！)。因为ThreadLocal类在Java 8中扩展，使用一个新的方法`withInitial()`，将Supplier功能接口作为参数。\n\n```java\n private static final ThreadLocal<SimpleDateFormat> formatter = new ThreadLocal<SimpleDateFormat>(){\n        @Override\n        protected SimpleDateFormat initialValue()\n        {\n            return new SimpleDateFormat(\"yyyyMMdd HHmm\");\n        }\n    };\n```\n\n### 3.3. ThreadLocal原理\n\n从 `Thread`类源代码入手。\n\n```java\npublic class Thread implements Runnable {\n ......\n//与此线程有关的ThreadLocal值。由ThreadLocal类维护\nThreadLocal.ThreadLocalMap threadLocals = null;\n\n//与此线程有关的InheritableThreadLocal值。由InheritableThreadLocal类维护\nThreadLocal.ThreadLocalMap inheritableThreadLocals = null;\n ......\n}\n```\n\n从上面`Thread`类 源代码可以看出`Thread` 类中有一个 `threadLocals` 和 一个  `inheritableThreadLocals` 变量，它们都是 `ThreadLocalMap`  类型的变量,我们可以把 `ThreadLocalMap`  理解为`ThreadLocal` 类实现的定制化的 `HashMap`。默认情况下这两个变量都是null，只有当前线程调用 `ThreadLocal` 类的 `set`或`get`方法时才创建它们，实际上调用这两个方法的时候，我们调用的是`ThreadLocalMap`类对应的 `get()`、`set() `方法。\n\n`ThreadLocal`类的`set()`方法\n\n```java\n    public void set(T value) {\n        Thread t = Thread.currentThread();\n        ThreadLocalMap map = getMap(t);\n        if (map != null)\n            map.set(this, value);\n        else\n            createMap(t, value);\n    }\n    ThreadLocalMap getMap(Thread t) {\n        return t.threadLocals;\n    }\n```\n\n通过上面这些内容，我们足以通过猜测得出结论：**最终的变量是放在了当前线程的 `ThreadLocalMap` 中，并不是存在 `ThreadLocal` 上，`ThreadLocal` 可以理解为只是`ThreadLocalMap`的封装，传递了变量值。** `ThrealLocal` 类中可以通过`Thread.currentThread()`获取到当前线程对象后，直接通过`getMap(Thread t)`可以访问到该线程的`ThreadLocalMap`对象。\n\n**每个`Thread`中都具备一个`ThreadLocalMap`，而`ThreadLocalMap`可以存储以`ThreadLocal`为key ，Object 对象为 value的键值对。** \n\n```java\nThreadLocalMap(ThreadLocal<?> firstKey, Object firstValue) {\n ......\n}\n```\n\n比如我们在同一个线程中声明了两个 `ThreadLocal` 对象的话，会使用 `Thread`内部都是使用仅有那个`ThreadLocalMap` 存放数据的，`ThreadLocalMap`的 key 就是 `ThreadLocal`对象，value 就是 `ThreadLocal` 对象调用`set`方法设置的值。\n\n![ThreadLocal数据结构](https://upload-images.jianshu.io/upload_images/7432604-ad2ff581127ba8cc.jpg?imageMogr2/auto-orient/strip|imageView2/2/w/806)\n\n`ThreadLocalMap`是`ThreadLocal`的静态内部类。\n\n![ThreadLocal内部类](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/ThreadLocal内部类.png)\n\n### 3.4. ThreadLocal 内存泄露问题\n\n`ThreadLocalMap` 中使用的 key 为 `ThreadLocal` 的弱引用,而 value 是强引用。所以，如果 `ThreadLocal` 没有被外部强引用的情况下，在垃圾回收的时候，key 会被清理掉，而 value 不会被清理掉。这样一来，`ThreadLocalMap` 中就会出现key为null的Entry。假如我们不做任何措施的话，value 永远无法被GC 回收，这个时候就可能会产生内存泄露。ThreadLocalMap实现中已经考虑了这种情况，在调用 `set()`、`get()`、`remove()` 方法的时候，会清理掉 key 为 null 的记录。使用完 `ThreadLocal`方法后 最好手动调用`remove()`方法\n\n```java\n      static class Entry extends WeakReference<ThreadLocal<?>> {\n            /** The value associated with this ThreadLocal. */\n            Object value;\n\n            Entry(ThreadLocal<?> k, Object v) {\n                super(k);\n                value = v;\n            }\n        }\n```\n\n**弱引用介绍：**\n\n> 如果一个对象只具有弱引用，那就类似于**可有可无的生活用品**。弱引用与软引用的区别在于：只具有弱引用的对象拥有更短暂的生命周期。在垃圾回收器线程扫描它 所管辖的内存区域的过程中，一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。不过，由于垃圾回收器是一个优先级很低的线程， 因此不一定会很快发现那些只具有弱引用的对象。\n>\n> 弱引用可以和一个引用队列（ReferenceQueue）联合使用，如果弱引用所引用的对象被垃圾回收，Java虚拟机就会把这个弱引用加入到与之关联的引用队列中。\n\n## 4. 线程池\n\n### 4.1. 为什么要用线程池？\n\n> **池化技术相比大家已经屡见不鲜了，线程池、数据库连接池、Http 连接池等等都是对这个思想的应用。池化技术的思想主要是为了减少每次获取资源的消耗，提高对资源的利用率。**\n\n**线程池**提供了一种限制和管理资源（包括执行一个任务）。 每个**线程池**还维护一些基本统计信息，例如已完成任务的数量。\n\n这里借用《Java 并发编程的艺术》提到的来说一下**使用线程池的好处**：\n\n- **降低资源消耗**。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。\n- **提高响应速度**。当任务到达时，任务可以不需要的等到线程创建就能立即执行。\n- **提高线程的可管理性**。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。\n\n### 4.2. 实现Runnable接口和Callable接口的区别\n\n`Runnable`自Java 1.0以来一直存在，但`Callable`仅在Java 1.5中引入,目的就是为了来处理`Runnable`不支持的用例。**`Runnable` 接口**不会返回结果或抛出检查异常，但是**`Callable` 接口**可以。所以，如果任务不需要返回结果或抛出异常推荐使用 **`Runnable` 接口**，这样代码看起来会更加简洁。\n\n工具类 `Executors` 可以实现 `Runnable` 对象和 `Callable` 对象之间的相互转换。（`Executors.callable（Runnable task`）或 `Executors.callable（Runnable task，Object resule）`）。\n\n`Runnable.java`\n\n```java\n@FunctionalInterface\npublic interface Runnable {\n   /**\n    * 被线程执行，没有返回值也无法抛出异常\n    */\n    public abstract void run();\n}\n```\n\n`Callable.java`\n\n```java\n@FunctionalInterface\npublic interface Callable<V> {\n    /**\n     * 计算结果，或在无法这样做时抛出异常。\n     * @return 计算得出的结果\n     * @throws 如果无法计算结果，则抛出异常\n     */\n    V call() throws Exception;\n}\n```\n\n### 4.3. 执行execute()方法和submit()方法的区别是什么呢？\n\n1. **`execute()`方法用于提交不需要返回值的任务，所以无法判断任务是否被线程池执行成功与否；**\n2. **`submit()`方法用于提交需要返回值的任务。线程池会返回一个 `Future` 类型的对象，通过这个 `Future` 对象可以判断任务是否执行成功**，并且可以通过 `Future` 的 `get()`方法来获取返回值，`get()`方法会阻塞当前线程直到任务完成，而使用 `get（long timeout，TimeUnit unit）`方法则会阻塞当前线程一段时间后立即返回，这时候有可能任务没有执行完。\n\n我们以**`AbstractExecutorService`**接口中的一个 `submit` 方法为例子来看看源代码：\n\n```java\n    public Future<?> submit(Runnable task) {\n        if (task == null) throw new NullPointerException();\n        RunnableFuture<Void> ftask = newTaskFor(task, null);\n        execute(ftask);\n        return ftask;\n    }\n```\n\n上面方法调用的 `newTaskFor` 方法返回了一个 `FutureTask` 对象。\n\n```java\n    protected <T> RunnableFuture<T> newTaskFor(Runnable runnable, T value) {\n        return new FutureTask<T>(runnable, value);\n    }\n```\n\n我们再来看看`execute()`方法：\n\n```java\n    public void execute(Runnable command) {\n      ...\n    }\n```\n\n### 4.4. 如何创建线程池\n\n《阿里巴巴Java开发手册》中强制线程池不允许使用 Executors 去创建，而是通过 ThreadPoolExecutor 的方式，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险\n\n> Executors 返回线程池对象的弊端如下：\n>\n> - **FixedThreadPool 和 SingleThreadExecutor** ： 允许请求的队列长度为 Integer.MAX_VALUE ，可能堆积大量的请求，从而导致OOM。\n> - **CachedThreadPool 和 ScheduledThreadPool** ： 允许创建的线程数量为 Integer.MAX_VALUE ，可能会创建大量线程，从而导致OOM。\n\n**方式一：通过构造方法实现**\n![ThreadPoolExecutor构造方法](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/ThreadPoolExecutor构造方法.png)\n**方式二：通过Executor 框架的工具类Executors来实现**\n我们可以创建三种类型的ThreadPoolExecutor：\n\n- **FixedThreadPool** ： 该方法返回一个固定线程数量的线程池。该线程池中的线程数量始终不变。当有一个新的任务提交时，线程池中若有空闲线程，则立即执行。若没有，则新的任务会被暂存在一个任务队列中，待有线程空闲时，便处理在任务队列中的任务。\n- **SingleThreadExecutor：** 方法返回一个只有一个线程的线程池。若多余一个任务被提交到该线程池，任务会被保存在一个任务队列中，待线程空闲，按先入先出的顺序执行队列中的任务。\n- **CachedThreadPool：** 该方法返回一个可根据实际情况调整线程数量的线程池。线程池的线程数量不确定，但若有空闲线程可以复用，则会优先使用可复用的线程。若所有线程均在工作，又有新的任务提交，则会创建新的线程处理任务。所有线程在当前任务执行完毕后，将返回线程池进行复用。\n\n对应Executors工具类中的方法如图所示：\n![Executor框架的工具类](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/Executor框架的工具类.png)\n\n### 4.5 ThreadPoolExecutor 类分析\n\n`ThreadPoolExecutor` 类中提供的四个构造方法。我们来看最长的那个，其余三个都是在这个构造方法的基础上产生（其他几个构造方法说白点都是给定某些默认参数的构造方法比如默认制定拒绝策略是什么），这里就不贴代码讲了，比较简单。\n\n```java\n    /**\n     * 用给定的初始参数创建一个新的ThreadPoolExecutor。\n     */\n    public ThreadPoolExecutor(int corePoolSize,\n                              int maximumPoolSize,\n                              long keepAliveTime,\n                              TimeUnit unit,\n                              BlockingQueue<Runnable> workQueue,\n                              ThreadFactory threadFactory,\n                              RejectedExecutionHandler handler) {\n        if (corePoolSize < 0 ||\n            maximumPoolSize <= 0 ||\n            maximumPoolSize < corePoolSize ||\n            keepAliveTime < 0)\n            throw new IllegalArgumentException();\n        if (workQueue == null || threadFactory == null || handler == null)\n            throw new NullPointerException();\n        this.corePoolSize = corePoolSize;\n        this.maximumPoolSize = maximumPoolSize;\n        this.workQueue = workQueue;\n        this.keepAliveTime = unit.toNanos(keepAliveTime);\n        this.threadFactory = threadFactory;\n        this.handler = handler;\n    }\n```\n\n**下面这些对创建 非常重要，在后面使用线程池的过程中你一定会用到！所以，务必拿着小本本记清楚。**\n\n#### 4.5.1 `ThreadPoolExecutor`构造函数重要参数分析\n\n**`ThreadPoolExecutor` 3 个最重要的参数：**\n\n- **`corePoolSize` :** 核心线程数线程数定义了最小可以同时运行的线程数量。\n- **`maximumPoolSize` :** 当队列中存放的任务达到队列容量的时候，当前可以同时运行的线程数量变为最大线程数。\n- **`workQueue`:** 当新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到的话，新任务就会被存放在队列中。\n\n`ThreadPoolExecutor`其他常见参数:\n\n1. **`keepAliveTime`**:当线程池中的线程数量大于 `corePoolSize` 的时候，如果这时没有新的任务提交，核心线程外的线程不会立即销毁，而是会等待，直到等待的时间超过了 `keepAliveTime`才会被回收销毁；\n2. **`unit`** : `keepAliveTime` 参数的时间单位。\n3. **`threadFactory`** :executor 创建新线程的时候会用到。\n4. **`handler`** :饱和策略。关于饱和策略下面单独介绍一下。\n\n#### 4.5.2 `ThreadPoolExecutor` 饱和策略\n\n**`ThreadPoolExecutor` 饱和策略定义:**\n\n如果当前同时运行的线程数量达到最大线程数量并且队列也已经被放满了任时，`ThreadPoolTaskExecutor` 定义一些策略:\n\n- **`ThreadPoolExecutor.AbortPolicy`**：抛出 `RejectedExecutionException`来拒绝新任务的处理。\n- **`ThreadPoolExecutor.CallerRunsPolicy`**：调用执行自己的线程运行任务。您不会任务请求。但是这种策略会降低对于新任务提交速度，影响程序的整体性能。另外，这个策略喜欢增加队列容量。如果您的应用程序可以承受此延迟并且你不能任务丢弃任何一个任务请求的话，你可以选择这个策略。\n- **`ThreadPoolExecutor.DiscardPolicy`：** 不处理新任务，直接丢弃掉。\n- **`ThreadPoolExecutor.DiscardOldestPolicy`：** 此策略将丢弃最早的未处理的任务请求。\n\n举个例子： Spring 通过 `ThreadPoolTaskExecutor` 或者我们直接通过 `ThreadPoolExecutor` 的构造函数创建线程池的时候，当我们不指定 `RejectedExecutionHandler` 饱和策略的话来配置线程池的时候默认使用的是 `ThreadPoolExecutor.AbortPolicy`。在默认情况下，`ThreadPoolExecutor` 将抛出 `RejectedExecutionException` 来拒绝新来的任务 ，这代表你将丢失对这个任务的处理。 对于可伸缩的应用程序，建议使用 `ThreadPoolExecutor.CallerRunsPolicy`。当最大池被填满时，此策略为我们提供可伸缩队列。（这个直接查看 `ThreadPoolExecutor` 的构造函数源码就可以看出，比较简单的原因，这里就不贴代码了）\n\n### 4.6 一个简单的线程池Demo:`Runnable`+`ThreadPoolExecutor`\n\n为了让大家更清楚上面的面试题中的一些概念，我写了一个简单的线程池 Demo。\n\n首先创建一个 `Runnable` 接口的实现类（当然也可以是 `Callable` 接口，我们上面也说了两者的区别。）\n\n`MyRunnable.java`\n\n```java\nimport java.util.Date;\n\n/**\n * 这是一个简单的Runnable类，需要大约5秒钟来执行其任务。\n * @author shuang.kou\n */\npublic class MyRunnable implements Runnable {\n\n    private String command;\n\n    public MyRunnable(String s) {\n        this.command = s;\n    }\n\n    @Override\n    public void run() {\n        System.out.println(Thread.currentThread().getName() + \" Start. Time = \" + new Date());\n        processCommand();\n        System.out.println(Thread.currentThread().getName() + \" End. Time = \" + new Date());\n    }\n\n    private void processCommand() {\n        try {\n            Thread.sleep(5000);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n    }\n\n    @Override\n    public String toString() {\n        return this.command;\n    }\n}\n\n```\n\n编写测试程序，我们这里以阿里巴巴推荐的使用 `ThreadPoolExecutor` 构造函数自定义参数的方式来创建线程池。\n\n`ThreadPoolExecutorDemo.java`\n\n```java\nimport java.util.concurrent.ArrayBlockingQueue;\nimport java.util.concurrent.ThreadPoolExecutor;\nimport java.util.concurrent.TimeUnit;\n\npublic class ThreadPoolExecutorDemo {\n\n    private static final int CORE_POOL_SIZE = 5;\n    private static final int MAX_POOL_SIZE = 10;\n    private static final int QUEUE_CAPACITY = 100;\n    private static final Long KEEP_ALIVE_TIME = 1L;\n    public static void main(String[] args) {\n\n        //使用阿里巴巴推荐的创建线程池的方式\n        //通过ThreadPoolExecutor构造函数自定义参数创建\n        ThreadPoolExecutor executor = new ThreadPoolExecutor(\n                CORE_POOL_SIZE,\n                MAX_POOL_SIZE,\n                KEEP_ALIVE_TIME,\n                TimeUnit.SECONDS,\n                new ArrayBlockingQueue<>(QUEUE_CAPACITY),\n                new ThreadPoolExecutor.CallerRunsPolicy());\n\n        for (int i = 0; i < 10; i++) {\n            //创建WorkerThread对象（WorkerThread类实现了Runnable 接口）\n            Runnable worker = new MyRunnable(\"\" + i);\n            //执行Runnable\n            executor.execute(worker);\n        }\n        //终止线程池\n        executor.shutdown();\n        while (!executor.isTerminated()) {\n        }\n        System.out.println(\"Finished all threads\");\n    }\n}\n\n```\n\n可以看到我们上面的代码指定了：\n\n1. `corePoolSize`: 核心线程数为 5。\n2. `maximumPoolSize` ：最大线程数 10\n3. `keepAliveTime` : 等待时间为 1L。\n4. `unit`: 等待时间的单位为 TimeUnit.SECONDS。\n5. `workQueue`：任务队列为 `ArrayBlockingQueue`，并且容量为 100;\n6. `handler`:饱和策略为 `CallerRunsPolicy`。\n\n**Output：**\n\n```\npool-1-thread-2 Start. Time = Tue Nov 12 20:59:44 CST 2019\npool-1-thread-5 Start. Time = Tue Nov 12 20:59:44 CST 2019\npool-1-thread-4 Start. Time = Tue Nov 12 20:59:44 CST 2019\npool-1-thread-1 Start. Time = Tue Nov 12 20:59:44 CST 2019\npool-1-thread-3 Start. Time = Tue Nov 12 20:59:44 CST 2019\npool-1-thread-5 End. Time = Tue Nov 12 20:59:49 CST 2019\npool-1-thread-3 End. Time = Tue Nov 12 20:59:49 CST 2019\npool-1-thread-2 End. Time = Tue Nov 12 20:59:49 CST 2019\npool-1-thread-4 End. Time = Tue Nov 12 20:59:49 CST 2019\npool-1-thread-1 End. Time = Tue Nov 12 20:59:49 CST 2019\npool-1-thread-2 Start. Time = Tue Nov 12 20:59:49 CST 2019\npool-1-thread-1 Start. Time = Tue Nov 12 20:59:49 CST 2019\npool-1-thread-4 Start. Time = Tue Nov 12 20:59:49 CST 2019\npool-1-thread-3 Start. Time = Tue Nov 12 20:59:49 CST 2019\npool-1-thread-5 Start. Time = Tue Nov 12 20:59:49 CST 2019\npool-1-thread-2 End. Time = Tue Nov 12 20:59:54 CST 2019\npool-1-thread-3 End. Time = Tue Nov 12 20:59:54 CST 2019\npool-1-thread-4 End. Time = Tue Nov 12 20:59:54 CST 2019\npool-1-thread-5 End. Time = Tue Nov 12 20:59:54 CST 2019\npool-1-thread-1 End. Time = Tue Nov 12 20:59:54 CST 2019\n\n```\n\n### 4.7 线程池原理分析\n\n承接 4.6 节，我们通过代码输出结果可以看出：**线程池每次会同时执行 5 个任务，这 5 个任务执行完之后，剩余的 5 个任务才会被执行。** 大家可以先通过上面讲解的内容，分析一下到底是咋回事？（自己独立思考一会）\n\n现在，我们就分析上面的输出内容来简单分析一下线程池原理。\n\n**为了搞懂线程池的原理，我们需要首先分析一下 `execute`方法。**在 4.6 节中的 Demo 中我们使用 `executor.execute(worker)`来提交一个任务到线程池中去，这个方法非常重要，下面我们来看看它的源码：\n\n```java\n   // 存放线程池的运行状态 (runState) 和线程池内有效线程的数量 (workerCount)\n   private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));\n\n    private static int workerCountOf(int c) {\n        return c & CAPACITY;\n    }\n\n    private final BlockingQueue<Runnable> workQueue;\n\n    public void execute(Runnable command) {\n        // 如果任务为null，则抛出异常。\n        if (command == null)\n            throw new NullPointerException();\n        // ctl 中保存的线程池当前的一些状态信息\n        int c = ctl.get();\n\n        //  下面会涉及到 3 步 操作\n        // 1.首先判断当前线程池中之行的任务数量是否小于 corePoolSize\n        // 如果小于的话，通过addWorker(command, true)新建一个线程，并将任务(command)添加到该线程中；然后，启动该线程从而执行任务。\n        if (workerCountOf(c) < corePoolSize) {\n            if (addWorker(command, true))\n                return;\n            c = ctl.get();\n        }\n        // 2.如果当前之行的任务数量大于等于 corePoolSize 的时候就会走到这里\n        // 通过 isRunning 方法判断线程池状态，线程池处于 RUNNING 状态才会被并且队列可以加入任务，该任务才会被加入进去\n        if (isRunning(c) && workQueue.offer(command)) {\n            int recheck = ctl.get();\n            // 再次获取线程池状态，如果线程池状态不是 RUNNING 状态就需要从任务队列中移除任务，并尝试判断线程是否全部执行完毕。同时执行拒绝策略。\n            if (!isRunning(recheck) && remove(command))\n                reject(command);\n                // 如果当前线程池为空就新创建一个线程并执行。\n            else if (workerCountOf(recheck) == 0)\n                addWorker(null, false);\n        }\n        //3. 通过addWorker(command, false)新建一个线程，并将任务(command)添加到该线程中；然后，启动该线程从而执行任务。\n        //如果addWorker(command, false)执行失败，则通过reject()执行相应的拒绝策略的内容。\n        else if (!addWorker(command, false))\n            reject(command);\n    }\n```\n\n通过下图可以更好的对上面这 3 步做一个展示，下图是我为了省事直接从网上找到，原地址不明。\n\n![图解线程池实现原理](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-7/图解线程池实现原理.png)\n\n现在，让我们在回到 4.6 节我们写的 Demo， 现在应该是不是很容易就可以搞懂它的原理了呢？\n\n没搞懂的话，也没关系，可以看看我的分析：\n\n> 我们在代码中模拟了 10 个任务，我们配置的核心线程数为 5 、等待队列容量为 100 ，所以每次只可能存在 5 个任务同时执行，剩下的 5 个任务会被放到等待队列中去。当前的 5 个任务之行完成后，才会之行剩下的 5 个任务。\n\n## 5. Atomic 原子类\n\n### 5.1. 介绍一下Atomic 原子类\n\nAtomic 翻译成中文是原子的意思。在化学上，我们知道原子是构成一般物质的最小单位，在化学反应中是不可分割的。在我们这里 Atomic 是指一个操作是不可中断的。即使是在多个线程一起执行的时候，一个操作一旦开始，就不会被其他线程干扰。\n\n所以，所谓原子类说简单点就是具有原子/原子操作特征的类。\n\n\n并发包 `java.util.concurrent` 的原子类都存放在`java.util.concurrent.atomic`下,如下图所示。\n\n![JUC原子类概览](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/JUC原子类概览.png)\n\n### 5.2. JUC 包中的原子类是哪4类?\n\n**基本类型** \n\n使用原子的方式更新基本类型\n\n- AtomicInteger：整形原子类\n- AtomicLong：长整型原子类\n- AtomicBoolean：布尔型原子类\n\n**数组类型**\n\n使用原子的方式更新数组里的某个元素\n\n\n- AtomicIntegerArray：整形数组原子类\n- AtomicLongArray：长整形数组原子类\n- AtomicReferenceArray：引用类型数组原子类\n\n**引用类型**\n\n- AtomicReference：引用类型原子类\n- AtomicStampedReference：原子更新引用类型里的字段原子类\n- AtomicMarkableReference ：原子更新带有标记位的引用类型\n\n**对象的属性修改类型**\n\n- AtomicIntegerFieldUpdater：原子更新整形字段的更新器\n- AtomicLongFieldUpdater：原子更新长整形字段的更新器\n- AtomicStampedReference：原子更新带有版本号的引用类型。该类将整数值与引用关联起来，可用于解决原子的更新数据和数据的版本号，可以解决使用 CAS 进行原子更新时可能出现的 ABA 问题。\n\n\n### 5.3. 讲讲 AtomicInteger 的使用\n\n **AtomicInteger 类常用方法**\n\n```java\npublic final int get() //获取当前的值\npublic final int getAndSet(int newValue)//获取当前的值，并设置新的值\npublic final int getAndIncrement()//获取当前的值，并自增\npublic final int getAndDecrement() //获取当前的值，并自减\npublic final int getAndAdd(int delta) //获取当前的值，并加上预期的值\nboolean compareAndSet(int expect, int update) //如果输入的数值等于预期值，则以原子方式将该值设置为输入值（update）\npublic final void lazySet(int newValue)//最终设置为newValue,使用 lazySet 设置之后可能导致其他线程在之后的一小段时间内还是可以读到旧的值。\n```\n\n **AtomicInteger 类的使用示例**\n\n使用 AtomicInteger 之后，不用对 increment() 方法加锁也可以保证线程安全。\n```java\nclass AtomicIntegerTest {\n        private AtomicInteger count = new AtomicInteger();\n      //使用AtomicInteger之后，不需要对该方法加锁，也可以实现线程安全。\n        public void increment() {\n                  count.incrementAndGet();\n        }\n     \n       public int getCount() {\n                return count.get();\n        }\n}\n\n```\n\n### 5.4. 能不能给我简单介绍一下 AtomicInteger 类的原理\n\nAtomicInteger 线程安全原理简单分析\n\nAtomicInteger 类的部分源码：\n\n```java\n    // setup to use Unsafe.compareAndSwapInt for updates（更新操作时提供“比较并替换”的作用）\n    private static final Unsafe unsafe = Unsafe.getUnsafe();\n    private static final long valueOffset;\n\n    static {\n        try {\n            valueOffset = unsafe.objectFieldOffset\n                (AtomicInteger.class.getDeclaredField(\"value\"));\n        } catch (Exception ex) { throw new Error(ex); }\n    }\n\n    private volatile int value;\n```\n\nAtomicInteger 类主要利用 CAS (compare and swap) + volatile 和 native 方法来保证原子操作，从而避免 synchronized 的高开销，执行效率大为提升。\n\nCAS的原理是拿期望的值和原本的一个值作比较，如果相同则更新成新的值。UnSafe 类的 objectFieldOffset() 方法是一个本地方法，这个方法是用来拿到“原来的值”的内存地址，返回值是 valueOffset。另外 value 是一个volatile变量，在内存中可见，因此 JVM 可以保证任何时刻任何线程总能拿到该变量的最新值。\n\n关于 Atomic 原子类这部分更多内容可以查看我的这篇文章：并发编程面试必备：[JUC 中的 Atomic 原子类总结](https://mp.weixin.qq.com/s/joa-yOiTrYF67bElj8xqvg)\n\n## 6. AQS\n\n### 6.1. AQS 介绍\n\nAQS的全称为（AbstractQueuedSynchronizer），这个类在java.util.concurrent.locks包下面。\n\n![AQS类](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/AQS类.png)\n\nAQS是一个用来构建锁和同步器的框架，使用AQS能简单且高效地构造出应用广泛的大量的同步器，比如我们提到的ReentrantLock，Semaphore，其他的诸如ReentrantReadWriteLock，SynchronousQueue，FutureTask等等皆是基于AQS的。当然，我们自己也能利用AQS非常轻松容易地构造出符合我们自己需求的同步器。\n\n### 6.2. AQS 原理分析\n\nAQS 原理这部分参考了部分博客，在5.2节末尾放了链接。\n\n> 在面试中被问到并发知识的时候，大多都会被问到“请你说一下自己对于AQS原理的理解”。下面给大家一个示例供大家参加，面试不是背题，大家一定要加入自己的思想，即使加入不了自己的思想也要保证自己能够通俗的讲出来而不是背出来。\n\n下面大部分内容其实在AQS类注释上已经给出了，不过是英语看着比较吃力一点，感兴趣的话可以看看源码。\n\n#### 6.2.1. AQS 原理概览\n\n**AQS核心思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制AQS是用CLH队列锁实现的，即将暂时获取不到锁的线程加入到队列中。**\n\n> CLH(Craig,Landin,and Hagersten)队列是一个虚拟的双向队列（虚拟的双向队列即不存在队列实例，仅存在结点之间的关联关系）。AQS是将每条请求共享资源的线程封装成一个CLH锁队列的一个结点（Node）来实现锁的分配。\n\n看个AQS(AbstractQueuedSynchronizer)原理图：\n\n\n![AQS原理图](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/AQS原理图.png)\n\nAQS使用一个int成员变量来表示同步状态，通过内置的FIFO队列来完成获取资源线程的排队工作。AQS使用CAS对该同步状态进行原子操作实现对其值的修改。\n\n```java\nprivate volatile int state;//共享变量，使用volatile修饰保证线程可见性\n```\n\n状态信息通过protected类型的getState，setState，compareAndSetState进行操作\n\n```java\n\n//返回同步状态的当前值\nprotected final int getState() {  \n        return state;\n}\n // 设置同步状态的值\nprotected final void setState(int newState) { \n        state = newState;\n}\n//原子地（CAS操作）将同步状态值设置为给定值update如果当前同步状态的值等于expect（期望值）\nprotected final boolean compareAndSetState(int expect, int update) {\n        return unsafe.compareAndSwapInt(this, stateOffset, expect, update);\n}\n```\n\n#### 6.2.2. AQS 对资源的共享方式\n\n**AQS定义两种资源共享方式**\n\n- **Exclusive**（独占）：只有一个线程能执行，如ReentrantLock。又可分为公平锁和非公平锁：\n    - 公平锁：按照线程在队列中的排队顺序，先到者先拿到锁\n    - 非公平锁：当线程要获取锁时，无视队列顺序直接去抢锁，谁抢到就是谁的\n- **Share**（共享）：多个线程可同时执行，如Semaphore/CountDownLatch。Semaphore、CountDownLatch、 CyclicBarrier、ReadWriteLock 我们都会在后面讲到。\n\nReentrantReadWriteLock 可以看成是组合式，因为ReentrantReadWriteLock也就是读写锁允许多个线程同时对某一资源进行读。\n\n不同的自定义同步器争用共享资源的方式也不同。自定义同步器在实现时只需要实现共享资源 state 的获取与释放方式即可，至于具体线程等待队列的维护（如获取资源失败入队/唤醒出队等），AQS已经在顶层实现好了。\n\n#### 6.2.3. AQS底层使用了模板方法模式\n\n同步器的设计是基于模板方法模式的，如果需要自定义同步器一般的方式是这样（模板方法模式很经典的一个应用）：\n\n1. 使用者继承AbstractQueuedSynchronizer并重写指定的方法。（这些重写方法很简单，无非是对于共享资源state的获取和释放）\n2. 将AQS组合在自定义同步组件的实现中，并调用其模板方法，而这些模板方法会调用使用者重写的方法。\n\n这和我们以往通过实现接口的方式有很大区别，这是模板方法模式很经典的一个运用。\n\n**AQS使用了模板方法模式，自定义同步器时需要重写下面几个AQS提供的模板方法：**\n\n```java\nisHeldExclusively()//该线程是否正在独占资源。只有用到condition才需要去实现它。\ntryAcquire(int)//独占方式。尝试获取资源，成功则返回true，失败则返回false。\ntryRelease(int)//独占方式。尝试释放资源，成功则返回true，失败则返回false。\ntryAcquireShared(int)//共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。\ntryReleaseShared(int)//共享方式。尝试释放资源，成功则返回true，失败则返回false。\n\n```\n\n默认情况下，每个方法都抛出 `UnsupportedOperationException`。 这些方法的实现必须是内部线程安全的，并且通常应该简短而不是阻塞。AQS类中的其他方法都是final ，所以无法被其他类使用，只有这几个方法可以被其他类使用。 \n\n以ReentrantLock为例，state初始化为0，表示未锁定状态。A线程lock()时，会调用tryAcquire()独占该锁并将state+1。此后，其他线程再tryAcquire()时就会失败，直到A线程unlock()到state=0（即释放锁）为止，其它线程才有机会获取该锁。当然，释放锁之前，A线程自己是可以重复获取此锁的（state会累加），这就是可重入的概念。但要注意，获取多少次就要释放多么次，这样才能保证state是能回到零态的。\n\n再以CountDownLatch以例，任务分为N个子线程去执行，state也初始化为N（注意N要与线程个数一致）。这N个子线程是并行执行的，每个子线程执行完后countDown()一次，state会CAS(Compare and Swap)减1。等到所有子线程都执行完后(即state=0)，会unpark()主调用线程，然后主调用线程就会从await()函数返回，继续后余动作。\n\n一般来说，自定义同步器要么是独占方法，要么是共享方式，他们也只需实现`tryAcquire-tryRelease`、`tryAcquireShared-tryReleaseShared`中的一种即可。但AQS也支持自定义同步器同时实现独占和共享两种方式，如`ReentrantReadWriteLock`。\n\n推荐两篇 AQS 原理和相关源码分析的文章：\n\n- http://www.cnblogs.com/waterystone/p/4920797.html\n- https://www.cnblogs.com/chengxiao/archive/2017/07/24/7141160.html\n\n### 6.3. AQS 组件总结\n\n- **Semaphore(信号量)-允许多个线程同时访问：** synchronized 和 ReentrantLock 都是一次只允许一个线程访问某个资源，Semaphore(信号量)可以指定多个线程同时访问某个资源。\n- **CountDownLatch （倒计时器）：** CountDownLatch是一个同步工具类，用来协调多个线程之间的同步。这个工具通常用来控制线程等待，它可以让某一个线程等待直到倒计时结束，再开始执行。\n- **CyclicBarrier(循环栅栏)：** CyclicBarrier 和 CountDownLatch 非常类似，它也可以实现线程间的技术等待，但是它的功能比 CountDownLatch 更加复杂和强大。主要应用场景和 CountDownLatch 类似。CyclicBarrier 的字面意思是可循环使用（Cyclic）的屏障（Barrier）。它要做的事情是，让一组线程到达一个屏障（也可以叫同步点）时被阻塞，直到最后一个线程到达屏障时，屏障才会开门，所有被屏障拦截的线程才会继续干活。CyclicBarrier默认的构造方法是 CyclicBarrier(int parties)，其参数表示屏障拦截的线程数量，每个线程调用await()方法告诉 CyclicBarrier 我已经到达了屏障，然后当前线程被阻塞。\n\n## 7 Reference\n\n- 《深入理解 Java 虚拟机》\n- 《实战 Java 高并发程序设计》\n- 《Java并发编程的艺术》\n- http://www.cnblogs.com/waterystone/p/4920797.html\n- https://www.cnblogs.com/chengxiao/archive/2017/07/24/7141160.html\n- <https://www.journaldev.com/1076/java-threadlocal-example>\n","source":"_posts/2018-06-08-kongzheng1993-java多线程总结.md","raw":"---\nlayout: post\ntitle: \"java多线程总结\"\ndate: 2018-06-08\nexcerpt: \"java 多线程\"\ntags: [java,多线程,安全]\ncategories: [java]\ncomments: true\n---\n\n以下文字摘自[JavaGuide](https://github.com/Snailclimb/JavaGuide)\n\n<!-- TOC -->\n\n- [Java 并发基础常见面试题总结](#java-并发基础常见面试题总结)\n    - [1. 什么是线程和进程?](#1-什么是线程和进程)\n        - [1.1. 何为进程?](#11-何为进程)\n        - [1.2. 何为线程?](#12-何为线程)\n    - [2. 请简要描述线程与进程的关系,区别及优缺点？](#2-请简要描述线程与进程的关系区别及优缺点)\n        - [2.1. 图解进程和线程的关系](#21-图解进程和线程的关系)\n        - [2.2. 程序计数器为什么是私有的?](#22-程序计数器为什么是私有的)\n        - [2.3. 虚拟机栈和本地方法栈为什么是私有的?](#23-虚拟机栈和本地方法栈为什么是私有的)\n        - [2.4. 一句话简单了解堆和方法区](#24-一句话简单了解堆和方法区)\n    - [3. 说说并发与并行的区别?](#3-说说并发与并行的区别)\n    - [4. 为什么要使用多线程呢?](#4-为什么要使用多线程呢)\n    - [5. 使用多线程可能带来什么问题?](#5-使用多线程可能带来什么问题)\n    - [6. 说说线程的生命周期和状态?](#6-说说线程的生命周期和状态)\n    - [7. 什么是上下文切换?](#7-什么是上下文切换)\n    - [8. 什么是线程死锁?如何避免死锁?](#8-什么是线程死锁如何避免死锁)\n        - [8.1. 认识线程死锁](#81-认识线程死锁)\n        - [8.2. 如何避免线程死锁?](#82-如何避免线程死锁)\n    - [9. 说说 sleep() 方法和 wait() 方法区别和共同点?](#9-说说-sleep-方法和-wait-方法区别和共同点)\n    - [10. 为什么我们调用 start() 方法时会执行 run() 方法，为什么我们不能直接调用 run() 方法？](#10-为什么我们调用-start-方法时会执行-run-方法为什么我们不能直接调用-run-方法)\n\n<!-- /TOC -->\n\n# Java 并发基础常见面试题总结\n\n## 1. 什么是线程和进程?\n\n### 1.1. 何为进程?\n\n进程是程序的一次执行过程，是系统运行程序的基本单位，因此进程是动态的。系统运行一个程序即是一个进程从创建，运行到消亡的过程。\n\n在 Java 中，当我们启动 main 函数时其实就是启动了一个 JVM 的进程，而 main 函数所在的线程就是这个进程中的一个线程，也称主线程。\n\n如下图所示，在 windows 中通过查看任务管理器的方式，我们就可以清楚看到 window 当前运行的进程（.exe 文件的运行）。\n\n![进程示例图片-Windows](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/进程示例图片-Windows.png)\n\n### 1.2. 何为线程?\n\n线程与进程相似，但线程是一个比进程更小的执行单位。一个进程在其执行的过程中可以产生多个线程。与进程不同的是同类的多个线程共享进程的**堆**和**方法区**资源，但每个线程有自己的**程序计数器**、**虚拟机栈**和**本地方法栈**，所以系统在产生一个线程，或是在各个线程之间作切换工作时，负担要比进程小得多，也正因为如此，线程也被称为轻量级进程。\n\nJava 程序天生就是多线程程序，我们可以通过 JMX 来看一下一个普通的 Java 程序有哪些线程，代码如下。\n\n```java\npublic class MultiThread {\n\tpublic static void main(String[] args) {\n\t\t// 获取 Java 线程管理 MXBean\n\tThreadMXBean threadMXBean = ManagementFactory.getThreadMXBean();\n\t\t// 不需要获取同步的 monitor 和 synchronizer 信息，仅获取线程和线程堆栈信息\n\t\tThreadInfo[] threadInfos = threadMXBean.dumpAllThreads(false, false);\n\t\t// 遍历线程信息，仅打印线程 ID 和线程名称信息\n\t\tfor (ThreadInfo threadInfo : threadInfos) {\n\t\t\tSystem.out.println(\"[\" + threadInfo.getThreadId() + \"] \" + threadInfo.getThreadName());\n\t\t}\n\t}\n}\n```\n\n上述程序输出如下（输出内容可能不同，不用太纠结下面每个线程的作用，只用知道 main 线程执行 main 方法即可）：\n\n```\n[5] Attach Listener //添加事件\n[4] Signal Dispatcher // 分发处理给 JVM 信号的线程\n[3] Finalizer //调用对象 finalize 方法的线程\n[2] Reference Handler //清除 reference 线程\n[1] main //main 线程,程序入口\n```\n\n从上面的输出内容可以看出：**一个 Java 程序的运行是 main 线程和多个其他线程同时运行**。\n\n## 2. 请简要描述线程与进程的关系,区别及优缺点？\n\n**从 JVM 角度说进程和线程之间的关系**\n\n### 2.1. 图解进程和线程的关系\n\n下图是 Java 内存区域，通过下图我们从 JVM 的角度来说一下线程和进程之间的关系。如果你对 Java 内存区域 (运行时数据区) 这部分知识不太了解的话可以阅读一下这篇文章：[《可能是把 Java 内存区域讲的最清楚的一篇文章》](https://github.com/Snailclimb/JavaGuide/blob/3965c02cc0f294b0bd3580df4868d5e396959e2e/Java%E7%9B%B8%E5%85%B3/%E5%8F%AF%E8%83%BD%E6%98%AF%E6%8A%8AJava%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F%E8%AE%B2%E7%9A%84%E6%9C%80%E6%B8%85%E6%A5%9A%E7%9A%84%E4%B8%80%E7%AF%87%E6%96%87%E7%AB%A0.md \"《可能是把 Java 内存区域讲的最清楚的一篇文章》\")\n\n<div align=\"center\">  \n<img src=\"https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-3/JVM运行时数据区域.png\" width=\"600px\"/>\n</div>\n\n从上图可以看出：一个进程中可以有多个线程，多个线程共享进程的**堆**和**方法区 (JDK1.8 之后的元空间)**资源，但是每个线程有自己的**程序计数器**、**虚拟机栈** 和 **本地方法栈**。\n\n**总结：** 线程 是 进程 划分成的更小的运行单位。线程和进程最大的不同在于基本上各进程是独立的，而各线程则不一定，因为同一进程中的线程极有可能会相互影响。线程执行开销小，但不利于资源的管理和保护；而进程正相反\n\n下面是该知识点的扩展内容！\n\n下面来思考这样一个问题：为什么**程序计数器**、**虚拟机栈**和**本地方法栈**是线程私有的呢？为什么堆和方法区是线程共享的呢？\n\n### 2.2. 程序计数器为什么是私有的?\n\n程序计数器主要有下面两个作用：\n\n1. 字节码解释器通过改变程序计数器来依次读取指令，从而实现代码的流程控制，如：顺序执行、选择、循环、异常处理。\n2. 在多线程的情况下，程序计数器用于记录当前线程执行的位置，从而当线程被切换回来的时候能够知道该线程上次运行到哪儿了。\n\n需要注意的是，如果执行的是 native 方法，那么程序计数器记录的是 undefined 地址，只有执行的是 Java 代码时程序计数器记录的才是下一条指令的地址。\n\n所以，程序计数器私有主要是为了**线程切换后能恢复到正确的执行位置**。\n\n### 2.3. 虚拟机栈和本地方法栈为什么是私有的?\n\n- **虚拟机栈：** 每个 Java 方法在执行的同时会创建一个栈帧用于存储局部变量表、操作数栈、常量池引用等信息。从方法调用直至执行完成的过程，就对应着一个栈帧在 Java 虚拟机栈中入栈和出栈的过程。\n- **本地方法栈：** 和虚拟机栈所发挥的作用非常相似，区别是： **虚拟机栈为虚拟机执行 Java 方法 （也就是字节码）服务，而本地方法栈则为虚拟机使用到的 Native 方法服务。** 在 HotSpot 虚拟机中和 Java 虚拟机栈合二为一。\n\n所以，为了**保证线程中的局部变量不被别的线程访问到**，虚拟机栈和本地方法栈是线程私有的。\n\n### 2.4. 一句话简单了解堆和方法区\n\n堆和方法区是所有线程共享的资源，其中堆是进程中最大的一块内存，主要用于存放新创建的对象 (所有对象都在这里分配内存)，方法区主要用于存放已被加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。\n\n## 3. 说说并发与并行的区别?\n\n- **并发：** 同一时间段，多个任务都在执行 (单位时间内不一定同时执行)；\n- **并行：** 单位时间内，多个任务同时执行。\n\n## 4. 为什么要使用多线程呢?\n\n先从总体上来说：\n\n- **从计算机底层来说：** 线程可以比作是轻量级的进程，是程序执行的最小单位,线程间的切换和调度的成本远远小于进程。另外，多核 CPU 时代意味着多个线程可以同时运行，这减少了线程上下文切换的开销。\n- **从当代互联网发展趋势来说：** 现在的系统动不动就要求百万级甚至千万级的并发量，而多线程并发编程正是开发高并发系统的基础，利用好多线程机制可以大大提高系统整体的并发能力以及性能。\n\n再深入到计算机底层来探讨：\n\n- **单核时代：** 在单核时代多线程主要是为了提高 CPU 和 IO 设备的综合利用率。举个例子：当只有一个线程的时候会导致 CPU 计算时，IO 设备空闲；进行 IO 操作时，CPU 空闲。我们可以简单地说这两者的利用率目前都是 50%左右。但是当有两个线程的时候就不一样了，当一个线程执行 CPU 计算时，另外一个线程可以进行 IO 操作，这样两个的利用率就可以在理想情况下达到 100%了。\n- **多核时代:** 多核时代多线程主要是为了提高 CPU 利用率。举个例子：假如我们要计算一个复杂的任务，我们只用一个线程的话，CPU 只会一个 CPU 核心被利用到，而创建多个线程就可以让多个 CPU 核心被利用到，这样就提高了 CPU 的利用率。\n\n## 5. 使用多线程可能带来什么问题?\n\n并发编程的目的就是为了能提高程序的执行效率提高程序运行速度，但是并发编程并不总是能提高程序运行速度的，而且并发编程可能会遇到很多问题，比如：内存泄漏、死锁、线程不安全等等。\n\n## 6. 说说线程的生命周期和状态?\n\nJava 线程在运行的生命周期中的指定时刻只可能处于下面 6 种不同状态的其中一个状态（图源《Java 并发编程艺术》4.1.4 节）。\n\n![Java 线程的状态 ](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/19-1-29/Java%E7%BA%BF%E7%A8%8B%E7%9A%84%E7%8A%B6%E6%80%81.png)\n\n线程在生命周期中并不是固定处于某一个状态而是随着代码的执行在不同状态之间切换。Java 线程状态变迁如下图所示（图源《Java 并发编程艺术》4.1.4 节）：\n\n![Java 线程状态变迁 ](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/19-1-29/Java+%E7%BA%BF%E7%A8%8B%E7%8A%B6%E6%80%81%E5%8F%98%E8%BF%81.png)\n\n由上图可以看出：线程创建之后它将处于 **NEW（新建）** 状态，调用 `start()` 方法后开始运行，线程这时候处于 **READY（可运行）** 状态。可运行状态的线程获得了 CPU 时间片（timeslice）后就处于 **RUNNING（运行）** 状态。\n\n> 操作系统隐藏 Java 虚拟机（JVM）中的 RUNNABLE 和 RUNNING 状态，它只能看到 RUNNABLE 状态（图源：[HowToDoInJava](https://howtodoinjava.com/ \"HowToDoInJava\")：[Java Thread Life Cycle and Thread States](https://howtodoinjava.com/java/multi-threading/java-thread-life-cycle-and-thread-states/ \"Java Thread Life Cycle and Thread States\")），所以 Java 系统一般将这两个状态统称为 **RUNNABLE（运行中）** 状态 。\n\n![RUNNABLE-VS-RUNNING](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-3/RUNNABLE-VS-RUNNING.png)\n\n当线程执行 `wait()`方法之后，线程进入 **WAITING（等待）** 状态。进入等待状态的线程需要依靠其他线程的通知才能够返回到运行状态，而 **TIME_WAITING(超时等待)** 状态相当于在等待状态的基础上增加了超时限制，比如通过 `sleep（long millis）`方法或 `wait（long millis）`方法可以将 Java 线程置于 TIMED WAITING 状态。当超时时间到达后 Java 线程将会返回到 RUNNABLE 状态。当线程调用同步方法时，在没有获取到锁的情况下，线程将会进入到 **BLOCKED（阻塞）** 状态。线程在执行 Runnable 的`run()`方法之后将会进入到 **TERMINATED（终止）** 状态。\n\n## 7. 什么是上下文切换?\n\n多线程编程中一般线程的个数都大于 CPU 核心的个数，而一个 CPU 核心在任意时刻只能被一个线程使用，为了让这些线程都能得到有效执行，CPU 采取的策略是为每个线程分配时间片并轮转的形式。当一个线程的时间片用完的时候就会重新处于就绪状态让给其他线程使用，这个过程就属于一次上下文切换。\n\n概括来说就是：当前任务在执行完 CPU 时间片切换到另一个任务之前会先保存自己的状态，以便下次再切换回这个任务时，可以再加载这个任务的状态。**任务从保存到再加载的过程就是一次上下文切换**。\n\n上下文切换通常是计算密集型的。也就是说，它需要相当可观的处理器时间，在每秒几十上百次的切换中，每次切换都需要纳秒量级的时间。所以，上下文切换对系统来说意味着消耗大量的 CPU 时间，事实上，可能是操作系统中时间消耗最大的操作。\n\nLinux 相比与其他操作系统（包括其他类 Unix 系统）有很多的优点，其中有一项就是，其上下文切换和模式切换的时间消耗非常少。\n\n## 8. 什么是线程死锁?如何避免死锁?\n\n### 8.1. 认识线程死锁\n\n线程死锁描述的是这样一种情况：多个线程同时被阻塞，它们中的一个或者全部都在等待某个资源被释放。由于线程被无限期地阻塞，因此程序不可能正常终止。\n\n如下图所示，线程 A 持有资源 2，线程 B 持有资源 1，他们同时都想申请对方的资源，所以这两个线程就会互相等待而进入死锁状态。\n\n![线程死锁示意图 ](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-4/2019-4%E6%AD%BB%E9%94%811.png)\n\n下面通过一个例子来说明线程死锁,代码模拟了上图的死锁的情况 (代码来源于《并发编程之美》)：\n\n```java\npublic class DeadLockDemo {\n    private static Object resource1 = new Object();//资源 1\n    private static Object resource2 = new Object();//资源 2\n\n    public static void main(String[] args) {\n        new Thread(() -> {\n            synchronized (resource1) {\n                System.out.println(Thread.currentThread() + \"get resource1\");\n                try {\n                    Thread.sleep(1000);\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n                System.out.println(Thread.currentThread() + \"waiting get resource2\");\n                synchronized (resource2) {\n                    System.out.println(Thread.currentThread() + \"get resource2\");\n                }\n            }\n        }, \"线程 1\").start();\n\n        new Thread(() -> {\n            synchronized (resource2) {\n                System.out.println(Thread.currentThread() + \"get resource2\");\n                try {\n                    Thread.sleep(1000);\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n                System.out.println(Thread.currentThread() + \"waiting get resource1\");\n                synchronized (resource1) {\n                    System.out.println(Thread.currentThread() + \"get resource1\");\n                }\n            }\n        }, \"线程 2\").start();\n    }\n}\n```\n\nOutput\n\n```\nThread[线程 1,5,main]get resource1\nThread[线程 2,5,main]get resource2\nThread[线程 1,5,main]waiting get resource2\nThread[线程 2,5,main]waiting get resource1\n```\n\n线程 A 通过 synchronized (resource1) 获得 resource1 的监视器锁，然后通过`Thread.sleep(1000);`让线程 A 休眠 1s 为的是让线程 B 得到执行然后获取到 resource2 的监视器锁。线程 A 和线程 B 休眠结束了都开始企图请求获取对方的资源，然后这两个线程就会陷入互相等待的状态，这也就产生了死锁。上面的例子符合产生死锁的四个必要条件。\n\n学过操作系统的朋友都知道产生死锁必须具备以下四个条件：\n\n1. 互斥条件：该资源任意一个时刻只由一个线程占用。\n2. 请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。\n3. 不剥夺条件:线程已获得的资源在末使用完之前不能被其他线程强行剥夺，只有自己使用完毕后才释放资源。\n4. 循环等待条件:若干进程之间形成一种头尾相接的循环等待资源关系。\n\n### 8.2. 如何避免线程死锁?\n\n我上面说了产生死锁的四个必要条件，为了避免死锁，我们只要破坏产生死锁的四个条件中的其中一个就可以了。现在我们来挨个分析一下：\n\n1. **破坏互斥条件** ：这个条件我们没有办法破坏，因为我们用锁本来就是想让他们互斥的（临界资源需要互斥访问）。\n2. **破坏请求与保持条件**  ：一次性申请所有的资源。\n3. **破坏不剥夺条件** ：占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源。\n4. **破坏循环等待条件** ：靠按序申请资源来预防。按某一顺序申请资源，释放资源则反序释放。破坏循环等待条件。\n\n我们对线程 2 的代码修改成下面这样就不会产生死锁了。\n\n```java\n        new Thread(() -> {\n            synchronized (resource1) {\n                System.out.println(Thread.currentThread() + \"get resource1\");\n                try {\n                    Thread.sleep(1000);\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n                System.out.println(Thread.currentThread() + \"waiting get resource2\");\n                synchronized (resource2) {\n                    System.out.println(Thread.currentThread() + \"get resource2\");\n                }\n            }\n        }, \"线程 2\").start();\n```\n\nOutput\n\n```\nThread[线程 1,5,main]get resource1\nThread[线程 1,5,main]waiting get resource2\nThread[线程 1,5,main]get resource2\nThread[线程 2,5,main]get resource1\nThread[线程 2,5,main]waiting get resource2\nThread[线程 2,5,main]get resource2\n\nProcess finished with exit code 0\n```\n\n我们分析一下上面的代码为什么避免了死锁的发生?\n\n线程 1 首先获得到 resource1 的监视器锁,这时候线程 2 就获取不到了。然后线程 1 再去获取 resource2 的监视器锁，可以获取到。然后线程 1 释放了对 resource1、resource2 的监视器锁的占用，线程 2 获取到就可以执行了。这样就破坏了破坏循环等待条件，因此避免了死锁。\n\n## 9. 说说 sleep() 方法和 wait() 方法区别和共同点?\n\n- 两者最主要的区别在于：**sleep 方法没有释放锁，而 wait 方法释放了锁** 。\n- 两者都可以暂停线程的执行。\n- Wait 通常被用于线程间交互/通信，sleep 通常被用于暂停执行。\n- wait() 方法被调用后，线程不会自动苏醒，需要别的线程调用同一个对象上的 notify() 或者 notifyAll() 方法。sleep() 方法执行完成后，线程会自动苏醒。或者可以使用 wait(long timeout)超时后线程会自动苏醒。\n\n## 10. 为什么我们调用 start() 方法时会执行 run() 方法，为什么我们不能直接调用 run() 方法？\n\n这是另一个非常经典的 java 多线程面试问题，而且在面试中会经常被问到。很简单，但是很多人都会答不上来！\n\nnew 一个 Thread，线程进入了新建状态;调用 start() 方法，会启动一个线程并使线程进入了就绪状态，当分配到时间片后就可以开始运行了。 start() 会执行线程的相应准备工作，然后自动执行 run() 方法的内容，这是真正的多线程工作。 而直接执行 run() 方法，会把 run 方法当成一个 main 线程下的普通方法去执行，并不会在某个线程中执行它，所以这并不是多线程工作。\n\n**总结： 调用 start 方法方可启动线程并使线程进入就绪状态，而 run 方法只是 thread 的一个普通方法调用，还是在主线程里执行。**\n\n\n\n\n\n<!-- TOC -->\n\n- [Java 并发进阶常见面试题总结](#java-并发进阶常见面试题总结)\n    - [1. synchronized 关键字](#1-synchronized-关键字)\n        - [1.1. 说一说自己对于 synchronized 关键字的了解](#11-说一说自己对于-synchronized-关键字的了解)\n        - [1.2. 说说自己是怎么使用 synchronized 关键字，在项目中用到了吗](#12-说说自己是怎么使用-synchronized-关键字在项目中用到了吗)\n        - [1.3. 讲一下 synchronized 关键字的底层原理](#13-讲一下-synchronized-关键字的底层原理)\n        - [1.4. 说说 JDK1.6 之后的synchronized 关键字底层做了哪些优化，可以详细介绍一下这些优化吗](#14-说说-jdk16-之后的synchronized-关键字底层做了哪些优化可以详细介绍一下这些优化吗)\n        - [1.5. 谈谈 synchronized和ReentrantLock 的区别](#15-谈谈-synchronized和reentrantlock-的区别)\n    - [2. volatile关键字](#2-volatile关键字)\n        - [2.1. 讲一下Java内存模型](#21-讲一下java内存模型)\n        - [2.2. 说说 synchronized 关键字和 volatile 关键字的区别](#22-说说-synchronized-关键字和-volatile-关键字的区别)\n    - [3. ThreadLocal](#3-threadlocal)\n        - [3.1. ThreadLocal简介](#31-threadlocal简介)\n        - [3.2. ThreadLocal示例](#32-threadlocal示例)\n        - [3.3. ThreadLocal原理](#33-threadlocal原理)\n        - [3.4. ThreadLocal 内存泄露问题](#34-threadlocal-内存泄露问题)\n    - [4. 线程池](#4-线程池)\n        - [4.1. 为什么要用线程池？](#41-为什么要用线程池)\n        - [4.2. 实现Runnable接口和Callable接口的区别](#42-实现runnable接口和callable接口的区别)\n        - [4.3. 执行execute()方法和submit()方法的区别是什么呢？](#43-执行execute方法和submit方法的区别是什么呢)\n        - [4.4. 如何创建线程池](#44-如何创建线程池)\n    - [5. Atomic 原子类](#5-atomic-原子类)\n        - [5.1. 介绍一下Atomic 原子类](#51-介绍一下atomic-原子类)\n        - [5.2. JUC 包中的原子类是哪4类?](#52-juc-包中的原子类是哪4类)\n        - [5.3. 讲讲 AtomicInteger 的使用](#53-讲讲-atomicinteger-的使用)\n        - [5.4. 能不能给我简单介绍一下 AtomicInteger 类的原理](#54-能不能给我简单介绍一下-atomicinteger-类的原理)\n    - [6. AQS](#6-aqs)\n        - [6.1. AQS 介绍](#61-aqs-介绍)\n        - [6.2. AQS 原理分析](#62-aqs-原理分析)\n            - [6.2.1. AQS 原理概览](#621-aqs-原理概览)\n            - [6.2.2. AQS 对资源的共享方式](#622-aqs-对资源的共享方式)\n            - [6.2.3. AQS底层使用了模板方法模式](#623-aqs底层使用了模板方法模式)\n        - [6.3. AQS 组件总结](#63-aqs-组件总结)\n    - [7 Reference](#7-reference)\n\n<!-- /TOC -->\n\n# Java 并发进阶常见面试题总结\n\n## 1. synchronized 关键字\n\n### 1.1. 说一说自己对于 synchronized 关键字的了解\n\nsynchronized关键字解决的是多个线程之间访问资源的同步性，synchronized关键字可以保证被它修饰的方法或者代码块在任意时刻只能有一个线程执行。\n\n另外，在 Java 早期版本中，synchronized属于重量级锁，效率低下，因为监视器锁（monitor）是依赖于底层的操作系统的 Mutex Lock 来实现的，Java 的线程是映射到操作系统的原生线程之上的。如果要挂起或者唤醒一个线程，都需要操作系统帮忙完成，而操作系统实现线程之间的切换时需要从用户态转换到内核态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高，这也是为什么早期的 synchronized 效率低的原因。庆幸的是在 Java 6 之后 Java 官方对从 JVM 层面对synchronized 较大优化，所以现在的 synchronized 锁效率也优化得很不错了。JDK1.6对锁的实现引入了大量的优化，如自旋锁、适应性自旋锁、锁消除、锁粗化、偏向锁、轻量级锁等技术来减少锁操作的开销。\n\n\n### 1.2. 说说自己是怎么使用 synchronized 关键字，在项目中用到了吗\n\n**synchronized关键字最主要的三种使用方式：**\n\n- **修饰实例方法:** 作用于当前对象实例加锁，进入同步代码前要获得当前对象实例的锁\n- **修饰静态方法:** 也就是给当前类加锁，会作用于类的所有对象实例，因为静态成员不属于任何一个实例对象，是类成员（ static 表明这是该类的一个静态资源，不管new了多少个对象，只有一份）。所以如果一个线程 A 调用一个实例对象的非静态 synchronized 方法，而线程 B 需要调用这个实例对象所属类的静态 synchronized 方法，是允许的，不会发生互斥现象，**因为访问静态 synchronized 方法占用的锁是当前类的锁，而访问非静态 synchronized 方法占用的锁是当前实例对象锁**。\n- **修饰代码块:** 指定加锁对象，对给定对象加锁，进入同步代码库前要获得给定对象的锁。\n\n**总结：** synchronized 关键字加到 static 静态方法和 synchronized(class)代码块上都是是给 Class 类上锁。synchronized 关键字加到实例方法上是给对象实例上锁。尽量不要使用 synchronized(String a) 因为JVM中，字符串常量池具有缓存功能！\n\n下面我以一个常见的面试题为例讲解一下 synchronized 关键字的具体使用。\n\n面试中面试官经常会说：“单例模式了解吗？来给我手写一下！给我解释一下双重检验锁方式实现单例模式的原理呗！”\n\n**双重校验锁实现对象单例（线程安全）**\n\n```java\npublic class Singleton {\n\n    private volatile static Singleton uniqueInstance;\n\n    private Singleton() {\n    }\n\n    public static Singleton getUniqueInstance() {\n       //先判断对象是否已经实例过，没有实例化过才进入加锁代码\n        if (uniqueInstance == null) {\n            //类对象加锁\n            synchronized (Singleton.class) {\n                if (uniqueInstance == null) {\n                    uniqueInstance = new Singleton();\n                }\n            }\n        }\n        return uniqueInstance;\n    }\n}\n```\n另外，需要注意 uniqueInstance 采用 volatile 关键字修饰也是很有必要。\n\nuniqueInstance 采用 volatile 关键字修饰也是很有必要的， uniqueInstance = new Singleton(); 这段代码其实是分为三步执行：\n\n1. 为 uniqueInstance 分配内存空间\n2. 初始化 uniqueInstance\n3. 将 uniqueInstance 指向分配的内存地址\n\n但是由于 JVM 具有指令重排的特性，执行顺序有可能变成 1->3->2。指令重排在单线程环境下不会出现问题，但是在多线程环境下会导致一个线程获得还没有初始化的实例。例如，线程 T1 执行了 1 和 3，此时 T2 调用 getUniqueInstance() 后发现 uniqueInstance 不为空，因此返回 uniqueInstance，但此时 uniqueInstance 还未被初始化。\n\n使用 volatile 可以禁止 JVM 的指令重排，保证在多线程环境下也能正常运行。\n\n### 1.3. 讲一下 synchronized 关键字的底层原理\n\n**synchronized 关键字底层原理属于 JVM 层面。**\n\n**① synchronized 同步语句块的情况**\n\n```java\npublic class SynchronizedDemo {\n\tpublic void method() {\n\t\tsynchronized (this) {\n\t\t\tSystem.out.println(\"synchronized 代码块\");\n\t\t}\n\t}\n}\n\n```\n\n通过 JDK 自带的 javap 命令查看 SynchronizedDemo 类的相关字节码信息：首先切换到类的对应目录执行 `javac SynchronizedDemo.java` 命令生成编译后的 .class 文件，然后执行`javap -c -s -v -l SynchronizedDemo.class`。\n\n![synchronized关键字原理](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/synchronized关键字原理.png)\n\n从上面我们可以看出：\n\n**synchronized 同步语句块的实现使用的是 monitorenter 和 monitorexit 指令，其中 monitorenter 指令指向同步代码块的开始位置，monitorexit 指令则指明同步代码块的结束位置。** 当执行 monitorenter 指令时，线程试图获取锁也就是获取 monitor(monitor对象存在于每个Java对象的对象头中，synchronized 锁便是通过这种方式获取锁的，也是为什么Java中任意对象可以作为锁的原因) 的持有权。当计数器为0则可以成功获取，获取后将锁计数器设为1也就是加1。相应的在执行 monitorexit 指令后，将锁计数器设为0，表明锁被释放。如果获取对象锁失败，那当前线程就要阻塞等待，直到锁被另外一个线程释放为止。\n\n**② synchronized 修饰方法的的情况**\n\n```java\npublic class SynchronizedDemo2 {\n\tpublic synchronized void method() {\n\t\tSystem.out.println(\"synchronized 方法\");\n\t}\n}\n\n```\n\n![synchronized关键字原理](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/synchronized关键字原理2.png)\n\nsynchronized 修饰的方法并没有 monitorenter 指令和 monitorexit 指令，取得代之的确实是 ACC_SYNCHRONIZED 标识，该标识指明了该方法是一个同步方法，JVM 通过该 ACC_SYNCHRONIZED 访问标志来辨别一个方法是否声明为同步方法，从而执行相应的同步调用。\n\n\n### 1.4. 说说 JDK1.6 之后的synchronized 关键字底层做了哪些优化，可以详细介绍一下这些优化吗\n\nJDK1.6 对锁的实现引入了大量的优化，如偏向锁、轻量级锁、自旋锁、适应性自旋锁、锁消除、锁粗化等技术来减少锁操作的开销。\n\n锁主要存在四种状态，依次是：无锁状态、偏向锁状态、轻量级锁状态、重量级锁状态，他们会随着竞争的激烈而逐渐升级。注意锁可以升级不可降级，这种策略是为了提高获得锁和释放锁的效率。\n\n关于这几种优化的详细信息可以查看笔主的这篇文章：<https://gitee.com/SnailClimb/JavaGuide/blob/master/docs/java/Multithread/synchronized.md>\n\n### 1.5. 谈谈 synchronized和ReentrantLock 的区别\n\n\n**① 两者都是可重入锁**\n\n两者都是可重入锁。“可重入锁”概念是：自己可以再次获取自己的内部锁。比如一个线程获得了某个对象的锁，此时这个对象锁还没有释放，当其再次想要获取这个对象的锁的时候还是可以获取的，如果不可锁重入的话，就会造成死锁。同一个线程每次获取锁，锁的计数器都自增1，所以要等到锁的计数器下降为0时才能释放锁。\n\n**② synchronized 依赖于 JVM 而 ReentrantLock 依赖于 API**\n\nsynchronized 是依赖于 JVM 实现的，前面我们也讲到了 虚拟机团队在 JDK1.6 为 synchronized 关键字进行了很多优化，但是这些优化都是在虚拟机层面实现的，并没有直接暴露给我们。ReentrantLock 是 JDK 层面实现的（也就是 API 层面，需要 lock() 和 unlock() 方法配合 try/finally 语句块来完成），所以我们可以通过查看它的源代码，来看它是如何实现的。\n\n**③ ReentrantLock 比 synchronized 增加了一些高级功能**\n\n相比synchronized，ReentrantLock增加了一些高级功能。主要来说主要有三点：**①等待可中断；②可实现公平锁；③可实现选择性通知（锁可以绑定多个条件）**\n\n- **ReentrantLock提供了一种能够中断等待锁的线程的机制**，通过lock.lockInterruptibly()来实现这个机制。也就是说正在等待的线程可以选择放弃等待，改为处理其他事情。\n- **ReentrantLock可以指定是公平锁还是非公平锁。而synchronized只能是非公平锁。所谓的公平锁就是先等待的线程先获得锁。** ReentrantLock默认情况是非公平的，可以通过 ReentrantLock类的`ReentrantLock(boolean fair)`构造方法来制定是否是公平的。\n- synchronized关键字与wait()和notify()/notifyAll()方法相结合可以实现等待/通知机制，ReentrantLock类当然也可以实现，但是需要借助于Condition接口与newCondition() 方法。Condition是JDK1.5之后才有的，它具有很好的灵活性，比如可以实现多路通知功能也就是在一个Lock对象中可以创建多个Condition实例（即对象监视器），**线程对象可以注册在指定的Condition中，从而可以有选择性的进行线程通知，在调度线程上更加灵活。 在使用notify()/notifyAll()方法进行通知时，被通知的线程是由 JVM 选择的，用ReentrantLock类结合Condition实例可以实现“选择性通知”** ，这个功能非常重要，而且是Condition接口默认提供的。而synchronized关键字就相当于整个Lock对象中只有一个Condition实例，所有的线程都注册在它一个身上。如果执行notifyAll()方法的话就会通知所有处于等待状态的线程这样会造成很大的效率问题，而Condition实例的signalAll()方法 只会唤醒注册在该Condition实例中的所有等待线程。\n\n如果你想使用上述功能，那么选择ReentrantLock是一个不错的选择。\n\n**④ 性能已不是选择标准**\n\n## 2. volatile关键字\n\n### 2.1. 讲一下Java内存模型\n\n\n在 JDK1.2 之前，Java的内存模型实现总是从**主存**（即共享内存）读取变量，是不需要进行特别的注意的。而在当前的 Java 内存模型下，线程可以把变量保存**本地内存**（比如机器的寄存器）中，而不是直接在主存中进行读写。这就可能造成一个线程在主存中修改了一个变量的值，而另外一个线程还继续使用它在寄存器中的变量值的拷贝，造成**数据的不一致**。\n\n![数据不一致](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/数据不一致.png)\n\n要解决这个问题，就需要把变量声明为**volatile**，这就指示 JVM，这个变量是不稳定的，每次使用它都到主存中进行读取。\n\n说白了， **volatile** 关键字的主要作用就是保证变量的可见性然后还有一个作用是防止指令重排序。\n\n![volatile关键字的可见性](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/volatile关键字的可见性.png)\n\n### 2.2 并发编程的三个重要特性\n\n1. **原子性** : 一个的操作或者多次操作，要么所有的操作全部都得到执行并且不会收到任何因素的干扰而中断，要么所有的操作都执行，要么都不执行。`synchronized ` 可以保证代码片段的原子性。\n2. **可见性**  ：当一个变量对共享变量进行了修改，那么另外的线程都是立即可以看到修改后的最新值。`volatile` 关键字可以保证共享变量的可见性。\n3. **有序性** ：代码在执行的过程中的先后顺序，Java 在编译器以及运行期间的优化，代码的执行顺序未必就是编写代码时候的顺序。`volatile` 关键字可以禁止指令进行重排序优化。\n\n### 2.3. 说说 synchronized 关键字和 volatile 关键字的区别\n\n`synchronized` 关键字和 `volatile` 关键字是两个互补的存在，而不是对立的存在：\n\n- **volatile关键字**是线程同步的**轻量级实现**，所以**volatile性能肯定比synchronized关键字要好**。但是**volatile关键字只能用于变量而synchronized关键字可以修饰方法以及代码块**。synchronized关键字在JavaSE1.6之后进行了主要包括为了减少获得锁和释放锁带来的性能消耗而引入的偏向锁和轻量级锁以及其它各种优化之后执行效率有了显著提升，**实际开发中使用 synchronized 关键字的场景还是更多一些**。\n- **多线程访问volatile关键字不会发生阻塞，而synchronized关键字可能会发生阻塞**\n- **volatile关键字能保证数据的可见性，但不能保证数据的原子性。synchronized关键字两者都能保证。**\n- **volatile关键字主要用于解决变量在多个线程之间的可见性，而 synchronized关键字解决的是多个线程之间访问资源的同步性。**\n\n## 3. ThreadLocal\n\n### 3.1. ThreadLocal简介\n\n通常情况下，我们创建的变量是可以被任何一个线程访问并修改的。**如果想实现每一个线程都有自己的专属本地变量该如何解决呢？** JDK中提供的`ThreadLocal`类正是为了解决这样的问题。 **`ThreadLocal`类主要解决的就是让每个线程绑定自己的值，可以将`ThreadLocal`类形象的比喻成存放数据的盒子，盒子中可以存储每个线程的私有数据。**\n\n**如果你创建了一个`ThreadLocal`变量，那么访问这个变量的每个线程都会有这个变量的本地副本，这也是`ThreadLocal`变量名的由来。他们可以使用 `get（）` 和 `set（）` 方法来获取默认值或将其值更改为当前线程所存的副本的值，从而避免了线程安全问题。**\n\n再举个简单的例子： \n\n比如有两个人去宝屋收集宝物，这两个共用一个袋子的话肯定会产生争执，但是给他们两个人每个人分配一个袋子的话就不会出现这样的问题。如果把这两个人比作线程的话，那么ThreadLocal就是用来避免这两个线程竞争的。\n\n### 3.2. ThreadLocal示例\n\n相信看了上面的解释，大家已经搞懂 ThreadLocal 类是个什么东西了。\n\n```java\nimport java.text.SimpleDateFormat;\nimport java.util.Random;\n\npublic class ThreadLocalExample implements Runnable{\n\n     // SimpleDateFormat 不是线程安全的，所以每个线程都要有自己独立的副本\n    private static final ThreadLocal<SimpleDateFormat> formatter = ThreadLocal.withInitial(() -> new SimpleDateFormat(\"yyyyMMdd HHmm\"));\n\n    public static void main(String[] args) throws InterruptedException {\n        ThreadLocalExample obj = new ThreadLocalExample();\n        for(int i=0 ; i<10; i++){\n            Thread t = new Thread(obj, \"\"+i);\n            Thread.sleep(new Random().nextInt(1000));\n            t.start();\n        }\n    }\n\n    @Override\n    public void run() {\n        System.out.println(\"Thread Name= \"+Thread.currentThread().getName()+\" default Formatter = \"+formatter.get().toPattern());\n        try {\n            Thread.sleep(new Random().nextInt(1000));\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n        //formatter pattern is changed here by thread, but it won't reflect to other threads\n        formatter.set(new SimpleDateFormat());\n\n        System.out.println(\"Thread Name= \"+Thread.currentThread().getName()+\" formatter = \"+formatter.get().toPattern());\n    }\n\n}\n\n```\n\nOutput:\n\n```\nThread Name= 0 default Formatter = yyyyMMdd HHmm\nThread Name= 0 formatter = yy-M-d ah:mm\nThread Name= 1 default Formatter = yyyyMMdd HHmm\nThread Name= 2 default Formatter = yyyyMMdd HHmm\nThread Name= 1 formatter = yy-M-d ah:mm\nThread Name= 3 default Formatter = yyyyMMdd HHmm\nThread Name= 2 formatter = yy-M-d ah:mm\nThread Name= 4 default Formatter = yyyyMMdd HHmm\nThread Name= 3 formatter = yy-M-d ah:mm\nThread Name= 4 formatter = yy-M-d ah:mm\nThread Name= 5 default Formatter = yyyyMMdd HHmm\nThread Name= 5 formatter = yy-M-d ah:mm\nThread Name= 6 default Formatter = yyyyMMdd HHmm\nThread Name= 6 formatter = yy-M-d ah:mm\nThread Name= 7 default Formatter = yyyyMMdd HHmm\nThread Name= 7 formatter = yy-M-d ah:mm\nThread Name= 8 default Formatter = yyyyMMdd HHmm\nThread Name= 9 default Formatter = yyyyMMdd HHmm\nThread Name= 8 formatter = yy-M-d ah:mm\nThread Name= 9 formatter = yy-M-d ah:mm\n```\n\n从输出中可以看出，Thread-0已经改变了formatter的值，但仍然是thread-2默认格式化程序与初始化值相同，其他线程也一样。\n\n上面有一段代码用到了创建 `ThreadLocal` 变量的那段代码用到了 Java8 的知识，它等于下面这段代码，如果你写了下面这段代码的话，IDEA会提示你转换为Java8的格式(IDEA真的不错！)。因为ThreadLocal类在Java 8中扩展，使用一个新的方法`withInitial()`，将Supplier功能接口作为参数。\n\n```java\n private static final ThreadLocal<SimpleDateFormat> formatter = new ThreadLocal<SimpleDateFormat>(){\n        @Override\n        protected SimpleDateFormat initialValue()\n        {\n            return new SimpleDateFormat(\"yyyyMMdd HHmm\");\n        }\n    };\n```\n\n### 3.3. ThreadLocal原理\n\n从 `Thread`类源代码入手。\n\n```java\npublic class Thread implements Runnable {\n ......\n//与此线程有关的ThreadLocal值。由ThreadLocal类维护\nThreadLocal.ThreadLocalMap threadLocals = null;\n\n//与此线程有关的InheritableThreadLocal值。由InheritableThreadLocal类维护\nThreadLocal.ThreadLocalMap inheritableThreadLocals = null;\n ......\n}\n```\n\n从上面`Thread`类 源代码可以看出`Thread` 类中有一个 `threadLocals` 和 一个  `inheritableThreadLocals` 变量，它们都是 `ThreadLocalMap`  类型的变量,我们可以把 `ThreadLocalMap`  理解为`ThreadLocal` 类实现的定制化的 `HashMap`。默认情况下这两个变量都是null，只有当前线程调用 `ThreadLocal` 类的 `set`或`get`方法时才创建它们，实际上调用这两个方法的时候，我们调用的是`ThreadLocalMap`类对应的 `get()`、`set() `方法。\n\n`ThreadLocal`类的`set()`方法\n\n```java\n    public void set(T value) {\n        Thread t = Thread.currentThread();\n        ThreadLocalMap map = getMap(t);\n        if (map != null)\n            map.set(this, value);\n        else\n            createMap(t, value);\n    }\n    ThreadLocalMap getMap(Thread t) {\n        return t.threadLocals;\n    }\n```\n\n通过上面这些内容，我们足以通过猜测得出结论：**最终的变量是放在了当前线程的 `ThreadLocalMap` 中，并不是存在 `ThreadLocal` 上，`ThreadLocal` 可以理解为只是`ThreadLocalMap`的封装，传递了变量值。** `ThrealLocal` 类中可以通过`Thread.currentThread()`获取到当前线程对象后，直接通过`getMap(Thread t)`可以访问到该线程的`ThreadLocalMap`对象。\n\n**每个`Thread`中都具备一个`ThreadLocalMap`，而`ThreadLocalMap`可以存储以`ThreadLocal`为key ，Object 对象为 value的键值对。** \n\n```java\nThreadLocalMap(ThreadLocal<?> firstKey, Object firstValue) {\n ......\n}\n```\n\n比如我们在同一个线程中声明了两个 `ThreadLocal` 对象的话，会使用 `Thread`内部都是使用仅有那个`ThreadLocalMap` 存放数据的，`ThreadLocalMap`的 key 就是 `ThreadLocal`对象，value 就是 `ThreadLocal` 对象调用`set`方法设置的值。\n\n![ThreadLocal数据结构](https://upload-images.jianshu.io/upload_images/7432604-ad2ff581127ba8cc.jpg?imageMogr2/auto-orient/strip|imageView2/2/w/806)\n\n`ThreadLocalMap`是`ThreadLocal`的静态内部类。\n\n![ThreadLocal内部类](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/ThreadLocal内部类.png)\n\n### 3.4. ThreadLocal 内存泄露问题\n\n`ThreadLocalMap` 中使用的 key 为 `ThreadLocal` 的弱引用,而 value 是强引用。所以，如果 `ThreadLocal` 没有被外部强引用的情况下，在垃圾回收的时候，key 会被清理掉，而 value 不会被清理掉。这样一来，`ThreadLocalMap` 中就会出现key为null的Entry。假如我们不做任何措施的话，value 永远无法被GC 回收，这个时候就可能会产生内存泄露。ThreadLocalMap实现中已经考虑了这种情况，在调用 `set()`、`get()`、`remove()` 方法的时候，会清理掉 key 为 null 的记录。使用完 `ThreadLocal`方法后 最好手动调用`remove()`方法\n\n```java\n      static class Entry extends WeakReference<ThreadLocal<?>> {\n            /** The value associated with this ThreadLocal. */\n            Object value;\n\n            Entry(ThreadLocal<?> k, Object v) {\n                super(k);\n                value = v;\n            }\n        }\n```\n\n**弱引用介绍：**\n\n> 如果一个对象只具有弱引用，那就类似于**可有可无的生活用品**。弱引用与软引用的区别在于：只具有弱引用的对象拥有更短暂的生命周期。在垃圾回收器线程扫描它 所管辖的内存区域的过程中，一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。不过，由于垃圾回收器是一个优先级很低的线程， 因此不一定会很快发现那些只具有弱引用的对象。\n>\n> 弱引用可以和一个引用队列（ReferenceQueue）联合使用，如果弱引用所引用的对象被垃圾回收，Java虚拟机就会把这个弱引用加入到与之关联的引用队列中。\n\n## 4. 线程池\n\n### 4.1. 为什么要用线程池？\n\n> **池化技术相比大家已经屡见不鲜了，线程池、数据库连接池、Http 连接池等等都是对这个思想的应用。池化技术的思想主要是为了减少每次获取资源的消耗，提高对资源的利用率。**\n\n**线程池**提供了一种限制和管理资源（包括执行一个任务）。 每个**线程池**还维护一些基本统计信息，例如已完成任务的数量。\n\n这里借用《Java 并发编程的艺术》提到的来说一下**使用线程池的好处**：\n\n- **降低资源消耗**。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。\n- **提高响应速度**。当任务到达时，任务可以不需要的等到线程创建就能立即执行。\n- **提高线程的可管理性**。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。\n\n### 4.2. 实现Runnable接口和Callable接口的区别\n\n`Runnable`自Java 1.0以来一直存在，但`Callable`仅在Java 1.5中引入,目的就是为了来处理`Runnable`不支持的用例。**`Runnable` 接口**不会返回结果或抛出检查异常，但是**`Callable` 接口**可以。所以，如果任务不需要返回结果或抛出异常推荐使用 **`Runnable` 接口**，这样代码看起来会更加简洁。\n\n工具类 `Executors` 可以实现 `Runnable` 对象和 `Callable` 对象之间的相互转换。（`Executors.callable（Runnable task`）或 `Executors.callable（Runnable task，Object resule）`）。\n\n`Runnable.java`\n\n```java\n@FunctionalInterface\npublic interface Runnable {\n   /**\n    * 被线程执行，没有返回值也无法抛出异常\n    */\n    public abstract void run();\n}\n```\n\n`Callable.java`\n\n```java\n@FunctionalInterface\npublic interface Callable<V> {\n    /**\n     * 计算结果，或在无法这样做时抛出异常。\n     * @return 计算得出的结果\n     * @throws 如果无法计算结果，则抛出异常\n     */\n    V call() throws Exception;\n}\n```\n\n### 4.3. 执行execute()方法和submit()方法的区别是什么呢？\n\n1. **`execute()`方法用于提交不需要返回值的任务，所以无法判断任务是否被线程池执行成功与否；**\n2. **`submit()`方法用于提交需要返回值的任务。线程池会返回一个 `Future` 类型的对象，通过这个 `Future` 对象可以判断任务是否执行成功**，并且可以通过 `Future` 的 `get()`方法来获取返回值，`get()`方法会阻塞当前线程直到任务完成，而使用 `get（long timeout，TimeUnit unit）`方法则会阻塞当前线程一段时间后立即返回，这时候有可能任务没有执行完。\n\n我们以**`AbstractExecutorService`**接口中的一个 `submit` 方法为例子来看看源代码：\n\n```java\n    public Future<?> submit(Runnable task) {\n        if (task == null) throw new NullPointerException();\n        RunnableFuture<Void> ftask = newTaskFor(task, null);\n        execute(ftask);\n        return ftask;\n    }\n```\n\n上面方法调用的 `newTaskFor` 方法返回了一个 `FutureTask` 对象。\n\n```java\n    protected <T> RunnableFuture<T> newTaskFor(Runnable runnable, T value) {\n        return new FutureTask<T>(runnable, value);\n    }\n```\n\n我们再来看看`execute()`方法：\n\n```java\n    public void execute(Runnable command) {\n      ...\n    }\n```\n\n### 4.4. 如何创建线程池\n\n《阿里巴巴Java开发手册》中强制线程池不允许使用 Executors 去创建，而是通过 ThreadPoolExecutor 的方式，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险\n\n> Executors 返回线程池对象的弊端如下：\n>\n> - **FixedThreadPool 和 SingleThreadExecutor** ： 允许请求的队列长度为 Integer.MAX_VALUE ，可能堆积大量的请求，从而导致OOM。\n> - **CachedThreadPool 和 ScheduledThreadPool** ： 允许创建的线程数量为 Integer.MAX_VALUE ，可能会创建大量线程，从而导致OOM。\n\n**方式一：通过构造方法实现**\n![ThreadPoolExecutor构造方法](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/ThreadPoolExecutor构造方法.png)\n**方式二：通过Executor 框架的工具类Executors来实现**\n我们可以创建三种类型的ThreadPoolExecutor：\n\n- **FixedThreadPool** ： 该方法返回一个固定线程数量的线程池。该线程池中的线程数量始终不变。当有一个新的任务提交时，线程池中若有空闲线程，则立即执行。若没有，则新的任务会被暂存在一个任务队列中，待有线程空闲时，便处理在任务队列中的任务。\n- **SingleThreadExecutor：** 方法返回一个只有一个线程的线程池。若多余一个任务被提交到该线程池，任务会被保存在一个任务队列中，待线程空闲，按先入先出的顺序执行队列中的任务。\n- **CachedThreadPool：** 该方法返回一个可根据实际情况调整线程数量的线程池。线程池的线程数量不确定，但若有空闲线程可以复用，则会优先使用可复用的线程。若所有线程均在工作，又有新的任务提交，则会创建新的线程处理任务。所有线程在当前任务执行完毕后，将返回线程池进行复用。\n\n对应Executors工具类中的方法如图所示：\n![Executor框架的工具类](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/Executor框架的工具类.png)\n\n### 4.5 ThreadPoolExecutor 类分析\n\n`ThreadPoolExecutor` 类中提供的四个构造方法。我们来看最长的那个，其余三个都是在这个构造方法的基础上产生（其他几个构造方法说白点都是给定某些默认参数的构造方法比如默认制定拒绝策略是什么），这里就不贴代码讲了，比较简单。\n\n```java\n    /**\n     * 用给定的初始参数创建一个新的ThreadPoolExecutor。\n     */\n    public ThreadPoolExecutor(int corePoolSize,\n                              int maximumPoolSize,\n                              long keepAliveTime,\n                              TimeUnit unit,\n                              BlockingQueue<Runnable> workQueue,\n                              ThreadFactory threadFactory,\n                              RejectedExecutionHandler handler) {\n        if (corePoolSize < 0 ||\n            maximumPoolSize <= 0 ||\n            maximumPoolSize < corePoolSize ||\n            keepAliveTime < 0)\n            throw new IllegalArgumentException();\n        if (workQueue == null || threadFactory == null || handler == null)\n            throw new NullPointerException();\n        this.corePoolSize = corePoolSize;\n        this.maximumPoolSize = maximumPoolSize;\n        this.workQueue = workQueue;\n        this.keepAliveTime = unit.toNanos(keepAliveTime);\n        this.threadFactory = threadFactory;\n        this.handler = handler;\n    }\n```\n\n**下面这些对创建 非常重要，在后面使用线程池的过程中你一定会用到！所以，务必拿着小本本记清楚。**\n\n#### 4.5.1 `ThreadPoolExecutor`构造函数重要参数分析\n\n**`ThreadPoolExecutor` 3 个最重要的参数：**\n\n- **`corePoolSize` :** 核心线程数线程数定义了最小可以同时运行的线程数量。\n- **`maximumPoolSize` :** 当队列中存放的任务达到队列容量的时候，当前可以同时运行的线程数量变为最大线程数。\n- **`workQueue`:** 当新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到的话，新任务就会被存放在队列中。\n\n`ThreadPoolExecutor`其他常见参数:\n\n1. **`keepAliveTime`**:当线程池中的线程数量大于 `corePoolSize` 的时候，如果这时没有新的任务提交，核心线程外的线程不会立即销毁，而是会等待，直到等待的时间超过了 `keepAliveTime`才会被回收销毁；\n2. **`unit`** : `keepAliveTime` 参数的时间单位。\n3. **`threadFactory`** :executor 创建新线程的时候会用到。\n4. **`handler`** :饱和策略。关于饱和策略下面单独介绍一下。\n\n#### 4.5.2 `ThreadPoolExecutor` 饱和策略\n\n**`ThreadPoolExecutor` 饱和策略定义:**\n\n如果当前同时运行的线程数量达到最大线程数量并且队列也已经被放满了任时，`ThreadPoolTaskExecutor` 定义一些策略:\n\n- **`ThreadPoolExecutor.AbortPolicy`**：抛出 `RejectedExecutionException`来拒绝新任务的处理。\n- **`ThreadPoolExecutor.CallerRunsPolicy`**：调用执行自己的线程运行任务。您不会任务请求。但是这种策略会降低对于新任务提交速度，影响程序的整体性能。另外，这个策略喜欢增加队列容量。如果您的应用程序可以承受此延迟并且你不能任务丢弃任何一个任务请求的话，你可以选择这个策略。\n- **`ThreadPoolExecutor.DiscardPolicy`：** 不处理新任务，直接丢弃掉。\n- **`ThreadPoolExecutor.DiscardOldestPolicy`：** 此策略将丢弃最早的未处理的任务请求。\n\n举个例子： Spring 通过 `ThreadPoolTaskExecutor` 或者我们直接通过 `ThreadPoolExecutor` 的构造函数创建线程池的时候，当我们不指定 `RejectedExecutionHandler` 饱和策略的话来配置线程池的时候默认使用的是 `ThreadPoolExecutor.AbortPolicy`。在默认情况下，`ThreadPoolExecutor` 将抛出 `RejectedExecutionException` 来拒绝新来的任务 ，这代表你将丢失对这个任务的处理。 对于可伸缩的应用程序，建议使用 `ThreadPoolExecutor.CallerRunsPolicy`。当最大池被填满时，此策略为我们提供可伸缩队列。（这个直接查看 `ThreadPoolExecutor` 的构造函数源码就可以看出，比较简单的原因，这里就不贴代码了）\n\n### 4.6 一个简单的线程池Demo:`Runnable`+`ThreadPoolExecutor`\n\n为了让大家更清楚上面的面试题中的一些概念，我写了一个简单的线程池 Demo。\n\n首先创建一个 `Runnable` 接口的实现类（当然也可以是 `Callable` 接口，我们上面也说了两者的区别。）\n\n`MyRunnable.java`\n\n```java\nimport java.util.Date;\n\n/**\n * 这是一个简单的Runnable类，需要大约5秒钟来执行其任务。\n * @author shuang.kou\n */\npublic class MyRunnable implements Runnable {\n\n    private String command;\n\n    public MyRunnable(String s) {\n        this.command = s;\n    }\n\n    @Override\n    public void run() {\n        System.out.println(Thread.currentThread().getName() + \" Start. Time = \" + new Date());\n        processCommand();\n        System.out.println(Thread.currentThread().getName() + \" End. Time = \" + new Date());\n    }\n\n    private void processCommand() {\n        try {\n            Thread.sleep(5000);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n    }\n\n    @Override\n    public String toString() {\n        return this.command;\n    }\n}\n\n```\n\n编写测试程序，我们这里以阿里巴巴推荐的使用 `ThreadPoolExecutor` 构造函数自定义参数的方式来创建线程池。\n\n`ThreadPoolExecutorDemo.java`\n\n```java\nimport java.util.concurrent.ArrayBlockingQueue;\nimport java.util.concurrent.ThreadPoolExecutor;\nimport java.util.concurrent.TimeUnit;\n\npublic class ThreadPoolExecutorDemo {\n\n    private static final int CORE_POOL_SIZE = 5;\n    private static final int MAX_POOL_SIZE = 10;\n    private static final int QUEUE_CAPACITY = 100;\n    private static final Long KEEP_ALIVE_TIME = 1L;\n    public static void main(String[] args) {\n\n        //使用阿里巴巴推荐的创建线程池的方式\n        //通过ThreadPoolExecutor构造函数自定义参数创建\n        ThreadPoolExecutor executor = new ThreadPoolExecutor(\n                CORE_POOL_SIZE,\n                MAX_POOL_SIZE,\n                KEEP_ALIVE_TIME,\n                TimeUnit.SECONDS,\n                new ArrayBlockingQueue<>(QUEUE_CAPACITY),\n                new ThreadPoolExecutor.CallerRunsPolicy());\n\n        for (int i = 0; i < 10; i++) {\n            //创建WorkerThread对象（WorkerThread类实现了Runnable 接口）\n            Runnable worker = new MyRunnable(\"\" + i);\n            //执行Runnable\n            executor.execute(worker);\n        }\n        //终止线程池\n        executor.shutdown();\n        while (!executor.isTerminated()) {\n        }\n        System.out.println(\"Finished all threads\");\n    }\n}\n\n```\n\n可以看到我们上面的代码指定了：\n\n1. `corePoolSize`: 核心线程数为 5。\n2. `maximumPoolSize` ：最大线程数 10\n3. `keepAliveTime` : 等待时间为 1L。\n4. `unit`: 等待时间的单位为 TimeUnit.SECONDS。\n5. `workQueue`：任务队列为 `ArrayBlockingQueue`，并且容量为 100;\n6. `handler`:饱和策略为 `CallerRunsPolicy`。\n\n**Output：**\n\n```\npool-1-thread-2 Start. Time = Tue Nov 12 20:59:44 CST 2019\npool-1-thread-5 Start. Time = Tue Nov 12 20:59:44 CST 2019\npool-1-thread-4 Start. Time = Tue Nov 12 20:59:44 CST 2019\npool-1-thread-1 Start. Time = Tue Nov 12 20:59:44 CST 2019\npool-1-thread-3 Start. Time = Tue Nov 12 20:59:44 CST 2019\npool-1-thread-5 End. Time = Tue Nov 12 20:59:49 CST 2019\npool-1-thread-3 End. Time = Tue Nov 12 20:59:49 CST 2019\npool-1-thread-2 End. Time = Tue Nov 12 20:59:49 CST 2019\npool-1-thread-4 End. Time = Tue Nov 12 20:59:49 CST 2019\npool-1-thread-1 End. Time = Tue Nov 12 20:59:49 CST 2019\npool-1-thread-2 Start. Time = Tue Nov 12 20:59:49 CST 2019\npool-1-thread-1 Start. Time = Tue Nov 12 20:59:49 CST 2019\npool-1-thread-4 Start. Time = Tue Nov 12 20:59:49 CST 2019\npool-1-thread-3 Start. Time = Tue Nov 12 20:59:49 CST 2019\npool-1-thread-5 Start. Time = Tue Nov 12 20:59:49 CST 2019\npool-1-thread-2 End. Time = Tue Nov 12 20:59:54 CST 2019\npool-1-thread-3 End. Time = Tue Nov 12 20:59:54 CST 2019\npool-1-thread-4 End. Time = Tue Nov 12 20:59:54 CST 2019\npool-1-thread-5 End. Time = Tue Nov 12 20:59:54 CST 2019\npool-1-thread-1 End. Time = Tue Nov 12 20:59:54 CST 2019\n\n```\n\n### 4.7 线程池原理分析\n\n承接 4.6 节，我们通过代码输出结果可以看出：**线程池每次会同时执行 5 个任务，这 5 个任务执行完之后，剩余的 5 个任务才会被执行。** 大家可以先通过上面讲解的内容，分析一下到底是咋回事？（自己独立思考一会）\n\n现在，我们就分析上面的输出内容来简单分析一下线程池原理。\n\n**为了搞懂线程池的原理，我们需要首先分析一下 `execute`方法。**在 4.6 节中的 Demo 中我们使用 `executor.execute(worker)`来提交一个任务到线程池中去，这个方法非常重要，下面我们来看看它的源码：\n\n```java\n   // 存放线程池的运行状态 (runState) 和线程池内有效线程的数量 (workerCount)\n   private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));\n\n    private static int workerCountOf(int c) {\n        return c & CAPACITY;\n    }\n\n    private final BlockingQueue<Runnable> workQueue;\n\n    public void execute(Runnable command) {\n        // 如果任务为null，则抛出异常。\n        if (command == null)\n            throw new NullPointerException();\n        // ctl 中保存的线程池当前的一些状态信息\n        int c = ctl.get();\n\n        //  下面会涉及到 3 步 操作\n        // 1.首先判断当前线程池中之行的任务数量是否小于 corePoolSize\n        // 如果小于的话，通过addWorker(command, true)新建一个线程，并将任务(command)添加到该线程中；然后，启动该线程从而执行任务。\n        if (workerCountOf(c) < corePoolSize) {\n            if (addWorker(command, true))\n                return;\n            c = ctl.get();\n        }\n        // 2.如果当前之行的任务数量大于等于 corePoolSize 的时候就会走到这里\n        // 通过 isRunning 方法判断线程池状态，线程池处于 RUNNING 状态才会被并且队列可以加入任务，该任务才会被加入进去\n        if (isRunning(c) && workQueue.offer(command)) {\n            int recheck = ctl.get();\n            // 再次获取线程池状态，如果线程池状态不是 RUNNING 状态就需要从任务队列中移除任务，并尝试判断线程是否全部执行完毕。同时执行拒绝策略。\n            if (!isRunning(recheck) && remove(command))\n                reject(command);\n                // 如果当前线程池为空就新创建一个线程并执行。\n            else if (workerCountOf(recheck) == 0)\n                addWorker(null, false);\n        }\n        //3. 通过addWorker(command, false)新建一个线程，并将任务(command)添加到该线程中；然后，启动该线程从而执行任务。\n        //如果addWorker(command, false)执行失败，则通过reject()执行相应的拒绝策略的内容。\n        else if (!addWorker(command, false))\n            reject(command);\n    }\n```\n\n通过下图可以更好的对上面这 3 步做一个展示，下图是我为了省事直接从网上找到，原地址不明。\n\n![图解线程池实现原理](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-7/图解线程池实现原理.png)\n\n现在，让我们在回到 4.6 节我们写的 Demo， 现在应该是不是很容易就可以搞懂它的原理了呢？\n\n没搞懂的话，也没关系，可以看看我的分析：\n\n> 我们在代码中模拟了 10 个任务，我们配置的核心线程数为 5 、等待队列容量为 100 ，所以每次只可能存在 5 个任务同时执行，剩下的 5 个任务会被放到等待队列中去。当前的 5 个任务之行完成后，才会之行剩下的 5 个任务。\n\n## 5. Atomic 原子类\n\n### 5.1. 介绍一下Atomic 原子类\n\nAtomic 翻译成中文是原子的意思。在化学上，我们知道原子是构成一般物质的最小单位，在化学反应中是不可分割的。在我们这里 Atomic 是指一个操作是不可中断的。即使是在多个线程一起执行的时候，一个操作一旦开始，就不会被其他线程干扰。\n\n所以，所谓原子类说简单点就是具有原子/原子操作特征的类。\n\n\n并发包 `java.util.concurrent` 的原子类都存放在`java.util.concurrent.atomic`下,如下图所示。\n\n![JUC原子类概览](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/JUC原子类概览.png)\n\n### 5.2. JUC 包中的原子类是哪4类?\n\n**基本类型** \n\n使用原子的方式更新基本类型\n\n- AtomicInteger：整形原子类\n- AtomicLong：长整型原子类\n- AtomicBoolean：布尔型原子类\n\n**数组类型**\n\n使用原子的方式更新数组里的某个元素\n\n\n- AtomicIntegerArray：整形数组原子类\n- AtomicLongArray：长整形数组原子类\n- AtomicReferenceArray：引用类型数组原子类\n\n**引用类型**\n\n- AtomicReference：引用类型原子类\n- AtomicStampedReference：原子更新引用类型里的字段原子类\n- AtomicMarkableReference ：原子更新带有标记位的引用类型\n\n**对象的属性修改类型**\n\n- AtomicIntegerFieldUpdater：原子更新整形字段的更新器\n- AtomicLongFieldUpdater：原子更新长整形字段的更新器\n- AtomicStampedReference：原子更新带有版本号的引用类型。该类将整数值与引用关联起来，可用于解决原子的更新数据和数据的版本号，可以解决使用 CAS 进行原子更新时可能出现的 ABA 问题。\n\n\n### 5.3. 讲讲 AtomicInteger 的使用\n\n **AtomicInteger 类常用方法**\n\n```java\npublic final int get() //获取当前的值\npublic final int getAndSet(int newValue)//获取当前的值，并设置新的值\npublic final int getAndIncrement()//获取当前的值，并自增\npublic final int getAndDecrement() //获取当前的值，并自减\npublic final int getAndAdd(int delta) //获取当前的值，并加上预期的值\nboolean compareAndSet(int expect, int update) //如果输入的数值等于预期值，则以原子方式将该值设置为输入值（update）\npublic final void lazySet(int newValue)//最终设置为newValue,使用 lazySet 设置之后可能导致其他线程在之后的一小段时间内还是可以读到旧的值。\n```\n\n **AtomicInteger 类的使用示例**\n\n使用 AtomicInteger 之后，不用对 increment() 方法加锁也可以保证线程安全。\n```java\nclass AtomicIntegerTest {\n        private AtomicInteger count = new AtomicInteger();\n      //使用AtomicInteger之后，不需要对该方法加锁，也可以实现线程安全。\n        public void increment() {\n                  count.incrementAndGet();\n        }\n     \n       public int getCount() {\n                return count.get();\n        }\n}\n\n```\n\n### 5.4. 能不能给我简单介绍一下 AtomicInteger 类的原理\n\nAtomicInteger 线程安全原理简单分析\n\nAtomicInteger 类的部分源码：\n\n```java\n    // setup to use Unsafe.compareAndSwapInt for updates（更新操作时提供“比较并替换”的作用）\n    private static final Unsafe unsafe = Unsafe.getUnsafe();\n    private static final long valueOffset;\n\n    static {\n        try {\n            valueOffset = unsafe.objectFieldOffset\n                (AtomicInteger.class.getDeclaredField(\"value\"));\n        } catch (Exception ex) { throw new Error(ex); }\n    }\n\n    private volatile int value;\n```\n\nAtomicInteger 类主要利用 CAS (compare and swap) + volatile 和 native 方法来保证原子操作，从而避免 synchronized 的高开销，执行效率大为提升。\n\nCAS的原理是拿期望的值和原本的一个值作比较，如果相同则更新成新的值。UnSafe 类的 objectFieldOffset() 方法是一个本地方法，这个方法是用来拿到“原来的值”的内存地址，返回值是 valueOffset。另外 value 是一个volatile变量，在内存中可见，因此 JVM 可以保证任何时刻任何线程总能拿到该变量的最新值。\n\n关于 Atomic 原子类这部分更多内容可以查看我的这篇文章：并发编程面试必备：[JUC 中的 Atomic 原子类总结](https://mp.weixin.qq.com/s/joa-yOiTrYF67bElj8xqvg)\n\n## 6. AQS\n\n### 6.1. AQS 介绍\n\nAQS的全称为（AbstractQueuedSynchronizer），这个类在java.util.concurrent.locks包下面。\n\n![AQS类](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/AQS类.png)\n\nAQS是一个用来构建锁和同步器的框架，使用AQS能简单且高效地构造出应用广泛的大量的同步器，比如我们提到的ReentrantLock，Semaphore，其他的诸如ReentrantReadWriteLock，SynchronousQueue，FutureTask等等皆是基于AQS的。当然，我们自己也能利用AQS非常轻松容易地构造出符合我们自己需求的同步器。\n\n### 6.2. AQS 原理分析\n\nAQS 原理这部分参考了部分博客，在5.2节末尾放了链接。\n\n> 在面试中被问到并发知识的时候，大多都会被问到“请你说一下自己对于AQS原理的理解”。下面给大家一个示例供大家参加，面试不是背题，大家一定要加入自己的思想，即使加入不了自己的思想也要保证自己能够通俗的讲出来而不是背出来。\n\n下面大部分内容其实在AQS类注释上已经给出了，不过是英语看着比较吃力一点，感兴趣的话可以看看源码。\n\n#### 6.2.1. AQS 原理概览\n\n**AQS核心思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制AQS是用CLH队列锁实现的，即将暂时获取不到锁的线程加入到队列中。**\n\n> CLH(Craig,Landin,and Hagersten)队列是一个虚拟的双向队列（虚拟的双向队列即不存在队列实例，仅存在结点之间的关联关系）。AQS是将每条请求共享资源的线程封装成一个CLH锁队列的一个结点（Node）来实现锁的分配。\n\n看个AQS(AbstractQueuedSynchronizer)原理图：\n\n\n![AQS原理图](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/AQS原理图.png)\n\nAQS使用一个int成员变量来表示同步状态，通过内置的FIFO队列来完成获取资源线程的排队工作。AQS使用CAS对该同步状态进行原子操作实现对其值的修改。\n\n```java\nprivate volatile int state;//共享变量，使用volatile修饰保证线程可见性\n```\n\n状态信息通过protected类型的getState，setState，compareAndSetState进行操作\n\n```java\n\n//返回同步状态的当前值\nprotected final int getState() {  \n        return state;\n}\n // 设置同步状态的值\nprotected final void setState(int newState) { \n        state = newState;\n}\n//原子地（CAS操作）将同步状态值设置为给定值update如果当前同步状态的值等于expect（期望值）\nprotected final boolean compareAndSetState(int expect, int update) {\n        return unsafe.compareAndSwapInt(this, stateOffset, expect, update);\n}\n```\n\n#### 6.2.2. AQS 对资源的共享方式\n\n**AQS定义两种资源共享方式**\n\n- **Exclusive**（独占）：只有一个线程能执行，如ReentrantLock。又可分为公平锁和非公平锁：\n    - 公平锁：按照线程在队列中的排队顺序，先到者先拿到锁\n    - 非公平锁：当线程要获取锁时，无视队列顺序直接去抢锁，谁抢到就是谁的\n- **Share**（共享）：多个线程可同时执行，如Semaphore/CountDownLatch。Semaphore、CountDownLatch、 CyclicBarrier、ReadWriteLock 我们都会在后面讲到。\n\nReentrantReadWriteLock 可以看成是组合式，因为ReentrantReadWriteLock也就是读写锁允许多个线程同时对某一资源进行读。\n\n不同的自定义同步器争用共享资源的方式也不同。自定义同步器在实现时只需要实现共享资源 state 的获取与释放方式即可，至于具体线程等待队列的维护（如获取资源失败入队/唤醒出队等），AQS已经在顶层实现好了。\n\n#### 6.2.3. AQS底层使用了模板方法模式\n\n同步器的设计是基于模板方法模式的，如果需要自定义同步器一般的方式是这样（模板方法模式很经典的一个应用）：\n\n1. 使用者继承AbstractQueuedSynchronizer并重写指定的方法。（这些重写方法很简单，无非是对于共享资源state的获取和释放）\n2. 将AQS组合在自定义同步组件的实现中，并调用其模板方法，而这些模板方法会调用使用者重写的方法。\n\n这和我们以往通过实现接口的方式有很大区别，这是模板方法模式很经典的一个运用。\n\n**AQS使用了模板方法模式，自定义同步器时需要重写下面几个AQS提供的模板方法：**\n\n```java\nisHeldExclusively()//该线程是否正在独占资源。只有用到condition才需要去实现它。\ntryAcquire(int)//独占方式。尝试获取资源，成功则返回true，失败则返回false。\ntryRelease(int)//独占方式。尝试释放资源，成功则返回true，失败则返回false。\ntryAcquireShared(int)//共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。\ntryReleaseShared(int)//共享方式。尝试释放资源，成功则返回true，失败则返回false。\n\n```\n\n默认情况下，每个方法都抛出 `UnsupportedOperationException`。 这些方法的实现必须是内部线程安全的，并且通常应该简短而不是阻塞。AQS类中的其他方法都是final ，所以无法被其他类使用，只有这几个方法可以被其他类使用。 \n\n以ReentrantLock为例，state初始化为0，表示未锁定状态。A线程lock()时，会调用tryAcquire()独占该锁并将state+1。此后，其他线程再tryAcquire()时就会失败，直到A线程unlock()到state=0（即释放锁）为止，其它线程才有机会获取该锁。当然，释放锁之前，A线程自己是可以重复获取此锁的（state会累加），这就是可重入的概念。但要注意，获取多少次就要释放多么次，这样才能保证state是能回到零态的。\n\n再以CountDownLatch以例，任务分为N个子线程去执行，state也初始化为N（注意N要与线程个数一致）。这N个子线程是并行执行的，每个子线程执行完后countDown()一次，state会CAS(Compare and Swap)减1。等到所有子线程都执行完后(即state=0)，会unpark()主调用线程，然后主调用线程就会从await()函数返回，继续后余动作。\n\n一般来说，自定义同步器要么是独占方法，要么是共享方式，他们也只需实现`tryAcquire-tryRelease`、`tryAcquireShared-tryReleaseShared`中的一种即可。但AQS也支持自定义同步器同时实现独占和共享两种方式，如`ReentrantReadWriteLock`。\n\n推荐两篇 AQS 原理和相关源码分析的文章：\n\n- http://www.cnblogs.com/waterystone/p/4920797.html\n- https://www.cnblogs.com/chengxiao/archive/2017/07/24/7141160.html\n\n### 6.3. AQS 组件总结\n\n- **Semaphore(信号量)-允许多个线程同时访问：** synchronized 和 ReentrantLock 都是一次只允许一个线程访问某个资源，Semaphore(信号量)可以指定多个线程同时访问某个资源。\n- **CountDownLatch （倒计时器）：** CountDownLatch是一个同步工具类，用来协调多个线程之间的同步。这个工具通常用来控制线程等待，它可以让某一个线程等待直到倒计时结束，再开始执行。\n- **CyclicBarrier(循环栅栏)：** CyclicBarrier 和 CountDownLatch 非常类似，它也可以实现线程间的技术等待，但是它的功能比 CountDownLatch 更加复杂和强大。主要应用场景和 CountDownLatch 类似。CyclicBarrier 的字面意思是可循环使用（Cyclic）的屏障（Barrier）。它要做的事情是，让一组线程到达一个屏障（也可以叫同步点）时被阻塞，直到最后一个线程到达屏障时，屏障才会开门，所有被屏障拦截的线程才会继续干活。CyclicBarrier默认的构造方法是 CyclicBarrier(int parties)，其参数表示屏障拦截的线程数量，每个线程调用await()方法告诉 CyclicBarrier 我已经到达了屏障，然后当前线程被阻塞。\n\n## 7 Reference\n\n- 《深入理解 Java 虚拟机》\n- 《实战 Java 高并发程序设计》\n- 《Java并发编程的艺术》\n- http://www.cnblogs.com/waterystone/p/4920797.html\n- https://www.cnblogs.com/chengxiao/archive/2017/07/24/7141160.html\n- <https://www.journaldev.com/1076/java-threadlocal-example>\n","slug":"kongzheng1993-java多线程总结","published":1,"updated":"2023-03-08T07:05:58.773Z","photos":[],"link":"","_id":"clg0k2aza00jtt26fwe3ur7d3","content":"<p>以下文字摘自<a href=\"https://github.com/Snailclimb/JavaGuide\" target=\"_blank\" rel=\"noopener\">JavaGuide</a></p>\n<!-- TOC -->\n\n<ul>\n<li><a href=\"#java-并发基础常见面试题总结\">Java 并发基础常见面试题总结</a><ul>\n<li><a href=\"#1-什么是线程和进程\">1. 什么是线程和进程?</a><ul>\n<li><a href=\"#11-何为进程\">1.1. 何为进程?</a></li>\n<li><a href=\"#12-何为线程\">1.2. 何为线程?</a></li>\n</ul>\n</li>\n<li><a href=\"#2-请简要描述线程与进程的关系区别及优缺点\">2. 请简要描述线程与进程的关系,区别及优缺点？</a><ul>\n<li><a href=\"#21-图解进程和线程的关系\">2.1. 图解进程和线程的关系</a></li>\n<li><a href=\"#22-程序计数器为什么是私有的\">2.2. 程序计数器为什么是私有的?</a></li>\n<li><a href=\"#23-虚拟机栈和本地方法栈为什么是私有的\">2.3. 虚拟机栈和本地方法栈为什么是私有的?</a></li>\n<li><a href=\"#24-一句话简单了解堆和方法区\">2.4. 一句话简单了解堆和方法区</a></li>\n</ul>\n</li>\n<li><a href=\"#3-说说并发与并行的区别\">3. 说说并发与并行的区别?</a></li>\n<li><a href=\"#4-为什么要使用多线程呢\">4. 为什么要使用多线程呢?</a></li>\n<li><a href=\"#5-使用多线程可能带来什么问题\">5. 使用多线程可能带来什么问题?</a></li>\n<li><a href=\"#6-说说线程的生命周期和状态\">6. 说说线程的生命周期和状态?</a></li>\n<li><a href=\"#7-什么是上下文切换\">7. 什么是上下文切换?</a></li>\n<li><a href=\"#8-什么是线程死锁如何避免死锁\">8. 什么是线程死锁?如何避免死锁?</a><ul>\n<li><a href=\"#81-认识线程死锁\">8.1. 认识线程死锁</a></li>\n<li><a href=\"#82-如何避免线程死锁\">8.2. 如何避免线程死锁?</a></li>\n</ul>\n</li>\n<li><a href=\"#9-说说-sleep-方法和-wait-方法区别和共同点\">9. 说说 sleep() 方法和 wait() 方法区别和共同点?</a></li>\n<li><a href=\"#10-为什么我们调用-start-方法时会执行-run-方法为什么我们不能直接调用-run-方法\">10. 为什么我们调用 start() 方法时会执行 run() 方法，为什么我们不能直接调用 run() 方法？</a></li>\n</ul>\n</li>\n</ul>\n<!-- /TOC -->\n\n<h1 id=\"Java-并发基础常见面试题总结\"><a href=\"#Java-并发基础常见面试题总结\" class=\"headerlink\" title=\"Java 并发基础常见面试题总结\"></a>Java 并发基础常见面试题总结</h1><h2 id=\"1-什么是线程和进程\"><a href=\"#1-什么是线程和进程\" class=\"headerlink\" title=\"1. 什么是线程和进程?\"></a>1. 什么是线程和进程?</h2><h3 id=\"1-1-何为进程\"><a href=\"#1-1-何为进程\" class=\"headerlink\" title=\"1.1. 何为进程?\"></a>1.1. 何为进程?</h3><p>进程是程序的一次执行过程，是系统运行程序的基本单位，因此进程是动态的。系统运行一个程序即是一个进程从创建，运行到消亡的过程。</p>\n<p>在 Java 中，当我们启动 main 函数时其实就是启动了一个 JVM 的进程，而 main 函数所在的线程就是这个进程中的一个线程，也称主线程。</p>\n<p>如下图所示，在 windows 中通过查看任务管理器的方式，我们就可以清楚看到 window 当前运行的进程（.exe 文件的运行）。</p>\n<p><img src=\"https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/%E8%BF%9B%E7%A8%8B%E7%A4%BA%E4%BE%8B%E5%9B%BE%E7%89%87-Windows.png\" alt=\"进程示例图片-Windows\"></p>\n<h3 id=\"1-2-何为线程\"><a href=\"#1-2-何为线程\" class=\"headerlink\" title=\"1.2. 何为线程?\"></a>1.2. 何为线程?</h3><p>线程与进程相似，但线程是一个比进程更小的执行单位。一个进程在其执行的过程中可以产生多个线程。与进程不同的是同类的多个线程共享进程的<strong>堆</strong>和<strong>方法区</strong>资源，但每个线程有自己的<strong>程序计数器</strong>、<strong>虚拟机栈</strong>和<strong>本地方法栈</strong>，所以系统在产生一个线程，或是在各个线程之间作切换工作时，负担要比进程小得多，也正因为如此，线程也被称为轻量级进程。</p>\n<p>Java 程序天生就是多线程程序，我们可以通过 JMX 来看一下一个普通的 Java 程序有哪些线程，代码如下。</p>\n<pre><code class=\"java\">public class MultiThread {\n    public static void main(String[] args) {\n        // 获取 Java 线程管理 MXBean\n    ThreadMXBean threadMXBean = ManagementFactory.getThreadMXBean();\n        // 不需要获取同步的 monitor 和 synchronizer 信息，仅获取线程和线程堆栈信息\n        ThreadInfo[] threadInfos = threadMXBean.dumpAllThreads(false, false);\n        // 遍历线程信息，仅打印线程 ID 和线程名称信息\n        for (ThreadInfo threadInfo : threadInfos) {\n            System.out.println(&quot;[&quot; + threadInfo.getThreadId() + &quot;] &quot; + threadInfo.getThreadName());\n        }\n    }\n}</code></pre>\n<p>上述程序输出如下（输出内容可能不同，不用太纠结下面每个线程的作用，只用知道 main 线程执行 main 方法即可）：</p>\n<pre><code>[5] Attach Listener //添加事件\n[4] Signal Dispatcher // 分发处理给 JVM 信号的线程\n[3] Finalizer //调用对象 finalize 方法的线程\n[2] Reference Handler //清除 reference 线程\n[1] main //main 线程,程序入口</code></pre><p>从上面的输出内容可以看出：<strong>一个 Java 程序的运行是 main 线程和多个其他线程同时运行</strong>。</p>\n<h2 id=\"2-请简要描述线程与进程的关系-区别及优缺点？\"><a href=\"#2-请简要描述线程与进程的关系-区别及优缺点？\" class=\"headerlink\" title=\"2. 请简要描述线程与进程的关系,区别及优缺点？\"></a>2. 请简要描述线程与进程的关系,区别及优缺点？</h2><p><strong>从 JVM 角度说进程和线程之间的关系</strong></p>\n<h3 id=\"2-1-图解进程和线程的关系\"><a href=\"#2-1-图解进程和线程的关系\" class=\"headerlink\" title=\"2.1. 图解进程和线程的关系\"></a>2.1. 图解进程和线程的关系</h3><p>下图是 Java 内存区域，通过下图我们从 JVM 的角度来说一下线程和进程之间的关系。如果你对 Java 内存区域 (运行时数据区) 这部分知识不太了解的话可以阅读一下这篇文章：<a href=\"https://github.com/Snailclimb/JavaGuide/blob/3965c02cc0f294b0bd3580df4868d5e396959e2e/Java%E7%9B%B8%E5%85%B3/%E5%8F%AF%E8%83%BD%E6%98%AF%E6%8A%8AJava%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F%E8%AE%B2%E7%9A%84%E6%9C%80%E6%B8%85%E6%A5%9A%E7%9A%84%E4%B8%80%E7%AF%87%E6%96%87%E7%AB%A0.md\" title=\"《可能是把 Java 内存区域讲的最清楚的一篇文章》\" target=\"_blank\" rel=\"noopener\">《可能是把 Java 内存区域讲的最清楚的一篇文章》</a></p>\n<div align=\"center\">  \n<img src=\"https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-3/JVM运行时数据区域.png\" width=\"600px\">\n</div>\n\n<p>从上图可以看出：一个进程中可以有多个线程，多个线程共享进程的<strong>堆</strong>和<strong>方法区 (JDK1.8 之后的元空间)</strong>资源，但是每个线程有自己的<strong>程序计数器</strong>、<strong>虚拟机栈</strong> 和 <strong>本地方法栈</strong>。</p>\n<p><strong>总结：</strong> 线程 是 进程 划分成的更小的运行单位。线程和进程最大的不同在于基本上各进程是独立的，而各线程则不一定，因为同一进程中的线程极有可能会相互影响。线程执行开销小，但不利于资源的管理和保护；而进程正相反</p>\n<p>下面是该知识点的扩展内容！</p>\n<p>下面来思考这样一个问题：为什么<strong>程序计数器</strong>、<strong>虚拟机栈</strong>和<strong>本地方法栈</strong>是线程私有的呢？为什么堆和方法区是线程共享的呢？</p>\n<h3 id=\"2-2-程序计数器为什么是私有的\"><a href=\"#2-2-程序计数器为什么是私有的\" class=\"headerlink\" title=\"2.2. 程序计数器为什么是私有的?\"></a>2.2. 程序计数器为什么是私有的?</h3><p>程序计数器主要有下面两个作用：</p>\n<ol>\n<li>字节码解释器通过改变程序计数器来依次读取指令，从而实现代码的流程控制，如：顺序执行、选择、循环、异常处理。</li>\n<li>在多线程的情况下，程序计数器用于记录当前线程执行的位置，从而当线程被切换回来的时候能够知道该线程上次运行到哪儿了。</li>\n</ol>\n<p>需要注意的是，如果执行的是 native 方法，那么程序计数器记录的是 undefined 地址，只有执行的是 Java 代码时程序计数器记录的才是下一条指令的地址。</p>\n<p>所以，程序计数器私有主要是为了<strong>线程切换后能恢复到正确的执行位置</strong>。</p>\n<h3 id=\"2-3-虚拟机栈和本地方法栈为什么是私有的\"><a href=\"#2-3-虚拟机栈和本地方法栈为什么是私有的\" class=\"headerlink\" title=\"2.3. 虚拟机栈和本地方法栈为什么是私有的?\"></a>2.3. 虚拟机栈和本地方法栈为什么是私有的?</h3><ul>\n<li><strong>虚拟机栈：</strong> 每个 Java 方法在执行的同时会创建一个栈帧用于存储局部变量表、操作数栈、常量池引用等信息。从方法调用直至执行完成的过程，就对应着一个栈帧在 Java 虚拟机栈中入栈和出栈的过程。</li>\n<li><strong>本地方法栈：</strong> 和虚拟机栈所发挥的作用非常相似，区别是： <strong>虚拟机栈为虚拟机执行 Java 方法 （也就是字节码）服务，而本地方法栈则为虚拟机使用到的 Native 方法服务。</strong> 在 HotSpot 虚拟机中和 Java 虚拟机栈合二为一。</li>\n</ul>\n<p>所以，为了<strong>保证线程中的局部变量不被别的线程访问到</strong>，虚拟机栈和本地方法栈是线程私有的。</p>\n<h3 id=\"2-4-一句话简单了解堆和方法区\"><a href=\"#2-4-一句话简单了解堆和方法区\" class=\"headerlink\" title=\"2.4. 一句话简单了解堆和方法区\"></a>2.4. 一句话简单了解堆和方法区</h3><p>堆和方法区是所有线程共享的资源，其中堆是进程中最大的一块内存，主要用于存放新创建的对象 (所有对象都在这里分配内存)，方法区主要用于存放已被加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。</p>\n<h2 id=\"3-说说并发与并行的区别\"><a href=\"#3-说说并发与并行的区别\" class=\"headerlink\" title=\"3. 说说并发与并行的区别?\"></a>3. 说说并发与并行的区别?</h2><ul>\n<li><strong>并发：</strong> 同一时间段，多个任务都在执行 (单位时间内不一定同时执行)；</li>\n<li><strong>并行：</strong> 单位时间内，多个任务同时执行。</li>\n</ul>\n<h2 id=\"4-为什么要使用多线程呢\"><a href=\"#4-为什么要使用多线程呢\" class=\"headerlink\" title=\"4. 为什么要使用多线程呢?\"></a>4. 为什么要使用多线程呢?</h2><p>先从总体上来说：</p>\n<ul>\n<li><strong>从计算机底层来说：</strong> 线程可以比作是轻量级的进程，是程序执行的最小单位,线程间的切换和调度的成本远远小于进程。另外，多核 CPU 时代意味着多个线程可以同时运行，这减少了线程上下文切换的开销。</li>\n<li><strong>从当代互联网发展趋势来说：</strong> 现在的系统动不动就要求百万级甚至千万级的并发量，而多线程并发编程正是开发高并发系统的基础，利用好多线程机制可以大大提高系统整体的并发能力以及性能。</li>\n</ul>\n<p>再深入到计算机底层来探讨：</p>\n<ul>\n<li><strong>单核时代：</strong> 在单核时代多线程主要是为了提高 CPU 和 IO 设备的综合利用率。举个例子：当只有一个线程的时候会导致 CPU 计算时，IO 设备空闲；进行 IO 操作时，CPU 空闲。我们可以简单地说这两者的利用率目前都是 50%左右。但是当有两个线程的时候就不一样了，当一个线程执行 CPU 计算时，另外一个线程可以进行 IO 操作，这样两个的利用率就可以在理想情况下达到 100%了。</li>\n<li><strong>多核时代:</strong> 多核时代多线程主要是为了提高 CPU 利用率。举个例子：假如我们要计算一个复杂的任务，我们只用一个线程的话，CPU 只会一个 CPU 核心被利用到，而创建多个线程就可以让多个 CPU 核心被利用到，这样就提高了 CPU 的利用率。</li>\n</ul>\n<h2 id=\"5-使用多线程可能带来什么问题\"><a href=\"#5-使用多线程可能带来什么问题\" class=\"headerlink\" title=\"5. 使用多线程可能带来什么问题?\"></a>5. 使用多线程可能带来什么问题?</h2><p>并发编程的目的就是为了能提高程序的执行效率提高程序运行速度，但是并发编程并不总是能提高程序运行速度的，而且并发编程可能会遇到很多问题，比如：内存泄漏、死锁、线程不安全等等。</p>\n<h2 id=\"6-说说线程的生命周期和状态\"><a href=\"#6-说说线程的生命周期和状态\" class=\"headerlink\" title=\"6. 说说线程的生命周期和状态?\"></a>6. 说说线程的生命周期和状态?</h2><p>Java 线程在运行的生命周期中的指定时刻只可能处于下面 6 种不同状态的其中一个状态（图源《Java 并发编程艺术》4.1.4 节）。</p>\n<p><img src=\"https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/19-1-29/Java%E7%BA%BF%E7%A8%8B%E7%9A%84%E7%8A%B6%E6%80%81.png\" alt=\"Java 线程的状态 \"></p>\n<p>线程在生命周期中并不是固定处于某一个状态而是随着代码的执行在不同状态之间切换。Java 线程状态变迁如下图所示（图源《Java 并发编程艺术》4.1.4 节）：</p>\n<p><img src=\"https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/19-1-29/Java+%E7%BA%BF%E7%A8%8B%E7%8A%B6%E6%80%81%E5%8F%98%E8%BF%81.png\" alt=\"Java 线程状态变迁 \"></p>\n<p>由上图可以看出：线程创建之后它将处于 <strong>NEW（新建）</strong> 状态，调用 <code>start()</code> 方法后开始运行，线程这时候处于 <strong>READY（可运行）</strong> 状态。可运行状态的线程获得了 CPU 时间片（timeslice）后就处于 <strong>RUNNING（运行）</strong> 状态。</p>\n<blockquote>\n<p>操作系统隐藏 Java 虚拟机（JVM）中的 RUNNABLE 和 RUNNING 状态，它只能看到 RUNNABLE 状态（图源：<a href=\"https://howtodoinjava.com/\" title=\"HowToDoInJava\" target=\"_blank\" rel=\"noopener\">HowToDoInJava</a>：<a href=\"https://howtodoinjava.com/java/multi-threading/java-thread-life-cycle-and-thread-states/\" title=\"Java Thread Life Cycle and Thread States\" target=\"_blank\" rel=\"noopener\">Java Thread Life Cycle and Thread States</a>），所以 Java 系统一般将这两个状态统称为 <strong>RUNNABLE（运行中）</strong> 状态 。</p>\n</blockquote>\n<p><img src=\"https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-3/RUNNABLE-VS-RUNNING.png\" alt=\"RUNNABLE-VS-RUNNING\"></p>\n<p>当线程执行 <code>wait()</code>方法之后，线程进入 <strong>WAITING（等待）</strong> 状态。进入等待状态的线程需要依靠其他线程的通知才能够返回到运行状态，而 <strong>TIME_WAITING(超时等待)</strong> 状态相当于在等待状态的基础上增加了超时限制，比如通过 <code>sleep（long millis）</code>方法或 <code>wait（long millis）</code>方法可以将 Java 线程置于 TIMED WAITING 状态。当超时时间到达后 Java 线程将会返回到 RUNNABLE 状态。当线程调用同步方法时，在没有获取到锁的情况下，线程将会进入到 <strong>BLOCKED（阻塞）</strong> 状态。线程在执行 Runnable 的<code>run()</code>方法之后将会进入到 <strong>TERMINATED（终止）</strong> 状态。</p>\n<h2 id=\"7-什么是上下文切换\"><a href=\"#7-什么是上下文切换\" class=\"headerlink\" title=\"7. 什么是上下文切换?\"></a>7. 什么是上下文切换?</h2><p>多线程编程中一般线程的个数都大于 CPU 核心的个数，而一个 CPU 核心在任意时刻只能被一个线程使用，为了让这些线程都能得到有效执行，CPU 采取的策略是为每个线程分配时间片并轮转的形式。当一个线程的时间片用完的时候就会重新处于就绪状态让给其他线程使用，这个过程就属于一次上下文切换。</p>\n<p>概括来说就是：当前任务在执行完 CPU 时间片切换到另一个任务之前会先保存自己的状态，以便下次再切换回这个任务时，可以再加载这个任务的状态。<strong>任务从保存到再加载的过程就是一次上下文切换</strong>。</p>\n<p>上下文切换通常是计算密集型的。也就是说，它需要相当可观的处理器时间，在每秒几十上百次的切换中，每次切换都需要纳秒量级的时间。所以，上下文切换对系统来说意味着消耗大量的 CPU 时间，事实上，可能是操作系统中时间消耗最大的操作。</p>\n<p>Linux 相比与其他操作系统（包括其他类 Unix 系统）有很多的优点，其中有一项就是，其上下文切换和模式切换的时间消耗非常少。</p>\n<h2 id=\"8-什么是线程死锁-如何避免死锁\"><a href=\"#8-什么是线程死锁-如何避免死锁\" class=\"headerlink\" title=\"8. 什么是线程死锁?如何避免死锁?\"></a>8. 什么是线程死锁?如何避免死锁?</h2><h3 id=\"8-1-认识线程死锁\"><a href=\"#8-1-认识线程死锁\" class=\"headerlink\" title=\"8.1. 认识线程死锁\"></a>8.1. 认识线程死锁</h3><p>线程死锁描述的是这样一种情况：多个线程同时被阻塞，它们中的一个或者全部都在等待某个资源被释放。由于线程被无限期地阻塞，因此程序不可能正常终止。</p>\n<p>如下图所示，线程 A 持有资源 2，线程 B 持有资源 1，他们同时都想申请对方的资源，所以这两个线程就会互相等待而进入死锁状态。</p>\n<p><img src=\"https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-4/2019-4%E6%AD%BB%E9%94%811.png\" alt=\"线程死锁示意图 \"></p>\n<p>下面通过一个例子来说明线程死锁,代码模拟了上图的死锁的情况 (代码来源于《并发编程之美》)：</p>\n<pre><code class=\"java\">public class DeadLockDemo {\n    private static Object resource1 = new Object();//资源 1\n    private static Object resource2 = new Object();//资源 2\n\n    public static void main(String[] args) {\n        new Thread(() -&gt; {\n            synchronized (resource1) {\n                System.out.println(Thread.currentThread() + &quot;get resource1&quot;);\n                try {\n                    Thread.sleep(1000);\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n                System.out.println(Thread.currentThread() + &quot;waiting get resource2&quot;);\n                synchronized (resource2) {\n                    System.out.println(Thread.currentThread() + &quot;get resource2&quot;);\n                }\n            }\n        }, &quot;线程 1&quot;).start();\n\n        new Thread(() -&gt; {\n            synchronized (resource2) {\n                System.out.println(Thread.currentThread() + &quot;get resource2&quot;);\n                try {\n                    Thread.sleep(1000);\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n                System.out.println(Thread.currentThread() + &quot;waiting get resource1&quot;);\n                synchronized (resource1) {\n                    System.out.println(Thread.currentThread() + &quot;get resource1&quot;);\n                }\n            }\n        }, &quot;线程 2&quot;).start();\n    }\n}</code></pre>\n<p>Output</p>\n<pre><code>Thread[线程 1,5,main]get resource1\nThread[线程 2,5,main]get resource2\nThread[线程 1,5,main]waiting get resource2\nThread[线程 2,5,main]waiting get resource1</code></pre><p>线程 A 通过 synchronized (resource1) 获得 resource1 的监视器锁，然后通过<code>Thread.sleep(1000);</code>让线程 A 休眠 1s 为的是让线程 B 得到执行然后获取到 resource2 的监视器锁。线程 A 和线程 B 休眠结束了都开始企图请求获取对方的资源，然后这两个线程就会陷入互相等待的状态，这也就产生了死锁。上面的例子符合产生死锁的四个必要条件。</p>\n<p>学过操作系统的朋友都知道产生死锁必须具备以下四个条件：</p>\n<ol>\n<li>互斥条件：该资源任意一个时刻只由一个线程占用。</li>\n<li>请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。</li>\n<li>不剥夺条件:线程已获得的资源在末使用完之前不能被其他线程强行剥夺，只有自己使用完毕后才释放资源。</li>\n<li>循环等待条件:若干进程之间形成一种头尾相接的循环等待资源关系。</li>\n</ol>\n<h3 id=\"8-2-如何避免线程死锁\"><a href=\"#8-2-如何避免线程死锁\" class=\"headerlink\" title=\"8.2. 如何避免线程死锁?\"></a>8.2. 如何避免线程死锁?</h3><p>我上面说了产生死锁的四个必要条件，为了避免死锁，我们只要破坏产生死锁的四个条件中的其中一个就可以了。现在我们来挨个分析一下：</p>\n<ol>\n<li><strong>破坏互斥条件</strong> ：这个条件我们没有办法破坏，因为我们用锁本来就是想让他们互斥的（临界资源需要互斥访问）。</li>\n<li><strong>破坏请求与保持条件</strong>  ：一次性申请所有的资源。</li>\n<li><strong>破坏不剥夺条件</strong> ：占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源。</li>\n<li><strong>破坏循环等待条件</strong> ：靠按序申请资源来预防。按某一顺序申请资源，释放资源则反序释放。破坏循环等待条件。</li>\n</ol>\n<p>我们对线程 2 的代码修改成下面这样就不会产生死锁了。</p>\n<pre><code class=\"java\">        new Thread(() -&gt; {\n            synchronized (resource1) {\n                System.out.println(Thread.currentThread() + &quot;get resource1&quot;);\n                try {\n                    Thread.sleep(1000);\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n                System.out.println(Thread.currentThread() + &quot;waiting get resource2&quot;);\n                synchronized (resource2) {\n                    System.out.println(Thread.currentThread() + &quot;get resource2&quot;);\n                }\n            }\n        }, &quot;线程 2&quot;).start();</code></pre>\n<p>Output</p>\n<pre><code>Thread[线程 1,5,main]get resource1\nThread[线程 1,5,main]waiting get resource2\nThread[线程 1,5,main]get resource2\nThread[线程 2,5,main]get resource1\nThread[线程 2,5,main]waiting get resource2\nThread[线程 2,5,main]get resource2\n\nProcess finished with exit code 0</code></pre><p>我们分析一下上面的代码为什么避免了死锁的发生?</p>\n<p>线程 1 首先获得到 resource1 的监视器锁,这时候线程 2 就获取不到了。然后线程 1 再去获取 resource2 的监视器锁，可以获取到。然后线程 1 释放了对 resource1、resource2 的监视器锁的占用，线程 2 获取到就可以执行了。这样就破坏了破坏循环等待条件，因此避免了死锁。</p>\n<h2 id=\"9-说说-sleep-方法和-wait-方法区别和共同点\"><a href=\"#9-说说-sleep-方法和-wait-方法区别和共同点\" class=\"headerlink\" title=\"9. 说说 sleep() 方法和 wait() 方法区别和共同点?\"></a>9. 说说 sleep() 方法和 wait() 方法区别和共同点?</h2><ul>\n<li>两者最主要的区别在于：<strong>sleep 方法没有释放锁，而 wait 方法释放了锁</strong> 。</li>\n<li>两者都可以暂停线程的执行。</li>\n<li>Wait 通常被用于线程间交互/通信，sleep 通常被用于暂停执行。</li>\n<li>wait() 方法被调用后，线程不会自动苏醒，需要别的线程调用同一个对象上的 notify() 或者 notifyAll() 方法。sleep() 方法执行完成后，线程会自动苏醒。或者可以使用 wait(long timeout)超时后线程会自动苏醒。</li>\n</ul>\n<h2 id=\"10-为什么我们调用-start-方法时会执行-run-方法，为什么我们不能直接调用-run-方法？\"><a href=\"#10-为什么我们调用-start-方法时会执行-run-方法，为什么我们不能直接调用-run-方法？\" class=\"headerlink\" title=\"10. 为什么我们调用 start() 方法时会执行 run() 方法，为什么我们不能直接调用 run() 方法？\"></a>10. 为什么我们调用 start() 方法时会执行 run() 方法，为什么我们不能直接调用 run() 方法？</h2><p>这是另一个非常经典的 java 多线程面试问题，而且在面试中会经常被问到。很简单，但是很多人都会答不上来！</p>\n<p>new 一个 Thread，线程进入了新建状态;调用 start() 方法，会启动一个线程并使线程进入了就绪状态，当分配到时间片后就可以开始运行了。 start() 会执行线程的相应准备工作，然后自动执行 run() 方法的内容，这是真正的多线程工作。 而直接执行 run() 方法，会把 run 方法当成一个 main 线程下的普通方法去执行，并不会在某个线程中执行它，所以这并不是多线程工作。</p>\n<p><strong>总结： 调用 start 方法方可启动线程并使线程进入就绪状态，而 run 方法只是 thread 的一个普通方法调用，还是在主线程里执行。</strong></p>\n<!-- TOC -->\n\n<ul>\n<li><a href=\"#java-并发进阶常见面试题总结\">Java 并发进阶常见面试题总结</a><ul>\n<li><a href=\"#1-synchronized-关键字\">1. synchronized 关键字</a><ul>\n<li><a href=\"#11-说一说自己对于-synchronized-关键字的了解\">1.1. 说一说自己对于 synchronized 关键字的了解</a></li>\n<li><a href=\"#12-说说自己是怎么使用-synchronized-关键字在项目中用到了吗\">1.2. 说说自己是怎么使用 synchronized 关键字，在项目中用到了吗</a></li>\n<li><a href=\"#13-讲一下-synchronized-关键字的底层原理\">1.3. 讲一下 synchronized 关键字的底层原理</a></li>\n<li><a href=\"#14-说说-jdk16-之后的synchronized-关键字底层做了哪些优化可以详细介绍一下这些优化吗\">1.4. 说说 JDK1.6 之后的synchronized 关键字底层做了哪些优化，可以详细介绍一下这些优化吗</a></li>\n<li><a href=\"#15-谈谈-synchronized和reentrantlock-的区别\">1.5. 谈谈 synchronized和ReentrantLock 的区别</a></li>\n</ul>\n</li>\n<li><a href=\"#2-volatile关键字\">2. volatile关键字</a><ul>\n<li><a href=\"#21-讲一下java内存模型\">2.1. 讲一下Java内存模型</a></li>\n<li><a href=\"#22-说说-synchronized-关键字和-volatile-关键字的区别\">2.2. 说说 synchronized 关键字和 volatile 关键字的区别</a></li>\n</ul>\n</li>\n<li><a href=\"#3-threadlocal\">3. ThreadLocal</a><ul>\n<li><a href=\"#31-threadlocal简介\">3.1. ThreadLocal简介</a></li>\n<li><a href=\"#32-threadlocal示例\">3.2. ThreadLocal示例</a></li>\n<li><a href=\"#33-threadlocal原理\">3.3. ThreadLocal原理</a></li>\n<li><a href=\"#34-threadlocal-内存泄露问题\">3.4. ThreadLocal 内存泄露问题</a></li>\n</ul>\n</li>\n<li><a href=\"#4-线程池\">4. 线程池</a><ul>\n<li><a href=\"#41-为什么要用线程池\">4.1. 为什么要用线程池？</a></li>\n<li><a href=\"#42-实现runnable接口和callable接口的区别\">4.2. 实现Runnable接口和Callable接口的区别</a></li>\n<li><a href=\"#43-执行execute方法和submit方法的区别是什么呢\">4.3. 执行execute()方法和submit()方法的区别是什么呢？</a></li>\n<li><a href=\"#44-如何创建线程池\">4.4. 如何创建线程池</a></li>\n</ul>\n</li>\n<li><a href=\"#5-atomic-原子类\">5. Atomic 原子类</a><ul>\n<li><a href=\"#51-介绍一下atomic-原子类\">5.1. 介绍一下Atomic 原子类</a></li>\n<li><a href=\"#52-juc-包中的原子类是哪4类\">5.2. JUC 包中的原子类是哪4类?</a></li>\n<li><a href=\"#53-讲讲-atomicinteger-的使用\">5.3. 讲讲 AtomicInteger 的使用</a></li>\n<li><a href=\"#54-能不能给我简单介绍一下-atomicinteger-类的原理\">5.4. 能不能给我简单介绍一下 AtomicInteger 类的原理</a></li>\n</ul>\n</li>\n<li><a href=\"#6-aqs\">6. AQS</a><ul>\n<li><a href=\"#61-aqs-介绍\">6.1. AQS 介绍</a></li>\n<li><a href=\"#62-aqs-原理分析\">6.2. AQS 原理分析</a><ul>\n<li><a href=\"#621-aqs-原理概览\">6.2.1. AQS 原理概览</a></li>\n<li><a href=\"#622-aqs-对资源的共享方式\">6.2.2. AQS 对资源的共享方式</a></li>\n<li><a href=\"#623-aqs底层使用了模板方法模式\">6.2.3. AQS底层使用了模板方法模式</a></li>\n</ul>\n</li>\n<li><a href=\"#63-aqs-组件总结\">6.3. AQS 组件总结</a></li>\n</ul>\n</li>\n<li><a href=\"#7-reference\">7 Reference</a></li>\n</ul>\n</li>\n</ul>\n<!-- /TOC -->\n\n<h1 id=\"Java-并发进阶常见面试题总结\"><a href=\"#Java-并发进阶常见面试题总结\" class=\"headerlink\" title=\"Java 并发进阶常见面试题总结\"></a>Java 并发进阶常见面试题总结</h1><h2 id=\"1-synchronized-关键字\"><a href=\"#1-synchronized-关键字\" class=\"headerlink\" title=\"1. synchronized 关键字\"></a>1. synchronized 关键字</h2><h3 id=\"1-1-说一说自己对于-synchronized-关键字的了解\"><a href=\"#1-1-说一说自己对于-synchronized-关键字的了解\" class=\"headerlink\" title=\"1.1. 说一说自己对于 synchronized 关键字的了解\"></a>1.1. 说一说自己对于 synchronized 关键字的了解</h3><p>synchronized关键字解决的是多个线程之间访问资源的同步性，synchronized关键字可以保证被它修饰的方法或者代码块在任意时刻只能有一个线程执行。</p>\n<p>另外，在 Java 早期版本中，synchronized属于重量级锁，效率低下，因为监视器锁（monitor）是依赖于底层的操作系统的 Mutex Lock 来实现的，Java 的线程是映射到操作系统的原生线程之上的。如果要挂起或者唤醒一个线程，都需要操作系统帮忙完成，而操作系统实现线程之间的切换时需要从用户态转换到内核态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高，这也是为什么早期的 synchronized 效率低的原因。庆幸的是在 Java 6 之后 Java 官方对从 JVM 层面对synchronized 较大优化，所以现在的 synchronized 锁效率也优化得很不错了。JDK1.6对锁的实现引入了大量的优化，如自旋锁、适应性自旋锁、锁消除、锁粗化、偏向锁、轻量级锁等技术来减少锁操作的开销。</p>\n<h3 id=\"1-2-说说自己是怎么使用-synchronized-关键字，在项目中用到了吗\"><a href=\"#1-2-说说自己是怎么使用-synchronized-关键字，在项目中用到了吗\" class=\"headerlink\" title=\"1.2. 说说自己是怎么使用 synchronized 关键字，在项目中用到了吗\"></a>1.2. 说说自己是怎么使用 synchronized 关键字，在项目中用到了吗</h3><p><strong>synchronized关键字最主要的三种使用方式：</strong></p>\n<ul>\n<li><strong>修饰实例方法:</strong> 作用于当前对象实例加锁，进入同步代码前要获得当前对象实例的锁</li>\n<li><strong>修饰静态方法:</strong> 也就是给当前类加锁，会作用于类的所有对象实例，因为静态成员不属于任何一个实例对象，是类成员（ static 表明这是该类的一个静态资源，不管new了多少个对象，只有一份）。所以如果一个线程 A 调用一个实例对象的非静态 synchronized 方法，而线程 B 需要调用这个实例对象所属类的静态 synchronized 方法，是允许的，不会发生互斥现象，<strong>因为访问静态 synchronized 方法占用的锁是当前类的锁，而访问非静态 synchronized 方法占用的锁是当前实例对象锁</strong>。</li>\n<li><strong>修饰代码块:</strong> 指定加锁对象，对给定对象加锁，进入同步代码库前要获得给定对象的锁。</li>\n</ul>\n<p><strong>总结：</strong> synchronized 关键字加到 static 静态方法和 synchronized(class)代码块上都是是给 Class 类上锁。synchronized 关键字加到实例方法上是给对象实例上锁。尽量不要使用 synchronized(String a) 因为JVM中，字符串常量池具有缓存功能！</p>\n<p>下面我以一个常见的面试题为例讲解一下 synchronized 关键字的具体使用。</p>\n<p>面试中面试官经常会说：“单例模式了解吗？来给我手写一下！给我解释一下双重检验锁方式实现单例模式的原理呗！”</p>\n<p><strong>双重校验锁实现对象单例（线程安全）</strong></p>\n<pre><code class=\"java\">public class Singleton {\n\n    private volatile static Singleton uniqueInstance;\n\n    private Singleton() {\n    }\n\n    public static Singleton getUniqueInstance() {\n       //先判断对象是否已经实例过，没有实例化过才进入加锁代码\n        if (uniqueInstance == null) {\n            //类对象加锁\n            synchronized (Singleton.class) {\n                if (uniqueInstance == null) {\n                    uniqueInstance = new Singleton();\n                }\n            }\n        }\n        return uniqueInstance;\n    }\n}</code></pre>\n<p>另外，需要注意 uniqueInstance 采用 volatile 关键字修饰也是很有必要。</p>\n<p>uniqueInstance 采用 volatile 关键字修饰也是很有必要的， uniqueInstance = new Singleton(); 这段代码其实是分为三步执行：</p>\n<ol>\n<li>为 uniqueInstance 分配内存空间</li>\n<li>初始化 uniqueInstance</li>\n<li>将 uniqueInstance 指向分配的内存地址</li>\n</ol>\n<p>但是由于 JVM 具有指令重排的特性，执行顺序有可能变成 1-&gt;3-&gt;2。指令重排在单线程环境下不会出现问题，但是在多线程环境下会导致一个线程获得还没有初始化的实例。例如，线程 T1 执行了 1 和 3，此时 T2 调用 getUniqueInstance() 后发现 uniqueInstance 不为空，因此返回 uniqueInstance，但此时 uniqueInstance 还未被初始化。</p>\n<p>使用 volatile 可以禁止 JVM 的指令重排，保证在多线程环境下也能正常运行。</p>\n<h3 id=\"1-3-讲一下-synchronized-关键字的底层原理\"><a href=\"#1-3-讲一下-synchronized-关键字的底层原理\" class=\"headerlink\" title=\"1.3. 讲一下 synchronized 关键字的底层原理\"></a>1.3. 讲一下 synchronized 关键字的底层原理</h3><p><strong>synchronized 关键字底层原理属于 JVM 层面。</strong></p>\n<p><strong>① synchronized 同步语句块的情况</strong></p>\n<pre><code class=\"java\">public class SynchronizedDemo {\n    public void method() {\n        synchronized (this) {\n            System.out.println(&quot;synchronized 代码块&quot;);\n        }\n    }\n}\n</code></pre>\n<p>通过 JDK 自带的 javap 命令查看 SynchronizedDemo 类的相关字节码信息：首先切换到类的对应目录执行 <code>javac SynchronizedDemo.java</code> 命令生成编译后的 .class 文件，然后执行<code>javap -c -s -v -l SynchronizedDemo.class</code>。</p>\n<p><img src=\"https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/synchronized%E5%85%B3%E9%94%AE%E5%AD%97%E5%8E%9F%E7%90%86.png\" alt=\"synchronized关键字原理\"></p>\n<p>从上面我们可以看出：</p>\n<p><strong>synchronized 同步语句块的实现使用的是 monitorenter 和 monitorexit 指令，其中 monitorenter 指令指向同步代码块的开始位置，monitorexit 指令则指明同步代码块的结束位置。</strong> 当执行 monitorenter 指令时，线程试图获取锁也就是获取 monitor(monitor对象存在于每个Java对象的对象头中，synchronized 锁便是通过这种方式获取锁的，也是为什么Java中任意对象可以作为锁的原因) 的持有权。当计数器为0则可以成功获取，获取后将锁计数器设为1也就是加1。相应的在执行 monitorexit 指令后，将锁计数器设为0，表明锁被释放。如果获取对象锁失败，那当前线程就要阻塞等待，直到锁被另外一个线程释放为止。</p>\n<p><strong>② synchronized 修饰方法的的情况</strong></p>\n<pre><code class=\"java\">public class SynchronizedDemo2 {\n    public synchronized void method() {\n        System.out.println(&quot;synchronized 方法&quot;);\n    }\n}\n</code></pre>\n<p><img src=\"https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/synchronized%E5%85%B3%E9%94%AE%E5%AD%97%E5%8E%9F%E7%90%862.png\" alt=\"synchronized关键字原理\"></p>\n<p>synchronized 修饰的方法并没有 monitorenter 指令和 monitorexit 指令，取得代之的确实是 ACC_SYNCHRONIZED 标识，该标识指明了该方法是一个同步方法，JVM 通过该 ACC_SYNCHRONIZED 访问标志来辨别一个方法是否声明为同步方法，从而执行相应的同步调用。</p>\n<h3 id=\"1-4-说说-JDK1-6-之后的synchronized-关键字底层做了哪些优化，可以详细介绍一下这些优化吗\"><a href=\"#1-4-说说-JDK1-6-之后的synchronized-关键字底层做了哪些优化，可以详细介绍一下这些优化吗\" class=\"headerlink\" title=\"1.4. 说说 JDK1.6 之后的synchronized 关键字底层做了哪些优化，可以详细介绍一下这些优化吗\"></a>1.4. 说说 JDK1.6 之后的synchronized 关键字底层做了哪些优化，可以详细介绍一下这些优化吗</h3><p>JDK1.6 对锁的实现引入了大量的优化，如偏向锁、轻量级锁、自旋锁、适应性自旋锁、锁消除、锁粗化等技术来减少锁操作的开销。</p>\n<p>锁主要存在四种状态，依次是：无锁状态、偏向锁状态、轻量级锁状态、重量级锁状态，他们会随着竞争的激烈而逐渐升级。注意锁可以升级不可降级，这种策略是为了提高获得锁和释放锁的效率。</p>\n<p>关于这几种优化的详细信息可以查看笔主的这篇文章：<a href=\"https://gitee.com/SnailClimb/JavaGuide/blob/master/docs/java/Multithread/synchronized.md\" target=\"_blank\" rel=\"noopener\">https://gitee.com/SnailClimb/JavaGuide/blob/master/docs/java/Multithread/synchronized.md</a></p>\n<h3 id=\"1-5-谈谈-synchronized和ReentrantLock-的区别\"><a href=\"#1-5-谈谈-synchronized和ReentrantLock-的区别\" class=\"headerlink\" title=\"1.5. 谈谈 synchronized和ReentrantLock 的区别\"></a>1.5. 谈谈 synchronized和ReentrantLock 的区别</h3><p><strong>① 两者都是可重入锁</strong></p>\n<p>两者都是可重入锁。“可重入锁”概念是：自己可以再次获取自己的内部锁。比如一个线程获得了某个对象的锁，此时这个对象锁还没有释放，当其再次想要获取这个对象的锁的时候还是可以获取的，如果不可锁重入的话，就会造成死锁。同一个线程每次获取锁，锁的计数器都自增1，所以要等到锁的计数器下降为0时才能释放锁。</p>\n<p><strong>② synchronized 依赖于 JVM 而 ReentrantLock 依赖于 API</strong></p>\n<p>synchronized 是依赖于 JVM 实现的，前面我们也讲到了 虚拟机团队在 JDK1.6 为 synchronized 关键字进行了很多优化，但是这些优化都是在虚拟机层面实现的，并没有直接暴露给我们。ReentrantLock 是 JDK 层面实现的（也就是 API 层面，需要 lock() 和 unlock() 方法配合 try/finally 语句块来完成），所以我们可以通过查看它的源代码，来看它是如何实现的。</p>\n<p><strong>③ ReentrantLock 比 synchronized 增加了一些高级功能</strong></p>\n<p>相比synchronized，ReentrantLock增加了一些高级功能。主要来说主要有三点：<strong>①等待可中断；②可实现公平锁；③可实现选择性通知（锁可以绑定多个条件）</strong></p>\n<ul>\n<li><strong>ReentrantLock提供了一种能够中断等待锁的线程的机制</strong>，通过lock.lockInterruptibly()来实现这个机制。也就是说正在等待的线程可以选择放弃等待，改为处理其他事情。</li>\n<li><strong>ReentrantLock可以指定是公平锁还是非公平锁。而synchronized只能是非公平锁。所谓的公平锁就是先等待的线程先获得锁。</strong> ReentrantLock默认情况是非公平的，可以通过 ReentrantLock类的<code>ReentrantLock(boolean fair)</code>构造方法来制定是否是公平的。</li>\n<li>synchronized关键字与wait()和notify()/notifyAll()方法相结合可以实现等待/通知机制，ReentrantLock类当然也可以实现，但是需要借助于Condition接口与newCondition() 方法。Condition是JDK1.5之后才有的，它具有很好的灵活性，比如可以实现多路通知功能也就是在一个Lock对象中可以创建多个Condition实例（即对象监视器），<strong>线程对象可以注册在指定的Condition中，从而可以有选择性的进行线程通知，在调度线程上更加灵活。 在使用notify()/notifyAll()方法进行通知时，被通知的线程是由 JVM 选择的，用ReentrantLock类结合Condition实例可以实现“选择性通知”</strong> ，这个功能非常重要，而且是Condition接口默认提供的。而synchronized关键字就相当于整个Lock对象中只有一个Condition实例，所有的线程都注册在它一个身上。如果执行notifyAll()方法的话就会通知所有处于等待状态的线程这样会造成很大的效率问题，而Condition实例的signalAll()方法 只会唤醒注册在该Condition实例中的所有等待线程。</li>\n</ul>\n<p>如果你想使用上述功能，那么选择ReentrantLock是一个不错的选择。</p>\n<p><strong>④ 性能已不是选择标准</strong></p>\n<h2 id=\"2-volatile关键字\"><a href=\"#2-volatile关键字\" class=\"headerlink\" title=\"2. volatile关键字\"></a>2. volatile关键字</h2><h3 id=\"2-1-讲一下Java内存模型\"><a href=\"#2-1-讲一下Java内存模型\" class=\"headerlink\" title=\"2.1. 讲一下Java内存模型\"></a>2.1. 讲一下Java内存模型</h3><p>在 JDK1.2 之前，Java的内存模型实现总是从<strong>主存</strong>（即共享内存）读取变量，是不需要进行特别的注意的。而在当前的 Java 内存模型下，线程可以把变量保存<strong>本地内存</strong>（比如机器的寄存器）中，而不是直接在主存中进行读写。这就可能造成一个线程在主存中修改了一个变量的值，而另外一个线程还继续使用它在寄存器中的变量值的拷贝，造成<strong>数据的不一致</strong>。</p>\n<p><img src=\"https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/%E6%95%B0%E6%8D%AE%E4%B8%8D%E4%B8%80%E8%87%B4.png\" alt=\"数据不一致\"></p>\n<p>要解决这个问题，就需要把变量声明为<strong>volatile</strong>，这就指示 JVM，这个变量是不稳定的，每次使用它都到主存中进行读取。</p>\n<p>说白了， <strong>volatile</strong> 关键字的主要作用就是保证变量的可见性然后还有一个作用是防止指令重排序。</p>\n<p><img src=\"https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/volatile%E5%85%B3%E9%94%AE%E5%AD%97%E7%9A%84%E5%8F%AF%E8%A7%81%E6%80%A7.png\" alt=\"volatile关键字的可见性\"></p>\n<h3 id=\"2-2-并发编程的三个重要特性\"><a href=\"#2-2-并发编程的三个重要特性\" class=\"headerlink\" title=\"2.2 并发编程的三个重要特性\"></a>2.2 并发编程的三个重要特性</h3><ol>\n<li><strong>原子性</strong> : 一个的操作或者多次操作，要么所有的操作全部都得到执行并且不会收到任何因素的干扰而中断，要么所有的操作都执行，要么都不执行。<code>synchronized</code> 可以保证代码片段的原子性。</li>\n<li><strong>可见性</strong>  ：当一个变量对共享变量进行了修改，那么另外的线程都是立即可以看到修改后的最新值。<code>volatile</code> 关键字可以保证共享变量的可见性。</li>\n<li><strong>有序性</strong> ：代码在执行的过程中的先后顺序，Java 在编译器以及运行期间的优化，代码的执行顺序未必就是编写代码时候的顺序。<code>volatile</code> 关键字可以禁止指令进行重排序优化。</li>\n</ol>\n<h3 id=\"2-3-说说-synchronized-关键字和-volatile-关键字的区别\"><a href=\"#2-3-说说-synchronized-关键字和-volatile-关键字的区别\" class=\"headerlink\" title=\"2.3. 说说 synchronized 关键字和 volatile 关键字的区别\"></a>2.3. 说说 synchronized 关键字和 volatile 关键字的区别</h3><p><code>synchronized</code> 关键字和 <code>volatile</code> 关键字是两个互补的存在，而不是对立的存在：</p>\n<ul>\n<li><strong>volatile关键字</strong>是线程同步的<strong>轻量级实现</strong>，所以<strong>volatile性能肯定比synchronized关键字要好</strong>。但是<strong>volatile关键字只能用于变量而synchronized关键字可以修饰方法以及代码块</strong>。synchronized关键字在JavaSE1.6之后进行了主要包括为了减少获得锁和释放锁带来的性能消耗而引入的偏向锁和轻量级锁以及其它各种优化之后执行效率有了显著提升，<strong>实际开发中使用 synchronized 关键字的场景还是更多一些</strong>。</li>\n<li><strong>多线程访问volatile关键字不会发生阻塞，而synchronized关键字可能会发生阻塞</strong></li>\n<li><strong>volatile关键字能保证数据的可见性，但不能保证数据的原子性。synchronized关键字两者都能保证。</strong></li>\n<li><strong>volatile关键字主要用于解决变量在多个线程之间的可见性，而 synchronized关键字解决的是多个线程之间访问资源的同步性。</strong></li>\n</ul>\n<h2 id=\"3-ThreadLocal\"><a href=\"#3-ThreadLocal\" class=\"headerlink\" title=\"3. ThreadLocal\"></a>3. ThreadLocal</h2><h3 id=\"3-1-ThreadLocal简介\"><a href=\"#3-1-ThreadLocal简介\" class=\"headerlink\" title=\"3.1. ThreadLocal简介\"></a>3.1. ThreadLocal简介</h3><p>通常情况下，我们创建的变量是可以被任何一个线程访问并修改的。<strong>如果想实现每一个线程都有自己的专属本地变量该如何解决呢？</strong> JDK中提供的<code>ThreadLocal</code>类正是为了解决这样的问题。 <strong><code>ThreadLocal</code>类主要解决的就是让每个线程绑定自己的值，可以将<code>ThreadLocal</code>类形象的比喻成存放数据的盒子，盒子中可以存储每个线程的私有数据。</strong></p>\n<p><strong>如果你创建了一个<code>ThreadLocal</code>变量，那么访问这个变量的每个线程都会有这个变量的本地副本，这也是<code>ThreadLocal</code>变量名的由来。他们可以使用 <code>get（）</code> 和 <code>set（）</code> 方法来获取默认值或将其值更改为当前线程所存的副本的值，从而避免了线程安全问题。</strong></p>\n<p>再举个简单的例子： </p>\n<p>比如有两个人去宝屋收集宝物，这两个共用一个袋子的话肯定会产生争执，但是给他们两个人每个人分配一个袋子的话就不会出现这样的问题。如果把这两个人比作线程的话，那么ThreadLocal就是用来避免这两个线程竞争的。</p>\n<h3 id=\"3-2-ThreadLocal示例\"><a href=\"#3-2-ThreadLocal示例\" class=\"headerlink\" title=\"3.2. ThreadLocal示例\"></a>3.2. ThreadLocal示例</h3><p>相信看了上面的解释，大家已经搞懂 ThreadLocal 类是个什么东西了。</p>\n<pre><code class=\"java\">import java.text.SimpleDateFormat;\nimport java.util.Random;\n\npublic class ThreadLocalExample implements Runnable{\n\n     // SimpleDateFormat 不是线程安全的，所以每个线程都要有自己独立的副本\n    private static final ThreadLocal&lt;SimpleDateFormat&gt; formatter = ThreadLocal.withInitial(() -&gt; new SimpleDateFormat(&quot;yyyyMMdd HHmm&quot;));\n\n    public static void main(String[] args) throws InterruptedException {\n        ThreadLocalExample obj = new ThreadLocalExample();\n        for(int i=0 ; i&lt;10; i++){\n            Thread t = new Thread(obj, &quot;&quot;+i);\n            Thread.sleep(new Random().nextInt(1000));\n            t.start();\n        }\n    }\n\n    @Override\n    public void run() {\n        System.out.println(&quot;Thread Name= &quot;+Thread.currentThread().getName()+&quot; default Formatter = &quot;+formatter.get().toPattern());\n        try {\n            Thread.sleep(new Random().nextInt(1000));\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n        //formatter pattern is changed here by thread, but it won&#39;t reflect to other threads\n        formatter.set(new SimpleDateFormat());\n\n        System.out.println(&quot;Thread Name= &quot;+Thread.currentThread().getName()+&quot; formatter = &quot;+formatter.get().toPattern());\n    }\n\n}\n</code></pre>\n<p>Output:</p>\n<pre><code>Thread Name= 0 default Formatter = yyyyMMdd HHmm\nThread Name= 0 formatter = yy-M-d ah:mm\nThread Name= 1 default Formatter = yyyyMMdd HHmm\nThread Name= 2 default Formatter = yyyyMMdd HHmm\nThread Name= 1 formatter = yy-M-d ah:mm\nThread Name= 3 default Formatter = yyyyMMdd HHmm\nThread Name= 2 formatter = yy-M-d ah:mm\nThread Name= 4 default Formatter = yyyyMMdd HHmm\nThread Name= 3 formatter = yy-M-d ah:mm\nThread Name= 4 formatter = yy-M-d ah:mm\nThread Name= 5 default Formatter = yyyyMMdd HHmm\nThread Name= 5 formatter = yy-M-d ah:mm\nThread Name= 6 default Formatter = yyyyMMdd HHmm\nThread Name= 6 formatter = yy-M-d ah:mm\nThread Name= 7 default Formatter = yyyyMMdd HHmm\nThread Name= 7 formatter = yy-M-d ah:mm\nThread Name= 8 default Formatter = yyyyMMdd HHmm\nThread Name= 9 default Formatter = yyyyMMdd HHmm\nThread Name= 8 formatter = yy-M-d ah:mm\nThread Name= 9 formatter = yy-M-d ah:mm</code></pre><p>从输出中可以看出，Thread-0已经改变了formatter的值，但仍然是thread-2默认格式化程序与初始化值相同，其他线程也一样。</p>\n<p>上面有一段代码用到了创建 <code>ThreadLocal</code> 变量的那段代码用到了 Java8 的知识，它等于下面这段代码，如果你写了下面这段代码的话，IDEA会提示你转换为Java8的格式(IDEA真的不错！)。因为ThreadLocal类在Java 8中扩展，使用一个新的方法<code>withInitial()</code>，将Supplier功能接口作为参数。</p>\n<pre><code class=\"java\"> private static final ThreadLocal&lt;SimpleDateFormat&gt; formatter = new ThreadLocal&lt;SimpleDateFormat&gt;(){\n        @Override\n        protected SimpleDateFormat initialValue()\n        {\n            return new SimpleDateFormat(&quot;yyyyMMdd HHmm&quot;);\n        }\n    };</code></pre>\n<h3 id=\"3-3-ThreadLocal原理\"><a href=\"#3-3-ThreadLocal原理\" class=\"headerlink\" title=\"3.3. ThreadLocal原理\"></a>3.3. ThreadLocal原理</h3><p>从 <code>Thread</code>类源代码入手。</p>\n<pre><code class=\"java\">public class Thread implements Runnable {\n ......\n//与此线程有关的ThreadLocal值。由ThreadLocal类维护\nThreadLocal.ThreadLocalMap threadLocals = null;\n\n//与此线程有关的InheritableThreadLocal值。由InheritableThreadLocal类维护\nThreadLocal.ThreadLocalMap inheritableThreadLocals = null;\n ......\n}</code></pre>\n<p>从上面<code>Thread</code>类 源代码可以看出<code>Thread</code> 类中有一个 <code>threadLocals</code> 和 一个  <code>inheritableThreadLocals</code> 变量，它们都是 <code>ThreadLocalMap</code>  类型的变量,我们可以把 <code>ThreadLocalMap</code>  理解为<code>ThreadLocal</code> 类实现的定制化的 <code>HashMap</code>。默认情况下这两个变量都是null，只有当前线程调用 <code>ThreadLocal</code> 类的 <code>set</code>或<code>get</code>方法时才创建它们，实际上调用这两个方法的时候，我们调用的是<code>ThreadLocalMap</code>类对应的 <code>get()</code>、<code>set()</code>方法。</p>\n<p><code>ThreadLocal</code>类的<code>set()</code>方法</p>\n<pre><code class=\"java\">    public void set(T value) {\n        Thread t = Thread.currentThread();\n        ThreadLocalMap map = getMap(t);\n        if (map != null)\n            map.set(this, value);\n        else\n            createMap(t, value);\n    }\n    ThreadLocalMap getMap(Thread t) {\n        return t.threadLocals;\n    }</code></pre>\n<p>通过上面这些内容，我们足以通过猜测得出结论：<strong>最终的变量是放在了当前线程的 <code>ThreadLocalMap</code> 中，并不是存在 <code>ThreadLocal</code> 上，<code>ThreadLocal</code> 可以理解为只是<code>ThreadLocalMap</code>的封装，传递了变量值。</strong> <code>ThrealLocal</code> 类中可以通过<code>Thread.currentThread()</code>获取到当前线程对象后，直接通过<code>getMap(Thread t)</code>可以访问到该线程的<code>ThreadLocalMap</code>对象。</p>\n<p><strong>每个<code>Thread</code>中都具备一个<code>ThreadLocalMap</code>，而<code>ThreadLocalMap</code>可以存储以<code>ThreadLocal</code>为key ，Object 对象为 value的键值对。</strong> </p>\n<pre><code class=\"java\">ThreadLocalMap(ThreadLocal&lt;?&gt; firstKey, Object firstValue) {\n ......\n}</code></pre>\n<p>比如我们在同一个线程中声明了两个 <code>ThreadLocal</code> 对象的话，会使用 <code>Thread</code>内部都是使用仅有那个<code>ThreadLocalMap</code> 存放数据的，<code>ThreadLocalMap</code>的 key 就是 <code>ThreadLocal</code>对象，value 就是 <code>ThreadLocal</code> 对象调用<code>set</code>方法设置的值。</p>\n<p><img src=\"https://upload-images.jianshu.io/upload_images/7432604-ad2ff581127ba8cc.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/806\" alt=\"ThreadLocal数据结构\"></p>\n<p><code>ThreadLocalMap</code>是<code>ThreadLocal</code>的静态内部类。</p>\n<p><img src=\"https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/ThreadLocal%E5%86%85%E9%83%A8%E7%B1%BB.png\" alt=\"ThreadLocal内部类\"></p>\n<h3 id=\"3-4-ThreadLocal-内存泄露问题\"><a href=\"#3-4-ThreadLocal-内存泄露问题\" class=\"headerlink\" title=\"3.4. ThreadLocal 内存泄露问题\"></a>3.4. ThreadLocal 内存泄露问题</h3><p><code>ThreadLocalMap</code> 中使用的 key 为 <code>ThreadLocal</code> 的弱引用,而 value 是强引用。所以，如果 <code>ThreadLocal</code> 没有被外部强引用的情况下，在垃圾回收的时候，key 会被清理掉，而 value 不会被清理掉。这样一来，<code>ThreadLocalMap</code> 中就会出现key为null的Entry。假如我们不做任何措施的话，value 永远无法被GC 回收，这个时候就可能会产生内存泄露。ThreadLocalMap实现中已经考虑了这种情况，在调用 <code>set()</code>、<code>get()</code>、<code>remove()</code> 方法的时候，会清理掉 key 为 null 的记录。使用完 <code>ThreadLocal</code>方法后 最好手动调用<code>remove()</code>方法</p>\n<pre><code class=\"java\">      static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; {\n            /** The value associated with this ThreadLocal. */\n            Object value;\n\n            Entry(ThreadLocal&lt;?&gt; k, Object v) {\n                super(k);\n                value = v;\n            }\n        }</code></pre>\n<p><strong>弱引用介绍：</strong></p>\n<blockquote>\n<p>如果一个对象只具有弱引用，那就类似于<strong>可有可无的生活用品</strong>。弱引用与软引用的区别在于：只具有弱引用的对象拥有更短暂的生命周期。在垃圾回收器线程扫描它 所管辖的内存区域的过程中，一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。不过，由于垃圾回收器是一个优先级很低的线程， 因此不一定会很快发现那些只具有弱引用的对象。</p>\n<p>弱引用可以和一个引用队列（ReferenceQueue）联合使用，如果弱引用所引用的对象被垃圾回收，Java虚拟机就会把这个弱引用加入到与之关联的引用队列中。</p>\n</blockquote>\n<h2 id=\"4-线程池\"><a href=\"#4-线程池\" class=\"headerlink\" title=\"4. 线程池\"></a>4. 线程池</h2><h3 id=\"4-1-为什么要用线程池？\"><a href=\"#4-1-为什么要用线程池？\" class=\"headerlink\" title=\"4.1. 为什么要用线程池？\"></a>4.1. 为什么要用线程池？</h3><blockquote>\n<p><strong>池化技术相比大家已经屡见不鲜了，线程池、数据库连接池、Http 连接池等等都是对这个思想的应用。池化技术的思想主要是为了减少每次获取资源的消耗，提高对资源的利用率。</strong></p>\n</blockquote>\n<p><strong>线程池</strong>提供了一种限制和管理资源（包括执行一个任务）。 每个<strong>线程池</strong>还维护一些基本统计信息，例如已完成任务的数量。</p>\n<p>这里借用《Java 并发编程的艺术》提到的来说一下<strong>使用线程池的好处</strong>：</p>\n<ul>\n<li><strong>降低资源消耗</strong>。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。</li>\n<li><strong>提高响应速度</strong>。当任务到达时，任务可以不需要的等到线程创建就能立即执行。</li>\n<li><strong>提高线程的可管理性</strong>。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。</li>\n</ul>\n<h3 id=\"4-2-实现Runnable接口和Callable接口的区别\"><a href=\"#4-2-实现Runnable接口和Callable接口的区别\" class=\"headerlink\" title=\"4.2. 实现Runnable接口和Callable接口的区别\"></a>4.2. 实现Runnable接口和Callable接口的区别</h3><p><code>Runnable</code>自Java 1.0以来一直存在，但<code>Callable</code>仅在Java 1.5中引入,目的就是为了来处理<code>Runnable</code>不支持的用例。<strong><code>Runnable</code> 接口</strong>不会返回结果或抛出检查异常，但是<strong><code>Callable</code> 接口</strong>可以。所以，如果任务不需要返回结果或抛出异常推荐使用 <strong><code>Runnable</code> 接口</strong>，这样代码看起来会更加简洁。</p>\n<p>工具类 <code>Executors</code> 可以实现 <code>Runnable</code> 对象和 <code>Callable</code> 对象之间的相互转换。（<code>Executors.callable（Runnable task</code>）或 <code>Executors.callable（Runnable task，Object resule）</code>）。</p>\n<p><code>Runnable.java</code></p>\n<pre><code class=\"java\">@FunctionalInterface\npublic interface Runnable {\n   /**\n    * 被线程执行，没有返回值也无法抛出异常\n    */\n    public abstract void run();\n}</code></pre>\n<p><code>Callable.java</code></p>\n<pre><code class=\"java\">@FunctionalInterface\npublic interface Callable&lt;V&gt; {\n    /**\n     * 计算结果，或在无法这样做时抛出异常。\n     * @return 计算得出的结果\n     * @throws 如果无法计算结果，则抛出异常\n     */\n    V call() throws Exception;\n}</code></pre>\n<h3 id=\"4-3-执行execute-方法和submit-方法的区别是什么呢？\"><a href=\"#4-3-执行execute-方法和submit-方法的区别是什么呢？\" class=\"headerlink\" title=\"4.3. 执行execute()方法和submit()方法的区别是什么呢？\"></a>4.3. 执行execute()方法和submit()方法的区别是什么呢？</h3><ol>\n<li><strong><code>execute()</code>方法用于提交不需要返回值的任务，所以无法判断任务是否被线程池执行成功与否；</strong></li>\n<li><strong><code>submit()</code>方法用于提交需要返回值的任务。线程池会返回一个 <code>Future</code> 类型的对象，通过这个 <code>Future</code> 对象可以判断任务是否执行成功</strong>，并且可以通过 <code>Future</code> 的 <code>get()</code>方法来获取返回值，<code>get()</code>方法会阻塞当前线程直到任务完成，而使用 <code>get（long timeout，TimeUnit unit）</code>方法则会阻塞当前线程一段时间后立即返回，这时候有可能任务没有执行完。</li>\n</ol>\n<p>我们以<strong><code>AbstractExecutorService</code></strong>接口中的一个 <code>submit</code> 方法为例子来看看源代码：</p>\n<pre><code class=\"java\">    public Future&lt;?&gt; submit(Runnable task) {\n        if (task == null) throw new NullPointerException();\n        RunnableFuture&lt;Void&gt; ftask = newTaskFor(task, null);\n        execute(ftask);\n        return ftask;\n    }</code></pre>\n<p>上面方法调用的 <code>newTaskFor</code> 方法返回了一个 <code>FutureTask</code> 对象。</p>\n<pre><code class=\"java\">    protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Runnable runnable, T value) {\n        return new FutureTask&lt;T&gt;(runnable, value);\n    }</code></pre>\n<p>我们再来看看<code>execute()</code>方法：</p>\n<pre><code class=\"java\">    public void execute(Runnable command) {\n      ...\n    }</code></pre>\n<h3 id=\"4-4-如何创建线程池\"><a href=\"#4-4-如何创建线程池\" class=\"headerlink\" title=\"4.4. 如何创建线程池\"></a>4.4. 如何创建线程池</h3><p>《阿里巴巴Java开发手册》中强制线程池不允许使用 Executors 去创建，而是通过 ThreadPoolExecutor 的方式，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险</p>\n<blockquote>\n<p>Executors 返回线程池对象的弊端如下：</p>\n<ul>\n<li><strong>FixedThreadPool 和 SingleThreadExecutor</strong> ： 允许请求的队列长度为 Integer.MAX_VALUE ，可能堆积大量的请求，从而导致OOM。</li>\n<li><strong>CachedThreadPool 和 ScheduledThreadPool</strong> ： 允许创建的线程数量为 Integer.MAX_VALUE ，可能会创建大量线程，从而导致OOM。</li>\n</ul>\n</blockquote>\n<p><strong>方式一：通过构造方法实现</strong><br><img src=\"https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/ThreadPoolExecutor%E6%9E%84%E9%80%A0%E6%96%B9%E6%B3%95.png\" alt=\"ThreadPoolExecutor构造方法\"><br><strong>方式二：通过Executor 框架的工具类Executors来实现</strong><br>我们可以创建三种类型的ThreadPoolExecutor：</p>\n<ul>\n<li><strong>FixedThreadPool</strong> ： 该方法返回一个固定线程数量的线程池。该线程池中的线程数量始终不变。当有一个新的任务提交时，线程池中若有空闲线程，则立即执行。若没有，则新的任务会被暂存在一个任务队列中，待有线程空闲时，便处理在任务队列中的任务。</li>\n<li><strong>SingleThreadExecutor：</strong> 方法返回一个只有一个线程的线程池。若多余一个任务被提交到该线程池，任务会被保存在一个任务队列中，待线程空闲，按先入先出的顺序执行队列中的任务。</li>\n<li><strong>CachedThreadPool：</strong> 该方法返回一个可根据实际情况调整线程数量的线程池。线程池的线程数量不确定，但若有空闲线程可以复用，则会优先使用可复用的线程。若所有线程均在工作，又有新的任务提交，则会创建新的线程处理任务。所有线程在当前任务执行完毕后，将返回线程池进行复用。</li>\n</ul>\n<p>对应Executors工具类中的方法如图所示：<br><img src=\"https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/Executor%E6%A1%86%E6%9E%B6%E7%9A%84%E5%B7%A5%E5%85%B7%E7%B1%BB.png\" alt=\"Executor框架的工具类\"></p>\n<h3 id=\"4-5-ThreadPoolExecutor-类分析\"><a href=\"#4-5-ThreadPoolExecutor-类分析\" class=\"headerlink\" title=\"4.5 ThreadPoolExecutor 类分析\"></a>4.5 ThreadPoolExecutor 类分析</h3><p><code>ThreadPoolExecutor</code> 类中提供的四个构造方法。我们来看最长的那个，其余三个都是在这个构造方法的基础上产生（其他几个构造方法说白点都是给定某些默认参数的构造方法比如默认制定拒绝策略是什么），这里就不贴代码讲了，比较简单。</p>\n<pre><code class=\"java\">    /**\n     * 用给定的初始参数创建一个新的ThreadPoolExecutor。\n     */\n    public ThreadPoolExecutor(int corePoolSize,\n                              int maximumPoolSize,\n                              long keepAliveTime,\n                              TimeUnit unit,\n                              BlockingQueue&lt;Runnable&gt; workQueue,\n                              ThreadFactory threadFactory,\n                              RejectedExecutionHandler handler) {\n        if (corePoolSize &lt; 0 ||\n            maximumPoolSize &lt;= 0 ||\n            maximumPoolSize &lt; corePoolSize ||\n            keepAliveTime &lt; 0)\n            throw new IllegalArgumentException();\n        if (workQueue == null || threadFactory == null || handler == null)\n            throw new NullPointerException();\n        this.corePoolSize = corePoolSize;\n        this.maximumPoolSize = maximumPoolSize;\n        this.workQueue = workQueue;\n        this.keepAliveTime = unit.toNanos(keepAliveTime);\n        this.threadFactory = threadFactory;\n        this.handler = handler;\n    }</code></pre>\n<p><strong>下面这些对创建 非常重要，在后面使用线程池的过程中你一定会用到！所以，务必拿着小本本记清楚。</strong></p>\n<h4 id=\"4-5-1-ThreadPoolExecutor构造函数重要参数分析\"><a href=\"#4-5-1-ThreadPoolExecutor构造函数重要参数分析\" class=\"headerlink\" title=\"4.5.1 ThreadPoolExecutor构造函数重要参数分析\"></a>4.5.1 <code>ThreadPoolExecutor</code>构造函数重要参数分析</h4><p><strong><code>ThreadPoolExecutor</code> 3 个最重要的参数：</strong></p>\n<ul>\n<li><strong><code>corePoolSize</code> :</strong> 核心线程数线程数定义了最小可以同时运行的线程数量。</li>\n<li><strong><code>maximumPoolSize</code> :</strong> 当队列中存放的任务达到队列容量的时候，当前可以同时运行的线程数量变为最大线程数。</li>\n<li><strong><code>workQueue</code>:</strong> 当新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到的话，新任务就会被存放在队列中。</li>\n</ul>\n<p><code>ThreadPoolExecutor</code>其他常见参数:</p>\n<ol>\n<li><strong><code>keepAliveTime</code></strong>:当线程池中的线程数量大于 <code>corePoolSize</code> 的时候，如果这时没有新的任务提交，核心线程外的线程不会立即销毁，而是会等待，直到等待的时间超过了 <code>keepAliveTime</code>才会被回收销毁；</li>\n<li><strong><code>unit</code></strong> : <code>keepAliveTime</code> 参数的时间单位。</li>\n<li><strong><code>threadFactory</code></strong> :executor 创建新线程的时候会用到。</li>\n<li><strong><code>handler</code></strong> :饱和策略。关于饱和策略下面单独介绍一下。</li>\n</ol>\n<h4 id=\"4-5-2-ThreadPoolExecutor-饱和策略\"><a href=\"#4-5-2-ThreadPoolExecutor-饱和策略\" class=\"headerlink\" title=\"4.5.2 ThreadPoolExecutor 饱和策略\"></a>4.5.2 <code>ThreadPoolExecutor</code> 饱和策略</h4><p><strong><code>ThreadPoolExecutor</code> 饱和策略定义:</strong></p>\n<p>如果当前同时运行的线程数量达到最大线程数量并且队列也已经被放满了任时，<code>ThreadPoolTaskExecutor</code> 定义一些策略:</p>\n<ul>\n<li><strong><code>ThreadPoolExecutor.AbortPolicy</code></strong>：抛出 <code>RejectedExecutionException</code>来拒绝新任务的处理。</li>\n<li><strong><code>ThreadPoolExecutor.CallerRunsPolicy</code></strong>：调用执行自己的线程运行任务。您不会任务请求。但是这种策略会降低对于新任务提交速度，影响程序的整体性能。另外，这个策略喜欢增加队列容量。如果您的应用程序可以承受此延迟并且你不能任务丢弃任何一个任务请求的话，你可以选择这个策略。</li>\n<li><strong><code>ThreadPoolExecutor.DiscardPolicy</code>：</strong> 不处理新任务，直接丢弃掉。</li>\n<li><strong><code>ThreadPoolExecutor.DiscardOldestPolicy</code>：</strong> 此策略将丢弃最早的未处理的任务请求。</li>\n</ul>\n<p>举个例子： Spring 通过 <code>ThreadPoolTaskExecutor</code> 或者我们直接通过 <code>ThreadPoolExecutor</code> 的构造函数创建线程池的时候，当我们不指定 <code>RejectedExecutionHandler</code> 饱和策略的话来配置线程池的时候默认使用的是 <code>ThreadPoolExecutor.AbortPolicy</code>。在默认情况下，<code>ThreadPoolExecutor</code> 将抛出 <code>RejectedExecutionException</code> 来拒绝新来的任务 ，这代表你将丢失对这个任务的处理。 对于可伸缩的应用程序，建议使用 <code>ThreadPoolExecutor.CallerRunsPolicy</code>。当最大池被填满时，此策略为我们提供可伸缩队列。（这个直接查看 <code>ThreadPoolExecutor</code> 的构造函数源码就可以看出，比较简单的原因，这里就不贴代码了）</p>\n<h3 id=\"4-6-一个简单的线程池Demo-Runnable-ThreadPoolExecutor\"><a href=\"#4-6-一个简单的线程池Demo-Runnable-ThreadPoolExecutor\" class=\"headerlink\" title=\"4.6 一个简单的线程池Demo:Runnable+ThreadPoolExecutor\"></a>4.6 一个简单的线程池Demo:<code>Runnable</code>+<code>ThreadPoolExecutor</code></h3><p>为了让大家更清楚上面的面试题中的一些概念，我写了一个简单的线程池 Demo。</p>\n<p>首先创建一个 <code>Runnable</code> 接口的实现类（当然也可以是 <code>Callable</code> 接口，我们上面也说了两者的区别。）</p>\n<p><code>MyRunnable.java</code></p>\n<pre><code class=\"java\">import java.util.Date;\n\n/**\n * 这是一个简单的Runnable类，需要大约5秒钟来执行其任务。\n * @author shuang.kou\n */\npublic class MyRunnable implements Runnable {\n\n    private String command;\n\n    public MyRunnable(String s) {\n        this.command = s;\n    }\n\n    @Override\n    public void run() {\n        System.out.println(Thread.currentThread().getName() + &quot; Start. Time = &quot; + new Date());\n        processCommand();\n        System.out.println(Thread.currentThread().getName() + &quot; End. Time = &quot; + new Date());\n    }\n\n    private void processCommand() {\n        try {\n            Thread.sleep(5000);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n    }\n\n    @Override\n    public String toString() {\n        return this.command;\n    }\n}\n</code></pre>\n<p>编写测试程序，我们这里以阿里巴巴推荐的使用 <code>ThreadPoolExecutor</code> 构造函数自定义参数的方式来创建线程池。</p>\n<p><code>ThreadPoolExecutorDemo.java</code></p>\n<pre><code class=\"java\">import java.util.concurrent.ArrayBlockingQueue;\nimport java.util.concurrent.ThreadPoolExecutor;\nimport java.util.concurrent.TimeUnit;\n\npublic class ThreadPoolExecutorDemo {\n\n    private static final int CORE_POOL_SIZE = 5;\n    private static final int MAX_POOL_SIZE = 10;\n    private static final int QUEUE_CAPACITY = 100;\n    private static final Long KEEP_ALIVE_TIME = 1L;\n    public static void main(String[] args) {\n\n        //使用阿里巴巴推荐的创建线程池的方式\n        //通过ThreadPoolExecutor构造函数自定义参数创建\n        ThreadPoolExecutor executor = new ThreadPoolExecutor(\n                CORE_POOL_SIZE,\n                MAX_POOL_SIZE,\n                KEEP_ALIVE_TIME,\n                TimeUnit.SECONDS,\n                new ArrayBlockingQueue&lt;&gt;(QUEUE_CAPACITY),\n                new ThreadPoolExecutor.CallerRunsPolicy());\n\n        for (int i = 0; i &lt; 10; i++) {\n            //创建WorkerThread对象（WorkerThread类实现了Runnable 接口）\n            Runnable worker = new MyRunnable(&quot;&quot; + i);\n            //执行Runnable\n            executor.execute(worker);\n        }\n        //终止线程池\n        executor.shutdown();\n        while (!executor.isTerminated()) {\n        }\n        System.out.println(&quot;Finished all threads&quot;);\n    }\n}\n</code></pre>\n<p>可以看到我们上面的代码指定了：</p>\n<ol>\n<li><code>corePoolSize</code>: 核心线程数为 5。</li>\n<li><code>maximumPoolSize</code> ：最大线程数 10</li>\n<li><code>keepAliveTime</code> : 等待时间为 1L。</li>\n<li><code>unit</code>: 等待时间的单位为 TimeUnit.SECONDS。</li>\n<li><code>workQueue</code>：任务队列为 <code>ArrayBlockingQueue</code>，并且容量为 100;</li>\n<li><code>handler</code>:饱和策略为 <code>CallerRunsPolicy</code>。</li>\n</ol>\n<p><strong>Output：</strong></p>\n<pre><code>pool-1-thread-2 Start. Time = Tue Nov 12 20:59:44 CST 2019\npool-1-thread-5 Start. Time = Tue Nov 12 20:59:44 CST 2019\npool-1-thread-4 Start. Time = Tue Nov 12 20:59:44 CST 2019\npool-1-thread-1 Start. Time = Tue Nov 12 20:59:44 CST 2019\npool-1-thread-3 Start. Time = Tue Nov 12 20:59:44 CST 2019\npool-1-thread-5 End. Time = Tue Nov 12 20:59:49 CST 2019\npool-1-thread-3 End. Time = Tue Nov 12 20:59:49 CST 2019\npool-1-thread-2 End. Time = Tue Nov 12 20:59:49 CST 2019\npool-1-thread-4 End. Time = Tue Nov 12 20:59:49 CST 2019\npool-1-thread-1 End. Time = Tue Nov 12 20:59:49 CST 2019\npool-1-thread-2 Start. Time = Tue Nov 12 20:59:49 CST 2019\npool-1-thread-1 Start. Time = Tue Nov 12 20:59:49 CST 2019\npool-1-thread-4 Start. Time = Tue Nov 12 20:59:49 CST 2019\npool-1-thread-3 Start. Time = Tue Nov 12 20:59:49 CST 2019\npool-1-thread-5 Start. Time = Tue Nov 12 20:59:49 CST 2019\npool-1-thread-2 End. Time = Tue Nov 12 20:59:54 CST 2019\npool-1-thread-3 End. Time = Tue Nov 12 20:59:54 CST 2019\npool-1-thread-4 End. Time = Tue Nov 12 20:59:54 CST 2019\npool-1-thread-5 End. Time = Tue Nov 12 20:59:54 CST 2019\npool-1-thread-1 End. Time = Tue Nov 12 20:59:54 CST 2019\n</code></pre><h3 id=\"4-7-线程池原理分析\"><a href=\"#4-7-线程池原理分析\" class=\"headerlink\" title=\"4.7 线程池原理分析\"></a>4.7 线程池原理分析</h3><p>承接 4.6 节，我们通过代码输出结果可以看出：<strong>线程池每次会同时执行 5 个任务，这 5 个任务执行完之后，剩余的 5 个任务才会被执行。</strong> 大家可以先通过上面讲解的内容，分析一下到底是咋回事？（自己独立思考一会）</p>\n<p>现在，我们就分析上面的输出内容来简单分析一下线程池原理。</p>\n<p><strong>为了搞懂线程池的原理，我们需要首先分析一下 <code>execute</code>方法。</strong>在 4.6 节中的 Demo 中我们使用 <code>executor.execute(worker)</code>来提交一个任务到线程池中去，这个方法非常重要，下面我们来看看它的源码：</p>\n<pre><code class=\"java\">   // 存放线程池的运行状态 (runState) 和线程池内有效线程的数量 (workerCount)\n   private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));\n\n    private static int workerCountOf(int c) {\n        return c &amp; CAPACITY;\n    }\n\n    private final BlockingQueue&lt;Runnable&gt; workQueue;\n\n    public void execute(Runnable command) {\n        // 如果任务为null，则抛出异常。\n        if (command == null)\n            throw new NullPointerException();\n        // ctl 中保存的线程池当前的一些状态信息\n        int c = ctl.get();\n\n        //  下面会涉及到 3 步 操作\n        // 1.首先判断当前线程池中之行的任务数量是否小于 corePoolSize\n        // 如果小于的话，通过addWorker(command, true)新建一个线程，并将任务(command)添加到该线程中；然后，启动该线程从而执行任务。\n        if (workerCountOf(c) &lt; corePoolSize) {\n            if (addWorker(command, true))\n                return;\n            c = ctl.get();\n        }\n        // 2.如果当前之行的任务数量大于等于 corePoolSize 的时候就会走到这里\n        // 通过 isRunning 方法判断线程池状态，线程池处于 RUNNING 状态才会被并且队列可以加入任务，该任务才会被加入进去\n        if (isRunning(c) &amp;&amp; workQueue.offer(command)) {\n            int recheck = ctl.get();\n            // 再次获取线程池状态，如果线程池状态不是 RUNNING 状态就需要从任务队列中移除任务，并尝试判断线程是否全部执行完毕。同时执行拒绝策略。\n            if (!isRunning(recheck) &amp;&amp; remove(command))\n                reject(command);\n                // 如果当前线程池为空就新创建一个线程并执行。\n            else if (workerCountOf(recheck) == 0)\n                addWorker(null, false);\n        }\n        //3. 通过addWorker(command, false)新建一个线程，并将任务(command)添加到该线程中；然后，启动该线程从而执行任务。\n        //如果addWorker(command, false)执行失败，则通过reject()执行相应的拒绝策略的内容。\n        else if (!addWorker(command, false))\n            reject(command);\n    }</code></pre>\n<p>通过下图可以更好的对上面这 3 步做一个展示，下图是我为了省事直接从网上找到，原地址不明。</p>\n<p><img src=\"https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-7/%E5%9B%BE%E8%A7%A3%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86.png\" alt=\"图解线程池实现原理\"></p>\n<p>现在，让我们在回到 4.6 节我们写的 Demo， 现在应该是不是很容易就可以搞懂它的原理了呢？</p>\n<p>没搞懂的话，也没关系，可以看看我的分析：</p>\n<blockquote>\n<p>我们在代码中模拟了 10 个任务，我们配置的核心线程数为 5 、等待队列容量为 100 ，所以每次只可能存在 5 个任务同时执行，剩下的 5 个任务会被放到等待队列中去。当前的 5 个任务之行完成后，才会之行剩下的 5 个任务。</p>\n</blockquote>\n<h2 id=\"5-Atomic-原子类\"><a href=\"#5-Atomic-原子类\" class=\"headerlink\" title=\"5. Atomic 原子类\"></a>5. Atomic 原子类</h2><h3 id=\"5-1-介绍一下Atomic-原子类\"><a href=\"#5-1-介绍一下Atomic-原子类\" class=\"headerlink\" title=\"5.1. 介绍一下Atomic 原子类\"></a>5.1. 介绍一下Atomic 原子类</h3><p>Atomic 翻译成中文是原子的意思。在化学上，我们知道原子是构成一般物质的最小单位，在化学反应中是不可分割的。在我们这里 Atomic 是指一个操作是不可中断的。即使是在多个线程一起执行的时候，一个操作一旦开始，就不会被其他线程干扰。</p>\n<p>所以，所谓原子类说简单点就是具有原子/原子操作特征的类。</p>\n<p>并发包 <code>java.util.concurrent</code> 的原子类都存放在<code>java.util.concurrent.atomic</code>下,如下图所示。</p>\n<p><img src=\"https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/JUC%E5%8E%9F%E5%AD%90%E7%B1%BB%E6%A6%82%E8%A7%88.png\" alt=\"JUC原子类概览\"></p>\n<h3 id=\"5-2-JUC-包中的原子类是哪4类\"><a href=\"#5-2-JUC-包中的原子类是哪4类\" class=\"headerlink\" title=\"5.2. JUC 包中的原子类是哪4类?\"></a>5.2. JUC 包中的原子类是哪4类?</h3><p><strong>基本类型</strong> </p>\n<p>使用原子的方式更新基本类型</p>\n<ul>\n<li>AtomicInteger：整形原子类</li>\n<li>AtomicLong：长整型原子类</li>\n<li>AtomicBoolean：布尔型原子类</li>\n</ul>\n<p><strong>数组类型</strong></p>\n<p>使用原子的方式更新数组里的某个元素</p>\n<ul>\n<li>AtomicIntegerArray：整形数组原子类</li>\n<li>AtomicLongArray：长整形数组原子类</li>\n<li>AtomicReferenceArray：引用类型数组原子类</li>\n</ul>\n<p><strong>引用类型</strong></p>\n<ul>\n<li>AtomicReference：引用类型原子类</li>\n<li>AtomicStampedReference：原子更新引用类型里的字段原子类</li>\n<li>AtomicMarkableReference ：原子更新带有标记位的引用类型</li>\n</ul>\n<p><strong>对象的属性修改类型</strong></p>\n<ul>\n<li>AtomicIntegerFieldUpdater：原子更新整形字段的更新器</li>\n<li>AtomicLongFieldUpdater：原子更新长整形字段的更新器</li>\n<li>AtomicStampedReference：原子更新带有版本号的引用类型。该类将整数值与引用关联起来，可用于解决原子的更新数据和数据的版本号，可以解决使用 CAS 进行原子更新时可能出现的 ABA 问题。</li>\n</ul>\n<h3 id=\"5-3-讲讲-AtomicInteger-的使用\"><a href=\"#5-3-讲讲-AtomicInteger-的使用\" class=\"headerlink\" title=\"5.3. 讲讲 AtomicInteger 的使用\"></a>5.3. 讲讲 AtomicInteger 的使用</h3><p> <strong>AtomicInteger 类常用方法</strong></p>\n<pre><code class=\"java\">public final int get() //获取当前的值\npublic final int getAndSet(int newValue)//获取当前的值，并设置新的值\npublic final int getAndIncrement()//获取当前的值，并自增\npublic final int getAndDecrement() //获取当前的值，并自减\npublic final int getAndAdd(int delta) //获取当前的值，并加上预期的值\nboolean compareAndSet(int expect, int update) //如果输入的数值等于预期值，则以原子方式将该值设置为输入值（update）\npublic final void lazySet(int newValue)//最终设置为newValue,使用 lazySet 设置之后可能导致其他线程在之后的一小段时间内还是可以读到旧的值。</code></pre>\n<p> <strong>AtomicInteger 类的使用示例</strong></p>\n<p>使用 AtomicInteger 之后，不用对 increment() 方法加锁也可以保证线程安全。</p>\n<pre><code class=\"java\">class AtomicIntegerTest {\n        private AtomicInteger count = new AtomicInteger();\n      //使用AtomicInteger之后，不需要对该方法加锁，也可以实现线程安全。\n        public void increment() {\n                  count.incrementAndGet();\n        }\n\n       public int getCount() {\n                return count.get();\n        }\n}\n</code></pre>\n<h3 id=\"5-4-能不能给我简单介绍一下-AtomicInteger-类的原理\"><a href=\"#5-4-能不能给我简单介绍一下-AtomicInteger-类的原理\" class=\"headerlink\" title=\"5.4. 能不能给我简单介绍一下 AtomicInteger 类的原理\"></a>5.4. 能不能给我简单介绍一下 AtomicInteger 类的原理</h3><p>AtomicInteger 线程安全原理简单分析</p>\n<p>AtomicInteger 类的部分源码：</p>\n<pre><code class=\"java\">    // setup to use Unsafe.compareAndSwapInt for updates（更新操作时提供“比较并替换”的作用）\n    private static final Unsafe unsafe = Unsafe.getUnsafe();\n    private static final long valueOffset;\n\n    static {\n        try {\n            valueOffset = unsafe.objectFieldOffset\n                (AtomicInteger.class.getDeclaredField(&quot;value&quot;));\n        } catch (Exception ex) { throw new Error(ex); }\n    }\n\n    private volatile int value;</code></pre>\n<p>AtomicInteger 类主要利用 CAS (compare and swap) + volatile 和 native 方法来保证原子操作，从而避免 synchronized 的高开销，执行效率大为提升。</p>\n<p>CAS的原理是拿期望的值和原本的一个值作比较，如果相同则更新成新的值。UnSafe 类的 objectFieldOffset() 方法是一个本地方法，这个方法是用来拿到“原来的值”的内存地址，返回值是 valueOffset。另外 value 是一个volatile变量，在内存中可见，因此 JVM 可以保证任何时刻任何线程总能拿到该变量的最新值。</p>\n<p>关于 Atomic 原子类这部分更多内容可以查看我的这篇文章：并发编程面试必备：<a href=\"https://mp.weixin.qq.com/s/joa-yOiTrYF67bElj8xqvg\" target=\"_blank\" rel=\"noopener\">JUC 中的 Atomic 原子类总结</a></p>\n<h2 id=\"6-AQS\"><a href=\"#6-AQS\" class=\"headerlink\" title=\"6. AQS\"></a>6. AQS</h2><h3 id=\"6-1-AQS-介绍\"><a href=\"#6-1-AQS-介绍\" class=\"headerlink\" title=\"6.1. AQS 介绍\"></a>6.1. AQS 介绍</h3><p>AQS的全称为（AbstractQueuedSynchronizer），这个类在java.util.concurrent.locks包下面。</p>\n<p><img src=\"https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/AQS%E7%B1%BB.png\" alt=\"AQS类\"></p>\n<p>AQS是一个用来构建锁和同步器的框架，使用AQS能简单且高效地构造出应用广泛的大量的同步器，比如我们提到的ReentrantLock，Semaphore，其他的诸如ReentrantReadWriteLock，SynchronousQueue，FutureTask等等皆是基于AQS的。当然，我们自己也能利用AQS非常轻松容易地构造出符合我们自己需求的同步器。</p>\n<h3 id=\"6-2-AQS-原理分析\"><a href=\"#6-2-AQS-原理分析\" class=\"headerlink\" title=\"6.2. AQS 原理分析\"></a>6.2. AQS 原理分析</h3><p>AQS 原理这部分参考了部分博客，在5.2节末尾放了链接。</p>\n<blockquote>\n<p>在面试中被问到并发知识的时候，大多都会被问到“请你说一下自己对于AQS原理的理解”。下面给大家一个示例供大家参加，面试不是背题，大家一定要加入自己的思想，即使加入不了自己的思想也要保证自己能够通俗的讲出来而不是背出来。</p>\n</blockquote>\n<p>下面大部分内容其实在AQS类注释上已经给出了，不过是英语看着比较吃力一点，感兴趣的话可以看看源码。</p>\n<h4 id=\"6-2-1-AQS-原理概览\"><a href=\"#6-2-1-AQS-原理概览\" class=\"headerlink\" title=\"6.2.1. AQS 原理概览\"></a>6.2.1. AQS 原理概览</h4><p><strong>AQS核心思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制AQS是用CLH队列锁实现的，即将暂时获取不到锁的线程加入到队列中。</strong></p>\n<blockquote>\n<p>CLH(Craig,Landin,and Hagersten)队列是一个虚拟的双向队列（虚拟的双向队列即不存在队列实例，仅存在结点之间的关联关系）。AQS是将每条请求共享资源的线程封装成一个CLH锁队列的一个结点（Node）来实现锁的分配。</p>\n</blockquote>\n<p>看个AQS(AbstractQueuedSynchronizer)原理图：</p>\n<p><img src=\"https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/AQS%E5%8E%9F%E7%90%86%E5%9B%BE.png\" alt=\"AQS原理图\"></p>\n<p>AQS使用一个int成员变量来表示同步状态，通过内置的FIFO队列来完成获取资源线程的排队工作。AQS使用CAS对该同步状态进行原子操作实现对其值的修改。</p>\n<pre><code class=\"java\">private volatile int state;//共享变量，使用volatile修饰保证线程可见性</code></pre>\n<p>状态信息通过protected类型的getState，setState，compareAndSetState进行操作</p>\n<pre><code class=\"java\">\n//返回同步状态的当前值\nprotected final int getState() {  \n        return state;\n}\n // 设置同步状态的值\nprotected final void setState(int newState) { \n        state = newState;\n}\n//原子地（CAS操作）将同步状态值设置为给定值update如果当前同步状态的值等于expect（期望值）\nprotected final boolean compareAndSetState(int expect, int update) {\n        return unsafe.compareAndSwapInt(this, stateOffset, expect, update);\n}</code></pre>\n<h4 id=\"6-2-2-AQS-对资源的共享方式\"><a href=\"#6-2-2-AQS-对资源的共享方式\" class=\"headerlink\" title=\"6.2.2. AQS 对资源的共享方式\"></a>6.2.2. AQS 对资源的共享方式</h4><p><strong>AQS定义两种资源共享方式</strong></p>\n<ul>\n<li><strong>Exclusive</strong>（独占）：只有一个线程能执行，如ReentrantLock。又可分为公平锁和非公平锁：<ul>\n<li>公平锁：按照线程在队列中的排队顺序，先到者先拿到锁</li>\n<li>非公平锁：当线程要获取锁时，无视队列顺序直接去抢锁，谁抢到就是谁的</li>\n</ul>\n</li>\n<li><strong>Share</strong>（共享）：多个线程可同时执行，如Semaphore/CountDownLatch。Semaphore、CountDownLatch、 CyclicBarrier、ReadWriteLock 我们都会在后面讲到。</li>\n</ul>\n<p>ReentrantReadWriteLock 可以看成是组合式，因为ReentrantReadWriteLock也就是读写锁允许多个线程同时对某一资源进行读。</p>\n<p>不同的自定义同步器争用共享资源的方式也不同。自定义同步器在实现时只需要实现共享资源 state 的获取与释放方式即可，至于具体线程等待队列的维护（如获取资源失败入队/唤醒出队等），AQS已经在顶层实现好了。</p>\n<h4 id=\"6-2-3-AQS底层使用了模板方法模式\"><a href=\"#6-2-3-AQS底层使用了模板方法模式\" class=\"headerlink\" title=\"6.2.3. AQS底层使用了模板方法模式\"></a>6.2.3. AQS底层使用了模板方法模式</h4><p>同步器的设计是基于模板方法模式的，如果需要自定义同步器一般的方式是这样（模板方法模式很经典的一个应用）：</p>\n<ol>\n<li>使用者继承AbstractQueuedSynchronizer并重写指定的方法。（这些重写方法很简单，无非是对于共享资源state的获取和释放）</li>\n<li>将AQS组合在自定义同步组件的实现中，并调用其模板方法，而这些模板方法会调用使用者重写的方法。</li>\n</ol>\n<p>这和我们以往通过实现接口的方式有很大区别，这是模板方法模式很经典的一个运用。</p>\n<p><strong>AQS使用了模板方法模式，自定义同步器时需要重写下面几个AQS提供的模板方法：</strong></p>\n<pre><code class=\"java\">isHeldExclusively()//该线程是否正在独占资源。只有用到condition才需要去实现它。\ntryAcquire(int)//独占方式。尝试获取资源，成功则返回true，失败则返回false。\ntryRelease(int)//独占方式。尝试释放资源，成功则返回true，失败则返回false。\ntryAcquireShared(int)//共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。\ntryReleaseShared(int)//共享方式。尝试释放资源，成功则返回true，失败则返回false。\n</code></pre>\n<p>默认情况下，每个方法都抛出 <code>UnsupportedOperationException</code>。 这些方法的实现必须是内部线程安全的，并且通常应该简短而不是阻塞。AQS类中的其他方法都是final ，所以无法被其他类使用，只有这几个方法可以被其他类使用。 </p>\n<p>以ReentrantLock为例，state初始化为0，表示未锁定状态。A线程lock()时，会调用tryAcquire()独占该锁并将state+1。此后，其他线程再tryAcquire()时就会失败，直到A线程unlock()到state=0（即释放锁）为止，其它线程才有机会获取该锁。当然，释放锁之前，A线程自己是可以重复获取此锁的（state会累加），这就是可重入的概念。但要注意，获取多少次就要释放多么次，这样才能保证state是能回到零态的。</p>\n<p>再以CountDownLatch以例，任务分为N个子线程去执行，state也初始化为N（注意N要与线程个数一致）。这N个子线程是并行执行的，每个子线程执行完后countDown()一次，state会CAS(Compare and Swap)减1。等到所有子线程都执行完后(即state=0)，会unpark()主调用线程，然后主调用线程就会从await()函数返回，继续后余动作。</p>\n<p>一般来说，自定义同步器要么是独占方法，要么是共享方式，他们也只需实现<code>tryAcquire-tryRelease</code>、<code>tryAcquireShared-tryReleaseShared</code>中的一种即可。但AQS也支持自定义同步器同时实现独占和共享两种方式，如<code>ReentrantReadWriteLock</code>。</p>\n<p>推荐两篇 AQS 原理和相关源码分析的文章：</p>\n<ul>\n<li><a href=\"http://www.cnblogs.com/waterystone/p/4920797.html\" target=\"_blank\" rel=\"noopener\">http://www.cnblogs.com/waterystone/p/4920797.html</a></li>\n<li><a href=\"https://www.cnblogs.com/chengxiao/archive/2017/07/24/7141160.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/chengxiao/archive/2017/07/24/7141160.html</a></li>\n</ul>\n<h3 id=\"6-3-AQS-组件总结\"><a href=\"#6-3-AQS-组件总结\" class=\"headerlink\" title=\"6.3. AQS 组件总结\"></a>6.3. AQS 组件总结</h3><ul>\n<li><strong>Semaphore(信号量)-允许多个线程同时访问：</strong> synchronized 和 ReentrantLock 都是一次只允许一个线程访问某个资源，Semaphore(信号量)可以指定多个线程同时访问某个资源。</li>\n<li><strong>CountDownLatch （倒计时器）：</strong> CountDownLatch是一个同步工具类，用来协调多个线程之间的同步。这个工具通常用来控制线程等待，它可以让某一个线程等待直到倒计时结束，再开始执行。</li>\n<li><strong>CyclicBarrier(循环栅栏)：</strong> CyclicBarrier 和 CountDownLatch 非常类似，它也可以实现线程间的技术等待，但是它的功能比 CountDownLatch 更加复杂和强大。主要应用场景和 CountDownLatch 类似。CyclicBarrier 的字面意思是可循环使用（Cyclic）的屏障（Barrier）。它要做的事情是，让一组线程到达一个屏障（也可以叫同步点）时被阻塞，直到最后一个线程到达屏障时，屏障才会开门，所有被屏障拦截的线程才会继续干活。CyclicBarrier默认的构造方法是 CyclicBarrier(int parties)，其参数表示屏障拦截的线程数量，每个线程调用await()方法告诉 CyclicBarrier 我已经到达了屏障，然后当前线程被阻塞。</li>\n</ul>\n<h2 id=\"7-Reference\"><a href=\"#7-Reference\" class=\"headerlink\" title=\"7 Reference\"></a>7 Reference</h2><ul>\n<li>《深入理解 Java 虚拟机》</li>\n<li>《实战 Java 高并发程序设计》</li>\n<li>《Java并发编程的艺术》</li>\n<li><a href=\"http://www.cnblogs.com/waterystone/p/4920797.html\" target=\"_blank\" rel=\"noopener\">http://www.cnblogs.com/waterystone/p/4920797.html</a></li>\n<li><a href=\"https://www.cnblogs.com/chengxiao/archive/2017/07/24/7141160.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/chengxiao/archive/2017/07/24/7141160.html</a></li>\n<li><a href=\"https://www.journaldev.com/1076/java-threadlocal-example\" target=\"_blank\" rel=\"noopener\">https://www.journaldev.com/1076/java-threadlocal-example</a></li>\n</ul>\n","site":{"data":{}},"more":"<p>以下文字摘自<a href=\"https://github.com/Snailclimb/JavaGuide\" target=\"_blank\" rel=\"noopener\">JavaGuide</a></p>\n<!-- TOC -->\n\n<ul>\n<li><a href=\"#java-并发基础常见面试题总结\">Java 并发基础常见面试题总结</a><ul>\n<li><a href=\"#1-什么是线程和进程\">1. 什么是线程和进程?</a><ul>\n<li><a href=\"#11-何为进程\">1.1. 何为进程?</a></li>\n<li><a href=\"#12-何为线程\">1.2. 何为线程?</a></li>\n</ul>\n</li>\n<li><a href=\"#2-请简要描述线程与进程的关系区别及优缺点\">2. 请简要描述线程与进程的关系,区别及优缺点？</a><ul>\n<li><a href=\"#21-图解进程和线程的关系\">2.1. 图解进程和线程的关系</a></li>\n<li><a href=\"#22-程序计数器为什么是私有的\">2.2. 程序计数器为什么是私有的?</a></li>\n<li><a href=\"#23-虚拟机栈和本地方法栈为什么是私有的\">2.3. 虚拟机栈和本地方法栈为什么是私有的?</a></li>\n<li><a href=\"#24-一句话简单了解堆和方法区\">2.4. 一句话简单了解堆和方法区</a></li>\n</ul>\n</li>\n<li><a href=\"#3-说说并发与并行的区别\">3. 说说并发与并行的区别?</a></li>\n<li><a href=\"#4-为什么要使用多线程呢\">4. 为什么要使用多线程呢?</a></li>\n<li><a href=\"#5-使用多线程可能带来什么问题\">5. 使用多线程可能带来什么问题?</a></li>\n<li><a href=\"#6-说说线程的生命周期和状态\">6. 说说线程的生命周期和状态?</a></li>\n<li><a href=\"#7-什么是上下文切换\">7. 什么是上下文切换?</a></li>\n<li><a href=\"#8-什么是线程死锁如何避免死锁\">8. 什么是线程死锁?如何避免死锁?</a><ul>\n<li><a href=\"#81-认识线程死锁\">8.1. 认识线程死锁</a></li>\n<li><a href=\"#82-如何避免线程死锁\">8.2. 如何避免线程死锁?</a></li>\n</ul>\n</li>\n<li><a href=\"#9-说说-sleep-方法和-wait-方法区别和共同点\">9. 说说 sleep() 方法和 wait() 方法区别和共同点?</a></li>\n<li><a href=\"#10-为什么我们调用-start-方法时会执行-run-方法为什么我们不能直接调用-run-方法\">10. 为什么我们调用 start() 方法时会执行 run() 方法，为什么我们不能直接调用 run() 方法？</a></li>\n</ul>\n</li>\n</ul>\n<!-- /TOC -->\n\n<h1 id=\"Java-并发基础常见面试题总结\"><a href=\"#Java-并发基础常见面试题总结\" class=\"headerlink\" title=\"Java 并发基础常见面试题总结\"></a>Java 并发基础常见面试题总结</h1><h2 id=\"1-什么是线程和进程\"><a href=\"#1-什么是线程和进程\" class=\"headerlink\" title=\"1. 什么是线程和进程?\"></a>1. 什么是线程和进程?</h2><h3 id=\"1-1-何为进程\"><a href=\"#1-1-何为进程\" class=\"headerlink\" title=\"1.1. 何为进程?\"></a>1.1. 何为进程?</h3><p>进程是程序的一次执行过程，是系统运行程序的基本单位，因此进程是动态的。系统运行一个程序即是一个进程从创建，运行到消亡的过程。</p>\n<p>在 Java 中，当我们启动 main 函数时其实就是启动了一个 JVM 的进程，而 main 函数所在的线程就是这个进程中的一个线程，也称主线程。</p>\n<p>如下图所示，在 windows 中通过查看任务管理器的方式，我们就可以清楚看到 window 当前运行的进程（.exe 文件的运行）。</p>\n<p><img src=\"https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/%E8%BF%9B%E7%A8%8B%E7%A4%BA%E4%BE%8B%E5%9B%BE%E7%89%87-Windows.png\" alt=\"进程示例图片-Windows\"></p>\n<h3 id=\"1-2-何为线程\"><a href=\"#1-2-何为线程\" class=\"headerlink\" title=\"1.2. 何为线程?\"></a>1.2. 何为线程?</h3><p>线程与进程相似，但线程是一个比进程更小的执行单位。一个进程在其执行的过程中可以产生多个线程。与进程不同的是同类的多个线程共享进程的<strong>堆</strong>和<strong>方法区</strong>资源，但每个线程有自己的<strong>程序计数器</strong>、<strong>虚拟机栈</strong>和<strong>本地方法栈</strong>，所以系统在产生一个线程，或是在各个线程之间作切换工作时，负担要比进程小得多，也正因为如此，线程也被称为轻量级进程。</p>\n<p>Java 程序天生就是多线程程序，我们可以通过 JMX 来看一下一个普通的 Java 程序有哪些线程，代码如下。</p>\n<pre><code class=\"java\">public class MultiThread {\n    public static void main(String[] args) {\n        // 获取 Java 线程管理 MXBean\n    ThreadMXBean threadMXBean = ManagementFactory.getThreadMXBean();\n        // 不需要获取同步的 monitor 和 synchronizer 信息，仅获取线程和线程堆栈信息\n        ThreadInfo[] threadInfos = threadMXBean.dumpAllThreads(false, false);\n        // 遍历线程信息，仅打印线程 ID 和线程名称信息\n        for (ThreadInfo threadInfo : threadInfos) {\n            System.out.println(&quot;[&quot; + threadInfo.getThreadId() + &quot;] &quot; + threadInfo.getThreadName());\n        }\n    }\n}</code></pre>\n<p>上述程序输出如下（输出内容可能不同，不用太纠结下面每个线程的作用，只用知道 main 线程执行 main 方法即可）：</p>\n<pre><code>[5] Attach Listener //添加事件\n[4] Signal Dispatcher // 分发处理给 JVM 信号的线程\n[3] Finalizer //调用对象 finalize 方法的线程\n[2] Reference Handler //清除 reference 线程\n[1] main //main 线程,程序入口</code></pre><p>从上面的输出内容可以看出：<strong>一个 Java 程序的运行是 main 线程和多个其他线程同时运行</strong>。</p>\n<h2 id=\"2-请简要描述线程与进程的关系-区别及优缺点？\"><a href=\"#2-请简要描述线程与进程的关系-区别及优缺点？\" class=\"headerlink\" title=\"2. 请简要描述线程与进程的关系,区别及优缺点？\"></a>2. 请简要描述线程与进程的关系,区别及优缺点？</h2><p><strong>从 JVM 角度说进程和线程之间的关系</strong></p>\n<h3 id=\"2-1-图解进程和线程的关系\"><a href=\"#2-1-图解进程和线程的关系\" class=\"headerlink\" title=\"2.1. 图解进程和线程的关系\"></a>2.1. 图解进程和线程的关系</h3><p>下图是 Java 内存区域，通过下图我们从 JVM 的角度来说一下线程和进程之间的关系。如果你对 Java 内存区域 (运行时数据区) 这部分知识不太了解的话可以阅读一下这篇文章：<a href=\"https://github.com/Snailclimb/JavaGuide/blob/3965c02cc0f294b0bd3580df4868d5e396959e2e/Java%E7%9B%B8%E5%85%B3/%E5%8F%AF%E8%83%BD%E6%98%AF%E6%8A%8AJava%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F%E8%AE%B2%E7%9A%84%E6%9C%80%E6%B8%85%E6%A5%9A%E7%9A%84%E4%B8%80%E7%AF%87%E6%96%87%E7%AB%A0.md\" title=\"《可能是把 Java 内存区域讲的最清楚的一篇文章》\" target=\"_blank\" rel=\"noopener\">《可能是把 Java 内存区域讲的最清楚的一篇文章》</a></p>\n<div align=\"center\">  \n<img src=\"https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-3/JVM运行时数据区域.png\" width=\"600px\">\n</div>\n\n<p>从上图可以看出：一个进程中可以有多个线程，多个线程共享进程的<strong>堆</strong>和<strong>方法区 (JDK1.8 之后的元空间)</strong>资源，但是每个线程有自己的<strong>程序计数器</strong>、<strong>虚拟机栈</strong> 和 <strong>本地方法栈</strong>。</p>\n<p><strong>总结：</strong> 线程 是 进程 划分成的更小的运行单位。线程和进程最大的不同在于基本上各进程是独立的，而各线程则不一定，因为同一进程中的线程极有可能会相互影响。线程执行开销小，但不利于资源的管理和保护；而进程正相反</p>\n<p>下面是该知识点的扩展内容！</p>\n<p>下面来思考这样一个问题：为什么<strong>程序计数器</strong>、<strong>虚拟机栈</strong>和<strong>本地方法栈</strong>是线程私有的呢？为什么堆和方法区是线程共享的呢？</p>\n<h3 id=\"2-2-程序计数器为什么是私有的\"><a href=\"#2-2-程序计数器为什么是私有的\" class=\"headerlink\" title=\"2.2. 程序计数器为什么是私有的?\"></a>2.2. 程序计数器为什么是私有的?</h3><p>程序计数器主要有下面两个作用：</p>\n<ol>\n<li>字节码解释器通过改变程序计数器来依次读取指令，从而实现代码的流程控制，如：顺序执行、选择、循环、异常处理。</li>\n<li>在多线程的情况下，程序计数器用于记录当前线程执行的位置，从而当线程被切换回来的时候能够知道该线程上次运行到哪儿了。</li>\n</ol>\n<p>需要注意的是，如果执行的是 native 方法，那么程序计数器记录的是 undefined 地址，只有执行的是 Java 代码时程序计数器记录的才是下一条指令的地址。</p>\n<p>所以，程序计数器私有主要是为了<strong>线程切换后能恢复到正确的执行位置</strong>。</p>\n<h3 id=\"2-3-虚拟机栈和本地方法栈为什么是私有的\"><a href=\"#2-3-虚拟机栈和本地方法栈为什么是私有的\" class=\"headerlink\" title=\"2.3. 虚拟机栈和本地方法栈为什么是私有的?\"></a>2.3. 虚拟机栈和本地方法栈为什么是私有的?</h3><ul>\n<li><strong>虚拟机栈：</strong> 每个 Java 方法在执行的同时会创建一个栈帧用于存储局部变量表、操作数栈、常量池引用等信息。从方法调用直至执行完成的过程，就对应着一个栈帧在 Java 虚拟机栈中入栈和出栈的过程。</li>\n<li><strong>本地方法栈：</strong> 和虚拟机栈所发挥的作用非常相似，区别是： <strong>虚拟机栈为虚拟机执行 Java 方法 （也就是字节码）服务，而本地方法栈则为虚拟机使用到的 Native 方法服务。</strong> 在 HotSpot 虚拟机中和 Java 虚拟机栈合二为一。</li>\n</ul>\n<p>所以，为了<strong>保证线程中的局部变量不被别的线程访问到</strong>，虚拟机栈和本地方法栈是线程私有的。</p>\n<h3 id=\"2-4-一句话简单了解堆和方法区\"><a href=\"#2-4-一句话简单了解堆和方法区\" class=\"headerlink\" title=\"2.4. 一句话简单了解堆和方法区\"></a>2.4. 一句话简单了解堆和方法区</h3><p>堆和方法区是所有线程共享的资源，其中堆是进程中最大的一块内存，主要用于存放新创建的对象 (所有对象都在这里分配内存)，方法区主要用于存放已被加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。</p>\n<h2 id=\"3-说说并发与并行的区别\"><a href=\"#3-说说并发与并行的区别\" class=\"headerlink\" title=\"3. 说说并发与并行的区别?\"></a>3. 说说并发与并行的区别?</h2><ul>\n<li><strong>并发：</strong> 同一时间段，多个任务都在执行 (单位时间内不一定同时执行)；</li>\n<li><strong>并行：</strong> 单位时间内，多个任务同时执行。</li>\n</ul>\n<h2 id=\"4-为什么要使用多线程呢\"><a href=\"#4-为什么要使用多线程呢\" class=\"headerlink\" title=\"4. 为什么要使用多线程呢?\"></a>4. 为什么要使用多线程呢?</h2><p>先从总体上来说：</p>\n<ul>\n<li><strong>从计算机底层来说：</strong> 线程可以比作是轻量级的进程，是程序执行的最小单位,线程间的切换和调度的成本远远小于进程。另外，多核 CPU 时代意味着多个线程可以同时运行，这减少了线程上下文切换的开销。</li>\n<li><strong>从当代互联网发展趋势来说：</strong> 现在的系统动不动就要求百万级甚至千万级的并发量，而多线程并发编程正是开发高并发系统的基础，利用好多线程机制可以大大提高系统整体的并发能力以及性能。</li>\n</ul>\n<p>再深入到计算机底层来探讨：</p>\n<ul>\n<li><strong>单核时代：</strong> 在单核时代多线程主要是为了提高 CPU 和 IO 设备的综合利用率。举个例子：当只有一个线程的时候会导致 CPU 计算时，IO 设备空闲；进行 IO 操作时，CPU 空闲。我们可以简单地说这两者的利用率目前都是 50%左右。但是当有两个线程的时候就不一样了，当一个线程执行 CPU 计算时，另外一个线程可以进行 IO 操作，这样两个的利用率就可以在理想情况下达到 100%了。</li>\n<li><strong>多核时代:</strong> 多核时代多线程主要是为了提高 CPU 利用率。举个例子：假如我们要计算一个复杂的任务，我们只用一个线程的话，CPU 只会一个 CPU 核心被利用到，而创建多个线程就可以让多个 CPU 核心被利用到，这样就提高了 CPU 的利用率。</li>\n</ul>\n<h2 id=\"5-使用多线程可能带来什么问题\"><a href=\"#5-使用多线程可能带来什么问题\" class=\"headerlink\" title=\"5. 使用多线程可能带来什么问题?\"></a>5. 使用多线程可能带来什么问题?</h2><p>并发编程的目的就是为了能提高程序的执行效率提高程序运行速度，但是并发编程并不总是能提高程序运行速度的，而且并发编程可能会遇到很多问题，比如：内存泄漏、死锁、线程不安全等等。</p>\n<h2 id=\"6-说说线程的生命周期和状态\"><a href=\"#6-说说线程的生命周期和状态\" class=\"headerlink\" title=\"6. 说说线程的生命周期和状态?\"></a>6. 说说线程的生命周期和状态?</h2><p>Java 线程在运行的生命周期中的指定时刻只可能处于下面 6 种不同状态的其中一个状态（图源《Java 并发编程艺术》4.1.4 节）。</p>\n<p><img src=\"https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/19-1-29/Java%E7%BA%BF%E7%A8%8B%E7%9A%84%E7%8A%B6%E6%80%81.png\" alt=\"Java 线程的状态 \"></p>\n<p>线程在生命周期中并不是固定处于某一个状态而是随着代码的执行在不同状态之间切换。Java 线程状态变迁如下图所示（图源《Java 并发编程艺术》4.1.4 节）：</p>\n<p><img src=\"https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/19-1-29/Java+%E7%BA%BF%E7%A8%8B%E7%8A%B6%E6%80%81%E5%8F%98%E8%BF%81.png\" alt=\"Java 线程状态变迁 \"></p>\n<p>由上图可以看出：线程创建之后它将处于 <strong>NEW（新建）</strong> 状态，调用 <code>start()</code> 方法后开始运行，线程这时候处于 <strong>READY（可运行）</strong> 状态。可运行状态的线程获得了 CPU 时间片（timeslice）后就处于 <strong>RUNNING（运行）</strong> 状态。</p>\n<blockquote>\n<p>操作系统隐藏 Java 虚拟机（JVM）中的 RUNNABLE 和 RUNNING 状态，它只能看到 RUNNABLE 状态（图源：<a href=\"https://howtodoinjava.com/\" title=\"HowToDoInJava\" target=\"_blank\" rel=\"noopener\">HowToDoInJava</a>：<a href=\"https://howtodoinjava.com/java/multi-threading/java-thread-life-cycle-and-thread-states/\" title=\"Java Thread Life Cycle and Thread States\" target=\"_blank\" rel=\"noopener\">Java Thread Life Cycle and Thread States</a>），所以 Java 系统一般将这两个状态统称为 <strong>RUNNABLE（运行中）</strong> 状态 。</p>\n</blockquote>\n<p><img src=\"https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-3/RUNNABLE-VS-RUNNING.png\" alt=\"RUNNABLE-VS-RUNNING\"></p>\n<p>当线程执行 <code>wait()</code>方法之后，线程进入 <strong>WAITING（等待）</strong> 状态。进入等待状态的线程需要依靠其他线程的通知才能够返回到运行状态，而 <strong>TIME_WAITING(超时等待)</strong> 状态相当于在等待状态的基础上增加了超时限制，比如通过 <code>sleep（long millis）</code>方法或 <code>wait（long millis）</code>方法可以将 Java 线程置于 TIMED WAITING 状态。当超时时间到达后 Java 线程将会返回到 RUNNABLE 状态。当线程调用同步方法时，在没有获取到锁的情况下，线程将会进入到 <strong>BLOCKED（阻塞）</strong> 状态。线程在执行 Runnable 的<code>run()</code>方法之后将会进入到 <strong>TERMINATED（终止）</strong> 状态。</p>\n<h2 id=\"7-什么是上下文切换\"><a href=\"#7-什么是上下文切换\" class=\"headerlink\" title=\"7. 什么是上下文切换?\"></a>7. 什么是上下文切换?</h2><p>多线程编程中一般线程的个数都大于 CPU 核心的个数，而一个 CPU 核心在任意时刻只能被一个线程使用，为了让这些线程都能得到有效执行，CPU 采取的策略是为每个线程分配时间片并轮转的形式。当一个线程的时间片用完的时候就会重新处于就绪状态让给其他线程使用，这个过程就属于一次上下文切换。</p>\n<p>概括来说就是：当前任务在执行完 CPU 时间片切换到另一个任务之前会先保存自己的状态，以便下次再切换回这个任务时，可以再加载这个任务的状态。<strong>任务从保存到再加载的过程就是一次上下文切换</strong>。</p>\n<p>上下文切换通常是计算密集型的。也就是说，它需要相当可观的处理器时间，在每秒几十上百次的切换中，每次切换都需要纳秒量级的时间。所以，上下文切换对系统来说意味着消耗大量的 CPU 时间，事实上，可能是操作系统中时间消耗最大的操作。</p>\n<p>Linux 相比与其他操作系统（包括其他类 Unix 系统）有很多的优点，其中有一项就是，其上下文切换和模式切换的时间消耗非常少。</p>\n<h2 id=\"8-什么是线程死锁-如何避免死锁\"><a href=\"#8-什么是线程死锁-如何避免死锁\" class=\"headerlink\" title=\"8. 什么是线程死锁?如何避免死锁?\"></a>8. 什么是线程死锁?如何避免死锁?</h2><h3 id=\"8-1-认识线程死锁\"><a href=\"#8-1-认识线程死锁\" class=\"headerlink\" title=\"8.1. 认识线程死锁\"></a>8.1. 认识线程死锁</h3><p>线程死锁描述的是这样一种情况：多个线程同时被阻塞，它们中的一个或者全部都在等待某个资源被释放。由于线程被无限期地阻塞，因此程序不可能正常终止。</p>\n<p>如下图所示，线程 A 持有资源 2，线程 B 持有资源 1，他们同时都想申请对方的资源，所以这两个线程就会互相等待而进入死锁状态。</p>\n<p><img src=\"https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-4/2019-4%E6%AD%BB%E9%94%811.png\" alt=\"线程死锁示意图 \"></p>\n<p>下面通过一个例子来说明线程死锁,代码模拟了上图的死锁的情况 (代码来源于《并发编程之美》)：</p>\n<pre><code class=\"java\">public class DeadLockDemo {\n    private static Object resource1 = new Object();//资源 1\n    private static Object resource2 = new Object();//资源 2\n\n    public static void main(String[] args) {\n        new Thread(() -&gt; {\n            synchronized (resource1) {\n                System.out.println(Thread.currentThread() + &quot;get resource1&quot;);\n                try {\n                    Thread.sleep(1000);\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n                System.out.println(Thread.currentThread() + &quot;waiting get resource2&quot;);\n                synchronized (resource2) {\n                    System.out.println(Thread.currentThread() + &quot;get resource2&quot;);\n                }\n            }\n        }, &quot;线程 1&quot;).start();\n\n        new Thread(() -&gt; {\n            synchronized (resource2) {\n                System.out.println(Thread.currentThread() + &quot;get resource2&quot;);\n                try {\n                    Thread.sleep(1000);\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n                System.out.println(Thread.currentThread() + &quot;waiting get resource1&quot;);\n                synchronized (resource1) {\n                    System.out.println(Thread.currentThread() + &quot;get resource1&quot;);\n                }\n            }\n        }, &quot;线程 2&quot;).start();\n    }\n}</code></pre>\n<p>Output</p>\n<pre><code>Thread[线程 1,5,main]get resource1\nThread[线程 2,5,main]get resource2\nThread[线程 1,5,main]waiting get resource2\nThread[线程 2,5,main]waiting get resource1</code></pre><p>线程 A 通过 synchronized (resource1) 获得 resource1 的监视器锁，然后通过<code>Thread.sleep(1000);</code>让线程 A 休眠 1s 为的是让线程 B 得到执行然后获取到 resource2 的监视器锁。线程 A 和线程 B 休眠结束了都开始企图请求获取对方的资源，然后这两个线程就会陷入互相等待的状态，这也就产生了死锁。上面的例子符合产生死锁的四个必要条件。</p>\n<p>学过操作系统的朋友都知道产生死锁必须具备以下四个条件：</p>\n<ol>\n<li>互斥条件：该资源任意一个时刻只由一个线程占用。</li>\n<li>请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。</li>\n<li>不剥夺条件:线程已获得的资源在末使用完之前不能被其他线程强行剥夺，只有自己使用完毕后才释放资源。</li>\n<li>循环等待条件:若干进程之间形成一种头尾相接的循环等待资源关系。</li>\n</ol>\n<h3 id=\"8-2-如何避免线程死锁\"><a href=\"#8-2-如何避免线程死锁\" class=\"headerlink\" title=\"8.2. 如何避免线程死锁?\"></a>8.2. 如何避免线程死锁?</h3><p>我上面说了产生死锁的四个必要条件，为了避免死锁，我们只要破坏产生死锁的四个条件中的其中一个就可以了。现在我们来挨个分析一下：</p>\n<ol>\n<li><strong>破坏互斥条件</strong> ：这个条件我们没有办法破坏，因为我们用锁本来就是想让他们互斥的（临界资源需要互斥访问）。</li>\n<li><strong>破坏请求与保持条件</strong>  ：一次性申请所有的资源。</li>\n<li><strong>破坏不剥夺条件</strong> ：占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源。</li>\n<li><strong>破坏循环等待条件</strong> ：靠按序申请资源来预防。按某一顺序申请资源，释放资源则反序释放。破坏循环等待条件。</li>\n</ol>\n<p>我们对线程 2 的代码修改成下面这样就不会产生死锁了。</p>\n<pre><code class=\"java\">        new Thread(() -&gt; {\n            synchronized (resource1) {\n                System.out.println(Thread.currentThread() + &quot;get resource1&quot;);\n                try {\n                    Thread.sleep(1000);\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n                System.out.println(Thread.currentThread() + &quot;waiting get resource2&quot;);\n                synchronized (resource2) {\n                    System.out.println(Thread.currentThread() + &quot;get resource2&quot;);\n                }\n            }\n        }, &quot;线程 2&quot;).start();</code></pre>\n<p>Output</p>\n<pre><code>Thread[线程 1,5,main]get resource1\nThread[线程 1,5,main]waiting get resource2\nThread[线程 1,5,main]get resource2\nThread[线程 2,5,main]get resource1\nThread[线程 2,5,main]waiting get resource2\nThread[线程 2,5,main]get resource2\n\nProcess finished with exit code 0</code></pre><p>我们分析一下上面的代码为什么避免了死锁的发生?</p>\n<p>线程 1 首先获得到 resource1 的监视器锁,这时候线程 2 就获取不到了。然后线程 1 再去获取 resource2 的监视器锁，可以获取到。然后线程 1 释放了对 resource1、resource2 的监视器锁的占用，线程 2 获取到就可以执行了。这样就破坏了破坏循环等待条件，因此避免了死锁。</p>\n<h2 id=\"9-说说-sleep-方法和-wait-方法区别和共同点\"><a href=\"#9-说说-sleep-方法和-wait-方法区别和共同点\" class=\"headerlink\" title=\"9. 说说 sleep() 方法和 wait() 方法区别和共同点?\"></a>9. 说说 sleep() 方法和 wait() 方法区别和共同点?</h2><ul>\n<li>两者最主要的区别在于：<strong>sleep 方法没有释放锁，而 wait 方法释放了锁</strong> 。</li>\n<li>两者都可以暂停线程的执行。</li>\n<li>Wait 通常被用于线程间交互/通信，sleep 通常被用于暂停执行。</li>\n<li>wait() 方法被调用后，线程不会自动苏醒，需要别的线程调用同一个对象上的 notify() 或者 notifyAll() 方法。sleep() 方法执行完成后，线程会自动苏醒。或者可以使用 wait(long timeout)超时后线程会自动苏醒。</li>\n</ul>\n<h2 id=\"10-为什么我们调用-start-方法时会执行-run-方法，为什么我们不能直接调用-run-方法？\"><a href=\"#10-为什么我们调用-start-方法时会执行-run-方法，为什么我们不能直接调用-run-方法？\" class=\"headerlink\" title=\"10. 为什么我们调用 start() 方法时会执行 run() 方法，为什么我们不能直接调用 run() 方法？\"></a>10. 为什么我们调用 start() 方法时会执行 run() 方法，为什么我们不能直接调用 run() 方法？</h2><p>这是另一个非常经典的 java 多线程面试问题，而且在面试中会经常被问到。很简单，但是很多人都会答不上来！</p>\n<p>new 一个 Thread，线程进入了新建状态;调用 start() 方法，会启动一个线程并使线程进入了就绪状态，当分配到时间片后就可以开始运行了。 start() 会执行线程的相应准备工作，然后自动执行 run() 方法的内容，这是真正的多线程工作。 而直接执行 run() 方法，会把 run 方法当成一个 main 线程下的普通方法去执行，并不会在某个线程中执行它，所以这并不是多线程工作。</p>\n<p><strong>总结： 调用 start 方法方可启动线程并使线程进入就绪状态，而 run 方法只是 thread 的一个普通方法调用，还是在主线程里执行。</strong></p>\n<!-- TOC -->\n\n<ul>\n<li><a href=\"#java-并发进阶常见面试题总结\">Java 并发进阶常见面试题总结</a><ul>\n<li><a href=\"#1-synchronized-关键字\">1. synchronized 关键字</a><ul>\n<li><a href=\"#11-说一说自己对于-synchronized-关键字的了解\">1.1. 说一说自己对于 synchronized 关键字的了解</a></li>\n<li><a href=\"#12-说说自己是怎么使用-synchronized-关键字在项目中用到了吗\">1.2. 说说自己是怎么使用 synchronized 关键字，在项目中用到了吗</a></li>\n<li><a href=\"#13-讲一下-synchronized-关键字的底层原理\">1.3. 讲一下 synchronized 关键字的底层原理</a></li>\n<li><a href=\"#14-说说-jdk16-之后的synchronized-关键字底层做了哪些优化可以详细介绍一下这些优化吗\">1.4. 说说 JDK1.6 之后的synchronized 关键字底层做了哪些优化，可以详细介绍一下这些优化吗</a></li>\n<li><a href=\"#15-谈谈-synchronized和reentrantlock-的区别\">1.5. 谈谈 synchronized和ReentrantLock 的区别</a></li>\n</ul>\n</li>\n<li><a href=\"#2-volatile关键字\">2. volatile关键字</a><ul>\n<li><a href=\"#21-讲一下java内存模型\">2.1. 讲一下Java内存模型</a></li>\n<li><a href=\"#22-说说-synchronized-关键字和-volatile-关键字的区别\">2.2. 说说 synchronized 关键字和 volatile 关键字的区别</a></li>\n</ul>\n</li>\n<li><a href=\"#3-threadlocal\">3. ThreadLocal</a><ul>\n<li><a href=\"#31-threadlocal简介\">3.1. ThreadLocal简介</a></li>\n<li><a href=\"#32-threadlocal示例\">3.2. ThreadLocal示例</a></li>\n<li><a href=\"#33-threadlocal原理\">3.3. ThreadLocal原理</a></li>\n<li><a href=\"#34-threadlocal-内存泄露问题\">3.4. ThreadLocal 内存泄露问题</a></li>\n</ul>\n</li>\n<li><a href=\"#4-线程池\">4. 线程池</a><ul>\n<li><a href=\"#41-为什么要用线程池\">4.1. 为什么要用线程池？</a></li>\n<li><a href=\"#42-实现runnable接口和callable接口的区别\">4.2. 实现Runnable接口和Callable接口的区别</a></li>\n<li><a href=\"#43-执行execute方法和submit方法的区别是什么呢\">4.3. 执行execute()方法和submit()方法的区别是什么呢？</a></li>\n<li><a href=\"#44-如何创建线程池\">4.4. 如何创建线程池</a></li>\n</ul>\n</li>\n<li><a href=\"#5-atomic-原子类\">5. Atomic 原子类</a><ul>\n<li><a href=\"#51-介绍一下atomic-原子类\">5.1. 介绍一下Atomic 原子类</a></li>\n<li><a href=\"#52-juc-包中的原子类是哪4类\">5.2. JUC 包中的原子类是哪4类?</a></li>\n<li><a href=\"#53-讲讲-atomicinteger-的使用\">5.3. 讲讲 AtomicInteger 的使用</a></li>\n<li><a href=\"#54-能不能给我简单介绍一下-atomicinteger-类的原理\">5.4. 能不能给我简单介绍一下 AtomicInteger 类的原理</a></li>\n</ul>\n</li>\n<li><a href=\"#6-aqs\">6. AQS</a><ul>\n<li><a href=\"#61-aqs-介绍\">6.1. AQS 介绍</a></li>\n<li><a href=\"#62-aqs-原理分析\">6.2. AQS 原理分析</a><ul>\n<li><a href=\"#621-aqs-原理概览\">6.2.1. AQS 原理概览</a></li>\n<li><a href=\"#622-aqs-对资源的共享方式\">6.2.2. AQS 对资源的共享方式</a></li>\n<li><a href=\"#623-aqs底层使用了模板方法模式\">6.2.3. AQS底层使用了模板方法模式</a></li>\n</ul>\n</li>\n<li><a href=\"#63-aqs-组件总结\">6.3. AQS 组件总结</a></li>\n</ul>\n</li>\n<li><a href=\"#7-reference\">7 Reference</a></li>\n</ul>\n</li>\n</ul>\n<!-- /TOC -->\n\n<h1 id=\"Java-并发进阶常见面试题总结\"><a href=\"#Java-并发进阶常见面试题总结\" class=\"headerlink\" title=\"Java 并发进阶常见面试题总结\"></a>Java 并发进阶常见面试题总结</h1><h2 id=\"1-synchronized-关键字\"><a href=\"#1-synchronized-关键字\" class=\"headerlink\" title=\"1. synchronized 关键字\"></a>1. synchronized 关键字</h2><h3 id=\"1-1-说一说自己对于-synchronized-关键字的了解\"><a href=\"#1-1-说一说自己对于-synchronized-关键字的了解\" class=\"headerlink\" title=\"1.1. 说一说自己对于 synchronized 关键字的了解\"></a>1.1. 说一说自己对于 synchronized 关键字的了解</h3><p>synchronized关键字解决的是多个线程之间访问资源的同步性，synchronized关键字可以保证被它修饰的方法或者代码块在任意时刻只能有一个线程执行。</p>\n<p>另外，在 Java 早期版本中，synchronized属于重量级锁，效率低下，因为监视器锁（monitor）是依赖于底层的操作系统的 Mutex Lock 来实现的，Java 的线程是映射到操作系统的原生线程之上的。如果要挂起或者唤醒一个线程，都需要操作系统帮忙完成，而操作系统实现线程之间的切换时需要从用户态转换到内核态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高，这也是为什么早期的 synchronized 效率低的原因。庆幸的是在 Java 6 之后 Java 官方对从 JVM 层面对synchronized 较大优化，所以现在的 synchronized 锁效率也优化得很不错了。JDK1.6对锁的实现引入了大量的优化，如自旋锁、适应性自旋锁、锁消除、锁粗化、偏向锁、轻量级锁等技术来减少锁操作的开销。</p>\n<h3 id=\"1-2-说说自己是怎么使用-synchronized-关键字，在项目中用到了吗\"><a href=\"#1-2-说说自己是怎么使用-synchronized-关键字，在项目中用到了吗\" class=\"headerlink\" title=\"1.2. 说说自己是怎么使用 synchronized 关键字，在项目中用到了吗\"></a>1.2. 说说自己是怎么使用 synchronized 关键字，在项目中用到了吗</h3><p><strong>synchronized关键字最主要的三种使用方式：</strong></p>\n<ul>\n<li><strong>修饰实例方法:</strong> 作用于当前对象实例加锁，进入同步代码前要获得当前对象实例的锁</li>\n<li><strong>修饰静态方法:</strong> 也就是给当前类加锁，会作用于类的所有对象实例，因为静态成员不属于任何一个实例对象，是类成员（ static 表明这是该类的一个静态资源，不管new了多少个对象，只有一份）。所以如果一个线程 A 调用一个实例对象的非静态 synchronized 方法，而线程 B 需要调用这个实例对象所属类的静态 synchronized 方法，是允许的，不会发生互斥现象，<strong>因为访问静态 synchronized 方法占用的锁是当前类的锁，而访问非静态 synchronized 方法占用的锁是当前实例对象锁</strong>。</li>\n<li><strong>修饰代码块:</strong> 指定加锁对象，对给定对象加锁，进入同步代码库前要获得给定对象的锁。</li>\n</ul>\n<p><strong>总结：</strong> synchronized 关键字加到 static 静态方法和 synchronized(class)代码块上都是是给 Class 类上锁。synchronized 关键字加到实例方法上是给对象实例上锁。尽量不要使用 synchronized(String a) 因为JVM中，字符串常量池具有缓存功能！</p>\n<p>下面我以一个常见的面试题为例讲解一下 synchronized 关键字的具体使用。</p>\n<p>面试中面试官经常会说：“单例模式了解吗？来给我手写一下！给我解释一下双重检验锁方式实现单例模式的原理呗！”</p>\n<p><strong>双重校验锁实现对象单例（线程安全）</strong></p>\n<pre><code class=\"java\">public class Singleton {\n\n    private volatile static Singleton uniqueInstance;\n\n    private Singleton() {\n    }\n\n    public static Singleton getUniqueInstance() {\n       //先判断对象是否已经实例过，没有实例化过才进入加锁代码\n        if (uniqueInstance == null) {\n            //类对象加锁\n            synchronized (Singleton.class) {\n                if (uniqueInstance == null) {\n                    uniqueInstance = new Singleton();\n                }\n            }\n        }\n        return uniqueInstance;\n    }\n}</code></pre>\n<p>另外，需要注意 uniqueInstance 采用 volatile 关键字修饰也是很有必要。</p>\n<p>uniqueInstance 采用 volatile 关键字修饰也是很有必要的， uniqueInstance = new Singleton(); 这段代码其实是分为三步执行：</p>\n<ol>\n<li>为 uniqueInstance 分配内存空间</li>\n<li>初始化 uniqueInstance</li>\n<li>将 uniqueInstance 指向分配的内存地址</li>\n</ol>\n<p>但是由于 JVM 具有指令重排的特性，执行顺序有可能变成 1-&gt;3-&gt;2。指令重排在单线程环境下不会出现问题，但是在多线程环境下会导致一个线程获得还没有初始化的实例。例如，线程 T1 执行了 1 和 3，此时 T2 调用 getUniqueInstance() 后发现 uniqueInstance 不为空，因此返回 uniqueInstance，但此时 uniqueInstance 还未被初始化。</p>\n<p>使用 volatile 可以禁止 JVM 的指令重排，保证在多线程环境下也能正常运行。</p>\n<h3 id=\"1-3-讲一下-synchronized-关键字的底层原理\"><a href=\"#1-3-讲一下-synchronized-关键字的底层原理\" class=\"headerlink\" title=\"1.3. 讲一下 synchronized 关键字的底层原理\"></a>1.3. 讲一下 synchronized 关键字的底层原理</h3><p><strong>synchronized 关键字底层原理属于 JVM 层面。</strong></p>\n<p><strong>① synchronized 同步语句块的情况</strong></p>\n<pre><code class=\"java\">public class SynchronizedDemo {\n    public void method() {\n        synchronized (this) {\n            System.out.println(&quot;synchronized 代码块&quot;);\n        }\n    }\n}\n</code></pre>\n<p>通过 JDK 自带的 javap 命令查看 SynchronizedDemo 类的相关字节码信息：首先切换到类的对应目录执行 <code>javac SynchronizedDemo.java</code> 命令生成编译后的 .class 文件，然后执行<code>javap -c -s -v -l SynchronizedDemo.class</code>。</p>\n<p><img src=\"https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/synchronized%E5%85%B3%E9%94%AE%E5%AD%97%E5%8E%9F%E7%90%86.png\" alt=\"synchronized关键字原理\"></p>\n<p>从上面我们可以看出：</p>\n<p><strong>synchronized 同步语句块的实现使用的是 monitorenter 和 monitorexit 指令，其中 monitorenter 指令指向同步代码块的开始位置，monitorexit 指令则指明同步代码块的结束位置。</strong> 当执行 monitorenter 指令时，线程试图获取锁也就是获取 monitor(monitor对象存在于每个Java对象的对象头中，synchronized 锁便是通过这种方式获取锁的，也是为什么Java中任意对象可以作为锁的原因) 的持有权。当计数器为0则可以成功获取，获取后将锁计数器设为1也就是加1。相应的在执行 monitorexit 指令后，将锁计数器设为0，表明锁被释放。如果获取对象锁失败，那当前线程就要阻塞等待，直到锁被另外一个线程释放为止。</p>\n<p><strong>② synchronized 修饰方法的的情况</strong></p>\n<pre><code class=\"java\">public class SynchronizedDemo2 {\n    public synchronized void method() {\n        System.out.println(&quot;synchronized 方法&quot;);\n    }\n}\n</code></pre>\n<p><img src=\"https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/synchronized%E5%85%B3%E9%94%AE%E5%AD%97%E5%8E%9F%E7%90%862.png\" alt=\"synchronized关键字原理\"></p>\n<p>synchronized 修饰的方法并没有 monitorenter 指令和 monitorexit 指令，取得代之的确实是 ACC_SYNCHRONIZED 标识，该标识指明了该方法是一个同步方法，JVM 通过该 ACC_SYNCHRONIZED 访问标志来辨别一个方法是否声明为同步方法，从而执行相应的同步调用。</p>\n<h3 id=\"1-4-说说-JDK1-6-之后的synchronized-关键字底层做了哪些优化，可以详细介绍一下这些优化吗\"><a href=\"#1-4-说说-JDK1-6-之后的synchronized-关键字底层做了哪些优化，可以详细介绍一下这些优化吗\" class=\"headerlink\" title=\"1.4. 说说 JDK1.6 之后的synchronized 关键字底层做了哪些优化，可以详细介绍一下这些优化吗\"></a>1.4. 说说 JDK1.6 之后的synchronized 关键字底层做了哪些优化，可以详细介绍一下这些优化吗</h3><p>JDK1.6 对锁的实现引入了大量的优化，如偏向锁、轻量级锁、自旋锁、适应性自旋锁、锁消除、锁粗化等技术来减少锁操作的开销。</p>\n<p>锁主要存在四种状态，依次是：无锁状态、偏向锁状态、轻量级锁状态、重量级锁状态，他们会随着竞争的激烈而逐渐升级。注意锁可以升级不可降级，这种策略是为了提高获得锁和释放锁的效率。</p>\n<p>关于这几种优化的详细信息可以查看笔主的这篇文章：<a href=\"https://gitee.com/SnailClimb/JavaGuide/blob/master/docs/java/Multithread/synchronized.md\" target=\"_blank\" rel=\"noopener\">https://gitee.com/SnailClimb/JavaGuide/blob/master/docs/java/Multithread/synchronized.md</a></p>\n<h3 id=\"1-5-谈谈-synchronized和ReentrantLock-的区别\"><a href=\"#1-5-谈谈-synchronized和ReentrantLock-的区别\" class=\"headerlink\" title=\"1.5. 谈谈 synchronized和ReentrantLock 的区别\"></a>1.5. 谈谈 synchronized和ReentrantLock 的区别</h3><p><strong>① 两者都是可重入锁</strong></p>\n<p>两者都是可重入锁。“可重入锁”概念是：自己可以再次获取自己的内部锁。比如一个线程获得了某个对象的锁，此时这个对象锁还没有释放，当其再次想要获取这个对象的锁的时候还是可以获取的，如果不可锁重入的话，就会造成死锁。同一个线程每次获取锁，锁的计数器都自增1，所以要等到锁的计数器下降为0时才能释放锁。</p>\n<p><strong>② synchronized 依赖于 JVM 而 ReentrantLock 依赖于 API</strong></p>\n<p>synchronized 是依赖于 JVM 实现的，前面我们也讲到了 虚拟机团队在 JDK1.6 为 synchronized 关键字进行了很多优化，但是这些优化都是在虚拟机层面实现的，并没有直接暴露给我们。ReentrantLock 是 JDK 层面实现的（也就是 API 层面，需要 lock() 和 unlock() 方法配合 try/finally 语句块来完成），所以我们可以通过查看它的源代码，来看它是如何实现的。</p>\n<p><strong>③ ReentrantLock 比 synchronized 增加了一些高级功能</strong></p>\n<p>相比synchronized，ReentrantLock增加了一些高级功能。主要来说主要有三点：<strong>①等待可中断；②可实现公平锁；③可实现选择性通知（锁可以绑定多个条件）</strong></p>\n<ul>\n<li><strong>ReentrantLock提供了一种能够中断等待锁的线程的机制</strong>，通过lock.lockInterruptibly()来实现这个机制。也就是说正在等待的线程可以选择放弃等待，改为处理其他事情。</li>\n<li><strong>ReentrantLock可以指定是公平锁还是非公平锁。而synchronized只能是非公平锁。所谓的公平锁就是先等待的线程先获得锁。</strong> ReentrantLock默认情况是非公平的，可以通过 ReentrantLock类的<code>ReentrantLock(boolean fair)</code>构造方法来制定是否是公平的。</li>\n<li>synchronized关键字与wait()和notify()/notifyAll()方法相结合可以实现等待/通知机制，ReentrantLock类当然也可以实现，但是需要借助于Condition接口与newCondition() 方法。Condition是JDK1.5之后才有的，它具有很好的灵活性，比如可以实现多路通知功能也就是在一个Lock对象中可以创建多个Condition实例（即对象监视器），<strong>线程对象可以注册在指定的Condition中，从而可以有选择性的进行线程通知，在调度线程上更加灵活。 在使用notify()/notifyAll()方法进行通知时，被通知的线程是由 JVM 选择的，用ReentrantLock类结合Condition实例可以实现“选择性通知”</strong> ，这个功能非常重要，而且是Condition接口默认提供的。而synchronized关键字就相当于整个Lock对象中只有一个Condition实例，所有的线程都注册在它一个身上。如果执行notifyAll()方法的话就会通知所有处于等待状态的线程这样会造成很大的效率问题，而Condition实例的signalAll()方法 只会唤醒注册在该Condition实例中的所有等待线程。</li>\n</ul>\n<p>如果你想使用上述功能，那么选择ReentrantLock是一个不错的选择。</p>\n<p><strong>④ 性能已不是选择标准</strong></p>\n<h2 id=\"2-volatile关键字\"><a href=\"#2-volatile关键字\" class=\"headerlink\" title=\"2. volatile关键字\"></a>2. volatile关键字</h2><h3 id=\"2-1-讲一下Java内存模型\"><a href=\"#2-1-讲一下Java内存模型\" class=\"headerlink\" title=\"2.1. 讲一下Java内存模型\"></a>2.1. 讲一下Java内存模型</h3><p>在 JDK1.2 之前，Java的内存模型实现总是从<strong>主存</strong>（即共享内存）读取变量，是不需要进行特别的注意的。而在当前的 Java 内存模型下，线程可以把变量保存<strong>本地内存</strong>（比如机器的寄存器）中，而不是直接在主存中进行读写。这就可能造成一个线程在主存中修改了一个变量的值，而另外一个线程还继续使用它在寄存器中的变量值的拷贝，造成<strong>数据的不一致</strong>。</p>\n<p><img src=\"https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/%E6%95%B0%E6%8D%AE%E4%B8%8D%E4%B8%80%E8%87%B4.png\" alt=\"数据不一致\"></p>\n<p>要解决这个问题，就需要把变量声明为<strong>volatile</strong>，这就指示 JVM，这个变量是不稳定的，每次使用它都到主存中进行读取。</p>\n<p>说白了， <strong>volatile</strong> 关键字的主要作用就是保证变量的可见性然后还有一个作用是防止指令重排序。</p>\n<p><img src=\"https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/volatile%E5%85%B3%E9%94%AE%E5%AD%97%E7%9A%84%E5%8F%AF%E8%A7%81%E6%80%A7.png\" alt=\"volatile关键字的可见性\"></p>\n<h3 id=\"2-2-并发编程的三个重要特性\"><a href=\"#2-2-并发编程的三个重要特性\" class=\"headerlink\" title=\"2.2 并发编程的三个重要特性\"></a>2.2 并发编程的三个重要特性</h3><ol>\n<li><strong>原子性</strong> : 一个的操作或者多次操作，要么所有的操作全部都得到执行并且不会收到任何因素的干扰而中断，要么所有的操作都执行，要么都不执行。<code>synchronized</code> 可以保证代码片段的原子性。</li>\n<li><strong>可见性</strong>  ：当一个变量对共享变量进行了修改，那么另外的线程都是立即可以看到修改后的最新值。<code>volatile</code> 关键字可以保证共享变量的可见性。</li>\n<li><strong>有序性</strong> ：代码在执行的过程中的先后顺序，Java 在编译器以及运行期间的优化，代码的执行顺序未必就是编写代码时候的顺序。<code>volatile</code> 关键字可以禁止指令进行重排序优化。</li>\n</ol>\n<h3 id=\"2-3-说说-synchronized-关键字和-volatile-关键字的区别\"><a href=\"#2-3-说说-synchronized-关键字和-volatile-关键字的区别\" class=\"headerlink\" title=\"2.3. 说说 synchronized 关键字和 volatile 关键字的区别\"></a>2.3. 说说 synchronized 关键字和 volatile 关键字的区别</h3><p><code>synchronized</code> 关键字和 <code>volatile</code> 关键字是两个互补的存在，而不是对立的存在：</p>\n<ul>\n<li><strong>volatile关键字</strong>是线程同步的<strong>轻量级实现</strong>，所以<strong>volatile性能肯定比synchronized关键字要好</strong>。但是<strong>volatile关键字只能用于变量而synchronized关键字可以修饰方法以及代码块</strong>。synchronized关键字在JavaSE1.6之后进行了主要包括为了减少获得锁和释放锁带来的性能消耗而引入的偏向锁和轻量级锁以及其它各种优化之后执行效率有了显著提升，<strong>实际开发中使用 synchronized 关键字的场景还是更多一些</strong>。</li>\n<li><strong>多线程访问volatile关键字不会发生阻塞，而synchronized关键字可能会发生阻塞</strong></li>\n<li><strong>volatile关键字能保证数据的可见性，但不能保证数据的原子性。synchronized关键字两者都能保证。</strong></li>\n<li><strong>volatile关键字主要用于解决变量在多个线程之间的可见性，而 synchronized关键字解决的是多个线程之间访问资源的同步性。</strong></li>\n</ul>\n<h2 id=\"3-ThreadLocal\"><a href=\"#3-ThreadLocal\" class=\"headerlink\" title=\"3. ThreadLocal\"></a>3. ThreadLocal</h2><h3 id=\"3-1-ThreadLocal简介\"><a href=\"#3-1-ThreadLocal简介\" class=\"headerlink\" title=\"3.1. ThreadLocal简介\"></a>3.1. ThreadLocal简介</h3><p>通常情况下，我们创建的变量是可以被任何一个线程访问并修改的。<strong>如果想实现每一个线程都有自己的专属本地变量该如何解决呢？</strong> JDK中提供的<code>ThreadLocal</code>类正是为了解决这样的问题。 <strong><code>ThreadLocal</code>类主要解决的就是让每个线程绑定自己的值，可以将<code>ThreadLocal</code>类形象的比喻成存放数据的盒子，盒子中可以存储每个线程的私有数据。</strong></p>\n<p><strong>如果你创建了一个<code>ThreadLocal</code>变量，那么访问这个变量的每个线程都会有这个变量的本地副本，这也是<code>ThreadLocal</code>变量名的由来。他们可以使用 <code>get（）</code> 和 <code>set（）</code> 方法来获取默认值或将其值更改为当前线程所存的副本的值，从而避免了线程安全问题。</strong></p>\n<p>再举个简单的例子： </p>\n<p>比如有两个人去宝屋收集宝物，这两个共用一个袋子的话肯定会产生争执，但是给他们两个人每个人分配一个袋子的话就不会出现这样的问题。如果把这两个人比作线程的话，那么ThreadLocal就是用来避免这两个线程竞争的。</p>\n<h3 id=\"3-2-ThreadLocal示例\"><a href=\"#3-2-ThreadLocal示例\" class=\"headerlink\" title=\"3.2. ThreadLocal示例\"></a>3.2. ThreadLocal示例</h3><p>相信看了上面的解释，大家已经搞懂 ThreadLocal 类是个什么东西了。</p>\n<pre><code class=\"java\">import java.text.SimpleDateFormat;\nimport java.util.Random;\n\npublic class ThreadLocalExample implements Runnable{\n\n     // SimpleDateFormat 不是线程安全的，所以每个线程都要有自己独立的副本\n    private static final ThreadLocal&lt;SimpleDateFormat&gt; formatter = ThreadLocal.withInitial(() -&gt; new SimpleDateFormat(&quot;yyyyMMdd HHmm&quot;));\n\n    public static void main(String[] args) throws InterruptedException {\n        ThreadLocalExample obj = new ThreadLocalExample();\n        for(int i=0 ; i&lt;10; i++){\n            Thread t = new Thread(obj, &quot;&quot;+i);\n            Thread.sleep(new Random().nextInt(1000));\n            t.start();\n        }\n    }\n\n    @Override\n    public void run() {\n        System.out.println(&quot;Thread Name= &quot;+Thread.currentThread().getName()+&quot; default Formatter = &quot;+formatter.get().toPattern());\n        try {\n            Thread.sleep(new Random().nextInt(1000));\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n        //formatter pattern is changed here by thread, but it won&#39;t reflect to other threads\n        formatter.set(new SimpleDateFormat());\n\n        System.out.println(&quot;Thread Name= &quot;+Thread.currentThread().getName()+&quot; formatter = &quot;+formatter.get().toPattern());\n    }\n\n}\n</code></pre>\n<p>Output:</p>\n<pre><code>Thread Name= 0 default Formatter = yyyyMMdd HHmm\nThread Name= 0 formatter = yy-M-d ah:mm\nThread Name= 1 default Formatter = yyyyMMdd HHmm\nThread Name= 2 default Formatter = yyyyMMdd HHmm\nThread Name= 1 formatter = yy-M-d ah:mm\nThread Name= 3 default Formatter = yyyyMMdd HHmm\nThread Name= 2 formatter = yy-M-d ah:mm\nThread Name= 4 default Formatter = yyyyMMdd HHmm\nThread Name= 3 formatter = yy-M-d ah:mm\nThread Name= 4 formatter = yy-M-d ah:mm\nThread Name= 5 default Formatter = yyyyMMdd HHmm\nThread Name= 5 formatter = yy-M-d ah:mm\nThread Name= 6 default Formatter = yyyyMMdd HHmm\nThread Name= 6 formatter = yy-M-d ah:mm\nThread Name= 7 default Formatter = yyyyMMdd HHmm\nThread Name= 7 formatter = yy-M-d ah:mm\nThread Name= 8 default Formatter = yyyyMMdd HHmm\nThread Name= 9 default Formatter = yyyyMMdd HHmm\nThread Name= 8 formatter = yy-M-d ah:mm\nThread Name= 9 formatter = yy-M-d ah:mm</code></pre><p>从输出中可以看出，Thread-0已经改变了formatter的值，但仍然是thread-2默认格式化程序与初始化值相同，其他线程也一样。</p>\n<p>上面有一段代码用到了创建 <code>ThreadLocal</code> 变量的那段代码用到了 Java8 的知识，它等于下面这段代码，如果你写了下面这段代码的话，IDEA会提示你转换为Java8的格式(IDEA真的不错！)。因为ThreadLocal类在Java 8中扩展，使用一个新的方法<code>withInitial()</code>，将Supplier功能接口作为参数。</p>\n<pre><code class=\"java\"> private static final ThreadLocal&lt;SimpleDateFormat&gt; formatter = new ThreadLocal&lt;SimpleDateFormat&gt;(){\n        @Override\n        protected SimpleDateFormat initialValue()\n        {\n            return new SimpleDateFormat(&quot;yyyyMMdd HHmm&quot;);\n        }\n    };</code></pre>\n<h3 id=\"3-3-ThreadLocal原理\"><a href=\"#3-3-ThreadLocal原理\" class=\"headerlink\" title=\"3.3. ThreadLocal原理\"></a>3.3. ThreadLocal原理</h3><p>从 <code>Thread</code>类源代码入手。</p>\n<pre><code class=\"java\">public class Thread implements Runnable {\n ......\n//与此线程有关的ThreadLocal值。由ThreadLocal类维护\nThreadLocal.ThreadLocalMap threadLocals = null;\n\n//与此线程有关的InheritableThreadLocal值。由InheritableThreadLocal类维护\nThreadLocal.ThreadLocalMap inheritableThreadLocals = null;\n ......\n}</code></pre>\n<p>从上面<code>Thread</code>类 源代码可以看出<code>Thread</code> 类中有一个 <code>threadLocals</code> 和 一个  <code>inheritableThreadLocals</code> 变量，它们都是 <code>ThreadLocalMap</code>  类型的变量,我们可以把 <code>ThreadLocalMap</code>  理解为<code>ThreadLocal</code> 类实现的定制化的 <code>HashMap</code>。默认情况下这两个变量都是null，只有当前线程调用 <code>ThreadLocal</code> 类的 <code>set</code>或<code>get</code>方法时才创建它们，实际上调用这两个方法的时候，我们调用的是<code>ThreadLocalMap</code>类对应的 <code>get()</code>、<code>set()</code>方法。</p>\n<p><code>ThreadLocal</code>类的<code>set()</code>方法</p>\n<pre><code class=\"java\">    public void set(T value) {\n        Thread t = Thread.currentThread();\n        ThreadLocalMap map = getMap(t);\n        if (map != null)\n            map.set(this, value);\n        else\n            createMap(t, value);\n    }\n    ThreadLocalMap getMap(Thread t) {\n        return t.threadLocals;\n    }</code></pre>\n<p>通过上面这些内容，我们足以通过猜测得出结论：<strong>最终的变量是放在了当前线程的 <code>ThreadLocalMap</code> 中，并不是存在 <code>ThreadLocal</code> 上，<code>ThreadLocal</code> 可以理解为只是<code>ThreadLocalMap</code>的封装，传递了变量值。</strong> <code>ThrealLocal</code> 类中可以通过<code>Thread.currentThread()</code>获取到当前线程对象后，直接通过<code>getMap(Thread t)</code>可以访问到该线程的<code>ThreadLocalMap</code>对象。</p>\n<p><strong>每个<code>Thread</code>中都具备一个<code>ThreadLocalMap</code>，而<code>ThreadLocalMap</code>可以存储以<code>ThreadLocal</code>为key ，Object 对象为 value的键值对。</strong> </p>\n<pre><code class=\"java\">ThreadLocalMap(ThreadLocal&lt;?&gt; firstKey, Object firstValue) {\n ......\n}</code></pre>\n<p>比如我们在同一个线程中声明了两个 <code>ThreadLocal</code> 对象的话，会使用 <code>Thread</code>内部都是使用仅有那个<code>ThreadLocalMap</code> 存放数据的，<code>ThreadLocalMap</code>的 key 就是 <code>ThreadLocal</code>对象，value 就是 <code>ThreadLocal</code> 对象调用<code>set</code>方法设置的值。</p>\n<p><img src=\"https://upload-images.jianshu.io/upload_images/7432604-ad2ff581127ba8cc.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/806\" alt=\"ThreadLocal数据结构\"></p>\n<p><code>ThreadLocalMap</code>是<code>ThreadLocal</code>的静态内部类。</p>\n<p><img src=\"https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/ThreadLocal%E5%86%85%E9%83%A8%E7%B1%BB.png\" alt=\"ThreadLocal内部类\"></p>\n<h3 id=\"3-4-ThreadLocal-内存泄露问题\"><a href=\"#3-4-ThreadLocal-内存泄露问题\" class=\"headerlink\" title=\"3.4. ThreadLocal 内存泄露问题\"></a>3.4. ThreadLocal 内存泄露问题</h3><p><code>ThreadLocalMap</code> 中使用的 key 为 <code>ThreadLocal</code> 的弱引用,而 value 是强引用。所以，如果 <code>ThreadLocal</code> 没有被外部强引用的情况下，在垃圾回收的时候，key 会被清理掉，而 value 不会被清理掉。这样一来，<code>ThreadLocalMap</code> 中就会出现key为null的Entry。假如我们不做任何措施的话，value 永远无法被GC 回收，这个时候就可能会产生内存泄露。ThreadLocalMap实现中已经考虑了这种情况，在调用 <code>set()</code>、<code>get()</code>、<code>remove()</code> 方法的时候，会清理掉 key 为 null 的记录。使用完 <code>ThreadLocal</code>方法后 最好手动调用<code>remove()</code>方法</p>\n<pre><code class=\"java\">      static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; {\n            /** The value associated with this ThreadLocal. */\n            Object value;\n\n            Entry(ThreadLocal&lt;?&gt; k, Object v) {\n                super(k);\n                value = v;\n            }\n        }</code></pre>\n<p><strong>弱引用介绍：</strong></p>\n<blockquote>\n<p>如果一个对象只具有弱引用，那就类似于<strong>可有可无的生活用品</strong>。弱引用与软引用的区别在于：只具有弱引用的对象拥有更短暂的生命周期。在垃圾回收器线程扫描它 所管辖的内存区域的过程中，一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。不过，由于垃圾回收器是一个优先级很低的线程， 因此不一定会很快发现那些只具有弱引用的对象。</p>\n<p>弱引用可以和一个引用队列（ReferenceQueue）联合使用，如果弱引用所引用的对象被垃圾回收，Java虚拟机就会把这个弱引用加入到与之关联的引用队列中。</p>\n</blockquote>\n<h2 id=\"4-线程池\"><a href=\"#4-线程池\" class=\"headerlink\" title=\"4. 线程池\"></a>4. 线程池</h2><h3 id=\"4-1-为什么要用线程池？\"><a href=\"#4-1-为什么要用线程池？\" class=\"headerlink\" title=\"4.1. 为什么要用线程池？\"></a>4.1. 为什么要用线程池？</h3><blockquote>\n<p><strong>池化技术相比大家已经屡见不鲜了，线程池、数据库连接池、Http 连接池等等都是对这个思想的应用。池化技术的思想主要是为了减少每次获取资源的消耗，提高对资源的利用率。</strong></p>\n</blockquote>\n<p><strong>线程池</strong>提供了一种限制和管理资源（包括执行一个任务）。 每个<strong>线程池</strong>还维护一些基本统计信息，例如已完成任务的数量。</p>\n<p>这里借用《Java 并发编程的艺术》提到的来说一下<strong>使用线程池的好处</strong>：</p>\n<ul>\n<li><strong>降低资源消耗</strong>。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。</li>\n<li><strong>提高响应速度</strong>。当任务到达时，任务可以不需要的等到线程创建就能立即执行。</li>\n<li><strong>提高线程的可管理性</strong>。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。</li>\n</ul>\n<h3 id=\"4-2-实现Runnable接口和Callable接口的区别\"><a href=\"#4-2-实现Runnable接口和Callable接口的区别\" class=\"headerlink\" title=\"4.2. 实现Runnable接口和Callable接口的区别\"></a>4.2. 实现Runnable接口和Callable接口的区别</h3><p><code>Runnable</code>自Java 1.0以来一直存在，但<code>Callable</code>仅在Java 1.5中引入,目的就是为了来处理<code>Runnable</code>不支持的用例。<strong><code>Runnable</code> 接口</strong>不会返回结果或抛出检查异常，但是<strong><code>Callable</code> 接口</strong>可以。所以，如果任务不需要返回结果或抛出异常推荐使用 <strong><code>Runnable</code> 接口</strong>，这样代码看起来会更加简洁。</p>\n<p>工具类 <code>Executors</code> 可以实现 <code>Runnable</code> 对象和 <code>Callable</code> 对象之间的相互转换。（<code>Executors.callable（Runnable task</code>）或 <code>Executors.callable（Runnable task，Object resule）</code>）。</p>\n<p><code>Runnable.java</code></p>\n<pre><code class=\"java\">@FunctionalInterface\npublic interface Runnable {\n   /**\n    * 被线程执行，没有返回值也无法抛出异常\n    */\n    public abstract void run();\n}</code></pre>\n<p><code>Callable.java</code></p>\n<pre><code class=\"java\">@FunctionalInterface\npublic interface Callable&lt;V&gt; {\n    /**\n     * 计算结果，或在无法这样做时抛出异常。\n     * @return 计算得出的结果\n     * @throws 如果无法计算结果，则抛出异常\n     */\n    V call() throws Exception;\n}</code></pre>\n<h3 id=\"4-3-执行execute-方法和submit-方法的区别是什么呢？\"><a href=\"#4-3-执行execute-方法和submit-方法的区别是什么呢？\" class=\"headerlink\" title=\"4.3. 执行execute()方法和submit()方法的区别是什么呢？\"></a>4.3. 执行execute()方法和submit()方法的区别是什么呢？</h3><ol>\n<li><strong><code>execute()</code>方法用于提交不需要返回值的任务，所以无法判断任务是否被线程池执行成功与否；</strong></li>\n<li><strong><code>submit()</code>方法用于提交需要返回值的任务。线程池会返回一个 <code>Future</code> 类型的对象，通过这个 <code>Future</code> 对象可以判断任务是否执行成功</strong>，并且可以通过 <code>Future</code> 的 <code>get()</code>方法来获取返回值，<code>get()</code>方法会阻塞当前线程直到任务完成，而使用 <code>get（long timeout，TimeUnit unit）</code>方法则会阻塞当前线程一段时间后立即返回，这时候有可能任务没有执行完。</li>\n</ol>\n<p>我们以<strong><code>AbstractExecutorService</code></strong>接口中的一个 <code>submit</code> 方法为例子来看看源代码：</p>\n<pre><code class=\"java\">    public Future&lt;?&gt; submit(Runnable task) {\n        if (task == null) throw new NullPointerException();\n        RunnableFuture&lt;Void&gt; ftask = newTaskFor(task, null);\n        execute(ftask);\n        return ftask;\n    }</code></pre>\n<p>上面方法调用的 <code>newTaskFor</code> 方法返回了一个 <code>FutureTask</code> 对象。</p>\n<pre><code class=\"java\">    protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Runnable runnable, T value) {\n        return new FutureTask&lt;T&gt;(runnable, value);\n    }</code></pre>\n<p>我们再来看看<code>execute()</code>方法：</p>\n<pre><code class=\"java\">    public void execute(Runnable command) {\n      ...\n    }</code></pre>\n<h3 id=\"4-4-如何创建线程池\"><a href=\"#4-4-如何创建线程池\" class=\"headerlink\" title=\"4.4. 如何创建线程池\"></a>4.4. 如何创建线程池</h3><p>《阿里巴巴Java开发手册》中强制线程池不允许使用 Executors 去创建，而是通过 ThreadPoolExecutor 的方式，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险</p>\n<blockquote>\n<p>Executors 返回线程池对象的弊端如下：</p>\n<ul>\n<li><strong>FixedThreadPool 和 SingleThreadExecutor</strong> ： 允许请求的队列长度为 Integer.MAX_VALUE ，可能堆积大量的请求，从而导致OOM。</li>\n<li><strong>CachedThreadPool 和 ScheduledThreadPool</strong> ： 允许创建的线程数量为 Integer.MAX_VALUE ，可能会创建大量线程，从而导致OOM。</li>\n</ul>\n</blockquote>\n<p><strong>方式一：通过构造方法实现</strong><br><img src=\"https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/ThreadPoolExecutor%E6%9E%84%E9%80%A0%E6%96%B9%E6%B3%95.png\" alt=\"ThreadPoolExecutor构造方法\"><br><strong>方式二：通过Executor 框架的工具类Executors来实现</strong><br>我们可以创建三种类型的ThreadPoolExecutor：</p>\n<ul>\n<li><strong>FixedThreadPool</strong> ： 该方法返回一个固定线程数量的线程池。该线程池中的线程数量始终不变。当有一个新的任务提交时，线程池中若有空闲线程，则立即执行。若没有，则新的任务会被暂存在一个任务队列中，待有线程空闲时，便处理在任务队列中的任务。</li>\n<li><strong>SingleThreadExecutor：</strong> 方法返回一个只有一个线程的线程池。若多余一个任务被提交到该线程池，任务会被保存在一个任务队列中，待线程空闲，按先入先出的顺序执行队列中的任务。</li>\n<li><strong>CachedThreadPool：</strong> 该方法返回一个可根据实际情况调整线程数量的线程池。线程池的线程数量不确定，但若有空闲线程可以复用，则会优先使用可复用的线程。若所有线程均在工作，又有新的任务提交，则会创建新的线程处理任务。所有线程在当前任务执行完毕后，将返回线程池进行复用。</li>\n</ul>\n<p>对应Executors工具类中的方法如图所示：<br><img src=\"https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/Executor%E6%A1%86%E6%9E%B6%E7%9A%84%E5%B7%A5%E5%85%B7%E7%B1%BB.png\" alt=\"Executor框架的工具类\"></p>\n<h3 id=\"4-5-ThreadPoolExecutor-类分析\"><a href=\"#4-5-ThreadPoolExecutor-类分析\" class=\"headerlink\" title=\"4.5 ThreadPoolExecutor 类分析\"></a>4.5 ThreadPoolExecutor 类分析</h3><p><code>ThreadPoolExecutor</code> 类中提供的四个构造方法。我们来看最长的那个，其余三个都是在这个构造方法的基础上产生（其他几个构造方法说白点都是给定某些默认参数的构造方法比如默认制定拒绝策略是什么），这里就不贴代码讲了，比较简单。</p>\n<pre><code class=\"java\">    /**\n     * 用给定的初始参数创建一个新的ThreadPoolExecutor。\n     */\n    public ThreadPoolExecutor(int corePoolSize,\n                              int maximumPoolSize,\n                              long keepAliveTime,\n                              TimeUnit unit,\n                              BlockingQueue&lt;Runnable&gt; workQueue,\n                              ThreadFactory threadFactory,\n                              RejectedExecutionHandler handler) {\n        if (corePoolSize &lt; 0 ||\n            maximumPoolSize &lt;= 0 ||\n            maximumPoolSize &lt; corePoolSize ||\n            keepAliveTime &lt; 0)\n            throw new IllegalArgumentException();\n        if (workQueue == null || threadFactory == null || handler == null)\n            throw new NullPointerException();\n        this.corePoolSize = corePoolSize;\n        this.maximumPoolSize = maximumPoolSize;\n        this.workQueue = workQueue;\n        this.keepAliveTime = unit.toNanos(keepAliveTime);\n        this.threadFactory = threadFactory;\n        this.handler = handler;\n    }</code></pre>\n<p><strong>下面这些对创建 非常重要，在后面使用线程池的过程中你一定会用到！所以，务必拿着小本本记清楚。</strong></p>\n<h4 id=\"4-5-1-ThreadPoolExecutor构造函数重要参数分析\"><a href=\"#4-5-1-ThreadPoolExecutor构造函数重要参数分析\" class=\"headerlink\" title=\"4.5.1 ThreadPoolExecutor构造函数重要参数分析\"></a>4.5.1 <code>ThreadPoolExecutor</code>构造函数重要参数分析</h4><p><strong><code>ThreadPoolExecutor</code> 3 个最重要的参数：</strong></p>\n<ul>\n<li><strong><code>corePoolSize</code> :</strong> 核心线程数线程数定义了最小可以同时运行的线程数量。</li>\n<li><strong><code>maximumPoolSize</code> :</strong> 当队列中存放的任务达到队列容量的时候，当前可以同时运行的线程数量变为最大线程数。</li>\n<li><strong><code>workQueue</code>:</strong> 当新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到的话，新任务就会被存放在队列中。</li>\n</ul>\n<p><code>ThreadPoolExecutor</code>其他常见参数:</p>\n<ol>\n<li><strong><code>keepAliveTime</code></strong>:当线程池中的线程数量大于 <code>corePoolSize</code> 的时候，如果这时没有新的任务提交，核心线程外的线程不会立即销毁，而是会等待，直到等待的时间超过了 <code>keepAliveTime</code>才会被回收销毁；</li>\n<li><strong><code>unit</code></strong> : <code>keepAliveTime</code> 参数的时间单位。</li>\n<li><strong><code>threadFactory</code></strong> :executor 创建新线程的时候会用到。</li>\n<li><strong><code>handler</code></strong> :饱和策略。关于饱和策略下面单独介绍一下。</li>\n</ol>\n<h4 id=\"4-5-2-ThreadPoolExecutor-饱和策略\"><a href=\"#4-5-2-ThreadPoolExecutor-饱和策略\" class=\"headerlink\" title=\"4.5.2 ThreadPoolExecutor 饱和策略\"></a>4.5.2 <code>ThreadPoolExecutor</code> 饱和策略</h4><p><strong><code>ThreadPoolExecutor</code> 饱和策略定义:</strong></p>\n<p>如果当前同时运行的线程数量达到最大线程数量并且队列也已经被放满了任时，<code>ThreadPoolTaskExecutor</code> 定义一些策略:</p>\n<ul>\n<li><strong><code>ThreadPoolExecutor.AbortPolicy</code></strong>：抛出 <code>RejectedExecutionException</code>来拒绝新任务的处理。</li>\n<li><strong><code>ThreadPoolExecutor.CallerRunsPolicy</code></strong>：调用执行自己的线程运行任务。您不会任务请求。但是这种策略会降低对于新任务提交速度，影响程序的整体性能。另外，这个策略喜欢增加队列容量。如果您的应用程序可以承受此延迟并且你不能任务丢弃任何一个任务请求的话，你可以选择这个策略。</li>\n<li><strong><code>ThreadPoolExecutor.DiscardPolicy</code>：</strong> 不处理新任务，直接丢弃掉。</li>\n<li><strong><code>ThreadPoolExecutor.DiscardOldestPolicy</code>：</strong> 此策略将丢弃最早的未处理的任务请求。</li>\n</ul>\n<p>举个例子： Spring 通过 <code>ThreadPoolTaskExecutor</code> 或者我们直接通过 <code>ThreadPoolExecutor</code> 的构造函数创建线程池的时候，当我们不指定 <code>RejectedExecutionHandler</code> 饱和策略的话来配置线程池的时候默认使用的是 <code>ThreadPoolExecutor.AbortPolicy</code>。在默认情况下，<code>ThreadPoolExecutor</code> 将抛出 <code>RejectedExecutionException</code> 来拒绝新来的任务 ，这代表你将丢失对这个任务的处理。 对于可伸缩的应用程序，建议使用 <code>ThreadPoolExecutor.CallerRunsPolicy</code>。当最大池被填满时，此策略为我们提供可伸缩队列。（这个直接查看 <code>ThreadPoolExecutor</code> 的构造函数源码就可以看出，比较简单的原因，这里就不贴代码了）</p>\n<h3 id=\"4-6-一个简单的线程池Demo-Runnable-ThreadPoolExecutor\"><a href=\"#4-6-一个简单的线程池Demo-Runnable-ThreadPoolExecutor\" class=\"headerlink\" title=\"4.6 一个简单的线程池Demo:Runnable+ThreadPoolExecutor\"></a>4.6 一个简单的线程池Demo:<code>Runnable</code>+<code>ThreadPoolExecutor</code></h3><p>为了让大家更清楚上面的面试题中的一些概念，我写了一个简单的线程池 Demo。</p>\n<p>首先创建一个 <code>Runnable</code> 接口的实现类（当然也可以是 <code>Callable</code> 接口，我们上面也说了两者的区别。）</p>\n<p><code>MyRunnable.java</code></p>\n<pre><code class=\"java\">import java.util.Date;\n\n/**\n * 这是一个简单的Runnable类，需要大约5秒钟来执行其任务。\n * @author shuang.kou\n */\npublic class MyRunnable implements Runnable {\n\n    private String command;\n\n    public MyRunnable(String s) {\n        this.command = s;\n    }\n\n    @Override\n    public void run() {\n        System.out.println(Thread.currentThread().getName() + &quot; Start. Time = &quot; + new Date());\n        processCommand();\n        System.out.println(Thread.currentThread().getName() + &quot; End. Time = &quot; + new Date());\n    }\n\n    private void processCommand() {\n        try {\n            Thread.sleep(5000);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n    }\n\n    @Override\n    public String toString() {\n        return this.command;\n    }\n}\n</code></pre>\n<p>编写测试程序，我们这里以阿里巴巴推荐的使用 <code>ThreadPoolExecutor</code> 构造函数自定义参数的方式来创建线程池。</p>\n<p><code>ThreadPoolExecutorDemo.java</code></p>\n<pre><code class=\"java\">import java.util.concurrent.ArrayBlockingQueue;\nimport java.util.concurrent.ThreadPoolExecutor;\nimport java.util.concurrent.TimeUnit;\n\npublic class ThreadPoolExecutorDemo {\n\n    private static final int CORE_POOL_SIZE = 5;\n    private static final int MAX_POOL_SIZE = 10;\n    private static final int QUEUE_CAPACITY = 100;\n    private static final Long KEEP_ALIVE_TIME = 1L;\n    public static void main(String[] args) {\n\n        //使用阿里巴巴推荐的创建线程池的方式\n        //通过ThreadPoolExecutor构造函数自定义参数创建\n        ThreadPoolExecutor executor = new ThreadPoolExecutor(\n                CORE_POOL_SIZE,\n                MAX_POOL_SIZE,\n                KEEP_ALIVE_TIME,\n                TimeUnit.SECONDS,\n                new ArrayBlockingQueue&lt;&gt;(QUEUE_CAPACITY),\n                new ThreadPoolExecutor.CallerRunsPolicy());\n\n        for (int i = 0; i &lt; 10; i++) {\n            //创建WorkerThread对象（WorkerThread类实现了Runnable 接口）\n            Runnable worker = new MyRunnable(&quot;&quot; + i);\n            //执行Runnable\n            executor.execute(worker);\n        }\n        //终止线程池\n        executor.shutdown();\n        while (!executor.isTerminated()) {\n        }\n        System.out.println(&quot;Finished all threads&quot;);\n    }\n}\n</code></pre>\n<p>可以看到我们上面的代码指定了：</p>\n<ol>\n<li><code>corePoolSize</code>: 核心线程数为 5。</li>\n<li><code>maximumPoolSize</code> ：最大线程数 10</li>\n<li><code>keepAliveTime</code> : 等待时间为 1L。</li>\n<li><code>unit</code>: 等待时间的单位为 TimeUnit.SECONDS。</li>\n<li><code>workQueue</code>：任务队列为 <code>ArrayBlockingQueue</code>，并且容量为 100;</li>\n<li><code>handler</code>:饱和策略为 <code>CallerRunsPolicy</code>。</li>\n</ol>\n<p><strong>Output：</strong></p>\n<pre><code>pool-1-thread-2 Start. Time = Tue Nov 12 20:59:44 CST 2019\npool-1-thread-5 Start. Time = Tue Nov 12 20:59:44 CST 2019\npool-1-thread-4 Start. Time = Tue Nov 12 20:59:44 CST 2019\npool-1-thread-1 Start. Time = Tue Nov 12 20:59:44 CST 2019\npool-1-thread-3 Start. Time = Tue Nov 12 20:59:44 CST 2019\npool-1-thread-5 End. Time = Tue Nov 12 20:59:49 CST 2019\npool-1-thread-3 End. Time = Tue Nov 12 20:59:49 CST 2019\npool-1-thread-2 End. Time = Tue Nov 12 20:59:49 CST 2019\npool-1-thread-4 End. Time = Tue Nov 12 20:59:49 CST 2019\npool-1-thread-1 End. Time = Tue Nov 12 20:59:49 CST 2019\npool-1-thread-2 Start. Time = Tue Nov 12 20:59:49 CST 2019\npool-1-thread-1 Start. Time = Tue Nov 12 20:59:49 CST 2019\npool-1-thread-4 Start. Time = Tue Nov 12 20:59:49 CST 2019\npool-1-thread-3 Start. Time = Tue Nov 12 20:59:49 CST 2019\npool-1-thread-5 Start. Time = Tue Nov 12 20:59:49 CST 2019\npool-1-thread-2 End. Time = Tue Nov 12 20:59:54 CST 2019\npool-1-thread-3 End. Time = Tue Nov 12 20:59:54 CST 2019\npool-1-thread-4 End. Time = Tue Nov 12 20:59:54 CST 2019\npool-1-thread-5 End. Time = Tue Nov 12 20:59:54 CST 2019\npool-1-thread-1 End. Time = Tue Nov 12 20:59:54 CST 2019\n</code></pre><h3 id=\"4-7-线程池原理分析\"><a href=\"#4-7-线程池原理分析\" class=\"headerlink\" title=\"4.7 线程池原理分析\"></a>4.7 线程池原理分析</h3><p>承接 4.6 节，我们通过代码输出结果可以看出：<strong>线程池每次会同时执行 5 个任务，这 5 个任务执行完之后，剩余的 5 个任务才会被执行。</strong> 大家可以先通过上面讲解的内容，分析一下到底是咋回事？（自己独立思考一会）</p>\n<p>现在，我们就分析上面的输出内容来简单分析一下线程池原理。</p>\n<p><strong>为了搞懂线程池的原理，我们需要首先分析一下 <code>execute</code>方法。</strong>在 4.6 节中的 Demo 中我们使用 <code>executor.execute(worker)</code>来提交一个任务到线程池中去，这个方法非常重要，下面我们来看看它的源码：</p>\n<pre><code class=\"java\">   // 存放线程池的运行状态 (runState) 和线程池内有效线程的数量 (workerCount)\n   private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));\n\n    private static int workerCountOf(int c) {\n        return c &amp; CAPACITY;\n    }\n\n    private final BlockingQueue&lt;Runnable&gt; workQueue;\n\n    public void execute(Runnable command) {\n        // 如果任务为null，则抛出异常。\n        if (command == null)\n            throw new NullPointerException();\n        // ctl 中保存的线程池当前的一些状态信息\n        int c = ctl.get();\n\n        //  下面会涉及到 3 步 操作\n        // 1.首先判断当前线程池中之行的任务数量是否小于 corePoolSize\n        // 如果小于的话，通过addWorker(command, true)新建一个线程，并将任务(command)添加到该线程中；然后，启动该线程从而执行任务。\n        if (workerCountOf(c) &lt; corePoolSize) {\n            if (addWorker(command, true))\n                return;\n            c = ctl.get();\n        }\n        // 2.如果当前之行的任务数量大于等于 corePoolSize 的时候就会走到这里\n        // 通过 isRunning 方法判断线程池状态，线程池处于 RUNNING 状态才会被并且队列可以加入任务，该任务才会被加入进去\n        if (isRunning(c) &amp;&amp; workQueue.offer(command)) {\n            int recheck = ctl.get();\n            // 再次获取线程池状态，如果线程池状态不是 RUNNING 状态就需要从任务队列中移除任务，并尝试判断线程是否全部执行完毕。同时执行拒绝策略。\n            if (!isRunning(recheck) &amp;&amp; remove(command))\n                reject(command);\n                // 如果当前线程池为空就新创建一个线程并执行。\n            else if (workerCountOf(recheck) == 0)\n                addWorker(null, false);\n        }\n        //3. 通过addWorker(command, false)新建一个线程，并将任务(command)添加到该线程中；然后，启动该线程从而执行任务。\n        //如果addWorker(command, false)执行失败，则通过reject()执行相应的拒绝策略的内容。\n        else if (!addWorker(command, false))\n            reject(command);\n    }</code></pre>\n<p>通过下图可以更好的对上面这 3 步做一个展示，下图是我为了省事直接从网上找到，原地址不明。</p>\n<p><img src=\"https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-7/%E5%9B%BE%E8%A7%A3%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86.png\" alt=\"图解线程池实现原理\"></p>\n<p>现在，让我们在回到 4.6 节我们写的 Demo， 现在应该是不是很容易就可以搞懂它的原理了呢？</p>\n<p>没搞懂的话，也没关系，可以看看我的分析：</p>\n<blockquote>\n<p>我们在代码中模拟了 10 个任务，我们配置的核心线程数为 5 、等待队列容量为 100 ，所以每次只可能存在 5 个任务同时执行，剩下的 5 个任务会被放到等待队列中去。当前的 5 个任务之行完成后，才会之行剩下的 5 个任务。</p>\n</blockquote>\n<h2 id=\"5-Atomic-原子类\"><a href=\"#5-Atomic-原子类\" class=\"headerlink\" title=\"5. Atomic 原子类\"></a>5. Atomic 原子类</h2><h3 id=\"5-1-介绍一下Atomic-原子类\"><a href=\"#5-1-介绍一下Atomic-原子类\" class=\"headerlink\" title=\"5.1. 介绍一下Atomic 原子类\"></a>5.1. 介绍一下Atomic 原子类</h3><p>Atomic 翻译成中文是原子的意思。在化学上，我们知道原子是构成一般物质的最小单位，在化学反应中是不可分割的。在我们这里 Atomic 是指一个操作是不可中断的。即使是在多个线程一起执行的时候，一个操作一旦开始，就不会被其他线程干扰。</p>\n<p>所以，所谓原子类说简单点就是具有原子/原子操作特征的类。</p>\n<p>并发包 <code>java.util.concurrent</code> 的原子类都存放在<code>java.util.concurrent.atomic</code>下,如下图所示。</p>\n<p><img src=\"https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/JUC%E5%8E%9F%E5%AD%90%E7%B1%BB%E6%A6%82%E8%A7%88.png\" alt=\"JUC原子类概览\"></p>\n<h3 id=\"5-2-JUC-包中的原子类是哪4类\"><a href=\"#5-2-JUC-包中的原子类是哪4类\" class=\"headerlink\" title=\"5.2. JUC 包中的原子类是哪4类?\"></a>5.2. JUC 包中的原子类是哪4类?</h3><p><strong>基本类型</strong> </p>\n<p>使用原子的方式更新基本类型</p>\n<ul>\n<li>AtomicInteger：整形原子类</li>\n<li>AtomicLong：长整型原子类</li>\n<li>AtomicBoolean：布尔型原子类</li>\n</ul>\n<p><strong>数组类型</strong></p>\n<p>使用原子的方式更新数组里的某个元素</p>\n<ul>\n<li>AtomicIntegerArray：整形数组原子类</li>\n<li>AtomicLongArray：长整形数组原子类</li>\n<li>AtomicReferenceArray：引用类型数组原子类</li>\n</ul>\n<p><strong>引用类型</strong></p>\n<ul>\n<li>AtomicReference：引用类型原子类</li>\n<li>AtomicStampedReference：原子更新引用类型里的字段原子类</li>\n<li>AtomicMarkableReference ：原子更新带有标记位的引用类型</li>\n</ul>\n<p><strong>对象的属性修改类型</strong></p>\n<ul>\n<li>AtomicIntegerFieldUpdater：原子更新整形字段的更新器</li>\n<li>AtomicLongFieldUpdater：原子更新长整形字段的更新器</li>\n<li>AtomicStampedReference：原子更新带有版本号的引用类型。该类将整数值与引用关联起来，可用于解决原子的更新数据和数据的版本号，可以解决使用 CAS 进行原子更新时可能出现的 ABA 问题。</li>\n</ul>\n<h3 id=\"5-3-讲讲-AtomicInteger-的使用\"><a href=\"#5-3-讲讲-AtomicInteger-的使用\" class=\"headerlink\" title=\"5.3. 讲讲 AtomicInteger 的使用\"></a>5.3. 讲讲 AtomicInteger 的使用</h3><p> <strong>AtomicInteger 类常用方法</strong></p>\n<pre><code class=\"java\">public final int get() //获取当前的值\npublic final int getAndSet(int newValue)//获取当前的值，并设置新的值\npublic final int getAndIncrement()//获取当前的值，并自增\npublic final int getAndDecrement() //获取当前的值，并自减\npublic final int getAndAdd(int delta) //获取当前的值，并加上预期的值\nboolean compareAndSet(int expect, int update) //如果输入的数值等于预期值，则以原子方式将该值设置为输入值（update）\npublic final void lazySet(int newValue)//最终设置为newValue,使用 lazySet 设置之后可能导致其他线程在之后的一小段时间内还是可以读到旧的值。</code></pre>\n<p> <strong>AtomicInteger 类的使用示例</strong></p>\n<p>使用 AtomicInteger 之后，不用对 increment() 方法加锁也可以保证线程安全。</p>\n<pre><code class=\"java\">class AtomicIntegerTest {\n        private AtomicInteger count = new AtomicInteger();\n      //使用AtomicInteger之后，不需要对该方法加锁，也可以实现线程安全。\n        public void increment() {\n                  count.incrementAndGet();\n        }\n\n       public int getCount() {\n                return count.get();\n        }\n}\n</code></pre>\n<h3 id=\"5-4-能不能给我简单介绍一下-AtomicInteger-类的原理\"><a href=\"#5-4-能不能给我简单介绍一下-AtomicInteger-类的原理\" class=\"headerlink\" title=\"5.4. 能不能给我简单介绍一下 AtomicInteger 类的原理\"></a>5.4. 能不能给我简单介绍一下 AtomicInteger 类的原理</h3><p>AtomicInteger 线程安全原理简单分析</p>\n<p>AtomicInteger 类的部分源码：</p>\n<pre><code class=\"java\">    // setup to use Unsafe.compareAndSwapInt for updates（更新操作时提供“比较并替换”的作用）\n    private static final Unsafe unsafe = Unsafe.getUnsafe();\n    private static final long valueOffset;\n\n    static {\n        try {\n            valueOffset = unsafe.objectFieldOffset\n                (AtomicInteger.class.getDeclaredField(&quot;value&quot;));\n        } catch (Exception ex) { throw new Error(ex); }\n    }\n\n    private volatile int value;</code></pre>\n<p>AtomicInteger 类主要利用 CAS (compare and swap) + volatile 和 native 方法来保证原子操作，从而避免 synchronized 的高开销，执行效率大为提升。</p>\n<p>CAS的原理是拿期望的值和原本的一个值作比较，如果相同则更新成新的值。UnSafe 类的 objectFieldOffset() 方法是一个本地方法，这个方法是用来拿到“原来的值”的内存地址，返回值是 valueOffset。另外 value 是一个volatile变量，在内存中可见，因此 JVM 可以保证任何时刻任何线程总能拿到该变量的最新值。</p>\n<p>关于 Atomic 原子类这部分更多内容可以查看我的这篇文章：并发编程面试必备：<a href=\"https://mp.weixin.qq.com/s/joa-yOiTrYF67bElj8xqvg\" target=\"_blank\" rel=\"noopener\">JUC 中的 Atomic 原子类总结</a></p>\n<h2 id=\"6-AQS\"><a href=\"#6-AQS\" class=\"headerlink\" title=\"6. AQS\"></a>6. AQS</h2><h3 id=\"6-1-AQS-介绍\"><a href=\"#6-1-AQS-介绍\" class=\"headerlink\" title=\"6.1. AQS 介绍\"></a>6.1. AQS 介绍</h3><p>AQS的全称为（AbstractQueuedSynchronizer），这个类在java.util.concurrent.locks包下面。</p>\n<p><img src=\"https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/AQS%E7%B1%BB.png\" alt=\"AQS类\"></p>\n<p>AQS是一个用来构建锁和同步器的框架，使用AQS能简单且高效地构造出应用广泛的大量的同步器，比如我们提到的ReentrantLock，Semaphore，其他的诸如ReentrantReadWriteLock，SynchronousQueue，FutureTask等等皆是基于AQS的。当然，我们自己也能利用AQS非常轻松容易地构造出符合我们自己需求的同步器。</p>\n<h3 id=\"6-2-AQS-原理分析\"><a href=\"#6-2-AQS-原理分析\" class=\"headerlink\" title=\"6.2. AQS 原理分析\"></a>6.2. AQS 原理分析</h3><p>AQS 原理这部分参考了部分博客，在5.2节末尾放了链接。</p>\n<blockquote>\n<p>在面试中被问到并发知识的时候，大多都会被问到“请你说一下自己对于AQS原理的理解”。下面给大家一个示例供大家参加，面试不是背题，大家一定要加入自己的思想，即使加入不了自己的思想也要保证自己能够通俗的讲出来而不是背出来。</p>\n</blockquote>\n<p>下面大部分内容其实在AQS类注释上已经给出了，不过是英语看着比较吃力一点，感兴趣的话可以看看源码。</p>\n<h4 id=\"6-2-1-AQS-原理概览\"><a href=\"#6-2-1-AQS-原理概览\" class=\"headerlink\" title=\"6.2.1. AQS 原理概览\"></a>6.2.1. AQS 原理概览</h4><p><strong>AQS核心思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制AQS是用CLH队列锁实现的，即将暂时获取不到锁的线程加入到队列中。</strong></p>\n<blockquote>\n<p>CLH(Craig,Landin,and Hagersten)队列是一个虚拟的双向队列（虚拟的双向队列即不存在队列实例，仅存在结点之间的关联关系）。AQS是将每条请求共享资源的线程封装成一个CLH锁队列的一个结点（Node）来实现锁的分配。</p>\n</blockquote>\n<p>看个AQS(AbstractQueuedSynchronizer)原理图：</p>\n<p><img src=\"https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/AQS%E5%8E%9F%E7%90%86%E5%9B%BE.png\" alt=\"AQS原理图\"></p>\n<p>AQS使用一个int成员变量来表示同步状态，通过内置的FIFO队列来完成获取资源线程的排队工作。AQS使用CAS对该同步状态进行原子操作实现对其值的修改。</p>\n<pre><code class=\"java\">private volatile int state;//共享变量，使用volatile修饰保证线程可见性</code></pre>\n<p>状态信息通过protected类型的getState，setState，compareAndSetState进行操作</p>\n<pre><code class=\"java\">\n//返回同步状态的当前值\nprotected final int getState() {  \n        return state;\n}\n // 设置同步状态的值\nprotected final void setState(int newState) { \n        state = newState;\n}\n//原子地（CAS操作）将同步状态值设置为给定值update如果当前同步状态的值等于expect（期望值）\nprotected final boolean compareAndSetState(int expect, int update) {\n        return unsafe.compareAndSwapInt(this, stateOffset, expect, update);\n}</code></pre>\n<h4 id=\"6-2-2-AQS-对资源的共享方式\"><a href=\"#6-2-2-AQS-对资源的共享方式\" class=\"headerlink\" title=\"6.2.2. AQS 对资源的共享方式\"></a>6.2.2. AQS 对资源的共享方式</h4><p><strong>AQS定义两种资源共享方式</strong></p>\n<ul>\n<li><strong>Exclusive</strong>（独占）：只有一个线程能执行，如ReentrantLock。又可分为公平锁和非公平锁：<ul>\n<li>公平锁：按照线程在队列中的排队顺序，先到者先拿到锁</li>\n<li>非公平锁：当线程要获取锁时，无视队列顺序直接去抢锁，谁抢到就是谁的</li>\n</ul>\n</li>\n<li><strong>Share</strong>（共享）：多个线程可同时执行，如Semaphore/CountDownLatch。Semaphore、CountDownLatch、 CyclicBarrier、ReadWriteLock 我们都会在后面讲到。</li>\n</ul>\n<p>ReentrantReadWriteLock 可以看成是组合式，因为ReentrantReadWriteLock也就是读写锁允许多个线程同时对某一资源进行读。</p>\n<p>不同的自定义同步器争用共享资源的方式也不同。自定义同步器在实现时只需要实现共享资源 state 的获取与释放方式即可，至于具体线程等待队列的维护（如获取资源失败入队/唤醒出队等），AQS已经在顶层实现好了。</p>\n<h4 id=\"6-2-3-AQS底层使用了模板方法模式\"><a href=\"#6-2-3-AQS底层使用了模板方法模式\" class=\"headerlink\" title=\"6.2.3. AQS底层使用了模板方法模式\"></a>6.2.3. AQS底层使用了模板方法模式</h4><p>同步器的设计是基于模板方法模式的，如果需要自定义同步器一般的方式是这样（模板方法模式很经典的一个应用）：</p>\n<ol>\n<li>使用者继承AbstractQueuedSynchronizer并重写指定的方法。（这些重写方法很简单，无非是对于共享资源state的获取和释放）</li>\n<li>将AQS组合在自定义同步组件的实现中，并调用其模板方法，而这些模板方法会调用使用者重写的方法。</li>\n</ol>\n<p>这和我们以往通过实现接口的方式有很大区别，这是模板方法模式很经典的一个运用。</p>\n<p><strong>AQS使用了模板方法模式，自定义同步器时需要重写下面几个AQS提供的模板方法：</strong></p>\n<pre><code class=\"java\">isHeldExclusively()//该线程是否正在独占资源。只有用到condition才需要去实现它。\ntryAcquire(int)//独占方式。尝试获取资源，成功则返回true，失败则返回false。\ntryRelease(int)//独占方式。尝试释放资源，成功则返回true，失败则返回false。\ntryAcquireShared(int)//共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。\ntryReleaseShared(int)//共享方式。尝试释放资源，成功则返回true，失败则返回false。\n</code></pre>\n<p>默认情况下，每个方法都抛出 <code>UnsupportedOperationException</code>。 这些方法的实现必须是内部线程安全的，并且通常应该简短而不是阻塞。AQS类中的其他方法都是final ，所以无法被其他类使用，只有这几个方法可以被其他类使用。 </p>\n<p>以ReentrantLock为例，state初始化为0，表示未锁定状态。A线程lock()时，会调用tryAcquire()独占该锁并将state+1。此后，其他线程再tryAcquire()时就会失败，直到A线程unlock()到state=0（即释放锁）为止，其它线程才有机会获取该锁。当然，释放锁之前，A线程自己是可以重复获取此锁的（state会累加），这就是可重入的概念。但要注意，获取多少次就要释放多么次，这样才能保证state是能回到零态的。</p>\n<p>再以CountDownLatch以例，任务分为N个子线程去执行，state也初始化为N（注意N要与线程个数一致）。这N个子线程是并行执行的，每个子线程执行完后countDown()一次，state会CAS(Compare and Swap)减1。等到所有子线程都执行完后(即state=0)，会unpark()主调用线程，然后主调用线程就会从await()函数返回，继续后余动作。</p>\n<p>一般来说，自定义同步器要么是独占方法，要么是共享方式，他们也只需实现<code>tryAcquire-tryRelease</code>、<code>tryAcquireShared-tryReleaseShared</code>中的一种即可。但AQS也支持自定义同步器同时实现独占和共享两种方式，如<code>ReentrantReadWriteLock</code>。</p>\n<p>推荐两篇 AQS 原理和相关源码分析的文章：</p>\n<ul>\n<li><a href=\"http://www.cnblogs.com/waterystone/p/4920797.html\" target=\"_blank\" rel=\"noopener\">http://www.cnblogs.com/waterystone/p/4920797.html</a></li>\n<li><a href=\"https://www.cnblogs.com/chengxiao/archive/2017/07/24/7141160.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/chengxiao/archive/2017/07/24/7141160.html</a></li>\n</ul>\n<h3 id=\"6-3-AQS-组件总结\"><a href=\"#6-3-AQS-组件总结\" class=\"headerlink\" title=\"6.3. AQS 组件总结\"></a>6.3. AQS 组件总结</h3><ul>\n<li><strong>Semaphore(信号量)-允许多个线程同时访问：</strong> synchronized 和 ReentrantLock 都是一次只允许一个线程访问某个资源，Semaphore(信号量)可以指定多个线程同时访问某个资源。</li>\n<li><strong>CountDownLatch （倒计时器）：</strong> CountDownLatch是一个同步工具类，用来协调多个线程之间的同步。这个工具通常用来控制线程等待，它可以让某一个线程等待直到倒计时结束，再开始执行。</li>\n<li><strong>CyclicBarrier(循环栅栏)：</strong> CyclicBarrier 和 CountDownLatch 非常类似，它也可以实现线程间的技术等待，但是它的功能比 CountDownLatch 更加复杂和强大。主要应用场景和 CountDownLatch 类似。CyclicBarrier 的字面意思是可循环使用（Cyclic）的屏障（Barrier）。它要做的事情是，让一组线程到达一个屏障（也可以叫同步点）时被阻塞，直到最后一个线程到达屏障时，屏障才会开门，所有被屏障拦截的线程才会继续干活。CyclicBarrier默认的构造方法是 CyclicBarrier(int parties)，其参数表示屏障拦截的线程数量，每个线程调用await()方法告诉 CyclicBarrier 我已经到达了屏障，然后当前线程被阻塞。</li>\n</ul>\n<h2 id=\"7-Reference\"><a href=\"#7-Reference\" class=\"headerlink\" title=\"7 Reference\"></a>7 Reference</h2><ul>\n<li>《深入理解 Java 虚拟机》</li>\n<li>《实战 Java 高并发程序设计》</li>\n<li>《Java并发编程的艺术》</li>\n<li><a href=\"http://www.cnblogs.com/waterystone/p/4920797.html\" target=\"_blank\" rel=\"noopener\">http://www.cnblogs.com/waterystone/p/4920797.html</a></li>\n<li><a href=\"https://www.cnblogs.com/chengxiao/archive/2017/07/24/7141160.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/chengxiao/archive/2017/07/24/7141160.html</a></li>\n<li><a href=\"https://www.journaldev.com/1076/java-threadlocal-example\" target=\"_blank\" rel=\"noopener\">https://www.journaldev.com/1076/java-threadlocal-example</a></li>\n</ul>\n"}],"PostAsset":[{"_id":"source/_posts/2019-05-30-kongzheng1993-生产部署illegal-character/WechatIMG1.jpeg","slug":"WechatIMG1.jpeg","post":"clg0k2ac20016t26f0eauehtf","modified":0,"renderable":0},{"_id":"source/_posts/2020-03-08-kongzheng1993-带你撸一台免费云服务器/1.png","slug":"1.png","post":"clg0k2adn0029t26fxuhl9tfz","modified":0,"renderable":0},{"_id":"source/_posts/2020-03-08-kongzheng1993-带你撸一台免费云服务器/10.png","slug":"10.png","post":"clg0k2adn0029t26fxuhl9tfz","modified":0,"renderable":0},{"_id":"source/_posts/2020-03-08-kongzheng1993-带你撸一台免费云服务器/3.png","slug":"3.png","post":"clg0k2adn0029t26fxuhl9tfz","modified":0,"renderable":0},{"_id":"source/_posts/2020-03-08-kongzheng1993-带你撸一台免费云服务器/7.png","slug":"7.png","post":"clg0k2adn0029t26fxuhl9tfz","modified":0,"renderable":0},{"_id":"source/_posts/2020-03-08-kongzheng1993-带你撸一台免费云服务器/9.png","slug":"9.png","post":"clg0k2adn0029t26fxuhl9tfz","modified":0,"renderable":0},{"_id":"source/_posts/2020-03-30-kongzheng1993-用nodejs做一个测试api服务/test.bmp","slug":"test.bmp","post":"clg0k2ae4002it26fo67pkj8c","modified":0,"renderable":0},{"_id":"source/_posts/2020-04-21-kongzheng1993-synchronized锁升级/v2-8f405804cd55a26b34d59fefc002dc08_r.jpg","slug":"v2-8f405804cd55a26b34d59fefc002dc08_r.jpg","post":"clg0k2ai1003dt26ft523oo54","modified":0,"renderable":0},{"_id":"source/_posts/2016-06-16-kongzheng1993-synchronized/1.png","slug":"1.png","post":"clg0k2abh000ht26fm0pb7gpr","modified":0,"renderable":0},{"_id":"source/_posts/2020-03-08-kongzheng1993-带你撸一台免费云服务器/13.png","slug":"13.png","post":"clg0k2adn0029t26fxuhl9tfz","modified":0,"renderable":0},{"_id":"source/_posts/2020-03-08-kongzheng1993-带你撸一台免费云服务器/8.png","slug":"8.png","post":"clg0k2adn0029t26fxuhl9tfz","modified":0,"renderable":0},{"_id":"source/_posts/2020-04-04-kongzheng1993-TCP三次握手&四次挥手/11111.png","slug":"11111.png","post":"clg0k2apn00hut26f8tbkns9e","modified":0,"renderable":0},{"_id":"source/_posts/2020-04-08-kongzheng1993-chromebook再次折腾crouton/recovery.bmp","slug":"recovery.bmp","post":"clg0k2aq200hxt26f3l518d6l","modified":0,"renderable":0},{"_id":"source/_posts/2020-04-04-kongzheng1993-TCP三次握手&四次挥手/51585999731_.pic_hd.jpg","slug":"51585999731_.pic_hd.jpg","post":"clg0k2apn00hut26f8tbkns9e","modified":0,"renderable":0},{"_id":"source/_posts/2021-07-01-kongzheng1993-springMVC消息转换器/1.jpg","slug":"1.jpg","post":"clg0k2arv00j5t26f79tb2qp2","modified":0,"renderable":0},{"_id":"source/_posts/2020-04-14-kongzheng1993-JavaObjectHeader/Java_Monitor.png","slug":"Java_Monitor.png","post":"clg0k2aek002rt26fcacispvg","modified":0,"renderable":0},{"_id":"source/_posts/2020-04-20-kongzheng1993-JVM/20170513134212845.png","slug":"20170513134212845.png","post":"clg0k2ajd003jt26fm9uuxwvy","modified":0,"renderable":0},{"_id":"source/_posts/2020-04-28-kongzheng1993-devtools/截屏2020-04-28下午6.51.22.png","slug":"截屏2020-04-28下午6.51.22.png","post":"clg0k2ajq003qt26fm252khmm","modified":0,"renderable":0},{"_id":"source/_posts/2020-04-24-kongzheng1993-SPI/v2-a4598f8b9ab46951b190cc9ce059eee0_720w.jpg","slug":"v2-a4598f8b9ab46951b190cc9ce059eee0_720w.jpg","post":"clg0k2aji003kt26fik5ktvwf","modified":0,"renderable":0},{"_id":"source/_posts/2020-04-25-kongzheng1993-死锁/v2-fccd6ccc07c0caf2643f324cdb7856e7_b.jpg","slug":"v2-fccd6ccc07c0caf2643f324cdb7856e7_b.jpg","post":"clg0k2aju003tt26fst305u6t","modified":0,"renderable":0},{"_id":"source/_posts/2020-06-29-kongzheng1993-NLP/statistical-machine-translation.png","slug":"statistical-machine-translation.png","post":"clg0k2akp004ht26fh6xq0lgb","modified":0,"renderable":0},{"_id":"source/_posts/2020-05-21-kongzheng1993-分布式事务/seata.png","slug":"seata.png","post":"clg0k2akq004lt26fzv9i9r77","modified":0,"renderable":0},{"_id":"source/_posts/2020-07-05-kongzheng1993-Java-rmi/rmi.png","slug":"rmi.png","post":"clg0k2aks004ut26f8h7jl3tj","modified":0,"renderable":0},{"_id":"source/_posts/2020-10-21-kongzheng1993-原生js实现双击复制后的思考/WechatIMG26.jpeg","slug":"WechatIMG26.jpeg","post":"clg0k2al10056t26fojh32hjb","modified":0,"renderable":0},{"_id":"source/_posts/2021-03-27-kongzheng1993-JavaRemoteDebug/idea_remote_debug.png","slug":"idea_remote_debug.png","post":"clg0k2alx006nt26flq1ztkt2","modified":0,"renderable":0},{"_id":"source/_posts/2021-04-29-kongzheng1993-getResource/IDE.png","slug":"IDE.png","post":"clg0k2aly006rt26fys80sagk","modified":0,"renderable":0},{"_id":"source/_posts/2022-03-09-kongzheng1993-包装类==的问题/Integer.png","slug":"Integer.png","post":"clg0k2amk008jt26fn0lsekaz","modified":0,"renderable":0},{"_id":"source/_posts/2021-11-29-kongzheng1993-maven_resource_plugin/20161012101735543.png","slug":"20161012101735543.png","post":"clg0k2am4007zt26f300uvrkj","modified":0,"renderable":0},{"_id":"source/_posts/2016-05-20-kongzheng1993-servlet/servlet实例化过程.jpg","slug":"servlet实例化过程.jpg","post":"clg0k2a9v0005t26fho0xkfm4","modified":0,"renderable":0},{"_id":"source/_posts/2016-05-20-kongzheng1993-servlet/servlet接口.jpg","slug":"servlet接口.jpg","post":"clg0k2a9v0005t26fho0xkfm4","modified":0,"renderable":0},{"_id":"source/_posts/2016-06-16-kongzheng1993-synchronized/fanyi.png","slug":"fanyi.png","post":"clg0k2abh000ht26fm0pb7gpr","modified":0,"renderable":0},{"_id":"source/_posts/2020-04-17-kongzheng1993-Java_Monitor/1.png","slug":"1.png","post":"clg0k2agu0033t26fqpf54ccu","modified":0,"renderable":0},{"_id":"source/_posts/2020-04-17-kongzheng1993-Java_Monitor/2.png","slug":"2.png","post":"clg0k2agu0033t26fqpf54ccu","modified":0,"renderable":0},{"_id":"source/_posts/2020-04-19-kongzheng1993-Java就是值传递的/1.jpg","slug":"1.jpg","post":"clg0k2ahn0039t26fdgst541q","modified":0,"renderable":0},{"_id":"source/_posts/2020-04-19-kongzheng1993-Java就是值传递的/2.png","slug":"2.png","post":"clg0k2ahn0039t26fdgst541q","modified":0,"renderable":0},{"_id":"source/_posts/2020-07-26-kongzheng1993-apollo/apollo-flow.png","slug":"apollo-flow.png","post":"clg0k2al40059t26fqif1l6ng","modified":0,"renderable":0},{"_id":"source/_posts/2020-07-26-kongzheng1993-apollo/overall-architecture.png","slug":"overall-architecture.png","post":"clg0k2al40059t26fqif1l6ng","modified":0,"renderable":0},{"_id":"source/_posts/2021-07-04-kongzheng1993-JVM调优/JVM.png","slug":"JVM.png","post":"clg0k2alz006wt26fd80oidjh","modified":0,"renderable":0},{"_id":"source/_posts/2021-07-04-kongzheng1993-JVM调优/stack.png","slug":"stack.png","post":"clg0k2alz006wt26fd80oidjh","modified":0,"renderable":0},{"_id":"source/_posts/2021-11-29-kongzheng1993-hs_err_pid_pid_log/飞书20211129-112140.png","slug":"飞书20211129-112140.png","post":"clg0k2am3007ut26f3d1n3ng1","modified":0,"renderable":0},{"_id":"source/_posts/2021-11-29-kongzheng1993-hs_err_pid_pid_log/飞书20211129-112155.png","slug":"飞书20211129-112155.png","post":"clg0k2am3007ut26f3d1n3ng1","modified":0,"renderable":0},{"_id":"source/_posts/2022-04-15-kongzheng1993-FastThrow/noParam.png","slug":"noParam.png","post":"clg0k2amq008rt26f7vnybqjh","modified":0,"renderable":0},{"_id":"source/_posts/2022-04-15-kongzheng1993-FastThrow/param.png","slug":"param.png","post":"clg0k2amq008rt26f7vnybqjh","modified":0,"renderable":0},{"_id":"source/_posts/2022-11-19-kongzheng1993-feign继承特性/1.png","slug":"1.png","post":"clg0k2amx009ft26fh3xbnosw","modified":0,"renderable":0},{"_id":"source/_posts/2022-11-19-kongzheng1993-feign继承特性/2.png","slug":"2.png","post":"clg0k2amx009ft26fh3xbnosw","modified":0,"renderable":0},{"_id":"source/_posts/2020-03-30-kongzheng1993-用nodejs做一个测试api服务/cnpm.bmp","slug":"cnpm.bmp","post":"clg0k2ae4002it26fo67pkj8c","modified":0,"renderable":0},{"_id":"source/_posts/2020-03-30-kongzheng1993-用nodejs做一个测试api服务/express.bmp","slug":"express.bmp","post":"clg0k2ae4002it26fo67pkj8c","modified":0,"renderable":0},{"_id":"source/_posts/2020-03-30-kongzheng1993-用nodejs做一个测试api服务/run.bmp","slug":"run.bmp","post":"clg0k2ae4002it26fo67pkj8c","modified":0,"renderable":0},{"_id":"source/_posts/2020-04-29-kongzheng1993-各种索引/1216484-20190825001255129-2032384167.png","slug":"1216484-20190825001255129-2032384167.png","post":"clg0k2ak10040t26fodpu4vaq","modified":0,"renderable":0},{"_id":"source/_posts/2020-04-29-kongzheng1993-各种索引/820365-20160721211316388-637070407.png","slug":"820365-20160721211316388-637070407.png","post":"clg0k2ak10040t26fodpu4vaq","modified":0,"renderable":0},{"_id":"source/_posts/2020-04-29-kongzheng1993-各种索引/v2-2c2264cc1c6c603dfeca4f84a2575901_r.jpg","slug":"v2-2c2264cc1c6c603dfeca4f84a2575901_r.jpg","post":"clg0k2ak10040t26fodpu4vaq","modified":0,"renderable":0},{"_id":"source/_posts/2020-04-29-kongzheng1993-各种索引/v2-5f069fd820637db1b877fdd6799a2b67_r.jpg","slug":"v2-5f069fd820637db1b877fdd6799a2b67_r.jpg","post":"clg0k2ak10040t26fodpu4vaq","modified":0,"renderable":0},{"_id":"source/_posts/2020-03-08-kongzheng1993-带你撸一台免费云服务器/11.png","slug":"11.png","post":"clg0k2adn0029t26fxuhl9tfz","modified":0,"renderable":0},{"_id":"source/_posts/2020-03-08-kongzheng1993-带你撸一台免费云服务器/12.png","slug":"12.png","post":"clg0k2adn0029t26fxuhl9tfz","modified":0,"renderable":0},{"_id":"source/_posts/2020-03-08-kongzheng1993-带你撸一台免费云服务器/2.png","slug":"2.png","post":"clg0k2adn0029t26fxuhl9tfz","modified":0,"renderable":0},{"_id":"source/_posts/2020-03-08-kongzheng1993-带你撸一台免费云服务器/5.png","slug":"5.png","post":"clg0k2adn0029t26fxuhl9tfz","modified":0,"renderable":0},{"_id":"source/_posts/2020-03-08-kongzheng1993-带你撸一台免费云服务器/6.png","slug":"6.png","post":"clg0k2adn0029t26fxuhl9tfz","modified":0,"renderable":0},{"_id":"source/_posts/2022-03-05-kongzheng1993-JVM知识点总结/Class.png","slug":"Class.png","post":"clg0k2arb00idt26f3im7va7s","modified":0,"renderable":0},{"_id":"source/_posts/2022-03-10-kongzheng1993-DDD/entity_model的副本.png","slug":"entity_model的副本.png","post":"clg0k2as300j9t26fq5g7k4yg","modified":0,"renderable":0},{"_id":"source/_posts/2023-01-30-kongzheng1993-Netty/nonBlockingIO.png","slug":"nonBlockingIO.png","post":"clg0k2arc00ift26fucipng4b","modified":0,"renderable":0},{"_id":"source/_posts/2021-07-15-kongzheng1993-MongoDB/image-20210715174420382.png","slug":"image-20210715174420382.png","post":"clg0k2ar100i8t26fs8efff96","modified":0,"renderable":0},{"_id":"source/_posts/2020-05-15-kongzheng1993-ThreadPool总结/2020-05-18 12-50-13屏幕截图.png","slug":"2020-05-18 12-50-13屏幕截图.png","post":"clg0k2aqb00i2t26fscm8v1yn","modified":0,"renderable":0},{"_id":"source/_posts/2020-05-15-kongzheng1993-Nginx/v2-e1826bab1d07df8e97d61aa809b94a10_r.jpg","slug":"v2-e1826bab1d07df8e97d61aa809b94a10_r.jpg","post":"clg0k2aqn00i5t26fwobzynza","modified":0,"renderable":0},{"_id":"source/_posts/2023-03-23-kongzheng1993-服务日志实现方式切换引起的问题/new.png","slug":"new.png","post":"clg0k2ard00ijt26fxbpizrtx","modified":0,"renderable":0},{"_id":"source/_posts/2023-03-23-kongzheng1993-服务日志实现方式切换引起的问题/old.png","slug":"old.png","post":"clg0k2ard00ijt26fxbpizrtx","modified":0,"renderable":0},{"_id":"source/_posts/2020-04-04-kongzheng1993-TCP三次握手&四次挥手/11585992522_.pic.jpg","slug":"11585992522_.pic.jpg","post":"clg0k2apn00hut26f8tbkns9e","modified":0,"renderable":0},{"_id":"source/_posts/2020-04-04-kongzheng1993-TCP三次握手&四次挥手/21585993169_.pic_hd.jpg","slug":"21585993169_.pic_hd.jpg","post":"clg0k2apn00hut26f8tbkns9e","modified":0,"renderable":0},{"_id":"source/_posts/2020-04-04-kongzheng1993-TCP三次握手&四次挥手/31585998651_.pic_hd.jpg","slug":"31585998651_.pic_hd.jpg","post":"clg0k2apn00hut26f8tbkns9e","modified":0,"renderable":0},{"_id":"source/_posts/2020-04-04-kongzheng1993-TCP三次握手&四次挥手/41585998713_.pic_hd.jpg","slug":"41585998713_.pic_hd.jpg","post":"clg0k2apn00hut26f8tbkns9e","modified":0,"renderable":0},{"_id":"source/_posts/2020-04-08-kongzheng1993-chromebook再次折腾crouton/finishInstall.jpg","slug":"finishInstall.jpg","post":"clg0k2aq200hxt26f3l518d6l","modified":0,"renderable":0},{"_id":"source/_posts/2020-04-08-kongzheng1993-chromebook再次折腾crouton/kaliLinux.png","slug":"kaliLinux.png","post":"clg0k2aq200hxt26f3l518d6l","modified":0,"renderable":0},{"_id":"source/_posts/2020-04-08-kongzheng1993-chromebook再次折腾crouton/linuxRelease.jpg","slug":"linuxRelease.jpg","post":"clg0k2aq200hxt26f3l518d6l","modified":0,"renderable":0},{"_id":"source/_posts/2020-04-08-kongzheng1993-chromebook再次折腾crouton/taobao.jpg","slug":"taobao.jpg","post":"clg0k2aq200hxt26f3l518d6l","modified":0,"renderable":0},{"_id":"source/_posts/2020-04-08-kongzheng1993-chromebook再次折腾crouton/xfce4.jpg","slug":"xfce4.jpg","post":"clg0k2aq200hxt26f3l518d6l","modified":0,"renderable":0},{"_id":"source/_posts/2023-01-30-kongzheng1993-Netty/EventLoop.png","slug":"EventLoop.png","post":"clg0k2arc00ift26fucipng4b","modified":0,"renderable":0},{"_id":"source/_posts/2023-01-30-kongzheng1993-Netty/Reactor.png","slug":"Reactor.png","post":"clg0k2arc00ift26fucipng4b","modified":0,"renderable":0},{"_id":"source/_posts/2023-01-30-kongzheng1993-Netty/asyncIO.png","slug":"asyncIO.png","post":"clg0k2arc00ift26fucipng4b","modified":0,"renderable":0},{"_id":"source/_posts/2023-01-30-kongzheng1993-Netty/blockingIO.png","slug":"blockingIO.png","post":"clg0k2arc00ift26fucipng4b","modified":0,"renderable":0},{"_id":"source/_posts/2023-01-30-kongzheng1993-Netty/channel.png","slug":"channel.png","post":"clg0k2arc00ift26fucipng4b","modified":0,"renderable":0},{"_id":"source/_posts/2023-01-30-kongzheng1993-Netty/handler.png","slug":"handler.png","post":"clg0k2arc00ift26fucipng4b","modified":0,"renderable":0},{"_id":"source/_posts/2023-01-30-kongzheng1993-Netty/man2kqueue.png","slug":"man2kqueue.png","post":"clg0k2arc00ift26fucipng4b","modified":0,"renderable":0},{"_id":"source/_posts/2023-01-30-kongzheng1993-Netty/man2select.png","slug":"man2select.png","post":"clg0k2arc00ift26fucipng4b","modified":0,"renderable":0},{"_id":"source/_posts/2023-01-30-kongzheng1993-Netty/multiplexing.png","slug":"multiplexing.png","post":"clg0k2arc00ift26fucipng4b","modified":0,"renderable":0},{"_id":"source/_posts/2023-01-30-kongzheng1993-Netty/netty_reactor.png","slug":"netty_reactor.png","post":"clg0k2arc00ift26fucipng4b","modified":0,"renderable":0},{"_id":"source/_posts/2022-03-10-kongzheng1993-DDD/entity_model.png","slug":"entity_model.png","post":"clg0k2as300j9t26fq5g7k4yg","modified":0,"renderable":0},{"_id":"source/_posts/2021-07-01-kongzheng1993-springMVC消息转换器/2.jpg","slug":"2.jpg","post":"clg0k2arv00j5t26f79tb2qp2","modified":0,"renderable":0},{"_id":"source/_posts/2021-07-01-kongzheng1993-springMVC消息转换器/3.jpg","slug":"3.jpg","post":"clg0k2arv00j5t26f79tb2qp2","modified":0,"renderable":0},{"_id":"source/_posts/2018-06-08-kongzheng1993-java多线程总结/20150309140927553.jpeg","slug":"20150309140927553.jpeg","post":"clg0k2aza00jtt26fwe3ur7d3","modified":0,"renderable":0}],"PostCategory":[{"post_id":"clg0k2ac20016t26f0eauehtf","category_id":"clg0k2acj001lt26fy872xsu7","_id":"clg0k2ada001xt26fclvapxsy"},{"post_id":"clg0k2ac3001at26frlrtdk5c","category_id":"clg0k2acx001tt26f81m22ixl","_id":"clg0k2adk0022t26figzp7i9l"},{"post_id":"clg0k2ac00011t26fppgdnx4m","category_id":"clg0k2ac30017t26fjt58hkz7","_id":"clg0k2adm0027t26f37sc1kgr"},{"post_id":"clg0k2ac00011t26fppgdnx4m","category_id":"clg0k2ada001yt26flpge9yoz","_id":"clg0k2adn002bt26f3989o1vs"},{"post_id":"clg0k2acf001kt26ftqr9zz50","category_id":"clg0k2ae4002jt26fbrjwekvu","_id":"clg0k2afy002wt26f6d2i9umn"},{"post_id":"clg0k2aby000xt26fa5tclbdf","category_id":"clg0k2ac00010t26f6gsknie7","_id":"clg0k2agt0032t26fladrkb4t"},{"post_id":"clg0k2aby000xt26fa5tclbdf","category_id":"clg0k2ac6001gt26fhvt0dzxx","_id":"clg0k2ah70035t26fvfgomdgv"},{"post_id":"clg0k2aby000xt26fa5tclbdf","category_id":"clg0k2aeb002qt26fmrekq8cw","_id":"clg0k2ahm0038t26fs5jp14f0"},{"post_id":"clg0k2acm001st26fti0sj2ba","category_id":"clg0k2agt0031t26faz9he24d","_id":"clg0k2aiv003gt26fg4x29990"},{"post_id":"clg0k2ai1003dt26ft523oo54","category_id":"clg0k2ahp003at26fpnz24slm","_id":"clg0k2aji003lt26fuxxnarwl"},{"post_id":"clg0k2ad4001vt26f2e5xqk3d","category_id":"clg0k2ahp003at26fpnz24slm","_id":"clg0k2ajm003ot26fzi0awsdq"},{"post_id":"clg0k2ajd003jt26fm9uuxwvy","category_id":"clg0k2ahp003at26fpnz24slm","_id":"clg0k2ajr003rt26fbqno497d"},{"post_id":"clg0k2ad9001wt26f8r2mvodp","category_id":"clg0k2ahp003at26fpnz24slm","_id":"clg0k2aju003ut26fv4d1fdwn"},{"post_id":"clg0k2aji003kt26fik5ktvwf","category_id":"clg0k2ahp003at26fpnz24slm","_id":"clg0k2ajy003xt26f1lqbwa2v"},{"post_id":"clg0k2ada0020t26fvjyyypwr","category_id":"clg0k2aji003mt26f307upm7q","_id":"clg0k2ak10041t26f9c69u6zh"},{"post_id":"clg0k2ajq003qt26fm252khmm","category_id":"clg0k2ahp003at26fpnz24slm","_id":"clg0k2ak50045t26f8kdyd8zu"},{"post_id":"clg0k2adb0021t26fntuez238","category_id":"clg0k2aji003mt26f307upm7q","_id":"clg0k2ak90049t26fy1cxtty7"},{"post_id":"clg0k2ajy003wt26f7xyyoyyr","category_id":"clg0k2ahp003at26fpnz24slm","_id":"clg0k2ake004dt26fjakmq7fw"},{"post_id":"clg0k2adl0024t26fzx9xc7s9","category_id":"clg0k2ak1003zt26ftyp73z3i","_id":"clg0k2akp004gt26fbunxbdom"},{"post_id":"clg0k2adm0026t26f9iuzoj7b","category_id":"clg0k2ahp003at26fpnz24slm","_id":"clg0k2akq004jt26f4nhzwlws"},{"post_id":"clg0k2adn0029t26fxuhl9tfz","category_id":"clg0k2akr004mt26f9679pdbx","_id":"clg0k2akw004yt26fk8j4wgx7"},{"post_id":"clg0k2adn002ct26fbii4b5z1","category_id":"clg0k2ahp003at26fpnz24slm","_id":"clg0k2al00053t26fi3r99xfx"},{"post_id":"clg0k2akw004wt26f62rqecp9","category_id":"clg0k2ac00010t26f6gsknie7","_id":"clg0k2al30057t26fsqghejmu"},{"post_id":"clg0k2akx0050t26fv740cypa","category_id":"clg0k2akr004mt26f9679pdbx","_id":"clg0k2al5005bt26fuzqj1e6n"},{"post_id":"clg0k2ac10014t26fxr065v9i","category_id":"clg0k2ac5001ct26f6v9sbmzs","_id":"clg0k2al6005ft26feg4qvnrb"},{"post_id":"clg0k2ac10014t26fxr065v9i","category_id":"clg0k2adm0028t26fznptrq8i","_id":"clg0k2ala005ht26fbid7rfuf"},{"post_id":"clg0k2ac10014t26fxr065v9i","category_id":"clg0k2akw004xt26fsya5p6yw","_id":"clg0k2alc005lt26fgfp4llqo"},{"post_id":"clg0k2akx0052t26f9yztkweh","category_id":"clg0k2ahp003at26fpnz24slm","_id":"clg0k2ale005nt26f8ogalohc"},{"post_id":"clg0k2ado002dt26fq7n6ir8m","category_id":"clg0k2ahp003at26fpnz24slm","_id":"clg0k2alf005rt26f9bkkkxsc"},{"post_id":"clg0k2ae3002gt26fmj9inlg9","category_id":"clg0k2al5005ct26fl0zdngfe","_id":"clg0k2alg005ut26f42oxnu6n"},{"post_id":"clg0k2alf005pt26fd823ftxy","category_id":"clg0k2al5005ct26fl0zdngfe","_id":"clg0k2alo0061t26fqllcw3qu"},{"post_id":"clg0k2ae4002it26fo67pkj8c","category_id":"clg0k2alf005qt26fyutmonz1","_id":"clg0k2alp0066t26fel0s989e"},{"post_id":"clg0k2ali005xt26fumef1my1","category_id":"clg0k2al5005ct26fl0zdngfe","_id":"clg0k2alp0068t26f1052v27r"},{"post_id":"clg0k2ae5002mt26f3lbdtea0","category_id":"clg0k2ahp003at26fpnz24slm","_id":"clg0k2alv006bt26fkbyvskwr"},{"post_id":"clg0k2alo0063t26fz5c18acl","category_id":"clg0k2ahp003at26fpnz24slm","_id":"clg0k2alw006ft26f7zyijcxt"},{"post_id":"clg0k2alp0067t26fgp718a9d","category_id":"clg0k2ahp003at26fpnz24slm","_id":"clg0k2alx006jt26f1u9je9i8"},{"post_id":"clg0k2ae5002ot26fukqznvri","category_id":"clg0k2ahp003at26fpnz24slm","_id":"clg0k2alx006mt26f51xj4ijo"},{"post_id":"clg0k2als0069t26f4qf1nwab","category_id":"clg0k2ahp003at26fpnz24slm","_id":"clg0k2aly006ot26frpzwquvq"},{"post_id":"clg0k2alw006dt26fq65wxvyt","category_id":"clg0k2ahp003at26fpnz24slm","_id":"clg0k2aly006st26fjgh455r3"},{"post_id":"clg0k2aek002rt26fcacispvg","category_id":"clg0k2ahp003at26fpnz24slm","_id":"clg0k2alz006ut26f3kmtw10m"},{"post_id":"clg0k2alx006lt26fm6snn2z9","category_id":"clg0k2ahp003at26fpnz24slm","_id":"clg0k2alz006yt26fbsfzd2f2"},{"post_id":"clg0k2afe002ut26f8818sn1e","category_id":"clg0k2alx006it26fyi4qi6uz","_id":"clg0k2alz0071t26fq99mo5n1"},{"post_id":"clg0k2alx006nt26flq1ztkt2","category_id":"clg0k2ahp003at26fpnz24slm","_id":"clg0k2am00075t26fdgh57mtk"},{"post_id":"clg0k2ag3002yt26fpkui29gr","category_id":"clg0k2ahp003at26fpnz24slm","_id":"clg0k2am00079t26fpg1vv5pz"},{"post_id":"clg0k2agn0030t26ffp0qo0cu","category_id":"clg0k2alx006it26fyi4qi6uz","_id":"clg0k2am1007ct26f360jby1v"},{"post_id":"clg0k2am00074t26fz68b8ogr","category_id":"clg0k2ahp003at26fpnz24slm","_id":"clg0k2am1007ft26f4uyil79p"},{"post_id":"clg0k2acl001qt26fpykbpbv0","category_id":"clg0k2acx001tt26f81m22ixl","_id":"clg0k2am2007jt26fq35hk50w"},{"post_id":"clg0k2acl001qt26fpykbpbv0","category_id":"clg0k2alz0072t26fpp2w41z6","_id":"clg0k2am2007nt26fomlb3j3u"},{"post_id":"clg0k2am0007bt26fza8oop1z","category_id":"clg0k2ahp003at26fpnz24slm","_id":"clg0k2am3007qt26fbqenbp44"},{"post_id":"clg0k2agu0033t26fqpf54ccu","category_id":"clg0k2ahp003at26fpnz24slm","_id":"clg0k2am3007tt26fj9rm3e47"},{"post_id":"clg0k2ah90036t26fbe2neeb6","category_id":"clg0k2am1007ht26fhfklscr2","_id":"clg0k2am3007wt26f60j2z097"},{"post_id":"clg0k2am3007rt26fa515kbuo","category_id":"clg0k2ahp003at26fpnz24slm","_id":"clg0k2am40080t26fcpa9crfa"},{"post_id":"clg0k2ahn0039t26fdgst541q","category_id":"clg0k2ahp003at26fpnz24slm","_id":"clg0k2amc0083t26fvpyj0r39"},{"post_id":"clg0k2ain003ft26ftr9z1yku","category_id":"clg0k2am3007vt26fy0mrre88","_id":"clg0k2amf0086t26fzzsicikm"},{"post_id":"clg0k2am80082t26ff06z2d7a","category_id":"clg0k2acx001tt26f81m22ixl","_id":"clg0k2amg008dt26fwmq3cruo"},{"post_id":"clg0k2ajl003nt26f1387vxd4","category_id":"clg0k2am60081t26fis59zt49","_id":"clg0k2ami008ht26fo7x07vsq"},{"post_id":"clg0k2amf0089t26fsbac5mw4","category_id":"clg0k2al5005ct26fl0zdngfe","_id":"clg0k2amo008kt26f3t7paur9"},{"post_id":"clg0k2aju003tt26fst305u6t","category_id":"clg0k2am60081t26fis59zt49","_id":"clg0k2amp008pt26f5ykw5wb9"},{"post_id":"clg0k2amg008ct26fipfg07e6","category_id":"clg0k2acx001tt26f81m22ixl","_id":"clg0k2amq008st26fq2zlvb0j"},{"post_id":"clg0k2ak10040t26fodpu4vaq","category_id":"clg0k2amg008ft26fhig3jcrh","_id":"clg0k2amq008xt26fyxnf857q"},{"post_id":"clg0k2ak50044t26fjh3rijd0","category_id":"clg0k2am3007vt26fy0mrre88","_id":"clg0k2amr0091t26fur9akj5q"},{"post_id":"clg0k2ak80048t26f03zs5gk2","category_id":"clg0k2amq008vt26fuqwhvcuy","_id":"clg0k2amt0099t26fc9ta2x4a"},{"post_id":"clg0k2amr0092t26f1ufvokun","category_id":"clg0k2ahp003at26fpnz24slm","_id":"clg0k2amw009dt26fukvm0xkm"},{"post_id":"clg0k2ams0095t26f3zaj3yqb","category_id":"clg0k2ahp003at26fpnz24slm","_id":"clg0k2amz009gt26fiq8cf8on"},{"post_id":"clg0k2ake004ct26f2miap5hq","category_id":"clg0k2ams0093t26f5sk60foc","_id":"clg0k2an0009kt26fe479ymr1"},{"post_id":"clg0k2amt009ct26flwfrnvwi","category_id":"clg0k2ahp003at26fpnz24slm","_id":"clg0k2an0009ot26fwowo9cog"},{"post_id":"clg0k2akl004ft26f40unky7l","category_id":"clg0k2amt009at26fb913q9th","_id":"clg0k2an0009st26fpir4v227"},{"post_id":"clg0k2akp004ht26fh6xq0lgb","category_id":"clg0k2amz009it26fzr966jlm","_id":"clg0k2an1009vt26fkg61rkgn"},{"post_id":"clg0k2an0009nt26fgy2atepz","category_id":"clg0k2ahp003at26fpnz24slm","_id":"clg0k2an1009yt26fltm88nfo"},{"post_id":"clg0k2ac4001bt26f1mr6ck8s","category_id":"clg0k2adk0023t26fmdya3cv3","_id":"clg0k2an100a0t26fvvlzhtq9"},{"post_id":"clg0k2ac4001bt26f1mr6ck8s","category_id":"clg0k2akk004et26faecgwxyv","_id":"clg0k2an100a3t26ftt305nut"},{"post_id":"clg0k2ac4001bt26f1mr6ck8s","category_id":"clg0k2an0009qt26ff679e6nq","_id":"clg0k2an200a5t26f19iixkf6"},{"post_id":"clg0k2akq004lt26fzv9i9r77","category_id":"clg0k2an1009xt26fdujsauis","_id":"clg0k2an200a8t26f9rnfmcxt"},{"post_id":"clg0k2akr004ot26f3nm38b9g","category_id":"clg0k2an100a2t26fc63ycuun","_id":"clg0k2an200act26fm3kbqdxm"},{"post_id":"clg0k2akr004rt26fh6yirhwd","category_id":"clg0k2amt009at26fb913q9th","_id":"clg0k2an300aft26fms641utn"},{"post_id":"clg0k2aks004ut26f8h7jl3tj","category_id":"clg0k2an100a2t26fc63ycuun","_id":"clg0k2an300ait26fcojvmk40"},{"post_id":"clg0k2al10056t26fojh32hjb","category_id":"clg0k2an300aet26fnzd6jt3q","_id":"clg0k2an300ant26fzm0nlpt8"},{"post_id":"clg0k2al40059t26fqif1l6ng","category_id":"clg0k2an1009xt26fdujsauis","_id":"clg0k2an400aqt26f9okkkcpy"},{"post_id":"clg0k2al5005et26fieo9h7sq","category_id":"clg0k2an300amt26fn2ilk4bm","_id":"clg0k2an400avt26f6237g01u"},{"post_id":"clg0k2al7005gt26f20a807e6","category_id":"clg0k2an400ast26flqs58qag","_id":"clg0k2an400azt26fr5bh3ecv"},{"post_id":"clg0k2ala005kt26fw65uyg2x","category_id":"clg0k2an400awt26fjt21cw8h","_id":"clg0k2an900b3t26fa3rxlfo0"},{"post_id":"clg0k2ald005mt26f5dc7tesq","category_id":"clg0k2an400b0t26f1nks67np","_id":"clg0k2ane00b7t26f5kv208il"},{"post_id":"clg0k2alg005tt26f1hin0ad0","category_id":"clg0k2ane00b8t26f39apzduj","_id":"clg0k2anf00bet26f9ruxsmz5"},{"post_id":"clg0k2alo0060t26f301wqmii","category_id":"clg0k2anf00bbt26fnmgw8ja6","_id":"clg0k2ang00bit26f9by1si8m"},{"post_id":"clg0k2alw006gt26f29jlsiz0","category_id":"clg0k2anf00bft26fttrxdcyp","_id":"clg0k2anj00bnt26frqptawff"},{"post_id":"clg0k2aly006rt26fys80sagk","category_id":"clg0k2ane00b8t26f39apzduj","_id":"clg0k2ank00bqt26fskunvgca"},{"post_id":"clg0k2aly006tt26f6wx9xa44","category_id":"clg0k2anj00bmt26f6xqdilr4","_id":"clg0k2ank00but26fytybddhs"},{"post_id":"clg0k2alz006wt26fd80oidjh","category_id":"clg0k2ank00bst26fles16vjf","_id":"clg0k2ank00c0t26fgphsbs8k"},{"post_id":"clg0k2alz0070t26foj5n91h9","category_id":"clg0k2amg008ft26fhig3jcrh","_id":"clg0k2anl00c3t26fp4au418e"},{"post_id":"clg0k2am00078t26fplvndi5t","category_id":"clg0k2ank00bzt26fbxs72e41","_id":"clg0k2anl00c8t26fgyz7xkv8"},{"post_id":"clg0k2am1007et26fa5p3ag88","category_id":"clg0k2an400awt26fjt21cw8h","_id":"clg0k2anl00cbt26fvp5nhd41"},{"post_id":"clg0k2am1007it26ffjby2ibe","category_id":"clg0k2anl00c7t26fxgnwsm4z","_id":"clg0k2anm00cgt26frnp2vdjs"},{"post_id":"clg0k2am2007mt26fv3uqirp1","category_id":"clg0k2an400awt26fjt21cw8h","_id":"clg0k2anm00ckt26fn9elm9gk"},{"post_id":"clg0k2am2007ot26fyzcfe5ry","category_id":"clg0k2an400awt26fjt21cw8h","_id":"clg0k2anm00cmt26fpvl7x9ff"},{"post_id":"clg0k2am3007ut26f3d1n3ng1","category_id":"clg0k2an400awt26fjt21cw8h","_id":"clg0k2ann00crt26ffkdp8q4q"},{"post_id":"clg0k2am3007xt26f3jwg1hed","category_id":"clg0k2an400awt26fjt21cw8h","_id":"clg0k2ann00ctt26fovvf8rh4"},{"post_id":"clg0k2am4007zt26f300uvrkj","category_id":"clg0k2ann00cqt26fdrj4s7jq","_id":"clg0k2ann00czt26fdf22v81x"},{"post_id":"clg0k2amd0085t26fotwp1uru","category_id":"clg0k2an400awt26fjt21cw8h","_id":"clg0k2ano00d3t26f6topp1x9"},{"post_id":"clg0k2amg008gt26f40jhfyif","category_id":"clg0k2an100a2t26fc63ycuun","_id":"clg0k2ano00d6t26f5bu6fz3y"},{"post_id":"clg0k2amk008jt26fn0lsekaz","category_id":"clg0k2ane00b8t26f39apzduj","_id":"clg0k2ano00dbt26f46r30yi5"},{"post_id":"clg0k2amp008ot26f2zjr6ibs","category_id":"clg0k2an400ast26flqs58qag","_id":"clg0k2anp00dft26fwlww0r99"},{"post_id":"clg0k2amq008rt26f7vnybqjh","category_id":"clg0k2ank00bst26fles16vjf","_id":"clg0k2anp00dit26fuk7ahj3i"},{"post_id":"clg0k2amq008wt26f55zujceo","category_id":"clg0k2anp00det26fvolyusqi","_id":"clg0k2anp00dmt26fiybyetwv"},{"post_id":"clg0k2amr008zt26feqgiett2","category_id":"clg0k2anp00djt26fxlsv4j7n","_id":"clg0k2anq00drt26fh2cfmar6"},{"post_id":"clg0k2amt0098t26f5ujmwi8f","category_id":"clg0k2anp00djt26fxlsv4j7n","_id":"clg0k2anq00dut26f52jodsa5"},{"post_id":"clg0k2amx009ft26fh3xbnosw","category_id":"clg0k2anq00dqt26fki3nzawh","_id":"clg0k2anq00dyt26furgp9tqb"},{"post_id":"clg0k2amz009jt26fcaqshlxj","category_id":"clg0k2anq00dvt26ftc3bi4w1","_id":"clg0k2anr00e2t26ffrkoxm7f"},{"post_id":"clg0k2an0009rt26fuizbv8go","category_id":"clg0k2anq00dzt26fwdd3d93b","_id":"clg0k2anr00e6t26fpgo377ss"},{"post_id":"clg0k2ac6001ht26fzgt2ggl9","category_id":"clg0k2ae1002et26fdhe7glqe","_id":"clg0k2ans00eet26fo3ufv8kb"},{"post_id":"clg0k2ac6001ht26fzgt2ggl9","category_id":"clg0k2ala005jt26fq7njzfix","_id":"clg0k2ans00egt26fvze5sajz"},{"post_id":"clg0k2ac6001ht26fzgt2ggl9","category_id":"clg0k2an900b4t26fqql8bck0","_id":"clg0k2ans00eht26fwin1n6q2"},{"post_id":"clg0k2ac6001ht26fzgt2ggl9","category_id":"clg0k2anr00e7t26f5tb3num7","_id":"clg0k2ans00ekt26f0glw431y"},{"post_id":"clg0k2an1009tt26fgep1l2vf","category_id":"clg0k2anr00e3t26fdf8jqml9","_id":"clg0k2ans00elt26f6pese6y0"},{"post_id":"clg0k2an1009tt26fgep1l2vf","category_id":"clg0k2anr00ebt26f4n9gkpd0","_id":"clg0k2ans00eot26f2itxlokx"},{"post_id":"clg0k2aog00hct26fsr149y42","category_id":"clg0k2aor00het26fjyz9u7iu","_id":"clg0k2ape00hrt26fh0l78ddv"},{"post_id":"clg0k2aou00hkt26fbyn9gewu","category_id":"clg0k2acx001tt26f81m22ixl","_id":"clg0k2apo00hvt26fpstdskbe"},{"post_id":"clg0k2aov00hot26fpkth3z3s","category_id":"clg0k2al5005ct26fl0zdngfe","_id":"clg0k2aq300hyt26fny8k1udj"},{"post_id":"clg0k2apb00hqt26ff1sxdw6z","category_id":"clg0k2ahp003at26fpnz24slm","_id":"clg0k2aqb00i3t26fu6wc3ty9"},{"post_id":"clg0k2aou00hit26f1qbykpdj","category_id":"clg0k2aov00hmt26fd64s8myq","_id":"clg0k2aqo00i6t26f3qgzc81b"},{"post_id":"clg0k2aq200hxt26f3l518d6l","category_id":"clg0k2akr004mt26f9679pdbx","_id":"clg0k2ar400iat26fde9hw11a"},{"post_id":"clg0k2apn00hut26f8tbkns9e","category_id":"clg0k2aqa00hzt26f37amzu08","_id":"clg0k2arc00igt26f0zlf0kjx"},{"post_id":"clg0k2arb00idt26f3im7va7s","category_id":"clg0k2ank00bst26fles16vjf","_id":"clg0k2are00imt26f7mijfqql"},{"post_id":"clg0k2aqb00i2t26fscm8v1yn","category_id":"clg0k2ahp003at26fpnz24slm","_id":"clg0k2are00ipt26f5h55ngap"},{"post_id":"clg0k2aqb00i2t26fscm8v1yn","category_id":"clg0k2ar400i9t26f5slmreaj","_id":"clg0k2are00ist26fgdhsd2mh"},{"post_id":"clg0k2arc00ift26fucipng4b","category_id":"clg0k2anq00dzt26fwdd3d93b","_id":"clg0k2arh00ivt26fb680enaf"},{"post_id":"clg0k2aqn00i5t26fwobzynza","category_id":"clg0k2ard00iht26fvo68ayqx","_id":"clg0k2ari00ixt26fw7xhavfi"},{"post_id":"clg0k2ar100i8t26fs8efff96","category_id":"clg0k2are00int26fvcu5zyts","_id":"clg0k2ari00izt26fswa8nobz"},{"post_id":"clg0k2ard00ijt26fxbpizrtx","category_id":"clg0k2anr00e3t26fdf8jqml9","_id":"clg0k2ari00j2t26fmmvr1eo4"},{"post_id":"clg0k2ard00ijt26fxbpizrtx","category_id":"clg0k2are00itt26fxrprdisl","_id":"clg0k2ari00j3t26ffk07xh57"},{"post_id":"clg0k2arv00j6t26fsovu8omk","category_id":"clg0k2ahp003at26fpnz24slm","_id":"clg0k2asc00jbt26fhpxz6qs5"},{"post_id":"clg0k2arv00j5t26f79tb2qp2","category_id":"clg0k2as200j7t26f1ea0xulv","_id":"clg0k2asc00jft26fh15vgaj6"},{"post_id":"clg0k2as300j9t26fq5g7k4yg","category_id":"clg0k2asc00jct26fiijbs3hw","_id":"clg0k2asc00jht26fwu134xej"},{"post_id":"clg0k2asi00jit26fhbnyicb9","category_id":"clg0k2asm00jjt26fzlwjusb1","_id":"clg0k2atu00jmt26fmepqm82f"},{"post_id":"clg0k2aui00jnt26f0dgd6e3s","category_id":"clg0k2amg008ft26fhig3jcrh","_id":"clg0k2auz00jrt26f3v3mcjwm"},{"post_id":"clg0k2auo00jot26fsllxnm0z","category_id":"clg0k2an400awt26fjt21cw8h","_id":"clg0k2av400jst26f2xs4achz"},{"post_id":"clg0k2aza00jtt26fwe3ur7d3","category_id":"clg0k2an100a2t26fc63ycuun","_id":"clg0k2aze00jvt26fycup5zwl"}],"PostTag":[{"post_id":"clg0k2a8h0000t26f9smaxe1z","tag_id":"clg0k2a9r0002t26fe9gbrkq9","_id":"clg0k2aa50007t26fdcacacz4"},{"post_id":"clg0k2aa60008t26f4hhze9x0","tag_id":"clg0k2a9r0002t26fe9gbrkq9","_id":"clg0k2aav000bt26f0g5k8qh7"},{"post_id":"clg0k2a9l0001t26fq3yke2gi","tag_id":"clg0k2a9r0002t26fe9gbrkq9","_id":"clg0k2ab0000dt26fal2cpequ"},{"post_id":"clg0k2a9t0003t26fg296edr5","tag_id":"clg0k2a9r0002t26fe9gbrkq9","_id":"clg0k2abg000gt26fu6d9k08y"},{"post_id":"clg0k2a9u0004t26f6eb76x5t","tag_id":"clg0k2ab8000ft26f7rz103xh","_id":"clg0k2abl000lt26fuh9wcmwn"},{"post_id":"clg0k2a9v0005t26fho0xkfm4","tag_id":"clg0k2abl000jt26fb024tidq","_id":"clg0k2abn000pt26fm0vp7unl"},{"post_id":"clg0k2abm000ot26fp84nuwku","tag_id":"clg0k2a9r0002t26fe9gbrkq9","_id":"clg0k2abn000rt26ftldt5t7e"},{"post_id":"clg0k2aad0009t26f1kp4vfnf","tag_id":"clg0k2abm000nt26f2pu8d1cr","_id":"clg0k2abo000ut26fnjp5cbnp"},{"post_id":"clg0k2abn000tt26fm3qwemjv","tag_id":"clg0k2a9r0002t26fe9gbrkq9","_id":"clg0k2abx000wt26fnxcmt666"},{"post_id":"clg0k2abz000zt26fhx2k3evc","tag_id":"clg0k2abm000nt26f2pu8d1cr","_id":"clg0k2ac10013t26f79f2585j"},{"post_id":"clg0k2aaw000ct26fc374fm3g","tag_id":"clg0k2abn000st26fpq4tm6ed","_id":"clg0k2ac20015t26fnz8o726r"},{"post_id":"clg0k2aaw000ct26fc374fm3g","tag_id":"clg0k2aby000yt26fxoh828bg","_id":"clg0k2ac30019t26frtiltfn4"},{"post_id":"clg0k2ab0000et26fvf3zt23d","tag_id":"clg0k2ac10012t26fej9vf7aq","_id":"clg0k2ace001jt26f5gk083lm"},{"post_id":"clg0k2ab0000et26fvf3zt23d","tag_id":"clg0k2ac30018t26fvdb4jwaq","_id":"clg0k2acj001mt26fa73kkxlr"},{"post_id":"clg0k2ab0000et26fvf3zt23d","tag_id":"clg0k2ac5001dt26f8g8q2sg5","_id":"clg0k2acl001pt26fehk6v3ds"},{"post_id":"clg0k2abk000it26fkjqdv0bd","tag_id":"clg0k2ac7001it26f12ut8n9a","_id":"clg0k2acm001rt26f3dm9ukrz"},{"post_id":"clg0k2abl000kt26fdpdzy47w","tag_id":"clg0k2ack001ot26fxc7jnocf","_id":"clg0k2ae3002ht26ftjaxlsnv"},{"post_id":"clg0k2abl000kt26fdpdzy47w","tag_id":"clg0k2acz001ut26f2rl4mvuh","_id":"clg0k2ae4002kt26fu79c8wv6"},{"post_id":"clg0k2abl000kt26fdpdzy47w","tag_id":"clg0k2ada001zt26fgzzd1oiy","_id":"clg0k2ae5002nt26foiwgyb93"},{"post_id":"clg0k2abl000kt26fdpdzy47w","tag_id":"clg0k2adl0025t26fmxl5p8ji","_id":"clg0k2ae6002pt26f3w08wxkf"},{"post_id":"clg0k2abl000kt26fdpdzy47w","tag_id":"clg0k2adn002at26f79o6u6w1","_id":"clg0k2aep002tt26fbdky8hzi"},{"post_id":"clg0k2abl000mt26fwgstu05j","tag_id":"clg0k2ae2002ft26fmqh19q16","_id":"clg0k2afg002vt26fjfa9n6uc"},{"post_id":"clg0k2abn000qt26ftv65xhc8","tag_id":"clg0k2ae4002lt26fee5o762a","_id":"clg0k2ahb0037t26fu3y8i6kb"},{"post_id":"clg0k2abn000qt26ftv65xhc8","tag_id":"clg0k2aep002st26fc50irk2r","_id":"clg0k2ahq003bt26fv1ew6r8r"},{"post_id":"clg0k2abn000qt26ftv65xhc8","tag_id":"clg0k2ack001ot26fxc7jnocf","_id":"clg0k2ai4003et26fg0biy5b2"},{"post_id":"clg0k2abo000vt26fx7kohq4s","tag_id":"clg0k2agu0034t26f179ogimv","_id":"clg0k2ajy003yt26fl1n4y19q"},{"post_id":"clg0k2abo000vt26fx7kohq4s","tag_id":"clg0k2ahz003ct26fcwzoqxk6","_id":"clg0k2ak10042t26fknt5p8n3"},{"post_id":"clg0k2abo000vt26fx7kohq4s","tag_id":"clg0k2aja003it26fe466eqfn","_id":"clg0k2ak50046t26fi8rt82xu"},{"post_id":"clg0k2abo000vt26fx7kohq4s","tag_id":"clg0k2ajm003pt26fguu05qut","_id":"clg0k2ak9004at26ffnsazw52"},{"post_id":"clg0k2aby000xt26fa5tclbdf","tag_id":"clg0k2aju003vt26fg7tt73zx","_id":"clg0k2akq004kt26fprd2gzfq"},{"post_id":"clg0k2aby000xt26fa5tclbdf","tag_id":"clg0k2ak40043t26f3kmpx9m2","_id":"clg0k2akr004nt26folz27h19"},{"post_id":"clg0k2aby000xt26fa5tclbdf","tag_id":"clg0k2ake004bt26f8v4ohjo9","_id":"clg0k2akr004qt26fytgeexz1"},{"post_id":"clg0k2akr004ot26f3nm38b9g","tag_id":"clg0k2agu0034t26f179ogimv","_id":"clg0k2aks004tt26f2vgj25st"},{"post_id":"clg0k2aks004ut26f8h7jl3tj","tag_id":"clg0k2agu0034t26f179ogimv","_id":"clg0k2akx004zt26f1umhvksi"},{"post_id":"clg0k2ac00011t26fppgdnx4m","tag_id":"clg0k2akq004it26fbu0q40hr","_id":"clg0k2al00055t26fqa26x6j9"},{"post_id":"clg0k2ac00011t26fppgdnx4m","tag_id":"clg0k2akr004pt26fs0j0w9sv","_id":"clg0k2al30058t26f873vikmm"},{"post_id":"clg0k2ac00011t26fppgdnx4m","tag_id":"clg0k2akw004vt26f6a5rzjkw","_id":"clg0k2al5005dt26fbc033x1a"},{"post_id":"clg0k2ac10014t26fxr065v9i","tag_id":"clg0k2akx0051t26fpoe7jyg3","_id":"clg0k2alf005st26f3rrx0hnt"},{"post_id":"clg0k2ac10014t26fxr065v9i","tag_id":"clg0k2al5005at26fbwn7eu98","_id":"clg0k2alg005vt26f6a0zdso5"},{"post_id":"clg0k2ac10014t26fxr065v9i","tag_id":"clg0k2ala005it26fg9j7ge8k","_id":"clg0k2aln005zt26f276pwqqs"},{"post_id":"clg0k2ac20016t26f0eauehtf","tag_id":"clg0k2ale005ot26f3rq0d91c","_id":"clg0k2alo0062t26fe9yovuzh"},{"post_id":"clg0k2ac3001at26frlrtdk5c","tag_id":"clg0k2alh005wt26ftg5kxjy6","_id":"clg0k2alw006et26fo28r00q5"},{"post_id":"clg0k2ac3001at26frlrtdk5c","tag_id":"clg0k2alo0064t26f203zrcnj","_id":"clg0k2alx006ht26fs2hoyabv"},{"post_id":"clg0k2ac4001bt26f1mr6ck8s","tag_id":"clg0k2alv006ct26f5tvnde1g","_id":"clg0k2alz006zt26fo863di1j"},{"post_id":"clg0k2ac4001bt26f1mr6ck8s","tag_id":"clg0k2alx006kt26fez1p6kze","_id":"clg0k2am00073t26flein4dl2"},{"post_id":"clg0k2ac4001bt26f1mr6ck8s","tag_id":"clg0k2aly006qt26f2o85j7j5","_id":"clg0k2am00077t26ff3w06cyl"},{"post_id":"clg0k2ac5001et26f0aozkpp0","tag_id":"clg0k2alz006xt26fcdl5bjlx","_id":"clg0k2am1007gt26fop48dse0"},{"post_id":"clg0k2ac5001et26f0aozkpp0","tag_id":"clg0k2am00076t26fguxb25rk","_id":"clg0k2am2007kt26feus1lq7c"},{"post_id":"clg0k2ac6001ht26fzgt2ggl9","tag_id":"clg0k2am1007dt26ffdtpkq0x","_id":"clg0k2amf0087t26f6hs7tose"},{"post_id":"clg0k2ac6001ht26fzgt2ggl9","tag_id":"clg0k2am2007lt26fw5efp1hm","_id":"clg0k2amf008at26fhbwltnbx"},{"post_id":"clg0k2ac6001ht26fzgt2ggl9","tag_id":"clg0k2am3007st26fg62ek293","_id":"clg0k2amg008et26fapvhx9ki"},{"post_id":"clg0k2ac6001ht26fzgt2ggl9","tag_id":"clg0k2am4007yt26f0iagi2j9","_id":"clg0k2amk008it26fak457vcj"},{"post_id":"clg0k2am80082t26ff06z2d7a","tag_id":"clg0k2alh005wt26ftg5kxjy6","_id":"clg0k2amp008mt26fzm031l92"},{"post_id":"clg0k2acf001kt26ftqr9zz50","tag_id":"clg0k2amd0084t26fjwd0qirz","_id":"clg0k2amq008qt26f7skc7jvy"},{"post_id":"clg0k2amg008ct26fipfg07e6","tag_id":"clg0k2alh005wt26ftg5kxjy6","_id":"clg0k2amq008ut26f0xkcjztu"},{"post_id":"clg0k2amg008gt26f40jhfyif","tag_id":"clg0k2agu0034t26f179ogimv","_id":"clg0k2amr008yt26fg60b1o8r"},{"post_id":"clg0k2acj001nt26fckvz3bpf","tag_id":"clg0k2amf008bt26fm5xaiuui","_id":"clg0k2ams0094t26f7e11yee9"},{"post_id":"clg0k2acj001nt26fckvz3bpf","tag_id":"clg0k2amo008lt26ff3j5hld4","_id":"clg0k2ams0096t26fksfjasxv"},{"post_id":"clg0k2acj001nt26fckvz3bpf","tag_id":"clg0k2amq008tt26fb4hw5j2q","_id":"clg0k2amt009bt26frhkr9b9q"},{"post_id":"clg0k2acl001qt26fpykbpbv0","tag_id":"clg0k2alh005wt26ftg5kxjy6","_id":"clg0k2amz009ht26fwqnbtfiz"},{"post_id":"clg0k2acl001qt26fpykbpbv0","tag_id":"clg0k2agu0034t26f179ogimv","_id":"clg0k2an0009lt26fxoc7qm91"},{"post_id":"clg0k2acm001st26fti0sj2ba","tag_id":"clg0k2amx009et26ft568y0kz","_id":"clg0k2an0009pt26f94ybrmnu"},{"post_id":"clg0k2ad4001vt26f2e5xqk3d","tag_id":"clg0k2an0009mt26fwlbbauwy","_id":"clg0k2an1009wt26f7td8937j"},{"post_id":"clg0k2ad9001wt26f8r2mvodp","tag_id":"clg0k2an1009ut26fatjfayzy","_id":"clg0k2an100a1t26flpqstgu3"},{"post_id":"clg0k2ada0020t26fvjyyypwr","tag_id":"clg0k2an1009zt26f2u1xax1s","_id":"clg0k2an200a6t26fbqwua758"},{"post_id":"clg0k2adb0021t26fntuez238","tag_id":"clg0k2an1009zt26f2u1xax1s","_id":"clg0k2an200aat26fr2rrw38d"},{"post_id":"clg0k2adl0024t26fzx9xc7s9","tag_id":"clg0k2an200a9t26fwan67v25","_id":"clg0k2an300agt26fpf1a5trv"},{"post_id":"clg0k2adm0026t26f9iuzoj7b","tag_id":"clg0k2an1009ut26fatjfayzy","_id":"clg0k2an300ajt26fo0sp3d5f"},{"post_id":"clg0k2adn0029t26fxuhl9tfz","tag_id":"clg0k2an300aht26fvfyhr23j","_id":"clg0k2an300aot26foat1odh1"},{"post_id":"clg0k2adn002ct26fbii4b5z1","tag_id":"clg0k2an1009ut26fatjfayzy","_id":"clg0k2an400art26fd6atunzx"},{"post_id":"clg0k2ado002dt26fq7n6ir8m","tag_id":"clg0k2an1009ut26fatjfayzy","_id":"clg0k2an400aut26fgod8u436"},{"post_id":"clg0k2ae3002gt26fmj9inlg9","tag_id":"clg0k2an400att26fkpy44kmp","_id":"clg0k2an400ayt26f15znh3el"},{"post_id":"clg0k2ae4002it26fo67pkj8c","tag_id":"clg0k2an400axt26fjn559ayq","_id":"clg0k2an800b2t26ft2hf7qid"},{"post_id":"clg0k2ae5002mt26f3lbdtea0","tag_id":"clg0k2an1009ut26fatjfayzy","_id":"clg0k2and00b6t26f2k9rcffe"},{"post_id":"clg0k2ae5002ot26fukqznvri","tag_id":"clg0k2an1009ut26fatjfayzy","_id":"clg0k2anf00bat26fml24xsbe"},{"post_id":"clg0k2aek002rt26fcacispvg","tag_id":"clg0k2an1009ut26fatjfayzy","_id":"clg0k2anf00bdt26f1w5h405y"},{"post_id":"clg0k2afe002ut26f8818sn1e","tag_id":"clg0k2anf00bct26fqr2qkdjq","_id":"clg0k2anf00bht26fqo50adch"},{"post_id":"clg0k2ag3002yt26fpkui29gr","tag_id":"clg0k2an1009ut26fatjfayzy","_id":"clg0k2ani00blt26fy0jqs1pv"},{"post_id":"clg0k2agn0030t26ffp0qo0cu","tag_id":"clg0k2anf00bct26fqr2qkdjq","_id":"clg0k2anj00bpt26f1ca6blc8"},{"post_id":"clg0k2agu0033t26fqpf54ccu","tag_id":"clg0k2an1009ut26fatjfayzy","_id":"clg0k2ank00btt26fpnb6aii1"},{"post_id":"clg0k2ah90036t26fbe2neeb6","tag_id":"clg0k2ank00brt26fgumkg2ds","_id":"clg0k2ank00bxt26fp1cd1ecv"},{"post_id":"clg0k2ahn0039t26fdgst541q","tag_id":"clg0k2an1009ut26fatjfayzy","_id":"clg0k2anl00c1t26fsaidsr4j"},{"post_id":"clg0k2ai1003dt26ft523oo54","tag_id":"clg0k2an1009ut26fatjfayzy","_id":"clg0k2anl00c5t26fiz3zp8kx"},{"post_id":"clg0k2ain003ft26ftr9z1yku","tag_id":"clg0k2anl00c2t26fja897alo","_id":"clg0k2anl00c9t26fccz9ejdu"},{"post_id":"clg0k2ajd003jt26fm9uuxwvy","tag_id":"clg0k2an1009ut26fatjfayzy","_id":"clg0k2anm00cdt26fjlv1dyiz"},{"post_id":"clg0k2aji003kt26fik5ktvwf","tag_id":"clg0k2an1009ut26fatjfayzy","_id":"clg0k2anm00cht26fnzszgqfm"},{"post_id":"clg0k2ajl003nt26f1387vxd4","tag_id":"clg0k2anm00cet26fzey50c7i","_id":"clg0k2ann00cot26fwu36c79f"},{"post_id":"clg0k2ajl003nt26f1387vxd4","tag_id":"clg0k2anm00cit26f89f1n7v7","_id":"clg0k2ann00cpt26fgp9pb7qe"},{"post_id":"clg0k2ajq003qt26fm252khmm","tag_id":"clg0k2anm00cnt26f0pqc62a5","_id":"clg0k2ann00cwt26fxlugpono"},{"post_id":"clg0k2ajq003qt26fm252khmm","tag_id":"clg0k2an1009ut26fatjfayzy","_id":"clg0k2ann00cxt26ffrw01gts"},{"post_id":"clg0k2aju003tt26fst305u6t","tag_id":"clg0k2anm00cet26fzey50c7i","_id":"clg0k2ano00d1t26f05vpnec6"},{"post_id":"clg0k2ajy003wt26f7xyyoyyr","tag_id":"clg0k2anm00cet26fzey50c7i","_id":"clg0k2ano00d8t26fnn81kwu3"},{"post_id":"clg0k2ajy003wt26f7xyyoyyr","tag_id":"clg0k2an1009ut26fatjfayzy","_id":"clg0k2ano00d9t26fgyavliin"},{"post_id":"clg0k2ak10040t26fodpu4vaq","tag_id":"clg0k2ano00d7t26fpt7blvw5","_id":"clg0k2anp00ddt26fqkildthc"},{"post_id":"clg0k2ak50044t26fjh3rijd0","tag_id":"clg0k2anl00c2t26fja897alo","_id":"clg0k2anp00dht26f7gq32n5t"},{"post_id":"clg0k2ak80048t26f03zs5gk2","tag_id":"clg0k2anp00dgt26fv6rhvmoe","_id":"clg0k2anp00dlt26fvqevmyp5"},{"post_id":"clg0k2ake004ct26f2miap5hq","tag_id":"clg0k2anp00dkt26fjqp6s3cf","_id":"clg0k2anq00dpt26fnv0o4092"},{"post_id":"clg0k2akl004ft26f40unky7l","tag_id":"clg0k2anp00dot26fad7nz4ao","_id":"clg0k2anq00dtt26ft7ce6dw9"},{"post_id":"clg0k2akp004ht26fh6xq0lgb","tag_id":"clg0k2anq00dst26fghusqpav","_id":"clg0k2anq00dxt26f2cmgjnka"},{"post_id":"clg0k2akq004lt26fzv9i9r77","tag_id":"clg0k2aly006qt26f2o85j7j5","_id":"clg0k2anq00e1t26fqtttfm18"},{"post_id":"clg0k2akr004rt26fh6yirhwd","tag_id":"clg0k2anp00dot26fad7nz4ao","_id":"clg0k2anr00e5t26fvus9ysbb"},{"post_id":"clg0k2akw004wt26f62rqecp9","tag_id":"clg0k2anr00e4t26fqiimr4vp","_id":"clg0k2anr00e9t26f9y2nzj76"},{"post_id":"clg0k2akx0050t26fv740cypa","tag_id":"clg0k2an300aht26fvfyhr23j","_id":"clg0k2anr00ect26f0wpz0uyx"},{"post_id":"clg0k2akx0052t26f9yztkweh","tag_id":"clg0k2an1009ut26fatjfayzy","_id":"clg0k2ans00eft26ftqk0z3xb"},{"post_id":"clg0k2al10056t26fojh32hjb","tag_id":"clg0k2anr00edt26f3z9t965k","_id":"clg0k2ans00ejt26fv11hci3e"},{"post_id":"clg0k2al40059t26fqif1l6ng","tag_id":"clg0k2aly006qt26f2o85j7j5","_id":"clg0k2ans00ent26f3pj1fxo5"},{"post_id":"clg0k2al5005et26fieo9h7sq","tag_id":"clg0k2ans00emt26foynxqymh","_id":"clg0k2ans00eqt26fw8uqdlb7"},{"post_id":"clg0k2al7005gt26f20a807e6","tag_id":"clg0k2ans00ept26f0ea9w9ri","_id":"clg0k2ans00est26fr1zycbgm"},{"post_id":"clg0k2ala005kt26fw65uyg2x","tag_id":"clg0k2ans00ert26fdyylndpl","_id":"clg0k2ans00eut26fm12wlois"},{"post_id":"clg0k2ald005mt26f5dc7tesq","tag_id":"clg0k2anm00cit26f89f1n7v7","_id":"clg0k2ant00ewt26fr7qpcqnf"},{"post_id":"clg0k2alf005pt26fd823ftxy","tag_id":"clg0k2an400att26fkpy44kmp","_id":"clg0k2ant00eyt26foilm9p1z"},{"post_id":"clg0k2alg005tt26f1hin0ad0","tag_id":"clg0k2ant00ext26f4hkdfk4r","_id":"clg0k2ant00f0t26f06mf0r9z"},{"post_id":"clg0k2ali005xt26fumef1my1","tag_id":"clg0k2an400att26fkpy44kmp","_id":"clg0k2ant00f2t26fe0y8wemb"},{"post_id":"clg0k2alo0060t26f301wqmii","tag_id":"clg0k2ant00f1t26fugiebqc7","_id":"clg0k2ant00f4t26fef1ksx01"},{"post_id":"clg0k2alo0063t26fz5c18acl","tag_id":"clg0k2an1009ut26fatjfayzy","_id":"clg0k2ant00f6t26f678jj8ed"},{"post_id":"clg0k2alp0067t26fgp718a9d","tag_id":"clg0k2an1009ut26fatjfayzy","_id":"clg0k2anu00f8t26fy37szxxk"},{"post_id":"clg0k2als0069t26f4qf1nwab","tag_id":"clg0k2an1009ut26fatjfayzy","_id":"clg0k2anu00fat26flci9k7i1"},{"post_id":"clg0k2alw006dt26fq65wxvyt","tag_id":"clg0k2an1009ut26fatjfayzy","_id":"clg0k2anu00fct26f99dc1fx5"},{"post_id":"clg0k2alw006gt26f29jlsiz0","tag_id":"clg0k2anu00fbt26fxbt3at1u","_id":"clg0k2anu00fft26f5ytd17vw"},{"post_id":"clg0k2alw006gt26f29jlsiz0","tag_id":"clg0k2amd0084t26fjwd0qirz","_id":"clg0k2anu00fgt26fs9lvbrxc"},{"post_id":"clg0k2alx006lt26fm6snn2z9","tag_id":"clg0k2an1009ut26fatjfayzy","_id":"clg0k2anv00fit26fpu045vsp"},{"post_id":"clg0k2alx006nt26flq1ztkt2","tag_id":"clg0k2an1009ut26fatjfayzy","_id":"clg0k2anv00fkt26f5f2uqrnu"},{"post_id":"clg0k2aly006rt26fys80sagk","tag_id":"clg0k2ant00ext26f4hkdfk4r","_id":"clg0k2anv00fmt26fvtkqgbbo"},{"post_id":"clg0k2aly006tt26f6wx9xa44","tag_id":"clg0k2anv00flt26f85i4e42d","_id":"clg0k2anv00fot26f77xiqx1r"},{"post_id":"clg0k2alz006wt26fd80oidjh","tag_id":"clg0k2anv00fnt26fjy2z7u63","_id":"clg0k2anv00fqt26ff21jvce6"},{"post_id":"clg0k2alz0070t26foj5n91h9","tag_id":"clg0k2ano00d7t26fpt7blvw5","_id":"clg0k2anv00fst26f19qy79yc"},{"post_id":"clg0k2am00074t26fz68b8ogr","tag_id":"clg0k2an1009ut26fatjfayzy","_id":"clg0k2anw00fut26fo6fikhc3"},{"post_id":"clg0k2am00078t26fplvndi5t","tag_id":"clg0k2anv00ftt26fjndjchdz","_id":"clg0k2anw00fwt26f5b2xvbfs"},{"post_id":"clg0k2am0007bt26fza8oop1z","tag_id":"clg0k2an1009ut26fatjfayzy","_id":"clg0k2anw00fyt26fp7nzjnog"},{"post_id":"clg0k2am1007et26fa5p3ag88","tag_id":"clg0k2ans00ert26fdyylndpl","_id":"clg0k2anw00g0t26f7ik9nlvq"},{"post_id":"clg0k2am1007it26ffjby2ibe","tag_id":"clg0k2anw00fzt26fngr4lv4p","_id":"clg0k2anw00g2t26f6ixz6nk5"},{"post_id":"clg0k2am2007mt26fv3uqirp1","tag_id":"clg0k2ans00ert26fdyylndpl","_id":"clg0k2anw00g4t26fsv6j9j72"},{"post_id":"clg0k2am2007ot26fyzcfe5ry","tag_id":"clg0k2ans00ert26fdyylndpl","_id":"clg0k2anx00g6t26fie4y1z2k"},{"post_id":"clg0k2am3007rt26fa515kbuo","tag_id":"clg0k2an1009ut26fatjfayzy","_id":"clg0k2anx00g8t26ff4jacaxu"},{"post_id":"clg0k2am3007ut26f3d1n3ng1","tag_id":"clg0k2ans00ert26fdyylndpl","_id":"clg0k2anx00gat26fqfy4xv4j"},{"post_id":"clg0k2am3007xt26f3jwg1hed","tag_id":"clg0k2ans00ert26fdyylndpl","_id":"clg0k2anx00gct26f2r6dgmf9"},{"post_id":"clg0k2am4007zt26f300uvrkj","tag_id":"clg0k2anx00gbt26fhq8vicgx","_id":"clg0k2anx00get26frbagt9su"},{"post_id":"clg0k2amd0085t26fotwp1uru","tag_id":"clg0k2ans00ert26fdyylndpl","_id":"clg0k2any00ggt26fml3lhc3a"},{"post_id":"clg0k2amf0089t26fsbac5mw4","tag_id":"clg0k2an400att26fkpy44kmp","_id":"clg0k2any00git26fz6gc657o"},{"post_id":"clg0k2amk008jt26fn0lsekaz","tag_id":"clg0k2ant00ext26f4hkdfk4r","_id":"clg0k2any00gkt26f93nvdzmo"},{"post_id":"clg0k2amp008ot26f2zjr6ibs","tag_id":"clg0k2ans00ept26f0ea9w9ri","_id":"clg0k2any00gmt26foa1t5gno"},{"post_id":"clg0k2amq008rt26f7vnybqjh","tag_id":"clg0k2anv00fnt26fjy2z7u63","_id":"clg0k2any00got26fc0l0o9ld"},{"post_id":"clg0k2amq008wt26f55zujceo","tag_id":"clg0k2any00gnt26f46gd3rmg","_id":"clg0k2anz00gqt26fy5is6tlm"},{"post_id":"clg0k2amr008zt26feqgiett2","tag_id":"clg0k2any00gpt26fyxv532en","_id":"clg0k2anz00gst26f4p0s9wpc"},{"post_id":"clg0k2amr0092t26f1ufvokun","tag_id":"clg0k2an1009ut26fatjfayzy","_id":"clg0k2anz00gut26f7kc4yfel"},{"post_id":"clg0k2ams0095t26f3zaj3yqb","tag_id":"clg0k2an1009ut26fatjfayzy","_id":"clg0k2anz00gwt26fdrq3dogx"},{"post_id":"clg0k2amt0098t26f5ujmwi8f","tag_id":"clg0k2any00gpt26fyxv532en","_id":"clg0k2anz00gyt26fu9ft7x5u"},{"post_id":"clg0k2amt009ct26flwfrnvwi","tag_id":"clg0k2an1009ut26fatjfayzy","_id":"clg0k2anz00h0t26f7kvpyfbm"},{"post_id":"clg0k2amx009ft26fh3xbnosw","tag_id":"clg0k2anz00gzt26fmph9s942","_id":"clg0k2ao000h2t26f7wcvs9lm"},{"post_id":"clg0k2amz009jt26fcaqshlxj","tag_id":"clg0k2ao000h1t26f4nujsraf","_id":"clg0k2ao000h4t26f9zkwyg1x"},{"post_id":"clg0k2an0009nt26fgy2atepz","tag_id":"clg0k2an1009ut26fatjfayzy","_id":"clg0k2ao000h6t26f6e9ao05f"},{"post_id":"clg0k2an0009rt26fuizbv8go","tag_id":"clg0k2ao000h5t26fa2moa7kp","_id":"clg0k2ao000h8t26fe6wuxy8m"},{"post_id":"clg0k2an1009tt26fgep1l2vf","tag_id":"clg0k2ao000h7t26fah4e88zt","_id":"clg0k2ao000hat26f5hy6m9mf"},{"post_id":"clg0k2an1009tt26fgep1l2vf","tag_id":"clg0k2ao000h9t26fkye17qcy","_id":"clg0k2ao000hbt26fz0qfc4to"},{"post_id":"clg0k2aol00hdt26fry5jx7oj","tag_id":"clg0k2ac10012t26fej9vf7aq","_id":"clg0k2aou00hht26f5r9j7f25"},{"post_id":"clg0k2aol00hdt26fry5jx7oj","tag_id":"clg0k2ac30018t26fvdb4jwaq","_id":"clg0k2aou00hjt26fnpoe1prs"},{"post_id":"clg0k2aol00hdt26fry5jx7oj","tag_id":"clg0k2ac5001dt26f8g8q2sg5","_id":"clg0k2aov00hnt26fqkjanqcl"},{"post_id":"clg0k2aos00hgt26f42a7km0i","tag_id":"clg0k2abm000nt26f2pu8d1cr","_id":"clg0k2ap900hpt26f9lw3xz5t"},{"post_id":"clg0k2aou00hkt26fbyn9gewu","tag_id":"clg0k2alh005wt26ftg5kxjy6","_id":"clg0k2apn00htt26fnj35oy4w"},{"post_id":"clg0k2aov00hot26fpkth3z3s","tag_id":"clg0k2an400att26fkpy44kmp","_id":"clg0k2apz00hwt26f0l4k8rlj"},{"post_id":"clg0k2aog00hct26fsr149y42","tag_id":"clg0k2aos00hft26f93pywtcg","_id":"clg0k2aqb00i1t26fhy4157mr"},{"post_id":"clg0k2aog00hct26fsr149y42","tag_id":"clg0k2aov00hlt26f3f490u4h","_id":"clg0k2aql00i4t26fw643k8gf"},{"post_id":"clg0k2apb00hqt26ff1sxdw6z","tag_id":"clg0k2an1009ut26fatjfayzy","_id":"clg0k2ar000i7t26fnqgkqf4d"},{"post_id":"clg0k2aou00hit26f1qbykpdj","tag_id":"clg0k2apf00hst26fl2ztof39","_id":"clg0k2arb00ict26ftimhk43l"},{"post_id":"clg0k2aq200hxt26f3l518d6l","tag_id":"clg0k2an300aht26fvfyhr23j","_id":"clg0k2arc00iet26f3gralnsx"},{"post_id":"clg0k2aqb00i2t26fscm8v1yn","tag_id":"clg0k2an1009ut26fatjfayzy","_id":"clg0k2ard00iit26ftzrjh6ub"},{"post_id":"clg0k2aqb00i2t26fscm8v1yn","tag_id":"clg0k2any00gnt26f46gd3rmg","_id":"clg0k2are00ilt26fzuq9594f"},{"post_id":"clg0k2apn00hut26f8tbkns9e","tag_id":"clg0k2aqb00i0t26fxclu6y1q","_id":"clg0k2are00iot26f28wdk3f9"},{"post_id":"clg0k2arb00idt26f3im7va7s","tag_id":"clg0k2anv00fnt26fjy2z7u63","_id":"clg0k2are00irt26f9x85dsxb"},{"post_id":"clg0k2arc00ift26fucipng4b","tag_id":"clg0k2ao000h5t26fa2moa7kp","_id":"clg0k2arh00iut26fbju401ks"},{"post_id":"clg0k2aqn00i5t26fwobzynza","tag_id":"clg0k2arb00ibt26fj3wnw52h","_id":"clg0k2ari00iwt26fljoz6pys"},{"post_id":"clg0k2ar100i8t26fs8efff96","tag_id":"clg0k2ard00ikt26fnb15rl9c","_id":"clg0k2ari00iyt26f7masdf1y"},{"post_id":"clg0k2ard00ijt26fxbpizrtx","tag_id":"clg0k2ao000h7t26fah4e88zt","_id":"clg0k2ari00j0t26ftqtp4g2z"},{"post_id":"clg0k2ard00ijt26fxbpizrtx","tag_id":"clg0k2are00iqt26fo7jugdal","_id":"clg0k2ari00j1t26fcr21ogh6"},{"post_id":"clg0k2arv00j6t26fsovu8omk","tag_id":"clg0k2an1009ut26fatjfayzy","_id":"clg0k2asb00jat26f9pjdl67a"},{"post_id":"clg0k2arv00j5t26f79tb2qp2","tag_id":"clg0k2as200j8t26fz6i7u5os","_id":"clg0k2asc00jet26fk0nn3f95"},{"post_id":"clg0k2as300j9t26fq5g7k4yg","tag_id":"clg0k2asc00jdt26fagemsawg","_id":"clg0k2asc00jgt26fr70izcna"},{"post_id":"clg0k2asi00jit26fhbnyicb9","tag_id":"clg0k2asm00jkt26fouhf44ro","_id":"clg0k2ath00jlt26ffaezqt1u"},{"post_id":"clg0k2aui00jnt26f0dgd6e3s","tag_id":"clg0k2ano00d7t26fpt7blvw5","_id":"clg0k2auq00jpt26fqjvcc963"},{"post_id":"clg0k2auo00jot26fsllxnm0z","tag_id":"clg0k2ans00ert26fdyylndpl","_id":"clg0k2auy00jqt26fieqari2f"},{"post_id":"clg0k2aza00jtt26fwe3ur7d3","tag_id":"clg0k2agu0034t26f179ogimv","_id":"clg0k2aze00jwt26fhlhyazvh"},{"post_id":"clg0k2aza00jtt26fwe3ur7d3","tag_id":"clg0k2anm00cet26fzey50c7i","_id":"clg0k2aze00jxt26fxicbbwek"},{"post_id":"clg0k2aza00jtt26fwe3ur7d3","tag_id":"clg0k2aze00jut26fdftxann0","_id":"clg0k2azf00jyt26f32cbhf1w"}],"Tag":[{"name":"oop","_id":"clg0k2a9r0002t26fe9gbrkq9"},{"name":"float","_id":"clg0k2ab8000ft26f7rz103xh"},{"name":"servlet","_id":"clg0k2abl000jt26fb024tidq"},{"name":"re","_id":"clg0k2abm000nt26f2pu8d1cr"},{"name":"String","_id":"clg0k2abn000st26fpq4tm6ed"},{"name":"new","_id":"clg0k2aby000yt26fxoh828bg"},{"name":"sample post","_id":"clg0k2ac10012t26fej9vf7aq"},{"name":"images","_id":"clg0k2ac30018t26fvdb4jwaq"},{"name":"test","_id":"clg0k2ac5001dt26f8g8q2sg5"},{"name":"catch，try","_id":"clg0k2ac7001it26f12ut8n9a"},{"name":"sql","_id":"clg0k2ack001ot26fxc7jnocf"},{"name":"select","_id":"clg0k2acz001ut26f2rl4mvuh"},{"name":"distinct","_id":"clg0k2ada001zt26fgzzd1oiy"},{"name":"group by","_id":"clg0k2adl0025t26fmxl5p8ji"},{"name":"order by","_id":"clg0k2adn002at26f79o6u6w1"},{"name":"oracle","_id":"clg0k2ae2002ft26fmqh19q16"},{"name":"sys","_id":"clg0k2ae4002lt26fee5o762a"},{"name":"sqlplus","_id":"clg0k2aep002st26fc50irk2r"},{"name":"java","_id":"clg0k2agu0034t26f179ogimv"},{"name":"reflect","_id":"clg0k2ahz003ct26fcwzoqxk6"},{"name":"Class","_id":"clg0k2aja003it26fe466eqfn"},{"name":"对象，Class对象","_id":"clg0k2ajm003pt26fguu05qut"},{"name":"github","_id":"clg0k2aju003vt26fg7tt73zx"},{"name":"hexo","_id":"clg0k2ak40043t26f3kmpx9m2"},{"name":"git","_id":"clg0k2ake004bt26f8v4ohjo9"},{"name":"linux","_id":"clg0k2akq004it26fbu0q40hr"},{"name":"ss","_id":"clg0k2akr004pt26fs0j0w9sv"},{"name":"console","_id":"clg0k2akw004vt26f6a5rzjkw"},{"name":"suse","_id":"clg0k2akx0051t26fpoe7jyg3"},{"name":"server","_id":"clg0k2al5005at26fbwn7eu98"},{"name":"FTP","_id":"clg0k2ala005it26fg9j7ge8k"},{"name":"编码","_id":"clg0k2ale005ot26f3rq0d91c"},{"name":"mysql","_id":"clg0k2alh005wt26ftg5kxjy6"},{"name":"备份","_id":"clg0k2alo0064t26f203zrcnj"},{"name":"quartz","_id":"clg0k2alv006ct26f5tvnde1g"},{"name":"锁","_id":"clg0k2alx006kt26fez1p6kze"},{"name":"分布式","_id":"clg0k2aly006qt26f2o85j7j5"},{"name":"mq","_id":"clg0k2alz006xt26fcdl5bjlx"},{"name":"消息队列","_id":"clg0k2am00076t26fguxb25rk"},{"name":"RSA","_id":"clg0k2am1007dt26ffdtpkq0x"},{"name":"SHA","_id":"clg0k2am2007lt26fw5efp1hm"},{"name":"加密","_id":"clg0k2am3007st26fg62ek293"},{"name":"签名","_id":"clg0k2am4007yt26f0iagi2j9"},{"name":"Linux","_id":"clg0k2amd0084t26fjwd0qirz"},{"name":"职业","_id":"clg0k2amf008bt26fm5xaiuui"},{"name":"业务","_id":"clg0k2amo008lt26ff3j5hld4"},{"name":"学习","_id":"clg0k2amq008tt26fb4hw5j2q"},{"name":"NIO BIO IO","_id":"clg0k2amx009et26ft568y0kz"},{"name":"Guava","_id":"clg0k2an0009mt26fwlbbauwy"},{"name":"Java","_id":"clg0k2an1009ut26fatjfayzy"},{"name":"jvm","_id":"clg0k2an1009zt26f2u1xax1s"},{"name":"MQ","_id":"clg0k2an200a9t26fwan67v25"},{"name":"other","_id":"clg0k2an300aht26fvfyhr23j"},{"name":"Web","_id":"clg0k2an400att26fkpy44kmp"},{"name":"node.js","_id":"clg0k2an400axt26fjn559ayq"},{"name":"RocketMQ","_id":"clg0k2anf00bct26fqr2qkdjq"},{"name":"Mysql","_id":"clg0k2ank00brt26fgumkg2ds"},{"name":"SQL","_id":"clg0k2anl00c2t26fja897alo"},{"name":"多线程","_id":"clg0k2anm00cet26fzey50c7i"},{"name":"算法","_id":"clg0k2anm00cit26f89f1n7v7"},{"name":"tools","_id":"clg0k2anm00cnt26f0pqc62a5"},{"name":"MySQL","_id":"clg0k2ano00d7t26fpt7blvw5"},{"name":"Ohters","_id":"clg0k2anp00dgt26fv6rhvmoe"},{"name":"others","_id":"clg0k2anp00dkt26fjqp6s3cf"},{"name":"maven","_id":"clg0k2anp00dot26fad7nz4ao"},{"name":"AI","_id":"clg0k2anq00dst26fghusqpav"},{"name":"blog","_id":"clg0k2anr00e4t26fqiimr4vp"},{"name":"JavaScript","_id":"clg0k2anr00edt26f3z9t965k"},{"name":"vue","_id":"clg0k2ans00emt26foynxqymh"},{"name":"SpringBoot","_id":"clg0k2ans00ept26f0ea9w9ri"},{"name":"Spring","_id":"clg0k2ans00ert26fdyylndpl"},{"name":"JDK","_id":"clg0k2ant00ext26f4hkdfk4r"},{"name":"分页","_id":"clg0k2ant00f1t26fugiebqc7"},{"name":"Windows","_id":"clg0k2anu00fbt26fxbt3at1u"},{"name":"杂谈","_id":"clg0k2anv00flt26f85i4e42d"},{"name":"JVM","_id":"clg0k2anv00fnt26fjy2z7u63"},{"name":"SpringCloud","_id":"clg0k2anv00ftt26fjndjchdz"},{"name":"Spring Cloud","_id":"clg0k2anw00fzt26fngr4lv4p"},{"name":"Maven","_id":"clg0k2anx00gbt26fhq8vicgx"},{"name":"并发","_id":"clg0k2any00gnt26f46gd3rmg"},{"name":"数据库","_id":"clg0k2any00gpt26fyxv532en"},{"name":"feign","_id":"clg0k2anz00gzt26fmph9s942"},{"name":"Kafka","_id":"clg0k2ao000h1t26f4nujsraf"},{"name":"netty","_id":"clg0k2ao000h5t26fa2moa7kp"},{"name":"SpringMVC","_id":"clg0k2ao000h7t26fah4e88zt"},{"name":"Actuator","_id":"clg0k2ao000h9t26fkye17qcy"},{"name":"resume","_id":"clg0k2aos00hft26f93pywtcg"},{"name":"简历","_id":"clg0k2aov00hlt26f3f490u4h"},{"name":"jdk","_id":"clg0k2apf00hst26fl2ztof39"},{"name":"网络","_id":"clg0k2aqb00i0t26fxclu6y1q"},{"name":"Nginx","_id":"clg0k2arb00ibt26fj3wnw52h"},{"name":"MongoDB","_id":"clg0k2ard00ikt26fnb15rl9c"},{"name":"Logger","_id":"clg0k2are00iqt26fo7jugdal"},{"name":"spring","_id":"clg0k2as200j8t26fz6i7u5os"},{"name":"架构","_id":"clg0k2asc00jdt26fagemsawg"},{"name":"面试","_id":"clg0k2asm00jkt26fouhf44ro"},{"name":"安全","_id":"clg0k2aze00jut26fdftxann0"}]}}